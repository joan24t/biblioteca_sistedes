<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0"
	xmlns:excerpt="http://wordpress.org/export/1.2/excerpt/"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:wp="http://wordpress.org/export/1.2/"
>
	<item>
		<title>Un índice espacio-temporal compacto para consultas time-slice y time-interval</title>
		<link>https://biblioteca.sistedes.es/articulo/un-indice-espacio-temporal-compacto-para-consultas-time-slice-y-time-interval/</link>
		<pubDate>Mon, 10 Aug 2015 19:30:45 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=123</guid>
		<description></description>
		<content><![CDATA[La indexación de datos espacio-temporales es fundamental para responder de manera eficiente consultas acerca de objetos móviles que se encuentran en una región durante un instante o intervalo temporal determinado. Esto es de interés, por ejemplo, para detectar embarcaciones que invaden zonas de navegación prohibidas. Este artículo presenta un índice espacio-temporal compacto (eficiente en espacio) que permite responder ambos tipos de consultas. La evaluación experimental muestra que el índice propuesto es competitivo en tiempo al compararlo con el MVR-Tree usando significativamente menos espacio.]]></content>
		<excerpt><![CDATA[La indexación de datos espacio-temporales es fundamental para responder de manera eficiente consultas acerca de objetos móviles que se encuentran en una región durante un instante o intervalo temporal determinado. Esto es de interés, por ejemplo, para detectar embarcaciones que invaden zonas de navegación prohibidas. Este artículo presenta un índice espacio-temporal compacto (eficiente en espacio) que permite responder ambos tipos de consultas. La evaluación experimental muestra que el índice propuesto es competitivo en tiempo al compararlo con el MVR-Tree usando significativamente menos espacio.]]></excerpt>
		<post_id>123</post_id>
		<post_date><![CDATA[2015-08-10 21:30:45]]></post_date>
		<post_date_gmt><![CDATA[2015-08-10 19:30:45]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-indice-espacio-temporal-compacto-para-consultas-time-slice-y-time-interval]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="espacio-temporal"><![CDATA[espacio-temporal]]></category>
		<category domain="post_tag" nicename="estructura-de-datos-compacta"><![CDATA[estructura de datos compacta]]></category>
		<category domain="post_tag" nicename="indexacion"><![CDATA[indexación]]></category>
		<category domain="post_tag" nicename="objeto-movil"><![CDATA[Objeto móvil]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Nieves R. Brisaboa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de datos, Universidade da Coruña Campus de Elviña, 15071 A Coruña, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[brisaboa@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ramón Casares]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de datos, Universidade da Coruña Campus de Elviña, 15071 A Coruña, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[rcasares@enxenio.es 2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Andrea Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Concepción, Departamento de Ingeniería Informática y Ciencias de la Computación, Edmundo Larenas 215, 4070409 Concepción, Chile]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[andrea@udec.cl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Miguel Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad del Bío-Bío, Departamento de Ciencias de la Computación y Tecnologías de la Información Andrés Bello s/n, 3800708 Chillán, Chile]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[miguel.romero@ubiobio.cl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Diego Seco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Concepción, Departamento de Ingeniería Informática y Ciencias de la Computación, Edmundo Larenas 215, 4070409 Concepción, Chile]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[dseco@udec.cl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La indexación de datos espacio-temporales es fundamental para responder de manera eficiente consultas acerca de objetos móviles que se encuentran en una región durante un instante o intervalo temporal determinado. Esto es de interés, por ejemplo, para detectar embarcaciones que invaden zonas de navegación prohibidas. Este artículo presenta un índice espacio-temporal compacto (eficiente en espacio) que permite responder ambos tipos de consultas. La evaluación experimental muestra que el índice propuesto es competitivo en tiempo al compararlo con el MVR-Tree usando significativamente menos espacio.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Objeto móvil, espacio-temporal, estructura de datos compacta, indexación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[gestion de datos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[124]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/009]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Query approximation in the case of incompletely aligned datasets</title>
		<link>https://biblioteca.sistedes.es/articulo/query-approximation-in-the-case-of-incompletely-aligned-datasets/</link>
		<pubDate>Mon, 10 Aug 2015 19:39:38 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=128</guid>
		<description></description>
		<content><![CDATA[Clouds of Linked Open Data about the same domain promote the formulation of a query over a source dataset and then try to process the same query over different target datasets, one after another, in order to obtain a broader set of answers. However, heterogeneity of vocabularies used in the datasets and the scarce number of alignments among those datasets makes that querying task extremely difficult. This paper presents a proposal that allows on demand transformations of queries by using a set of transformation rules that are able to rewrite a query formulated over a source dataset into another query adequate for a target dataset, which approximates the original one. The approach relieves users from knowing the vocabulary used in the targeted datasets and even more it considers situations where alignments do not exist or they are not suitable for the formulated query. Therefore, in order to favor the possibility of getting answers, sometimes there is no guarantee of obtaining a semantically equivalent translation. Experiments with benchmark queries validate the feasibility of the proposal.]]></content>
		<excerpt><![CDATA[Clouds of Linked Open Data about the same domain promote the formulation of a query over a source dataset and then try to process the same query over different target datasets, one after another, in order to obtain a broader set of answers. However, heterogeneity of vocabularies used in the datasets and the scarce number of alignments among those datasets makes that querying task extremely difficult. This paper presents a proposal that allows on demand transformations of queries by using a set of transformation rules that are able to rewrite a query formulated over a source dataset into another query adequate for a target dataset, which approximates the original one. The approach relieves users from knowing the vocabulary used in the targeted datasets and even more it considers situations where alignments do not exist or they are not suitable for the formulated query. Therefore, in order to favor the possibility of getting answers, sometimes there is no guarantee of obtaining a semantically equivalent translation. Experiments with benchmark queries validate the feasibility of the proposal.]]></excerpt>
		<post_id>128</post_id>
		<post_date><![CDATA[2015-08-10 21:39:38]]></post_date>
		<post_date_gmt><![CDATA[2015-08-10 19:39:38]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[query-approximation-in-the-case-of-incompletely-aligned-datasets]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana I. Torre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Tecnalia Research & Innovation]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[isabel.torre@tecnalia.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jesus Bermudez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country UPV/EHU]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jesus.bermudez@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Arantza Illarramendi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country UPV/EHU]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[a.illarramendi@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Clouds of Linked Open Data about the same domain promote the formulation of a query over a source dataset and then try to process the same query over different target datasets, one after another, in order to obtain a broader set of answers. However, heterogeneity of vocabularies used in the datasets and the scarce number of alignments among those datasets makes that querying task extremely difficult. This paper presents a proposal that allows on demand transformations of queries by using a set of transformation rules that are able to rewrite a query formulated over a source dataset into another query adequate for a target dataset, which approximates the original one. The approach relieves users from knowing the vocabulary used in the targeted datasets and even more it considers situations where alignments do not exist or they are not suitable for the formulated query. Therefore, in order to favor the possibility of getting answers, sometimes there is no guarantee of obtaining a semantically equivalent translation. Experiments with benchmark queries validate the feasibility of the proposal.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[129]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/008]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A First Step Towards Keyword-Based Searching for Recommendation Systems</title>
		<link>https://biblioteca.sistedes.es/articulo/a-first-step-towards-keyword-based-searching-for-recommendation-systems/</link>
		<pubDate>Mon, 10 Aug 2015 19:45:00 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=131</guid>
		<description></description>
		<content><![CDATA[Due to the high availability of data, users are frequently overloaded with a huge amount of alternatives when they need to choose a particular item. This has motivated an increased interest in research on recommendation systems, which filter the options and provide users with suggestions about specific elements (e.g., movies, restaurants, hotels, news, etc.) that are estimated to be potentially relevant for the user. Recommendation systems are still an active area of research, and particularly in the last years the concept of context-aware recommendation systems has started to be popular, due to the interest of considering the context of the user in the recommendation process. In this paper, we describe our work-in-progress concerning pull-based recommendations (i.e., recommendations about certain types of items that are explicitly requested by the user). In particular, we focus on the problem of detecting the type of item the user is interested in. Due to its popularity, we consider a keyword-based user interface: the user types a few keywords and the system must determine what the user is searching for. Whereas there is extensive work in the field of keyword-based search, which is still a very active research area, keyword searching has not been applied so far in most recommendation contexts.]]></content>
		<excerpt><![CDATA[Due to the high availability of data, users are frequently overloaded with a huge amount of alternatives when they need to choose a particular item. This has motivated an increased interest in research on recommendation systems, which filter the options and provide users with suggestions about specific elements (e.g., movies, restaurants, hotels, news, etc.) that are estimated to be potentially relevant for the user. Recommendation systems are still an active area of research, and particularly in the last years the concept of context-aware recommendation systems has started to be popular, due to the interest of considering the context of the user in the recommendation process. In this paper, we describe our work-in-progress concerning pull-based recommendations (i.e., recommendations about certain types of items that are explicitly requested by the user). In particular, we focus on the problem of detecting the type of item the user is interested in. Due to its popularity, we consider a keyword-based user interface: the user types a few keywords and the system must determine what the user is searching for. Whereas there is extensive work in the field of keyword-based search, which is still a very active research area, keyword searching has not been applied so far in most recommendation contexts.]]></excerpt>
		<post_id>131</post_id>
		<post_date><![CDATA[2015-08-10 21:45:00]]></post_date>
		<post_date_gmt><![CDATA[2015-08-10 19:45:00]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-first-step-towards-keyword-based-searching-for-recommendation-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="keyword-based-search"><![CDATA[keyword-based search]]></category>
		<category domain="post_tag" nicename="mobile-computing"><![CDATA[mobile computing]]></category>
		<category domain="post_tag" nicename="recommendation-systems"><![CDATA[recommendation systems]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María del Carmen Rodríguez-Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science and Systems Engineering University of Zaragoza, Zaragoza, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mary0485@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francesco Guerra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Modena and Reggio Emilia, Modena, Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[francesco.guerra@unimore.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sergio Ilarri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science and Systems Engineering University of Zaragoza, Zaragoza, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[silarri@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Raquel Trillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science and Systems Engineering University of Zaragoza, Zaragoza, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[raqueltl@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Due to the high availability of data, users are frequently overloaded with a huge amount of alternatives when they need to choose a particular item. This has motivated an increased interest in research on recommendation systems, which filter the options and provide users with suggestions about specific elements (e.g., movies, restaurants, hotels, news, etc.) that are estimated to be potentially relevant for the user. Recommendation systems are still an active area of research, and particularly in the last years the concept of context-aware recommendation systems has started to be popular, due to the interest of considering the context of the user in the recommendation process. In this paper, we describe our work-in-progress concerning pull-based recommendations (i.e., recommendations about certain types of items that are explicitly requested by the user). In particular, we focus on the problem of detecting the type of item the user is interested in. Due to its popularity, we consider a keyword-based user interface: the user types a few keywords and the system must determine what the user is searching for. Whereas there is extensive work in the field of keyword-based search, which is still a very active research area, keyword searching has not been applied so far in most recommendation contexts.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[keyword-based search, recommendation systems, mobile computing]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[132]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/007]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Integración semántica de datos de observación mediante servicios SOS</title>
		<link>https://biblioteca.sistedes.es/articulo/integracion-semantica-de-datos-de-observacion-mediante-servicios-sos/</link>
		<pubDate>Mon, 10 Aug 2015 19:51:47 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=134</guid>
		<description></description>
		<content><![CDATA[En este documento se describe el trabajo en marcha de diseño e implementación de un servicio de acceso a datos de observación medioambiental SOS (Sensor Observation Service) que permite la integración semántica de fuentes de datos accesible a través de este estándar.]]></content>
		<excerpt><![CDATA[En este documento se describe el trabajo en marcha de diseño e implementación de un servicio de acceso a datos de observación medioambiental SOS (Sensor Observation Service) que permite la integración semántica de fuentes de datos accesible a través de este estándar.]]></excerpt>
		<post_id>134</post_id>
		<post_date><![CDATA[2015-08-10 21:51:47]]></post_date>
		<post_date_gmt><![CDATA[2015-08-10 19:51:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[integracion-semantica-de-datos-de-observacion-mediante-servicios-sos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="integracion-semantica"><![CDATA[Integración Semántica]]></category>
		<category domain="post_tag" nicename="observacion-medioambiental"><![CDATA[Observación Medioambiental]]></category>
		<category domain="post_tag" nicename="ogc"><![CDATA[OGC]]></category>
		<category domain="post_tag" nicename="ontologias"><![CDATA[Ontologías]]></category>
		<category domain="post_tag" nicename="sensor-web"><![CDATA[Sensor Web]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel A. Regueiro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Computer Graphics and Data Engineering Group (COGRADE) Centro de Investigaci´on en Tecnolox´ıas da Informaci´on (CITIUS) Universidade de Santiago de Compostela (USC) Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[manuelantonio.regueiro@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José  R.R. Viqueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Computer Graphics and Data Engineering Group (COGRADE) Centro de Investigaci´on en Tecnolox´ıas da Informaci´on (CITIUS) Universidade de Santiago de Compostela (USC) Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrr.viqueira@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Christoph Stasch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[52 North Initiative for Geospatial Open Source Software GmbH Martin-Luther-King-Weg 24, 48155 Muenster, Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[c.stasch@52north.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José M. Cotos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Computer Graphics and Data Engineering Group (COGRADE) Centro de Investigaci´on en Tecnolox´ıas da Informaci´on (CITIUS) Universidade de Santiago de Compostela (USC) Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manel.cotos@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este documento se describe el trabajo en marcha de diseño e implementación de un servicio de acceso a datos de observación medioambiental SOS (Sensor Observation Service) que permite la integración semántica de fuentes de datos accesible a través de este estándar.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[OGC, Sensor Web, Observación Medioambiental, Ontologías, Integración Semántica]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[135]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/006]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Optimización del Almacenamiento de Datos en la Gestión Energética de Edificios Inteligentes</title>
		<link>https://biblioteca.sistedes.es/articulo/optimizacion-del-almacenamiento-de-datos-en-la-gestion-energetica-de-edificios-inteligentes/</link>
		<pubDate>Mon, 10 Aug 2015 20:02:42 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=137</guid>
		<description></description>
		<content><![CDATA[El objetivo principal del proyecto LIFE-OPERE es mejorar la gestión energética en grandes instalaciones de la Universidad de Santiago de Compostela (USC). Se almacenará y analizará la información de sensorización de los edificios para determinar el impacto de las nuevas medidas adoptadas. Para ello, se ha diseñado e implementado un sistema de adquisición, almacenamiento y publicación de datos. Este artículo se centra en la optimización del modelo de datos para hacer frente a los problemas y retos que han surgido durante el proyecto. Además, se valora también la necesidad de implantar una infraestructura big data.]]></content>
		<excerpt><![CDATA[El objetivo principal del proyecto LIFE-OPERE es mejorar la gestión energética en grandes instalaciones de la Universidad de Santiago de Compostela (USC). Se almacenará y analizará la información de sensorización de los edificios para determinar el impacto de las nuevas medidas adoptadas. Para ello, se ha diseñado e implementado un sistema de adquisición, almacenamiento y publicación de datos. Este artículo se centra en la optimización del modelo de datos para hacer frente a los problemas y retos que han surgido durante el proyecto. Además, se valora también la necesidad de implantar una infraestructura big data.]]></excerpt>
		<post_id>137</post_id>
		<post_date><![CDATA[2015-08-10 22:02:42]]></post_date>
		<post_date_gmt><![CDATA[2015-08-10 20:02:42]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[optimizacion-del-almacenamiento-de-datos-en-la-gestion-energetica-de-edificios-inteligentes]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="automatizacion"><![CDATA[automatización]]></category>
		<category domain="post_tag" nicename="base-de-datos"><![CDATA[base de datos]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="edificio-inteligente"><![CDATA[edificio inteligente]]></category>
		<category domain="post_tag" nicename="sensor"><![CDATA[sensor]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Samuel Otero Paz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[COGRADE – Centro de Investigación en Tecnoloxías da Información, Systems Laboratory – Instituto de Investigacións Tecnolóxicas, Universidade de Santiago de Compostela, Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[samuel.otero@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose A. Taboada González]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[COGRADE – Centro de Investigación en Tecnoloxías da Información]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[joseangel.taboada@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose R.R. Viqueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[COGRADE – Centro de Investigación en Tecnoloxías da Información]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jrr.viqueira@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan E. Arias Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Systems Laboratory – Instituto de Investigacións Tecnolóxicas, Universidade de Santiago de Compostela, Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juan.arias@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El objetivo principal del proyecto LIFE-OPERE es mejorar la gestión energética en grandes instalaciones de la Universidad de Santiago de Compostela (USC). Se almacenará y analizará la información de sensorización de los edificios para determinar el impacto de las nuevas medidas adoptadas. Para ello, se ha diseñado e implementado un sistema de adquisición, almacenamiento y publicación de datos. Este artículo se centra en la optimización del modelo de datos para hacer frente a los problemas y retos que han surgido durante el proyecto. Además, se valora también la necesidad de implantar una infraestructura big data.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[sensor, automatización, big data, base de datos, edificio inteligente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[139]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un marco para democratizar la minería de datos: propuesta inicial y retos</title>
		<link>https://biblioteca.sistedes.es/articulo/un-marco-para-democratizar-la-mineria-de-datos-propuesta-inicial-y-retos/</link>
		<pubDate>Mon, 10 Aug 2015 20:12:40 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=140</guid>
		<description></description>
		<content><![CDATA[Movimientos como el de datos abiertos posibilitan que cada vez haya una mayor disponibilidad de datos accesibles para su reuti lización. A pesar de que el número de herramientas analíticas que están a nuestra disposición crece cada día, lamentablemente ninguna permite realizar un proceso de extracción de conocimiento directo a usuarios con poca o nula experiencia en el uso de la estadística y de algoritmos de minería de datos. En este artículo se presenta una aproximación a un marco KaaS (Knowledge as a Service) que posibilite a usuarios no ex pertos la extracción de conocimiento a partir de un conjunto de datos. Se muestra que la propuesta es viable y se plantean los retos aún abiertos.]]></content>
		<excerpt><![CDATA[Movimientos como el de datos abiertos posibilitan que cada vez haya una mayor disponibilidad de datos accesibles para su reuti lización. A pesar de que el número de herramientas analíticas que están a nuestra disposición crece cada día, lamentablemente ninguna permite realizar un proceso de extracción de conocimiento directo a usuarios con poca o nula experiencia en el uso de la estadística y de algoritmos de minería de datos. En este artículo se presenta una aproximación a un marco KaaS (Knowledge as a Service) que posibilite a usuarios no ex pertos la extracción de conocimiento a partir de un conjunto de datos. Se muestra que la propuesta es viable y se plantean los retos aún abiertos.]]></excerpt>
		<post_id>140</post_id>
		<post_date><![CDATA[2015-08-10 22:12:40]]></post_date>
		<post_date_gmt><![CDATA[2015-08-10 20:12:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-marco-para-democratizar-la-mineria-de-datos-propuesta-inicial-y-retos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="analitica"><![CDATA[Analítica]]></category>
		<category domain="post_tag" nicename="conocimiento-como-servicio"><![CDATA[Conocimiento como Servicio]]></category>
		<category domain="post_tag" nicename="meta-aprendizaje"><![CDATA[Meta-aprendizaje]]></category>
		<category domain="post_tag" nicename="mineria-de-datos"><![CDATA[Minería de datos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Diego García-Saiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería Informática y Electrónica, Universidad de Cantabria, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[diego.garcias@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Roberto Espinosa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[WaKe Research, Universidad de Matanzas, Cuba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[roberto.espinosa@umcc.cu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José Jacobo Zubcoff]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[WaKe Research, Dpto. Ciencias del Mar y Biología Aplicada, Universidad de Alicante, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jose.zubcoff@ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José-Norberto Mazón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[WaKe Research, Dpto. Lenguajes y Sistemas Informáticos, Instituto Universitari de Investigación Informática, Universidad de Alicante, Espa˜na]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jnmazon@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Marta Zorrilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería Informática y Electrónica, Universidad de Cantabria, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[marta.zorrilla@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Movimientos como el de datos abiertos posibilitan que cada vez haya una mayor disponibilidad de datos accesibles para su reuti lización. A pesar de que el número de herramientas analíticas que están a nuestra disposición crece cada día, lamentablemente ninguna permite realizar un proceso de extracción de conocimiento directo a usuarios con poca o nula experiencia en el uso de la estadística y de algoritmos de minería de datos. En este artículo se presenta una aproximación a un marco KaaS (Knowledge as a Service) que posibilite a usuarios no ex pertos la extracción de conocimiento a partir de un conjunto de datos. Se muestra que la propuesta es viable y se plantean los retos aún abiertos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Conocimiento como Servicio, Minería de datos, Analítica, Meta-aprendizaje]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[141]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>JET: A Proof of Concept Enabling Mobile Devices as Personal Profile Providers</title>
		<link>https://biblioteca.sistedes.es/articulo/jet-a-proof-of-concept-enabling-mobile-devices-as-personal-profile-providers/</link>
		<pubDate>Sat, 29 Aug 2015 16:43:58 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=158</guid>
		<description></description>
		<content><![CDATA[In recent years smartphone users have increased the number of cloud services and platforms used from them. These platforms and services are usually used, by users, to interact with others people and, by
the mobile telephony firms, to create a sociological profile of the people and, thus, achieving a more adapted advertising. However, the information uploaded to these platforms is usually very similar. Uploading it to every platform entails an irrational consumption of the device resources.
But, if it is not the same, the sociological profiles created could be inconsistent. The capabilities of current smartphones enable them to keep all the owner’s information and to provide services for accessing it. To achieve such paradigm shift new tools and platforms are needed. This paper reports a proof of concept of a mobile application that creates and stores the sociological profiles of their users, allowing them to send messages based on those profiles. The use of this new paradigm reduces the consumption of the smartphone resources and facilitates the creation of comprehensive sociological profiles.]]></content>
		<excerpt><![CDATA[In recent years smartphone users have increased the number
of cloud services and platforms used from them. These platforms and services are usually used, by users, to interact with others people and, by
the mobile telephony firms, to create a sociological profile of the people
and, thus, achieving a more adapted advertising. However, the information uploaded to these platforms is usually very similar. Uploading it to
every platform entails an irrational consumption of the device resources.
But, if it is not the same, the sociological profiles created could be inconsistent. The capabilities of current smartphones enable them to keep
all the owner’s information and to provide services for accessing it. To
achieve such paradigm shift new tools and platforms are needed. This
paper reports a proof of concept of a mobile application that creates and
stores the sociological profiles of their users, allowing them to send messages based on those profiles. The use of this new paradigm reduces the
consumption of the smartphone resources and facilitates the creation of
comprehensive sociological profiles.]]></excerpt>
		<post_id>158</post_id>
		<post_date><![CDATA[2015-08-29 18:43:58]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 16:43:58]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[jet-a-proof-of-concept-enabling-mobile-devices-as-personal-profile-providers]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mobile-computing"><![CDATA[mobile computing]]></category>
		<category domain="post_tag" nicename="smartphones"><![CDATA[Smartphones]]></category>
		<category domain="post_tag" nicename="sociological-profiles"><![CDATA[Sociological Profiles]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose Garcia-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Niko Mäkitalo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Tampere University of Technology]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[niko.makitalo@cs.tut.fi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Tommi Mikkonen]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Tampere University of Technology]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[tjm@cs.tut.fi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In recent years smartphone users have increased the number of cloud services and platforms used from them. These platforms and services are usually used, by users, to interact with others people and, by
the mobile telephony firms, to create a sociological profile of the people and, thus, achieving a more adapted advertising. However, the information uploaded to these platforms is usually very similar. Uploading it to every platform entails an irrational consumption of the device resources.
But, if it is not the same, the sociological profiles created could be inconsistent. The capabilities of current smartphones enable them to keep all the owner’s information and to provide services for accessing it. To achieve such paradigm shift new tools and platforms are needed. This paper reports a proof of concept of a mobile application that creates and stores the sociological profiles of their users, allowing them to send messages based on those profiles. The use of this new paradigm reduces the consumption of the smartphone resources and facilitates the creation of comprehensive sociological profiles.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Smartphones, Mobile Computing, Sociological Profiles]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Ingeniería Web y Sistemas Colaborativos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[159]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Javier Miranda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Juan M. Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[Gloin S.L.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[jmiranda@gloin.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/011]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>GeoNews: Generación automática de contextos geográficos para programas de noticias a través de HbbTV</title>
		<link>https://biblioteca.sistedes.es/articulo/geonews-generaci-n-autom-tica-de-contextos-o-a-geogr-ficos-para-programas-de-noticias-a-trav-s-a-e-de-hbbtv/</link>
		<pubDate>Sat, 29 Aug 2015 16:56:13 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=161</guid>
		<description></description>
		<content><![CDATA[Varios estudios recientes han detectado nuevos hábitos en la audiencia de televisió relacionados con el acceso a travé de otros
dispositivos a información que complemente los contenidos de televisión.
En este documento se describe una solución preliminar para la generación de contextos geográficos para programas de noticias en lengua castellana y para su visualización sincronizada en un televisor a través de tecnología HbbTV.]]></content>
		<excerpt><![CDATA[Varios estudios recientes han detectado nuevos hábitos en la audiencia de televisió relacionados con el acceso a travé de otros
dispositivos a información que complemente los contenidos de televisión.
En este documento se describe una solución preliminar para la generación de contextos geográficos para programas de noticias en lengua castellana y para su visualización  sincronizada en un televisor a través de tecnología HbbTV.]]></excerpt>
		<post_id>161</post_id>
		<post_date><![CDATA[2015-08-29 18:56:13]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 16:56:13]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[geonews-generaci-n-autom-tica-de-contextos-o-a-geogr-ficos-para-programas-de-noticias-a-trav-s-a-e-de-hbbtv]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="contexto-geogr-fico"><![CDATA[Contexto geogr ́fico]]></category>
		<category domain="post_tag" nicename="geoetiquetado"><![CDATA[Geoetiquetado]]></category>
		<category domain="post_tag" nicename="gis"><![CDATA[GIS]]></category>
		<category domain="post_tag" nicename="hbbtv"><![CDATA[HbbTV]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Moisés Vilar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Computer Graphics and Data Engineering Group (COGRADE) Centro de Investigaci ́n en Tecnolox ́ da Informaci ́n (CiTIUS) o ıas o Universidade de Santiago de Compostela (USC) Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[moises.vilar@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sebastián Villarroya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Computer Graphics and Data Engineering Group (COGRADE) Centro de Investigaci ́n en Tecnolox ́ da Informaci ́n (CiTIUS) o ıas o Universidade de Santiago de Compostela (USC) Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sebastian.villarroya@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José R.R. Viqueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Computer Graphics and Data Engineering Group (COGRADE) Centro de Investigaci ́n en Tecnolox ́ da Informaci ́n (CiTIUS) o ıas o Universidade de Santiago de Compostela (USC) Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[rr.viqueira@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José M. Cotos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Computer Graphics and Data Engineering Group (COGRADE) Centro de Investigaci ́n en Tecnolox ́ da Informaci ́n (CiTIUS) o ıas o Universidade de Santiago de Compostela (USC) Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manel.cotos@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Varios estudios recientes han detectado nuevos hábitos en la audiencia de televisió relacionados con el acceso a travé de otros
dispositivos a información que complemente los contenidos de televisión.
En este documento se describe una solución preliminar para la generación de contextos geográficos para programas de noticias en lengua castellana y para su visualización  sincronizada en un televisor a través de tecnología HbbTV.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[HbbTV, Geoetiquetado, Contexto geogr ́fico, GIS]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[162]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/010]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modelos de Contexto en el Desarrollo de Interfaces PostWIMP: una Revisión Crítica</title>
		<link>https://biblioteca.sistedes.es/articulo/modelos-de-contexto-en-el-desarrollo-de-interfaces-postwimp-una-revision-critica/</link>
		<pubDate>Sat, 29 Aug 2015 17:00:16 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=165</guid>
		<description></description>
		<content><![CDATA[A lo largo de los últimos años, el avance de la tecnología y la aparición
de nuevos dispositivos ha dado lugar a nuevos paradigmas de interacción persona-ordenador que cada vez son más comunes entre los usuarios finales. La hegemonía de las interfaces clásicas WIMP (Windows, Icons, Menus, Pointers) ha
quedado en un segundo plano, dando paso a nuevos tipos de interacción basados
en tecnologías, otrora llamadas futuristas, como realidad virtual, dispositivos corporales, reconocimiento de voz y gestos, entre otros. El desarrollo de este nuevo
tipo de interfaces, llamadas Post-WIMP, está fuertemente ligado al análisis del
contexto, que en muchos casos determinará la viabilidad e idoneidad de las mismas. De esta forma, la interfaz final tendrá en cuenta las necesidades del usuario
y las características específicas del entorno y la plataforma en la que se desarrolla,
mejorando así la usabilidad de la aplicación. Por otro lado, el contexto de una
aplicación ha sido interpretado desde distintos puntos de vista, pero existe cierto
consenso a la hora de asociarlo a aspectos relativos al usuario, la plataforma y el
entorno. En este sentido, se han propuesto numerosos meta-modelos que ayudan
a especificar el contexto durante el análisis de una aplicación. Sin embargo, la
mayoría de estos meta-modelos no están enfocados a describir las necesidades
que aparecen en el desarrollo de sistemas con interfaces Post-WIMP, sino que
tienen como objetivo el desarrollo de sistemas sensibles al contexto específicos
o sistemas con interfaces clásicas WIMP. En este artículo, repasaremos el concepto de contexto, su relación con el desarrollo de interfaces Post-WIMP y analizaremos, desde la perspectiva del desarrollo de sistemas con interfaces PostWIMP dirigido por modelos, varios meta-modelos de contexto.]]></content>
		<excerpt><![CDATA[A lo largo de los últimos años, el avance de la tecnología y la aparición
de nuevos dispositivos ha dado lugar a nuevos paradigmas de interacción persona-ordenador que cada vez son más comunes entre los usuarios finales. La hegemonía de las interfaces clásicas WIMP (Windows, Icons, Menus, Pointers) ha
quedado en un segundo plano, dando paso a nuevos tipos de interacción basados
en tecnologías, otrora llamadas futuristas, como realidad virtual, dispositivos corporales, reconocimiento de voz y gestos, entre otros. El desarrollo de este nuevo
tipo de interfaces, llamadas Post-WIMP, está fuertemente ligado al análisis del
contexto, que en muchos casos determinará la viabilidad e idoneidad de las mismas. De esta forma, la interfaz final tendrá en cuenta las necesidades del usuario
y las características específicas del entorno y la plataforma en la que se desarrolla,
mejorando así la usabilidad de la aplicación. Por otro lado, el contexto de una
aplicación ha sido interpretado desde distintos puntos de vista, pero existe cierto
consenso a la hora de asociarlo a aspectos relativos al usuario, la plataforma y el
entorno. En este sentido, se han propuesto numerosos meta-modelos que ayudan
a especificar el contexto durante el análisis de una aplicación. Sin embargo, la
mayoría de estos meta-modelos no están enfocados a describir las necesidades
que aparecen en el desarrollo de sistemas con interfaces Post-WIMP, sino que
tienen como objetivo el desarrollo de sistemas sensibles al contexto específicos
o sistemas con interfaces clásicas WIMP. En este artículo, repasaremos el concepto de contexto, su relación con el desarrollo de interfaces Post-WIMP y analizaremos, desde la perspectiva del desarrollo de sistemas con interfaces PostWIMP dirigido por modelos, varios meta-modelos de contexto.]]></excerpt>
		<post_id>165</post_id>
		<post_date><![CDATA[2015-08-29 19:00:16]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 17:00:16]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modelos-de-contexto-en-el-desarrollo-de-interfaces-postwimp-una-revision-critica]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="contexto"><![CDATA[Contexto]]></category>
		<category domain="post_tag" nicename="interfaces-post-wimp"><![CDATA[Interfaces Post-WIMP]]></category>
		<category domain="post_tag" nicename="meta-modelos"><![CDATA[Meta-Modelos]]></category>
		<category domain="post_tag" nicename="modelos"><![CDATA[Modelos]]></category>
		<category domain="post_tag" nicename="revision"><![CDATA[Revisión]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Arturo C. Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación LoUISE, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Arturo.Rodriguez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Cristina Roda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación LoUISE, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Cristina.Roda@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Elena Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación LoUISE, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Elena.Navarro@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Pascual González]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación LoUISE, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Pascual.Gonzalez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A lo largo de los últimos años, el avance de la tecnología y la aparición
de nuevos dispositivos ha dado lugar a nuevos paradigmas de interacción persona-ordenador que cada vez son más comunes entre los usuarios finales. La hegemonía de las interfaces clásicas WIMP (Windows, Icons, Menus, Pointers) ha
quedado en un segundo plano, dando paso a nuevos tipos de interacción basados
en tecnologías, otrora llamadas futuristas, como realidad virtual, dispositivos corporales, reconocimiento de voz y gestos, entre otros. El desarrollo de este nuevo
tipo de interfaces, llamadas Post-WIMP, está fuertemente ligado al análisis del
contexto, que en muchos casos determinará la viabilidad e idoneidad de las mismas. De esta forma, la interfaz final tendrá en cuenta las necesidades del usuario
y las características específicas del entorno y la plataforma en la que se desarrolla,
mejorando así la usabilidad de la aplicación. Por otro lado, el contexto de una
aplicación ha sido interpretado desde distintos puntos de vista, pero existe cierto
consenso a la hora de asociarlo a aspectos relativos al usuario, la plataforma y el
entorno. En este sentido, se han propuesto numerosos meta-modelos que ayudan
a especificar el contexto durante el análisis de una aplicación. Sin embargo, la
mayoría de estos meta-modelos no están enfocados a describir las necesidades
que aparecen en el desarrollo de sistemas con interfaces Post-WIMP, sino que
tienen como objetivo el desarrollo de sistemas sensibles al contexto específicos
o sistemas con interfaces clásicas WIMP. En este artículo, repasaremos el concepto de contexto, su relación con el desarrollo de interfaces Post-WIMP y analizaremos, desde la perspectiva del desarrollo de sistemas con interfaces PostWIMP dirigido por modelos, varios meta-modelos de contexto.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Modelos, Meta-Modelos, Contexto, Interfaces Post-WIMP, Revisión]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Ingeniería Web y Sistemas Colaborativos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[166]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/037]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Pruebas basadas en flujo de datos para programas MapReduce</title>
		<link>https://biblioteca.sistedes.es/articulo/pruebas-basadas-en-flujo-de-datos-para-programas-mapreduce/</link>
		<pubDate>Sat, 29 Aug 2015 17:17:29 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=170</guid>
		<description></description>
		<content><![CDATA[MapReduce es un paradigma de procesamiento masivo de información. Estos programas realizan varias transformaciones de los datos hasta que se obtiene la salida representando la lógica de negocio del programa. En este artículo se elabora una técnica de prueba basada en data flow y que deriva las pruebas a partir de las transformaciones que ocurren en el programa. Se muestran resultados de la ejecución de los casos de prueba derivados de la aplicación de la técnica, los cuales permiten detectar algunos defectos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>170</post_id>
		<post_date><![CDATA[2015-08-29 19:17:29]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 17:17:29]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[pruebas-basadas-en-flujo-de-datos-para-programas-mapreduce]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mapreduce"><![CDATA[MapReduce]]></category>
		<category domain="post_tag" nicename="pruebas-data-flow"><![CDATA[pruebas data flow]]></category>
		<category domain="post_tag" nicename="pruebas-de-software"><![CDATA[Pruebas de Software]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús Morán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo, Gijón, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[moranjesus@lsi.uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Claudio de la Riva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo, Gijón, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[claudio@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo, Gijón, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[MapReduce es un paradigma de procesamiento masivo de información. Estos programas realizan varias transformaciones de los datos hasta que se obtiene la salida representando la lógica de negocio del programa. En este artículo se elabora una técnica de prueba basada en data flow y que deriva las pruebas a partir de las transformaciones que ocurren en el programa. Se muestran resultados de la ejecución de los casos de prueba derivados de la aplicación de la técnica, los cuales permiten detectar algunos defectos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Pruebas de Software, pruebas data flow, MapReduce]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[171]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/013]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>I8K&#124;DQ-BigData: Extensión Arquitectura I8K para Calidad de Datos en Big Data</title>
		<link>https://biblioteca.sistedes.es/articulo/i8kdq-bigdata-extension-arquitectura-i8k-para-calidad-de-datos-en-big-data/</link>
		<pubDate>Sat, 29 Aug 2015 17:21:04 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=173</guid>
		<description></description>
		<content><![CDATA[Durante la ejecución de procesos de negocios que implican a varias
organizaciones, normalmente se intercambian Datos Maestros. Es necesario que dichos datos tengan niveles adecuados de calidad, ya que de otro modo, puede ocurrir que los procesos de negocio fallen. Si los datos intercambiados llevasen información sobre su nivel de calidad, entonces sería posible decidir si pueden
usarse o no en dichos procesos. Las partes 100 a 140 de ISO/TS 8000 pueden ayudar a proporcionar esta información de forma usable. En concreto I8K, una implementación de referencia con fines académicos del citado estándar, puede ser usado para tal fin. Lamentablemente, la eficiencia de I8K cae cuando se trata de evaluar la calidad de grandes volúmenes de Datos Maestros. Este artículo describe la extensión realizada sobre la arquitectura I8K para solventar los problemas de rendimiento al evaluar grandes volúmenes de datos utilizando tecnologías Big Data.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>173</post_id>
		<post_date><![CDATA[2015-08-29 19:21:04]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 17:21:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[i8kdq-bigdata-extension-arquitectura-i8k-para-calidad-de-datos-en-big-data]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="big-data-calidad-de-datos-i8k-intercambio-de-datos-maestros"><![CDATA[Big Data - Calidad de Datos - I8K – Intercambio de datos Maestros]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Bibiano Rivas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información Universidad de Castilla–La Mancha.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Bibiano.Rivas@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jorge Merino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información Universidad de Castilla–La Mancha.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Jorge.Merino@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Serrano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información Universidad de Castilla–La Mancha.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Manuel.Serrano@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ismael Caballero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información Universidad de Castilla–La Mancha.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Ismael.Caballero@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información Universidad de Castilla–La Mancha.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[Mario.Piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Durante la ejecución de procesos de negocios que implican a varias
organizaciones, normalmente se intercambian Datos Maestros. Es necesario que dichos datos tengan niveles adecuados de calidad, ya que de otro modo, puede ocurrir que los procesos de negocio fallen. Si los datos intercambiados llevasen información sobre su nivel de calidad, entonces sería posible decidir si pueden
usarse o no en dichos procesos. Las partes 100 a 140 de ISO/TS 8000 pueden ayudar a proporcionar esta información de forma usable. En concreto I8K, una implementación de referencia con fines académicos del citado estándar, puede ser usado para tal fin. Lamentablemente, la eficiencia de I8K cae cuando se trata de evaluar la calidad de grandes volúmenes de Datos Maestros. Este artículo describe la extensión realizada sobre la arquitectura I8K para solventar los problemas de rendimiento al evaluar grandes volúmenes de datos utilizando tecnologías Big Data.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Big Data - Calidad de Datos - I8K – Intercambio de datos Maestros]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[174]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/036]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Herramienta para la Prueba de Mutaciones en el Lenguaje C++</title>
		<link>https://biblioteca.sistedes.es/articulo/herramienta-para-la-prueba-de-mutaciones-en-el-lenguaje-c/</link>
		<pubDate>Sat, 29 Aug 2015 17:24:10 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=176</guid>
		<description></description>
		<content><![CDATA[La prueba de mutaciones es una técnica basada en fallos en torno a la cual se han elaborado herramientas para un amplio abanico de lenguajes de programación. Sin embargo, el desarrollo de un marco de prueba de mutaciones no comercial para C++ estaba pendiente. En este artículo se presenta una herramienta que permite analizar código C++, generar mutantes y ejecutar un conjunto de casos de prueba para obtener resultados que nos permitan determinar su efectividad en la detección de errores en el código. La herramienta está diseñada para permitir la inclusión de nuevos operadores para cubrir cualquier característica del lenguaje. En este documento, el uso de la herramienta se muestra a través de un operador de mutación al nivel de clase.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>176</post_id>
		<post_date><![CDATA[2015-08-29 19:24:10]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 17:24:10]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[herramienta-para-la-prueba-de-mutaciones-en-el-lenguaje-c]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="c"><![CDATA[C++]]></category>
		<category domain="post_tag" nicename="prueba-de-mutaciones"><![CDATA[prueba de mutaciones]]></category>
		<category domain="post_tag" nicename="prueba-de-software"><![CDATA[Prueba de software]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Delgado-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software, Departamento de Ingeniería Informática, Universidad de Cádiz, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pedro.delgado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software, Departamento de Ingeniería Informática, Universidad de Cádiz, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan José Domínguez-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software, Departamento de Ingeniería Informática, Universidad de Cádiz, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanjose.dominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La prueba de mutaciones es una técnica basada en fallos en torno a la cual se han elaborado herramientas para un amplio abanico de lenguajes de programación. Sin embargo, el desarrollo de un marco  de prueba de mutaciones no comercial para C++ estaba pendiente. En este artículo se presenta una herramienta que permite analizar código C++, generar mutantes y ejecutar un conjunto de casos de prueba para obtener resultados que nos permitan determinar su efectividad en la detección de errores en el código. La herramienta está diseñada para permitir la inclusión de nuevos operadores para cubrir cualquier característica del lenguaje. En este documento, el uso de la herramienta se muestra a través de un operador de mutación al nivel de clase.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Prueba de software, prueba de mutaciones, C++]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Calidad y Pruebas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[177]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/012]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>CEViNEdit: mejorando el proceso de creación de editores gráficos cognitivamente eficaces con GMF</title>
		<link>https://biblioteca.sistedes.es/articulo/cevinedit-mejorando-el-proceso-de-creacion-de-editores-graficos-cognitivamente-eficaces-con-gmf/</link>
		<pubDate>Sat, 29 Aug 2015 17:34:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=182</guid>
		<description></description>
		<content><![CDATA[Durante los últimos años, el auge de los Lenguajes Específicos de Dominio (visuales) y la complejidad inherente del desarrollo de editores gráficos para estos lenguajes, ha provocado la aparición de propuestas que proporcionan soporte técnico para esta tarea. La mayoría de estas propuestas utilizan como base EMF y GMF, que en efecto ayudan a simplificar y aumentar el nivel de automatización del proceso de desarrollo. Sin embargo, el desarrollo de herramientas sobre EMF y GMF no está exento de problemas, en su mayoría relacionados con la curva de aprendizaje de estas tecnologías, la escasa documentación o la complejidad que implica proporcionar todas las posibilidades de personalización al usuario. Con el fin de aliviar la complejidad intrínseca del enfoque EMF/GMF para el desarrollo de editores gráficos, en este trabajo presentamos CEViNEdit, una herramienta intuitiva que soporta la generación semi-automática de editores gráficos y, al mismo tiempo, la evaluación de la eficacia cognitiva de la notación visual que implementa el editor.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>182</post_id>
		<post_date><![CDATA[2015-08-29 19:34:07]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 17:34:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[cevinedit-mejorando-el-proceso-de-creacion-de-editores-graficos-cognitivamente-eficaces-con-gmf]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="ingenieria-dirigida-por-modelos"><![CDATA[Ingeniería Dirigida por Modelos]]></category>
		<category domain="post_tag" nicename="lenguajes-esp"><![CDATA[Lenguajes Esp]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Calle Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[david.granada@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ángel Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Calle Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[angel.moreno@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan M. Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Calle Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Verónica A. Bollati]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Calle Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[veronica.bollati@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Calle Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Durante los últimos años, el auge de los Lenguajes Específicos de Dominio (visuales) y la complejidad inherente del desarrollo de editores gráficos para estos lenguajes, ha provocado la aparición de propuestas que proporcionan soporte técnico para esta tarea. La mayoría de estas propuestas utilizan como base EMF y GMF, que en efecto ayudan a simplificar y aumentar el nivel de automatización del proceso de desarrollo. Sin embargo, el  desarrollo de herramientas sobre EMF y GMF no está exento de problemas, en su mayoría relacionados con la curva de aprendizaje de estas tecnologías, la escasa documentación o la complejidad que implica proporcionar todas las posibilidades de personalización al usuario. Con el fin de aliviar la complejidad intrínseca del enfoque EMF/GMF para el desarrollo de editores gráficos, en este trabajo presentamos CEViNEdit, una herramienta intuitiva que soporta la generación semi-automática de editores gráficos y, al mismo tiempo, la evaluación de la eficacia cognitiva de la notación visual que implementa el editor.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Ingeniería Dirigida por Modelos, Lenguajes Esp]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Desrrollo de Software Dirigido por Modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[183]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/024]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automatización para la edición de modelos basada en vistas de dominio</title>
		<link>https://biblioteca.sistedes.es/articulo/automatizacion-para-la-edicion-de-modelos-basada-en-vistas-de-dominio/</link>
		<pubDate>Sat, 29 Aug 2015 17:37:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=185</guid>
		<description></description>
		<content><![CDATA[Este trabajo aborda la generación automática de recursos para la edición asistida de modelos de un dominio en base a vistas especializadas de su meta-modelo. La tarea de un diseñador que construye modelos conformes a un meta-modelo de dominio complejo se ve facilitada si el editor le requiere la información según una vista del meta-modelo acorde a su conceptualización o a la estrategia específica de creación que utiliza. Se presenta el meta-modelo con el que el experto de dominio formula la estrategia de creación de modelos que quiere utilizar, la herramienta que a partir de esta información sobre la estrategia genera el meta-modelo que dirige la introducción de datos y la transformación M2M que genera el modelo final que es conforme al meta-modelo de dominio de partida y que contiene los nuevos datos introducidos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>185</post_id>
		<post_date><![CDATA[2015-08-29 19:37:48]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 17:37:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automatizacion-para-la-edicion-de-modelos-basada-en-vistas-de-dominio]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="hot"><![CDATA[HOT]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="meta-herramienta"><![CDATA[meta-herramienta]]></category>
		<category domain="post_tag" nicename="meta-modelo"><![CDATA[meta-modelo]]></category>
		<category domain="post_tag" nicename="vista"><![CDATA[vista]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[César Cuevas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ISTR, Universidad de Cantabria, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cuevasce@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Patricia López Martínez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ISTR, Universidad de Cantabria, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[lopezpa@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José M. Drake]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ISTR, Universidad de Cantabria, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[drakej@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este trabajo aborda la generación automática de recursos para la edición asistida de modelos de un dominio en base a vistas especializadas de su meta-modelo. La tarea de un diseñador que construye modelos conformes a un meta-modelo de dominio complejo se ve facilitada si el editor le requiere la información según una vista del meta-modelo acorde a su conceptualización o a la estrategia específica de creación que utiliza. Se presenta el meta-modelo con el que el experto de dominio formula la estrategia de creación de modelos que quiere utilizar, la herramienta que a partir de esta información sobre la estrategia genera el meta-modelo que dirige la introducción de datos y la transformación M2M que genera el modelo final que es conforme al meta-modelo de dominio de partida y que contiene los nuevos datos introducidos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[MDE, meta-modelo, vista, meta-herramienta, HOT]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Desrrollo de Software Dirigido por Modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[186]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/023]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>PyEmofUC: Un entorno MDE/EMOF minimalista</title>
		<link>https://biblioteca.sistedes.es/articulo/pyemofuc-un-entorno-mdeemof-minimalista/</link>
		<pubDate>Sat, 29 Aug 2015 17:41:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=188</guid>
		<description></description>
		<content><![CDATA[Se presenta el entorno PyEmofUC para la creación, procesado, transformación y visualización de información en base al paradigma de ingeniería dirigida por modelos (MDE). Los meta-modelos se formulan de acuerdo con la especificación EMOF de la organización OMG y se implementan utilizando el lenguaje de programación Python. El entorno es multiplataforma, abierto y minimalista. Además del espacio tecnológico de modelado nativo, basado en Python y EMOF, el entorno da soporte al espacio tecnológico basado en lenguajes específicos como medio de facilitar la interacción con los expertos de dominio, y al espacio tecnológico de serialización para el almacenamiento persistente de los modelos y para la inter-operación con otros entornos. Por último, PyEmofUC permite formular transformaciones de modelos utilizando estilos imperativo, declarativo e híbrido.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>188</post_id>
		<post_date><![CDATA[2015-08-29 19:41:05]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 17:41:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[pyemofuc-un-entorno-mdeemof-minimalista]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="emof"><![CDATA[EMOF]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="meta-modelado"><![CDATA[meta-modelado]]></category>
		<category domain="post_tag" nicename="python"><![CDATA[Python]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José M. Drake]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ISTR, Universidad de Cantabria, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[drakej@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[César Cuevas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ISTR, Universidad de Cantabria, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cuevasce@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan R. Fernández Castañera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ISTR, Universidad de Cantabria, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Patricia López Martínez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[ISTR, Universidad de Cantabria, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[lopezpa@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Se presenta el entorno PyEmofUC para la creación, procesado, transformación y visualización de información en base al paradigma de ingeniería dirigida por modelos (MDE). Los meta-modelos se formulan de acuerdo con la especificación EMOF de la organización OMG y se implementan utilizando el lenguaje de programación Python. El entorno es multiplataforma, abierto y minimalista. Además del espacio tecnológico de modelado nativo, basado en Python y EMOF, el entorno da soporte al espacio tecnológico basado en lenguajes específicos como medio de facilitar la interacción con los expertos de dominio, y al espacio tecnológico de serialización para el almacenamiento persistente de los modelos y para la inter-operación con otros entornos. Por último, PyEmofUC permite formular transformaciones de modelos utilizando estilos imperativo, declarativo e híbrido.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[MDE, EMOF, meta-modelado, Python]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[189]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/022]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Model-Driven NoSQL Data Engineering</title>
		<link>https://biblioteca.sistedes.es/articulo/model-driven-nosql-data-engineering/</link>
		<pubDate>Sat, 29 Aug 2015 17:44:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=191</guid>
		<description></description>
		<content><![CDATA[While the concept of database schema plays a central role in relational database systems, most NoSQL systems do not require having to formally define an schema. Instead, it is implicit in the stored data. This lack of schema definition offers a greater flexibility. More specifically, schemaless databases ease both the recording of non-uniform data and data evolution. However, this comes at the cost of losing some of the benefits provided by schemas, for instance, static checking that assure that stored data conforms to the database schema. We have started a research work aimed at inferring schemas from NoSQL databases, with the purpose of building database utilities able of automating tasks such as data validation, schema visualization, and data migration. This work has evidenced the benefits of using MDE techniques within the new “NoSQL Data Engineering” field.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>191</post_id>
		<post_date><![CDATA[2015-08-29 19:44:05]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 17:44:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[model-driven-nosql-data-engineering]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="json-schema"><![CDATA[JSON Schema]]></category>
		<category domain="post_tag" nicename="model-driven-data-reverse-engineering"><![CDATA[Model-Driven Data Reverse Engineering]]></category>
		<category domain="post_tag" nicename="nosql-databases"><![CDATA[NoSQL Databases]]></category>
		<category domain="post_tag" nicename="schema-inference"><![CDATA[Schema Inference]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Diego Sevilla Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Faculty of Computer Science, University of Murcia Campus Espinardo, Murcia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[dsevilla@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Severino Feliciano Morales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Faculty of Computer Science, University of Murcia Campus Espinardo, Murcia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[severino.feliciano@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesús García Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Faculty of Computer Science, University of Murcia Campus Espinardo, Murcia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jmolina@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[While the concept of database schema plays a central role in relational database systems, most NoSQL systems do not require having to formally define an schema. Instead, it is implicit in the stored data. This lack of schema definition offers a greater flexibility. More specifically, schemaless databases ease both the recording of non-uniform data and data evolution. However, this comes at the cost of losing some of the benefits provided by schemas, for instance, static checking that assure that stored data conforms to the database schema. We have started a research work aimed at inferring schemas from NoSQL databases, with the purpose of building database utilities able of automating tasks such as data validation, schema visualization, and data migration. This work has evidenced the benefits of using MDE techniques within the new “NoSQL Data Engineering” field.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[NoSQL Databases, Schema Inference, Model-Driven Data Reverse Engineering, JSON Schema]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[192]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/021]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Achieving software-assisted knowledge generation through model-driven interoperability</title>
		<link>https://biblioteca.sistedes.es/articulo/achieving-software-assisted-knowledge-generation-through-model-driven-interoperability/</link>
		<pubDate>Sat, 29 Aug 2015 18:31:40 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=194</guid>
		<description></description>
		<content><![CDATA[A software system is a complex artefact involving several aspects, such as requirements and behavioural workflows. Information systems engineering has generated several approaches to create software models reflecting these aspects. To obtain the necessary integration, the relations between the involved models must be expressed formally. Currently, this necessity is particularly evident in systems built to assist users in performing knowledge generation, such as scientific knowledge-management systems. Model-Driven Engineering provides some interoperability techniques for expressing inter-model relations. In this paper, a specific metamodel is proposed for integrating different modelling perspectives of software systems built for assisting users in knowledge generation. Furthermore, the integration metamodel is initially validated through its application to the integration of modelling perspectives of a system to assist knowledge generation in the cultural heritage domain. The integration metamodel proposed allows the system to make knowledge generation decisions by manipulating the relations between the involved models on behalf of the user.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>194</post_id>
		<post_date><![CDATA[2015-08-29 20:31:40]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 18:31:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[achieving-software-assisted-knowledge-generation-through-model-driven-interoperability]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="conceptual-modelling"><![CDATA[conceptual modelling]]></category>
		<category domain="post_tag" nicename="cultural-heritage"><![CDATA[cultural heritage]]></category>
		<category domain="post_tag" nicename="interoperability"><![CDATA[interoperability]]></category>
		<category domain="post_tag" nicename="knowledge-generation"><![CDATA[knowledge generation]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="software-assistance"><![CDATA[software assistance]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Patricia Martín-Rodilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ Institute of Heritage Sciences (Incipit), Spanish National Research Council (CSIC), Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[patricia.martin-rodilla@incipit.csic.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Giovanni Giachetti]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Facultad de Ingeniería, Universidad Andrés Bello, Santiago de Chile, Chile]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[giovanni.giachetti@unab.c]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Cesar Gonzalez-Perez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ Institute of Heritage Sciences (Incipit), Spanish National Research Council (CSIC), Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[cesar.gonzalez-perez@incipit.csic.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A software system is a complex artefact involving several aspects, such as requirements and behavioural workflows. Information systems engineering has generated several approaches to create software models reflecting these aspects. To obtain the necessary integration, the relations between the involved models must be expressed formally. Currently, this necessity is particularly evident in systems built to assist users in performing knowledge generation, such as scientific knowledge-management systems. Model-Driven Engineering provides some interoperability techniques for expressing inter-model relations. In this paper, a specific metamodel is proposed for integrating different modelling perspectives of software systems built for assisting users in knowledge generation. Furthermore, the integration metamodel is initially validated through its application to the integration of modelling perspectives of a system to assist knowledge generation in the cultural heritage domain. The integration metamodel proposed allows the system to make knowledge generation decisions by manipulating the relations between the involved models on behalf of the user.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[knowledge generation, interoperability, software assistance, MDE, conceptual modelling, cultural heritage]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[195]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/020]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Mediación semántica A* basada en MDE para la generación de arquitecturas en tiempo de ejecución</title>
		<link>https://biblioteca.sistedes.es/articulo/mediacion-semantica-a-basada-en-mde-para-la-generacion-de-arquitecturas-en-tiempo-de-ejecucion/</link>
		<pubDate>Sat, 29 Aug 2015 18:36:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=197</guid>
		<description></description>
		<content><![CDATA[Existen aplicaciones software que necesitan ser adaptadas en tiempo de ejecución debido a que los componentes que conforman su arquitectura no representan la configuración óptima. En estos casos, las arquitecturas deben ser reconfiguradas, por ejemplo, a˜nadiendo y eliminando componentes, o modificando las relaciones entre ellos. Este artículo presenta una propuesta para la generación de arquitecturas en tiempo de ejecución. Está enfocado en la descripción del proceso que ocurre desde que existe una definición de arquitectura que hay que resolver, hasta que se genera la mejor configuración que da solución a dicha arquitectura. Para construir dicha configuración, se utilizan técnicas de modelado, mecanismos de trading y un algoritmo de búsqueda A*. Dicho algoritmo hace uso de una heurística basada en la información sintáctica y semántica de los componentes. Como dominio de aplicación, se muestra un caso estudio para la generación de interfaces de usuario.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>197</post_id>
		<post_date><![CDATA[2015-08-29 20:36:09]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 18:36:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mediacion-semantica-a-basada-en-mde-para-la-generacion-de-arquitecturas-en-tiempo-de-ejecucion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="a"><![CDATA[A*]]></category>
		<category domain="post_tag" nicename="componentes"><![CDATA[Componentes]]></category>
		<category domain="post_tag" nicename="heuristica"><![CDATA[Heurística]]></category>
		<category domain="post_tag" nicename="m2m"><![CDATA[M2M]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="trading"><![CDATA[Trading]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Criado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Informática Aplicada, Universidad de Almería, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[javi.criado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Luis Iribarne]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Informática Aplicada, Universidad de Almería, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[luis.iribarne@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Nicolás Padilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Informática Aplicada, Universidad de Almería, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[npadilla@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Existen aplicaciones software que necesitan ser adaptadas en tiempo de ejecución debido a que los componentes que conforman su arquitectura no representan la configuración óptima. En estos casos, las arquitecturas deben ser reconfiguradas, por ejemplo, a˜nadiendo y eliminando componentes, o modificando las relaciones entre ellos. Este artículo presenta una propuesta para la generación de arquitecturas en tiempo de ejecución. Está enfocado en la descripción del proceso que ocurre desde que existe una definición de arquitectura que hay que resolver, hasta que se genera la mejor configuración que da solución a dicha arquitectura. Para construir dicha configuración, se utilizan técnicas de modelado, mecanismos de trading y un algoritmo de búsqueda A*. Dicho algoritmo hace uso de una heurística basada en la información sintáctica y semántica de los componentes. Como dominio de aplicación, se muestra un caso estudio para la generación de interfaces de usuario.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Componentes, Trading, Heurística, A*, MDE, M2M]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[198]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/019]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modular DSLs for flexible analysis: An e-Motions reimplementation of Palladio (High-level Work)</title>
		<link>https://biblioteca.sistedes.es/?post_type=articulo&#038;p=729</link>
		<pubDate>Mon, 30 Nov -0001 00:00:00 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=729</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>729</post_id>
		<post_date><![CDATA[2016-04-24 02:50:10]]></post_date>
		<post_date_gmt><![CDATA[0000-00-00 00:00:00]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[]]></post_name>
		<status><![CDATA[draft]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Boletín nº 1. Febrero de 2018</title>
		<link>https://biblioteca.sistedes.es/?post_type=articulo&#038;p=2805</link>
		<pubDate>Mon, 30 Nov -0001 00:00:00 +0000</pubDate>
		<creator><![CDATA[jhcanos]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/?post_type=articulo&#038;p=2805</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[Resumen de las noticias más destacables en los campos de actuación de la Comunidad SISTEDES]]></excerpt>
		<post_id>2805</post_id>
		<post_date><![CDATA[2018-03-01 18:42:12]]></post_date>
		<post_date_gmt><![CDATA[0000-00-00 00:00:00]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[]]></post_name>
		<status><![CDATA[draft]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SociAALML: Lenguaje de Modelado para Escenarios de Inteligencia Ambiental</title>
		<link>https://biblioteca.sistedes.es/articulo/sociaalml-lenguaje-de-modelado-para-escenarios-de-inteligencia-ambiental/</link>
		<pubDate>Sat, 29 Aug 2015 18:50:04 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=200</guid>
		<description></description>
		<content><![CDATA[El estudio y desarrollo de sistemas de inteligencia ambiental puede llegar a ser complejo y costoso, especialmente en fases avanzadas que se ejecutan en laboratorios vivientes (living labs). En la última década, los avances en tecnologías 3D permiten plantear entornos virtuales donde se puedan desplegar dispositivos y usuarios. Así se podría reducir costes y potenciar la investigación de este tipo de sistemas. En este trabajo se presenta SociAALML, un lenguaje específico de dominio para modelar escenarios de la vida cotidiana en el hogar, incluyendo el modelado de personas con Parkinson. Usando modelos creados con este lenguaje, se generan simuladores 3D que incluyen usuarios simulados, el propio entorno y los dispositivos que componen el sistema de inteligencia ambiental.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>200</post_id>
		<post_date><![CDATA[2015-08-29 20:50:04]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 18:50:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[sociaalml-lenguaje-de-modelado-para-escenarios-de-inteligencia-ambiental]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="inteligencia-ambiental"><![CDATA[Inteligencia Ambiental]]></category>
		<category domain="post_tag" nicename="modelado-de-la-actividad-diaria"><![CDATA[Modelado de la Actividad Diaria]]></category>
		<category domain="post_tag" nicename="modelado-de-parkinson"><![CDATA[Modelado de Parkinson]]></category>
		<category domain="post_tag" nicename="simulacion-dirigida-por-modelos"><![CDATA[Simulaci´on dirigida por modelos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Campillo-Sanchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Computense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pabcampi@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jorge J. Gómez-Sanz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Computense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jpavon@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Pavón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Computense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jjgomez@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El estudio y desarrollo de sistemas de inteligencia ambiental puede llegar a ser complejo y costoso, especialmente en fases avanzadas que se ejecutan en laboratorios vivientes (living labs). En la última década, los avances en tecnologías 3D permiten plantear entornos virtuales donde se puedan desplegar dispositivos y usuarios. Así se podría reducir costes y potenciar la investigación de este tipo de sistemas. En este trabajo se presenta SociAALML, un lenguaje específico de dominio para modelar escenarios de la vida cotidiana en el hogar, incluyendo el modelado de personas con Parkinson. Usando modelos creados con este lenguaje, se generan simuladores 3D que incluyen usuarios simulados, el propio entorno y los dispositivos que componen el sistema de inteligencia ambiental.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Simulaci´on dirigida por modelos, Inteligencia Ambiental, Modelado de la Actividad Diaria, Modelado de Parkinson]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Desrrollo de Software Dirigido por Modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[201]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/018]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Aplicando DSDM al Diseño, Implementación y Verificación de Software para Drones: Una Primera Aproximación</title>
		<link>https://biblioteca.sistedes.es/articulo/aplicando-dsdm-al-diseno-implementacion-y-verificacion-de-software-para-drones-una-primera-aproximacion/</link>
		<pubDate>Sat, 29 Aug 2015 18:53:55 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=203</guid>
		<description></description>
		<content><![CDATA[Hasta hace poco, el uso de sistemas de vuelo no tripulados (Unmanned Aerial Vehicles, UAV), también conocidos como drones, estaba limitado al campo militar. Sin embargo, en la actualidad, su uso en el ámbito civil y de la investigación prolifera con rapidez. En este artículo se presenta una primera aproximación al diseño de alto nivel tanto de la infraestructura (diseño físico) como de las misiones (diseño lógico) de los UAV utilizando un enfoque dirigido por modelos. El objetivo de este trabajo es ofrecer a los diseñadores un conjunto de herramientas que faciliten el diseño, la documentación y la implementación, así como la verificación temprana y formal de las restricciones físicas, lógicas y legales que deben guiar la construcción de estos sistemas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>203</post_id>
		<post_date><![CDATA[2015-08-29 20:53:55]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 18:53:55]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[aplicando-dsdm-al-diseno-implementacion-y-verificacion-de-software-para-drones-una-primera-aproximacion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="dron"><![CDATA[dron]]></category>
		<category domain="post_tag" nicename="dsdm"><![CDATA[DSDM]]></category>
		<category domain="post_tag" nicename="uav"><![CDATA[UAV]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Enrique Moguel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[QSEG, Escuela Politécnica de Cáceres, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[enrique@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Cristina Vicente-Chicote]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[QSEG, Escuela Politécnica de Cáceres, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cristinav@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[QSEG, Escuela Politécnica de Cáceres, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanher@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Carlos Preciado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[QSEG, Escuela Politécnica de Cáceres, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jcpreciado@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Fernando Sánchez-Figueroa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[QSEG, Escuela Politécnica de Cáceres, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[fernando@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Hasta hace poco, el uso de sistemas de vuelo no tripulados (Unmanned Aerial Vehicles, UAV), también conocidos como drones, estaba limitado al campo militar. Sin embargo, en la actualidad, su uso en el ámbito civil y de la investigación prolifera con rapidez. En este artículo se presenta una primera aproximación al diseño de alto nivel tanto de la infraestructura (diseño físico) como de las misiones (diseño lógico) de los UAV utilizando un enfoque dirigido por modelos. El objetivo de este trabajo es ofrecer a los diseñadores un conjunto de herramientas que faciliten el diseño, la documentación y la implementación, así como la verificación temprana y formal de las restricciones físicas, lógicas y legales que deben guiar la construcción de estos sistemas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[DSDM, dron, UAV]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Desrrollo de Software Dirigido por Modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[204]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/017]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Lenguaje específico del dominio para generación de aplicaciones de procesos administrativos</title>
		<link>https://biblioteca.sistedes.es/articulo/lenguaje-especifico-del-dominio-para-generacion-de-aplicaciones-de-procesos-administrativos/</link>
		<pubDate>Sat, 29 Aug 2015 18:57:03 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=206</guid>
		<description></description>
		<content><![CDATA[Muchas organizaciones reimplementan una y otra vez el mismo tipo de proceso de negocio «administrativo», en el que un formulario es manipulado por múltiples roles a lo largo de varios estados. Esta reimplementación hace perder un tiempo que se podría haber usado en entender mejor el proceso o cubrir los detalles que sí son específicos del proceso. Por otro lado, las soluciones existentes basadas en motores de procesos de negocio requieren formación e infraestructura específicas y pueden encerrar al usuario en una tecnología concreta. En este trabajo se propone usar un lenguaje de alto nivel para describir el proceso administrativo y producir a partir de él un sitio web en un marco estándar de desarrollo web que sea fácil de mantener por los técnicos de la organización. Se ha implementado el enfoque mediante tecnologías de código abierto, y se ilustra a través de un caso de estudio.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>206</post_id>
		<post_date><![CDATA[2015-08-29 20:57:03]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 18:57:03]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[lenguaje-especifico-del-dominio-para-generacion-de-aplicaciones-de-procesos-administrativos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio García Domínguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[antonio.garciadominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ismael Jerez Ibañez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ismael.jerezibanez@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Muchas organizaciones reimplementan una y otra vez el mismo tipo de proceso de negocio «administrativo», en el que un formulario es manipulado por múltiples roles a lo largo de varios estados. Esta reimplementación hace perder un tiempo que se podría haber usado en entender mejor el proceso o cubrir los detalles que sí son específicos del proceso. Por otro lado, las soluciones existentes basadas en motores de procesos de negocio requieren formación e infraestructura específicas y pueden encerrar al usuario en una tecnología concreta. En este trabajo se propone usar un lenguaje de alto nivel para describir el proceso administrativo y producir a partir de él un sitio web en un marco estándar de desarrollo web que sea fácil de mantener por los técnicos de la organización. Se ha implementado el enfoque mediante tecnologías de código abierto, y se ilustra a través de un caso de estudio.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Desrrollo de Software Dirigido por Modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[207]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/016]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Arquitectura basada en modelos para la generación de especificaciones textuales de requisitos a partir de procesos de negocio definidos mediante BPMN</title>
		<link>https://biblioteca.sistedes.es/articulo/arquitectura-basada-en-modelos-para-la-generacion-de-especificaciones-textuales-de-requisitos-a-partir-de-procesos-de-negocio-definidos-mediante-bpmn/</link>
		<pubDate>Sat, 29 Aug 2015 19:02:39 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=209</guid>
		<description></description>
		<content><![CDATA[En la ingeniería del software, la gestión de procesos de negocio (BPM) se suele aplicar para modelar y optimizar los procesos de negocio de un sistema. Junto con la Ingeniería de Requisitos (IR), constituye una base sobre la que especificar un sistema software. Sin embargo, a menudo existe una falta de alineación entre ambas especificaciones que repercute negativamente en el sistema. Este artículo presenta una arquitectura basada en modelos para la generación de especificaciones textuales de requisitos a partir de procesos de negocio representados mediante BPMN y su aplicación a un caso de estudio. El objetivo es agilizar y mejorar la etapa de análisis de un sistema software, generando un subconjunto de los requisitos del sistema para facilitar la escritura de una especificación completa y sincronizada con los procesos de negocio.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>209</post_id>
		<post_date><![CDATA[2015-08-29 21:02:39]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:02:39]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[arquitectura-basada-en-modelos-para-la-generacion-de-especificaciones-textuales-de-requisitos-a-partir-de-procesos-de-negocio-definidos-mediante-bpmn]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="generacion-de-requisitos-a-partir-de-procesos-de-negocio"><![CDATA[generación de requisitos a partir de procesos de negocio]]></category>
		<category domain="post_tag" nicename="generacion-de-requisitos-basada-en-modelos"><![CDATA[generación de requisitos basada en modelos]]></category>
		<category domain="post_tag" nicename="generacion-de-requisitos-textuales"><![CDATA[generación de requisitos textuales]]></category>
		<category domain="post_tag" nicename="transformacion-bpmn-requisitos"><![CDATA[transformación BPMN-requisitos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Manuel Cruz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación de Ingeniería del Software. Departamento de Informática y Sistemas. Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[josemanuel.cruz@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Begoña Moros Valle]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación de Ingeniería del Software. Departamento de Informática y Sistemas. Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[bmoros@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ambrosio Toval]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación de Ingeniería del Software. Departamento de Informática y Sistemas. Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[atoval@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En la ingeniería del software, la gestión de procesos de negocio (BPM) se suele aplicar para modelar y optimizar los procesos de negocio de un sistema. Junto con la Ingeniería de Requisitos (IR), constituye una base sobre la que especificar un sistema software. Sin embargo, a menudo existe una falta de alineación entre ambas especificaciones que repercute negativamente en el sistema. Este artículo presenta una arquitectura basada en modelos para la generación de especificaciones textuales de requisitos a partir de procesos de negocio representados mediante BPMN y su aplicación a un caso de estudio. El objetivo es agilizar y mejorar la etapa de análisis de un sistema software, generando un subconjunto de los requisitos del sistema para facilitar la escritura de una especificación completa y sincronizada con los procesos de negocio.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[transformación BPMN-requisitos, generación de requisitos textuales, generación de requisitos basada en modelos, generación de requisitos a partir de procesos de negocio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Desrrollo de Software Dirigido por Modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[210]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/015]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Analysis of the Scientific Production of the Spanish Software Engineering Community</title>
		<link>https://biblioteca.sistedes.es/articulo/analysis-of-the-scientific-production-of-the-spanish-software-engineering-community/</link>
		<pubDate>Sat, 29 Aug 2015 19:05:26 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=212</guid>
		<description></description>
		<content><![CDATA[Our group has been working on a report for the SpanishúSociety of Software Engineering and Software Development Technologies (SISTEDES) to provide a general overview of the Spanish scientificúproduction and its contributions worldwide in the field of Software Engineering. Although a Database solution could have been used, we decidedúto employ Model-Driven Development (MDD) techniques in order toúevaluate their applicability, suitability and fitness for these kinds of purposes, and to learn from the experience in this domain, which combinesúdata integration, large scale models, and complex queries.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>212</post_id>
		<post_date><![CDATA[2015-08-29 21:05:26]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:05:26]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analysis-of-the-scientific-production-of-the-spanish-software-engineering-community]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mdd"><![CDATA[MDD]]></category>
		<category domain="post_tag" nicename="scientific-contribution"><![CDATA[scientific contribution]]></category>
		<category domain="post_tag" nicename="sistedes"><![CDATA[SISTEDES]]></category>
		<category domain="post_tag" nicename="software-engineering"><![CDATA[software engineering]]></category>
		<category domain="post_tag" nicename="spain"><![CDATA[Spain]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Loli Burgueño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Atenea Research Group, Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[loli@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Moreno-Delgado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Atenea Research Group, Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[amoreno@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Vallecillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Atenea Research Group, Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[av@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Our group has been working on a report for the SpanishúSociety of Software Engineering and Software Development Technologies (SISTEDES) to provide a general overview of the Spanish scientificúproduction and its contributions worldwide in the field of Software Engineering. Although a Database solution could have been used, we decidedúto employ Model-Driven Development (MDD) techniques in order toúevaluate their applicability, suitability and fitness for these kinds of purposes, and to learn from the experience in this domain, which combinesúdata integration, large scale models, and complex queries.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[SISTEDES, scientific contribution, Spain, software engineering, MDD]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Desrrollo de Software Dirigido por Modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[213]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/014]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Desarrollo de una Línea de Productos Software utilizando las clases parciales C#: el patrón Slicer</title>
		<link>https://biblioteca.sistedes.es/articulo/desarrollo-de-una-linea-de-productos-software-utilizando-las-clases-parciales-c-el-patron-slicer/</link>
		<pubDate>Sat, 29 Aug 2015 19:10:13 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=217</guid>
		<description></description>
		<content><![CDATA[Las clases parciales de C# permiten dividir el comportamiento global de una clase en diversos fragmentos. Estos fragmentos pueden luego combinarse de diversas formas, produciendo clases completas con comportamientos similares pero ligeramente diferentes, en función de nuestras necesidades. La semejanza de este mecanismo con la programación orientada a características ha hecho que algunos autores hayan considerado las clases parciales de C# como un mecanismo apropiado para el desarrollo de líneas de productos de software. Sin embargo, un reciente estudio ha demostrado que las clases parciales de C# por sí solas no son suficientes para tal propósito, ya que presentan problemas a la hora de extender comportamientos preexistente. Para solventar dicha deficiencia, este artículo presenta un patrón, denominado Slicer Pattern, mediante el cual es posible implementar de forma completa diseños orientados a características en C# mediante clases parciales. La principal ventaja de dicho patrón es que permite utilizar el lenguaje C# como lenguaje orientado a características, sin necesidad de extender dicho lenguaje.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>217</post_id>
		<post_date><![CDATA[2015-08-29 21:10:13]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:10:13]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[desarrollo-de-una-linea-de-productos-software-utilizando-las-clases-parciales-c-el-patron-slicer]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="net"><![CDATA[.NET]]></category>
		<category domain="post_tag" nicename="clases-parciales-c"><![CDATA[Clases Parciales C#]]></category>
		<category domain="post_tag" nicename="desarrollo-software-orientado-a-caracteristicas"><![CDATA[Desarrollo Software Orientado a Características]]></category>
		<category domain="post_tag" nicename="linea-de-productos-software"><![CDATA[Línea de Productos Software]]></category>
		<category domain="post_tag" nicename="tente"><![CDATA[TENTE]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alejandro Pérez Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería Informática y Electrónica Universidad de Cantabria Santander (Cantabria), España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[perezruiza@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Sánchez Barreiro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería Informática y Electrónica Universidad de Cantabria Santander (Cantabria), España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[p.sanchez@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las clases parciales de C# permiten dividir el comportamiento global de una clase en diversos fragmentos. Estos fragmentos pueden luego combinarse de diversas formas, produciendo clases completas con comportamientos similares pero ligeramente diferentes, en función de nuestras necesidades. La semejanza de este mecanismo con la programación orientada a características ha hecho que algunos autores hayan considerado las clases parciales de C# como un mecanismo apropiado para el desarrollo de líneas de productos de software. Sin embargo, un reciente estudio ha demostrado que las clases parciales de C# por sí solas no son suficientes para tal propósito, ya que presentan problemas a la hora de extender comportamientos preexistente. Para solventar dicha deficiencia, este artículo presenta un patrón, denominado Slicer Pattern, mediante el cual es posible implementar de forma completa diseños orientados a características en C# mediante clases parciales. La principal ventaja de dicho patrón es que permite utilizar el lenguaje C# como lenguaje orientado a características, sin necesidad de extender dicho lenguaje.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Línea de Productos Software, Desarrollo Software Orientado a Características, TENTE, Clases Parciales C#, .NET]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Arquitecturas Software y Variabilidad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[219]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/027]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Propuesta para un acceso homogéneo a servicios PaaS en la Nube</title>
		<link>https://biblioteca.sistedes.es/articulo/propuesta-para-un-acceso-homogeneo-a-servicios-paas-en-la-nube/</link>
		<pubDate>Sat, 29 Aug 2015 19:15:11 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=221</guid>
		<description></description>
		<content><![CDATA[En el ámbito del Cloud Computing existen multitud de proveedores ofreciendo plataformas como un servicio, que proporcionan un conjunto de funcionalidades para apoyar el ciclo de vida completo de una aplicación, desde su desarrollo hasta el despliegue en la nube (incluso abordando la monitorización en ocasiones). Aunque la existencia de un número elevado de proveedores aumenta y enriquece la potencia de este tipo de servicios, el inconveniente surge cuando cada uno de ellos define servicios distintos, dando lugar a la problemática de la dependencia del vendedor o vendor lock-in. Esta variabilidad complica la selección y uso de los distintos proveedores, ya que cada uno de ellos especifica sus propios conceptos para el modelado de las aplicaciones y de los servicios requeridos durante el despliegue y ejecución de las mismas. En este trabajo, proponemos las bases para la descripción, tanto de las plataformas cloud como de las aplicaciones a desplegar, con el fin de generar una capa de homogeneización capaz de abstraer la interfaz de los servicios ofertados por las distintas plataformas, haciendo uso de una API unificada. Esto facilitará el manejo y selección de los servicios de los distintos proveedores. Para ilustrar la idea, se presenta un escenario de aplicación de chat usando servicios de plataformas cloud.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>221</post_id>
		<post_date><![CDATA[2015-08-29 21:15:11]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:15:11]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[propuesta-para-un-acceso-homogeneo-a-servicios-paas-en-la-nube]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cloud-computing"><![CDATA[Cloud Computing]]></category>
		<category domain="post_tag" nicename="computacion-en-la-nube"><![CDATA[Computación en la Nube]]></category>
		<category domain="post_tag" nicename="homegeneidad"><![CDATA[Homegeneidad]]></category>
		<category domain="post_tag" nicename="plataformas-cloud"><![CDATA[Plataformas Cloud]]></category>
		<category domain="post_tag" nicename="platform-as-a-service"><![CDATA[Platform-as-a-Service]]></category>
		<category domain="post_tag" nicename="unificacion"><![CDATA[Unificación]]></category>
		<category domain="post_tag" nicename="variabilidad"><![CDATA[Variabilidad]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel Barrientos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mbarrientos@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose Carrasco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[josec@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Cubo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[cubo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ernesto Pimentel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[ernesto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En el ámbito del Cloud Computing existen multitud de proveedores ofreciendo plataformas como un servicio, que proporcionan un conjunto de funcionalidades para apoyar el ciclo de vida completo de una aplicación, desde su desarrollo hasta el despliegue en la nube (incluso abordando la monitorización en ocasiones). Aunque la existencia de un número elevado de proveedores aumenta y enriquece la potencia de este tipo de servicios, el inconveniente surge cuando cada uno de ellos define servicios distintos, dando lugar a la problemática de la dependencia del vendedor o vendor lock-in. Esta variabilidad complica la selección y uso de los distintos proveedores, ya que cada uno de ellos especifica sus propios conceptos para el modelado de las aplicaciones y de los servicios requeridos durante el despliegue y ejecución de las mismas. En este trabajo, proponemos las bases para la descripción, tanto de las plataformas cloud como de las aplicaciones a desplegar, con el fin de generar una capa de homogeneización capaz de abstraer la interfaz de los servicios ofertados por las distintas plataformas, haciendo uso de una API unificada. Esto facilitará el manejo y selección de los servicios de los distintos proveedores. Para ilustrar la idea, se presenta un escenario de aplicación de chat usando servicios de plataformas cloud.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Computación en la Nube, Cloud Computing, Plataformas Cloud, Platform-as-a-Service, Variabilidad,Homegeneidad,Unificación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Arquitecturas Software y Variabilidad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[222]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/026]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Exploring the Synergies between Join Point Interfaces and Feature-Oriented Programming</title>
		<link>https://biblioteca.sistedes.es/articulo/exploring-the-synergies-between-join-point-interfaces-and-feature-oriented-programming/</link>
		<pubDate>Sat, 29 Aug 2015 19:18:34 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=224</guid>
		<description></description>
		<content><![CDATA[Feature-oriented programming FOP, and aspect-oriented programming AOP have been used to develop modular software product lines SPL. Both approaches focus on modularizing classes behavior and crosscutting concerns CC. Therefore, the symbiosis of FOP and AOP would permit reaching pros and cons of both software development approaches. Concretely, FOP permits a modular refinement of classes collaboration for software product lines SPL -an adequate structural representation of heterogeneous CC, but FOP does not well represent homogeneous CC. On the other hand, traditional AOP structurally well modularizes homogeneous CC, but aspects are not adequate to represent collaboration of classes for software evolution. In addition, AOP solutions present implicit dependencies and strong coupling between classes and aspects. Since Join Point Interface JPI solves mentioned AOP issues, this paper present JPI Feature Modules to represent and modularize the structure of FOP and JPI SPL instances, i.e., classes and join point interfaces for a transparent implementation in a FOP and JPI context. This paper, highlights benefits of a FOP and JPI symbiosis for the modular software conception using a case study to exemplify its use.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>224</post_id>
		<post_date><![CDATA[2015-08-29 21:18:34]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:18:34]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[exploring-the-synergies-between-join-point-interfaces-and-feature-oriented-programming]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="classic-aop"><![CDATA[classic AOP]]></category>
		<category domain="post_tag" nicename="fop"><![CDATA[FOP]]></category>
		<category domain="post_tag" nicename="jpi"><![CDATA[JPI]]></category>
		<category domain="post_tag" nicename="jpi-fm"><![CDATA[JPI-FM]]></category>
		<category domain="post_tag" nicename="modular-software"><![CDATA[modular software]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cristian Vidal Silva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Computaci´on e Inform´atica Facultad de Ingenier´ıa, Universidad de Playa Ancha Av. Leopoldo Bertossi 270, Playa Ancha, Valpara´ıso, Chile]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cristian.vidal@upla.cl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David Benavides]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville Av. de la Reina Mercedes S/N, 41012 Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[benavides@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José Angel Galindo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[INRIA Renes, France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jagalindo@inria.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Paul Leger]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Escuela de Ciencias Empresariales Universidad Católica del Norte Coquimbo, Chile]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[pleger@ucn.cl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Feature-oriented programming FOP, and aspect-oriented programming AOP have been used to develop modular software product lines SPL. Both approaches focus on modularizing classes behavior and crosscutting concerns CC. Therefore, the symbiosis of FOP and AOP would permit reaching pros and cons of both software development approaches. Concretely, FOP permits a modular refinement of classes collaboration for software product lines SPL -an adequate structural representation of heterogeneous CC, but FOP does not well represent homogeneous CC. On the other hand, traditional AOP structurally well modularizes homogeneous CC, but aspects are not adequate to represent collaboration of classes for software evolution. In addition, AOP solutions present implicit dependencies and strong coupling between classes and aspects. Since Join Point Interface JPI solves mentioned AOP issues, this paper present JPI Feature Modules to represent and modularize the structure of FOP and JPI SPL instances, i.e., classes and join point interfaces for a transparent implementation in a FOP and JPI context. This paper, highlights benefits of a FOP and JPI symbiosis for the modular software conception using a case study to exemplify its use.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[FOP, classic AOP, JPI, modular software, JPI-FM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Arquitecturas Software y Variabilidad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/025]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Análisis de las soluciones guiadas por búsqueda para el problema de selección de requisitos</title>
		<link>https://biblioteca.sistedes.es/articulo/analisis-de-las-soluciones-guiadas-por-busqueda-para-el-problema-de-seleccion-de-requisitos/</link>
		<pubDate>Sat, 29 Aug 2015 19:28:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=230</guid>
		<description></description>
		<content><![CDATA[La Ingeniería del Software guiada por búsqueda propone la utilización de algoritmos de optimización en los problemas de Ingeniería del Software. Este área de investigación ha sido muy prolífica durante los últimos a˜nos, formulando y dando soluciones a problemas de optimización multiobjetivo, como el de la selección de requisitos. Pero cuando los desarrolladores de software tienen que tomar la última decisión acerca de cuál es el conjunto de requisitos a implementar, de entre las soluciones ofrecidas por los métodos multiobjetivo, necesitan revisar y analizar una gran cantidad de datos. Para ayudar en este proceso de toma de decisiones, este trabajo propone un conjunto de indicadores de calidad que facilitan el análisis del problema a nivel de requisitos, soluciones y clientes. El proceso de análisis utilizado combina estos indicadores de calidad con resúmenes estadísticos y visualización de datos. El caso de estudio abordado muestra la forma en la que el proceso de análisis ayuda en la definición de criterios de selección de soluciones, apoyándose en el estudio y visualización de los indicadores de calidad propuestos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>230</post_id>
		<post_date><![CDATA[2015-08-29 21:28:02]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:28:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analisis-de-las-soluciones-guiadas-por-busqueda-para-el-problema-de-seleccion-de-requisitos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software-guiada-por-busqueda"><![CDATA[Ingeniería del Software guiada por búsqueda]]></category>
		<category domain="post_tag" nicename="optimos-de-pareto"><![CDATA[óptimos de Pareto]]></category>
		<category domain="post_tag" nicename="problema-de-seleccion-de-requisitos"><![CDATA[problema de selección de requisitos]]></category>
		<category domain="post_tag" nicename="procesos-de-toma-de-decisiones"><![CDATA[procesos de toma de decisiones]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Isabel María del Aguila]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad of Almería, Crtra. de la Playa s/n, 04120 Almería, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[imaguila@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José del Sagrado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad of Almería, Crtra. de la Playa s/n, 04120 Almería, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jsagrado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alfonso Bosch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad of Almería, Crtra. de la Playa s/n, 04120 Almería, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[abosch@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La Ingeniería del Software guiada por búsqueda propone la utilización de algoritmos de optimización en los problemas de Ingeniería del Software. Este área de investigación ha sido muy prolífica durante los últimos a˜nos, formulando y dando soluciones a problemas de optimización multiobjetivo, como el de la selección de requisitos. Pero cuando los desarrolladores de software tienen que tomar la última decisión acerca de cuál es el conjunto de requisitos a implementar, de entre las soluciones ofrecidas por los métodos multiobjetivo, necesitan revisar y analizar una gran cantidad de datos. Para ayudar en este proceso de toma de decisiones, este trabajo propone un conjunto de indicadores de calidad que facilitan el análisis del problema a nivel de requisitos, soluciones y clientes. El proceso de análisis utilizado combina estos indicadores de calidad con resúmenes estadísticos y visualización de datos. El caso de estudio abordado muestra la forma en la que el proceso de análisis ayuda en la definición de criterios de selección de soluciones, apoyándose en el estudio y visualización de los indicadores de calidad propuestos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Ingeniería del Software guiada por búsqueda, problema de selección de requisitos, óptimos de Pareto, procesos de toma de decisiones]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Ingeniería del Software Guiada por Búsqueda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[231]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/033]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Resolviendo un problema multi-objetivo de selección de requisitos mediante resolutores del problema SAT</title>
		<link>https://biblioteca.sistedes.es/articulo/resolviendo-un-problema-multi-objetivo-de-seleccion-de-requisitos-mediante-resolutores-del-problema-sat/</link>
		<pubDate>Sat, 29 Aug 2015 19:33:31 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=233</guid>
		<description></description>
		<content><![CDATA[El problema de selección de requisitos (o Next Release Problem, NRP) consiste en seleccionar el subconjunto de requisitos que se va a desarrollar en la siguiente versión de una aplicación software. Esta selección se debe hacer de tal forma que maximice la satisfacción de las partes interesadas a la vez que se minimiza el esfuerzo empleado en el desarrollo y se cumplen un conjunto de restricciones. Este es un problema de optimización combinatorio multi-objetivo para el que se han utilizado en el pasado técnicas heurísticas y metaheurísticas en su resolución, ya que es NP-difícil. En el presente trabajo proponemos la traducción de este problema a lógica proposicional y el uso de resolutores del problema SAT en una estrategia para encontrar el frente de Pareto de forma exacta.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>233</post_id>
		<post_date><![CDATA[2015-08-29 21:33:31]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:33:31]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[resolviendo-un-problema-multi-objetivo-de-seleccion-de-requisitos-mediante-resolutores-del-problema-sat]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="next-release-problem"><![CDATA[next release problem]]></category>
		<category domain="post_tag" nicename="optimizacion-multi-objetivo"><![CDATA[optimización multi-objetivo]]></category>
		<category domain="post_tag" nicename="resolutores-sat"><![CDATA[resolutores SAT]]></category>
		<category domain="post_tag" nicename="seleccion-de-requisitos"><![CDATA[Selección de requisitos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Isabel María del Aguila]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Almería, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[imaguila@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José del Sagrado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Almería, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jsagrado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco Chicano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[chicano@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Enrique Alba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[eat@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El problema de selección de requisitos (o Next Release Problem, NRP) consiste en seleccionar el subconjunto de requisitos que se va a desarrollar en la siguiente versión de una aplicación software. Esta selección se debe hacer de tal forma que maximice la satisfacción de las partes interesadas a la vez que se minimiza el esfuerzo empleado en el desarrollo y se cumplen un conjunto de restricciones. Este es un problema de optimización combinatorio multi-objetivo para el que se han utilizado en el pasado técnicas heurísticas y metaheurísticas en su resolución, ya que es NP-difícil. En el presente trabajo proponemos la traducción de este problema a lógica proposicional y el uso de resolutores del problema SAT en una estrategia para encontrar el frente de Pareto de forma exacta.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Selección de requisitos, next release problem, optimización multi-objetivo, resolutores SAT]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Ingeniería del Software Guiada por Búsqueda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[234]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/032]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>TESTAR - from academic protoype towards an industry-ready tool for automated testing at the User Interface level</title>
		<link>https://biblioteca.sistedes.es/articulo/testar-from-academic-protoype-towards-an-industry-ready-tool-for-automated-testing-at-the-user-interface-level/</link>
		<pubDate>Sat, 29 Aug 2015 19:37:20 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=236</guid>
		<description></description>
		<content><![CDATA[Testing applications with a Graphical User Interface (GUI) is an important, though challenging and time consuming task. The state of the art in the industry are still capture and replay tools, which may simplify the recording and execution of input sequences, but do not support the tester in finding fault-sensitive test cases and leads to a huge overhead on maintenance of the test cases when the GUI changes. While search-based test case generation strategies are well researched for various areas of testing, relatively little work has been done on applying these techniques to an entire GUI of an application. In this paper we present the tool TESTAR, an automated search-based approach to test applications at the GUI level whose objective is to solve part of the maintenance problem by automatically generating test cases based on a structure that is automatically derived from the GUI.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>236</post_id>
		<post_date><![CDATA[2015-08-29 21:37:20]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:37:20]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[testar-from-academic-protoype-towards-an-industry-ready-tool-for-automated-testing-at-the-user-interface-level]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="automated"><![CDATA[Automated]]></category>
		<category domain="post_tag" nicename="search-based"><![CDATA[Search-Based]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<category domain="post_tag" nicename="user-interface-level"><![CDATA[User Interface level]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Urko Rueda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Valencia, Spain, Camino de vera s/n, 46022 Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[urueda@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Tanja E.J. Vos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Valencia, Spain, Camino de vera s/n, 46022 Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[tvos@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco Almenar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Valencia, Spain, Camino de vera s/n, 46022 Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fraalpe2@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Mirella Oreto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Valencia, Spain, Camino de vera s/n, 46022 Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mimarmu1@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Anna Esparcia Alcazar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Valencia, Spain, Camino de vera s/n, 46022 Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aesparcia@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Testing applications with a Graphical User Interface (GUI) is an important, though challenging and time consuming task. The state of the art in the industry are still capture and replay tools, which may simplify the recording and execution of input sequences, but do not support the tester in finding fault-sensitive test cases and leads to a huge overhead on maintenance of the test cases when the GUI changes. While search-based test case generation strategies are well researched for various areas of testing, relatively little work has been done on applying these techniques to an entire GUI of an application. In this paper we present the tool TESTAR, an automated search-based approach to test applications at the GUI level whose objective is to solve part of the maintenance problem by automatically generating test cases based on a structure that is automatically derived from the GUI.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Automated, Search-Based, Testing, User Interface level]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Ingeniería del Software Guiada por Búsqueda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[237]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/031]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>People as a Service y la Ingeniería del Software Guiada por Búsqueda</title>
		<link>https://biblioteca.sistedes.es/articulo/people-as-a-service-y-la-ingenieria-del-software-guiada-por-busqueda/</link>
		<pubDate>Sat, 29 Aug 2015 19:45:21 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=239</guid>
		<description></description>
		<content><![CDATA[People as a Service es un nuevo paradigma de computación centrada en los dispositivos móviles que permite generar perfiles sociológicos de sus due˜nos y proporcionarlos como servicios de forma segura desde los propios dispositivos. Dentro de este paradigma, la Ingeniería del Software Guiada por Búsqueda proporciona aportaciones relevantes en dos áreas. Por una parte, las nuevas arquitecturas software habilitadas por el paradigma de People as a Service, facilitan el desarrollo de un nuevo tipo de aplicaciones móviles en el que los dispositivos sean usados como agentes de un sistema de inteligencia de . Por otra parte, la implementación de este paradigma, con las restricciones impuestas por los sistemas operativos móviles actuales, se enfrenta a una serie de limitaciones que pueden ser abordadas aplicando técnicas de Ingeniería del Software Guiada por Búsqueda. En este trabajo se exploran las posibles aplicaciones de estas técnicas dentro del paradigma de People as a Service y se establecen los próximos pasos a seguir en esta línea.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>239</post_id>
		<post_date><![CDATA[2015-08-29 21:45:21]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:45:21]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[people-as-a-service-y-la-ingenieria-del-software-guiada-por-busqueda]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software-guiada-por-busqueda"><![CDATA[Ingeniería del Software guiada por búsqueda]]></category>
		<category domain="post_tag" nicename="inteligencia-de-enjambre"><![CDATA[Inteligencia de enjambre]]></category>
		<category domain="post_tag" nicename="people-as-a-service"><![CDATA[People as a Service]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jose Garcia-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[People as a Service es un nuevo paradigma de computación centrada en los dispositivos móviles que permite generar perfiles sociológicos de sus due˜nos y proporcionarlos como servicios de forma segura desde los propios dispositivos. Dentro de este paradigma, la Ingeniería del Software Guiada por Búsqueda proporciona aportaciones relevantes en dos áreas. Por una parte, las nuevas arquitecturas software habilitadas por el paradigma de People as a Service, facilitan el desarrollo de un nuevo tipo de aplicaciones móviles en el que los dispositivos sean usados como agentes de un sistema de inteligencia de  . Por otra parte, la implementación de este paradigma, con las restricciones impuestas por los sistemas operativos móviles actuales, se enfrenta a una serie de limitaciones que pueden ser abordadas aplicando técnicas de Ingeniería del Software Guiada por Búsqueda. En este trabajo se exploran las posibles aplicaciones de estas técnicas dentro del paradigma de People as a Service y se establecen los próximos pasos a seguir en esta línea. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[People as a Service, Ingeniería del Software Guiada por Búsqueda, Inteligencia de enjambre ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Ingeniería del Software Guiada por Búsqueda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[240]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/030]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Interactividad en el descubrimiento evolutivo de arquitecturas</title>
		<link>https://biblioteca.sistedes.es/articulo/interactividad-en-el-descubrimiento-evolutivo-de-arquitecturas/</link>
		<pubDate>Sat, 29 Aug 2015 19:48:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=242</guid>
		<description></description>
		<content><![CDATA[Resolver tareas propias del dise˜no arquitectónico de manera automática es un reto complejo, puesto que los arquitectos cuentan con habilidades que difícilmente pueden simularse y son capaces, además, de mantener una visión global de la actividad que realizan. Por su parte, la ingeniería del software basada en búsqueda está demostrando que las técnicas metaheurísticas son útiles cuando se desea prestar apoyo al ingeniero, especialmente cuando éste puede intervenir activamente en el proceso. Este trabajo analiza los retos que plantea esta colaboración a la hora de desarrollar modelos metaheurísticos para resolver tareas en una fase temprana del software como es el dise˜no arquitectónico. Se estudian aspectos como el papel del ingeniero y los criterios que van a guiar su intervención durante la búsqueda, sirviendo como paso previo para la propuesta de un modelo inicial con el que abordar el descubrimiento de arquitecturas software mediante un algoritmo evolutivo interactivo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>242</post_id>
		<post_date><![CDATA[2015-08-29 21:48:48]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:48:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[interactividad-en-el-descubrimiento-evolutivo-de-arquitecturas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="algoritmos-evolutivos"><![CDATA[algoritmos evolutivos]]></category>
		<category domain="post_tag" nicename="dise%cb%9cno-arquitectonico"><![CDATA[Dise˜no arquitectónico]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software-basada-en-busqueda"><![CDATA[ingeniería del software basada en búsqueda]]></category>
		<category domain="post_tag" nicename="interactividad"><![CDATA[interactividad]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aurora Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico Universidad de Córdoba, Campus de Rabanales, 14071 Córdoba, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aramirez@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Raúl Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico Universidad de Córdoba, Campus de Rabanales, 14071 Córdoba, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sebastián Ventura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico Universidad de Córdoba, Campus de Rabanales, 14071 Córdoba, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ sventura@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resolver tareas propias del dise˜no arquitectónico de manera automática es un reto complejo, puesto que los arquitectos cuentan con habilidades que difícilmente pueden simularse y son capaces, además, de mantener una visión global de la actividad que realizan. Por su parte, la ingeniería del software basada en búsqueda está demostrando que las técnicas metaheurísticas son útiles cuando se desea prestar apoyo al ingeniero, especialmente cuando éste puede intervenir activamente en el proceso. Este trabajo analiza los retos que plantea esta colaboración a la hora de desarrollar modelos metaheurísticos para resolver tareas en una fase temprana del software como es el dise˜no arquitectónico. Se estudian aspectos como el papel del ingeniero y los criterios que van a guiar su intervención durante la búsqueda, sirviendo como paso previo para la propuesta de un modelo inicial con el que abordar el descubrimiento de arquitecturas software mediante un algoritmo evolutivo interactivo. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Dise˜no arquitectónico, ingeniería del software basada en búsqueda, algoritmos evolutivos, interactividad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Ingeniería del Software Guiada por Búsqueda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[243]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/029]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Análisis y determinación del impacto del operador de mutación en la generación genética de casos de prueba para WS-BPEL</title>
		<link>https://biblioteca.sistedes.es/articulo/analisis-y-determinacion-del-impacto-del-operador-de-mutacion-en-la-generacion-genetica-de-casos-de-prueba-para-ws-bpel/</link>
		<pubDate>Sat, 29 Aug 2015 19:55:40 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=245</guid>
		<description></description>
		<content><![CDATA[La prueba basada en búsqueda permite generar casos de prueba automáticamente mediante la codificación de un criterio de cobertura como una función de aptitud que guía la búsqueda. Los algoritmos genéticos se han aplicado con éxito a este tipo de prueba utilizando principalmente criterios de cobertura estructural. Este trabajo presenta el análisis realizado para mejorar el comportamiento del generador de casos de prueba Rodan, que emplea un algoritmo genético para generar casos de prueba que matan mutantes producidos a partir de composiciones WS-BPEL. Se presentan los resultados obtenidos sobre un caso de estudio clásico en la literatura de prueba (un clasificador de triángulos) para tres operadores de mutación, con siembra y sin ella, y con distintos tamaños del espacio de búsqueda. Estos resultados se comparan con los obtenidos mediante generación aleatoria de casos de prueba.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>245</post_id>
		<post_date><![CDATA[2015-08-29 21:55:40]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:55:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analisis-y-determinacion-del-impacto-del-operador-de-mutacion-en-la-generacion-genetica-de-casos-de-prueba-para-ws-bpel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonia Estero-Botaro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Avenida de la Universidad de Cádiz, 10, 11519, Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[antonia.estero@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Álvaro Cortijo-García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Avenida de la Universidad de Cádiz, 10, 11519, Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[alvaro.cortijogarcia@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio García-Domínguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Avenida de la Universidad de Cádiz, 10, 11519, Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[antonio.garciadominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Francisco Palomo-Lozano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Avenida de la Universidad de Cádiz, 10, 11519, Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[francisco.palomo@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Juan José Domínguez-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Avenida de la Universidad de Cádiz, 10, 11519, Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[juanjose.dominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Avenida de la Universidad de Cádiz, 10, 11519, Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La prueba basada en búsqueda permite generar casos de prueba automáticamente mediante la codificación de un criterio de cobertura como una función de aptitud que guía la búsqueda. Los algoritmos genéticos se han aplicado con éxito a este tipo de prueba utilizando principalmente criterios de cobertura estructural. Este trabajo presenta el análisis realizado para mejorar el comportamiento del generador de casos de prueba Rodan, que emplea un algoritmo genético para generar casos de prueba que matan mutantes producidos a partir de composiciones WS-BPEL. Se presentan los resultados obtenidos sobre un caso de estudio clásico en la literatura de prueba (un clasificador de triángulos) para tres operadores de mutación, con siembra y sin ella, y con distintos tamaños del espacio de búsqueda. Estos resultados se comparan con los obtenidos mediante generación aleatoria de casos de prueba.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Ingeniería del Software Guiada por Búsqueda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[246]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/028]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un entorno de gestión de casos para la resolución  flexible de emergencias</title>
		<link>https://biblioteca.sistedes.es/articulo/un-entorno-de-gestion-de-casos-para-la-resolucion-flexible-de-emergencias/</link>
		<pubDate>Sat, 29 Aug 2015 23:06:31 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=250</guid>
		<description></description>
		<content><![CDATA[Los lenguajes basados en procesos han sido utilizados durante la última década para modelar procedimientos de respuesta a situaciones de emergencia. La validez práctica y operativa de tales modelos depende de la capacidad de los mismos para manejar contingencias y situaciones excepcionales durante la respuesta a emergencias. Estos modelos proporcionan una flexibilidad limitada, ya que suelen tener únicamente en cuenta un número pequeño de variaciones y excepciones, donde los participantes en el proceso tienen poca libertad para decidir qué debería hacerse en cada momento. La gestión flexible de casos (Adaptive Case Management, ACM) es una aproximación nueva que se utiliza para gestionar procesos intensivos en conocimiento. ACM permite a los participantes en un proceso gestionar situaciones donde el nivel de flexibilidad es más avanzado que el proporcionado por los procesos clásicos. ACM supone un salto desde los modelos de procesos estructurados, de naturaleza imperativa, a modelos fuertemente declarativos. En este trabajo presentamos una extensión al módulo de ejecución de planes de emergencia de SAGA (Sistema de Apoyo a la Gestión de la Autoprotección), un marco para la gestión de planes de emergencia, para permitir la ejecución de planes modelados con un lenguaje de gestión de casos. De manera adicional hemos enriquecido, mediante la Arquitectura de Objetos Digitales, el módulo de definición de planes de SAGA para que el motor de ejecución pueda proporcionar a los participantes todos los recursos de información necesarios para llevar a cabo una tarea de respuesta.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>250</post_id>
		<post_date><![CDATA[2015-08-30 01:06:31]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 23:06:31]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-entorno-de-gestion-de-casos-para-la-resolucion-flexible-de-emergencias]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="gestion-de-casos"><![CDATA[gestión de casos]]></category>
		<category domain="post_tag" nicename="objetos-digitales"><![CDATA[objetos digitales]]></category>
		<category domain="post_tag" nicename="planes-de-emergencia"><![CDATA[planes de emergencia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan Sánchez Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ISSI-DSIC Universitat Politècnica de València Camino de Vera s/n. 46022 Valencia. España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jsanchez@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Carsí Cubel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ISSI-DSIC Universitat Politècnica de València Camino de Vera s/n. 46022 Valencia. España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pcarsi@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[M. Carmen Penadés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ISSI-DSIC Universitat Politècnica de València Camino de Vera s/n. 46022 Valencia. España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mpenades@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los lenguajes basados en procesos han sido utilizados durante la última década para modelar procedimientos de respuesta a situaciones de emergencia. La validez práctica y operativa de tales modelos depende de la capacidad de los mismos para manejar contingencias y situaciones excepcionales durante la respuesta a emergencias. Estos modelos proporcionan una flexibilidad limitada, ya que suelen tener únicamente en cuenta un número pequeño de variaciones y excepciones, donde los participantes en el proceso tienen poca libertad para decidir qué debería hacerse en cada momento. La gestión flexible de casos (Adaptive Case Management, ACM) es una aproximación nueva que se utiliza para gestionar procesos intensivos en conocimiento. ACM permite a los participantes en un proceso gestionar situaciones donde el nivel de flexibilidad es más avanzado que el proporcionado por los procesos clásicos. ACM supone un salto desde los modelos de procesos estructurados, de naturaleza imperativa, a modelos fuertemente declarativos. En este trabajo presentamos una extensión al módulo de ejecución de planes de emergencia de SAGA (Sistema de Apoyo a la Gestión de la Autoprotección), un marco para la gestión de planes de emergencia, para permitir la ejecución de planes modelados con un lenguaje de gestión de casos. De manera adicional hemos enriquecido, mediante la Arquitectura de Objetos Digitales, el módulo de definición de planes de SAGA para que el motor de ejecución pueda proporcionar a los participantes todos los recursos de información necesarios para llevar a cabo una tarea de respuesta.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[planes de emergencia, gestión de casos, objetos digitales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Open]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[251]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/035]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>KVLEAP: Interacción sin contacto (touchless) con ordenadores</title>
		<link>https://biblioteca.sistedes.es/articulo/kvleap-interaccion-sin-contacto-touchless-con-ordenadores/</link>
		<pubDate>Sat, 29 Aug 2015 23:12:14 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=254</guid>
		<description></description>
		<content><![CDATA[Hoy en día existen diferentes alternativas para interactuar con los ordenadores. Las más extendidas y utilizadas son el teclado, el ratón o la pantalla táctil, aunque en los tres casos resulta necesario que las manos del usuario entren en contacto con algún dispositivo. Sin embargo, en determinadas circunstancias en las que la higiene de las manos es un factor importante, puede suponer un inconveniente. Mostraremos una aplicación, KVLEAP, que usando el controlador Leap Motion, un dispositivo que detecta y rastrea la posición y los movimientos de las manos en el aire, permite interactuar con un ordenador sin que las manos del usuario tengan que entrar en contacto con ningún dispositivo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>254</post_id>
		<post_date><![CDATA[2015-08-30 01:12:14]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 23:12:14]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[kvleap-interaccion-sin-contacto-touchless-con-ordenadores]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="captura-de-movimiento"><![CDATA[Captura de movimiento]]></category>
		<category domain="post_tag" nicename="interaccion-touchless"><![CDATA[Interacción touchless]]></category>
		<category domain="post_tag" nicename="leap-motion"><![CDATA[Leap Motion]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[K. Villalobos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática UPV/EHU, Pº Manuel Lardizabal, 1 - 20018 Donostia-San Sebastián]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[kvillalobos001@ikasle.ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[D. Antón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática UPV/EHU, Pº Manuel Lardizabal, 1 - 20018 Donostia-San Sebastián]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[A. Goñi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática UPV/EHU, Pº Manuel Lardizabal, 1 - 20018 Donostia-San Sebastián]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[A. Illarramendi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática UPV/EHU, Pº Manuel Lardizabal, 1 - 20018 Donostia-San Sebastián]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Hoy en día existen diferentes alternativas para interactuar con los ordenadores. Las más extendidas y utilizadas son el teclado, el ratón o la pantalla táctil, aunque en los tres casos resulta necesario que las manos del usuario entren en contacto con algún dispositivo. Sin embargo, en determinadas circunstancias en las que la higiene de las manos es un factor importante, puede suponer un inconveniente. Mostraremos una aplicación, KVLEAP, que usando el controlador Leap Motion, un dispositivo que detecta y rastrea la posición y los movimientos de las manos en el aire, permite interactuar con un ordenador sin que las manos del usuario tengan que entrar en contacto con ningún dispositivo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Captura de movimiento, Leap Motion, Interacción touchless]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Open]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[255]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/034]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>BETaaS: A Distributed Platform for Things as a Service</title>
		<link>https://biblioteca.sistedes.es/articulo/betaas-a-distributed-platform-for-things-as-a-service/</link>
		<pubDate>Tue, 01 Sep 2015 00:58:22 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=316</guid>
		<description></description>
		<content><![CDATA[Internet of Things (IoT) has become an important research topic during the last years due to the increasing number of devices, sensors and actuators available, and the expected trends in the availability of these elements. BETaaS aims at providing a horizontal solution which will facilitate things management, exploiting their full potential and providing advanced capabilities such as Quality of Service (QoS), security, trust, virtualization, linked data and dependability, so things will be used as services with all the guarantees required by end users executing their applications in any environment.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>316</post_id>
		<post_date><![CDATA[2015-09-01 02:58:22]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 00:58:22]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[betaas-a-distributed-platform-for-things-as-a-service]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="internet-of-things"><![CDATA[Internet of Things]]></category>
		<category domain="post_tag" nicename="local-cloud"><![CDATA[Local Cloud]]></category>
		<category domain="post_tag" nicename="things-as-a-service"><![CDATA[Things as a Service]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Javier Nieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ATOS Research and Innovation Bilbao, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Francisco.nieto@atos.net]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[ Internet of Things (IoT) has become an important research topic during the last years due to the increasing number of devices, sensors and actuators available, and the expected trends in the availability of these elements. BETaaS aims at providing a horizontal solution which will facilitate things management, exploiting their full potential and providing advanced capabilities such as Quality of Service (QoS), security, trust, virtualization, linked data and dependability, so things will be used as services with all the guarantees required by end users executing their applications in any environment.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Internet of Things, Local Cloud, Things as a Service]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Experiencias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[317]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/019]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>CloudWave: Agile Service Engineering for the Future Internet</title>
		<link>https://biblioteca.sistedes.es/articulo/cloudwave-agile-service-engineering-for-the-future-internet/</link>
		<pubDate>Tue, 01 Sep 2015 01:01:19 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=319</guid>
		<description></description>
		<content><![CDATA[After achieving initial market penetration, Cloud Computing stakeholders now call for a next generation of Infrastructure and Software as a Service offering (IaaS and SaaS). CloudWave, an EU-funded FP7 research project, looks to dynamically adapt cloud services to their environment, resulting in improved service quality and optimized resource use. This is supported with an enhanced cloud monitoring that provides holistic analytics of IaaS and SaaS layer services running on the cloud, leading to CloudWave’s innovative, automated adaptation of the infrastructure and application, as well as enabling DevOps-like data and interfaces for the developer. DevOps-like data and interfaces for the developer.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>319</post_id>
		<post_date><![CDATA[2015-09-01 03:01:19]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:01:19]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[cloudwave-agile-service-engineering-for-the-future-internet]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cloud-computing"><![CDATA[Cloud Computing]]></category>
		<category domain="post_tag" nicename="devops"><![CDATA[DevOps]]></category>
		<category domain="post_tag" nicename="iaas"><![CDATA[IaaS]]></category>
		<category domain="post_tag" nicename="monitoring"><![CDATA[Monitoring]]></category>
		<category domain="post_tag" nicename="optimization"><![CDATA[Optimization]]></category>
		<category domain="post_tag" nicename="qos"><![CDATA[QoS]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Javier Nieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ATOS Research and Innovation ATOS Bilbao, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Francisco.nieto@atos.net]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[James Ahtes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ATOS Research and Innovation ATOS Barcelona, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[james.ahtes@atos.net]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[After achieving initial market penetration, Cloud Computing stakeholders now call for a next generation of Infrastructure and Software as a Service offering (IaaS and SaaS). CloudWave, an EU-funded FP7 research project, looks to dynamically adapt cloud services to their environment, resulting in improved service quality and optimized resource use. This is supported with an enhanced cloud monitoring that provides holistic analytics of IaaS and SaaS layer services running on the cloud, leading to CloudWave’s innovative, automated adaptation of the infrastructure and application, as well as enabling DevOps-like data and interfaces for the developer. DevOps-like data and interfaces for the developer.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ Cloud Computing, IaaS, Monitoring, DevOps, QoS, Optimization]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Experiencias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[320]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/018]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SeaClouds: An Application Management System over the Clouds</title>
		<link>https://biblioteca.sistedes.es/articulo/seaclouds-an-application-management-system-over-the-clouds/</link>
		<pubDate>Tue, 01 Sep 2015 01:08:37 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=322</guid>
		<description></description>
		<content><![CDATA[How to deploy and manage, in an efficient and adaptive way, complex applications across multiple heterogeneous cloud platforms is one of the problems that have emerged with the cloud revolution. Here we present the context, motivations, objectives, proposal and initial results of SeaClouds: an european research project, which aims at enabling a seamless adaptive multi-cloud management of complex applications by supporting the distribution, monitoring and migration of application modules over multiple heterogeneous cloud platforms.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>322</post_id>
		<post_date><![CDATA[2015-09-01 03:08:37]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:08:37]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[seaclouds-an-application-management-system-over-the-clouds]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="app-management"><![CDATA[app management]]></category>
		<category domain="post_tag" nicename="cloud-deployment"><![CDATA[Cloud deployment]]></category>
		<category domain="post_tag" nicename="cloud-interoperability"><![CDATA[cloud interoperability]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel Barrientos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[barrientos@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Leonardo Bartoloni]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Pisa, Dept. Computer Science, Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[bartolon@di.unipi.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Brogi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Pisa, Dept. Computer Science, Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[brogi@di.unipi.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Mattia Buccarella]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Pisa, Dept. Computer Science, Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[buccarella@di.unipi.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Jose Carrasco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[josec@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Javier Cubo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[cubo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Francesco D’Andria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[francesco.dandria@atos.net]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[ATOS Researcg and Innovation, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[How to deploy and manage, in an efficient and adaptive way, complex applications across multiple heterogeneous cloud platforms is one of the problems that have emerged with the cloud revolution. Here we present the context, motivations, objectives, proposal and initial results of SeaClouds: an european research project, which aims at enabling a seamless adaptive multi-cloud management of complex applications by supporting the distribution, monitoring and migration of application modules over multiple heterogeneous cloud platforms.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Cloud deployment, cloud interoperability, app management]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Experiencias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[323]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/017]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>ProDiGen: minando modelos completos, precisos y simples con un algoritmo genético</title>
		<link>https://biblioteca.sistedes.es/articulo/prodigen-minando-modelos-completos-precisos-y-simples-con-un-algoritmo-genetico/</link>
		<pubDate>Tue, 01 Sep 2015 01:13:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=325</guid>
		<description></description>
		<content><![CDATA[Un proceso se puede entender como una secuencia de tareas que se llevan a cabo para alcanzar un determinado objetivo. Por ejemplo, en educación, el dise˜no de aprendizaje es un proceso en el que los alumnos deben realizar una secuencia de actividades —escribir en el foro, hacer un examen, etc.— para poder lograr los objetivos pedagógicos del curso. En general, estos procesos están perfectamente detallados, sin embargo, incluso en estas situaciones, pueden existir diferencias entre lo que está sucediendo en el proceso, y lo que se cree que está a suceder en realidad. Por ejemplo, siguiengo el ejemplo del dominio educativo, los alumnos pueden realizar trabajos adicionales, como puede ser revisar la bibliografía o interactuar entre ellos. Es así como el descubrimiento de procesos es necesario para obtener información de qué es lo que está sucediendo en realidad durante la ejecución del proceso, y no lo que creemos que está a suceder. Típicamente, estas técnicas trabajan sobre registros que contienen la información sobre los eventos detectados y almacenados por el sistema de información donde tuvo lugar el proceso. El descubrimiento de procesos tiene como objetivo obtener el flujo de trabajo que mejor representa el comportamiento almacenado en dicho registro. En la última década se han desarrollado decenas de algoritmos que abordan esta problemática de descubrimiento, sin embargo, las técnicas actuales o bien generan modelos difíciles de leer, modelos que no son capaces de representar todo el comportamiento del registro, o bien modelos que no permiten hacer frente a todas las estructuras de control al mismo tiempo. Este artículo describe ProDiGen (Process Discovery through a Genetic algorithm), un algoritmo de descubrimiento de flujos de trabajo que guía su búsqueda en torno a modelos completos, precisos y simples. ProDiGen se basa en una función de fitness jerárquica que tiene en cuenta la completitud, la precisión y la simpicidad, utilizando dos métricas nuevas para los dos últimos criterios. Además, utiliza heurísticas para optimizar tanto el cruce —teniendo en cuenta los errores del modelo minado— como la mutación —guianda por las dependencias causales del log. ProDiGen se ha validado con 111 registros y se ha comparado con cuatro algoritmos del estado del arte, validándo los resultados con test estadísticos no paramétricos. Los resultados muestran una mejora significativa de ProDiGen respecto al resto de algoritmos utilizados en la comparativa.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>325</post_id>
		<post_date><![CDATA[2015-09-01 03:13:07]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:13:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[prodigen-minando-modelos-completos-precisos-y-simples-con-un-algoritmo-genetico]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Borja Vázquez-Barreiros]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnoloxías da Información (CiTIUS) Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[borja.vazquez@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Mucientes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnoloxías da Información (CiTIUS) Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[manuel.mucientes@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Lama]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnoloxías da Información (CiTIUS) Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuel.lama@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Un proceso se puede entender como una secuencia de tareas que se llevan a cabo para alcanzar un determinado objetivo. Por ejemplo, en educación, el dise˜no de aprendizaje es un proceso en el que los alumnos deben realizar una secuencia de actividades —escribir en el foro, hacer un examen, etc.— para poder lograr los objetivos pedagógicos del curso. En general, estos procesos están perfectamente detallados, sin embargo, incluso en estas situaciones, pueden existir diferencias entre lo que está sucediendo en el proceso, y lo que se cree que está a suceder en realidad. Por ejemplo, siguiengo el ejemplo del dominio educativo, los alumnos pueden realizar trabajos adicionales, como puede ser revisar la bibliografía o interactuar entre ellos. Es así como el descubrimiento de procesos es necesario para obtener información de qué es lo que está sucediendo en realidad durante la ejecución del proceso, y no lo que creemos que está a suceder. Típicamente, estas técnicas trabajan sobre registros que contienen la información sobre los eventos detectados y almacenados por el sistema de información donde tuvo lugar el proceso. El descubrimiento de procesos tiene como objetivo obtener el flujo de trabajo que mejor representa el comportamiento almacenado en dicho registro. En la última década se han desarrollado decenas de algoritmos que abordan esta problemática de descubrimiento, sin embargo, las técnicas actuales o bien generan modelos difíciles de leer, modelos que no son capaces de representar todo el comportamiento del registro, o bien modelos que no permiten hacer frente a todas las estructuras de control al mismo tiempo. Este artículo describe ProDiGen (Process Discovery through a Genetic algorithm), un algoritmo de descubrimiento de flujos de trabajo que guía su búsqueda en torno a modelos completos, precisos y simples. ProDiGen se basa en una función de fitness jerárquica que tiene en cuenta la completitud, la precisión y la simpicidad, utilizando dos métricas nuevas para los dos últimos criterios. Además, utiliza heurísticas para optimizar tanto el cruce —teniendo en cuenta los errores del modelo minado— como la mutación —guianda por las dependencias causales del log. ProDiGen se ha validado con 111 registros y se ha comparado con cuatro algoritmos del estado del arte, validándo los resultados con test estadísticos no paramétricos. Los resultados muestran una mejora significativa de ProDiGen respecto al resto de algoritmos utilizados en la comparativa.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[326]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/020]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Conservación de una Reserva Natural con un Enfoque Orientado a Servicios y Dirigido por Eventos</title>
		<link>https://biblioteca.sistedes.es/articulo/conservacion-de-una-reserva-natural-con-un-enfoque-orientado-a-servicios-y-dirigido-por-eventos/</link>
		<pubDate>Tue, 01 Sep 2015 01:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=328</guid>
		<description></description>
		<content><![CDATA[Las reservas naturales son una fuente de biodiversidad de inestimable valor que pretenden proteger la vida animal y vegetal manteniendo el equilibrio ecológico. La superpoblación de la tierra, las empresas constructoras, las empresas madereras y de extracción de recursos naturales, la caza furtiva descontrolada y la deposición de residuos, entre otros, amenazan con violar estas reservas protegidas. Por ello, se requieren nuevos enfoques tecnológicos para la observación, control, prevención y actuación, que garanticen el futuro de las reservas naturales. En este artículo se propone la monitorización en tiempo real de estos territorios usando un enfoque orientado a servicios y dirigido por eventos para la protección de los ecosistemas, haciendo hincapié en el uso de elementos electrónicos de bajo coste. Los beneficios derivados de esta propuesta redundarán en la protección de las especies autóctonas, la prevención de incendios, la obtención de datos sobre los cambios en los distintos hábitats y el apoyo a las unidades de guardabosques.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>328</post_id>
		<post_date><![CDATA[2015-09-01 03:17:54]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[conservacion-de-una-reserva-natural-con-un-enfoque-orientado-a-servicios-y-dirigido-por-eventos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="arquitectura-orientada-a-servicios-y-dirigida-por-eventos"><![CDATA[arquitectura orientada a servicios y dirigida por eventos]]></category>
		<category domain="post_tag" nicename="conservacion-de-reserva-natural"><![CDATA[conservación de reserva natural]]></category>
		<category domain="post_tag" nicename="procesamiento-de-eventos-complejos"><![CDATA[procesamiento de eventos complejos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio J. Arjona-Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Escuela Superior de Ingeniería, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[antonio.arjonarodriguez@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las reservas naturales son una fuente de biodiversidad de inestimable valor que pretenden proteger la vida animal y vegetal manteniendo el equilibrio ecológico. La superpoblación de la tierra, las empresas constructoras, las empresas madereras y de extracción de recursos naturales, la caza furtiva descontrolada y la deposición de residuos, entre otros, amenazan con violar estas reservas protegidas. Por ello, se requieren nuevos enfoques tecnológicos para la observación, control, prevención y actuación, que garanticen el futuro de las reservas naturales. En este artículo se propone la monitorización en tiempo real de estos territorios usando un enfoque orientado a servicios y dirigido por eventos para la protección de los ecosistemas, haciendo hincapié en el uso de elementos electrónicos de bajo coste. Los beneficios derivados de esta propuesta redundarán en la protección de las especies autóctonas, la prevención de incendios, la obtención de datos sobre los cambios en los distintos hábitats y el apoyo a las unidades de guardabosques.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[procesamiento de eventos complejos, arquitectura orientada a servicios y dirigida por eventos, conservación de reserva natural]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[329]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/016]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Estimación del coste de aprovisionar instancias de cómputo para ejecutar aplicaciones bag-of-task en el cloud de Amazon</title>
		<link>https://biblioteca.sistedes.es/articulo/estimacion-del-coste-de-aprovisionar-instancias-de-computo-para-ejecutar-aplicaciones-bag-of-task-en-el-cloud-de-amazon/</link>
		<pubDate>Tue, 01 Sep 2015 01:22:58 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=331</guid>
		<description></description>
		<content><![CDATA[Sin duda, el coste económico es un factor decisivo cuando se valora la posibilidad de ejecutar una aplicación en cloud. Hoy en día, estimar cuál es el precio a pagar no es sencillo si se trata de aplicaciones que requieren un elevado número de recursos de cómputo y almacenamiento. En este trabajo, se propone un método para minimizar el coste de ejecución de aplicaciones paralelas bag-of-task en un entorno de cómputo tipo cloud. Este método no sólo calcula una estimación del precio a pagar, sino que también determina qué recursos deberían ser contratados para minimizar ese precio. Una contribución importante de la solución es que considera la heterogeneidad de los proveedores cloud a nivel de catálogo de recursos, modelos y plazos de arrendamiento, opciones de pago, etc. La propuesta ha sido aplicada a un problema intenso en cómputo y ejecutado en el entorno de Amazon Elastic Compute Cloud (EC2).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>331</post_id>
		<post_date><![CDATA[2015-09-01 03:22:58]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:22:58]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[estimacion-del-coste-de-aprovisionar-instancias-de-computo-para-ejecutar-aplicaciones-bag-of-task-en-el-cloud-de-amazon]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="amazon-ec2"><![CDATA[Amazon EC2]]></category>
		<category domain="post_tag" nicename="aplicaciones-paralelas"><![CDATA[aplicaciones paralelas]]></category>
		<category domain="post_tag" nicename="aprovisionamiento-de-recursos"><![CDATA[aprovisionamiento de recursos]]></category>
		<category domain="post_tag" nicename="computacion-en-la-nube"><![CDATA[Computación en la Nube]]></category>
		<category domain="post_tag" nicename="minimizacion-de-costes"><![CDATA[minimización de costes]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Alvarez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Ingeniería de Aragón (I3A) Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alvaper@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Ingeniería de Aragón (I3A) Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[shernandez@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Fabra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Ingeniería de Aragón (I3A) Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jfabra@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Joaquín Ezpeleta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Ingeniería de Aragón (I3A) Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[ezpeleta@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Sin duda, el coste económico es un factor decisivo cuando se valora la posibilidad de ejecutar una aplicación en cloud. Hoy en día, estimar cuál es el precio a pagar no es sencillo si se trata de aplicaciones que requieren un elevado número de recursos de cómputo y almacenamiento. En este trabajo, se propone un método para minimizar el coste de ejecución de aplicaciones paralelas bag-of-task en un entorno de cómputo tipo cloud. Este método no sólo calcula una estimación del precio a pagar, sino que también determina qué recursos deberían ser contratados para minimizar ese precio. Una contribución importante de la solución es que considera la heterogeneidad de los proveedores cloud a nivel de catálogo de recursos, modelos y plazos de arrendamiento, opciones de pago, etc. La propuesta ha sido aplicada a un problema intenso en cómputo y ejecutado en el entorno de Amazon Elastic Compute Cloud (EC2).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Computación en la nube, minimización de costes, aplicaciones paralelas, aprovisionamiento de recursos, Amazon EC2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[332]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/015]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>What are the Three Top Challenges in Service Engineering?</title>
		<link>https://biblioteca.sistedes.es/articulo/what-are-the-three-top-challenges-in-service-engineering/</link>
		<pubDate>Tue, 01 Sep 2015 01:24:42 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=334</guid>
		<description></description>
		<content><![CDATA[This is a thought/position statement contribution for JCIS 2015 with the objective of promoting discussions on major challenges in the context of service engineering. It proposes to conduct the discussion as part of a research quality process for influencing future research and increasing impact. Gathering and processing inputs both from the JCIS/SISTEDES community and from outside to elaborate the list of top challenges is the proposed approach. This could further lead a debate on the role of JCIS/SISTEDES community for addressing them.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>334</post_id>
		<post_date><![CDATA[2015-09-01 03:24:42]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:24:42]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[what-are-the-three-top-challenges-in-service-engineering]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="scalable-computing"><![CDATA[Scalable Computing]]></category>
		<category domain="post_tag" nicename="service-engineering"><![CDATA[Service Engineering]]></category>
		<category domain="post_tag" nicename="ubiquitous-intelligence"><![CDATA[Ubiquitous Intelligence]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesus Bermejo Muñoz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[OSGi Users´ Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jesus@bermejo.link]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This is a thought/position statement contribution for JCIS 2015 with the objective of promoting discussions on major challenges in the context of service engineering. It proposes to conduct the discussion as part of a research quality process for influencing future research and increasing impact. Gathering and processing inputs both from the JCIS/SISTEDES community and from outside to elaborate the list of top challenges is the proposed approach. This could further lead a debate on the role of JCIS/SISTEDES community for addressing them.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Service Engineering, Scalable Computing, Ubiquitous Intelligence]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[335]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/014]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Definición de Mecanismos Personalizados de Monitorización de Servicios Cloud</title>
		<link>https://biblioteca.sistedes.es/articulo/definicion-de-mecanismos-personalizados-de-monitorizacion-de-servicios-cloud/</link>
		<pubDate>Tue, 01 Sep 2015 01:27:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=337</guid>
		<description></description>
		<content><![CDATA[Actualmente muchas empresas están adoptando tecnologías cloud como solución de provisión de recursos tecnológicos, para sus necesidades de infraestructura y software. Como consecuencia de esto, se hace necesario contar con mecanismos de monitorización flexibles, que permitan tanto al cliente como al proveedor, evaluar la calidad de los servicios ofertados con el fin de ofrecer una adecuada provisión de los mismos. Existen muchas soluciones en el mercado para la monitorización de servicios desplegados en la nube. Sin embargo, la mayoría provee métricas simples, que no están directamente relacionadas a los Acuerdos de Nivel de Servicios (SLA) y tampoco cuentan con mecanismos personalizados, que permitan especificar nuevas fórmulas para el cálculo de métricas complejas. En trabajos anteriores, hemos propuesto una infraestructura de monitorización de servicios de software desplegados en la nube, que utiliza modelos en tiempo de ejecución, los cuales proporcionan un alto grado de flexibilidad a la hora de realizar cambios en los requisitos no funcionales a ser monitorizados, sin necesidad de parar el sistema de monitorización o realizar cambios sustanciales en la infraestructura. En este trabajo, extendemos la infraestructura propuesta, con mecanismos personalizados de monitorización de servicios, que permite hacer uso de información provista por la plataforma cloud, de herramientas de monitorización de terceros y de cálculos de métricas programados directamente en los servicios que están siendo monitorizados. Finalmente, se muestra el uso de estos mecanismos personalizados para la monitorización de servicios desplegados en la plataforma Microsoft Azure©]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>337</post_id>
		<post_date><![CDATA[2015-09-01 03:27:48]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:27:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[definicion-de-mecanismos-personalizados-de-monitorizacion-de-servicios-cloud]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Priscila Cedillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València Camino de Vera s/n, 46022 Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[icedillo@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Jimenez-Gomez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València Camino de Vera s/n, 46022 Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jajimgme@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Silvia Abrahao]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València Camino de Vera s/n, 46022 Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sabrahao@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Emilio Insfran]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València Camino de Vera s/n, 46022 Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[einsfran@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Actualmente muchas empresas están adoptando tecnologías cloud como solución de provisión de recursos tecnológicos, para sus necesidades de infraestructura y software. Como consecuencia de esto, se hace necesario contar con mecanismos de monitorización flexibles, que permitan tanto al cliente como al proveedor, evaluar la calidad de los servicios ofertados con el fin de ofrecer una adecuada provisión de los mismos. Existen muchas soluciones en el mercado para la monitorización de servicios desplegados en la nube. Sin embargo, la mayoría provee métricas simples, que no están directamente relacionadas a los Acuerdos de Nivel de Servicios (SLA) y tampoco cuentan con mecanismos personalizados, que permitan especificar nuevas fórmulas para el cálculo de métricas complejas. En trabajos anteriores, hemos propuesto una infraestructura de monitorización de servicios de software desplegados en la nube, que utiliza modelos en tiempo de ejecución, los cuales proporcionan un alto grado de flexibilidad a la hora de realizar cambios en los requisitos no funcionales a ser monitorizados, sin necesidad de parar el sistema de monitorización o realizar cambios sustanciales en la infraestructura. En este trabajo, extendemos la infraestructura propuesta, con mecanismos personalizados de monitorización de servicios, que permite hacer uso de información provista por la plataforma cloud, de herramientas de monitorización de terceros y de cálculos de métricas programados directamente en los servicios que están siendo monitorizados. Finalmente, se muestra el uso de estos mecanismos personalizados para la monitorización de servicios desplegados en la plataforma Microsoft Azure©]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[338]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/013]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Algoritmo Híbrido de Composición Automática de Servicios con QoS</title>
		<link>https://biblioteca.sistedes.es/articulo/algoritmo-hibrido-de-composicion-automatica-de-servicios-con-qos/</link>
		<pubDate>Tue, 01 Sep 2015 01:31:13 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=340</guid>
		<description></description>
		<content><![CDATA[En este trabajo se presenta una aproximación híbrida para la composición automática de servicios mediante el emparejamiento semántico de entradas y salidas, optimizando el número de servicios y la calidad de servicio (QoS) de las composiciones. La aproximación propuesta está dividida en 4 fases: 1) generación del grafo de composición para un problema concreto de composición definido mediante entradas y salidas; 2) cálculo de la calidad de servicio óptima en el grafo; 3) optimización secuencial del grafo de composición identificando servicios equivalentes y dominados; 4) búsqueda híbrida para extraer la solución con calidad de servicio óptima y menor número de servicios. Los resultados experimentales con conjuntos de datos del Web Service Challenge 2009-2010 demuestran la efectividad de esta técnica.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>340</post_id>
		<post_date><![CDATA[2015-09-01 03:31:13]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:31:13]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[algoritmo-hibrido-de-composicion-automatica-de-servicios-con-qos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Rodriguez-Mier]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnologías de la Información (CITIUS) Universidad de Santiago de Compostela, E-15782 Spain,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pablo.rodriguez.mier@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Mucientes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnologías de la Información (CITIUS) Universidad de Santiago de Compostela, E-15782 Spain,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[manuel.mucientes@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Lama]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnologías de la Información (CITIUS) Universidad de Santiago de Compostela, E-15782 Spain,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuel.lama@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este trabajo se presenta una aproximación híbrida para la composición automática de servicios mediante el emparejamiento semántico de entradas y salidas, optimizando el número de servicios y la calidad de servicio (QoS) de las composiciones. La aproximación propuesta está dividida en 4 fases: 1) generación del grafo de composición para un problema concreto de composición definido mediante entradas y salidas; 2) cálculo de la calidad de servicio óptima en el grafo; 3) optimización secuencial del grafo de composición identificando servicios equivalentes y dominados; 4) búsqueda híbrida para extraer la solución con calidad de servicio óptima y menor número de servicios. Los resultados experimentales con conjuntos de datos del Web Service Challenge 2009-2010 demuestran la efectividad de esta técnica.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[341]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/012]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards Defining Data-Based Thresholds for Process-Related KPIs</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-defining-data-based-thresholds-for-process-related-kpis/</link>
		<pubDate>Tue, 01 Sep 2015 01:37:46 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=343</guid>
		<description></description>
		<content><![CDATA[The definition of process-related key performance indicators (KPIs) is a key part of performance measurement and one of the most challenging because of the lack of one best way to define businessapplicable KPIs that are both aligned with the strategic goals that the organisation wants to achieve and, at the same time, achievable in its context. It requires the identification of relevant threshold values able to distinguish different levels of process execution quality. However, obtaining these values remains an organization-specific task based on human abilities and no consensual technique exists. To overcome this problem, this paper introduces a methodology for threshold determination that considers not only the expert opinion but also data from real process executions.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>343</post_id>
		<post_date><![CDATA[2015-09-01 03:37:46]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:37:46]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-defining-data-based-thresholds-for-process-related-kpis]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Adela del-Río-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[adeladelrio@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Félix García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla La Mancha, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Felix.Garcia@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Francisco Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla La Mancha, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Francisco.RuizG@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The definition of process-related key performance indicators (KPIs) is a key part of performance measurement and one of the most challenging because of the lack of one best way to define businessapplicable KPIs that are both aligned with the strategic goals that the organisation wants to achieve and, at the same time, achievable in its context. It requires the identification of relevant threshold values able to distinguish different levels of process execution quality. However, obtaining these values remains an organization-specific task based on human abilities and no consensual technique exists. To overcome this problem, this paper introduces a methodology for threshold determination that considers not only the expert opinion but also data from real process executions.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[344]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/011]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards Assessing Open Source Communities’ Health using SOC Concepts</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-assessing-open-source-communities-health-using-soc-concepts/</link>
		<pubDate>Tue, 01 Sep 2015 01:43:27 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=346</guid>
		<description></description>
		<content><![CDATA[Quality of an open source software ecosystem (OSS ecosystem) is key for different ecosystem actors such as contributors or adopters. In fact, the consideration of several quality aspects(e.g., activeness, visibility, interrelatedness, etc.) as a whole may provide a measure of the healthiness of OSS ecosystems. The more health a OSS ecosystem is, the more and better contributors and adopters it will gather. Some research tools have been developed to gather specific quality information from open source community data sources. However, there exist no frameworks available that can be used to evaluate their quality as a whole in order to obtain the health of an OSS ecosystem. To assess the health of these ecosystems, we propose to adopt robust principles and methods from the Service Oriented Computing field.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>346</post_id>
		<post_date><![CDATA[2015-09-01 03:43:27]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:43:27]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-assessing-open-source-communities-health-using-soc-concepts]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Oscar Franco-Bedoya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ohernan@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Marc Oriol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[moriol@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Carlos Müller]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[cmuller@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jordi Marco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jmarco@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Pablo Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Xavier Franch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[franch@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_8]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_8]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_8]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Quality of an open source software ecosystem (OSS ecosystem) is key for different ecosystem actors such as contributors or adopters. In fact, the consideration of several quality aspects(e.g., activeness, visibility, interrelatedness, etc.) as a whole may provide a measure of the healthiness of OSS ecosystems. The more health a OSS ecosystem is, the more and better contributors and adopters it will gather. Some research tools have been developed to gather specific quality information from open source community data sources. However, there exist no frameworks available that can be used to evaluate their quality as a whole in order to obtain the health of an OSS ecosystem. To assess the health of these ecosystems, we propose to adopt robust principles and methods from the Service Oriented Computing field.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[348]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/010]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards Collaborative Human-Centric CPS</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-collaborative-human-centric-cps/</link>
		<pubDate>Tue, 01 Sep 2015 01:50:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=351</guid>
		<description></description>
		<content><![CDATA[The massive involvement of human in Cyber-Physical Systems is to a large extend managed through their smart devices. So far, these devices have been used as simple set of sensors capable of capturing the users context and uploading it to a central server. However, this architecture leads to a high consumption of the device’s resources. Consumption that is dramatically increased when similar data are used in several CPS. Nevertheless, smart devices even increasing storage and computing capacities allow them to take a more active role in these systems. This paper presents an architecture where smart devices are treated as the bridge between the physical world and the cyber space. In this architecture, smart devices store and infer the user contextual and sociological information, reacting to the state of the user or collaborating with other computational infrastructures. This architecture enables the development of human-centric CPS with clear social orientation.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>351</post_id>
		<post_date><![CDATA[2015-09-01 03:50:05]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:50:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-collaborative-human-centric-cps]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cps"><![CDATA[CPS]]></category>
		<category domain="post_tag" nicename="human-cetric-cps"><![CDATA[Human-Cetric CPS]]></category>
		<category domain="post_tag" nicename="mobile-computing"><![CDATA[mobile computing]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose Garcia-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Hernádez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juanher@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Niko Mäkitalo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Tampere University of Technology, Finland]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[niko.makitalo@cs.tut.fi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Tommi Mikkonen]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Tampere University of Technology, Finland]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[tjm@cs.tut.fi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Juan M. Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The massive involvement of human in Cyber-Physical Systems is to a large extend managed through their smart devices. So far, these devices have been used as simple set of sensors capable of capturing the users context and uploading it to a central server. However, this architecture leads to a high consumption of the device’s resources. Consumption that is dramatically increased when similar data are used in several CPS. Nevertheless, smart devices even increasing storage and computing capacities allow them to take a more active role in these systems. This paper presents an architecture where smart devices are treated as the bridge between the physical world and the cyber space. In this architecture, smart devices store and infer the user contextual and sociological information, reacting to the state of the user or collaborating with other computational infrastructures. This architecture enables the development of human-centric CPS with clear social orientation.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ CPS, Human-Cetric CPS, Mobile Computing]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[352]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/009]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Reduciendo la complejidad gráfica de indicadores de procesos de negocio usando abstracción</title>
		<link>https://biblioteca.sistedes.es/articulo/reduciendo-la-complejidad-grafica-de-indicadores-de-procesos-de-negocio-usando-abstraccion/</link>
		<pubDate>Tue, 01 Sep 2015 01:54:28 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=354</guid>
		<description></description>
		<content><![CDATA[La representación de indicadores de rendimiento sobre los procesos de negocio facilita la comprensión y definición en el cálculo y obtención de datos. Al incluir varios indicadores sobre un proceso puede ser necesario incorporar una gran cantidad de elementos de medición, generando un exceso de información y dificultando el análisis visual de los datos. En este artículo se presenta una ampliación de la notación gráfica Visual PPINOT, que permite modelar gráficamente indicadores de rendimiento sobre los procesos de negocio. A la notación se incorporan elementos de abstracción para facilitar la representación de patrones recurrentes en indicadores y para mejorar la legibilidad del diagrama del proceso. La implementación se valida utilizando el Modelo de Referencia SCOR. Se propone una clasificación de sus métricas y éstas se utilizan como referencia para estudiar las diferencias del modelado con la notación original en comparación con la notación ampliada.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>354</post_id>
		<post_date><![CDATA[2015-09-01 03:54:28]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:54:28]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[reduciendo-la-complejidad-grafica-de-indicadores-de-procesos-de-negocio-usando-abstraccion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Bedilia Estrada-Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas, Universidad de Sevilla. España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Adela del-Río-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas, Universidad de Sevilla. España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas, Universidad de Sevilla. España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas, Universidad de Sevilla. España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La representación de indicadores de rendimiento sobre los procesos de negocio facilita la comprensión y definición en el cálculo y obtención de datos. Al incluir varios indicadores sobre un proceso puede ser necesario incorporar una gran cantidad de elementos de medición, generando un exceso de información y dificultando el análisis visual de los datos. En este artículo se presenta una ampliación de la notación gráfica Visual PPINOT, que permite modelar gráficamente indicadores de rendimiento sobre los procesos de negocio. A la notación se incorporan elementos de abstracción para facilitar la representación de patrones recurrentes en indicadores y para mejorar la legibilidad del diagrama del proceso. La implementación se valida utilizando el Modelo de Referencia SCOR. Se propone una clasificación de sus métricas y éstas se utilizan como referencia para estudiar las diferencias del modelado con la notación original en comparación con la notación ampliada.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[355]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/008]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>IoT Compositions by and for the Crowd</title>
		<link>https://biblioteca.sistedes.es/articulo/iot-compositions-by-and-for-the-crowd/</link>
		<pubDate>Tue, 01 Sep 2015 01:57:56 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=357</guid>
		<description></description>
		<content><![CDATA[<a href="http://biblioteca.sistedes.es/wp-content/uploads/2016/02/JCIS_2015_submission_10.pdf" rel="">JCIS_2015_submission_10</a>The Internet of Things (IoT) offers a new eco-system of heterogeneous and distributed services that is available anytime and anywhere and that can be potentially accessed by any properly connected device. However, these available services are usually consumed in isolation, missing the potential that their combined usage can bring as new added-value services. In addition, the massive end-user adoption and usage of smartphones together with their powerful capabilities turn this type of devices into a promising platform to develop and execute these added-value services compositions. Moreover, end-users are nowadays getting more and more familiar with technology, fact that allows them to participate more actively in the development of new types of applications. However, this will not happen until we provide end-users with more powerful and easy-to-use tools. To this end, this paper presents an architectural solution to allow end-users building IoT services compositions by just focusing on domain-logic issues.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>357</post_id>
		<post_date><![CDATA[2015-09-01 03:57:56]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:57:56]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[iot-compositions-by-and-for-the-crowd]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="end-user-development"><![CDATA[End-user Development]]></category>
		<category domain="post_tag" nicename="iot"><![CDATA[IoT]]></category>
		<category domain="post_tag" nicename="service-compositions"><![CDATA[Service Compositions]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ignacio Mansanet]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia, Spain. Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[imansanet@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Victoria Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia, Spain. Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[vtorres@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pedro Valderas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia, Spain. Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pvalderas@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia, Spain. Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[pele@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The Internet of Things (IoT) offers a new eco-system of heterogeneous and distributed services that is available anytime and anywhere and that can be potentially accessed by any properly connected device. However, these available services are usually consumed in isolation, missing the potential that their combined usage can bring as new added-value services. In addition, the massive end-user adoption and usage of smartphones together with their powerful capabilities turn this type of devices into a promising platform to develop and execute these added-value services compositions. Moreover, end-users are nowadays getting more and more familiar with technology, fact that allows them to participate more actively in the development of new types of applications. However, this will not happen until we provide end-users with more powerful and easy-to-use tools. To this end, this paper presents an architectural solution to allow end-users building IoT services compositions by just focusing on domain-logic issues.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Service Compositions, IoT, End-user Development]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[671]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/007]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>On the Calculation of Process Performance Indicators</title>
		<link>https://biblioteca.sistedes.es/articulo/on-the-calculation-of-process-performance-indicators/</link>
		<pubDate>Tue, 01 Sep 2015 02:02:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=360</guid>
		<description></description>
		<content><![CDATA[Performance calculation is a key factor to match corporate goals between different partners in process execution. However, although, a number of standards protocols and languages have recently emerged to support business process services in the industry, there is no standard related to monitoring of performance indicators over processes in these systems. As a consequence, BPMS use propietary languages to define measures and calculate them over process execution. In this paper, we describe two different approaches to compute performance mea- sures on business process decoupled from specific Business Process Man- agement System (BPMS) with an existing BPMS-independent language (PPINOT) to define indicators over business processes. Finally, some optimization techniques are described to increase calculation performance based on computing aggregated measures incrementally.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>360</post_id>
		<post_date><![CDATA[2015-09-01 04:02:06]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 02:02:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[on-the-calculation-of-process-performance-indicators]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="business-process-management"><![CDATA[Business Process Management]]></category>
		<category domain="post_tag" nicename="complex-event-processing"><![CDATA[Complex Event Processing]]></category>
		<category domain="post_tag" nicename="key-performance-indicators"><![CDATA[Key Performance Indicators]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Manuel Gutiérrez–Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[School of Computer Engineering 6 University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[amgutierrez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[School of Computer Engineering 6 University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Adela del–Río–Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[School of Computer Engineering 6 University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[adeladelrio@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz–Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[School of Computer Engineering 6 University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Performance calculation is a key factor to match corporate goals between different partners in process execution. However, although, a number of standards protocols and languages have recently emerged to support business process services in the industry, there is no standard related to monitoring of performance indicators over processes in these systems. As a consequence, BPMS use propietary languages to define measures and calculate them over process execution. In this paper, we describe two different approaches to compute performance mea- sures on business process decoupled from specific Business Process Man- agement System (BPMS) with an existing BPMS-independent language (PPINOT) to define indicators over business processes. Finally, some optimization techniques are described to increase calculation performance based on computing aggregated measures incrementally.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Business Process Management, Key Performance Indicators, Complex Event Processing]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[361]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/006]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards SLA-Driven API Gateways</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-sla-driven-api-gateways/</link>
		<pubDate>Tue, 01 Sep 2015 02:04:59 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=363</guid>
		<description></description>
		<content><![CDATA[As APIs are becoming popular to build Service-Based Applications (SBA), API Gateways are being increasingly used to facilitate API features management. They offer API management functionalities such as pricing plans support, user authentication, API versioning or response caching. Some parts of the information that an API Gateway needs are already included into a Service Level Agreement (SLA), that providers use to describe the rights and the obligations of involved parties in the service. Unfortunately, current API Gateways do not use any SLA representation model nor SLA underlying technology, thereby missing potential opportunities. In this paper we analyze the state of the art to justify the current situation and we identify some research challenges so as to achieve SLA-Driven API Gateways.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>363</post_id>
		<post_date><![CDATA[2015-09-01 04:04:59]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 02:04:59]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-sla-driven-api-gateways]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Gámez-Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[agamez2@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Fernández-Montes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[As APIs are becoming popular to build Service-Based Applications (SBA), API Gateways are being increasingly used to facilitate API features management. They offer API management functionalities such as pricing plans support, user authentication, API versioning or response caching. Some parts of the information that an API Gateway needs are already included into a Service Level Agreement (SLA), that providers use to describe the rights and the obligations of involved parties in the service. Unfortunately, current API Gateways do not use any SLA representation model nor SLA underlying technology, thereby missing potential opportunities. In this paper we analyze the state of the art to justify the current situation and we identify some research challenges so as to achieve SLA-Driven API Gateways.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[364]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards a Comprehensive Purchasing Model for Cloud Services</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-a-comprehensive-purchasing-model-for-cloud-services/</link>
		<pubDate>Tue, 01 Sep 2015 02:08:12 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=366</guid>
		<description></description>
		<content><![CDATA[The Cloud Service Market has evolved into a complex landscape that challenges the decision making of users as they develop their purchasing process. In particular, we explore the case of cloud infrastructure (IaaS) providers as an example of heterogeneous variety of purchasing options and discounts; this variability represents an important drawback during the decision making process where there is a need to compare and select the best option. In this work, we define a common model to describe purchasing models from different providers taking into account such heterogeneity. This purchasing model represents a first step towards the automated support of decision making problems during the purchasing process. In order to illustrate our approach we apply the model in a real case study of IaaS purchasing.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>366</post_id>
		<post_date><![CDATA[2015-09-01 04:08:12]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 02:08:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-a-comprehensive-purchasing-model-for-cloud-services]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cloud-services"><![CDATA[Cloud Services]]></category>
		<category domain="post_tag" nicename="decision-making"><![CDATA[Decision Making]]></category>
		<category domain="post_tag" nicename="purchasing-options"><![CDATA[Purchasing Options]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Octavio Martín-Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática – Universidad de Sevilla 41012 Sevilla, España – Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[omartindiaz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática – Universidad de Sevilla 41012 Sevilla, España – Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José María García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática – Universidad de Sevilla 41012 Sevilla, España – Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[josemgarcia@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática – Universidad de Sevilla 41012 Sevilla, España – Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The Cloud Service Market has evolved into a complex landscape that challenges the decision making of users as they develop their purchasing process. In particular, we explore the case of cloud infrastructure (IaaS) providers as an example of heterogeneous variety of purchasing options and discounts; this variability represents an important drawback during the decision making process where there is a need to compare and select the best option. In this work, we define a common model to describe purchasing models from different providers taking into account such heterogeneity. This purchasing model represents a first step towards the automated support of decision making problems during the purchasing process. In order to illustrate our approach we apply the model in a real case study of IaaS purchasing.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Cloud Services, Purchasing Options, Decision Making]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[367]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Perfil UML para el Modelado de la Integración de Servicios Cloud en Procesos de Desarrollo Incremental</title>
		<link>https://biblioteca.sistedes.es/articulo/perfil-uml-para-el-modelado-de-la-integracion-de-servicios-cloud-en-procesos-de-desarrollo-incremental/</link>
		<pubDate>Tue, 01 Sep 2015 02:10:17 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=369</guid>
		<description></description>
		<content><![CDATA[En procesos de desarrollo incremental de servicios cloud, la integración de nuevos servicios puede requerir la reconfiguración de la arquitectura actual de la aplicación, siendo importante que dicha reconfiguración sea dinámica para evitar interrupciones en el sistema. En este artículo presentamos un perfil de UML para especificar cómo nuevos servicios deben integrarse en la arquitectura de la aplicación cloud. Esta información de integración es utilizada para generar una nueva orquestación de servicios y los scripts necesarios que actualizan los enlaces entre los nuevos servicios, produciendo por tanto una reconfiguración arquitectónica en tiempo de ejecución. Esta propuesta se ilustra con un caso de estudio práctico en la plataforma Windows Azure© utilizando WCF Workflow para la orquestación de servicios y archivos XML Document Transformation para actualizar la configuración de enlaces de los servicios involucrados.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>369</post_id>
		<post_date><![CDATA[2015-09-01 04:10:17]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 02:10:17]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[perfil-uml-para-el-modelado-de-la-integracion-de-servicios-cloud-en-procesos-de-desarrollo-incremental]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="arquitectura-de-software"><![CDATA[arquitectura de software]]></category>
		<category domain="post_tag" nicename="computacion-cloud"><![CDATA[computación cloud]]></category>
		<category domain="post_tag" nicename="perfil-uml"><![CDATA[perfil UML]]></category>
		<category domain="post_tag" nicename="reconfiguracion-dinamica"><![CDATA[reconfiguración dinámica]]></category>
		<category domain="post_tag" nicename="soaml"><![CDATA[SoaML]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel Zuñiga-Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universitat Politècnica de València Camino de Vera, s/n, 46022, Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mzuniga@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Silvia Abrahao]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universitat Politècnica de València Camino de Vera, s/n, 46022, Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sabrahao@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Emilio Insfran]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universitat Politècnica de València Camino de Vera, s/n, 46022, Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[einsfran@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En procesos de desarrollo incremental de servicios cloud, la integración de nuevos servicios puede requerir la reconfiguración de la arquitectura actual de la aplicación, siendo importante que dicha reconfiguración sea dinámica para evitar interrupciones en el sistema. En este artículo presentamos un perfil de UML para especificar cómo nuevos servicios deben integrarse en la arquitectura de la aplicación cloud. Esta información de integración es utilizada para generar una nueva orquestación de servicios y los scripts necesarios que actualizan los enlaces entre los nuevos servicios, produciendo por tanto una reconfiguración arquitectónica en tiempo de ejecución. Esta propuesta se ilustra con un caso de estudio práctico en la plataforma Windows Azure© utilizando WCF Workflow para la orquestación de servicios y archivos XML Document Transformation para actualizar la configuración de enlaces de los servicios involucrados.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[arquitectura de software, reconfiguración dinámica, computación cloud, SoaML, perfil UML]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[370]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/003]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SafeWalks: aplicación móvil de supervisión de pacientes de Alzheimer</title>
		<link>https://biblioteca.sistedes.es/articulo/safewalks-aplicacion-movil-de-supervision-de-pacientes-de-alzheimer/</link>
		<pubDate>Tue, 01 Sep 2015 02:12:59 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=372</guid>
		<description></description>
		<content><![CDATA[El principal objetivo de Internet of Things (IoT) es integrar las tecnologías informáticas en el quehacer cotidiano de las personas, facilitando su interacción con un entorno de dispositivos interconectados, pero el estado actual del arte hace que dicha interacción esté aún lejos de resultar trivial, precisando de continua intervención del usuario. El modelo People as a Service (PeaaS) pretende facilitar estas tareas por medio del uso del teléfono móvil como interfaz del usuario con IoT. PeaaS permite elaborar un perfil sociológico del usuario, que puede ser explotado por el mismo y servido a terceros de forma controlada. En este trabajo presentamos una aplicación móvil para la supervisión de personas afectadas de alzheimer como prueba de concepto del modelo PeaaS, teniendo como resultado una funcionalidad que va mucho más allá de la ofrecida por otros productos similares en este campo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>372</post_id>
		<post_date><![CDATA[2015-09-01 04:12:59]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 02:12:59]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[safewalks-aplicacion-movil-de-supervision-de-pacientes-de-alzheimer]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Pérez Lozano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pperezlo@alumnos.unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alejandro Pérez Vereda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[apvereda@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El principal objetivo de Internet of Things (IoT) es integrar las tecnologías informáticas en el quehacer cotidiano de las personas, facilitando su interacción con un entorno de dispositivos interconectados, pero el estado actual del arte hace que dicha interacción esté aún lejos de resultar trivial, precisando de continua intervención del usuario. El modelo People as a Service (PeaaS) pretende facilitar estas tareas por medio del uso del teléfono móvil como interfaz del usuario con IoT. PeaaS permite elaborar un perfil sociológico del usuario, que puede ser explotado por el mismo y servido a terceros de forma controlada. En este trabajo presentamos una aplicación móvil para la supervisión de personas afectadas de alzheimer como prueba de concepto del modelo PeaaS, teniendo como resultado una funcionalidad que va mucho más allá de la ofrecida por otros productos similares en este campo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[373]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/002]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Propuesta de una Arquitectura de Dispositivos como Servicios con Procesamiento de Eventos</title>
		<link>https://biblioteca.sistedes.es/articulo/propuesta-de-una-arquitectura-de-dispositivos-como-servicios-con-procesamiento-de-eventos/</link>
		<pubDate>Tue, 01 Sep 2015 02:17:20 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=375</guid>
		<description></description>
		<content><![CDATA[Internet de las Cosas representa un paradigma en el que los objetos que nos rodean están interconectados. En esta visión, existen problemas como la detección de dispositivos heterogéneos, la inexistencia de estándares para interoperar con los dispositivos, o la eficiencia en la obtención de la información. Para la detección e interacción, existen estándares e iniciativas que exponen los dispositivos y las cosas como servicios, siguiendo un enfoque de arquitecturas orientadas a servicios. Para procesar la información generada, además del análisis de datos, es fundamental reaccionar ante cambios en los dispositivos, estableciendo pautas de comportamiento. Las técnicas de procesamiento de eventos complejos junto con las arquitecturas dirigidas por eventos permiten dise˜nar sistemas reactivos y desacoplados, analizando los cambios en el entorno y adaptando su comportamiento en base a patrones de eventos. Actualmente, la mayoría de las soluciones que permiten interactuar con dispositivos heterogéneos son complejas y requieren conocimiento avanzado. En este trabajo, proponemos una arquitectura de dispositivos orientada a servicios y dirigida por eventos, exponiendo los dispositivos como servicios para unificar su manejo, que interactúan con el entorno mediante eventos que son procesados, y dotando al ecosistema de la capacidad de comportarse de forma autónoma y reactiva.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>375</post_id>
		<post_date><![CDATA[2015-09-01 04:17:20]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 02:17:20]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[propuesta-de-una-arquitectura-de-dispositivos-como-servicios-con-procesamiento-de-eventos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cep"><![CDATA[CEP]]></category>
		<category domain="post_tag" nicename="daas"><![CDATA[DaaS]]></category>
		<category domain="post_tag" nicename="dpws"><![CDATA[DPWS]]></category>
		<category domain="post_tag" nicename="iot"><![CDATA[IoT]]></category>
		<category domain="post_tag" nicename="soa-2-0"><![CDATA[SOA 2.0]]></category>
		<category domain="post_tag" nicename="soda"><![CDATA[SODA]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Dpto. Ingeniería Informática, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Cubo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dpto. Lenguajes y Ciencias de la Computación, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cubo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Adrián Nieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dpto. Lenguajes y Ciencias de la Computación, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[adrian@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Dpto. Ingeniería Informática, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Ernesto Pimentel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dpto. Lenguajes y Ciencias de la Computación, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[ernesto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Internet de las Cosas representa un paradigma en el que los objetos que nos rodean están interconectados. En esta visión, existen problemas como la detección de dispositivos heterogéneos, la inexistencia de estándares para interoperar con los dispositivos, o la eficiencia en la obtención de la información. Para la detección e interacción, existen estándares e iniciativas que exponen los dispositivos y las cosas como servicios, siguiendo un enfoque de arquitecturas orientadas a servicios. Para procesar la información generada, además del análisis de datos, es fundamental reaccionar ante cambios en los dispositivos, estableciendo pautas de comportamiento. Las técnicas de procesamiento de eventos complejos junto con las arquitecturas dirigidas por eventos permiten dise˜nar sistemas reactivos y desacoplados, analizando los cambios en el entorno y adaptando su comportamiento en base a patrones de eventos. Actualmente, la mayoría de las soluciones que permiten interactuar con dispositivos heterogéneos son complejas y requieren conocimiento avanzado. En este trabajo, proponemos una arquitectura de dispositivos orientada a servicios y dirigida por eventos, exponiendo los dispositivos como servicios para unificar su manejo, que interactúan con el entorno mediante eventos que son procesados, y dotando al ecosistema de la capacidad de comportarse de forma autónoma y reactiva.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[IoT, DaaS, CEP, SOA 2.0, SODA, DPWS]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[376]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/001]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Restricted Predicates for Hypothetical Datalog</title>
		<link>https://biblioteca.sistedes.es/articulo/restricted-predicates-for-hypothetical-datalog/</link>
		<pubDate>Fri, 11 Sep 2015 02:09:46 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=492</guid>
		<description></description>
		<content><![CDATA[Hypothetical Datalog is based on an intuitionistic semantics rather than on a classical logic semantics, and embedded implications are allowed in rule bodies. While the usual implication (i.e., the neck of a Horn clause) stands for inferring facts, an embedded implication plays the role of assuming its premise for deriving its consequence. A former work introduced both a formal framework and a goal-oriented tabled implementation, allowing negation in rule bodies. While in that work positive assumptions for both facts and rules can occur in the premise, negative assumptions are not allowed. In this work, we cover this subject by introducing a new concept: a restricted predicate, which allows negative assumptions by pruning the usual semantics of a predicate. This new setting has been implemented in the deductive system DES.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>492</post_id>
		<post_date><![CDATA[2015-09-11 04:09:46]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:09:46]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[restricted-predicates-for-hypothetical-datalog]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[493]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Hypothetical Datalog is based on an intuitionistic semantics rather than on a classical logic semantics, and embedded implications are allowed in rule bodies. While the usual implication (i.e., the neck of a Horn clause) stands for inferring facts, an embedded implication plays the role of assuming its premise for deriving its consequence. A former work introduced both a formal framework and a goal-oriented tabled implementation, allowing negation in rule bodies. While in that work positive assumptions for both facts and rules can occur in the premise, negative assumptions are not allowed. In this work, we cover this subject by introducing a new concept: a restricted predicate, which allows negative assumptions by pruning the usual semantics of a predicate. This new setting has been implemented in the deductive system DES.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Logic and Learning on Databases ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Fernando Sáenz-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fernan@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/021]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Declarative Semantics for a Fuzzy Logic Language Managing Similarities and Truth Degrees</title>
		<link>https://biblioteca.sistedes.es/articulo/a-declarative-semantics-for-a-fuzzy-logic-language-managing-similarities-and-truth-degrees/</link>
		<pubDate>Fri, 11 Sep 2015 02:18:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=495</guid>
		<description></description>
		<content><![CDATA[This work proposes a declarative semantics based on a fuzzy variant of the classical notion of least Herbrand model for the so-called FASILL language (acronym of “Fuzzy Aggregators and Similarity Into a Logic Language”) which has being recently designed and implemented in our research group for coping with implicit/explicit truth degree annotations, a great variety of connectives and unification by similarity.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>495</post_id>
		<post_date><![CDATA[2015-09-11 04:18:54]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:18:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-declarative-semantics-for-a-fuzzy-logic-language-managing-similarities-and-truth-degrees]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="fuzzy-logic-programming"><![CDATA[Fuzzy Logic Programming]]></category>
		<category domain="post_tag" nicename="herbrand-model"><![CDATA[Herbrand Model]]></category>
		<category domain="post_tag" nicename="similarity-relations"><![CDATA[Similarity Relations]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[496]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This work proposes a declarative semantics based on a fuzzy variant of the classical notion of least Herbrand model for the so-called FASILL language (acronym of “Fuzzy Aggregators and Similarity Into a Logic Language”) which has being recently designed and implemented in our research group for coping with implicit/explicit truth degree annotations, a great variety of connectives and unification by similarity.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Fuzzy Logic Programming, Similarity Relations, Herbrand Model]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pascual Julián-Iranzo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Technologies and Information Systems University of Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Pascual.Julian@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ginés Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computing Systems University of Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Gines.Moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jaime Penabad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Mathematics University of Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Jaime.Penabad@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Carlos Vázquez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computing Systems University of Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Carlos.Vazquez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/013]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A liberal type system for functional logic programs</title>
		<link>https://biblioteca.sistedes.es/articulo/a-liberal-type-system-for-functional-logic-programs/</link>
		<pubDate>Fri, 11 Sep 2015 02:23:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=499</guid>
		<description></description>
		<content><![CDATA[We propose a new type system for functional logic programming which is more liberal than the classical DamasMilner usually adopted, but it is also restrictive enough to ensure type soundness. Starting from DamasMilner typing of expressions, we propose a new notion of well-typed program that adds support for type-indexed functions, a particular form of existential types, opaque higherorder patterns and generic functions as shown by an extensive collection of examples that illustrate the possibilities of our proposal. In the negative side, the types of functions must be declared, and therefore types are checked but not inferred. Another consequence is that parametricity is lost, although the impact of this flaw is limited as free theorems were already compromised in functional logic programming because of non-determinism.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>499</post_id>
		<post_date><![CDATA[2015-09-11 04:23:51]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:23:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-liberal-type-system-for-functional-logic-programs]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[500]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We propose a new type system for functional logic programming which is more liberal than the classical DamasMilner usually adopted, but it is also restrictive enough to ensure type soundness. Starting from DamasMilner typing of expressions, we propose a new notion of well-typed program that adds support for type-indexed functions, a particular form of existential types, opaque higherorder patterns and generic functions as shown by an extensive collection of examples that illustrate the possibilities of our proposal. In the negative side, the types of functions must be declared, and therefore types are checked but not inferred. Another consequence is that parametricity is lost, although the impact of this flaw is limited as free theorems were already compromised in functional logic programming because of non-determinism.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco J. López-Fraguas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DSIC-UCM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fraguas@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Enrique Martin-Martin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[DSIC-UCM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[emartinm@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Rodríguez-Hortalá]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DSIC-UCM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanrh@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/024]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>HR-SQL: An SQL Database System with Extended Recursion and Hypothetical Reasoning</title>
		<link>https://biblioteca.sistedes.es/articulo/hr-sql-an-sql-database-system-with-extended-recursion-and-hypothetical-reasoning/</link>
		<pubDate>Fri, 11 Sep 2015 02:27:25 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=502</guid>
		<description></description>
		<content><![CDATA[In a former work we described the system and language R-SQL that overcomes some limitations of recursion of the relational database language SQL. Such limitations are non-linearity, mutual recursion, and some combinations of negation with recursion. In addition, R-SQL improved termination properties of recursive definitions. Next, this language was extended to include a restricted form of hypothetical relations and queries using assumptions, obtaining the language HR-SQL, and a preliminary implementation was developed for it. Here, we develop a new system HR-SQL from scratch and enhance the former system in several areas. First, hypothetical reasoning is fully integrated with recursive definitions. Second, the Python script generated by the system for computing the extension (materialization) of a database is now targeted to several state-of-the-art relational database systems. Third, the system has been interfaced to the integrated development environment ACIDE, allowing both a more friendly user interaction and a graphical view of the dependency graph that shows dependencies between relations. Fourth, being developed in Prolog, we have targeted it to both SICStus Prolog and SWI-Prolog, also providing standalone executables. Finally, the system has been extended with a bundle of commands, highly improving its capabilities with respect to the former system.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>502</post_id>
		<post_date><![CDATA[2015-09-11 04:27:25]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:27:25]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hr-sql-an-sql-database-system-with-extended-recursion-and-hypothetical-reasoning]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[503]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In a former work we described the system and language R-SQL that overcomes some limitations of recursion of the relational database language SQL. Such limitations are non-linearity, mutual recursion, and some combinations of negation with recursion. In addition, R-SQL improved termination properties of recursive definitions. Next, this language was extended to include a restricted form of hypothetical relations and queries using assumptions, obtaining the language HR-SQL, and a preliminary implementation was developed for it. Here, we develop a new system HR-SQL from scratch and enhance the former system in several areas. First, hypothetical reasoning is fully integrated with recursive definitions. Second, the Python script generated by the system for computing the extension (materialization) of a database is now targeted to several state-of-the-art relational database systems. Third, the system has been interfaced to the integrated development environment ACIDE, allowing both a more friendly user interaction and a graphical view of the dependency graph that shows dependencies between relations. Fourth, being developed in Prolog, we have targeted it to both SICStus Prolog and SWI-Prolog, also providing standalone executables. Finally, the system has been extended with a bundle of commands, highly improving its capabilities with respect to the former system.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Susana Nieva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[nieva@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando Sáenz-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fernan@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jaime Sánchez-Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jaime@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/020]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Haskell Implementation of a Rule-Based Program Transformation for C Programs</title>
		<link>https://biblioteca.sistedes.es/articulo/a-haskell-implementation-of-a-rule-based-program-transformation-for-c-programs/</link>
		<pubDate>Fri, 11 Sep 2015 02:30:56 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=505</guid>
		<description></description>
		<content><![CDATA[Obtaining good performance when programming heterogeneous computing platforms poses significant challenges for the programmer. We present a program transformation environment, implemented in Haskell, where architecture-agnostic scientific C code is transformed into a functionally equivalent one better suited for a given platform. The transformation rules are formalized in a domain-specific language (STML) that takes care of the syntactic and semantic conditions required to apply a given transformation. STML rules are compiled into Haskell function definitions that operate at AST level. Program properties, to be matched with rule conditions, can be automatically inferred or, alternatively, stated as annotations in the source code. Early experimental results are described.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>505</post_id>
		<post_date><![CDATA[2015-09-11 04:30:56]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:30:56]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-haskell-implementation-of-a-rule-based-program-transformation-for-c-programs]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[506]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Obtaining good performance when programming heterogeneous computing platforms poses significant challenges for the programmer. We present a program transformation environment, implemented in Haskell, where architecture-agnostic scientific C code is transformed into a functionally equivalent one better suited for a given platform. The transformation rules are formalized in a domain-specific language (STML) that takes care of the syntactic and semantic conditions required to apply a given transformation. STML rules are compiled into Haskell function definitions that operate at AST level. Program properties, to be matched with rule conditions, can be automatically inferred or, alternatively, stated as annotations in the source code. Early experimental results are described.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Tamarit]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[salvador.tamarit@upm.e]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Guillermo Vigueras]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[guillermo.vigueras@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Carro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuel.carro@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Julio Mariño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[julio.marino@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/006]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Declarative Debugger for Concurrent Erlang Programs</title>
		<link>https://biblioteca.sistedes.es/articulo/a-declarative-debugger-for-concurrent-erlang-programs/</link>
		<pubDate>Fri, 11 Sep 2015 02:35:03 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=508</guid>
		<description></description>
		<content><![CDATA[Erlang is a concurrent language with features such as actor model concurrency, no shared memory, message passing communication, high scalability and availability. However, the development of concurrent programs is a complex and error prone task. In this paper we present a declarative debugging approach for concurrent Erlang programs. Our debugger asks questions about the validity of transitions between the different points of the program that involve message passing and/or process creation. The answers, which represent the intended behavior of the program, are compared with the transitions obtained in an actual execution of the program. The differences allow us to detect program errors and to point out the pieces of source code responsible for the bugs. In order to represent the computations we present a semantic calculus for concurrent Core Erlang programs. The debugger uses the proof trees in this calculus as debugging trees used for selecting the questions asked to the user. The relation between the debugging trees and the semantic calculus allows us to establish the soundness of the approach. The theoretical ideas have been implemented in a debugger prototype.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>508</post_id>
		<post_date><![CDATA[2015-09-11 04:35:03]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:35:03]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-declarative-debugger-for-concurrent-erlang-programs]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="concurrency"><![CDATA[Concurrency]]></category>
		<category domain="post_tag" nicename="declarative-debugging"><![CDATA[Declarative Debugging]]></category>
		<category domain="post_tag" nicename="erlang"><![CDATA[Erlang]]></category>
		<category domain="post_tag" nicename="semantics"><![CDATA[Semantics]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[509]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Erlang is a concurrent language with features such as actor model concurrency, no shared memory, message passing communication, high scalability and availability. However, the development of concurrent programs is a complex and error prone task. In this paper we present a declarative debugging approach for concurrent Erlang programs. Our debugger asks questions about the validity of transitions between the different points of the program that involve message passing and/or process creation. The answers, which represent the intended behavior of the program, are compared with the transitions obtained in an actual execution of the program. The differences allow us to detect program errors and to point out the pieces of source code responsible for the bugs. In order to represent the computations we present a semantic calculus for concurrent Core Erlang programs. The debugger uses the proof trees in this calculus as debugging trees used for selecting the questions asked to the user. The relation between the debugging trees and the semantic calculus allows us to establish the soundness of the approach. The theoretical ideas have been implemented in a debugger prototype. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Concurrency, Declarative Debugging, Erlang, Semantics]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[R. Caballero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rafacr@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[E. Martin-Martin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[emartinm@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[A. Riesco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ariesco@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Salvador Tamarit]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[stamarit@babel.ls.fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/016]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Constraint Programming Meets SQL</title>
		<link>https://biblioteca.sistedes.es/articulo/constraint-programming-meets-sql/</link>
		<pubDate>Fri, 11 Sep 2015 02:38:04 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=511</guid>
		<description></description>
		<content><![CDATA[We present a proposal for introducing SQL tuples into the modeling programming language MINIZINC. The domain of the new decision variables is defined by arbitrary relational database tables indicated by the user. The new setting increases the expressiveness of MINIZINC, allowing the modeler to mix the usual finite domains already existing in the language with string constraints typical from SQL such as concat, substr, or like. In order to obtain the solutions of these combined models, we first replace the atomic constraints involving strings by boolean variables. The result is a standard MINIZINC model, which can be solved by any off-the-shelf solver. Then, each individual solution is applied to the remainder string constraints, which are then solved using an SQL query. We discuss how both languages, MINIZINC and SQL, benefit from this combination.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>511</post_id>
		<post_date><![CDATA[2015-09-11 04:38:04]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:38:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[constraint-programming-meets-sql]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[512]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We present a proposal for introducing SQL tuples into the modeling programming language MINIZINC. The domain of the new decision variables is defined by arbitrary relational database tables indicated by the user. The new setting increases the expressiveness of MINIZINC, allowing the modeler to mix the usual finite domains already existing in the language with string constraints typical from SQL such as concat, substr, or like. In order to obtain the solutions of these combined models, we first replace the atomic constraints involving strings by boolean variables. The result is a standard MINIZINC model, which can be solved by any off-the-shelf solver. Then, each individual solution is applied to the remainder string constraints, which are then solved using an SQL query. We discuss how both languages, MINIZINC and SQL, benefit from this combination.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rafael Caballero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University Complutense de Madrid Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rafacr@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carlo Ieva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Simula Research Laboratory Oslo, Norway]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[carlo@simula.no]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/018]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Proving Continuity of Coinductive Global Bisimulation Distances: A Never Ending Story</title>
		<link>https://biblioteca.sistedes.es/articulo/proving-continuity-of-coinductive-global-bisimulation-distances-a-never-ending-story/</link>
		<pubDate>Fri, 11 Sep 2015 02:53:40 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=514</guid>
		<description></description>
		<content><![CDATA[We have developed a global approach to define bisimulation distances which goes somehow further away than the bisimulation distances based on the bisimulation game, previously proposed by some other authors. Our proposal is based on the cost of transformations: how much we need to modify one of the compared processes to obtain the other. Our original definition only covered finite processes, but a coinductive approach extends it to cover infinite but finitary trees. We have shown many interesting properties of our distances, and we wanted to prove their continuity with respect to projections, bur unfortunately we have not been able to accomplish that task. However, we have obtained several partial results that we now present in this paper.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>514</post_id>
		<post_date><![CDATA[2015-09-11 04:53:40]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:53:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[proving-continuity-of-coinductive-global-bisimulation-distances-a-never-ending-story]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[515]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We have developed a global approach to define bisimulation distances which goes somehow further away than the bisimulation distances based on the bisimulation game, previously proposed by some other authors. Our proposal is based on the cost of transformations: how much we need to modify one of the compared processes to obtain the other. Our original definition only covered finite processes, but a coinductive approach extends it to cover infinite but finitary trees. We have shown many interesting properties of our distances, and we wanted to prove their continuity with respect to projections, bur unfortunately we have not been able to accomplish that task. However, we have obtained several partial results that we now present in this paper.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Romero-Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ Facultad CC. Matematicas, Universidad Complutense de Madrid Madrid, Spain. Departamento de Sistemas Informaticos y Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[dromeroh@pdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David de Frutos-Escrig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ Facultad CC. Matematicas, Universidad Complutense de Madrid Madrid, Spain. Departamento de Sistemas Informaticos y Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[defrutos@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Dario Della Monica]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ ICE-TCS, School of Computer Science, Reykjavik University, Reykjavik, Iceland]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[dariodm@ru.is]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/012]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Generic Intermediate Representation for Verification Condition Generation, Work in Progress</title>
		<link>https://biblioteca.sistedes.es/articulo/a-generic-intermediate-representation-for-verification-condition-generation-work-in-progress/</link>
		<pubDate>Fri, 11 Sep 2015 02:56:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=517</guid>
		<description></description>
		<content><![CDATA[As part of a platform for computer-assisted verification, we present an intermediate representation of programs that is both language independent and appropriate for the generation of verification conditions. We show how many imperative and functional languages can be translated to this generic internal representation, and how the generated conditions faithfully reflect the semantics of the original program. At this representation level, loop invariants and preconditions of recursive functions belonging to the original program are represented by assertions placed at certain edges of a directed graph. The paper defines the generic representation, sketches the transformation algorithms, and describes how the places where the invariants should be placed are computed. Assuming that, either manually or assisted by the platform, the invariants have been settled, it is shown how the verification conditions are generated. A running example illustrates the process.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>517</post_id>
		<post_date><![CDATA[2015-09-11 04:56:50]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:56:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-generic-intermediate-representation-for-verification-condition-generation-work-in-progress]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="intermediate-representation"><![CDATA[intermediate representation]]></category>
		<category domain="post_tag" nicename="program-transformation"><![CDATA[program transformation.]]></category>
		<category domain="post_tag" nicename="verification-conditions"><![CDATA[verification conditions]]></category>
		<category domain="post_tag" nicename="verification-platforms"><![CDATA[verification platforms]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[518]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[As part of a platform for computer-assisted verification, we present an intermediate representation of programs that is both language independent and appropriate for the generation of verification conditions. We show how many imperative and functional languages can be translated to this generic internal representation, and how the generated conditions faithfully reflect the semantics of the original program. At this representation level, loop invariants and preconditions of recursive functions belonging to the original program are represented by assertions placed at certain edges of a directed graph. The paper defines the generic representation, sketches the transformation algorithms, and describes how the places where the invariants should be placed are computed. Assuming that, either manually or assisted by the platform, the invariants have been settled, it is shown how the verification conditions are generated. A running example illustrates the process.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[verification platforms, intermediate representation, verification conditions, program transformation.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel Montenegro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[montenegro@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Ricardo Peña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ricardo@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jaime Sánchez-Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jaime@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/027]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Productivity of rewrite systems without transformations</title>
		<link>https://biblioteca.sistedes.es/articulo/productivity-of-rewrite-systems-without-transformations/</link>
		<pubDate>Fri, 11 Sep 2015 02:59:43 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=522</guid>
		<description></description>
		<content><![CDATA[Termination of programs, i.e., the absence of infinite computations, ensures the existence of normal forms for all initial expressions, thus providing an essential ingredient for the definition of a normalization semantics for functional programs. In lazy functional languages, though, infinite data structures are often delivered as the outcome of computations. For instance, the list of all prime numbers can be returned as a neverending stream of numerical expressions or data structures. If such streams are allowed, requiring termination is hopeless. In this setting, the notion of productivity can be used to provide an account of computations with infinite data structures, as it “captures the idea of computability, of progress of infinite-list programs” (B.A. Sijtsma, On the Productivity of Recursive List Definitions, ACM Transactions on Programming Languages and Systems 11(4):633- 649, 1989). However, in the realm of Term Rewriting Systems, which can be seen as (first-order, untyped, unconditional) functional programs, termination of Context-Sensitive Rewriting (CSR) has been showed equivalent to productivity of rewrite systems through appropriate transformations. In this way, tools for proving termination of CSR can be used to prove productivity. In term rewriting, CSR is the restriction of rewriting that arises when reductions are allowed on selected arguments of function symbols only. In this paper we show that well-known results about the computational power or CSR are useful to better understand the existing connections between productivity of rewrite systems and termination of CSR, and also to obtain more powerful techniques to prove productivity of rewrite systems.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>522</post_id>
		<post_date><![CDATA[2015-09-11 04:59:43]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:59:43]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[productivity-of-rewrite-systems-without-transformations]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="context-sensitive-rewriting"><![CDATA[context-sensitive rewriting]]></category>
		<category domain="post_tag" nicename="functional-programming"><![CDATA[functional programming]]></category>
		<category domain="post_tag" nicename="productivity"><![CDATA[productivity]]></category>
		<category domain="post_tag" nicename="termination"><![CDATA[termination]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[523]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Termination of programs, i.e., the absence of infinite computations, ensures the existence of normal forms for all initial expressions, thus providing an essential ingredient for the definition of a normalization semantics for functional programs. In lazy functional languages, though, infinite data structures are often delivered as the outcome of computations. For instance, the list of all prime numbers can be returned as a neverending stream of numerical expressions or data structures. If such streams are allowed, requiring termination is hopeless. In this setting, the notion of productivity can be used to provide an account of computations with infinite data structures, as it “captures the idea of computability, of progress of infinite-list programs” (B.A. Sijtsma, On the Productivity of Recursive List Definitions, ACM Transactions on Programming Languages and Systems 11(4):633- 649, 1989). However, in the realm of Term Rewriting Systems, which can be seen as (first-order, untyped, unconditional) functional programs, termination of Context-Sensitive Rewriting (CSR) has been showed equivalent to productivity of rewrite systems through appropriate transformations. In this way, tools for proving termination of CSR can be used to prove productivity. In term rewriting, CSR is the restriction of rewriting that arises when reductions are allowed on selected arguments of function symbols only. In this paper we show that well-known results about the computational power or CSR are useful to better understand the existing connections between productivity of rewrite systems and termination of CSR, and also to obtain more powerful techniques to prove productivity of rewrite systems.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ context-sensitive rewriting, functional programming, productivity, termination]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Lucas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politécnica de Valéncia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[http://users.dsic.upv.es/~slucas/]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/015]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Collection of Website Benchmarks Labelled for Template Detection and Content Extraction</title>
		<link>https://biblioteca.sistedes.es/articulo/a-collection-of-website-benchmarks-labelled-for-template-detection-and-content-extraction/</link>
		<pubDate>Fri, 11 Sep 2015 03:03:57 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=525</guid>
		<description></description>
		<content><![CDATA[Template detection and content extraction are two of the main areas of information retrieval applied to the Web. They perform different analyses over the structure and content of webpages to extract some part of the document. However, their objectives are different. While template detection identifies the template of a webpage (usually comparing with other webpages of the same website), content extraction identifies the main content of the webpage discarding the other part. Therefore, they are somehow complementary, because the main content is not part of the template. It has been measured that templates represent between 40% and 50% of data on the Web. Therefore, identifying templates is essential for indexing tasks because templates usually contain irrelevant information such as advertisements, menus and banners. Processing and storing this information is likely to lead to a waste of resources (storage space, bandwidth, etc.). Similarly, identifying the main content is essential for many information retrieval tasks. In this paper, we present a benchmark suite to test different approaches for template detection and content extraction. The suite is public, and it contains real heterogeneous webpages that have been labelled so that different techniques can be suitable (and automatically) compared.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>525</post_id>
		<post_date><![CDATA[2015-09-11 05:03:57]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:03:57]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-collection-of-website-benchmarks-labelled-for-template-detection-and-content-extraction]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[526]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Template detection and content extraction are two of the main areas of information retrieval applied to the Web. They perform different analyses over the structure and content of webpages to extract some part of the document. However, their objectives are different. While template detection identifies the template of a webpage (usually comparing with other webpages of the same website), content extraction identifies the main content of the webpage discarding the other part. Therefore, they are somehow complementary, because the main content is not part of the template. It has been measured that templates represent between 40% and 50% of data on the Web. Therefore, identifying templates is essential for indexing tasks because templates usually contain irrelevant information such as advertisements, menus and banners. Processing and storing this information is likely to lead to a waste of resources (storage space, bandwidth, etc.). Similarly, identifying the main content is essential for many information retrieval tasks. In this paper, we present a benchmark suite to test different approaches for template detection and content extraction. The suite is public, and it contains real heterogeneous webpages that have been labelled so that different techniques can be suitable (and automatically) compared.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julián Alarte]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalarte@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David Insa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[dinsa@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Josep Silva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jsilva@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Salvador Tamarit]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[stamarit@babel.ls.fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/009]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Reasoning about policy behavior in logic-based trust management systems: Some complexity results and an operational framework</title>
		<link>https://biblioteca.sistedes.es/articulo/reasoning-about-policy-behavior-in-logic-based-trust-management-systems-some-complexity-results-and-an-operational-framework/</link>
		<pubDate>Fri, 11 Sep 2015 03:08:58 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=528</guid>
		<description></description>
		<content><![CDATA[In this paper we show that the logical framework proposed by Becker et al. [1] to reason about security policy behavior in a trust management context can be captured by an operational framework that is based on the language proposed by Miller in 1989 to deal with scoping and/or modules in logic programming. The framework of Becker et al. uses propositional Horn clauses to represent both policies and credentials, implications in clauses are interpreted in counterfactual logic, a Hilbertstyle proof system is defined and a system based on SAT is used to prove whether properties about credentials, permissions and policies are valid, i.e. true under all possible policies. Our contributions in this paper are three. First, we show that this kind of validation can rely on an operational semantics (derivability relation) of a language very similar to Miller’s language, which is very close to derivability in logic programs. Second, we are able to establish that, as in propositional logic, validity of formulas is a co-NP-complete problem. And third, we present a provably correct implementation of a goal-oriented algorithm for validity.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>528</post_id>
		<post_date><![CDATA[2015-09-11 05:08:58]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:08:58]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[reasoning-about-policy-behavior-in-logic-based-trust-management-systems-some-complexity-results-and-an-operational-framework]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[529]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper we show that the logical framework proposed by Becker et al. [1] to reason about security policy behavior in a trust management context can be captured by an operational framework that is based on the language proposed by Miller in 1989 to deal with scoping and/or modules in logic programming. The framework of Becker et al. uses propositional Horn clauses to represent both policies and credentials, implications in clauses are interpreted in counterfactual logic, a Hilbertstyle proof system is defined and a system based on SAT is used to prove whether properties about credentials, permissions and policies are valid, i.e. true under all possible policies. Our contributions in this paper are three. First, we show that this kind of validation can rely on an operational semantics (derivability relation) of a language very similar to Miller’s language, which is very close to derivability in logic programs. Second, we are able to establish that, as in propositional logic, validity of formulas is a co-NP-complete problem. And third, we present a provably correct implementation of a goal-oriented algorithm for validity.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Edelmira Pasarella]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departament de Ciencies de la Computació Universitat Politecnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[edelmira@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jorge Lobo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Institució Catalana de Recerca i Estudis Avancats (ICREA) DTIC – Universitat Pompeu Fabra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jorge.lobo@upf.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/011]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Inferring Specifications in the K framework</title>
		<link>https://biblioteca.sistedes.es/articulo/inferring-specifications-in-the-k-framework/</link>
		<pubDate>Fri, 11 Sep 2015 03:14:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=531</guid>
		<description></description>
		<content><![CDATA[Despite its many unquestionable benefits, formal specifications are not widely used in industrial software development. In order to reduce the time and effort required to write formal specifications, in this paper we propose a technique for automatically discovering specifications from real code. The proposed methodology relies on the symbolic execution capabilities recently provided by the K framework that we exploit to automatically infer formal specifications from programs that are written in a non–trivial fragment of C, called KERNELC. Roughly speaking, our symbolic analysis of KERNELC programs explains the execution of a (modifier) function by using other (observer) routines in the program. We implemented our technique in the automated tool KINDSPEC 2.0, which generates axioms that describe the precise input/output behavior of C routines that handle pointerbased structures (i.e., result values and state change). We describe the implementation of our system and discuss the differences w.r.t. our previous work on inferring specifications from C code.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>531</post_id>
		<post_date><![CDATA[2015-09-11 05:14:07]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:14:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[inferring-specifications-in-the-k-framework]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[532]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Despite its many unquestionable benefits, formal specifications are not widely used in industrial software development. In order to reduce the time and effort required to write formal specifications, in this paper we propose a technique for automatically discovering specifications from real code. The proposed methodology relies on the symbolic execution capabilities recently provided by the K framework that we exploit to automatically infer formal specifications from programs that are written in a non–trivial fragment of C, called KERNELC. Roughly speaking, our symbolic analysis of KERNELC programs explains the execution of a (modifier) function by using other (observer) routines in the program. We implemented our technique in the automated tool KINDSPEC 2.0, which generates axioms that describe the precise input/output behavior of C routines that handle pointerbased structures (i.e., result values and state change). We describe the implementation of our system and discuss the differences w.r.t. our previous work on inferring specifications from C code.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Alpuente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alpuente@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Daniel Pardo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[dparpon@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alicia Villanueva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[villanue@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/023]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Satisfiability of Constraint Specifications on XML Documents</title>
		<link>https://biblioteca.sistedes.es/articulo/satisfiability-of-constraint-specifications-on-xml-documents/</link>
		<pubDate>Fri, 11 Sep 2015 03:19:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=534</guid>
		<description></description>
		<content><![CDATA[In this work, we present an approach for specifying the structure of XML documents using three kinds of constraints based on XPath, together with a sound and complete method for reasoning about them. Currently, the standard specification of classes of XML documents is done by means of DTDs or XML Schemas. In both cases, we essentially describe the abstract syntax of the class of documents and the types of its attributes. This is quite limited. In particular, we may want to state more complex conditions about the structure of documents in a given class or about their contents. For example, with respect to the structure of documents, we may want to state that if an element includes an attribute with a given content, then these documents should not include some other element. Or, with respect to the contents of documents, we may want to express that the value of some numeric attribute of a certain element is smaller than the value of another attribute of a different element. In this paper, we concentrate on the specification of the structure of documents, not paying much attention to their contents. In this sense, we present an abstract approach for the specification of (the structure of) classes of XML documents using sets of constraints that are based on XPath [8, 9] queries, as given in [4], using the concept of tree patterns. Roughly, a tree pattern describes a basic property on the structure of documents. Its root repre sents the root of documents. Nodes represent elements that must be present on the given documents and their labels represent their contents, i.e. the names of elements and their value, if any. A wild card (the symbol ∗), means that we don’t know or we don’t care about the contents of that element. Finally, single edges represent parent/child relations between elements, while double edges represent a descendant relationship between elements. Again, if any of these two relations is included in a tree pattern, then it should also be included in the documents satisfying that property. For instance, on the left of Fig. 1 we show a tree pattern p describing documents D whose root node is labelled with a, some child node of the root node in D is labelled b, and some descendant node of the root node in D has two child nodes labelled c and d, respectively. Similarly, we represent, in an abstract way, XML documents using the same kind of trees. The difference between a document and a tree pattern is that a document does not include double edges or wildcards. For example, on the right of Fig. 1 we show a document that satisfies the pattern on the left. In particular, we may see that the root of the document is labelled by a. Moreover, that root has a child node labelled b and a descendant node (the element labelled f) that has two child nodes labelled c and d, respectively. We consider three kinds of (atomic) constraints. The first one, called positive constraints, are tree patterns. The second one are negative constraints, ¬p, where p is a tree pattern, expressing that documents should not satisfy p. Finally, the third sort of constraint are conditional constraints, written ∀(c : p → q), where both p and q are tree patterns. Roughly speaking, these constraints express that if a document satisfies p then it must also satisfy q. Moreover, these constraints can be combined using the connectives ∧ and ∨. These kinds of constraints are similar to the graph constraints studied in [6, 7] in the context of graph transformation. The work presented in those papers, shows how to use graph constraints as a specification formalism, and how to reason about these specifications. However, the application of these ideas to our setting is not trivial. Specifically, the descendant relation in our constraints makes non-trivial the application of these techniques since, the descendent relation would be second-order in the logic of graph constraints defined in [6, 7]. Obviously, there are conditions on the structure of XML documents that are not expressible using the kind of constraints studied in this paper. However, our experience in the area of graph transformation [6, 7] shows that, in practice, these constraints are sufficient in most cases. Nevertheless, we believe that the ideas presented here can be extended to a class of XML constraints, similar to the class of nested graph conditions that has been shown equivalent to first-order logic of graphs [2]. However, we also believe that this extension is not straightforward. Since our aim is to be able to reason about these specifications, we present inference rules that are shown, by means of tableaux, to define a sound and complete refutation procedure for checking satisfiability of a given specification. We strongly believe that satisfiability problem for this class of constraints is only semidecidable, since we believe that it would be similar to the (un)decidability of the satisfiability problem for the Horn clause fragment of first-order logic. As a consequence, if a given specification is inconsistent, we can be sure that our procedure will terminate showing that unsatisfiability. However, our procedure may not terminate if the given specification is satisfiable. Nevertheless, we may like to have an idea about the performance of our approach when the procedure terminates. One could think, that this performance would be quite poor, since checking if there is a monomorphism between two trees (a basic operation in our deduction procedure) is an NP-complete problem [3]. Actually, this is not our experience with the tool that we have implemented [1]. We think that the situation is similar to what happens with graph transformation tools. In these tools, applying a graph transformation rule means finding a subgraph isomorphism, which is also a wellknown NP-complete problem. However, the fact that the graphs are typed (in our case, the trees are labelled), in practice, reduces considerably the search. Finally, in the future, we plan to extend our approach to consider also cross-references and properties about the contents of documents. The former problem means, in fact, to extend our approach to graphs and graph patterns. For the latter case, we plan to follow the same approach that we used to extend our results for graphs in [6, 7] to the case of attributed graphs in [5].]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>534</post_id>
		<post_date><![CDATA[2015-09-11 05:19:52]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:19:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[satisfiability-of-constraint-specifications-on-xml-documents]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[535]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this work, we present an approach for specifying the structure of XML documents using three kinds of constraints based on XPath, together with a sound and complete method for reasoning about them. Currently, the standard specification of classes of XML documents is done by means of DTDs or XML Schemas. In both cases, we essentially describe the abstract syntax of the class of documents and the types of its attributes. This is quite limited. In particular, we may want to state more complex conditions about the structure of documents in a given class or about their contents. For example, with respect to the structure of documents, we may want to state that if an element includes an attribute with a given content, then these documents should not include some other element. Or, with respect to the contents of documents, we may want to express that the value of some numeric attribute of a certain element is smaller than the value of another attribute of a different element. In this paper, we concentrate on the specification of the structure of documents, not paying much attention to their contents. In this sense, we present an abstract approach for the specification of (the structure of) classes of XML documents using sets of constraints that are based on XPath [8, 9] queries, as given in [4], using the concept of tree patterns. Roughly, a tree pattern describes a basic property on the structure of documents. Its root repre sents the root of documents. Nodes represent elements that must be present on the given documents and their labels represent their contents, i.e. the names of elements and their value, if any. A wild card (the symbol ∗), means that we don’t know or we don’t care about the contents of that element. Finally, single edges represent parent/child relations between elements, while double edges represent a descendant relationship between elements. Again, if any of these two relations is included in a tree pattern, then it should also be included in the documents satisfying that property. For instance, on the left of Fig. 1 we show a tree pattern p describing documents D whose root node is labelled with a, some child node of the root node in D is labelled b, and some descendant node of the root node in D has two child nodes labelled c and d, respectively. Similarly, we represent, in an abstract way, XML documents using the same kind of trees. The difference between a document and a tree pattern is that a document does not include double edges or wildcards. For example, on the right of Fig. 1 we show a document that satisfies the pattern on the left. In particular, we may see that the root of the document is labelled by a. Moreover, that root has a child node labelled b and a descendant node (the element labelled f) that has two child nodes labelled c and d, respectively. We consider three kinds of (atomic) constraints. The first one, called positive constraints, are tree patterns. The second one are negative constraints, ¬p, where p is a tree pattern, expressing that documents should not satisfy p. Finally, the third sort of constraint are conditional constraints, written ∀(c : p → q), where both p and q are tree patterns. Roughly speaking, these constraints express that if a document satisfies p then it must also satisfy q. Moreover, these constraints can be combined using the connectives ∧ and ∨. These kinds of constraints are similar to the graph constraints studied in [6, 7] in the context of graph transformation. The work presented in those papers, shows how to use graph constraints as a specification formalism, and how to reason about these specifications. However, the application of these ideas to our setting is not trivial. Specifically, the descendant relation in our constraints makes non-trivial the application of these techniques since, the descendent relation would be second-order in the logic of graph constraints defined in [6, 7]. Obviously, there are conditions on the structure of XML documents that are not expressible using the kind of constraints studied in this paper. However, our experience in the area of graph transformation [6, 7] shows that, in practice, these constraints are sufficient in most cases. Nevertheless, we believe that the ideas presented here can be extended to a class of XML constraints, similar to the class of nested graph conditions that has been shown equivalent to first-order logic of graphs [2]. However, we also believe that this extension is not straightforward. Since our aim is to be able to reason about these specifications, we present inference rules that are shown, by means of tableaux, to define a sound and complete refutation procedure for checking satisfiability of a given specification. We strongly believe that satisfiability problem for this class of constraints is only semidecidable, since we believe that it would be similar to the (un)decidability of the satisfiability problem for the Horn clause fragment of first-order logic. As a consequence, if a given specification is inconsistent, we can be sure that our procedure will terminate showing that unsatisfiability. However, our procedure may not terminate if the given specification is satisfiable. Nevertheless, we may like to have an idea about the performance of our approach when the procedure terminates. One could think, that this performance would be quite poor, since checking if there is a monomorphism between two trees (a basic operation in our deduction procedure) is an NP-complete problem [3]. Actually, this is not our experience with the tool that we have implemented [1]. We think that the situation is similar to what happens with graph transformation tools. In these tools, applying a graph transformation rule means finding a subgraph isomorphism, which is also a wellknown NP-complete problem. However, the fact that the graphs are typed (in our case, the trees are labelled), in practice, reduces considerably the search. Finally, in the future, we plan to extend our approach to consider also cross-references and properties about the contents of documents. The former problem means, in fact, to extend our approach to graphs and graph patterns. For the latter case, we plan to follow the same approach that we used to extend our results for graphs in [6, 7] to the case of attributed graphs in [5].]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Marisa Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad del País Vasco Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[marisa.navarro@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando Orejas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[orejas@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Elvira Pino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pino@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/022]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Property based Testing of XQuery Programs</title>
		<link>https://biblioteca.sistedes.es/articulo/property-based-testing-of-xquery-programs/</link>
		<pubDate>Fri, 11 Sep 2015 03:24:23 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=537</guid>
		<description></description>
		<content><![CDATA[In this paper we present the elements of an XQuery testing tool which makes possible to automatically test XQuery programs. The tool is able to systematically generate XML instances (i.e., test cases) from a given XML schema. The number and type of instances is defined by the human tester. These instances are used to execute the given XQuery program. In addition, the tool makes possible to provide an user defined property to be tested against the output of the XQuery program. The property can be specified with a Boolean XQuery function. The tool is implemented as an oracle able to report whether the XQuery program passes the test, that is, all the test cases satisfy the property, as well as the number of test cases used for testing. In the case when the XQuery program fails the testing, the tool shows counterexamples found in the test cases. The tool has been implemented as an XQuery library which makes possible to be used from any XQuery interpreter.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>537</post_id>
		<post_date><![CDATA[2015-09-11 05:24:23]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:24:23]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[property-based-testing-of-xquery-programs]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[538]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper we present the elements of an XQuery testing tool which makes possible to automatically test XQuery programs. The tool is able to systematically generate XML instances (i.e., test cases) from a given XML schema. The number and type of instances is defined by the human tester. These instances are used to execute the given XQuery program. In addition, the tool makes possible to provide an user defined property to be tested against the output of the XQuery program. The property can be specified with a Boolean XQuery function. The tool is implemented as an oracle able to report whether the XQuery program passes the test, that is, all the test cases satisfy the property, as well as the number of test cases used for testing. In the case when the XQuery program fails the testing, the tool shows counterexamples found in the test cases. The tool has been implemented as an XQuery library which makes possible to be used from any XQuery interpreter.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesus M. Almendros-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informatica. Universidad de Almería. 04120-Almería. SPAIN.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalmen@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Antonio Becerra-Terón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informatica. Universidad de Almería. 04120-Almería. SPAIN.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[abecerra@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/008]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A discretized operational semantics for the implementation of Hy-tccp</title>
		<link>https://biblioteca.sistedes.es/articulo/a-discretized-operational-semantics-for-the-implementation-of-hy-tccp/</link>
		<pubDate>Fri, 11 Sep 2015 03:27:34 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=540</guid>
		<description></description>
		<content><![CDATA[The language Hy-tccp was proposed as an extension of the Timed Concurrent Constraint paradigm (tccp) with continuous time and suitable mechanisms to handle continuous behaviors. This language provides a powerful model for hybrid and cyber-physical systems including concurrency and syn chronization features. In this paper, we propose a discretized operational semantics for Hy-tccp and an extension of the standard LTL to reason about temporal properties of Hy-tccp programs. The semantics and the logics will be the basis for the definition of formal verification and analysis tools, such as model checkers and theorem provers.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>540</post_id>
		<post_date><![CDATA[2015-09-11 05:27:34]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:27:34]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-discretized-operational-semantics-for-the-implementation-of-hy-tccp]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[541]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The language Hy-tccp was proposed as an extension of the Timed Concurrent Constraint paradigm (tccp) with continuous time and suitable mechanisms to handle continuous behaviors. This language provides a powerful model for hybrid and cyber-physical systems including concurrency and syn chronization features. In this paper, we propose a discretized operational semantics for Hy-tccp and an extension of the standard LTL to reason about temporal properties of Hy-tccp programs. The semantics and the logics will be the basis for the definition of formal verification and analysis tools, such as model checkers and theorem provers.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María del Mar Gallardo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dept. Lenguajes y Ciencias de la Computación E.T.S.I. Informatica University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[gallardo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Laura Panizo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dept. Lenguajes y Ciencias de la Computación E.T.S.I. Informatica University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[laurapanizo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Laura Titolo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dept. Lenguajes y Ciencias de la Computación E.T.S.I. Informatica University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[laura.titolo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/010]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Learning a Subclass of Multivalued Dependencies Formulas from Entailments</title>
		<link>https://biblioteca.sistedes.es/articulo/learning-a-subclass-of-multivalued-dependencies-formulas-from-entailments/</link>
		<pubDate>Fri, 11 Sep 2015 03:30:44 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=543</guid>
		<description></description>
		<content><![CDATA[Functional and multivalued dependencies play an important role in the design of relational databases. There is a strong connection between data dependencies and some fragments of the propositional logic. In particular, functional dependencies are closely related to Horn formulas. Also, multivalued dependencies are characterized in terms of multivalued formulas. It is known that both Horn formulas and sets of functional dependencies are efficiently learnable in the exact model of learning with queries. In this work, we study the learnability of a non-trivial subclass of multivalued formulas called CRMVDF. We use Angluin’s exact learning model with membership and equivalence queries and present a polynomial time algorithm which exactly learns CRMVDF from entailments.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>543</post_id>
		<post_date><![CDATA[2015-09-11 05:30:44]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:30:44]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[learning-a-subclass-of-multivalued-dependencies-formulas-from-entailments]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[544]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Functional and multivalued dependencies play an important role in the design of relational databases. There is a strong connection between data dependencies and some fragments of the propositional logic. In particular, functional dependencies are closely related to Horn formulas. Also, multivalued dependencies are characterized in terms of multivalued formulas. It is known that both Horn formulas and sets of functional dependencies are efficiently learnable in the exact model of learning with queries. In this work, we study the learnability of a non-trivial subclass of multivalued formulas called CRMVDF. We use Angluin’s exact learning model with membership and equivalence queries and present a polynomial time algorithm which exactly learns CRMVDF from entailments.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Montserrat Hermo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Languages and Information Systems The University of the Basque Country (UPV/EHU)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[montserrat.hermo@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ana Ozaki]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science University of Liverpool, UK]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[anaozaki@liverpool.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/019]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Abstract Diagnosis for tccp using a Linear Temporal Logic</title>
		<link>https://biblioteca.sistedes.es/articulo/abstract-diagnosis-for-tccp-using-a-linear-temporal-logic/</link>
		<pubDate>Fri, 11 Sep 2015 03:33:41 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=546</guid>
		<description></description>
		<content><![CDATA[This extended abstract is a summary of [5], where we provided an automatic decision method to check whether a given property, specified in a linear temporal logic, is valid w.r.t. a tccp program. Our proposal (based on abstract interpretation techniques) does not require to build any model of the program, in constrast with standard verification methods such as model checking. Our results guarantee correctness but, as usual when using an abstract semantics, completeness is lost.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>546</post_id>
		<post_date><![CDATA[2015-09-11 05:33:41]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:33:41]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[abstract-diagnosis-for-tccp-using-a-linear-temporal-logic]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[10]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[547]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This extended abstract is a summary of [5], where we provided an automatic decision method to check whether a given property, specified in a linear temporal logic, is valid w.r.t. a tccp program. Our proposal (based on abstract interpretation techniques) does not require to build any model of the program, in constrast with standard verification methods such as model checking. Our results guarantee correctness but, as usual when using an abstract semantics, completeness is lost.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[M. Comini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dipartimento di Matematica e Informatica, U. di Udine]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[L. Titolo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dipartimento di Matematica e Informatica, U. di Udine]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[A. Villanueva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politécnica de Valéncia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/026]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Using Model Checking to Generate Test Cases for Android Applications</title>
		<link>https://biblioteca.sistedes.es/articulo/using-model-checking-to-generate-test-cases-for-android-applications/</link>
		<pubDate>Fri, 11 Sep 2015 03:36:45 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=549</guid>
		<description></description>
		<content><![CDATA[The behavior of mobile devices is highly non deterministic and barely predictable due to the interaction of the user with its applications. In consequence, analyzing the correctness of applications running on a smartphone involves dealing with the complexity of its environment. In this paper, we propose the use of model-based testing to describe the potential behaviors of users interacting with mobile applications. These behaviors are modeled by composing specially-designed state machines. These composed state machines can be exhaustively explored using a model checking tool to automatically generate all possible user interactions. Each generated trace model checker can be interpreted as a test case to drive a runtime analysis of actual applications. We have implemented a tool that follows the proposed methodology to analyze ANDROID devices using the model checker SPIN as the exhaustive generator of test cases.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>549</post_id>
		<post_date><![CDATA[2015-09-11 05:36:45]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:36:45]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[using-model-checking-to-generate-test-cases-for-android-applications]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[550]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The behavior of mobile devices is highly non deterministic and barely predictable due to the interaction of the user with its applications. In consequence, analyzing the correctness of applications running on a smartphone involves dealing with the complexity of its environment. In this paper, we propose the use of model-based testing to describe the potential behaviors of users interacting with mobile applications. These behaviors are modeled by composing specially-designed state machines. These composed state machines can be exhaustively explored using a model checking tool to automatically generate all possible user interactions. Each generated trace model checker can be interpreted as a test case to drive a runtime analysis of actual applications. We have implemented a tool that follows the proposed methodology to analyze ANDROID devices using the model checker SPIN as the exhaustive generator of test cases.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana Rosario Espada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dept. Lenguajes y Ciencias de la Computación E.T.S.I. Informatica University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[anarosario@lcc.uma.e]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[María del Mar Gallardo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dept. Lenguajes y Ciencias de la Computación E.T.S.I. Informatica University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gallardo@lcc.uma.e]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alberto Salmerón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dept. Lenguajes y Ciencias de la Computación E.T.S.I. Informatica University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[salmeron@lcc.uma.e]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Pedro Merino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dept. Lenguajes y Ciencias de la Computación E.T.S.I. Informatica University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[pedro@lcc.uma.e]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/007]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards a Formal Semantics-Based Technique for Interprocedural Slicing</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-a-formal-semantics-based-technique-for-interprocedural-slicing/</link>
		<pubDate>Fri, 11 Sep 2015 03:39:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=552</guid>
		<description></description>
		<content><![CDATA[Interprocedural slicing is a technique applied on programs with procedures which relies on how the information is passed at procedure call/return sites. Such a technique computes program slices (i.e. program fragments restricted w.r.t. a given criterion). The existing approaches to interprocedural slicing exploit the particularities of the underlying language semantics in order to compute program slices. In this paper we propose a generic technique for interprocedural slicing. More specifically, our approach works with inferred particularities of a language semantics, given as a rewriting-logic specification, and computes program slices using a term slicing-based algorithm.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>552</post_id>
		<post_date><![CDATA[2015-09-11 05:39:53]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:39:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-a-formal-semantics-based-technique-for-interprocedural-slicing]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[553]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Interprocedural slicing is a technique applied on programs with procedures which relies on how the information is passed at procedure call/return sites. Such a technique computes program slices (i.e. program fragments restricted w.r.t. a given criterion). The existing approaches to interprocedural slicing exploit the particularities of the underlying language semantics in order to compute program slices. In this paper we propose a generic technique for interprocedural slicing. More specifically, our approach works with inferred particularities of a language semantics, given as a rewriting-logic specification, and computes program slices using a term slicing-based algorithm.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Irina Mariuca Asavoae]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Swansea University, United Kingdom]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[I.M.Asavoae@swansea.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mihail Asavoae]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Inria Rocquencourt, France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mihail.asavoae@inria.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Adrian Riesco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ariesco@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automatic generation of logical models for order-sorted first-order theories in program analysis</title>
		<link>https://biblioteca.sistedes.es/articulo/automatic-generation-of-logical-models-for-order-sorted-first-order-theories-in-program-analysis/</link>
		<pubDate>Fri, 11 Sep 2015 03:42:37 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=555</guid>
		<description></description>
		<content><![CDATA[Computations are often viewed as proofs of specific sentences in some computational logic describing the operational semantics of the programming language or computational system. Since the semantics of programs (i.e., the set of such specific sentences that are provable in the logic) is usually incomputable, and most program properties undecidable, abstraction is essential in program analysis. Abstractions can be formalized as semantic models which should be automatically generated in a push-the-button-and-wait style of program analysis and verification. We investigate the automatic generation of numerical models for order-sorted first-order logics and its use in program analysis. Our development systematically uses the recently introduced convex domains which are well-suited for representing domains for different sorts; we use them to interpret the ranked symbols of sorted signatures by means of appropriately adapted convex matrix interpretations. Such numerical interpretations permit the use of existing algorithms and tools from linear algebra (e.g., Farkas’ Lemma), real algebraic geometry, and arithmetic constraint solving in the implementation of the analyses.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>555</post_id>
		<post_date><![CDATA[2015-09-11 05:42:37]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:42:37]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automatic-generation-of-logical-models-for-order-sorted-first-order-theories-in-program-analysis]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="abstraction"><![CDATA[Abstraction]]></category>
		<category domain="post_tag" nicename="logical-models"><![CDATA[Logical models]]></category>
		<category domain="post_tag" nicename="order-sorted-first-order-logic"><![CDATA[Order-sorted first-order logic]]></category>
		<category domain="post_tag" nicename="program-analysis"><![CDATA[Program analysis]]></category>
		<category domain="post_tag" nicename="termination"><![CDATA[termination]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[556]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Computations are often viewed as proofs of specific sentences in some computational logic describing the operational semantics of the programming language or computational system. Since the semantics of programs (i.e., the set of such specific sentences that are provable in the logic) is usually incomputable, and most program properties undecidable, abstraction is essential in program analysis. Abstractions can be formalized as semantic models which should be automatically generated in a push-the-button-and-wait style of program analysis and verification. We investigate the automatic generation of numerical models for order-sorted first-order logics and its use in program analysis. Our development systematically uses the recently introduced convex domains which are well-suited for representing domains for different sorts; we use them to interpret the ranked symbols of sorted signatures by means of appropriately adapted convex matrix interpretations. Such numerical interpretations permit the use of existing algorithms and tools from linear algebra (e.g., Farkas’ Lemma), real algebraic geometry, and arithmetic constraint solving in the implementation of the analyses.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Abstraction, Logical models, Order-sorted first-order logic, Program analysis, Termination]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Lucas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politécnica de Valéncia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[http://users.dsic.upv.es/~slucas/]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Assertional Proof of the Stability and Correctness of Natural Mergesort</title>
		<link>https://biblioteca.sistedes.es/articulo/an-assertional-proof-of-the-stability-and-correctness-of-natural-mergesort/</link>
		<pubDate>Fri, 11 Sep 2015 03:45:11 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=558</guid>
		<description></description>
		<content><![CDATA[Natural Mergesort [9] is a sorting algorithm for linear data structures (arrays and lists) that has been widely studied mainly due to its good properties. It has Nlog(N) worst-case complexity and, even in the case of arrays, is slightly easier to code than heapsort. Further, it performs very well on input data that is already mostly sorted. Another good property is stability. A sorting algorithm is stable if it maintains the relative order of records with equal keys. The most obvious application of a stable algorithm is sorting using different (primary, secondary, etc.) keys. Stability is, as we show in lemma EqMultisets, stronger than the property of preserving the multiset of elements (from the input list to the sorted output list). Hence, stability, along with sortedness, implies the correctness of sorting algorithms (including the permutation property). Recently, Sternagel [13] has published an Isabelle/HOL proof of the correctness and stability of natural mergesort as a proof pearl. Sternagel [13], firstly, specifies the algorithm as a functional program and, then, formalizes and proves the desired properties using the proof-assistant Isabelle/HOL. The proof is non-assertional and uses higher-order constructions. Indeed, it is strongly based on two skillful ad-hoc induction schemes. The first one for handling the mutually recursive functions involved in the splitting of the input into ascending sequences. The second induction scheme is related to the merging of the ascending lists. Correctness and stability are deduced from auxiliary lemmas which are proved by means of these induction schemes and with the help of a subtle generalization of the predicate sorted. The definition of that generalization and the induction schemes require the power of higher-order logic. In particular, the stability property is formalized in higher-order logic. More recently, de Gouw et al. [7] discussed a semi-automated formal proof of the correctness and stability of two sorting algorithms on arrays: Counting sort and Radix sort. This proof is formalized using the theorem-prover KeY [2]. The implementation code is written in Java. The specification is written (using the Java Modeling Language, JML) in an extension of first-order logic with permutation predicates, which have recently been added [1] to the KeY system. There are many other formalizations of the natural mergesort algorithm and also of different sorting algorithms (e.g. insertion sort, quicksort, heapsort, radix sort, etc.) in various systems, such as Coq [3], Isabelle/HOL [12], Why3 [6], ACL2 [8], KeY [2], etc. However, to the best of our knowledge, stability is only considered in [13], [7], and in our assertional proof. In this paper, we present an implementation of natural mergesort over an algebraic data type of lists. The code is enriched with its contract-based specification and a proof of its correctness and its stability. Our proof is assertional, i.e. it uses assert statements, inserted in the code, to enable the (fully) automatic verification. The assertions are first-order formulas that explain how and why the program works. The proof is supported by a few definitions that are easy to understand, and a few lemmas that isolate useful properties. Moreover, only non-trivial lemmas have detailed proofs and these are short and easy to read and to understand. Hence, in our opinion, the presented proof is quite clear and elegant. The program-proof is implemented in the state-of-the-art verifier Dafny [10]. The Dafny programming language supports a mixture of imperative, object-oriented programming and functional programming. In this paper, we use mostly functions, methods, and algebraic datatypes. The Dafny specification language includes the usual assertional language for contracts of pre/post conditions, invariants, decreasing expressions for termination proofs, etc. Since Dafny is designed with the main purpose of facilitating the construction of correct code, Dafny notation is compact and easy to understand. For the sake of readability and conciseness, the Dafny proof language includes constructs for structuring proofs such as lemmas and calculational proofs [11]. Dafny automatically generates executable .NET code for verified programs. The presented proof is made on the basis of some lemmas that ensure natural properties. Most of the proofs are inductive and use calculations [11] when appropriate. We believe that our program-proof is a simple and intuitive example of how a practical verification tool can be used by software developers with a minimum of familiarity with contract-based specifications and first-order assertions. We aim to contribute to the spread of the educational use of automatic tools in the development of formally verified software. We are convinced that this kind of example is useful for the introduction of formal software development methods and tools in software engineering courses. To sum up, we present a mechanically verified implementation of the sorting algorithm Natural Mergesort that consists of a few methods specified by their contracts of pre/post conditions. Methods are annotated with assertions that allow the automatic verification of the contract satisfaction. Along the paper we provide and explain the complete text of the program-proof.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>558</post_id>
		<post_date><![CDATA[2015-09-11 05:45:11]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:45:11]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-assertional-proof-of-the-stability-and-correctness-of-natural-mergesort]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[559]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Natural Mergesort [9] is a sorting algorithm for linear data structures (arrays and lists) that has been widely studied mainly due to its good properties. It has Nlog(N) worst-case complexity and, even in the case of arrays, is slightly easier to code than heapsort. Further, it performs very well on input data that is already mostly sorted. Another good property is stability. A sorting algorithm is stable if it maintains the relative order of records with equal keys. The most obvious application of a stable algorithm is sorting using different (primary, secondary, etc.) keys. Stability is, as we show in lemma EqMultisets, stronger than the property of preserving the multiset of elements (from the input list to the sorted output list). Hence, stability, along with sortedness, implies the correctness of sorting algorithms (including the permutation property). Recently, Sternagel [13] has published an Isabelle/HOL proof of the correctness and stability of natural mergesort as a proof pearl. Sternagel [13], firstly, specifies the algorithm as a functional program and, then, formalizes and proves the desired properties using the proof-assistant Isabelle/HOL. The proof is non-assertional and uses higher-order constructions. Indeed, it is strongly based on two skillful ad-hoc induction schemes. The first one for handling the mutually recursive functions involved in the splitting of the input into ascending sequences. The second induction scheme is related to the merging of the ascending lists. Correctness and stability are deduced from auxiliary lemmas which are proved by means of these induction schemes and with the help of a subtle generalization of the predicate sorted. The definition of that generalization and the induction schemes require the power of higher-order logic. In particular, the stability property is formalized in higher-order logic. More recently, de Gouw et al. [7] discussed a semi-automated formal proof of the correctness and stability of two sorting algorithms on arrays: Counting sort and Radix sort. This proof is formalized using the theorem-prover KeY [2]. The implementation code is written in Java. The specification is written (using the Java Modeling Language, JML) in an extension of first-order logic with permutation predicates, which have recently been added [1] to the KeY system. There are many other formalizations of the natural mergesort algorithm and also of different sorting algorithms (e.g. insertion sort, quicksort, heapsort, radix sort, etc.) in various systems, such as Coq [3], Isabelle/HOL [12], Why3 [6], ACL2 [8], KeY [2], etc. However, to the best of our knowledge, stability is only considered in [13], [7], and in our assertional proof. In this paper, we present an implementation of natural mergesort over an algebraic data type of lists. The code is enriched with its contract-based specification and a proof of its correctness and its stability. Our proof is assertional, i.e. it uses assert statements, inserted in the code, to enable the (fully) automatic verification. The assertions are first-order formulas that explain how and why the program works. The proof is supported by a few definitions that are easy to understand, and a few lemmas that isolate useful properties. Moreover, only non-trivial lemmas have detailed proofs and these are short and easy to read and to understand. Hence, in our opinion, the presented proof is quite clear and elegant. The program-proof is implemented in the state-of-the-art verifier Dafny [10]. The Dafny programming language supports a mixture of imperative, object-oriented programming and functional programming. In this paper, we use mostly functions, methods, and algebraic datatypes. The Dafny specification language includes the usual assertional language for contracts of pre/post conditions, invariants, decreasing expressions for termination proofs, etc. Since Dafny is designed with the main purpose of facilitating the construction of correct code, Dafny notation is compact and easy to understand. For the sake of readability and conciseness, the Dafny proof language includes constructs for structuring proofs such as lemmas and calculational proofs [11]. Dafny automatically generates executable .NET code for verified programs. The presented proof is made on the basis of some lemmas that ensure natural properties. Most of the proofs are inductive and use calculations [11] when appropriate. We believe that our program-proof is a simple and intuitive example of how a practical verification tool can be used by software developers with a minimum of familiarity with contract-based specifications and first-order assertions. We aim to contribute to the spread of the educational use of automatic tools in the development of formally verified software. We are convinced that this kind of example is useful for the introduction of formal software development methods and tools in software engineering courses. To sum up, we present a mechanically verified implementation of the sorting algorithm Natural Mergesort that consists of a few methods specified by their contracts of pre/post conditions. Methods are annotated with assertions that allow the automatic verification of the contract satisfaction. Along the paper we provide and explain the complete text of the program-proof.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[K. Rustan M. Leino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Microsoft Research]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[leino@microsoft.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Paqui Lucio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[The University of the Basque Country (UPV/EHU)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[paqui.lucio@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/025]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Thresholded Debugging of XPath Queries</title>
		<link>https://biblioteca.sistedes.es/articulo/thresholded-debugging-of-xpath-queries/</link>
		<pubDate>Fri, 11 Sep 2015 03:58:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=561</guid>
		<description></description>
		<content><![CDATA[We have recently designed/implemented a method for debugging Fuzzy-XPath queries which produces a set of alternative Fuzzy-XPath expressions with higher chances for retrieving answers from XML files. The main goal of the present paper consists in the introduction of a new fuzzy command inside the Fuzzy-XPath debugger which comfortably relies on our implementation based on fuzzy logic programming. So, when &lt;&lt;[FILTER=r]&gt;&gt; precedes a fuzzy query the debugger lazily explores an input XML document for dynamically disregarding as soon as possible those branches of the XML tree leading to irrelevant solutions (i.e., with a chance degree degraded below r), thus allowing the possibility of efficiently managing large files without reducing the set of answers for which users are mainly interested in. Hence, advice that this dynamic thresholding technique embedded into the core of the Fuzzy-XPath debugger has two advantages: • firstly it permits to concentrate on significant answers (i.e., alternative queries which do not excessively deviate from the original one) without disturbing the attention with useless information, and • secondly, the computational behavior of the debugging process is highly improved (both in time and space) since a great amount of work is avoided when discriminating useless branches of the XML tree.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>561</post_id>
		<post_date><![CDATA[2015-09-11 05:58:09]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:58:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[thresholded-debugging-of-xpath-queries]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We have recently designed/implemented a method for debugging Fuzzy-XPath queries which produces a set of alternative Fuzzy-XPath expressions with higher chances for retrieving answers from XML files. The main goal of the present paper consists in the introduction of a new fuzzy command inside the Fuzzy-XPath debugger which comfortably relies on our implementation based on fuzzy logic programming. So, when <<[FILTER=r]>> precedes a fuzzy query the debugger lazily explores an input XML document for dynamically disregarding as soon as possible those branches of the XML tree leading to irrelevant solutions (i.e., with a chance degree degraded below r), thus allowing the possibility of efficiently managing large files without reducing the set of answers for which users are mainly interested in. Hence, advice that this dynamic thresholding technique embedded into the core of the Fuzzy-XPath debugger has two advantages: • firstly it permits to concentrate on significant answers (i.e., alternative queries which do not excessively deviate from the original one) without disturbing the attention with useless information, and • secondly, the computational behavior of the debugging process is highly improved (both in time and space) since a great amount of work is avoided when discriminating useless branches of the XML tree.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesus M. Almendros-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dept. of Informatics Universidad de Almería 04120 Almería (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalmen@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alejandro Luna]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dept. of Computing Systems University of Castilla-La Mancha 02071 Albacete (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Alejandro.Luna@alu.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ginés Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dept. of Computing Systems University of Castilla-La Mancha 02071 Albacete (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Gines.Moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/014]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Analysing the Termination of Term Rewriting Systems using Data Mining</title>
		<link>https://biblioteca.sistedes.es/articulo/analysing-the-termination-of-term-rewriting-systems-using-data-mining/</link>
		<pubDate>Fri, 11 Sep 2015 04:02:34 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=564</guid>
		<description></description>
		<content><![CDATA[During the last decades, researchers in the field of Term Rewriting System (TRS) have devoted a lot of effort in order to develop techniques and methods able to demonstrate the termination property of a TRS. As a consequence, some of the proposed techniques have been implemented and several termination tools have been developed in order to automatize the termination proofs. From 2004, the annual Termination Competition is the foro in which research groups compare their tools trying to provide termination proofs of as many TRS as possible. This event generates a large amount of information (results obtained by the different tools, time spent on each proof, ...) that is recorded in databases. In this paper, we propose an alternative approach to study the termination of TRS: to use data mining techniques that, based on the historical information collected in the competition, generate models to explore the termination of a TRS. The goal of our study is not to develop a termination tool but to show, for the first time, what machine learning techniques can offer to the analysis of TRS termination.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>564</post_id>
		<post_date><![CDATA[2015-09-11 06:02:34]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 04:02:34]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analysing-the-termination-of-term-rewriting-systems-using-data-mining]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[565]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[During the last decades, researchers in the field of Term Rewriting System (TRS) have devoted a lot of effort in order to develop techniques and methods able to demonstrate the termination property of a TRS. As a consequence, some of the proposed techniques have been implemented and several termination tools have been developed in order to automatize the termination proofs. From 2004, the annual Termination Competition is the foro in which research groups compare their tools trying to provide termination proofs of as many TRS as possible. This event generates a large amount of information (results obtained by the different tools, time spent on each proof, ...) that is recorded in databases. In this paper, we propose an alternative approach to study the termination of TRS: to use data mining techniques that, based on the historical information collected in the competition, generate models to explore the termination of a TRS. The goal of our study is not to develop a termination tool but to show, for the first time, what machine learning techniques can offer to the analysis of TRS termination.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[J. Piris]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politecnica de Valéncia, Camí de Vera s/n, 46022 Valéncia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jpiris@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[H. Fabregat]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politecnica de Valéncia, Camí de Vera s/n, 46022 Valéncia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[herfabma@inf.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[M.J. Ramírez-Quintana]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politecnica de Valéncia, Camí de Vera s/n, 46022 Valéncia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mramirez@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/017]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Verification games: Making software verification fun</title>
		<link>https://biblioteca.sistedes.es/articulo/verification-games-making-software-verification-fun/</link>
		<pubDate>Wed, 20 Apr 2016 02:42:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=712</guid>
		<description></description>
		<content><![CDATA[Program verification is the only way to be certain that a given piece of software is free of (certain
types of) errors – errors that could otherwise disrupt operations in the field. To date, formal verifica-
tion has been done by specially-trained engineers. Labor costs make formal verification too costly to
apply beyond small, critical software components.
Our goal is to make software verification more cost-effective by reducing the skill set required
for verification and increasing the pool of people capable of performing verification. Our approach
is to transform the verification task (a program and a goal property) into a visual puzzle task – a
game – that gets solved by people. The solution of the puzzle is then translated back into a proof of
correctness. The puzzle is engaging and intuitive enough that ordinary people can through game-play
become experts. It is publicly available to play, and game players have produced proofs of security
properties for real programs.
This talk will present the design goals and choices for both the game that the player sees and for
the underlying program analysis. It will conclude with implications to gaming, programming, and
beyond.
]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>712</post_id>
		<post_date><![CDATA[2016-04-20 04:42:09]]></post_date>
		<post_date_gmt><![CDATA[2016-04-20 02:42:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[verification-games-making-software-verification-fun]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[713]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Program verification is the only way to be certain that a given piece of software is free of (certain
types of) errors – errors that could otherwise disrupt operations in the field. To date, formal verifica-
tion has been done by specially-trained engineers. Labor costs make formal verification too costly to
apply beyond small, critical software components.
Our goal is to make software verification more cost-effective by reducing the skill set required
for verification and increasing the pool of people capable of performing verification. Our approach
is to transform the verification task (a program and a goal property) into a visual puzzle task – a
game – that gets solved by people. The solution of the puzzle is then translated back into a proof of
correctness. The puzzle is engaging and intuitive enough that ordinary people can through game-play
become experts. It is publicly available to play, and game players have produced proofs of security
properties for real programs.
This talk will present the design goals and choices for both the game that the player sees and for
the underlying program analysis. It will conclude with implications to gaming, programming, and
beyond.
]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Michael Ernst]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Washington, USA]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mernst@cs.washington.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2014/001]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>EDD: A Declarative Debugger for Sequential Erlang Programs (High-level Work)</title>
		<link>https://biblioteca.sistedes.es/articulo/edd-a-declarative-debugger-for-sequential-erlang-programs-high-level-work/</link>
		<pubDate>Sun, 24 Apr 2016 00:41:21 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=721</guid>
		<description></description>
		<content><![CDATA[Declarative debuggers are semi-automatic debugging tools that abstract the execution details to focuson the program semantics. This paper presents a tool implementing this approach for the sequentialsubset of Erlang, a functional language with dynamic typing and strict evaluation. Given an erro-neous computation, it first detects an erroneous function (either a "named" function or a lambda-abstraction), and then continues the process to identify the fragment of the function responsible forthe error. Among its features it includes support for exceptions, predefined and built-in functions,higher-order functions, and trusting and undo commands.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>721</post_id>
		<post_date><![CDATA[2016-04-24 02:41:21]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 00:41:21]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[edd-a-declarative-debugger-for-sequential-erlang-programs-high-level-work]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[722]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Declarative debuggers are semi-automatic debugging tools that abstract the execution details to focuson the program semantics. This paper presents a tool implementing this approach for the sequentialsubset of Erlang, a functional language with dynamic typing and strict evaluation. Given an erro-neous computation, it first detects an erroneous function (either a "named" function or a lambda-abstraction), and then continues the process to identify the fragment of the function responsible forthe error. Among its features it includes support for exceptions, predefined and built-in functions,higher-order functions, and trusting and undo commands.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rafael Caballero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Sistemas Informáticos y Computación Facultad de Informática Universidad Complutense de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rafa@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Enrique Martin-Martin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Sistemas Informáticos y Computación Facultad de Informática Universidad Complutense de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[emartinm@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Adrián Riesco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Sistemas Informáticos y Computación Facultad de Informática Universidad Complutense de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ariesco@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2014/008]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Using Big-step and Small-step Semantics to Perform Declarative Debugging (High-level Work)</title>
		<link>https://biblioteca.sistedes.es/articulo/using-big-step-and-small-step-semantics-to-perform-declarative-debugging-high-level-work/</link>
		<pubDate>Sun, 24 Apr 2016 00:45:44 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=724</guid>
		<description></description>
		<content><![CDATA[Declarative debugging is a semi-automatic debugging technique that abstracts the execution details to focus on results. This technique builds a debugging tree representing an incorrect computation and traverses it by asking questions to the user until the error is found. In previous works we have presented a declarative debugger for Maude specifications. Besides a programming language, Maude is a semantic framework where several other languages can be specified. However, our declarative debugger is only able to find errors in Maude specifications, so it cannot find bugs on the programs written on the languages being specified. We study in this paper how to modify our declarative debugger to find this kind of errors when defining programming languages using big-step and smallstep semantics, two generic approaches that allow to specify a wide range of languages in a natural way. We obtain our debugging trees by modifying the proof trees obtained from the semantic rules. We have extended our declarative debugger to deal with this kind of debugging, and examples have been developed to test its feasibility.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>724</post_id>
		<post_date><![CDATA[2016-04-24 02:45:44]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 00:45:44]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[using-big-step-and-small-step-semantics-to-perform-declarative-debugging-high-level-work]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Declarative debugging is a semi-automatic debugging technique that abstracts the execution details to focus on results. This technique builds a debugging tree representing an incorrect computation and traverses it by asking questions to the user until the error is found. In previous works we have presented a declarative debugger for Maude specifications. Besides a programming language, Maude is a semantic framework where several other languages can be specified. However, our declarative debugger is only able to find errors in Maude specifications, so it cannot find bugs on the programs written on the languages being specified. We study in this paper how to modify our declarative debugger to find this kind of errors when defining programming languages using big-step and smallstep semantics, two generic approaches that allow to specify a wide range of languages in a natural way. We obtain our debugging trees by modifying the proof trees obtained from the semantic rules. We have extended our declarative debugger to deal with this kind of debugging, and examples have been developed to test its feasibility.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Adrián Riesco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Sistemas Informáticos y Computación Facultad de Informática Universidad Complutense de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ariesco@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2014/007]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Correctness of Incremental Model Synchronization with Triple Graph Grammars (High-level Work)</title>
		<link>https://biblioteca.sistedes.es/articulo/correctness-incremental-model-synchronizarion/</link>
		<pubDate>Sun, 24 Apr 2016 00:49:29 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=726</guid>
		<description></description>
		<content><![CDATA[Cloud computing enables elasticity - rapid provisioning and deprovisioning of computational re-sources. Elasticity allows cloud users to quickly adapt resource allocation to meet changes in theirworkloads. For cloud providers, elasticity complicates capacity management as the amount of re-sources that can be requested by users is unknown and can vary significantly over time. Overbookingtechniques allow providers to increase utilization of their data centers. For safe overbooking, cloudproviders need admission control mechanisms to handle the tradeoff between increased utilization(and revenue), and risk of exhausting resources, potentially resulting in penalty fees and/or lost cus-tomers. We propose a flexible approach (implemented with fuzzy logic programming) to admissioncontrol and the associated risk estimation. Our measures exploit different fuzzy logic operators inorder to model optimistic, realistic, and pessimistic behaviour under uncertainty. An experimen-tal evaluation confirm that our fuzzy admission control approach can significantly increase resourceutilization while minimizing the risk of exceeding the total available capacity.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>726</post_id>
		<post_date><![CDATA[2016-04-24 02:49:29]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 00:49:29]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[correctness-incremental-model-synchronizarion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="admission-control"><![CDATA[Admission Control]]></category>
		<category domain="post_tag" nicename="cloud-computing"><![CDATA[Cloud Computing]]></category>
		<category domain="post_tag" nicename="fuzzy-logic-programming"><![CDATA[Fuzzy Logic Programming]]></category>
		<category domain="post_tag" nicename="risk-assessment"><![CDATA[Risk Assessment]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[727]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Cloud computing enables elasticity - rapid provisioning and deprovisioning of computational re-sources. Elasticity allows cloud users to quickly adapt resource allocation to meet changes in theirworkloads. For cloud providers, elasticity complicates capacity management as the amount of re-sources that can be requested by users is unknown and can vary significantly over time. Overbookingtechniques allow providers to increase utilization of their data centers. For safe overbooking, cloudproviders need admission control mechanisms to handle the tradeoff between increased utilization(and revenue), and risk of exhausting resources, potentially resulting in penalty fees and/or lost cus-tomers. We propose a flexible approach (implemented with fuzzy logic programming) to admissioncontrol and the associated risk estimation. Our measures exploit different fuzzy logic operators inorder to model optimistic, realistic, and pessimistic behaviour under uncertainty. An experimen-tal evaluation confirm that our fuzzy admission control approach can significantly increase resourceutilization while minimizing the risk of exceeding the total available capacity.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Cloud Computing, Admission Control, Fuzzy Logic Programming, Risk Assessment]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Fernando Orejas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[orejas@lsi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Elvira Pino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pino@lsi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_wp_old_slug]]></meta_key>
			<meta_value><![CDATA[726]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modular DSLs for flexible analysis: An e-Motions reimplementation of Palladio (High-level Work)</title>
		<link>https://biblioteca.sistedes.es/articulo/modular-dsls-for-flexible-analysis-an-e-motions-reimplementation-of-palladio-high-level-work/</link>
		<pubDate>Sun, 24 Apr 2016 01:01:13 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=731</guid>
		<description></description>
		<content><![CDATA[We summarize the main contributions of the work [11] presented in the Modelling Foundations and Applications - 10th European Conference, ECMFA 2014. In [11], we addressed some of the limitations for extending and validating implementations of Non Functional Properties (NFP) analysis tools by presenting a modular, model-based partial reimplementation of one well-known analysis framework, namely the Palladio Architecture Simulator. We specified the key DSLs from Palladio in the e-Motions system, describing the basic simulation semantics as a set of graph transformation rules. Different properties to be analyzed are then encoded as separate, parameterized DSLs, independent of the definition of Palladio. These can then be composed with the base Palladio DSL to generate specific simulation environments. Models created in the Palladio IDE can be fed directly into this simulation environment for analysis. We demonstrate two main benefits of our approach: 1) The semantics of the simulation and the non-functional properties to be analysed are made explicit in the respective DSL specifications, and 2) because of the compositional definition, we can add definitions of new non-functional properties and their analyses.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>731</post_id>
		<post_date><![CDATA[2016-04-24 03:01:13]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 01:01:13]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modular-dsls-for-flexible-analysis-an-e-motions-reimplementation-of-palladio-high-level-work]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[732]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We summarize the main contributions of the work [11] presented in the Modelling Foundations and Applications - 10th European Conference, ECMFA 2014. In [11], we addressed some of the limitations for extending and validating implementations of Non Functional Properties (NFP) analysis tools by presenting a modular, model-based partial reimplementation of one well-known analysis framework, namely the Palladio Architecture Simulator. We specified the key DSLs from Palladio in the e-Motions system, describing the basic simulation semantics as a set of graph transformation rules. Different properties to be analyzed are then encoded as separate, parameterized DSLs, independent of the definition of Palladio. These can then be composed with the base Palladio DSL to generate specific simulation environments. Models created in the Palladio IDE can be fed directly into this simulation environment for analysis. We demonstrate two main benefits of our approach: 1) The semantics of the simulation and the non-functional properties to be analysed are made explicit in the respective DSL specifications, and 2) because of the compositional definition, we can add definitions of new non-functional properties and their analyses.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Moreno-Delgado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Málaga, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[amoreno@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Steffen Zschaler]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[King's College London, UK]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[szschaler@acm.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Troya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Vienna University of Technology, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ troya@big.tuwien.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[ Francisco Durán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Málaga, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[duran@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2014/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A fuzzy approach to cloud admission control for safe overbooking (High-level Work)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-fuzzy-approach-to-cloud-admission-control-for-safe-overbooking-high-level-work/</link>
		<pubDate>Sun, 24 Apr 2016 01:05:26 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=734</guid>
		<description></description>
		<content><![CDATA[Cloud computing enables elasticity - rapid provisioning and deprovisioning of computational resources. Elasticity allows cloud users to quickly adapt resource allocation to meet changes in their workloads. For cloud providers, elasticity complicates capacity management as the amount of resources that can be requested by users is unknown and can vary significantly over time. Overbooking techniques allow providers to increase utilization of their data centers. For safe overbooking, cloud providers need admission control mechanisms to handle the tradeoff between increased utilization (and revenue), and risk of exhausting resources, potentially resulting in penalty fees and/or lost customers. We propose a flexible approach (implemented with fuzzy logic programming) to admission control and the associated risk estimation. Our measures exploit different fuzzy logic operators in order to model optimistic, realistic, and pessimistic behaviour under uncertainty. An experimental evaluation confirm that our fuzzy admission control approach can significantly increase resource utilization while minimizing the risk of exceeding the total available capacity.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>734</post_id>
		<post_date><![CDATA[2016-04-24 03:05:26]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 01:05:26]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-fuzzy-approach-to-cloud-admission-control-for-safe-overbooking-high-level-work]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="admission-control"><![CDATA[Admission Control]]></category>
		<category domain="post_tag" nicename="cloud-computing"><![CDATA[Cloud Computing]]></category>
		<category domain="post_tag" nicename="fuzzy-logic-programming"><![CDATA[Fuzzy Logic Programming]]></category>
		<category domain="post_tag" nicename="risk-assessment"><![CDATA[Risk Assessment]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[735]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Cloud computing enables elasticity - rapid provisioning and deprovisioning of computational resources. Elasticity allows cloud users to quickly adapt resource allocation to meet changes in their workloads. For cloud providers, elasticity complicates capacity management as the amount of resources that can be requested by users is unknown and can vary significantly over time. Overbooking techniques allow providers to increase utilization of their data centers. For safe overbooking, cloud providers need admission control mechanisms to handle the tradeoff between increased utilization (and revenue), and risk of exhausting resources, potentially resulting in penalty fees and/or lost customers. We propose a flexible approach (implemented with fuzzy logic programming) to admission control and the associated risk estimation. Our measures exploit different fuzzy logic operators in order to model optimistic, realistic, and pessimistic behaviour under uncertainty. An experimental evaluation confirm that our fuzzy admission control approach can significantly increase resource utilization while minimizing the risk of exceeding the total available capacity.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Cloud Computing, Admission Control, Fuzzy Logic Programming, Risk Assessment]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Vázquez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dept. of Computing Systems. University of Castilla­La Mancha. Spain. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Carlos.Vazquez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ginés Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dept. of Computing Systems. University of Castilla­La Mancha. Spain. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Gines.Moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Luis Tomás]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dept. of Computing Science. Umea° University. Sweden.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[luis@cs.umu.se]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Johan Tordsson]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dept. of Computing Science. Umea° University. Sweden.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[tordsson@cs.umu.se]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2014/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An operational framework to reason about policy behavior in trust management systems (High-level Work)</title>
		<link>https://biblioteca.sistedes.es/articulo/an-operational-framework-to-reason-about-policy-behavior-in-trust-management-systems-high-level-work/</link>
		<pubDate>Sun, 24 Apr 2016 01:07:58 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=737</guid>
		<description></description>
		<content><![CDATA[In this paper we show that the logical framework proposed by Becker et al. to reason about security policy behavior in a trust management context can be captured by an operational framework that is based on the language proposed by Miller to deal with scoping and/or modules in logic programming in 1989. The framework of Becker et al. uses propositional Horn clauses to represent both policies and credentials, implications in clauses are interpreted in counterfactual logic, a Hilbert-style proof is defined and a system based on SAT is used to proof whether properties about credentials, permissions and policies are valid in trust management systems, i.e. formulas that are true for all possible policies. Our contribution is to show that instead of using a SAT system, this kind of validation can rely on the operational semantics (derivability relation) of Miller's language, which is very close to derivability in logic programs, opening up the possibility to extend Becker et al.'s framework to the more practical first order case since Miller's language is first order.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>737</post_id>
		<post_date><![CDATA[2016-04-24 03:07:58]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 01:07:58]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-operational-framework-to-reason-about-policy-behavior-in-trust-management-systems-high-level-work]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[738]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper we show that the logical framework proposed by Becker et al. to reason about security policy behavior in a trust management context can be captured by an operational framework that is based on the language proposed by Miller to deal with scoping and/or modules in logic programming in 1989. The framework of Becker et al. uses propositional Horn clauses to represent both policies and credentials, implications in clauses are interpreted in counterfactual logic, a Hilbert-style proof is defined and a system based on SAT is used to proof whether properties about credentials, permissions and policies are valid in trust management systems, i.e. formulas that are true for all possible policies. Our contribution is to show that instead of using a SAT system, this kind of validation can rely on the operational semantics (derivability relation) of Miller's language, which is very close to derivability in logic programs, opening up the possibility to extend Becker et al.'s framework to the more practical first order case since Miller's language is first order.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Edelmira Pasarella]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departament de Ciéncies de la Computació Universitat Polite`cnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[edelmira@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jorge Lobo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Institució Catalana de Recerca i Estudis Avanc¸ats (ICREA) Universitat Pompeu Fabra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jorge.lobo@upf.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2014/003]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Site-Level Template Extraction Based on Hyperlink Analysis (Original Work)</title>
		<link>https://biblioteca.sistedes.es/articulo/site-level-template-extraction-based-on-hyperlink-analysis-original-work/</link>
		<pubDate>Sun, 24 Apr 2016 01:11:42 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=740</guid>
		<description></description>
		<content><![CDATA[Web templates are one of the main development resources for website engineers. Templates allow them to increase productivity by plugin content into already formatted and prepared pagelets. For the final user templates are also useful, because they provide uniformity and a common look and feel for all webpages. However, from the point of view of crawlers and indexers, templates are an important problem, because templates usually contain irrelevant information such as advertisements, menus, and banners. Processing and storing this information is likely to lead to a waste of resources (storage space, bandwidth, etc.). It has been measured that templates represent between 40% and 50% of data on the Web. Therefore, identifying templates is essential for indexing tasks. In this work we propose a novel method for automatic template extraction that is based on similarity analysis between the DOM trees of a collection of webpages that are detected using menus information. Our implementation and experiments demonstrate the usefulness of the technique.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>740</post_id>
		<post_date><![CDATA[2016-04-24 03:11:42]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 01:11:42]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[site-level-template-extraction-based-on-hyperlink-analysis-original-work]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[741]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Web templates are one of the main development resources for website engineers. Templates allow them to increase productivity by plugin content into already formatted and prepared pagelets. For the final user templates are also useful, because they provide uniformity and a common look and feel for all webpages. However, from the point of view of crawlers and indexers, templates are an important problem, because templates usually contain irrelevant information such as advertisements, menus, and banners. Processing and storing this information is likely to lead to a waste of resources (storage space, bandwidth, etc.). It has been measured that templates represent between 40% and 50% of data on the Web. Therefore, identifying templates is essential for indexing tasks. In this work we propose a novel method for automatic template extraction that is based on similarity analysis between the DOM trees of a collection of webpages that are detected using menus information. Our implementation and experiments demonstrate the usefulness of the technique.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julián Alarte]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universitat Politécnica de Valéncia, Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalarte@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David Insa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universitat Politécnica de Valéncia, Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[dinsa@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Josep Silva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universitat Politécnica de Valéncia, Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jsilva@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Salvador Tamarit]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Babel Research Group Universidad Politécnica de Madrid, Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[stamarit@babel.ls.fi.upm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Space Consumption Analysis by Abstract Interpretation: Reductivity Properties (High-level Work)</title>
		<link>https://biblioteca.sistedes.es/articulo/space-consumption-analysis-by-abstract-interpretation-reductivity-properties-high-level-work/</link>
		<pubDate>Sun, 24 Apr 2016 01:14:38 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=743</guid>
		<description></description>
		<content><![CDATA[In a previous paper we presented an abstract interpretation-based static analysis for inferring heap and stack memory consumption in a functional language. The language, called Safe, is eager and firstorder, and its memory management system is based on heap regions instead of the more conventional approach of having a garbage collector.
In this paper we concentrate on an important property of our analysis, namely that the inferred bounds are reductive under certain reasonable conditions. This means that by iterating the analysis using as input the prior inferred bound, we can get tighter and tighter bounds, all of them correct. In some cases, even the exact bound is obtained.
The paper includes several examples and case studies illustrating in detail the reductivity property of the inferred bounds.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>743</post_id>
		<post_date><![CDATA[2016-04-24 03:14:38]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 01:14:38]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[space-consumption-analysis-by-abstract-interpretation-reductivity-properties-high-level-work]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[744]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In a previous paper we presented an abstract interpretation-based static analysis for inferring heap and stack memory consumption in a functional language. The language, called Safe, is eager and firstorder, and its memory management system is based on heap regions instead of the more conventional approach of having a garbage collector.
In this paper we concentrate on an important property of our analysis, namely that the inferred bounds are reductive under certain reasonable conditions. This means that by iterating the analysis using as input the prior inferred bound, we can get tighter and tighter bounds, all of them correct. In some cases, even the exact bound is obtained.
The paper includes several examples and case studies illustrating in detail the reductivity property of the inferred bounds.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel Montenegro ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[montenegro@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Clara Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[csegura@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ricardo Peña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ricardo@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2014/002]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Improving the Deductive System DES with Persistence by Using SQL DBMS&#039;s (Original Work)</title>
		<link>https://biblioteca.sistedes.es/articulo/improving-the-deductive-system-des-with-persistence-by-using-sql-dbmss-original-work/</link>
		<pubDate>Sun, 24 Apr 2016 01:16:34 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=746</guid>
		<description></description>
		<content><![CDATA[This work presents how persistent predicates have been included in the in-memory deductive system DES by relying on external SQL database management systems. We introduce how persistence is supported from a user-point of view and the possible applications the system opens up, as the deductive expressive power is projected to relational databases. Also, we describe how it is possible to intermix computations of the deductive engine and the external database, explaining its implementation and some optimizations. Finally, a performance analysis is undertaken, comparing the system with current relational database systems.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>746</post_id>
		<post_date><![CDATA[2016-04-24 03:16:34]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 01:16:34]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[improving-the-deductive-system-des-with-persistence-by-using-sql-dbmss-original-work]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[747]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This work presents how persistent predicates have been included in the in-memory deductive system DES by relying on external SQL database management systems. We introduce how persistence is supported from a user-point of view and the possible applications the system opens up, as the deductive expressive power is projected to relational databases. Also, we describe how it is possible to intermix computations of the deductive engine and the external database, explaining its implementation and some optimizations. Finally, a performance analysis is undertaken, comparing the system with current relational database systems.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Fernando Sáenz-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Programación Declarativa (GPD) Dept. Ingenier´ia del Software e Inteligencia Artificial Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ fernan@sip.ucm.es ]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Software Testing and/or Software Monitoring: Differences and Commonalities</title>
		<link>https://biblioteca.sistedes.es/articulo/software-testing-andor-software-monitoring-differences-and-commonalities/</link>
		<pubDate>Sun, 24 Apr 2016 01:26:10 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=781</guid>
		<description></description>
		<content><![CDATA[Validation is an essential part of the software life cycle. The actual functional and non-functional behaviour of an application needs to be checked against the expected or intended behaviour. Both testing and monitoring are widely used approaches for this purpose. More traditionally testing is considered as a technique for fault removal and forecasting during development. Monitoring is instead conceived for run-time observation of deployed software. Testing and monitoring approaches are usually contrasted as being, respectively, in-the-laboratory vs. in-the-field, and active vs. passive. In this talk I will overview concepts and techniques for software testing and monitoring, and will discuss how for modern pervasive and dynamic software systems the two approaches tend to converge in combined and synergic ways.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>781</post_id>
		<post_date><![CDATA[2016-04-24 03:26:10]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 01:26:10]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[software-testing-andor-software-monitoring-differences-and-commonalities]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[782]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Validation is an essential part of the software life cycle. The actual functional and non-functional behaviour of an application needs to be checked against the expected or intended behaviour. Both testing and monitoring are widely used approaches for this purpose. More traditionally testing is considered as a technique for fault removal and forecasting during development. Monitoring is instead conceived for run-time observation of deployed software. Testing and monitoring approaches are usually contrasted as being, respectively, in-the-laboratory vs. in-the-field, and active vs. passive. In this talk I will overview concepts and techniques for software testing and monitoring, and will discuss how for modern pervasive and dynamic software systems the two approaches tend to converge in combined and synergic ways.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonia Bertolino ISTI-CNR]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Via Moruzzi, 1 Pisa, Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[antonia.bertolino@isti.cnr.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/052]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automatic Identification of Service Candidates from Business Process Models</title>
		<link>https://biblioteca.sistedes.es/articulo/automatic-identification-of-service-candidates-from-business-process-models/</link>
		<pubDate>Sun, 24 Apr 2016 01:27:57 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=784</guid>
		<description></description>
		<content><![CDATA[Business process models play an important role in the design and analysis of business operations. For this reason, many companies develop and maintain repositories in which models of business processes are centrally stored. In this talk, I will present analysis techniques for automatically extracting knowledge from such process repositories. The focus will be on leveraging these models for automatically identifying service candidates. Results are presented of applying these techniques on various process repositories from practice.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>784</post_id>
		<post_date><![CDATA[2016-04-24 03:27:57]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 01:27:57]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automatic-identification-of-service-candidates-from-business-process-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[785]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Business process models play an important role in the design and analysis of business operations. For this reason, many companies develop and maintain repositories in which models of business processes are centrally stored. In this talk, I will present analysis techniques for automatically extracting knowledge from such process repositories. The focus will be on leveraging these models for automatically identifying service candidates. Results are presented of applying these techniques on various process repositories from practice.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jan Mendling ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Wirtschaftsuniversität Wien Welthandelsplatz 1 1020 Vienna, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jan.mendling@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/051]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Actualización incremental de grafos RDF a partir de bases de datos relacionales</title>
		<link>https://biblioteca.sistedes.es/articulo/actualizacion-incremental-de-grafos-rdf-a-partir-de-bases-de-datos-relacionales/</link>
		<pubDate>Sun, 24 Apr 2016 01:32:24 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=787</guid>
		<description></description>
		<content><![CDATA[El modelo de datos relacional constituye el paradigma utilizado con mayor frecuencia por los sistemas operacionales que actualmente utilizan las empresas para gestionar sus procesos. Por otra parte, las tecnologías de la web semántica han logrado un importante impulso en los últimos años. Se han desarrollado estándares tales como Resource Description Framework (RDF) y Web Ontology Language (OWL). RDF constituye el modelo de datos utilizado para la publicación y enlazado de datos estructurados en la Web, un enfoque denominado datos vinculados (Linked Data) y que constituye la base sobre la que se sustenta la Web Semántica. Estudios recientes demuestran que es posible trasladar el modelo de datos relacional al modelo de datos basado en grafos RDF. Por tal motivo es posible realizar operaciones de inserción, actualización y eliminación en ambos sentidos relacional-grafo y grafo-relacional. Aproximaciones existentes solo se suscriben a la actualización total de los grafos RDF, es decir, un cambio generado en la base de datos relacional implica que sea necesario generar nuevamente el grafo RDF en su totalidad, incurriendo en altos costos de tiempo y recursos computaciones. Es por tanto necesario la definición de nuevos métodos que detecten estas actualizaciones y luego las trasladen al modelo de datos RDF. En este artículo se propone un modelo para la actualización incremental de grafos RDF a partir de la detección de cambios en las bases de datos relacionales, evitando así la generación total del grafo RDF.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>787</post_id>
		<post_date><![CDATA[2016-04-24 03:32:24]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 01:32:24]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[actualizacion-incremental-de-grafos-rdf-a-partir-de-bases-de-datos-relacionales]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="actualizacion-incremental"><![CDATA[actualización incremental]]></category>
		<category domain="post_tag" nicename="modelo-rdf"><![CDATA[modelo RDF]]></category>
		<category domain="post_tag" nicename="modelo-relacional"><![CDATA[modelo relacional]]></category>
		<category domain="post_tag" nicename="web-semantica"><![CDATA[Web Semántica]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[788]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El modelo de datos relacional constituye el paradigma utilizado con mayor frecuencia por los sistemas operacionales que actualmente utilizan las empresas para gestionar sus procesos. Por otra parte, las tecnologías de la web semántica han logrado un importante impulso en los últimos años. Se han desarrollado estándares tales como Resource Description Framework (RDF) y Web Ontology Language (OWL). RDF constituye el modelo de datos utilizado para la publicación y enlazado de datos estructurados en la Web, un enfoque denominado datos vinculados (Linked Data) y que constituye la base sobre la que se sustenta la Web Semántica. Estudios recientes demuestran que es posible trasladar el modelo de datos relacional al modelo de datos basado en grafos RDF. Por tal motivo es posible realizar operaciones de inserción, actualización y eliminación en ambos sentidos relacional-grafo y grafo-relacional. Aproximaciones existentes solo se suscriben a la actualización total de los grafos RDF, es decir, un cambio generado en la base de datos relacional implica que sea necesario generar nuevamente el grafo RDF en su totalidad, incurriendo en altos costos de tiempo y recursos computaciones. Es por tanto necesario la definición de nuevos métodos que detecten estas actualizaciones y luego las trasladen al modelo de datos RDF. En este artículo se propone un modelo para la actualización incremental de grafos RDF a partir de la detección de cambios en las bases de datos relacionales, evitando así la generación total del grafo RDF.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[actualización incremental, modelo relacional, modelo RDF, Web Semántica]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Liudmila Reyes-Álvarez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de las Ciencias Informáticas, Carretera a San Antonio de los Baños, Km. 2 1/2. Torrens, La Lisa. La Habana, Cuba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[lreyes, @uci.cu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Yusniel Hidalgo-Delgado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de las Ciencias Informáticas, Carretera a San Antonio de los Baños, Km. 2 1/2. Torrens, La Lisa. La Habana, Cuba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Yhdelgado@uci.cu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Katerín Martínez-Rojas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de las Ciencias Informáticas, Carretera a San Antonio de los Baños, Km. 2 1/2. Torrens, La Lisa. La Habana, Cuba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[kmrojas@estudiantes.uci.cu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[María del Mar Roldán-García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Ciencias de la Computación, Universidad de Málaga, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mmar@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[José F. Aldana-Montes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Ciencias de la Computación, Universidad de Málaga, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[mmar@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Geração Automática de Esqueletos para Sistemas ETL</title>
		<link>https://biblioteca.sistedes.es/articulo/geracao-automatica-de-esqueletos-para-sistemas-etl/</link>
		<pubDate>Sun, 24 Apr 2016 01:34:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=790</guid>
		<description></description>
		<content><![CDATA[O projeto de um sistema de povoamento obedece a regras de concepção e implementação bastante específicas, bem como integra um variadíssimo leque de regras de trabalho abrangendo um grande número de tarefas de extração, transformação e carregamento de dados. Com base em experiências práticas de aplicação, hoje sabemos que uma abordagem orientada por padrões de ETL facilita o seu projeto, desenvolvimento e exploração, além de facilitar muito a sua compreensão. Neste trabalho, abordamos esse tipo de aproximação e apresentamos uma forma de produzir automaticamente "esqueletos" para sistemas de ETL, a partir da sua especificação em redes de Petri coloridas. Além de expormos a base de definição e construção de padrões de ETL, bem como a sua especificação em redes de Petri coloridas, apresentamos e discutimos também a forma como podemos providenciar de forma automática a implementação física dos referidos esqueletos]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>790</post_id>
		<post_date><![CDATA[2016-04-24 03:34:51]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 01:34:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[geracao-automatica-de-esqueletos-para-sistemas-etl]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="data-warehousing-systems"><![CDATA[Data Warehousing Systems]]></category>
		<category domain="post_tag" nicename="logica-e-fisica-de-sistemas-de-etl"><![CDATA[Lógica e Física de Sistemas de ETL]]></category>
		<category domain="post_tag" nicename="modelacao-conceptual"><![CDATA[Modelação Conceptual]]></category>
		<category domain="post_tag" nicename="redes-de-petri-coloridas-e-kettle"><![CDATA[Redes de Petri Coloridas e Kettle]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[791]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[O projeto de um sistema de povoamento obedece a regras de concepção e implementação bastante específicas, bem como integra um variadíssimo leque de regras de trabalho abrangendo um grande número de tarefas de extração, transformação e carregamento de dados. Com base em experiências práticas de aplicação, hoje sabemos que uma abordagem orientada por padrões de ETL facilita o seu projeto, desenvolvimento e exploração, além de facilitar muito a sua compreensão. Neste trabalho, abordamos esse tipo de aproximação e apresentamos uma forma de produzir automaticamente "esqueletos" para sistemas de ETL, a partir da sua especificação em redes de Petri coloridas. Além de expormos a base de definição e construção de padrões de ETL, bem como a sua especificação em redes de Petri coloridas, apresentamos e discutimos também a forma como podemos providenciar de forma automática a implementação física dos referidos esqueletos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Data Warehousing Systems, Modelação Conceptual, Lógica e Física de Sistemas de ETL, Redes de Petri Coloridas e Kettle]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel Guimarães]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro de I&D ALGORITMI Departamento de Informática, Escola de Engenharia, Universidade do Minho Campus de Gualtar, 4710-057 Braga, PORTUGAL]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Orlando Belo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro de I&D ALGORITMI Departamento de Informática, Escola de Engenharia, Universidade do Minho Campus de Gualtar, 4710-057 Braga, PORTUGAL]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modelado multidimensional para la visualización integrada de Big Data en plataformas de Inteligencia de Negocio</title>
		<link>https://biblioteca.sistedes.es/articulo/modelado-multidimensional-para-la-visualizacion-integrada-de-big-data-en-plataformas-de-inteligencia-de-negocio/</link>
		<pubDate>Sun, 24 Apr 2016 01:39:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=793</guid>
		<description></description>
		<content><![CDATA[La gran cantidad de información disponible y así como su heterogeneidad han sobrepasado la capacidad de las tecnologías actuales de gestión de datos. El tratamiento con grandes volúmenes de datos estructurados y no estructurados, a menudo referido como Big Data, es un tema de investigación de actualidad así como un importante desafío tecnológico. En este artículo, se presenta un enfoque con el objetivo de permitir consultas OLAP a través de diferentes y heterogéneos orígenes de datos asistidos con herramientas de visualización que faciliten el tratamiento de los mismos. Nuestro enfoque está basado en el paradigma MapReduce, permitiendo la integración de diferentes formatos como el novedoso formato RDF Data Cube. Las principales contribuciones de nuestro enfoque son la capacidad de consultar y visualizar distintas fuentes de información, manteniendo al mismo tiempo, una visión integrada y completa de los datos disponibles, así como una sencilla interfaz de visualización de Big Data. El presente artículo también analiza las ventajas y desventajas, así como los retos de implementación que presenta este enfoque y, finaliza con un caso de estudio mostrando las ventajas de la aproximación presentada.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>793</post_id>
		<post_date><![CDATA[2016-04-24 03:39:49]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 01:39:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modelado-multidimensional-para-la-visualizacion-integrada-de-big-data-en-plataformas-de-inteligencia-de-negocio]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[794]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La gran cantidad de información disponible y así como su heterogeneidad han sobrepasado la capacidad de las tecnologías actuales de gestión de datos. El tratamiento con grandes volúmenes de datos estructurados y no estructurados, a menudo referido como Big Data, es un tema de investigación de actualidad así como un importante desafío tecnológico. En este artículo, se presenta un enfoque con el objetivo de permitir consultas OLAP a través de diferentes y heterogéneos orígenes de datos asistidos con herramientas de visualización que faciliten el tratamiento de los mismos. Nuestro enfoque está basado en el paradigma MapReduce, permitiendo la integración de diferentes formatos como el novedoso formato RDF Data Cube. Las principales contribuciones de nuestro enfoque son la capacidad de consultar y visualizar distintas fuentes de información, manteniendo al mismo tiempo, una visión integrada y completa de los datos disponibles, así como una sencilla interfaz de visualización de Big Data. El presente artículo también analiza las ventajas y desventajas, así como los retos de implementación que presenta este enfoque y, finaliza con un caso de estudio mostrando las ventajas de la aproximación presentada.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Roberto Tardío]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos  Universidad de Alicante, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rtardio@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Elisa de Gregorio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos  Universidad de Alicante, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[edg12@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alejandro Maté]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos  Universidad de Alicante, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[amate@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Rafa Muñoz-Terol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos  Universidad de Alicante, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[rafamt@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Hector Llorens]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos  Universidad de Alicante, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[hllorens@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Juan Trujillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos  Universidad de Alicante, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[jtrujillo@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[David Gil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[dgil@dtic.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Lucentia Research Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/003]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Bioqueries a Social Community for SPARQL queries in Life Sciencess</title>
		<link>https://biblioteca.sistedes.es/articulo/bioqueries-a-social-community-for-sparql-queries-in-life-sciencess/</link>
		<pubDate>Sun, 24 Apr 2016 01:43:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=797</guid>
		<description></description>
		<content><![CDATA[Life Sciences have emerged as a key domain in the Linked Data community because of the diversity of data semantics and formats available through a great variety of databases and web technologies. Unfortunately, bioinformaticians are not exploiting the full potential of this technology and experts in Life Sciences have real problems to discover, understand and devise how to take advantage of these interlinked data. In this context, we have implemented Bioqueries, a wiki-based portal that is aimed at community building around biological Linked Data (http://bioqueries.uma.es/). This space offers a collaborative platform in which users can create, modify, execute and share biological SPARQL queries.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>797</post_id>
		<post_date><![CDATA[2016-04-24 03:43:54]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 01:43:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[bioqueries-a-social-community-for-sparql-queries-in-life-sciencess]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[798]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Life Sciences have emerged as a key domain in the Linked Data community because of the diversity of data semantics and formats available through a great variety of databases and web technologies. Unfortunately, bioinformaticians are not exploiting the full potential of this technology and experts in Life Sciences have real problems to discover, understand and devise how to take advantage of these interlinked data. In this context, we have implemented Bioqueries, a wiki-based portal that is aimed at community building around biological Linked Data (http://bioqueries.uma.es/). This space offers a collaborative platform in which users can create, modify, execute and share biological SPARQL queries.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Jesús García Godoy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Lenguajes y Ciencias de la Computación, Universidad de Málaga, Bulevar Louis Pasteur 35, M´alaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mjgarciag@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Esteban López-Camacho]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Lenguajes y Ciencias de la Computación, Universidad de Málaga, Bulevar Louis Pasteur 35, M´alaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[esteban@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ismael Navas-Delgado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Lenguajes y Ciencias de la Computación, Universidad de Málaga, Bulevar Louis Pasteur 35, M´alaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ismael@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José F. Aldana-Montes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Lenguajes y Ciencias de la Computación, Universidad de Málaga, Bulevar Louis Pasteur 35, M´alaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jfam@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/002]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Adding Semantic Modules to improve Goal-Oriented Analysis of Data Warehouses using I-star</title>
		<link>https://biblioteca.sistedes.es/articulo/adding-semantic-modules-to-improve-goal-oriented-analysis-of-data-warehouses-using-i-star/</link>
		<pubDate>Sun, 24 Apr 2016 01:46:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=800</guid>
		<description></description>
		<content><![CDATA[Requirements elicitation and analysis is a key step in designing and maintaining data warehouses. In order to better support this step, in this paper we (i) propose an extension of the basic goaloriented metamodel in order to include semantic modules, (ii) include a description of each step followed in the process, and (iii) evaluate it by means of an empirical experiment.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>800</post_id>
		<post_date><![CDATA[2016-04-24 03:46:54]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 01:46:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[adding-semantic-modules-to-improve-goal-oriented-analysis-of-data-warehouses-using-i-star]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="data-warehouses"><![CDATA[Data warehouses]]></category>
		<category domain="post_tag" nicename="i-star"><![CDATA[i-star]]></category>
		<category domain="post_tag" nicename="user-requirements"><![CDATA[user requirements]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[801]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Requirements elicitation and analysis is a key step in designing and maintaining data warehouses. In order to better support this step, in this paper we (i) propose an extension of the basic goaloriented metamodel in order to include semantic modules, (ii) include a description of each step followed in the process, and (iii) evaluate it by means of an empirical experiment.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Data warehouses, user requirements, i-star]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alejandro Maté]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Lucentia Research Group, Department of Software and Computing Systems, University of Alicante, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[amate@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Trujillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Lucentia Research Group, Department of Software and Computing Systems, University of Alicante, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jtrujillo@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Xavier Franch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[BarcelonaTech, Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[franch@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/001]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modelado de calidad de contexto con MLContext</title>
		<link>https://biblioteca.sistedes.es/articulo/modelado-de-calidad-de-contexto-con-mlcontext/</link>
		<pubDate>Sun, 24 Apr 2016 01:50:37 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=803</guid>
		<description></description>
		<content><![CDATA[Un aspecto crucial de los sistemas context-aware es la calidad de la información de contexto obtenida de diversas fuentes. Esta información puede ser incompleta, imprecisa o ambigua. Por ello debe ir acompañada de otra información que describa su calidad (QoC, Quality of Context) con el fin de determinar si puede ser usada. MLContext es un lenguaje específico del dominio para el modelado del contexto que ha sido creado siguiendo los principios de MDE (Model-Driven Engineering). En este artículo se describe una extensión de MLContext para modelar QoC por medio de la definición de parámetros de calidad de los sensores. Se presenta un escenario y se describe cómo crear su modelo del contexto teniendo en cuenta la calidad. El modelo creado es validado con y sin parámetros de calidad, comparando los resultados y ofreciendo las conclusiones sobre el enfoque planteado.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>803</post_id>
		<post_date><![CDATA[2016-04-24 03:50:37]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 01:50:37]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modelado-de-calidad-de-contexto-con-mlcontext]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="calidad-del-contexto"><![CDATA[Calidad del contexto]]></category>
		<category domain="post_tag" nicename="context-aware"><![CDATA[Context-aware]]></category>
		<category domain="post_tag" nicename="ingenieria-de-software-dirigida-por-modelos"><![CDATA[Ingeniería de Software Dirigida por Modelos]]></category>
		<category domain="post_tag" nicename="modelado-del-contexto"><![CDATA[Modelado del Contexto]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Un aspecto crucial de los sistemas context-aware es la calidad de la información de contexto obtenida de diversas fuentes. Esta información puede ser incompleta, imprecisa o ambigua. Por ello debe ir acompañada de otra información que describa su calidad (QoC, Quality of Context) con el fin de determinar si puede ser usada. MLContext es un lenguaje específico del dominio para el modelado del contexto que ha sido creado siguiendo los principios de MDE (Model-Driven Engineering). En este artículo se describe una extensión de MLContext para modelar QoC por medio de la definición de parámetros de calidad de los sensores. Se presenta un escenario y se describe cómo crear su modelo del contexto teniendo en cuenta la calidad. El modelo creado es validado con y sin parámetros de calidad, comparando los resultados y ofreciendo las conclusiones sobre el enfoque planteado.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Modelado del Contexto, Calidad del contexto, Context-aware, Ingeniería de Software Dirigida por Modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José R. Hoyos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia, Facultad de Informática, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jose.hoyos@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jesús García-Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia, Facultad de Informática, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jmolina, juanbot@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan A. Botía]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Middlesex University, London, UK]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[.BotiaBlaya@mdx.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/012]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una solución MDE para crear aplicaciones basadas en mensajes instantaneos a través de Twitter</title>
		<link>https://biblioteca.sistedes.es/articulo/una-solucion-mde-para-crear-aplicaciones-basadas-en-mensajes-instantaneos-a-traves-de-twitter/</link>
		<pubDate>Sun, 24 Apr 2016 01:56:35 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=806</guid>
		<description></description>
		<content><![CDATA[Las redes sociales se utilizan para todo tipo de propósitos, en cualquier momento y lugar, gracias al auge de los dispositivos móviles. La capacidad de envío de mensajes (públicos o privados) de estos servicios se usa hoy día, de manera habitual, para segmentar al conjunto de usuarios según preferencias, opiniones y eventos. Esto no pasa desapercibido para empresas o servicios que analizan datos mediante la nueva figura del llamado social media manager. Como ejemplo de servicio, debido a su carácter eminentemente público, los tweets de Twitter pueden ser vistos como un mecanismo de díalogo entre usuarios y aplicaciones informáticas. Resaltando esta funcionalidad, proponemos el concepto de aplicación basada en mensajes instantáneos, una aplicacíon que usa los mensajes emitidos por los usuarios como un medio para obtener comandos de entrada y emitir salidas. Para ello, usaremos las ventajas del Desarrollo de Software Dirigido por Modelos para la construccíon de un prototipo (llamado Twiagle) que permita de una forma clara y concisa, mediante lenguajes de dominio específico: (i) detectar patrones en los mensajes de los usuarios, y (ii) construir aplicaciones simples mediante acciones, tales como consultas a los mensajes seleccionados y síntesis de mensajes.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>806</post_id>
		<post_date><![CDATA[2016-04-24 03:56:35]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 01:56:35]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-solucion-mde-para-crear-aplicaciones-basadas-en-mensajes-instantaneos-a-traves-de-twitter]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="desarrollo-de-software-dirigido-por-modelos"><![CDATA[Desarrollo de Software Dirigido por Modelos]]></category>
		<category domain="post_tag" nicename="ingenieria-basada-en-la-web"><![CDATA[Ingeniería basada en la Web]]></category>
		<category domain="post_tag" nicename="interfaces-de-usuario-basadas-en-mensajes"><![CDATA[Interfaces de Usuario basadas en Mensajes]]></category>
		<category domain="post_tag" nicename="lenguajes-de-dominio-especifico"><![CDATA[Lenguajes de Dominio Específico]]></category>
		<category domain="post_tag" nicename="twitter"><![CDATA[Twitter.]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[807]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las redes sociales se utilizan para todo tipo de propósitos, en cualquier momento y lugar, gracias al auge de los dispositivos móviles. La capacidad de envío de mensajes (públicos o privados) de estos servicios se usa hoy día, de manera habitual, para segmentar al conjunto de usuarios según preferencias, opiniones y eventos. Esto no pasa desapercibido para empresas o servicios que analizan datos mediante la nueva figura del llamado social media manager. Como ejemplo de servicio, debido a su carácter eminentemente público, los tweets de Twitter pueden ser vistos como un mecanismo de díalogo entre usuarios y aplicaciones informáticas. Resaltando esta funcionalidad, proponemos el concepto de aplicación basada en mensajes instantáneos, una aplicacíon que usa los mensajes emitidos por los usuarios como un medio para obtener comandos de entrada y emitir salidas. Para ello, usaremos las ventajas del Desarrollo de Software Dirigido por Modelos para la construccíon de un prototipo (llamado Twiagle) que permita de una forma clara y concisa, mediante lenguajes de dominio específico: (i) detectar patrones en los mensajes de los usuarios, y (ii) construir aplicaciones simples mediante acciones, tales como consultas a los mensajes seleccionados y síntesis de mensajes.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Desarrollo de Software Dirigido por Modelos, Ingeniería basada en la Web, Lenguajes de Dominio Específico, Interfaces de Usuario basadas en Mensajes, Twitter]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Angel Mora Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Modelado e Ingeniería del Software (http://www.miso.es) Departamento de Informática Universidad Autónoma de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Angel.MoraS@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan de Lara ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Modelado e Ingeniería del Software (http://www.miso.es) Departamento de Informática Universidad Autónoma de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Juan.deLara@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesús Sánchez Cuadrado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Modelado e Ingeniería del Software (http://www.miso.es) Departamento de Informática Universidad Autónoma de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Jesus.Sanchez.Cuadrado@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/011]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Simulating Mobile Agents in Vehicular Networks</title>
		<link>https://biblioteca.sistedes.es/articulo/simulating-mobile-agents-in-vehicular-networks/</link>
		<pubDate>Sun, 24 Apr 2016 01:59:03 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=809</guid>
		<description></description>
		<content><![CDATA[In the next years, vehicular ad hoc networks (VANETs) are expected to become a reality and a great number of interesting applications for drivers and passengers will be developed (related to safety, comfort, and entertainment). In all these applications, the acquisition, management and an efficient and effective exchange of data will be key issues. Therefore, significant data management challenges arise in this context. We argue that mobile agent technology could play an important role as a middleware for the development of applications for vehicular networks, as they naturally support disconnected operations and distributed data management. Overall, a development of solutions based on agents that autonomously take decisions may be promising. A significant problem arises when we need to evaluate a data management approach for vehicular networks. Deploying it in the real-world in order to evaluate the proposal with real cars is impractical and very expensive, and so field tests are limited to very small-scale and controlled scenarios, mainly as a proof of concept. Instead, simulators are usually used for experimental evaluation. However, existing simulators for vehicular networks do not directly support testing data management techniques based on the use of mobile agents. In this paper, we present a simulator that offers interesting functionalities for that context. The simulator has been developed in a quite generic and extensible way, in order to facilitate its use in a variety of scenarios to test different data management approaches.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>809</post_id>
		<post_date><![CDATA[2016-04-24 03:59:03]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 01:59:03]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[simulating-mobile-agents-in-vehicular-networks]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mobile-ad-hoc-networks"><![CDATA[mobile ad-hoc networks]]></category>
		<category domain="post_tag" nicename="mobile-agents"><![CDATA[mobile agents]]></category>
		<category domain="post_tag" nicename="mobile-computing"><![CDATA[mobile computing]]></category>
		<category domain="post_tag" nicename="simulations"><![CDATA[simulations]]></category>
		<category domain="post_tag" nicename="vehicular-networks"><![CDATA[vehicular networks]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[810]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In the next years, vehicular ad hoc networks (VANETs) are expected to become a reality and a great number of interesting applications for drivers and passengers will be developed (related to safety, comfort, and entertainment). In all these applications, the acquisition, management and an efficient and effective exchange of data will be key issues. Therefore, significant data management challenges arise in this context. We argue that mobile agent technology could play an important role as a middleware for the development of applications for vehicular networks, as they naturally support disconnected operations and distributed data management. Overall, a development of solutions based on agents that autonomously take decisions may be promising. A significant problem arises when we need to evaluate a data management approach for vehicular networks. Deploying it in the real-world in order to evaluate the proposal with real cars is impractical and very expensive, and so field tests are limited to very small-scale and controlled scenarios, mainly as a proof of concept. Instead, simulators are usually used for experimental evaluation. However, existing simulators for vehicular networks do not directly support testing data management techniques based on the use of mobile agents. In this paper, we present a simulator that offers interesting functionalities for that context. The simulator has been developed in a quite generic and extensible way, in order to facilitate its use in a variety of scenarios to test different data management approaches.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[vehicular networks, mobile agents, simulations, mobile computing, mobile ad-hoc networks]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Oscar Urra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science and System Engineering University of Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ourra@ita.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Ilarri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science and System Engineering University of Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[silarri@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Eduardo López]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science and System Engineering University of Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[eduardologa@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/010]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Context-Aware Recommendations in Mobile Environments</title>
		<link>https://biblioteca.sistedes.es/articulo/context-aware-recommendations-in-mobile-environments/</link>
		<pubDate>Sun, 24 Apr 2016 02:03:40 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=812</guid>
		<description></description>
		<content><![CDATA[Traditional recommendation systems offer relevant items (e.g., books, movies, music, etc.) to users, but they are not designed for mobile environments. In those environments, the context (e.g., the location, the time, the weather, the presence of other people, etc.) and the movements of the users may be important factors to obtain relevant and helpful recommendations. The emergence of context-aware recommendation systems has prompted the growth of recommendation algorithms that incorporate context information. However, most existing research in this field considers only static context information, despite the fact that exploiting dynamic context information would be very helpful in mobile computing scenarios. Moreover, the design and implementation of generic frameworks to support an easy development of context-aware recommendation systems has been relatively unexplored. In this paper, we present our ongoing work to develop a context-aware recommendation framework for distributed and mobile environments, which will allow suggesting relevant items to mobile users.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>812</post_id>
		<post_date><![CDATA[2016-04-24 04:03:40]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 02:03:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[context-aware-recommendations-in-mobile-environments]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="context-awareness"><![CDATA[context-awareness]]></category>
		<category domain="post_tag" nicename="mobile-computing"><![CDATA[mobile computing]]></category>
		<category domain="post_tag" nicename="recommendation-systems"><![CDATA[recommendation systems]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[813]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Traditional recommendation systems offer relevant items (e.g., books, movies, music, etc.) to users, but they are not designed for mobile environments. In those environments, the context (e.g., the location, the time, the weather, the presence of other people, etc.) and the movements of the users may be important factors to obtain relevant and helpful recommendations. The emergence of context-aware recommendation systems has prompted the growth of recommendation algorithms that incorporate context information. However, most existing research in this field considers only static context information, despite the fact that exploiting dynamic context information would be very helpful in mobile computing scenarios. Moreover, the design and implementation of generic frameworks to support an easy development of context-aware recommendation systems has been relatively unexplored. In this paper, we present our ongoing work to develop a context-aware recommendation framework for distributed and mobile environments, which will allow suggesting relevant items to mobile users.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[context-awareness, recommendation systems, mobile computing]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María del Carmen Rodríguez-Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science and Systems Engineering University of Zaragoza, Zaragoza, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[692383@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Ilarri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science and Systems Engineering University of Zaragoza, Zaragoza, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[silarri@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/009]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Herramienta Colaborativa Multidispositivo para la Edición de Modelos basada en EMF</title>
		<link>https://biblioteca.sistedes.es/articulo/herramienta-colaborativa-multidispositivo-para-la-edicion-de-modelos-basada-en-emf/</link>
		<pubDate>Sun, 24 Apr 2016 02:07:20 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=815</guid>
		<description></description>
		<content><![CDATA[En este trabajo se presenta un editor de modelos que permitirá el trabajo colaborativo con modelos pertenecientes a cualquier metamodelo creado con EMF. Además, este editor permite su uso desde una gran variedad de dispositivos, facilitando una colaboración efectiva gracias al awareness que proporciona tanto sobre el propio proceso de edición como de los usuarios que en ella colaboran. Además, la implementación como servicios webs de la de gestión de modelos EMF y del soporte a características de awareness permite su reutilización en futuras aplicaciones.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>815</post_id>
		<post_date><![CDATA[2016-04-24 04:07:20]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 02:07:20]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[herramienta-colaborativa-multidispositivo-para-la-edicion-de-modelos-basada-en-emf]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="colaboracion"><![CDATA[colaboración]]></category>
		<category domain="post_tag" nicename="ditor-modelos"><![CDATA[ditor modelos]]></category>
		<category domain="post_tag" nicename="emf"><![CDATA[EMF]]></category>
		<category domain="post_tag" nicename="multidispositivo"><![CDATA[multidispositivo]]></category>
		<category domain="post_tag" nicename="servicio-web"><![CDATA[servicio web]]></category>
		<category domain="post_tag" nicename="workspace-awareness"><![CDATA[Workspace Awareness]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[816]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este trabajo se presenta un editor de modelos que permitirá el trabajo colaborativo con modelos pertenecientes a cualquier metamodelo creado con EMF. Además, este editor permite su uso desde una gran variedad de dispositivos, facilitando una colaboración efectiva gracias al awareness que proporciona tanto sobre el propio proceso de edición como de los usuarios que en ella colaboran. Además, la implementación como servicios webs de la de gestión de modelos EMF y del soporte a características de awareness permite su reutilización en futuras aplicaciones.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ditor modelos, colaboración, multidispositivo, EMF, Workspace Awareness, servicio web]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel A. Teruel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[MiguelAngel.Teruel@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Arturo C. Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Arturo.Rodriguez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Elena Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Elena.Navarro@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Pascual González]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Pascual.Gonzalez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/008]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A CSCW Requirements Engineering CASE Tool: Development and Usability Evaluation</title>
		<link>https://biblioteca.sistedes.es/articulo/a-cscw-requirements-engineering-case-tool-development-and-usability-evaluation/</link>
		<pubDate>Sun, 24 Apr 2016 02:10:10 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=818</guid>
		<description></description>
		<content><![CDATA[ An experiment was performed in order to assess the usability of CSRML Tool 2012 (CT'12), a tool to specify the requirements of CSCW systems. The effectiveness and efficiency of CT'12 were evaluated by means of several experimental tasks. Moreover, the user's satisfaction was evaluated by using both a classical survey and analyzing the participants' facial expressions when performing the experiments. Furthermore, this evaluation has been reported by using the ISO/IEC 25062:2006 [2], thus making its results comparable with other usability assessments which follow this international standard. Finally, details about how to develop a CASE toll for a Domain Specific Language was provided in a tutorial style.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>818</post_id>
		<post_date><![CDATA[2016-04-24 04:10:10]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 02:10:10]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-cscw-requirements-engineering-case-tool-development-and-usability-evaluation]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="usability-evaluation-case-tool-csrml-requirements-engineering-cscw-isoiec"><![CDATA[Usability evaluation; CASE tool; CSRML; Requirements engineering; CSCW; ISO/IEC]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[819]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[ An experiment was performed in order to assess the usability of CSRML Tool 2012 (CT'12), a tool to specify the requirements of CSCW systems. The effectiveness and efficiency of CT'12 were evaluated by means of several experimental tasks. Moreover, the user's satisfaction was evaluated by using both a classical survey and analyzing the participants' facial expressions when performing the experiments. Furthermore, this evaluation has been reported by using the ISO/IEC 25062:2006 [2], thus making its results comparable with other usability assessments which follow this international standard. Finally, details about how to develop a CASE toll for a Domain Specific Language was provided in a tutorial style.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Usability evaluation; CASE tool; CSRML; Requirements engineering; CSCW; ISO/IEC ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel A. Teruel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[LoUISE, Departamento de Sistemas Informáticos, Universidad de Castilla-La Mancha, Avda. España s/n, 02071 - Albacete]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[miguel@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Elena Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[LoUISE, Departamento de Sistemas Informáticos, Universidad de Castilla-La Mancha, Avda. España s/n, 02071 - Albacete]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[enavarro@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Víctor López-Jaquero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[LoUISE, Departamento de Sistemas Informáticos, Universidad de Castilla-La Mancha, Avda. España s/n, 02071 - Albacete]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[victor@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Francisco Montero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[LoUISE, Departamento de Sistemas Informáticos, Universidad de Castilla-La Mancha, Avda. España s/n, 02071 - Albacete]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[fmontero@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Pascual González]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[pgonzalez@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/007]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>WebMakeup: An End-user Tool for Web Page Customization</title>
		<link>https://biblioteca.sistedes.es/articulo/webmakeup-an-end-user-tool-for-web-page-customization/</link>
		<pubDate>Sun, 24 Apr 2016 02:14:40 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=821</guid>
		<description></description>
		<content><![CDATA[The Personal Web refers to a collection of technologies that confer the ability to reorganize, configure and manage online content rather than just viewing it. The main forms of Web content are HTML pages. HTML pages are represented as DOM trees, hence the Web is conceived as a "forest of DOM trees". The vision is for users to "prune" (removing nodes) or "graft" (adding nodes) existing DOM trees to improve their Web experience. Hence, Web content is no longer consumed as canned by Web masters. Rather, users can remove content of no interest to them, or placing new content from somewhere else. This vision accounts for a post-production user-driven Web customization. Being user driven, appropriate abstractions and tools are needed. The paper introduces an IDE (realized as a plugin from Chrome) to empower nonprogrammers to achieve HTML rearrangement.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>821</post_id>
		<post_date><![CDATA[2016-04-24 04:14:40]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 02:14:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[webmakeup-an-end-user-tool-for-web-page-customization]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="domain-specific-languages"><![CDATA[Domain Specific Languages]]></category>
		<category domain="post_tag" nicename="end-user-programming"><![CDATA[End User Programming]]></category>
		<category domain="post_tag" nicename="visual-programming"><![CDATA[Visual Programming]]></category>
		<category domain="post_tag" nicename="web-modding"><![CDATA[Web Modding]]></category>
		<category domain="post_tag" nicename="web-widget"><![CDATA[Web Widget]]></category>
		<category domain="post_tag" nicename="webmakeup"><![CDATA[WebMakeUp]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[822]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The Personal Web refers to a collection of technologies that confer the ability to reorganize, configure and manage online content rather than just viewing it. The main forms of Web content are HTML pages. HTML pages are represented as DOM trees, hence the Web is conceived as a "forest of DOM trees". The vision is for users to "prune" (removing nodes) or "graft" (adding nodes) existing DOM trees to improve their Web experience. Hence, Web content is no longer consumed as canned by Web masters. Rather, users can remove content of no interest to them, or placing new content from somewhere else. This vision accounts for a post-production user-driven Web customization. Being user driven, appropriate abstractions and tools are needed. The paper introduces an IDE (realized as a plugin from Chrome) to empower nonprogrammers to achieve HTML rearrangement.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ Web Modding, Web Widget, End User Programming, Visual Programming, Domain Specific Languages, WebMakeUp]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Oscar Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU), San Sebastián (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[oscar.diaz@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Cristóbal Arellano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU), San Sebastián (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cristobal.arellano@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Iñigo Aldalur]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU), San Sebastián (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inigo.aldalur@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Sergio Firmenich]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[LIFIA, Facultad de Informática (Argentina) ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sergio.firmenich@lifia.info.unlp.edu.ar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Haritz Medina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU), San Sebastián (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[hmedina002@ikasle.ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/006]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Metodología para Diseñar, Desarrollar y Evaluar una Plataforma de Entrenamiento en Desarrollo Global de Software</title>
		<link>https://biblioteca.sistedes.es/articulo/metodologia-para-disenar-desarrollar-y-evaluar-una-plataforma-de-entrenamiento-en-desarrollo-global-de-software/</link>
		<pubDate>Sun, 24 Apr 2016 02:20:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=824</guid>
		<description></description>
		<content><![CDATA[La formación en Desarrollo Global de Software (DGS) ha cobrado especial relevancia en lo últimos años, tanto en el ámbito académico como en el de la industria. Las empresas ofrecen formación en DGS en áreas como el entrenamiento cultural y lingüístico, liderazgo, negociación o habilidades comunicativas. Por otro lado, las universidades también ofrecen formación en DGS aunque con objetivos más genéricos. Considerar las necesidades de ambos entornos (industria y academia) es un factor clave para proporcionar una solución formativa efectiva. VENTURE es un entorno basado en simulación para proporcionar entrenamiento en interacciones textuales de DGS. Este entorno considera diferentes tipos de problemas del DGS incluyendo barreras comunicativas tanto lingüísticas como culturales. Este artículo presenta la metodología utilizada para diseñar, desarrollar y evaluar VENTURE. Una vez descrita la metodología nos centraremos en explicar en detalle las últimas etapas de la misma que fueron: la evaluación de viabilidad, el estudio de expertos, el estudio de campo y el estudio comercial.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>824</post_id>
		<post_date><![CDATA[2016-04-24 04:20:53]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 02:20:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[metodologia-para-disenar-desarrollar-y-evaluar-una-plataforma-de-entrenamiento-en-desarrollo-global-de-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="desarrollo-global-de-software"><![CDATA[Desarrollo Global de Software]]></category>
		<category domain="post_tag" nicename="docencia"><![CDATA[Docencia]]></category>
		<category domain="post_tag" nicename="educacion"><![CDATA[Educación]]></category>
		<category domain="post_tag" nicename="equipos-virtuales"><![CDATA[Equipos Virtuales]]></category>
		<category domain="post_tag" nicename="evaluacion"><![CDATA[Evaluación]]></category>
		<category domain="post_tag" nicename="formacion"><![CDATA[Formación]]></category>
		<category domain="post_tag" nicename="metodologia"><![CDATA[Metodología]]></category>
		<category domain="post_tag" nicename="simulacion"><![CDATA[Simulación]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[825]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La formación en Desarrollo Global de Software (DGS) ha cobrado especial relevancia en lo últimos años, tanto en el ámbito académico como en el de la industria. Las empresas ofrecen formación en DGS en áreas como el entrenamiento cultural y lingüístico, liderazgo, negociación o habilidades comunicativas. Por otro lado, las universidades también ofrecen formación en DGS aunque con objetivos más genéricos. Considerar las necesidades de ambos entornos (industria y academia) es un factor clave para proporcionar una solución formativa efectiva. VENTURE es un entorno basado en simulación para proporcionar entrenamiento en interacciones textuales de DGS. Este entorno considera diferentes tipos de problemas del DGS incluyendo barreras comunicativas tanto lingüísticas como culturales. Este artículo presenta la metodología utilizada para diseñar, desarrollar y evaluar VENTURE. Una vez descrita la metodología nos centraremos en explicar en detalle las últimas etapas de la misma que fueron: la evaluación de viabilidad, el estudio de expertos, el estudio de campo y el estudio comercial.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Desarrollo Global de Software, Educación, Docencia, Formación, Equipos Virtuales, Simulación, Metodología, Evaluación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel J. Monasora]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[rupo de Investigación Alarcos, Instituto de Tecnologías y Sistemas de Información, Escuela Superior de Informática, Universidad de Castilla-La Mancha, 13071, Ciudad Real]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[J.Monasor@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Aurora Vizcaínoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[rupo de Investigación Alarcos, Instituto de Tecnologías y Sistemas de Información, Escuela Superior de Informática, Universidad de Castilla-La Mancha, 13071, Ciudad Real]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Aurora.Vizcaino@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Mario Piattinia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[rupo de Investigación Alarcos, Instituto de Tecnologías y Sistemas de Información, Escuela Superior de Informática, Universidad de Castilla-La Mancha, 13071, Ciudad Real]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Mario.Piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[John Noll]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Lero, The Irish Software Engineering Research Centre, Department of Computer Science and Information Systems, University of Limerick, Limerick, Ireland]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[John.Noll@lero.ie]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Sarah Beecham]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Lero, The Irish Software Engineering Research Centre, Department of Computer Science and Information Systems, University of Limerick, Limerick, Ireland]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[Sarah.Beecham, John.Noll}@lero.ie]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/020]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Sim-XPerience: Simulación Basada en Agentes Aplicada al Desarrollo de Software con XP</title>
		<link>https://biblioteca.sistedes.es/articulo/sim-xperience-simulacion-basada-en-agentes-aplicada-al-desarrollo-de-software-con-xp/</link>
		<pubDate>Sun, 24 Apr 2016 02:32:55 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=827</guid>
		<description></description>
		<content><![CDATA[En los últimos años han ganado protagonismo los métodos de desarrollo ágil, especialmente indicados en proyectos con requisitos poco definidos o cambiantes. Dentro de las metodologías ágiles eXtreme Programmimg (XP) es una de las más conocidas y mejor definidas. Sin embargo, uno de los factores que complica su aplicación es la dificultad de realizar estimaciones en este tipo de proyectos. En este trabajo, se describe el desarrollo de Sim-XPerience: un modelo de simulación aplicado al desarrollo de software bajo la metodología XP, que, a diferencia de los que podemos encontrar en la literatura, se ha desarrollado siguiendo el paradigma basado en agentes. SimXPerience se plantea como una herramienta de ayuda a la toma de decisiones para gestores y/o directores de proyectos que se desarrollen bajo esta metodología ágil. A través de los parámetros de entrada del modelo es posible configurar las características específicas del proyecto que se desee simular, y experimentar diferentes decisiones relativas a la gestión del equipo y la asignación de tareas, observando la evolución del proceso y del equipo así como las desviaciones de tiempo y coste respecto a las estimaciones iniciales. De este modo, SimXPerience constituye una valiosa herramienta de experimentación en el ámbito del desarrollo de software bajo la metodología XP.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>827</post_id>
		<post_date><![CDATA[2016-04-24 04:32:55]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 02:32:55]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[sim-xperience-simulacion-basada-en-agentes-aplicada-al-desarrollo-de-software-con-xp]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="metodologias-agiles"><![CDATA[Metodologías Ágiles]]></category>
		<category domain="post_tag" nicename="modelado-y-simulacion"><![CDATA[Modelado y Simulación]]></category>
		<category domain="post_tag" nicename="proceso-software-1-introduccion"><![CDATA[Proceso Software. 1 Introducción]]></category>
		<category domain="post_tag" nicename="programacion-extrema"><![CDATA[Programación Extrema]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[828]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años han ganado protagonismo los métodos de desarrollo ágil, especialmente indicados en proyectos con requisitos poco definidos o cambiantes. Dentro de las metodologías ágiles eXtreme Programmimg (XP) es una de las más conocidas y mejor definidas. Sin embargo, uno de los factores que complica su aplicación es la dificultad de realizar estimaciones en este tipo de proyectos. En este trabajo, se describe el desarrollo de Sim-XPerience: un modelo de simulación aplicado al desarrollo de software bajo la metodología XP, que, a diferencia de los que podemos encontrar en la literatura, se ha desarrollado siguiendo el paradigma basado en agentes. SimXPerience se plantea como una herramienta de ayuda a la toma de decisiones para gestores y/o directores de proyectos que se desarrollen bajo esta metodología ágil. A través de los parámetros de entrada del modelo es posible configurar las características específicas del proyecto que se desee simular, y experimentar diferentes decisiones relativas a la gestión del equipo y la asignación de tareas, observando la evolución del proceso y del equipo así como las desviaciones de tiempo y coste respecto a las estimaciones iniciales. De este modo, SimXPerience constituye una valiosa herramienta de experimentación en el ámbito del desarrollo de software bajo la metodología XP.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Modelado y Simulación, Programación Extrema, Metodologías Ágiles, Proceso Software. 1 Introducción]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cristina Capitas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación SPI&FM Departamento de Ingeniería Informática Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cristina.capitassanchez@mail.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Nuria Hurtado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación SPI&FM Departamento de Ingeniería Informática Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[nuria.hurtado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Mercedes Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación SPI&FM Departamento de Ingeniería Informática Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mercedes.ruiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/019]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Habilidades emocionales en el sector TIC: un análisis a partir de los empleos ofertados en el sector</title>
		<link>https://biblioteca.sistedes.es/articulo/habilidades-emocionales-en-el-sector-tic-un-analisis-a-partir-de-los-empleos-ofertados-en-el-sector/</link>
		<pubDate>Sun, 24 Apr 2016 02:35:35 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=830</guid>
		<description></description>
		<content><![CDATA[Cuando pensamos en los conocimientos que debe tener un profesional de las TIC, pensamos habitualmente en capacidades técnicas: de análisis y diseño de sistemas, captura de requisitos, programación, etc. Sin el factor humano juega un papel clave, ya que la tecnología se construye por y para las personas. Con el fin de comprobar si efectivamente las empresas del sector de las TIC conceden importancia a las capacidades no técnicas o habilidades emocionales, este trabajo presenta los resultados de un estudio en el que se analiza la demanda de habilidades emocionales en las ofertas de empleo del sector las TIC, así como la aplicación desarrollada para automatizar la búsqueda, extracción y clasificación de la información analizada en dicho estudio.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>830</post_id>
		<post_date><![CDATA[2016-04-24 04:35:35]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 02:35:35]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[habilidades-emocionales-en-el-sector-tic-un-analisis-a-partir-de-los-empleos-ofertados-en-el-sector]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="analisis-de-datos"><![CDATA[Análisis de Datos]]></category>
		<category domain="post_tag" nicename="comunicacion-1-introduccion"><![CDATA[Comunicación. 1 Introducción]]></category>
		<category domain="post_tag" nicename="habilidades-emocionales"><![CDATA[Habilidades emocionales]]></category>
		<category domain="post_tag" nicename="liderazgo"><![CDATA[Liderazgo]]></category>
		<category domain="post_tag" nicename="trabajo-en-equipo"><![CDATA[Trabajo en equipo]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[831]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Cuando pensamos en los conocimientos que debe tener un profesional de las TIC, pensamos habitualmente en capacidades técnicas: de análisis y diseño de sistemas, captura de requisitos, programación, etc. Sin el factor humano juega un papel clave, ya que la tecnología se construye por y para las personas. Con el fin de comprobar si efectivamente las empresas del sector de las TIC conceden importancia a las capacidades no técnicas o habilidades emocionales, este trabajo presenta los resultados de un estudio en el que se analiza la demanda de habilidades emocionales en las ofertas de empleo del sector las TIC, así como la aplicación desarrollada para automatizar la búsqueda, extracción y clasificación de la información analizada en dicho estudio.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Habilidades emocionales, Análisis de Datos, Liderazgo, Trabajo en equipo, Comunicación. 1 Introducción]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Víctor Serrano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[v.serranob@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan M. Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/018]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una aproximación Ágil a los niveles de madurez 2 y 3 de CMMI-DEV en entornos de desarrollo Web</title>
		<link>https://biblioteca.sistedes.es/articulo/una-aproximacion-agil-a-los-niveles-de-madurez-2-y-3-de-cmmi-dev-en-entornos-de-desarrollo-web/</link>
		<pubDate>Sun, 24 Apr 2016 02:39:36 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=833</guid>
		<description></description>
		<content><![CDATA[Las metodologías y técnicas Ágiles aparecieron hace aproximadamente 10 años y se han convertido en la actualidad en una alternativa para el desarrollo de software. Este tipo de metodologías son especialmente interesantes en el marco de los desarrollos Web, ya que las características de las técnicas Ágiles pueden encajar muy bien con la especificidad propia de un desarrollo Web. Por otro lado, los modelos de madurez como CMMI-DEV, que se centran en la madurez de una organización que desarrolla software, han probado ser mecanismos validos para incrementar la calidad en los procesos de desarrollo. La propuesta de un conjunto de técnicas Ágiles que permita a una determinada organización alcanzar los objetivo específicos de los niveles de madurez 2 y 3 de CMMI-DEV podría ser muy interesante para aquellas organizaciones (sobre todo pequeñas y medianas) que trabajan en proyectos de desarrollo Web, ya que se podría combinar la adaptabilidad proporcionada por las metodologías y técnicas Ágiles, tan necesaria en el entorno Web, con el incremento de madurez en los procesos posibilitado por CMMI-DEV. En este trabajo se propone un conjunto de técnicas, métodos y metodología que, combinados, podrían ayudar a una organización a alcanzar los objetivos genéricos y específicos de los niveles 2 y 3 de CMMI-DEV.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>833</post_id>
		<post_date><![CDATA[2016-04-24 04:39:36]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 02:39:36]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-aproximacion-agil-a-los-niveles-de-madurez-2-y-3-de-cmmi-dev-en-entornos-de-desarrollo-web]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cmmi"><![CDATA[CMMI]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software"><![CDATA[Ingeniería del Software]]></category>
		<category domain="post_tag" nicename="ingenieria-web"><![CDATA[Ingeniería Web]]></category>
		<category domain="post_tag" nicename="metodologias-agiles"><![CDATA[Metodologías Ágiles]]></category>
		<category domain="post_tag" nicename="scrum"><![CDATA[Scrum]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[834]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las metodologías y técnicas Ágiles aparecieron hace aproximadamente 10 años y se han convertido en la actualidad en una alternativa para el desarrollo de software. Este tipo de metodologías son especialmente interesantes en el marco de los desarrollos Web, ya que las características de las técnicas Ágiles pueden encajar muy bien con la especificidad propia de un desarrollo Web. Por otro lado, los modelos de madurez como CMMI-DEV, que se centran en la madurez de una organización que desarrolla software, han probado ser mecanismos validos para incrementar la calidad en los procesos de desarrollo. La propuesta de un conjunto de técnicas Ágiles que permita a una determinada organización alcanzar los objetivo específicos de los niveles de madurez 2 y 3 de CMMI-DEV podría ser muy interesante para aquellas organizaciones (sobre todo pequeñas y medianas) que trabajan en proyectos de desarrollo Web, ya que se podría combinar la adaptabilidad proporcionada por las metodologías y técnicas Ágiles, tan necesaria en el entorno Web, con el incremento de madurez en los procesos posibilitado por CMMI-DEV. En este trabajo se propone un conjunto de técnicas, métodos y metodología que, combinados, podrían ayudar a una organización a alcanzar los objetivos genéricos y específicos de los niveles 2 y 3 de CMMI-DEV.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Metodologías Ágiles, Scrum, Ingeniería Web, CMMI, Ingeniería del Software]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[C.J. Torrecilla-Salinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carlos.torrecilla@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[J. Sedeño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jorge.sedeno@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[M.J.Escalona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mjescalona@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[M. Mejías]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[gencia Andaluza de Instituciones Culturales ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[risoto@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/017]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Usability through Software Desig</title>
		<link>https://biblioteca.sistedes.es/articulo/usability-through-software-desig/</link>
		<pubDate>Sun, 24 Apr 2016 02:42:55 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=836</guid>
		<description></description>
		<content><![CDATA[Over the past two decades the HCI community has proposed specific features that software applications should include to overcome some of the most common usability problems. However, incorporating such usability features into software applications may not be a straightforward process for software developers who have not been trained in usability (i.e., determining when, how, and why usability features should been considered). We have defined a set of usability guidelines for software development to help software engineers incorporate particular usability features into their applications. In this paper we focus on the software design artifacts provided by the guidelines. We detail the structure of the proposed design artifacts and how they should be used according to the software development process and software architecture used in each application. We have tested our guidelines in an academic setting. Preliminary validation shows that the use of the guidelines reduces development time, improves the quality of the resulting designs and significantly decreases the perceived complexity of the usability features from the developers' perspective.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>836</post_id>
		<post_date><![CDATA[2016-04-24 04:42:55]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 02:42:55]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[usability-through-software-desig]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[837]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Over the past two decades the HCI community has proposed specific features that software applications should include to overcome some of the most common usability problems. However, incorporating such usability features into software applications may not be a straightforward process for software developers who have not been trained in usability (i.e., determining when, how, and why usability features should been considered). We have defined a set of usability guidelines for software development to help software engineers incorporate particular usability features into their applications. In this paper we focus on the software design artifacts provided by the guidelines. We detail the structure of the proposed design artifacts and how they should be used according to the software development process and software architecture used in each application. We have tested our guidelines in an academic setting. Preliminary validation shows that the use of the guidelines reduces development time, improves the quality of the resulting designs and significantly decreases the perceived complexity of the usability features from the developers' perspective.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Laura Carvajal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[lauraelena.carvajal@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ana M. Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ammoreno@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[María-Isabel Sánchez-Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Carlos III de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[misanche@inf.uc3m.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ahmed Seffah]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Concordia University, Canada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[seffah.ahmed@concordia.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/016]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A fine-grained analysis of the support provided by UML class diagrams and ER diagrams during data model maintenance</title>
		<link>https://biblioteca.sistedes.es/articulo/a-fine-grained-analysis-of-the-support-provided-by-uml-class-diagrams-and-er-diagrams-during-data-model-maintenance/</link>
		<pubDate>Sun, 24 Apr 2016 02:47:14 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=839</guid>
		<description></description>
		<content><![CDATA[This paper presents the results of an empirical study aiming at comparing the support provided by ER and UML class diagrams during maintenance of data models. We performed one controlled experiment and two replications that focused on comprehension activities and another controlled experiment on modification activities related to the implementation of given change requests. The results achieved were analyzed at a fine-grained level aiming at comparing the support given by each single building block of the two notations. Such an analysis is used to identify weaknesses (i.e., building blocks not easy to comprehend) in a notation and/or can justify the need of preferring ER or UML for data modeling. The analysis revealed that the UML class diagrams generally provided a better support for both comprehension and modification activities performed on data models as compared to ER diagrams. Nevertheless, the former has some weaknesses related to three building blocks, i.e., multi-value attribute, composite attribute, and weak entity. These findings suggest that an extension of UML class diagrams should be considered to overcome these weaknesses and improve the support provided by UML class diagrams during maintenance of data models.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>839</post_id>
		<post_date><![CDATA[2016-04-24 04:47:14]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 02:47:14]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-fine-grained-analysis-of-the-support-provided-by-uml-class-diagrams-and-er-diagrams-during-data-model-maintenance]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="comprehension"><![CDATA[Comprehension]]></category>
		<category domain="post_tag" nicename="er-diagrams"><![CDATA[ER diagrams]]></category>
		<category domain="post_tag" nicename="family-of-experiments"><![CDATA[Family of experiments]]></category>
		<category domain="post_tag" nicename="meta-analysis"><![CDATA[Meta-analysis]]></category>
		<category domain="post_tag" nicename="model-maintenance"><![CDATA[Model maintenance]]></category>
		<category domain="post_tag" nicename="uml-class-diagrams"><![CDATA[UML class diagrams]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[840]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper presents the results of an empirical study aiming at comparing the support provided by ER and UML class diagrams during maintenance of data models. We performed one controlled experiment and two replications that focused on comprehension activities and another controlled experiment on modification activities related to the implementation of given change requests. The results achieved were analyzed at a fine-grained level aiming at comparing the support given by each single building block of the two notations. Such an analysis is used to identify weaknesses (i.e., building blocks not easy to comprehend) in a notation and/or can justify the need of preferring ER or UML for data modeling. The analysis revealed that the UML class diagrams generally provided a better support for both comprehension and modification activities performed on data models as compared to ER diagrams. Nevertheless, the former has some weaknesses related to three building blocks, i.e., multi-value attribute, composite attribute, and weak entity. These findings suggest that an extension of UML class diagrams should be considered to overcome these weaknesses and improve the support provided by UML class diagrams during maintenance of data models.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Model maintenance, UML class diagrams, ER diagrams, Comprehension, Family of experiments, Meta-analysis]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Gabriele Bavota]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[gbavota@unisa.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[University of Salerno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carmine Gravino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Salerno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gravino@unisa.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Rocco Oliveto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Molise, Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[rocco.oliveto@unimol.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Andrea De Lucia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Salerno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[adelucia@unisa.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Genoveffa Tortora]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Salerno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[tortora@unisa.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Marcela Genero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[niversity of Castilla-La Mancha, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[Marcela.Genero@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[José A. Cruz-Lemus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[JoseAntonio.Cruz@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[niversity of Castilla-La Mancha, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/015]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>EXEMPLAR: An Experimental Information Repository for Software Engineering Research</title>
		<link>https://biblioteca.sistedes.es/articulo/exemplar-an-experimental-information-repository-for-software-engineering-research/</link>
		<pubDate>Sun, 24 Apr 2016 02:50:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=842</guid>
		<description></description>
		<content><![CDATA[ The number and variety of experiments carried in software engineering research is growing, leading to a increasing need of replication and review. In order to support such needs the information about experiments should be provided as lab-packs comprising of: a description of the experiment, the materials used and data generated during the conduction, and the results of the analyzes performed on such data. However, this information is often scattered, poorly structured, and even unavailable, implying a tedious process of search and gathering. EXEMPLAR is an online platform for managing experimental information, that allows the uploading and publication of experimental lab packs, and an efficient search. The platform also supports the use of formal languages for providing experimental descriptions (e.g. SEDL). In so doing, EXEMPLAR enables the automated analysis of lab-packs, in order to detect common validity threats and missing information which could hinder replicability.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>842</post_id>
		<post_date><![CDATA[2016-04-24 04:50:07]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 02:50:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[exemplar-an-experimental-information-repository-for-software-engineering-research]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="empirical-research"><![CDATA[empirical research]]></category>
		<category domain="post_tag" nicename="experimental-replicability"><![CDATA[experimental replicability]]></category>
		<category domain="post_tag" nicename="experimental-repositories"><![CDATA[experimental repositories]]></category>
		<category domain="post_tag" nicename="experiments"><![CDATA[experiments]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[843]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[ The number and variety of experiments carried in software engineering research is growing, leading to a increasing need of replication and review. In order to support such needs the information about experiments should be provided as lab-packs comprising of: a description of the experiment, the materials used and data generated during the conduction, and the results of the analyzes performed on such data. However, this information is often scattered, poorly structured, and even unavailable, implying a tedious process of search and gathering. EXEMPLAR is an online platform for managing experimental information, that allows the uploading and publication of experimental lab packs, and an efficient search. The platform also supports the use of formal languages for providing experimental descriptions (e.g. SEDL). In so doing, EXEMPLAR enables the automated analysis of lab-packs, in order to detect common validity threats and missing information which could hinder replicability.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[empirical research, experiments, experimental replicability, experimental repositories]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jose Antonio Parejo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Sevilla, Spain ETSII. Avda. de la Reina Mercedes s/n, 41012, Sevilla.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[japarejo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Sevilla, Spain ETSII. Avda. de la Reina Mercedes s/n, 41012, Sevilla.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Sevilla, Spain ETSII. Avda. de la Reina Mercedes s/n, 41012, Sevilla.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Sevilla, Spain ETSII. Avda. de la Reina Mercedes s/n, 41012, Sevilla.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/014]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Suite de aplicaciones colaborativas para dar soporte a la gamificación del prototipado de procesos</title>
		<link>https://biblioteca.sistedes.es/articulo/suite-de-aplicaciones-colaborativas-para-dar-soporte-a-la-gamificacion-del-prototipado-de-procesos/</link>
		<pubDate>Sun, 24 Apr 2016 02:52:29 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=845</guid>
		<description></description>
		<content><![CDATA[Este artículo presenta tres aplicaciones denominadas SysDyn, OpenBadgesUCA y GamAnalyze, que pretenden satisfacer un objetivo común: dar soporte a la aplicación de estrategias de gamificación en el ámbito del prototipado de negocios. Por un lado, SysDyn, cubre la ausencia de aplicaciones de prototipado de negocios basadas en simulación para dispositivos móviles tales como tablets. Por otro, OpenBadgesUCA se encarga de actuar como intermediario para poder subir las medallas logradas por los usuarios de SysDyn a la plataforma de almacenamiento de medallas Mozilla OpenBadges y de introducir los datos pertinentes de la experiencia en una base de datos. Finalmente, GamAnalyze se encarga de analizar la información relacionada con la estrategia de gamificación, procedente tanto del uso de SysDyn como de otras posibles aplicaciones registradas en OpenBadgesUCA, a fin de ayudar en la valoración de los resultados de dicha estrategia.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>845</post_id>
		<post_date><![CDATA[2016-04-24 04:52:29]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 02:52:29]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[suite-de-aplicaciones-colaborativas-para-dar-soporte-a-la-gamificacion-del-prototipado-de-procesos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="gamificacion"><![CDATA[gamificación]]></category>
		<category domain="post_tag" nicename="prototipado-de-negocio"><![CDATA[Prototipado de negocio]]></category>
		<category domain="post_tag" nicename="simulacion"><![CDATA[Simulación]]></category>
		<category domain="post_tag" nicename="toma-de-decisiones"><![CDATA[toma de decisiones]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[846]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo presenta tres aplicaciones denominadas SysDyn, OpenBadgesUCA y GamAnalyze, que pretenden satisfacer un objetivo común: dar soporte a la aplicación de estrategias de gamificación en el ámbito del prototipado de negocios. Por un lado, SysDyn, cubre la ausencia de aplicaciones de prototipado de negocios basadas en simulación para dispositivos móviles tales como tablets. Por otro, OpenBadgesUCA se encarga de actuar como intermediario para poder subir las medallas logradas por los usuarios de SysDyn a la plataforma de almacenamiento de medallas Mozilla OpenBadges y de introducir los datos pertinentes de la experiencia en una base de datos. Finalmente, GamAnalyze se encarga de analizar la información relacionada con la estrategia de gamificación, procedente tanto del uso de SysDyn como de otras posibles aplicaciones registradas en OpenBadgesUCA, a fin de ayudar en la valoración de los resultados de dicha estrategia.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Prototipado de negocio, gamificación, simulación, toma de decisiones]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel Trinidad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación en Mejora del Proceso Software y Métodos Formales Departamento de Ingeniería Informática Universidad de Cádiz C/ Chile, 1. 11003 ­ Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[manuel.trinidad@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mercedes Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación en Mejora del Proceso Software y Métodos Formales Departamento de Ingeniería Informática Universidad de Cádiz C/ Chile, 1. 11003 ­ Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mercedes.ruiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/013]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Entorno para la Evaluación y Certificación de la Calidad del Producto Software</title>
		<link>https://biblioteca.sistedes.es/articulo/entorno-para-la-evaluacion-y-certificacion-de-la-calidad-del-producto-software/</link>
		<pubDate>Sun, 24 Apr 2016 02:55:57 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=848</guid>
		<description></description>
		<content><![CDATA[La calidad del software está adquiriendo durante los últimos años una gran importancia, principalmente debido a que el software está presente en prácticamente todo lo que nos rodea. Para poder controlar dicha calidad se hace necesario llevar a cabo evaluaciones del software, que inicialmente se centraron en los procesos de desarrollo y que durante los últimos años se están enfocando más en la calidad del propio producto software. Para poder evaluar la calidad de un producto software se requiere de varios elementos entre los que se pueden destacar: un modelo de calidad, las métricas que se van a utilizar, el proceso de evaluación y las herramientas de soporte que automaticen todo lo posible el proceso. El presente artículo expone un entorno integrado que permite llevar a cabo la evaluación de la calidad del producto software, alineando todos los elementos anteriores a un estándar internacional como es la nueva familia de normas ISO/IEC 25000. Dicho entorno se ha validado además mediante su aplicación en un laboratorio de evaluación acreditado y la realización de varios proyectos piloto con una entidad de certificación, cuyo resultado ha sido la obtención de los primeros productos certificados por AENOR en mantenibilidad software a nivel internacional.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>848</post_id>
		<post_date><![CDATA[2016-04-24 04:55:57]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 02:55:57]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[entorno-para-la-evaluacion-y-certificacion-de-la-calidad-del-producto-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="certificacion-del-producto-software"><![CDATA[certificación del producto software]]></category>
		<category domain="post_tag" nicename="isoiec-25000"><![CDATA[ISO/IEC 25000]]></category>
		<category domain="post_tag" nicename="laboratorio-de-evaluacion"><![CDATA[laboratorio de evaluación]]></category>
		<category domain="post_tag" nicename="mantenibilidad"><![CDATA[mantenibilidad]]></category>
		<category domain="post_tag" nicename="metricas-de-calidad"><![CDATA[métricas de calidad]]></category>
		<category domain="post_tag" nicename="modelo-de-calidad"><![CDATA[modelo de calidad]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[849]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La calidad del software está adquiriendo durante los últimos años una gran importancia, principalmente debido a que el software está presente en prácticamente todo lo que nos rodea. Para poder controlar dicha calidad se hace necesario llevar a cabo evaluaciones del software, que inicialmente se centraron en los procesos de desarrollo y que durante los últimos años se están enfocando más en la calidad del propio producto software. Para poder evaluar la calidad de un producto software se requiere de varios elementos entre los que se pueden destacar: un modelo de calidad, las métricas que se van a utilizar, el proceso de evaluación y las herramientas de soporte que automaticen todo lo posible el proceso. El presente artículo expone un entorno integrado que permite llevar a cabo la evaluación de la calidad del producto software, alineando todos los elementos anteriores a un estándar internacional como es la nueva familia de normas ISO/IEC 25000. Dicho entorno se ha validado además mediante su aplicación en un laboratorio de evaluación acreditado y la realización de varios proyectos piloto con una entidad de certificación, cuyo resultado ha sido la obtención de los primeros productos certificados por AENOR en mantenibilidad software a nivel internacional.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[modelo de calidad, métricas de calidad, ISO/IEC 25000, mantenibilidad, laboratorio de evaluación, certificación del producto software]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Moisés Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[larcos Quality Center, Universidad de Castilla-La Mancha, Ciudad Real, España. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[moises.rodriguez@alarcosqualitycenter.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de la Información, Universidad de Castilla-La Mancha, Ciudad Real, España.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mario.piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/028]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación de Mutantes Válidos en el Lenguaje de Programación C++</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-de-mutantes-validos-en-el-lenguaje-de-programacion-c/</link>
		<pubDate>Sun, 24 Apr 2016 02:58:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=851</guid>
		<description></description>
		<content><![CDATA[La prueba de mutaciones es una técnica basada en fallos que se ha desarrollado alrededor de un amplio rango de lenguajes de programación. Sin embargo, la construcción de un marco de trabajo de prueba de mutaciones no comercial para C++ ha sido pospuesto en favor de otros lenguajes, principalmente por la variedad de alternativas que ofrece C++. Este artículo presenta una solución factible y completa para la implementación de los operadores de mutación en C++, la cual se basa en la búsqueda de patrones en el árbol de sintaxis abstracta (AST) que el compilador Clang genera a partir del código fuente. Estos patrones se construyen según las reglas que determinan los distintos operadores de mutación, permitiendo localizar los puntos del código en los que es posible introducir una mutación. Asimismo, en el artículo se abordan distintas situaciones que han de ser consideradas para la validez de los mutantes creados. Este proceso se ilustra a través de un operador de mutación a nivel de clase, si bien este enfoque sirve para crear operadores a cualquier nivel del lenguaje.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>851</post_id>
		<post_date><![CDATA[2016-04-24 04:58:06]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 02:58:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-de-mutantes-validos-en-el-lenguaje-de-programacion-c]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="arbol-de-sintaxis-abstracta"><![CDATA[árbol de sintaxis abstracta]]></category>
		<category domain="post_tag" nicename="c"><![CDATA[C++]]></category>
		<category domain="post_tag" nicename="operador-de-mutacion"><![CDATA[operador de mutación]]></category>
		<category domain="post_tag" nicename="prueba-de-mutaciones"><![CDATA[prueba de mutaciones]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[852]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La prueba de mutaciones es una técnica basada en fallos que se ha desarrollado alrededor de un amplio rango de lenguajes de programación. Sin embargo, la construcción de un marco de trabajo de prueba de mutaciones no comercial para C++ ha sido pospuesto en favor de otros lenguajes, principalmente por la variedad de alternativas que ofrece C++. Este artículo presenta una solución factible y completa para la implementación de los operadores de mutación en C++, la cual se basa en la búsqueda de patrones en el árbol de sintaxis abstracta (AST) que el compilador Clang genera a partir del código fuente. Estos patrones se construyen según las reglas que determinan los distintos operadores de mutación, permitiendo localizar los puntos del código en los que es posible introducir una mutación. Asimismo, en el artículo se abordan distintas situaciones que han de ser consideradas para la validez de los mutantes creados. Este proceso se ilustra a través de un operador de mutación a nivel de clase, si bien este enfoque sirve para crear operadores a cualquier nivel del lenguaje.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Prueba de mutaciones, C++, árbol de sintaxis abstracta, operador de mutación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Delgado-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software, Departamento de Ingeniería Informática, Universidad de Cádiz, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pedro.delgado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software, Departamento de Ingeniería Informática, Universidad de Cádiz, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan José Domínguez-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software, Departamento de Ingeniería Informática, Universidad de Cádiz, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanjose.dominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/027]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Pruebas funcionales en programas MapReduce basadas en comportamientos no esperados</title>
		<link>https://biblioteca.sistedes.es/articulo/pruebas-funcionales-en-programas-mapreduce-basadas-en-comportamientos-no-esperados/</link>
		<pubDate>Sun, 24 Apr 2016 03:00:36 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=854</guid>
		<description></description>
		<content><![CDATA[ MapReduce es un paradigma de programación que permite el procesamiento paralelo de grandes cantidades de datos. Los programas MapReduce se suelen ejecutar sobre el framework Hadoop, el cual no garantiza que se ejecuten siempre en las mismas condiciones, pudiendo producir comportamientos no esperados desde el punto de vista de su funcionalidad. En este artículo se analizan y describen diferentes tipos de defectos específicos que pueden estar presentes en programas MapReduce sobre Hadoop y se muestra cómo se pueden derivar casos de prueba que permiten la detección de dichos defectos. Lo anterior se ilustra sobre varios programas de ejemplo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>854</post_id>
		<post_date><![CDATA[2016-04-24 05:00:36]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:00:36]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[pruebas-funcionales-en-programas-mapreduce-basadas-en-comportamientos-no-esperados]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="hadoop"><![CDATA[Hadoop]]></category>
		<category domain="post_tag" nicename="mapreduce"><![CDATA[MapReduce]]></category>
		<category domain="post_tag" nicename="pruebas-de-software"><![CDATA[Pruebas de Software]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[855]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[ MapReduce es un paradigma de programación que permite el procesamiento paralelo de grandes cantidades de datos. Los programas MapReduce se suelen ejecutar sobre el framework Hadoop, el cual no garantiza que se ejecuten siempre en las mismas condiciones, pudiendo producir comportamientos no esperados desde el punto de vista de su funcionalidad. En este artículo se analizan y describen diferentes tipos de defectos específicos que pueden estar presentes en programas MapReduce sobre Hadoop y se muestra cómo se pueden derivar casos de prueba que permiten la detección de dichos defectos. Lo anterior se ilustra sobre varios programas de ejemplo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Pruebas de Software, MapReduce, Big Data, Hadoop]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús Morán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo, Gijón, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[moranjesus@lsi.uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Claudio de la Riva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo, Gijón, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[claudio@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo, Gijón, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/026]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards Multi-Objective Test Case generation for Variability-Intensive Systems</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-multi-objective-test-case-generation-for-variability-intensive-systems/</link>
		<pubDate>Sun, 24 Apr 2016 03:03:39 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=857</guid>
		<description></description>
		<content><![CDATA[Testing variability-intensive systems is a challenge due to the potentially huge number of derivable configurations. To alleviate this problem, many test case selection and prioritization techniques have been proposed with the aim of reducing the number of configurations to be tested and increasing their effectiveness. However, we found that these approaches do not exploit all available information since they are mainly driven by functional information such as the feature coverage. Furthermore, most of these works are focused on a single-objective perspective (e.g. features coverage), which could not reflect the real scenarios where several goals need to be met (e.g. features coverage and code changes coverage). In this context, we identify an important challenge, to take advantage of all available system information to guide the generation of test cases. As a first step towards a solution, we propose to study all this information with special emphasis on non-functional properties and address the test case generation as a multi-objective problem. Also, we describe some open issues to be explored that we hope have an important impact on future evaluations.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>857</post_id>
		<post_date><![CDATA[2016-04-24 05:03:39]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:03:39]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-multi-objective-test-case-generation-for-variability-intensive-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="extra-functional-attributes"><![CDATA[extra-functional attributes]]></category>
		<category domain="post_tag" nicename="multi-objective-test-generation"><![CDATA[Multi-objective test generation]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[858]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Testing variability-intensive systems is a challenge due to the potentially huge number of derivable configurations. To alleviate this problem, many test case selection and prioritization techniques have been proposed with the aim of reducing the number of configurations to be tested and increasing their effectiveness. However, we found that these approaches do not exploit all available information since they are mainly driven by functional information such as the feature coverage. Furthermore, most of these works are focused on a single-objective perspective (e.g. features coverage), which could not reflect the real scenarios where several goals need to be met (e.g. features coverage and code changes coverage). In this context, we identify an important challenge, to take advantage of all available system information to guide the generation of test cases. As a first step towards a solution, we propose to study all this information with special emphasis on non-functional properties and address the test case generation as a multi-objective problem. Also, we describe some open issues to be explored that we hope have an important impact on future evaluations.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Multi-objective test generation, extra-functional attributes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana B. Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Seville, Av Reina Mercedes S/N Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[anabsanchez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Seville, Av Reina Mercedes S/N Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Seville, Av Reina Mercedes S/N Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/025]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación automática de casos de prueba mediante siembra automática para WS-BPEL 2.0</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-automatica-de-casos-de-prueba-mediante-siembra-automatica-para-ws-bpel-2-0/</link>
		<pubDate>Sun, 24 Apr 2016 03:06:27 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=860</guid>
		<description></description>
		<content><![CDATA[Dada la importancia que en los últimos años están cobrando los servicios web en el ámbito de los procesos de negocio, es imprescindible contar con un soporte de casos de prueba lo suficientemente amplio como para detectar fallos en estos servicios. La automatizacíon de la generación de casos de prueba es importante en este contexto, ya que va a permitir reducir el coste asociado a las tareas de prueba. En este trabajo se aplica por primera vez a composiciones WS-BPEL 2.0 la siembra automática, que combina la generación aleatoria de casos de prueba con información adicional de las constantes del programa. Además, se define una optimizacíon de esta técnica para evitar la generación de conjuntos grandes de casos de prueba.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>860</post_id>
		<post_date><![CDATA[2016-04-24 05:06:27]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:06:27]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-automatica-de-casos-de-prueba-mediante-siembra-automatica-para-ws-bpel-2-0]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="generacion-automatica-de-casos-de-prueba"><![CDATA[generación automática de casos de prueba]]></category>
		<category domain="post_tag" nicename="servicios-web"><![CDATA[servicios web]]></category>
		<category domain="post_tag" nicename="siembra-automatica"><![CDATA[siembra automática]]></category>
		<category domain="post_tag" nicename="ws-bpel"><![CDATA[WS-BPEL]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[861]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Dada la importancia que en los últimos años están cobrando los servicios web en el ámbito de los procesos de negocio, es imprescindible contar con un soporte de casos de prueba lo suficientemente amplio como para detectar fallos en estos servicios. La automatizacíon de la generación de casos de prueba es importante en este contexto, ya que va a permitir reducir el coste asociado a las tareas de prueba. En este trabajo se aplica por primera vez a composiciones WS-BPEL 2.0 la siembra automática, que combina la generación aleatoria de casos de prueba con información adicional de las constantes del programa. Además, se define una optimizacíon de esta técnica para evitar la generación de conjuntos grandes de casos de prueba.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[generación automática de casos de prueba, siembra automática, servicios web, WS-BPEL]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Valentín Liñeiro Barea]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Chile 1, 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[valentin.lineiro@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonia Estero Botaro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Chile 1, 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[antonia.estero@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio García Domínguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Chile 1, 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[antonio.garciadominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Chile 1, 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/024]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Multi-dimensional Criteria for Testing Web Services Transactions</title>
		<link>https://biblioteca.sistedes.es/articulo/multi-dimensional-criteria-for-testing-web-services-transactions/</link>
		<pubDate>Sun, 24 Apr 2016 03:09:28 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=863</guid>
		<description></description>
		<content><![CDATA[Web services (WS) transactions are important in order to reliably compose web services and to ensure that their execution is consistent and correct. This paper addresses the key issue of testing WS transactions by proposing multi-dimensional criteria that provide tester with flexibility of adjusting the method in terms of test efforts and effectiveness. The criteria have been designed, implemented and evaluated through a case study. This work has been published in Journal of Computer and Systems Sciences1.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>863</post_id>
		<post_date><![CDATA[2016-04-24 05:09:28]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:09:28]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[multi-dimensional-criteria-for-testing-web-services-transactions]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="classification-tree"><![CDATA[classification-tree]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<category domain="post_tag" nicename="transactions"><![CDATA[transactions]]></category>
		<category domain="post_tag" nicename="web-services"><![CDATA[web services]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[864]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Web services (WS) transactions are important in order to reliably compose web services and to ensure that their execution is consistent and correct. This paper addresses the key issue of testing WS transactions by proposing multi-dimensional criteria that provide tester with flexibility of adjusting the method in terms of test efforts and effectiveness. The criteria have been designed, implemented and evaluated through a case study. This work has been published in Journal of Computer and Systems Sciences1.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[web services, transactions, testing, classification-tree]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rubén Casado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rcasado@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Muhammad Younas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computing and Communication Technologies, Oxford Brookes University, UK ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[m.younas@brookes.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/023]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>PTAC: Una herramienta para testing pasivo de sistemas con comunicaciones asíncronas</title>
		<link>https://biblioteca.sistedes.es/articulo/ptac-una-herramienta-para-testing-pasivo-de-sistemas-con-comunicaciones-asincronas/</link>
		<pubDate>Sun, 24 Apr 2016 03:12:25 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=866</guid>
		<description></description>
		<content><![CDATA[Resumen Las técnicas de pruebas pasivas nos ofrecen la ventaja de poder testear sistemas con los cuales no es posible la interacción directa. Actualmente, la gran mayoría de las propuestas basadas en este concepto asumen que las trazas analizadas reflejan el comportamiento real del sistema, sin tener en cuenta el canal a través del cual han sido observadas. Si la comunicación es asíncrona, la traza observada puede no corresponderse con la producida durante la ejecución del sistema. La necesidad de considerar este tipo de aspectos, llevó a la propuesta de una nueva metodología de pruebas pasivas centrada en canales asíncronos First Input First Output (FIFO). En este artículo se presenta PTAC, una herramienta software que automatiza la aplicación de esta técnica, permitiendo el análisis del comportamiento de los sistemas, mediante la validacíon de las diferentes propiedades que lo caracterizan a través de trazas reales.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>866</post_id>
		<post_date><![CDATA[2016-04-24 05:12:25]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:12:25]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[ptac-una-herramienta-para-testing-pasivo-de-sistemas-con-comunicaciones-asincronas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="prueba-de-software"><![CDATA[Prueba de software]]></category>
		<category domain="post_tag" nicename="pruebas-pasivas"><![CDATA[pruebas pasivas]]></category>
		<category domain="post_tag" nicename="sistemas-asincronos"><![CDATA[sistemas asíncronos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[867]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen Las técnicas de pruebas pasivas nos ofrecen la ventaja de poder testear sistemas con los cuales no es posible la interacción directa. Actualmente, la gran mayoría de las propuestas basadas en este concepto asumen que las trazas analizadas reflejan el comportamiento real del sistema, sin tener en cuenta el canal a través del cual han sido observadas. Si la comunicación es asíncrona, la traza observada puede no corresponderse con la producida durante la ejecución del sistema. La necesidad de considerar este tipo de aspectos, llevó a la propuesta de una nueva metodología de pruebas pasivas centrada en canales asíncronos First Input First Output (FIFO). En este artículo se presenta PTAC, una herramienta software que automatiza la aplicación de esta técnica, permitiendo el análisis del comportamiento de los sistemas, mediante la validacíon de las diferentes propiedades que lo caracterizan a través de trazas reales.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Prueba de software, pruebas pasivas, sistemas asíncronos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ma Azahara Camacho Magriñán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software, Departamento de Ingeniería Informática Universidad de Cádiz, Escuela Superior de Ingeniería, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[azahara.camacmagri@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software, Departamento de Ingeniería Informática Universidad de Cádiz, Escuela Superior de Ingeniería, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Mercedes G. Merayo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universidad Complutense de Madrid, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mgmerayo@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/022]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Demostración de NDT-Driver: una herramienta de soporte a los mecanismos de transformación de NDT</title>
		<link>https://biblioteca.sistedes.es/articulo/demostracion-de-ndt-driver-una-herramienta-de-soporte-a-los-mecanismos-de-transformacion-de-ndt/</link>
		<pubDate>Sun, 24 Apr 2016 03:14:37 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=869</guid>
		<description></description>
		<content><![CDATA[En el contexto del paradigma de ingeniería guiada por modelos (MDE), el uso de metodologías ­como es el caso de NDT (Navigational Development Techniques) ­ ayuda a asegurar la calidad de los resultados durante el desarrollo software. Sin embargo, en el día a día de las empresas que trabajan bajo el paraguas de este tipo de metodologías, muy a menudo acaecen problemas que no deberían darse y que provocan en última instancia, que la aplicación de las fases metodológicas sean consideradas como una mera formalidad sin utilidad aparente. Además, la definición teórica de metodologías hace impracticable su aplicación en contextos empresariales debido al uso de una terminología demasiado abstracta (metamodelos, transformaciones, conceptos, etc.). Por esto, se hace necesario desarrollar herramientas de soporte metodológico que oculten esta terminología teórica para mejorar su aplicabilidad. Este artículo presenta una demostración de NDT-Driver, una herramienta de soporte de la metodología NDT que permite a las empresas aprovechar todo el potencial de MDE de una manera transparente, sin tener que conocer conceptos tan abstractos como el de transformación de modelos. Actualmente, esta herramienta está siendo utilizada de forma satisfactoria en entornos reales de diferentes ámbitos de negocio.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>869</post_id>
		<post_date><![CDATA[2016-04-24 05:14:37]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:14:37]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[demostracion-de-ndt-driver-una-herramienta-de-soporte-a-los-mecanismos-de-transformacion-de-ndt]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="herramienta"><![CDATA[Herramienta]]></category>
		<category domain="post_tag" nicename="herramienta-basadas-en-modelos"><![CDATA[Herramienta Basadas en Modelos]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<category domain="post_tag" nicename="ndt"><![CDATA[NDT]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[870]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En el contexto del paradigma de ingeniería guiada por modelos (MDE), el uso de metodologías ­como es el caso de NDT (Navigational Development Techniques) ­ ayuda a asegurar la calidad de los resultados durante el desarrollo software. Sin embargo, en el día a día de las empresas que trabajan bajo el paraguas de este tipo de metodologías, muy a menudo acaecen problemas que no deberían darse y que provocan en última instancia, que la aplicación de las fases metodológicas sean consideradas como una mera formalidad sin utilidad aparente. Además, la definición teórica de metodologías hace impracticable su aplicación en contextos empresariales debido al uso de una terminología demasiado abstracta (metamodelos, transformaciones, conceptos, etc.). Por esto, se hace necesario desarrollar herramientas de soporte metodológico que oculten esta terminología teórica para mejorar su aplicabilidad. Este artículo presenta una demostración de NDT-Driver, una herramienta de soporte de la metodología NDT que permite a las empresas aprovechar todo el potencial de MDE de una manera transparente, sin tener que conocer conceptos tan abstractos como el de transformación de modelos. Actualmente, esta herramienta está siendo utilizada de forma satisfactoria en entornos reales de diferentes ámbitos de negocio.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ Model-Driven Engineering, Herramienta Basadas en Modelos, Herramienta, NDT]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[J. A. García-García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación IWT2. Universidad de Sevilla, Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[julian.garcia@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[M.J. Escalona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación IWT2. Universidad de Sevilla, Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mjescalona@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/021]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>DB-Main/Models: Un caso de estudio sobre la interoperabilidad de herramientas basada en MDE</title>
		<link>https://biblioteca.sistedes.es/articulo/db-mainmodels-un-caso-de-estudio-sobre-la-interoperabilidad-de-herramientas-basada-en-mde/</link>
		<pubDate>Sun, 24 Apr 2016 03:17:44 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=872</guid>
		<description></description>
		<content><![CDATA[La Ingeniería del Software Dirigida por Modelos (MDE) promueve la utilización sistemática de modelos para mejorar el nivel de abstraccíon en la construccíon de software y con ello proporcionar mejoras significativas en la productividad. Las técnicas MDE además de ser útiles para automatizar cualquier etapa del ciclo de vida del desarrollo de software, tambíen facilitan la integracíon de espacios tecnológicos y la interoperabilidad de herramientas y sistemas. En este artículo se presenta un caso de estudio sobre la integracíon de la herramienta DB-Main en el espacio tecnológico MDE (Modelware) y la interoperabilidad con otras herramientas haciendo uso de modelos. DB-Main es una herramienta bien conocida en Ingeniería de Datos que ha sido desarrollada por la empresa ReveR, spin-off surgida del grupo de investigación Precise (Universidad de Namur, Bélgica). DB-Main ofrece funcionalidad relacionada con procesos de diseño, transformaciones de datos, ingeniería inversa de datos, análisis de programas y evolución de datos. El trabajo muestra un análisis de varias posibles estrategias de interoperabilidad basada en modelos aplicadas a DB-Main, señalando algunas de las ventajas e inconvenientes encontrados y discutiendo la conveniencia de cada una de las alternativas presentadas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>872</post_id>
		<post_date><![CDATA[2016-04-24 05:17:44]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:17:44]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[db-mainmodels-un-caso-de-estudio-sobre-la-interoperabilidad-de-herramientas-basada-en-mde]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="db-main"><![CDATA[DB-Main]]></category>
		<category domain="post_tag" nicename="ingenieria-de-datos"><![CDATA[Ingeniería de datos]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software-basada-en-modelos"><![CDATA[Ingeniería del Software Basada en Modelos]]></category>
		<category domain="post_tag" nicename="integracion"><![CDATA[Integración]]></category>
		<category domain="post_tag" nicename="interoperabilidad"><![CDATA[Interoperabilidad]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[873]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La Ingeniería del Software Dirigida por Modelos (MDE) promueve la utilización sistemática de modelos para mejorar el nivel de abstraccíon en la construccíon de software y con ello proporcionar mejoras significativas en la productividad. Las técnicas MDE además de ser útiles para automatizar cualquier etapa del ciclo de vida del desarrollo de software, tambíen facilitan la integracíon de espacios tecnológicos y la interoperabilidad de herramientas y sistemas. En este artículo se presenta un caso de estudio sobre la integracíon de la herramienta DB-Main en el espacio tecnológico MDE (Modelware) y la interoperabilidad con otras herramientas haciendo uso de modelos. DB-Main es una herramienta bien conocida en Ingeniería de Datos que ha sido desarrollada por la empresa ReveR, spin-off surgida del grupo de investigación Precise (Universidad de Namur, Bélgica). DB-Main ofrece funcionalidad relacionada con procesos de diseño, transformaciones de datos, ingeniería inversa de datos, análisis de programas y evolución de datos. El trabajo muestra un análisis de varias posibles estrategias de interoperabilidad basada en modelos aplicadas a DB-Main, señalando algunas de las ventajas e inconvenientes encontrados y discutiendo la conveniencia de cada una de las alternativas presentadas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Ingeniería del Software Basada en Modelos, Ingeniería de datos, DB-Main, Integración, Interoperabilidad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Javier Bermúdez Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática y Sistemas Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fjavier@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jesús García Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática y Sistemas Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jmolina@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Oscar Díaz García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos Universidad del Pais Vasco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[oscar.diaz@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/041]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automatizando el desarrollo de editores gráficos cognitivamente eficaces</title>
		<link>https://biblioteca.sistedes.es/articulo/automatizando-el-desarrollo-de-editores-graficos-cognitivamente-eficaces/</link>
		<pubDate>Sun, 24 Apr 2016 03:21:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=875</guid>
		<description></description>
		<content><![CDATA[Los lenguajes específicos de dominio juegan un papel fundamental en el desarrollo de software dirigido por modelos, en cuanto permiten obtener una mayor expresividad y facilidad de uso respecto a un lenguaje de propósito general. La creación de editores gráficos para trabajar con este tipo de lenguajes no es una tarea trivial, aunque actualmente existen diferentes entornos de desarrollo que proporcionan el soporte para llevar a cabo dicha creación. Mediante el análisis de las principales características de dichos entornos, hemos identificado algunos aspectos de mejora relacionados con la eficacia cognitiva de las notaciones visuales y con la automatizacíon de todo el proceso de desarrollo de un editor gráfico. Por este motivo, en este trabajo introducimos CEViNEdit, una herramienta basada en GMF que proporciona mecanismos que permiten guiar la seleccíon de las variables visuales que componen la notación, evaluar la eficacia cognitiva de dicha seleccíon y automatizar la generación del editor gráfico.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>875</post_id>
		<post_date><![CDATA[2016-04-24 05:21:05]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:21:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automatizando-el-desarrollo-de-editores-graficos-cognitivamente-eficaces]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="automatizacion"><![CDATA[automatización]]></category>
		<category domain="post_tag" nicename="eficacia-cognitiva"><![CDATA[Eficacia Cognitiva]]></category>
		<category domain="post_tag" nicename="ingenieria-dirigida-por-modelos"><![CDATA[Ingeniería Dirigida por Modelos]]></category>
		<category domain="post_tag" nicename="lenguaje-especifico-de-dominio"><![CDATA[Lenguaje Específico de Dominio]]></category>
		<category domain="post_tag" nicename="notacion-visual"><![CDATA[Notacíon Visual]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[876]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los lenguajes específicos de dominio juegan un papel fundamental en el desarrollo de software dirigido por modelos, en cuanto permiten obtener una mayor expresividad y facilidad de uso respecto a un lenguaje de propósito general. La creación de editores gráficos para trabajar con este tipo de lenguajes no es una tarea trivial, aunque actualmente existen diferentes entornos de desarrollo que proporcionan el soporte para llevar a cabo dicha creación. Mediante el análisis de las principales características de dichos entornos, hemos identificado algunos aspectos de mejora relacionados con la eficacia cognitiva de las notaciones visuales y con la automatizacíon de todo el proceso de desarrollo de un editor gráfico. Por este motivo, en este trabajo introducimos CEViNEdit, una herramienta basada en GMF que proporciona mecanismos que permiten guiar la seleccíon de las variables visuales que componen la notación, evaluar la eficacia cognitiva de dicha seleccíon y automatizar la generación del editor gráfico.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Ingeniería Dirigida por Modelos, Lenguaje Específico de Dominio, Notacíon Visual, Automatización, Eficacia Cognitiva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos, Calle Tulipán S/N, 28933 Móstoles, Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[david.granada@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Angel Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos, Calle Tulipán S/N, 28933 Móstoles, Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[angel.moreno@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan M. Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos, Calle Tulipán S/N, 28933 Móstoles, Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Verónica A. Bollati]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos, Calle Tulipán S/N, 28933 Móstoles, Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[veronica.bollati@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos, Calle Tulipán S/N, 28933 Móstoles, Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/040]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SEPL: Social Environment Programming Language</title>
		<link>https://biblioteca.sistedes.es/articulo/sepl-social-environment-programming-language/</link>
		<pubDate>Sun, 24 Apr 2016 03:24:12 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=878</guid>
		<description></description>
		<content><![CDATA[En los últimos años el uso de redes y aplicaciones sociales ha colonizado muchos procesos en organizaciones. Esto ha derivado en falta de automatizacíon de los mismos, y en la necesidad de conectarse manualmente a diferentes redes para realizar estas tareas repetitivas. Proponemos SEPL, un DSL que se conecta con varias redes y aplicaciones sociales, para permitir automatizar estos procesos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>878</post_id>
		<post_date><![CDATA[2016-04-24 05:24:12]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:24:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[sepl-social-environment-programming-language]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="desarrollo-de-software-dirigido-por-modelos"><![CDATA[Desarrollo de Software Dirigido por Modelos]]></category>
		<category domain="post_tag" nicename="lenguajes-especificos-del-dominio"><![CDATA[Lenguajes específicos del dominio]]></category>
		<category domain="post_tag" nicename="redes-sociales"><![CDATA[Redes sociales]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[879]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años el uso de redes y aplicaciones sociales ha colonizado muchos procesos en organizaciones. Esto ha derivado en falta de automatizacíon de los mismos, y en la necesidad de conectarse manualmente a diferentes redes para realizar estas tareas repetitivas. Proponemos SEPL, un DSL que se conecta con varias redes y aplicaciones sociales, para permitir automatizar estos procesos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ Desarrollo de software dirigido por modelos, Lenguajes específicos del dominio, Redes sociales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Luis-María García-Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group, Universidad de Extremadura ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[luismaex@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alvaro Gutíerrez-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group, Universidad de Extremadura ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[agutierrez@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Rober Morales-Chaparro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group, Universidad de Extremadura ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[robermorales@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Fernando Sánchez-Figueroa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group, Universidad de Extremadura ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[fernando@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/039]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Proceso de verificacíon de reglas de transformacíon basado en métricas</title>
		<link>https://biblioteca.sistedes.es/articulo/proceso-de-verificacion-de-reglas-de-transformacion-basado-en-metricas/</link>
		<pubDate>Sun, 24 Apr 2016 03:27:20 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=881</guid>
		<description></description>
		<content><![CDATA[La Ingeniería Dirigida por Modelos (IDM) se basa fundamentalmente en la definición de metamodelos, la edicíon de modelos y la especificacíon de transformaciones entre éstos (MMT, Model-to-Model Transformations). En muchos casos el desarrollo, evolución y adaptacíon de estas transformaciones se sigue realizando sin apoyarse en métodos o herramientas que permitan reducir el esfuerzo y los costes asociados a estas actividades. En este trabajo se presenta un proceso que permite medir el grado en que las reglas que implementan dichas transformaciones se adecúan a su especificacíon. Para ello, se plantea el proceso de verificación de MMT como un proceso de extracción de informacíon aplicándose métricas ampliamente utilizadas en este tipo de escenarios. Este trabajo de verificacíon de MMT se ha desarrollado y probado en la adaptacíon de reglas de transformación dentro del proyecto MIGRARIA.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>881</post_id>
		<post_date><![CDATA[2016-04-24 05:27:20]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:27:20]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[proceso-de-verificacion-de-reglas-de-transformacion-basado-en-metricas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mdd"><![CDATA[MDD]]></category>
		<category domain="post_tag" nicename="mdsd"><![CDATA[MDSD]]></category>
		<category domain="post_tag" nicename="metricas"><![CDATA[métricas]]></category>
		<category domain="post_tag" nicename="transformacion"><![CDATA[transformacíon]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[882]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La Ingeniería Dirigida por Modelos (IDM) se basa fundamentalmente en la definición de metamodelos, la edicíon de modelos y la especificacíon de transformaciones entre éstos (MMT, Model-to-Model Transformations). En muchos casos el desarrollo, evolución y adaptacíon de estas transformaciones se sigue realizando sin apoyarse en métodos o herramientas que permitan reducir el esfuerzo y los costes asociados a estas actividades. En este trabajo se presenta un proceso que permite medir el grado en que las reglas que implementan dichas transformaciones se adecúan a su especificacíon. Para ello, se plantea el proceso de verificación de MMT como un proceso de extracción de informacíon aplicándose métricas ampliamente utilizadas en este tipo de escenarios. Este trabajo de verificacíon de MMT se ha desarrollado y probado en la adaptacíon de reglas de transformación dentro del proyecto MIGRARIA.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[MDD, transformacíon, métricas, MDSD]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Fernando Macías]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura, Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fernandomacias@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Roberto Rodríguez-Echeverría]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura, Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[rre@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Víctor M. Pavón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura, Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[victorpavon@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José M. Conejero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura, Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[chemacm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[ Fernando Sánchez-Figueroa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura, Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[fernando@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/038]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Primitive Operators for the Concurrent Execution of Model Transformations Based on LinTra</title>
		<link>https://biblioteca.sistedes.es/articulo/primitive-operators-for-the-concurrent-execution-of-model-transformations-based-on-lintra/</link>
		<pubDate>Sun, 24 Apr 2016 03:30:33 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=884</guid>
		<description></description>
		<content><![CDATA[Performance and scalability of model transformations are becoming prominent topics in Model-Driven Engineering. In previous work, we introduced LinTra, a platform for executing out-place model transformations in parallel. LinTra is based on the Linda coordination language for archiving concurrency and distribution and is intended to be used as a middleware where high-level model transformation languages (such as ATL and QVT) are compiled. To define modularly the compilation, this paper presents a minimal, yet sufficient, collection of primitive operators that can be composed to (re-)construct any out-place, unidirectional model transformation language (MTL). These primitives enable any MTL to be executed in parallel in a transparent way, without altering the original transformation.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>884</post_id>
		<post_date><![CDATA[2016-04-24 05:30:33]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:30:33]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[primitive-operators-for-the-concurrent-execution-of-model-transformations-based-on-lintra]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="lintra"><![CDATA[LinTra]]></category>
		<category domain="post_tag" nicename="model-transformation"><![CDATA[Model Transformation]]></category>
		<category domain="post_tag" nicename="primitives"><![CDATA[Primitives]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[885]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Performance and scalability of model transformations are becoming prominent topics in Model-Driven Engineering. In previous work, we introduced LinTra, a platform for executing out-place model transformations in parallel. LinTra is based on the Linda coordination language for archiving concurrency and distribution and is intended to be used as a middleware where high-level model transformation languages (such as ATL and QVT) are compiled. To define modularly the compilation, this paper presents a minimal, yet sufficient, collection of primitive operators that can be composed to (re-)construct any out-place, unidirectional model transformation language (MTL). These primitives enable any MTL to be executed in parallel in a transparent way, without altering the original transformation.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Model Transformation, Primitives, LinTra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Loli Burgueño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, GISUM/Atenea Research Group, Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[loli@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Vallecillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, GISUM/Atenea Research Group, Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[av@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Eugene Syriani]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Alabama, Department of Computer Science, Tuscaloosa AL, U.S.A.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[esyriani@cs.ua.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jeff Gray]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Alabama, Department of Computer Science, Tuscaloosa AL, U.S.A.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[gray@cs.ua.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Manuel Wimmer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[ienna University of Technology, Business Informatics Group, Vienna, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[wimmer@big.tuwien.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/037]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Propuesta de modelado de requerimientos en paradigmas de Ingeniería Web Ágil guiada por modelos</title>
		<link>https://biblioteca.sistedes.es/articulo/propuesta-de-modelado-de-requerimientos-en-paradigmas-de-ingenieria-web-agil-guiada-por-modelos/</link>
		<pubDate>Sun, 24 Apr 2016 03:34:26 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=887</guid>
		<description></description>
		<content><![CDATA[El paradigma guiado por modelos ha sido utilizado en los últimos años para promover mejores resultados en el desarrollo de Aplicaciones Web, en el campo que se ha denominado Ingeniería Web Guiada por Modelos (MDWE, Model-Driven Web Engineering). Por otro lado se ha demostrado que las metodologías ágiles se adaptan de manera muy adecuada a los entornos web, al estar centradas en técnicas empíricas e iterativas sobre las necesidades de los usuarios y tener la flexibilidad adecuada a la hora de adaptarse a los cambios de los mismos y del entorno. En cualquier caso, el punto de partida de ambos son los requerimientos. Sin embargo, ambos puntos de partida tienen diferencias, ya que los requerimientos en técnicas ágiles difieren a los utilizados en los paradigmas MDWE debido a que estos últimos necesitan estar completamente definidos antes de ser transformados. El objeto del presente trabajo es proponer la estructura de un requerimiento ágil fundamentado en las Historia de Usuario, que pueda ser abordado usando las transformaciones de la ingeniería guida por modelo, intentando conjugar lo mejor de ambos paradigmas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>887</post_id>
		<post_date><![CDATA[2016-04-24 05:34:26]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:34:26]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[propuesta-de-modelado-de-requerimientos-en-paradigmas-de-ingenieria-web-agil-guiada-por-modelos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="historia-de-usuario"><![CDATA[Historia de Usuario]]></category>
		<category domain="post_tag" nicename="ingenieria-web"><![CDATA[Ingeniería Web]]></category>
		<category domain="post_tag" nicename="metodologias-agiles"><![CDATA[Metodologías Ágiles]]></category>
		<category domain="post_tag" nicename="model-driven-web-engineering"><![CDATA[Model-Driven Web Engineering]]></category>
		<category domain="post_tag" nicename="scrum"><![CDATA[Scrum]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[888]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El paradigma guiado por modelos ha sido utilizado en los últimos años para promover mejores resultados en el desarrollo de Aplicaciones Web, en el campo que se ha denominado Ingeniería Web Guiada por Modelos (MDWE, Model-Driven Web Engineering). Por otro lado se ha demostrado que las metodologías ágiles se adaptan de manera muy adecuada a los entornos web, al estar centradas en técnicas empíricas e iterativas sobre las necesidades de los usuarios y tener la flexibilidad adecuada a la hora de adaptarse a los cambios de los mismos y del entorno. En cualquier caso, el punto de partida de ambos son los requerimientos. Sin embargo, ambos puntos de partida tienen diferencias, ya que los requerimientos en técnicas ágiles difieren a los utilizados en los paradigmas MDWE debido a que estos últimos necesitan estar completamente definidos antes de ser transformados. El objeto del presente trabajo es proponer la estructura de un requerimiento ágil fundamentado en las Historia de Usuario, que pueda ser abordado usando las transformaciones de la ingeniería guida por modelo, intentando conjugar lo mejor de ambos paradigmas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Metodologías Ágiles, Ingeniería Web, Scrum, Model-Driven Web Engineering, Historia de Usuario]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[J. Sedeño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jorge.sedeno@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[C.J. Torrecilla-Salinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[carlos.torrecilla@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[M.J.Escalona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mjescalona,@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[M. Mejías]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[risoto@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/036]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Introducing Approximate Model Transformations</title>
		<link>https://biblioteca.sistedes.es/articulo/introducing-approximate-model-transformations/</link>
		<pubDate>Sun, 24 Apr 2016 03:36:58 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=890</guid>
		<description></description>
		<content><![CDATA[Model transformations dealing with very large models need to count on mechanisms and tools to be able to manage them. The usual approach to improve performance in these cases has focused on the use of concurrency and parallelization techniques, which aim at producing the correct output model(s). In this paper we present our initial approach to produce target models that are accurate enough to provide meaningful and useful results, in an efficient way, but without having to be fully correct. We introduce the concept of Approximate Model Transformations.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>890</post_id>
		<post_date><![CDATA[2016-04-24 05:36:58]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:36:58]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[introducing-approximate-model-transformations]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="approximation"><![CDATA[Approximation]]></category>
		<category domain="post_tag" nicename="model-transformation"><![CDATA[Model Transformation]]></category>
		<category domain="post_tag" nicename="performance"><![CDATA[Performance]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[891]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Model transformations dealing with very large models need to count on mechanisms and tools to be able to manage them. The usual approach to improve performance in these cases has focused on the use of concurrency and parallelization techniques, which aim at producing the correct output model(s). In this paper we present our initial approach to produce target models that are accurate enough to provide meaningful and useful results, in an efficient way, but without having to be fully correct. We introduce the concept of Approximate Model Transformations.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Model Transformation, Approximation, Performance]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Troya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Vienna University of Technology, Business Informatics Group, Austria ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[troya@big.tuwien.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Vallecillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, ETSI Informática, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ av@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/035]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>DSL-2-Browser: Un ejemplo de ejecución de un lenguaje específico del dominio en un navegador</title>
		<link>https://biblioteca.sistedes.es/articulo/dsl-2-browser-un-ejemplo-de-ejecucion-de-un-lenguaje-especifico-del-dominio-en-un-navegador/</link>
		<pubDate>Sun, 24 Apr 2016 03:39:28 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=893</guid>
		<description></description>
		<content><![CDATA[En este trabajo se expone, mediante un ejemplo, la viabilidad de ejecutar un DSL en un navegador web. Para ello se ha usado principalmente Xtext y GWT sobre el caso concreto de un DSL de visualizacíon de datos. Aunque la propuesta se realiza a través de un ejemplo concreto, es posible su generalizacíon para otros DSL.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>893</post_id>
		<post_date><![CDATA[2016-04-24 05:39:28]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:39:28]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[dsl-2-browser-un-ejemplo-de-ejecucion-de-un-lenguaje-especifico-del-dominio-en-un-navegador]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="desarrollo-de-software-dirigido-por-modelos"><![CDATA[Desarrollo de Software Dirigido por Modelos]]></category>
		<category domain="post_tag" nicename="ingenieria-web"><![CDATA[Ingeniería Web]]></category>
		<category domain="post_tag" nicename="javascript"><![CDATA[JavaScript]]></category>
		<category domain="post_tag" nicename="lenguajes-especificos-del-dominio"><![CDATA[Lenguajes específicos del dominio]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[894]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este trabajo se expone, mediante un ejemplo, la viabilidad de ejecutar un DSL en un navegador web. Para ello se ha usado principalmente Xtext y GWT sobre el caso concreto de un DSL de visualizacíon de datos. Aunque la propuesta se realiza a través de un ejemplo concreto, es posible su generalizacíon para otros DSL.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Desarrollo de software dirigido por modelos, Ingeniería Web, Lenguajes específicos del dominio, JavaScript]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alvaro Gutíerrez-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group, Universidad de Extremadura ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[agutierrez@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Luis-María García-Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group, Universidad de Extremadura ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[luismaex@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Rober Morales-Chaparro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group, Universidad de Extremadura ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[robermorales@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Fernando Sánchez-Figueroa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group, Universidad de Extremadura ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[fernando@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/034]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>MDD vs. traditional software development: A practitioner&#039;s subjective perspective</title>
		<link>https://biblioteca.sistedes.es/articulo/mdd-vs-traditional-software-development-a-practitioners-subjective-perspective/</link>
		<pubDate>Sun, 24 Apr 2016 03:42:30 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=896</guid>
		<description></description>
		<content><![CDATA[Today practitioners have a myriad of methods from which to choose for the development of software applications. However they lack empirical data that characterize these methods in terms of usefulness, ease of use or compatibility, all of them relevant variables to assess the developer's intention to use them. In this context, we propose to compare three methods, each following a different paradigm (Model-Driven, Model-Based and the traditional, code-centric, respectively) with respect to its intention to use by junior software developers while developing the business layer of a Web 2.0 application. To do that, we have conducted an experiment with graduate students of the University of Alicante. The application developed was a Social Network, which was organized in three different modules. Subjects were asked to use a different method for each one of the three modules, and then answer a questionnaire that gathered their perceptions during its use. The results show that the method that followed the Model-Driven development paradigm is regarded as the most useful, although it is also regarded as the more difficult to use. They also show that junior software developers feel comfortable with the use of models, and are likely to use them if accompanied by a model-driven development environment.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>896</post_id>
		<post_date><![CDATA[2016-04-24 05:42:30]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:42:30]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mdd-vs-traditional-software-development-a-practitioners-subjective-perspective]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="code-centric-development"><![CDATA[code-centric development]]></category>
		<category domain="post_tag" nicename="compatibility"><![CDATA[compatibility]]></category>
		<category domain="post_tag" nicename="ease-of-use"><![CDATA[ease of use]]></category>
		<category domain="post_tag" nicename="experiment"><![CDATA[experiment]]></category>
		<category domain="post_tag" nicename="intention-to-use"><![CDATA[intention to use]]></category>
		<category domain="post_tag" nicename="mbd"><![CDATA[MBD]]></category>
		<category domain="post_tag" nicename="mdd"><![CDATA[MDD]]></category>
		<category domain="post_tag" nicename="usefulness"><![CDATA[usefulness]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[897]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Today practitioners have a myriad of methods from which to choose for the development of software applications. However they lack empirical data that characterize these methods in terms of usefulness, ease of use or compatibility, all of them relevant variables to assess the developer's intention to use them. In this context, we propose to compare three methods, each following a different paradigm (Model-Driven, Model-Based and the traditional, code-centric, respectively) with respect to its intention to use by junior software developers while developing the business layer of a Web 2.0 application. To do that, we have conducted an experiment with graduate students of the University of Alicante. The application developed was a Social Network, which was organized in three different modules. Subjects were asked to use a different method for each one of the three modules, and then answer a questionnaire that gathered their perceptions during its use. The results show that the method that followed the Model-Driven development paradigm is regarded as the most useful, although it is also regarded as the more difficult to use. They also show that junior software developers feel comfortable with the use of models, and are likely to use them if accompanied by a model-driven development environment.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[MDD, MBD, code-centric development, experiment, usefulness, ease of use, compatibility, intention to use]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Yulkeidi Martínez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Máximo Gómez Báez de Ciego de Avila, Cuba ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[yulkeidi@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Cristina Cachero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Alicante, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ccachero@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Santiago Meliá]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Alicante, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[santi@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/033]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>PRISMA: Model-Driven Development of AspectOriented Software Architectures</title>
		<link>https://biblioteca.sistedes.es/articulo/prisma-model-driven-development-of-aspectoriented-software-architectures/</link>
		<pubDate>Sun, 24 Apr 2016 03:45:59 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=899</guid>
		<description></description>
		<content><![CDATA[This summary presents a methodology for supporting the development of AOSAs following the MDD paradigm. This new methodology is called PRISMA and allows the code generation from models which specify functional and non-functional requirements.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>899</post_id>
		<post_date><![CDATA[2016-04-24 05:45:59]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:45:59]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[prisma-model-driven-development-of-aspectoriented-software-architectures]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="aspect-oriented-software-architectures"><![CDATA[Aspect-Oriented Software Architectures]]></category>
		<category domain="post_tag" nicename="code-generation"><![CDATA[code generation]]></category>
		<category domain="post_tag" nicename="mdd"><![CDATA[MDD]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[900]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This summary presents a methodology for supporting the development of AOSAs following the MDD paradigm. This new methodology is called PRISMA and allows the code generation from models which specify functional and non-functional requirements.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[MDD, Aspect-Oriented Software Architectures, code generation]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jennifer Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Technical University of Madrid (UPM) - ETSISI-CITSEM, Madrid, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jenifer.perez@eui.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Isidro Ramos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Valencia (UPV) - DSIC, Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ iramos@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose A. Carsí]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Valencia (UPV) - DSIC, Valencia, Spain  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pcarsi@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Cristóbal Costa-Soria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[lobal Metanoia S.L., Paterna Technological Science Park (Valencia), Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[ccosta@globalmetanoia.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/032]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Language for End-user Web Augmentation: Caring for Producers and Consumers Alike</title>
		<link>https://biblioteca.sistedes.es/articulo/a-language-for-end-user-web-augmentation-caring-for-producers-and-consumers-alike/</link>
		<pubDate>Sun, 24 Apr 2016 03:48:34 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=902</guid>
		<description></description>
		<content><![CDATA[This work advocates for the use of Domain Specific Languages to empower hobby programmers to achieve their own scripts for Web Augmentation (a special kind of applications to customize web pages). The work follows Mernik's methodology whereby the DSL is gradually constructed from the feature model to the concrete syntax.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>902</post_id>
		<post_date><![CDATA[2016-04-24 05:48:34]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:48:34]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-language-for-end-user-web-augmentation-caring-for-producers-and-consumers-alike]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="domain-specific-language"><![CDATA[Domain Specific Language]]></category>
		<category domain="post_tag" nicename="javascript"><![CDATA[JavaScript]]></category>
		<category domain="post_tag" nicename="web-augmentation"><![CDATA[Web Augmentation]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[903]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This work advocates for the use of Domain Specific Languages to empower hobby programmers to achieve their own scripts for Web Augmentation (a special kind of applications to customize web pages). The work follows Mernik's methodology whereby the DSL is gradually constructed from the feature model to the concrete syntax.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Web Augmentation, Domain Specific Language, JavaScript]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Oscar Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU), San Sebastián (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[oscar.diaz@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Cristóbal Arellano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU), San Sebastián (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cristobal.arellano@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Maider Azanza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU), San Sebastián (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[maider.azanza@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/031]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Herramienta de soporte en procesos de modernización, para las fases de ingeniería inversa y reestructuracíon</title>
		<link>https://biblioteca.sistedes.es/articulo/herramienta-de-soporte-en-procesos-de-modernizacion-para-las-fases-de-ingenieria-inversa-y-reestructuracion/</link>
		<pubDate>Sun, 24 Apr 2016 03:52:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=905</guid>
		<description></description>
		<content><![CDATA[El proyecto MIGRARIA define un proceso dirigido por modelos para la modernización de aplicaciones web heredadas. Una vez definido y validado el proceso, se ha puesto en marcha el desarrollo de una herramienta que asista al ingeniero de modernizacíon en las fases de ingeniería inversa y reestructuración. El objetivo de este trabajo es presentar el prototipo de esta herramienta, cuyas funcionalidades base son: ofrecer un editor de modelos MIGRARIA MVC que facilite la comprensión del sistema heredado; facilitar la navegacíon bidireccional entre los artefactos software de la aplicación heredada y su representación abstracta (modelos MIGRARIA MVC); y simplificar la configuración y automatizar la ejecución del proceso de ingeniería inversa.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>905</post_id>
		<post_date><![CDATA[2016-04-24 05:52:49]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:52:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[herramienta-de-soporte-en-procesos-de-modernizacion-para-las-fases-de-ingenieria-inversa-y-reestructuracion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="desarrollo-de-software-dirigido-por-modelos"><![CDATA[Desarrollo de Software Dirigido por Modelos]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="ngenieria-inversa"><![CDATA[ngeniería Inversa]]></category>
		<category domain="post_tag" nicename="ria"><![CDATA[RIA]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[906]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El proyecto MIGRARIA define un proceso dirigido por modelos para la modernización de aplicaciones web heredadas. Una vez definido y validado el proceso, se ha puesto en marcha el desarrollo de una herramienta que asista al ingeniero de modernizacíon en las fases de ingeniería inversa y reestructuración. El objetivo de este trabajo es presentar el prototipo de esta herramienta, cuyas funcionalidades base son: ofrecer un editor de modelos MIGRARIA MVC que facilite la comprensión del sistema heredado; facilitar la navegacíon bidireccional entre los artefactos software de la aplicación heredada y su representación abstracta (modelos MIGRARIA MVC); y simplificar la configuración y automatizar la ejecución del proceso de ingeniería inversa.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ngeniería Inversa, Desarrollo de Software Dirigido por Modelos, MDE, RIA]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Víctor M. Pavón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura, Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[victorpavon@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Roberto Rodríguez-Echeverría]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura, Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[rre@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Fernando Macías]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura, Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fernandomacias@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Pedro J. Clemente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura, Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[pjclemente@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Fernando Sánchez-Figueroa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura, Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[fernando@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/030]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>CERVANTES: Un framework para el diseño y desarrollo de sistemas distribuidos</title>
		<link>https://biblioteca.sistedes.es/articulo/cervantes-un-framework-para-el-diseno-y-desarrollo-de-sistemas-distribuidos/</link>
		<pubDate>Sun, 24 Apr 2016 03:56:35 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=908</guid>
		<description></description>
		<content><![CDATA[En la actualidad vivimos una continua evolución en los sistemas informáticos que nos rodean: cada vez son de mayor tamaño, cubren más funcionalidades y es necesario que interactúen con otros sistemas ya existentes. El desarrollo de estos sistemas es por tanto una tarea compleja que sin embargo ha evolucionado a un menor ritmo. En los últimos años han surgido iniciativas como el desarrollo dirigido por modelos (MDE ), la computacíon basada en servicios (SOC ) o la ingeniería del software orientada a servicios (SOSE ). En este trabajo se presenta una herramienta, basada en los conceptos de MDE y SOC, que desde el año 2002 se ha venido utilizando en la práctica con la industria para el diseño y desarrollo de sistemas distribuidos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>908</post_id>
		<post_date><![CDATA[2016-04-24 05:56:35]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 03:56:35]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[cervantes-un-framework-para-el-diseno-y-desarrollo-de-sistemas-distribuidos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="clave-model-driven-engineering"><![CDATA[Clave Model Driven Engineering]]></category>
		<category domain="post_tag" nicename="service-oriented-computing"><![CDATA[Service Oriented Computing]]></category>
		<category domain="post_tag" nicename="service-oriented-system-engineering"><![CDATA[Service-Oriented System Engineering]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[909]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En la actualidad vivimos una continua evolución en los sistemas informáticos que nos rodean: cada vez son de mayor tamaño, cubren más funcionalidades y es necesario que interactúen con otros sistemas ya existentes. El desarrollo de estos sistemas es por tanto una tarea compleja que sin embargo ha evolucionado a un menor ritmo. En los últimos años han surgido iniciativas como el desarrollo dirigido por modelos (MDE ), la computacíon basada en servicios (SOC ) o la ingeniería del software orientada a servicios (SOSE ). En este trabajo se presenta una herramienta, basada en los conceptos de MDE y SOC, que desde el año 2002 se ha venido utilizando en la práctica con la industria para el diseño y desarrollo de sistemas distribuidos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Clave Model Driven Engineering, Service Oriented Computing, Service-Oriented System Engineering]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[M.A. Barcelona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto Tecnológico de Aragón, c/ María de Luna 7, 50018 Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mabarcelona@ita.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[L. García-Borgoñón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto Tecnológico de Aragón, c/ María de Luna 7, 50018 Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[laurag@ita.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[J.I. Calvo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto Tecnológico de Aragón, c/ María de Luna 7, 50018 Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jicalvo@ita.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[M.J. Escalona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Av. Reina Mercedes S/N, 41012 Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mjescalona@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/029]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Análisis de la aplicabilidad de medidas software para el diseño semi-automático de arquitecturas</title>
		<link>https://biblioteca.sistedes.es/articulo/analisis-de-la-aplicabilidad-de-medidas-software-para-el-diseno-semi-automatico-de-arquitecturas/</link>
		<pubDate>Sun, 24 Apr 2016 04:00:36 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=911</guid>
		<description></description>
		<content><![CDATA[Dar soporte semi-automático al ingeniero software durante la fase de diseño arquitectónico es una tarea compleja, pues se deben manejar múltiples alternativas de diseño que satisfagan criterios de calidad de interés para el ingeniero. Cuando en el contexto de los sistemas de soporte a la decisíon se emplean técnicas metaheurísticas, estos criterios deben ser trasladados a medidas precisas que sean computacionalmente evaluables sobre las soluciones generadas automáticamente. Este trabajo analiza la problemática asociada a la utilizacíon de medidas software en el ámbito del diseño de arquitecturas basadas en componentes mediante técnicas de optimizacíon y búsqueda. Para ello se han analizado medidas relacionadas con los dos atributos de calidad más relevantes para este tipo de arquitecturas: la adecuacíon funcional y la mantenibilidad. El estudio realizado muestra que, si bien existe una gran variedad de medidas software, aún quedan diferentes aspectos que pueden limitar su aplicabilidad en el diseño semi-automático de arquitecturas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>911</post_id>
		<post_date><![CDATA[2016-04-24 06:00:36]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 04:00:36]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analisis-de-la-aplicabilidad-de-medidas-software-para-el-diseno-semi-automatico-de-arquitecturas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="diseno-arquitectonico"><![CDATA[Diseño arquitectónico]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software-basada-en-busqueda"><![CDATA[ingeniería del software basada en búsqueda]]></category>
		<category domain="post_tag" nicename="medidas-software"><![CDATA[medidas software]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[912]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Dar soporte semi-automático al ingeniero software durante la fase de diseño arquitectónico es una tarea compleja, pues se deben manejar múltiples alternativas de diseño que satisfagan criterios de calidad de interés para el ingeniero. Cuando en el contexto de los sistemas de soporte a la decisíon se emplean técnicas metaheurísticas, estos criterios deben ser trasladados a medidas precisas que sean computacionalmente evaluables sobre las soluciones generadas automáticamente. Este trabajo analiza la problemática asociada a la utilizacíon de medidas software en el ámbito del diseño de arquitecturas basadas en componentes mediante técnicas de optimizacíon y búsqueda. Para ello se han analizado medidas relacionadas con los dos atributos de calidad más relevantes para este tipo de arquitecturas: la adecuacíon funcional y la mantenibilidad. El estudio realizado muestra que, si bien existe una gran variedad de medidas software, aún quedan diferentes aspectos que pueden limitar su aplicabilidad en el diseño semi-automático de arquitecturas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Diseño arquitectónico, ingeniería del software basada en búsqueda, medidas software]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aurora Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico Universidad de Córdoba, Campus de Rabanales, 14071 Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aramirez@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Raúl Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico Universidad de Córdoba, Campus de Rabanales, 14071 Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sebastían Ventura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico Universidad de Córdoba, Campus de Rabanales, 14071 Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sventura@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/050]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Propuesta de metodología de despliegue de aplicaciones en nubes heterogéneas con TOSCA</title>
		<link>https://biblioteca.sistedes.es/articulo/propuesta-de-metodologia-de-despliegue-de-aplicaciones-en-nubes-heterogeneas-con-tosca/</link>
		<pubDate>Sun, 24 Apr 2016 04:02:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=914</guid>
		<description></description>
		<content><![CDATA[ Desplegar y controlar una aplicación compleja sobre un conjunto heterogéneo de proveedores es un problema muy novedoso y complejo al que los clientes de las plataformas de cloud se deben de enfrentar. Los proveedores exponen sus servicios de acuerdo a especificaciones independientes incurriendo en una falta de portabilidad e interoperabilidad que converge en la problemática conocida como vendor lock-in. Han surgido varias propuestas que aportan soluciones a este ámbito, como el estándar TOSCA que permite describir una aplicación y automatizar su despliegue de forma automática sobre un único proveedor. Extendiendo el estándar mencionado, en este trabajo proponemos una metodología de despliegue y orquestacíon de los componentes de una aplicacíon en un entorno multi-cloud mediante el uso simultáneo de servicios de diferentes proveedores. Palabras clave: Cloud Computing; Despliegue multi-cloud; Componentes cloud; Orquestacíon de servicios; TOSCA.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>914</post_id>
		<post_date><![CDATA[2016-04-24 06:02:53]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 04:02:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[propuesta-de-metodologia-de-despliegue-de-aplicaciones-en-nubes-heterogeneas-con-tosca]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[915]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[ Desplegar y controlar una aplicación compleja sobre un conjunto heterogéneo de proveedores es un problema muy novedoso y complejo al que los clientes de las plataformas de cloud se deben de enfrentar. Los proveedores exponen sus servicios de acuerdo a especificaciones independientes incurriendo en una falta de portabilidad e interoperabilidad que converge en la problemática conocida como vendor lock-in. Han surgido varias propuestas que aportan soluciones a este ámbito, como el estándar TOSCA que permite describir una aplicación y automatizar su despliegue de forma automática sobre un único proveedor. Extendiendo el estándar mencionado, en este trabajo proponemos una metodología de despliegue y orquestacíon de los componentes de una aplicacíon en un entorno multi-cloud mediante el uso simultáneo de servicios de diferentes proveedores. Palabras clave: Cloud Computing; Despliegue multi-cloud; Componentes cloud; Orquestacíon de servicios; TOSCA.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jose Carrasco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga Departamento de Lenguajes y Ciencias de la Computacíon, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[josec@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Cubo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga Departamento de Lenguajes y Ciencias de la Computacíon, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cubo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ernesto Pimentel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga Departamento de Lenguajes y Ciencias de la Computacíon, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ernesto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/049]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Configurable feature models</title>
		<link>https://biblioteca.sistedes.es/articulo/configurable-feature-models/</link>
		<pubDate>Sun, 24 Apr 2016 04:05:27 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=917</guid>
		<description></description>
		<content><![CDATA[Feature models represent all the products that can be built under a variability-intensive system such as a software product line, but they are not fully configurable. There exist no explicit effort in defining configuration models that enable making decisions on attributes and cardinalities in feature models that use these artefacts. In this paper we present configurable feature models as an evolution from feature models that integrate configuration models within, improving the configurability of variability-intensive systems.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>917</post_id>
		<post_date><![CDATA[2016-04-24 06:05:27]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 04:05:27]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[configurable-feature-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="configurable-feature-models"><![CDATA[configurable feature models]]></category>
		<category domain="post_tag" nicename="configuration"><![CDATA[configuration]]></category>
		<category domain="post_tag" nicename="model"><![CDATA[model]]></category>
		<category domain="post_tag" nicename="software-product-lines"><![CDATA[software product lines]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Feature models represent all the products that can be built under a variability-intensive system such as a software product line, but they are not fully configurable. There exist no explicit effort in defining configuration models that enable making decisions on attributes and cardinalities in feature models that use these artefacts. In this paper we present configurable feature models as an evolution from feature models that integrate configuration models within, improving the configurability of variability-intensive systems.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[software product lines, configurable feature models, configuration, model]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Trinidad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ptrinidad@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesús García-Galán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jegalan@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[918]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/048]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un Enfoque Basado en Modelos para incorporar Requisitos No Funcionales y de Integración de Software en el Diseño de Arquitecturas Orientadas a Servicios</title>
		<link>https://biblioteca.sistedes.es/articulo/un-enfoque-basado-en-modelos-para-incorporar-requisitos-no-funcionales-y-de-integracion-de-software-en-el-diseno-de-arquitecturas-orientadas-a-servicios/</link>
		<pubDate>Sun, 24 Apr 2016 04:08:10 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=920</guid>
		<description></description>
		<content><![CDATA[El interés creciente por parte de las organizaciones de desarrollo de software para disponer de metodologías y herramientas para aumentar la calidad de los productos y reducir el tiempo de desarrollo, exige introducir mejoras continuas que permitan agilizar y automatizar partes de los procesos. Navigational Development Techniques (NDT) es una metodología que cubre todas las fases del proceso de desarrollo y que ha tenido una gran aplicacíon práctica en la industria en los últimos años. Este trabajo pretende realizar una propuesta basada en modelos para definir requisitos no funcionales (RNF) y de integracíon de software, en especial los que pueden afectar al diseño de la arquitectura de sistemas distribuidos, como son la eficiencia y la escalabilidad, y establecer mecanismos de transformacíon para que puedan ser trazados y considerados en el diseño arquitectónico de un sistema dentro de NDT. En este trabajo emergente se presenta el problema a resolver, el estado del arte, la metodología que vamos a seguir y los principales resultados que esperamos obtener con nuestra investigación.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>920</post_id>
		<post_date><![CDATA[2016-04-24 06:08:10]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 04:08:10]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-enfoque-basado-en-modelos-para-incorporar-requisitos-no-funcionales-y-de-integracion-de-software-en-el-diseno-de-arquitecturas-orientadas-a-servicios]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="arquitecturas-orientadas-a-servicio"><![CDATA[Arquitecturas Orientadas a Servicio]]></category>
		<category domain="post_tag" nicename="enfoque-basado-en-modelos"><![CDATA[Enfoque Basado en Modelos]]></category>
		<category domain="post_tag" nicename="integracion-de-componentes-software"><![CDATA[Integración de componentes software]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<category domain="post_tag" nicename="navigational-development-techniques"><![CDATA[Navigational Development Techniques]]></category>
		<category domain="post_tag" nicename="requisitos-no-funcionales"><![CDATA[Requisitos No Funcionales]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[921]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El interés creciente por parte de las organizaciones de desarrollo de software para disponer de metodologías y herramientas para aumentar la calidad de los productos y reducir el tiempo de desarrollo, exige introducir mejoras continuas que permitan agilizar y automatizar partes de los procesos. Navigational Development Techniques (NDT) es una metodología que cubre todas las fases del proceso de desarrollo y que ha tenido una gran aplicacíon práctica en la industria en los últimos años. Este trabajo pretende realizar una propuesta basada en modelos para definir requisitos no funcionales (RNF) y de integracíon de software, en especial los que pueden afectar al diseño de la arquitectura de sistemas distribuidos, como son la eficiencia y la escalabilidad, y establecer mecanismos de transformacíon para que puedan ser trazados y considerados en el diseño arquitectónico de un sistema dentro de NDT. En este trabajo emergente se presenta el problema a resolver, el estado del arte, la metodología que vamos a seguir y los principales resultados que esperamos obtener con nuestra investigación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Requisitos No Funcionales, Navigational Development Techniques, Arquitecturas Orientadas a Servicio, Enfoque Basado en Modelos, Model Driven Engineering, Integración de componentes software]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[M. Guessous]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto Tecnológico de Aragón, c/ María de Luna 7, 50018 Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mguessous@ita.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[M.A. Barcelona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto Tecnológico de Aragón, c/ María de Luna 7, 50018 Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mabarcelona@ita.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[L. García-Borgoñón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto Tecnológico de Aragón, c/ María de Luna 7, 50018 Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[laurag@ita.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[M. Alba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Av. Reina Mercedes S/N, 41012 Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manuel.alba@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/047]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>People as a Service: a mobile-centric model for providing collective sociological profiles</title>
		<link>https://biblioteca.sistedes.es/articulo/people-as-a-service-a-mobile-centric-model-for-providing-collective-sociological-profiles/</link>
		<pubDate>Sun, 24 Apr 2016 04:11:24 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=923</guid>
		<description></description>
		<content><![CDATA[Mobile devices have become increasingly popular in the everyday life of many individuals. By taking an insight into the most common uses of mobile devices we clearly appreciate that accessing internetbased services has grown greatly. This, and the fact that they are extremely personal gadgets has turned them into the main interface used by individuals to express themselves towards the outside world and to receive information from others. As a result of the highly personal use, mobile devices have been granted the potential to become unrivaled devices for building and storing the virtual profiles of their owners. Access to such profiles is of great interest in fields such as governance, health, smart cities, etc. Generating a centralized profile of a user is a task upon which a lot of interest has been put in the field of social mining. Peopleas-a-Service (PeaaS) is a computing model that seeks to establish the foundations upon which technologies that rely on mobile-centric computing models for social purposes should evolve.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>923</post_id>
		<post_date><![CDATA[2016-04-24 06:11:24]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 04:11:24]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[people-as-a-service-a-mobile-centric-model-for-providing-collective-sociological-profiles]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mobile-devices"><![CDATA[Mobile devices]]></category>
		<category domain="post_tag" nicename="people-as-a-service"><![CDATA[People as a Service]]></category>
		<category domain="post_tag" nicename="sociological-profiles"><![CDATA[Sociological Profiles]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[924]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Mobile devices have become increasingly popular in the everyday life of many individuals. By taking an insight into the most common uses of mobile devices we clearly appreciate that accessing internetbased services has grown greatly. This, and the fact that they are extremely personal gadgets has turned them into the main interface used by individuals to express themselves towards the outside world and to receive information from others. As a result of the highly personal use, mobile devices have been granted the potential to become unrivaled devices for building and storing the virtual profiles of their owners. Access to such profiles is of great interest in fields such as governance, health, smart cities, etc. Generating a centralized profile of a user is a task upon which a lot of interest has been put in the field of social mining. Peopleas-a-Service (PeaaS) is a computing model that seeks to establish the foundations upon which technologies that rely on mobile-centric computing models for social purposes should evolve.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Sociological profiles, Mobile devices, People as a Service]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jose Garcia-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Information Technology and Telematic Systems Engineering, University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Miranda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Gloin, Calle de las Ocas 2,  Caceres, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jmiranda@gloin.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Information Technology and Telematic Systems Engineering, University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Information Technology and Telematic Systems Engineering, University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science, University of Malaga, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/046]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Change-Impact driven Agile Architecting</title>
		<link>https://biblioteca.sistedes.es/articulo/change-impact-driven-agile-architecting/</link>
		<pubDate>Sun, 24 Apr 2016 04:15:00 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=926</guid>
		<description></description>
		<content><![CDATA[his summary presents a solution based on the use of change-impact knowledge as the main driver for agile architecting. The solution consists of a Change Impact Analysis technique and a set of models to assist agile architects in the change (decision-making) process by retrieving the change-impact architectural knowledge resulting from adding or changing features iteration after iteration.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>926</post_id>
		<post_date><![CDATA[2016-04-24 06:15:00]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 04:15:00]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[change-impact-driven-agile-architecting]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="agile-architecting"><![CDATA[agile architecting]]></category>
		<category domain="post_tag" nicename="agile-software-development"><![CDATA[Agile software development]]></category>
		<category domain="post_tag" nicename="change-impact-analysis"><![CDATA[change-impact analysis]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[927]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[his summary presents a solution based on the use of change-impact knowledge as the main driver for agile architecting. The solution consists of a Change Impact Analysis technique and a set of models to assist agile architects in the change (decision-making) process by retrieving the change-impact architectural knowledge resulting from adding or changing features iteration after iteration.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Agile software development, agile architecting, change-impact analysis]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jessica Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Technical University of Madrid (UPM) - Universidad Politécnica de Madrid CITSEM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jdiaz@eui.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jennifer Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Technical University of Madrid (UPM) - Universidad Politécnica de Madrid CITSEM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jenifer.perez@eui.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Garbajosa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Technical University of Madrid (UPM) - Universidad Politécnica de Madrid CITSEM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jgs@eui.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Agustín Yagüe]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Systems & Software Technology Group (SYST), ETSISI, Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[agustin.yague@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/045]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Self-Adaptation of Mobile Systems with Dynamic Software Product Lines</title>
		<link>https://biblioteca.sistedes.es/articulo/self-adaptation-of-mobile-systems-with-dynamic-software-product-lines/</link>
		<pubDate>Sun, 24 Apr 2016 04:17:47 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=929</guid>
		<description></description>
		<content><![CDATA[Mobile ecosystems are generally long-lived and sometimes operate in inaccessible areas, so they require support for self-adaptation to the continuous context changes. Dynamic Software Product Lines (DSPLs) produce software products capable of adapting to requirements that change at runtime. We propose a DSPL-based self-adaptation process especially designed for mobile system requirements, such as context and device heterogeneity. We follow a lightweight model@run.time approach, by using variability models to generate, at runtime, the products adapted to the context changes, but without loading the models in the mobile devices. In addition, our approach takes into account the quality-of-service as part of the decision making process.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>929</post_id>
		<post_date><![CDATA[2016-04-24 06:17:47]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 04:17:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[self-adaptation-of-mobile-systems-with-dynamic-software-product-lines]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="dynamic-software-product-lines"><![CDATA[Dynamic Software Product Lines]]></category>
		<category domain="post_tag" nicename="self-adaptation"><![CDATA[Self-Adaptation]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[930]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Mobile ecosystems are generally long-lived and sometimes operate in inaccessible areas, so they require support for self-adaptation to the continuous context changes. Dynamic Software Product Lines (DSPLs) produce software products capable of adapting to requirements that change at runtime. We propose a DSPL-based self-adaptation process especially designed for mobile system requirements, such as context and device heterogeneity. We follow a lightweight model@run.time approach, by using variability models to generate, at runtime, the products adapted to the context changes, but without loading the models in the mobile devices. In addition, our approach takes into account the quality-of-service as part of the decision making process.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Self-Adaptation, Dynamic Software Product Lines]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Nadia Gamez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dpto de Lenguajes y Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[nadia@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dpto de Lenguajes y Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José María Troya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dpto de Lenguajes y Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[troya@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/044]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automated Analysis of Diverse Variability Models with Tool Support</title>
		<link>https://biblioteca.sistedes.es/articulo/automated-analysis-of-diverse-variability-models-with-tool-support/</link>
		<pubDate>Sun, 24 Apr 2016 04:21:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=932</guid>
		<description></description>
		<content><![CDATA[Over the past twenty years, there have been many contributions in the area of feature model automated analysis of variability models. We propose that the knowledge obtained during recent years to automatically analyse diverse variability models. In this paper we present FaMa OVM and FaMa DEB, which are prototypical implementations for the automated analysis of two distinct variability models, namely Orthogonal Variability Models and Debian Variablity Models, respectively. In order to minimise efforts and benefit from the feature model know­ how, we use FaMa Framework which allows the development of analysis tools for diverse variability modelling languages. This framework provides a well tested system that guides the tool development. Due to the structure provided by the framework, FaMa OVM and FaMa DEB tools are easy to extend and integrate with other tools. We report on the main points of both tools, such as the analysis operations provided and the logical solvers used for the analysis.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>932</post_id>
		<post_date><![CDATA[2016-04-24 06:21:48]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 04:21:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automated-analysis-of-diverse-variability-models-with-tool-support]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="automated-analysis"><![CDATA[Automated analysis]]></category>
		<category domain="post_tag" nicename="intensive-variability-systems"><![CDATA[Intensive variability systems]]></category>
		<category domain="post_tag" nicename="variability-models"><![CDATA[Variability models]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[933]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Over the past twenty years, there have been many contributions in the area of feature model automated analysis of variability models. We propose that the knowledge obtained during recent years to automatically analyse diverse variability models. In this paper we present FaMa OVM and FaMa DEB, which are prototypical implementations for the automated analysis of two distinct variability models, namely Orthogonal Variability Models and Debian Variablity Models, respectively. In order to minimise efforts and benefit from the feature model know­ how, we use FaMa Framework which allows the development of analysis tools for diverse variability modelling languages. This framework provides a well tested system that guides the tool development. Due to the structure provided by the framework, FaMa OVM and FaMa DEB tools are easy to extend and integrate with other tools. We report on the main points of both tools, such as the analysis operations provided and the logical solvers used for the analysis.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Variability models, Intensive variability systems, Automated analysis]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Fabricia Roos-Frantz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fabriciaroos@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José A. Galindo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[jagalindo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[David Benavides]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[benavides@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Jesús García-Galán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[jegalan@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/043]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>WindRose: A Cloud Based IDE for the Automated Analysis of Feature Models</title>
		<link>https://biblioteca.sistedes.es/articulo/windrose-a-cloud-based-ide-for-the-automated-analysis-of-feature-models/</link>
		<pubDate>Sun, 24 Apr 2016 04:24:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=935</guid>
		<description></description>
		<content><![CDATA[Feature modeling is the "de facto" standard to describe the common and variant parts of software product lines. Different tools, approaches and operations for the automated analysis of feature models have been proposed in the last 20 years. However, the installation and usage of those tools use to be time consuming. In this paper we present the WindRose IDE, a cloud based IDE that allows the storage, edition and analysis of feature models while being executed in the cloud. WindRose integrates different feature model analysis operations such as Valid or Number of Products. This reasoning capabilities rely in different well stablished tools like FaMa or FaMiliar.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>935</post_id>
		<post_date><![CDATA[2016-04-24 06:24:49]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 04:24:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[windrose-a-cloud-based-ide-for-the-automated-analysis-of-feature-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="automated-analysis"><![CDATA[Automated analysis]]></category>
		<category domain="post_tag" nicename="tool-integration"><![CDATA[Tool integration]]></category>
		<category domain="post_tag" nicename="variability-modeling"><![CDATA[Variability Modeling]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[936]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Feature modeling is the "de facto" standard to describe the common and variant parts of software product lines. Different tools, approaches and operations for the automated analysis of feature models have been proposed in the last 20 years. However, the installation and usage of those tools use to be time consuming. In this paper we present the WindRose IDE, a cloud based IDE that allows the storage, edition and analysis of feature models while being executed in the cloud. WindRose integrates different feature model analysis operations such as Valid or Number of Products. This reasoning capabilities rely in different well stablished tools like FaMa or FaMiliar.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Variability Modeling, Tool integration, Automated Analysis]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José A. Galindo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jagalindo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David Benavides]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[benavides@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Mauricio Alférez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Mathieu Acher]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Benoit Baudry]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2014/042]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Software Testing and/or Software Monitoring: Differences and Commonalities</title>
		<link>https://biblioteca.sistedes.es/articulo/software-testing-andor-software-monitoring-differences-and-commonalities-2/</link>
		<pubDate>Sun, 24 Apr 2016 04:31:20 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=947</guid>
		<description></description>
		<content><![CDATA[ Validation is an essential part of the software life cycle. The actual functional and non-functional behaviour of an application needs to be checked against the expected or intended behaviour. Both testing and monitoring are widely used approaches for this purpose. More traditionally testing is considered as a technique for fault removal and forecasting during development. Monitoring is instead conceived for run-time observation of deployed software. Testing and monitoring approaches are usually contrasted as being, respectively, in-the-laboratory vs. in-the-field, and active vs. passive. In this talk I will overview concepts and techniques for software testing and monitoring, and will discuss how for modern pervasive and dynamic software systems the two approaches tend to converge in combined and synergic ways.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>947</post_id>
		<post_date><![CDATA[2016-04-24 06:31:20]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 04:31:20]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[software-testing-andor-software-monitoring-differences-and-commonalities-2]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[948]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[ Validation is an essential part of the software life cycle. The actual functional and non-functional behaviour of an application needs to be checked against the expected or intended behaviour. Both testing and monitoring are widely used approaches for this purpose. More traditionally testing is considered as a technique for fault removal and forecasting during development. Monitoring is instead conceived for run-time observation of deployed software. Testing and monitoring approaches are usually contrasted as being, respectively, in-the-laboratory vs. in-the-field, and active vs. passive. In this talk I will overview concepts and techniques for software testing and monitoring, and will discuss how for modern pervasive and dynamic software systems the two approaches tend to converge in combined and synergic ways.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonia Bertolino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ISTI-CNR Via Moruzzi, 1 Pisa, Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[antonia.bertolino@isti.cnr.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/002]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automatic Identification of Service Candidates from Business Process Models</title>
		<link>https://biblioteca.sistedes.es/articulo/automatic-identification-of-service-candidates-from-business-process-models-2/</link>
		<pubDate>Sun, 24 Apr 2016 04:33:14 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=951</guid>
		<description></description>
		<content><![CDATA[Although several approaches for service identification have been defined in research and practice, none of them considers the potential of fully automating the associated phases. As a result, users have to invest a substantial amount of manual work. In this paper, we address the problem of manual work in the context of service identification and present an approach for automatically deriving service candidates from business process models. Our approach combines different analysis techniques in a novel way in order to derive ranked lists of service candidates. The approach is meant to be a useful aid for enabling business and IT managers to quickly spot reuse potential in their company. We demonstrate the usefulness of our approach by reporting on the results from an evaluation with a process model collection from industry.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>951</post_id>
		<post_date><![CDATA[2016-04-24 06:33:14]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 04:33:14]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automatic-identification-of-service-candidates-from-business-process-models-2]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[952]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Although several approaches for service identification have been defined in research and practice, none of them considers the potential of fully automating the associated phases. As a result, users have to invest a substantial amount of manual work. In this paper, we address the problem of manual work in the context of service identification and present an approach for automatically deriving service candidates from business process models. Our approach combines different analysis techniques in a novel way in order to derive ranked lists of service candidates. The approach is meant to be a useful aid for enabling business and IT managers to quickly spot reuse potential in their company. We demonstrate the usefulness of our approach by reporting on the results from an evaluation with a process model collection from industry.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Henrik Leopold]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Wirtschaftsuniversita¨t Wien, Welthandelsplatz 1, 1020 Vienna, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[henrik.leopold@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jan Mendling]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Wirtschaftsuniversita¨t Wien, Welthandelsplatz 1, 1020 Vienna, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jan.mendling@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/001]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Being Digital: The Power of the Bits. Science, University and Industry Perspective</title>
		<link>https://biblioteca.sistedes.es/articulo/being-digital-the-power-of-the-bits-science-university-and-industry-perspective/</link>
		<pubDate>Sun, 24 Apr 2016 04:37:10 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=955</guid>
		<description></description>
		<content><![CDATA[This book, made of "unwieldy atoms", will probably be replaced by a digital copy by the time anyone reads it, stated Nicholas Negroponte when presented "Being Digital" in 1995. Nevertheless, the process of digitization during the last two decades has probably moved far beyond what he could have imagined at that time.
Currently, there is a wide consensus on the fact that we are living a major transition, and that information technology (IT) powered services will have a relevant impact in terms of employment, business and economy. Computing, data analytics and, more in general, IT powered services will play an everyday more active role in our lives. The current speed of the technology is leading to foresee that business in the future will be carried out differently than today.
However, the potential of IT technology is still far from being efficiently applied addressing key social challenges such as sustainability, education, health and many others currently challenging future generations. Existing barriers among science, university and industry innovation approaches, combined with the current speed of the technologies in the field, are limiting the development of efficient innovation ecosystems.
The speech, jointly prepared by representatives from science, university and industry, will analyse the current digitalisation process in these sectors, current challenges in science-university-industry innovation cycle and collaborative efforts trying to address the existing gaps. It also considers a slot for discussions/debate within software and services research community.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>955</post_id>
		<post_date><![CDATA[2016-04-24 06:37:10]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 04:37:10]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[being-digital-the-power-of-the-bits-science-university-and-industry-perspective]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[956]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This book, made of "unwieldy atoms", will probably be replaced by a digital copy by the time anyone reads it, stated Nicholas Negroponte when presented "Being Digital" in 1995. Nevertheless, the process of digitization during the last two decades has probably moved far beyond what he could have imagined at that time.
Currently, there is a wide consensus on the fact that we are living a major transition, and that information technology (IT) powered services will have a relevant impact in terms of employment, business and economy. Computing, data analytics and, more in general, IT powered services will play an everyday more active role in our lives. The current speed of the technology is leading to foresee that business in the future will be carried out differently than today.
However, the potential of IT technology is still far from being efficiently applied addressing key social challenges such as sustainability, education, health and many others currently challenging future generations. Existing barriers among science, university and industry innovation approaches, combined with the current speed of the technologies in the field, are limiting the development of efficient innovation ecosystems.
The speech, jointly prepared by representatives from science, university and industry, will analyse the current digitalisation process in these sectors, current challenges in science-university-industry innovation cycle and collaborative efforts trying to address the existing gaps. It also considers a slot for discussions/debate within software and services research community.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús Bermejo Muñoz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[SGi Users' Forum Spain http://spain.osgiusers.org/]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jesus@bermejo.link]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carlos Fernández Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Supercomputing Centre of Galicia https://cesga.es/en/cesga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[carlosf@cesga.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jordi Guijarro Olivares]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Consorci de Serveis Universitaris de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jordi.guijarro@csuc.cat]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/003]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Mobile End-User Tool for Service Compositions</title>
		<link>https://biblioteca.sistedes.es/articulo/a-mobile-end-user-tool-for-service-compositions/</link>
		<pubDate>Sun, 24 Apr 2016 04:40:44 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=960</guid>
		<description></description>
		<content><![CDATA[With the advent of Web 2.0 and the massive adoption of smartphones, end-users are more keen to actively participate in the creation of content for the Internet. In addition, the big amount of data that the Internet of Things can bring to it, establishes an ideal framework to allow end-users not just consuming data but also creating new valueadded services. To achieve this, in this work we propose the development of an end-user tool for smartphones capable of composing services that are available in the Internet.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>960</post_id>
		<post_date><![CDATA[2016-04-24 06:40:44]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 04:40:44]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-mobile-end-user-tool-for-service-compositions]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[961]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[With the advent of Web 2.0 and the massive adoption of smartphones, end-users are more keen to actively participate in the creation of content for the Internet. In addition, the big amount of data that the Internet of Things can bring to it, establishes an ideal framework to allow end-users not just consuming data but also creating new valueadded services. To achieve this, in this work we propose the development of an end-user tool for smartphones capable of composing services that are available in the Internet.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ignacio Mansanet]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia, Spain Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[vtorres@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Victoria Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia, Spain Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[imansanet@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pedro Valderas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia, Spain Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pvalderas@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia, Spain Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[pele@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/008]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Alineación de modelos de negocio y software: un método orientado a servicios centrado en la arquitectura</title>
		<link>https://biblioteca.sistedes.es/articulo/alineacion-de-modelos-de-negocio-y-software-un-metodo-orientado-a-servicios-centrado-en-la-arquitectura/</link>
		<pubDate>Sun, 24 Apr 2016 04:44:36 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=963</guid>
		<description></description>
		<content><![CDATA[La alineación de negocios con soluciones tecnológicas orientadas a servicios se ha mostrado como un aspecto de vital importancia en la empresa moderna. En este sentido, la provisión de métodos para solventar el salto de negocio a tecnología se hace totalmente necesaria. Este artículo presenta una propuesta que pretende sistematizar ese salto mediante la definición de un método de desarrollo centrado en la arquitectura. La utilización de diferentes modelos arquitectónicos a diferentes niveles de abstracción junto con la definición de transformaciones entre modelos permite establecer una traza entre elementos de nivel de negocio y los elementos software que se deriven de ellos como soporte tecnológico. Los beneficios clave de nuestra propuesta son, por un lado, la provisión del método en sí para la alineación negocio-tecnología y, por otro lado, la definición de un nuevo modelo para representar la estructura de un negocio. Esta propuesta ha sido refinada utilizando el caso de un sistema de información para la gestión de percentiles pediátricos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>963</post_id>
		<post_date><![CDATA[2016-04-24 06:44:36]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 04:44:36]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[alineacion-de-modelos-de-negocio-y-software-un-metodo-orientado-a-servicios-centrado-en-la-arquitectura]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="alineacion-negocio-tecnologia"><![CDATA[Alineación negocio-tecnología]]></category>
		<category domain="post_tag" nicename="desarrollo-dirigido-por-modelos"><![CDATA[Desarrollo dirigido por modelos]]></category>
		<category domain="post_tag" nicename="orientacion-a-servicios"><![CDATA[Orientación a servicios]]></category>
		<category domain="post_tag" nicename="procesos-de-desarrollo-centrados-en-la-arquitectura"><![CDATA[Procesos de desarrollo centrados en la arquitectura]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[967]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La alineación de negocios con soluciones tecnológicas orientadas a servicios se ha mostrado como un aspecto de vital importancia en la empresa moderna. En este sentido, la provisión de métodos para solventar el salto de negocio a tecnología se hace totalmente necesaria. Este artículo presenta una propuesta que pretende sistematizar ese salto mediante la definición de un método de desarrollo centrado en la arquitectura. La utilización de diferentes modelos arquitectónicos a diferentes niveles de abstracción junto con la definición de transformaciones entre modelos permite establecer una traza entre elementos de nivel de negocio y los elementos software que se deriven de ellos como soporte tecnológico. Los beneficios clave de nuestra propuesta son, por un lado, la provisión del método en sí para la alineación negocio-tecnología y, por otro lado, la definición de un nuevo modelo para representar la estructura de un negocio. Esta propuesta ha sido refinada utilizando el caso de un sistema de información para la gestión de percentiles pediátricos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Alineación negocio-tecnología, Procesos de desarrollo centrados en la arquitectura, Orientación a servicios, Desarrollo dirigido por modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Marcos López-Sanz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Tulipán S/N, 28933, Móstoles, Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[marcos.lopez@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Valeria de Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Tulipán S/N, 28933, Móstoles, Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[valeria.decastro@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Tulipán S/N, 28933, Móstoles, Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/007]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generating reliable services composition using A-policies: a model-driven approach</title>
		<link>https://biblioteca.sistedes.es/articulo/generating-reliable-services-composition-using-a-policies-a-model-driven-approach/</link>
		<pubDate>Sun, 24 Apr 2016 04:49:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=969</guid>
		<description></description>
		<content><![CDATA[This paper presents an approach for modeling and associat-
ing A-Policies to services' based applications. It proposes to extend the SOD-M model driven method with (i) the -SCM an A-Policy services'
composition meta-model for representing non-functional constraints associated to services' based applications; (ii) the -Pews meta-model providing guidelines for expressing the composition and the policies; and, (iii) model to model and model to text transformation rules for semiautomatizing the implementation of reliable services' compositions.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>969</post_id>
		<post_date><![CDATA[2016-04-24 06:49:50]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 04:49:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generating-reliable-services-composition-using-a-policies-a-model-driven-approach]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mdd"><![CDATA[MDD]]></category>
		<category domain="post_tag" nicename="non-functional-properties"><![CDATA[Non-functional Properties]]></category>
		<category domain="post_tag" nicename="service-oriented-applications"><![CDATA[Service Oriented Applications]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[970]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper presents an approach for modeling and associat-
ing A-Policies to services' based applications. It proposes to extend the SOD-M model driven method with (i) the -SCM an A-Policy services'
composition meta-model for representing non-functional constraints associated to services' based applications; (ii) the -Pews meta-model providing guidelines for expressing the composition and the policies; and, (iii) model to model and model to text transformation rules for semiautomatizing the implementation of reliable services' compositions.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[MDD, Service Oriented Applications, Non-functional Properties]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Genoveva Vargas-Solar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[French Council of Scientic Research, LIG-LAFMIA, Grenoble, France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[enoveva.Vargas-Solar@imag.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Valeria de Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Rey Juan Carlos, Móstoles, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Valeria.deCastro@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Plácido Antonio de Souza Neto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto Federal do Rio Grande do Norte, Natal - RN, Brasil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[placido.neto@ifrn.edu.br]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Javier A. Espinosa-Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grenoble Institute of Technology, Grenoble, France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Javier.Espinosa@imag.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad Rey Juan Carlos, Móstoles, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Martin A. Musicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[DIMAp - UFRN, ForAll - Formal Methods and Language Research Laboratory, Natal - RN, Brasil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[mam@dimap.ufrn.br]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[José-Luis Zechinelli-Martini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[joseluis.zechinelli@udlap.mx]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Fundación Universidad de las Américas, San Andrés Cholula, Puebla, México]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_8]]></meta_key>
			<meta_value><![CDATA[Christine Collet]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_8]]></meta_key>
			<meta_value><![CDATA[Christine.Collet@grenoble-inp.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_8]]></meta_key>
			<meta_value><![CDATA[Grenoble Institute of Technology, Grenoble, France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/006]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Composition and Self-Adaptation of Service-Based Systems with Feature Models</title>
		<link>https://biblioteca.sistedes.es/articulo/composition-and-self-adaptation-of-service-based-systems-with-feature-models/</link>
		<pubDate>Sun, 24 Apr 2016 04:52:10 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=972</guid>
		<description></description>
		<content><![CDATA[The adoption of mechanisms for reusing software in pervasive systems has not yet become standard practice. This is because the use of pre-existing software requires the selection, composition and adaptation of prefabricated software parts, as well as the management of some complex problems such as guaranteeing high levels of efficiency and safety in critical domains. In addition to the wide variety of services, pervasive systems are composed of many networked heterogeneous devices with embedded software. In this work, we promote the safe reuse of services in servicebased systems using two complementary technologies, Service-Oriented Architecture and Software Product Lines. In order to do this, we extend both the service discovery and composition processes defined in the DAMASCo framework, which currently does not deal with the service variability that constitutes pervasive systems. We use feature models to represent the variability and to self-adapt the services during the composition in a safe way taking context changes into consideration. We illustrate our proposal with a case study related to the driving domain of an Intelligent Transportation System, handling the context information of the environment.
In this work, we present the integration process of the feature models (FM) into DAMASCo to deal with the services' variability in the composition. Firstly, in addition to the BPEL/WF descriptions, we have a FM for each service describing its variability. Then, each business process corresponds with a valid configuration of the FM that represents it. We focus on the representation of the service variability wrt the context. After a client executes a request, both the DAMASCo model transformation and the semantic-based service discovery process are activated. Due to the high variability of the services, it is possible that a small variation of a service could be needed. Then, a new process using FM is added to the DAMASCo framework, called service family discovery, to find a new matching as regards a certain context. A new valid configuration of that family containing this feature, representing the particular services, is automatically created, and the new service self-adaptation process added to DAMASCo is executed. Then, the CA-STS corresponding with this FM configuration is automatically created. Finally, this CA-STS interface is transformed into a WF/BPEL, composed with the services to satisfy the request.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>972</post_id>
		<post_date><![CDATA[2016-04-24 06:52:10]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 04:52:10]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[composition-and-self-adaptation-of-service-based-systems-with-feature-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[973]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The adoption of mechanisms for reusing software in pervasive systems has not yet become standard practice. This is because the use of pre-existing software requires the selection, composition and adaptation of prefabricated software parts, as well as the management of some complex problems such as guaranteeing high levels of efficiency and safety in critical domains. In addition to the wide variety of services, pervasive systems are composed of many networked heterogeneous devices with embedded software. In this work, we promote the safe reuse of services in servicebased systems using two complementary technologies, Service-Oriented Architecture and Software Product Lines. In order to do this, we extend both the service discovery and composition processes defined in the DAMASCo framework, which currently does not deal with the service variability that constitutes pervasive systems. We use feature models to represent the variability and to self-adapt the services during the composition in a safe way taking context changes into consideration. We illustrate our proposal with a case study related to the driving domain of an Intelligent Transportation System, handling the context information of the environment.
In this work, we present the integration process of the feature models (FM) into DAMASCo to deal with the services' variability in the composition. Firstly, in addition to the BPEL/WF descriptions, we have a FM for each service describing its variability. Then, each business process corresponds with a valid configuration of the FM that represents it. We focus on the representation of the service variability wrt the context. After a client executes a request, both the DAMASCo model transformation and the semantic-based service discovery process are activated. Due to the high variability of the services, it is possible that a small variation of a service could be needed. Then, a new process using FM is added to the DAMASCo framework, called service family discovery, to find a new matching as regards a certain context. A new valid configuration of that family containing this feature, representing the particular services, is automatically created, and the new service self-adaptation process added to DAMASCo is executed. Then, the CA-STS corresponding with this FM configuration is automatically created. Finally, this CA-STS interface is transformed into a WF/BPEL, composed with the services to satisfy the request.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Cubo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dpto de Lenguajes y Ciencias de la Computación ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cubo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Nadia Gamez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dpto de Lenguajes y Ciencias de la Computación ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[nadia@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dpto de Lenguajes y Ciencias de la Computación ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ernesto Pimentel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dpto de Lenguajes y Ciencias de la Computación ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[ernesto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A service-oriented framework for developing cross cloud migratable software</title>
		<link>https://biblioteca.sistedes.es/articulo/a-service-oriented-framework-for-developing-cross-cloud-migratable-software/</link>
		<pubDate>Sun, 24 Apr 2016 04:54:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=975</guid>
		<description></description>
		<content><![CDATA[Whilst cloud computing has burst into the current scene as a technology that allows companies to access high computing rates at limited costs, cloud vendors have rushed to provide tools that allow developers to build software for their cloud platforms. Cloud applications are developed using those tools, which provide different cloud-specific APIs, libraries, and even different project structures that vary depending on which cloud platform the software will be hosted. Consequently, applications developed with these tools are often tightly coupled to those platform's specific service implementations and restrictions. A scenario where component-based applications are developed for being deployed across several clouds, and each component can independently be deployed in one cloud or another, remains fictitious due to the complexity and the cost of their development.
This paper presents a cloud development framework that allows applications to be constructed as a composition of software components (cloud artefacts), where each component can be freely migrated between cloud platforms without having to redevelop the entire application. Information about cloud deployment and cloud integration is separated from the source code and managed by the framework. Interoperability between interdependent components deployed in different clouds is achieved by means of software adapters which automatically generate services and service clients. This allows software developers to segment their applications into different modules that can easily be deployed and redistributed across heterogeneous cloud platforms. This paper also analyzes the results of using the proposed framework in the development of an industrial research project as a validation of the approach.
 This work has been published in the Journal of Systems and Software 86(9), 2294-2308 (2013).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>975</post_id>
		<post_date><![CDATA[2016-04-24 06:54:48]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 04:54:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-service-oriented-framework-for-developing-cross-cloud-migratable-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[976]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Whilst cloud computing has burst into the current scene as a technology that allows companies to access high computing rates at limited costs, cloud vendors have rushed to provide tools that allow developers to build software for their cloud platforms. Cloud applications are developed using those tools, which provide different cloud-specific APIs, libraries, and even different project structures that vary depending on which cloud platform the software will be hosted. Consequently, applications developed with these tools are often tightly coupled to those platform's specific service implementations and restrictions. A scenario where component-based applications are developed for being deployed across several clouds, and each component can independently be deployed in one cloud or another, remains fictitious due to the complexity and the cost of their development.
This paper presents a cloud development framework that allows applications to be constructed as a composition of software components (cloud artefacts), where each component can be freely migrated between cloud platforms without having to redevelop the entire application. Information about cloud deployment and cloud integration is separated from the source code and managed by the framework. Interoperability between interdependent components deployed in different clouds is achieved by means of software adapters which automatically generate services and service clients. This allows software developers to segment their applications into different modules that can easily be deployed and redistributed across heterogeneous cloud platforms. This paper also analyzes the results of using the proposed framework in the development of an industrial research project as a validation of the approach.
 This work has been published in the Journal of Systems and Software 86(9), 2294-2308 (2013).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Miranda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Gloin, Calle de las Ocas 2, Cáceres, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jmiranda@gloin.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Information Technology and Telematic Systems Engineering, University of Extremadura, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science, University of Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una Propuesta Orientada a Servicios para la Prevención de Riesgos Personales Derivados de la Calidad del Aire</title>
		<link>https://biblioteca.sistedes.es/articulo/una-propuesta-orientada-a-servicios-para-la-prevencion-de-riesgos-personales-derivados-de-la-calidad-del-aire/</link>
		<pubDate>Sun, 24 Apr 2016 04:59:16 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=980</guid>
		<description></description>
		<content><![CDATA[La calidad del aire es un factor que ha tomado gran relevancia en los últimos años y que puede afectar seriamente a la salud y a la calidad de vida de los ciudadanos. Actualmente los medios que nos permiten mantenernos informados sobre la calidad del aire en general se caracterizan por no proporcionar la información en tiempo real ni mecanismos de informacíon de fácil acceso para el ciudadano y, sobre todo, no se adaptan a las condiciones específicas de cada ciudadano particular. En este artículo proponemos la implementacíon de una arquitectura orientada a servicios que nos va a permitir detectar cambios en la calidad del aire en tiempo real y poner esta informacíon a disposicíon del usuario en su móvil, notificándole inmediatamente de alertas personalizadas cuando se detecte algún nivel potencialmente peligroso para su salud, procurando así la prevención de riesgos personales.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>980</post_id>
		<post_date><![CDATA[2016-04-24 06:59:16]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 04:59:16]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-propuesta-orientada-a-servicios-para-la-prevencion-de-riesgos-personales-derivados-de-la-calidad-del-aire]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="arquitecturas-orientadas-a-servicios"><![CDATA[arquitecturas orientadas a servicios]]></category>
		<category domain="post_tag" nicename="calidad-del-aire"><![CDATA[calidad del aire]]></category>
		<category domain="post_tag" nicename="procesamiento-de-eventos-complejos"><![CDATA[procesamiento de eventos complejos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[981]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La calidad del aire es un factor que ha tomado gran relevancia en los últimos años y que puede afectar seriamente a la salud y a la calidad de vida de los ciudadanos. Actualmente los medios que nos permiten mantenernos informados sobre la calidad del aire en general se caracterizan por no proporcionar la información en tiempo real ni mecanismos de informacíon de fácil acceso para el ciudadano y, sobre todo, no se adaptan a las condiciones específicas de cada ciudadano particular. En este artículo proponemos la implementacíon de una arquitectura orientada a servicios que nos va a permitir detectar cambios en la calidad del aire en tiempo real y poner esta informacíon a disposicíon del usuario en su móvil, notificándole inmediatamente de alertas personalizadas cuando se detecte algún nivel potencialmente peligroso para su salud, procurando así la prevención de riesgos personales.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Procesamiento de eventos complejos, arquitecturas orientadas a servicios, calidad del aire]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software Departamento de Ingeniería Informática, Universidad de Cádiz, C/Chile 1, 11002 Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz Bellot]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software Departamento de Ingeniería Informática, Universidad de Cádiz, C/Chile 1, 11002 Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software Departamento de Ingeniería Informática, Universidad de Cádiz, C/Chile 1, 11002 Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/010]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>PERSEO: Identificando servicios en sistemas heredados mediante un enfoque ADM</title>
		<link>https://biblioteca.sistedes.es/articulo/perseo-identificando-servicios-en-sistemas-heredados-mediante-un-enfoque-adm/</link>
		<pubDate>Sun, 24 Apr 2016 05:02:32 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=983</guid>
		<description></description>
		<content><![CDATA[En la actualidad, las empresas se encuentran con el hecho de que sus sistemas de información empiezan a encontrarse obsoletos y sin apenas capacidad de maniobra para afrontar los cambios tanto tecnológicos como negocio que pueden surgir (y surgirán). El principal problema de esta obsolescencia es la cantidad de conocimiento embebido en el portafolio de sistemas de las empresas. Esto hace que la opción de desechar los sistemas actuales y sustituirlos por otros nuevos sea una opción que no resulta viable. La arquitectura orientada a servicios, también conocida como SOA, puede verse como otra fase dentro de la evolución del software, y que permite dotar a la infraestructura software de las empresas de esa flexibilidad de que en estos momentos adolece. Por ello, es posible que ésta sea la opción más adecuada ante la disyuntiva que se presenta con los sistemas heredados, permitiendo que los mismos evolucionen hacia este paradigma tecnológico. Este trabajo presenta una versión inicial de un entorno para la generación de especificaciones en SoaML a partir de sistemas heredados, facilitando así la migración de estos sistemas hacia el paradigma SOA.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>983</post_id>
		<post_date><![CDATA[2016-04-24 07:02:32]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 05:02:32]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[perseo-identificando-servicios-en-sistemas-heredados-mediante-un-enfoque-adm]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="kdm"><![CDATA[KDM]]></category>
		<category domain="post_tag" nicename="legacy-system"><![CDATA[legacy system]]></category>
		<category domain="post_tag" nicename="rchitecture-driven-modernization"><![CDATA[rchitecture-Driven Modernization]]></category>
		<category domain="post_tag" nicename="service-elicitation"><![CDATA[service elicitation]]></category>
		<category domain="post_tag" nicename="service-migration"><![CDATA[service migration]]></category>
		<category domain="post_tag" nicename="soaml"><![CDATA[SoaML]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[984]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En la actualidad, las empresas se encuentran con el hecho de que sus sistemas de información empiezan a encontrarse obsoletos y sin apenas capacidad de maniobra para afrontar los cambios tanto tecnológicos como negocio que pueden surgir (y surgirán). El principal problema de esta obsolescencia es la cantidad de conocimiento embebido en el portafolio de sistemas de las empresas. Esto hace que la opción de desechar los sistemas actuales y sustituirlos por otros nuevos sea una opción que no resulta viable. La arquitectura orientada a servicios, también conocida como SOA, puede verse como otra fase dentro de la evolución del software, y que permite dotar a la infraestructura software de las empresas de esa flexibilidad de que en estos momentos adolece. Por ello, es posible que ésta sea la opción más adecuada ante la disyuntiva que se presenta con los sistemas heredados, permitiendo que los mismos evolucionen hacia este paradigma tecnológico. Este trabajo presenta una versión inicial de un entorno para la generación de especificaciones en SoaML a partir de sistemas heredados, facilitando así la migración de estos sistemas hacia el paradigma SOA.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[rchitecture-Driven Modernization, service elicitation, legacy system, service migration, SoaML, KDM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ignacio García-Rodríguez de Guzmán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Institute of Information Technologies and Systems1 University of Castilla-La Mancha Camino de Moledores s/n, 13071, Ciudad Real]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Ignacio.GRodriguez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ricardo Pérez-Castillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Itestra GmbH2 Capitán Haya 1, Planta 15, 28020 Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[perez@itestra.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Institute of Information Technologies and Systems1 University of Castilla-La Mancha Camino de Moledores s/n, 13071, Ciudad Real]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Mario.Piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/009]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Embedding Widgets-as-a-Service into Dynamic GUI</title>
		<link>https://biblioteca.sistedes.es/articulo/embedding-widgets-as-a-service-into-dynamic-gui/</link>
		<pubDate>Sun, 24 Apr 2016 05:07:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=986</guid>
		<description></description>
		<content><![CDATA[The service-oriented computing offers an ideal development framework for carrying out business processes related to the dynamic management of component-based web user interfaces. This article proposes an architecture for specification, storage, management and visualization of web user interfaces built from widgets that follow the recommendation of the W3C. It describes a Widgets-as-a-Service (WaaS) approach for interface deployment and a three-level data model for the definition of components that take part in the architecture. In addition, it shows some particularities of the used technology and the implementation developed. To illustrate this proposal, an example of WaaS-based graphical interface developed for the Environmental Information Network of Andalusia (REDIAM) is shown.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>986</post_id>
		<post_date><![CDATA[2016-04-24 07:07:09]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 05:07:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[embedding-widgets-as-a-service-into-dynamic-gui]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="architectures"><![CDATA[architectures]]></category>
		<category domain="post_tag" nicename="components"><![CDATA[components]]></category>
		<category domain="post_tag" nicename="gui"><![CDATA[GUI]]></category>
		<category domain="post_tag" nicename="widgets"><![CDATA[widgets]]></category>
		<category domain="post_tag" nicename="wookie"><![CDATA[Wookie]]></category>
		<category domain="post_tag" nicename="wsdl"><![CDATA[WSDL]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[987]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The service-oriented computing offers an ideal development framework for carrying out business processes related to the dynamic management of component-based web user interfaces. This article proposes an architecture for specification, storage, management and visualization of web user interfaces built from widgets that follow the recommendation of the W3C. It describes a Widgets-as-a-Service (WaaS) approach for interface deployment and a three-level data model for the definition of components that take part in the architecture. In addition, it shows some particularities of the used technology and the implementation developed. To illustrate this proposal, an example of WaaS-based graphical interface developed for the Environmental Information Network of Andalusia (REDIAM) is shown.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[components, architectures, widgets, Wookie, WSDL, GUI]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús Vallecillos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, University of Almería, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jesus.vallecillos,@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Criado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, University of Almería, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[javi.criado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Luis Iribarne]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, University of Almería, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[luis.iribarne@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Nicolás Padilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, University of Almería, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[npadilla@ual.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards the automation of claiming in SLA-driven services</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-the-automation-of-claiming-in-sla-driven-services/</link>
		<pubDate>Sun, 24 Apr 2016 05:10:31 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=989</guid>
		<description></description>
		<content><![CDATA[Current software industry is evolving into a service­centric scenario and consequently, the importance to create reliable service consumptions amongst organizations is a key point. In such a context, the concept of Service Level Agreement (SLA) represents the foundation to express the responsibilities (i.e. rights and obligations) of service consumer and provider during the consumption. However, in spite there has been a major effort in both academia and industry to develop languages and frameworks to support SLAs, there still remain important challenges to address such as how to automate the detection of a violation of the SLAs and how to react accordingly in order to claim for a compensation. Specifically, in this paper we focus on the definition of the automated claiming of SLAs problem characterized as the set of processes of gathering, checking and explaining the evidences associated with the service consumption within the context of an SLA. In order to identify the key requirements to automate the claiming of SLAs, we analyse the real case of the Simple Storage Service (S3) provided by Amazon, that is regulated by an SLA. Based on our analysis we propose a set of extensions to current prominent SLA language specification (WS­Agreement) and conceptualize a list of research challenges to automate the management of the claiming process.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>989</post_id>
		<post_date><![CDATA[2016-04-24 07:10:31]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 05:10:31]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-the-automation-of-claiming-in-sla-driven-services]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[990]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Current software industry is evolving into a service­centric scenario and consequently, the importance to create reliable service consumptions amongst organizations is a key point. In such a context, the concept of Service Level Agreement (SLA) represents the foundation to express the responsibilities (i.e. rights and obligations) of service consumer and provider during the consumption. However, in spite there has been a major effort in both academia and industry to develop languages and frameworks to support SLAs, there still remain important challenges to address such as how to automate the detection of a violation of the SLAs and how to react accordingly in order to claim for a compensation. Specifically, in this paper we focus on the definition of the automated claiming of SLAs problem characterized as the set of processes of gathering, checking and explaining the evidences associated with the service consumption within the context of an SLA. In order to identify the key requirements to automate the claiming of SLAs, we analyse the real case of the Simple Storage Service (S3) provided by Amazon, that is regulated by an SLA. Based on our analysis we propose a set of extensions to current prominent SLA language specification (WS­Agreement) and conceptualize a list of research challenges to automate the management of the claiming process.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel Léon]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mjleon@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Metaherramienta para la generacíon de aplicaciones científicas basadas en workflows</title>
		<link>https://biblioteca.sistedes.es/articulo/metaherramienta-para-la-generacion-de-aplicaciones-cientificas-basadas-en-workflows/</link>
		<pubDate>Sun, 24 Apr 2016 05:13:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=992</guid>
		<description></description>
		<content><![CDATA[El uso de la programación visual en el ámbito científico ha contribuido al desarrollo de aplicaciones que facilitan la realizacíon de experimentos. Actualmente, existen aplicaciones para trabajar sobre un único dominio, limitadas a procedimientos propios de ese dominio, y aplicaciones multidominio, cuya complejidad para la configuracíon de sus elementos supone un gran esfuerzo para el usuario. Por tanto, es necesario ofrecer flexibilidad para trabajar sobre diversos dominios y permitir una adaptacíon intuitiva a dominios conocidos por el usuario. En este trabajo se presenta una metaherramienta para la generacíon automática de aplicaciones adaptadas a un dominio, o conjunto de dominios, para la composición y ejecucíon de workflows científicos en términos de procesos locales y servicios remotos. Estas nuevas aplicaciones disponen de una infraestructura que proporciona interoperabilidad con aplicaciones externas, presentan interfaces de usuario personalizadas y abstraen al usuario final de la complejidad de configuracíon al ofrecer elementos de trabajo ya adaptados a su campo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>992</post_id>
		<post_date><![CDATA[2016-04-24 07:13:53]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 05:13:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[metaherramienta-para-la-generacion-de-aplicaciones-cientificas-basadas-en-workflows]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="metaherramienta"><![CDATA[metaherramienta]]></category>
		<category domain="post_tag" nicename="programacion-visual"><![CDATA[programacíon visual]]></category>
		<category domain="post_tag" nicename="servicios-remotos"><![CDATA[servicios remotos]]></category>
		<category domain="post_tag" nicename="workflow-cientifico"><![CDATA[workflow científico]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[993]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El uso de la programación visual en el ámbito científico ha contribuido al desarrollo de aplicaciones que facilitan la realizacíon de experimentos. Actualmente, existen aplicaciones para trabajar sobre un único dominio, limitadas a procedimientos propios de ese dominio, y aplicaciones multidominio, cuya complejidad para la configuracíon de sus elementos supone un gran esfuerzo para el usuario. Por tanto, es necesario ofrecer flexibilidad para trabajar sobre diversos dominios y permitir una adaptacíon intuitiva a dominios conocidos por el usuario. En este trabajo se presenta una metaherramienta para la generacíon automática de aplicaciones adaptadas a un dominio, o conjunto de dominios, para la composición y ejecucíon de workflows científicos en términos de procesos locales y servicios remotos. Estas nuevas aplicaciones disponen de una infraestructura que proporciona interoperabilidad con aplicaciones externas, presentan interfaces de usuario personalizadas y abstraen al usuario final de la complejidad de configuracíon al ofrecer elementos de trabajo ya adaptados a su campo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[workflow científico, metaherramienta, programacíon visual, servicios remotos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rubén Salado-Cid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico Universidad de Córdoba, Campus de Rabanales, 14071 Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rsalado@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Raúl Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico Universidad de Córdoba, Campus de Rabanales, 14071 Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sebastián Ventura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico Universidad de Córdoba, Campus de Rabanales, 14071 Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sventura@uco.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Methodology to Extend RAL</title>
		<link>https://biblioteca.sistedes.es/articulo/methodology-to-extend-ral/</link>
		<pubDate>Sun, 24 Apr 2016 05:18:30 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=999</guid>
		<description></description>
		<content><![CDATA[Resource Assignment Language (RAL) is a language for the selection of organisational resources that can be used, for example, for the assignment of human resources to business process activities. Its formal semantics have allowed the automation of analysis operations in several phases of the business process lifecycle. RAL was designed considering a specific organisational metamodel and pursuing specific purposes. However, it can be extended to deal with similar problems in different domains and under different circumstances. In this paper, a methodology to extend RAL is introduced, and an extension to support another organisational metamodel is described as a proof-of-concept. ]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>999</post_id>
		<post_date><![CDATA[2016-04-24 07:18:30]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 05:18:30]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[methodology-to-extend-ral]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="business-process-management"><![CDATA[Business Process Management]]></category>
		<category domain="post_tag" nicename="description-logics"><![CDATA[description logics]]></category>
		<category domain="post_tag" nicename="ral"><![CDATA[RAL]]></category>
		<category domain="post_tag" nicename="resource-assignment"><![CDATA[resource assignment]]></category>
		<category domain="post_tag" nicename="w3c-organisation-ontology"><![CDATA[W3C Organisation Ontology]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1000]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resource Assignment Language (RAL) is a language for the selection of organisational resources that can be used, for example, for the assignment of human resources to business process activities. Its formal semantics have allowed the automation of analysis operations in several phases of the business process lifecycle. RAL was designed considering a specific organisational metamodel and pursuing specific purposes. However, it can be extended to deal with similar problems in different domains and under different circumstances. In this paper, a methodology to extend RAL is introduced, and an extension to support another organisational metamodel is described as a proof-of-concept. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[business process management, description logics, RAL, resource assignment, W3C Organisation Ontology]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cristina Cabanillas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Vienna University of Economics and Business, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cristina.cabanillas@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jan Mendling]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Vienna University of Economics and Business, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jan.mendling@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/015]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una solucíon basada en HTCondor para aprovechar la disponibilidad de recursos efímeros</title>
		<link>https://biblioteca.sistedes.es/articulo/una-solucion-basada-en-htcondor-para-aprovechar-la-disponibilidad-de-recursos-efimeros/</link>
		<pubDate>Sun, 24 Apr 2016 05:21:20 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1002</guid>
		<description></description>
		<content><![CDATA[Clusters, grids y, más actualmente, clouds, representan las infraestructuras de computacíon dedicada más utilizadas por científicos e investigadores. Sin embargo, existen otras alternativas cuya principal funcíon no es la computacíon y que pueden ser útiles para la resolución de problemas computacionalmente costosos. En el ámbito académico existen una gran cantidad de recursos que, durante gran parte del día, permanecen encendidos y desaprovechados, de forma que se podrían utilizar para tareas computacionales durante el tiempo que permanecen infrautilizados. Con este objetivo, en este artículo se propone la utilización del middleware HTCondor para aprovechar estos recursos efímeros existentes en nuestro departamento, así como su integracíon en un framework de computacíon distribuida desarrollado anteriormente y que en la práctica estamos utilizando y extendiendo para resolver problemas complejos. Esta integracíon se ha realizado mediante la adicíon de un componente en el framework que, basándose en el horario de reserva de los recursos integrados, es capaz de recomendar los más adecuados para la ejecucíon de cada trabajo. Finalmente, se ha utilizado el entorno de Amazon EC2, simulando el entorno real de ejecución, para configurar la nueva infraestructura y probar el nuevo componente.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1002</post_id>
		<post_date><![CDATA[2016-04-24 07:21:20]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 05:21:20]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-solucion-basada-en-htcondor-para-aprovechar-la-disponibilidad-de-recursos-efimeros]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="computacion-en-la-nube"><![CDATA[Computación en la Nube]]></category>
		<category domain="post_tag" nicename="heterogeneidad"><![CDATA[heterogeneidad]]></category>
		<category domain="post_tag" nicename="htcondor"><![CDATA[HTCondor]]></category>
		<category domain="post_tag" nicename="planificacion-de-recursos"><![CDATA[planificacíon de recursos]]></category>
		<category domain="post_tag" nicename="recursos-efimeros"><![CDATA[Recursos efímeros]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1003]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Clusters, grids y, más actualmente, clouds, representan las infraestructuras de computacíon dedicada más utilizadas por científicos e investigadores. Sin embargo, existen otras alternativas cuya principal funcíon no es la computacíon y que pueden ser útiles para la resolución de problemas computacionalmente costosos. En el ámbito académico existen una gran cantidad de recursos que, durante gran parte del día, permanecen encendidos y desaprovechados, de forma que se podrían utilizar para tareas computacionales durante el tiempo que permanecen infrautilizados. Con este objetivo, en este artículo se propone la utilización del middleware HTCondor para aprovechar estos recursos efímeros existentes en nuestro departamento, así como su integracíon en un framework de computacíon distribuida desarrollado anteriormente y que en la práctica estamos utilizando y extendiendo para resolver problemas complejos. Esta integracíon se ha realizado mediante la adicíon de un componente en el framework que, basándose en el horario de reserva de los recursos integrados, es capaz de recomendar los más adecuados para la ejecucíon de cada trabajo. Finalmente, se ha utilizado el entorno de Amazon EC2, simulando el entorno real de ejecución, para configurar la nueva infraestructura y probar el nuevo componente.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ Recursos efímeros, computacíon en la nube, planificacíon de recursos, heterogeneidad, HTCondor]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Sergio Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigacíon en Ingeniería de Aragón (I3A) Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[shernandez@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Fabra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigacíon en Ingeniería de Aragón (I3A) Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jfabra@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Joaqúin Ezpeleta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigacíon en Ingeniería de Aragón (I3A) Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ezpeleta@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Pedro Alvarez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigacíon en Ingeniería de Aragón (I3A) Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[alvaper@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/014]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards the user-centric analysis of the availability in IaaS</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-the-user-centric-analysis-of-the-availability-in-iaas/</link>
		<pubDate>Sun, 24 Apr 2016 05:24:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1005</guid>
		<description></description>
		<content><![CDATA[Availability is a key property in computational services and, therefore, is guaranteed by Service Level Agreements (SLAs) from the majority infrastructure services, such as virtualization (Amazon EC2, Windows Azure, Google Cloud, Joyent, Rackspace, ...) and storage (Amazon S3, Google Cloud Storage, ...). These SLAs describe availability in natural language and there are important differences in the scope and penalties that each service provides. Furthermore, descriptions use specific domain terms so they are difficult to understand by service customers. These circumstances make that availability analysis is a tedious, error-prone and time-consuming task. In this paper, we describe in detail this problem and provide a first approach to deal with these SLAs supported on current SLA analysis techniques.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1005</post_id>
		<post_date><![CDATA[2016-04-24 07:24:05]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 05:24:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-the-user-centric-analysis-of-the-availability-in-iaas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="availability"><![CDATA[Availability]]></category>
		<category domain="post_tag" nicename="cloud"><![CDATA[Cloud]]></category>
		<category domain="post_tag" nicename="iaas"><![CDATA[IaaS]]></category>
		<category domain="post_tag" nicename="service-level-agreements"><![CDATA[Service Level Agreements]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1006]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Availability is a key property in computational services and, therefore, is guaranteed by Service Level Agreements (SLAs) from the majority infrastructure services, such as virtualization (Amazon EC2, Windows Azure, Google Cloud, Joyent, Rackspace, ...) and storage (Amazon S3, Google Cloud Storage, ...). These SLAs describe availability in natural language and there are important differences in the scope and penalties that each service provides. Furthermore, descriptions use specific domain terms so they are difficult to understand by service customers. These circumstances make that availability analysis is a tedious, error-prone and time-consuming task. In this paper, we describe in detail this problem and provide a first approach to deal with these SLAs supported on current SLA analysis techniques.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Service Level Agreements, Availability, IaaS, Cloud]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Manuel Gutíerrez-Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[School of Computer Engineering University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[amgutierrez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[School of Computer Engineering University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[School of Computer Engineering University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[School of Computer Engineering University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/013]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Priority-Based Human Resource Allocation in Business Processes</title>
		<link>https://biblioteca.sistedes.es/articulo/priority-based-human-resource-allocation-in-business-processes/</link>
		<pubDate>Sun, 24 Apr 2016 05:28:10 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1008</guid>
		<description></description>
		<content><![CDATA[Business Process Management Systems (BPMS) are increasingly used to support service composition, typically working with executable BP models that involve resources, which include both automatic services and services provided by human resources. The appropriate selection of human resources is critical, as factors such as workload or skills have an impact on work performance. While priorities for automatic services are intensively researched, human resource prioritization has been hardly discussed. In classical workflow management, only resource assignment at BP design time to select potential performers for activities, and resource allocation at run time to choose actual performers, are considered. There is no explicit consideration of prioritizing potential performers to facilitate the selection of actual performers. It is also disregarded in professional solutions.
In this paper, we address this research gap and provide two contributions: (i) we conceptually define prioritized allocation based on preferences; and (ii) we propose a concrete way in which preferences over resources can be defined so that a resource priority ranking can be automatically generated. Our solution builds on the adaptation of a user preference model developed for the discovery and ranking of semantic web services called SOUP [1] to the domain at hand. As a proof of concept, we have extended the resource management tool CRISTAL (http://www.isa.us.es/cristal) with the SOUP component [2], using RAL [3] for resource selection. 1. J. M. García, D. Ruiz, and A. R. Cortés, "A Model of User Preferences for Semantic
Services Discovery and Ranking," in ESWC (2), pp. 1­14, Springer, 2010. 2. J. M. García, M. Junghans, D. Ruiz, S. Agarwal, and A. R. Cortés, "Integrating
semantic Web services ranking mechanisms using a common preference model," Knowl.-Based Syst., vol. 49, pp. 22­36, 2013. 3. C. Cabanillas, M. Resinas, and A. Ruiz-Cortés, "Defining and Analysing Resource Assignments in Business Processes with RAL," in ICSOC, vol. 7084, pp. 477­486, Springer, 2011.
This work was published in ICSOC 2013, vol. 8274, 374-388. It was partially supported by the EU-FP7, the EU Commission, the Spanish and the Andalusian R&D&I programmes (grants 318275, 284860, TIN2009-07366, TIN2012-32273, TIC-5906).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1008</post_id>
		<post_date><![CDATA[2016-04-24 07:28:10]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 05:28:10]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[priority-based-human-resource-allocation-in-business-processes]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1009]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Business Process Management Systems (BPMS) are increasingly used to support service composition, typically working with executable BP models that involve resources, which include both automatic services and services provided by human resources. The appropriate selection of human resources is critical, as factors such as workload or skills have an impact on work performance. While priorities for automatic services are intensively researched, human resource prioritization has been hardly discussed. In classical workflow management, only resource assignment at BP design time to select potential performers for activities, and resource allocation at run time to choose actual performers, are considered. There is no explicit consideration of prioritizing potential performers to facilitate the selection of actual performers. It is also disregarded in professional solutions.
In this paper, we address this research gap and provide two contributions: (i) we conceptually define prioritized allocation based on preferences; and (ii) we propose a concrete way in which preferences over resources can be defined so that a resource priority ranking can be automatically generated. Our solution builds on the adaptation of a user preference model developed for the discovery and ranking of semantic web services called SOUP [1] to the domain at hand. As a proof of concept, we have extended the resource management tool CRISTAL (http://www.isa.us.es/cristal) with the SOUP component [2], using RAL [3] for resource selection. 1. J. M. García, D. Ruiz, and A. R. Cortés, "A Model of User Preferences for Semantic
Services Discovery and Ranking," in ESWC (2), pp. 1­14, Springer, 2010. 2. J. M. García, M. Junghans, D. Ruiz, S. Agarwal, and A. R. Cortés, "Integrating
semantic Web services ranking mechanisms using a common preference model," Knowl.-Based Syst., vol. 49, pp. 22­36, 2013. 3. C. Cabanillas, M. Resinas, and A. Ruiz-Cortés, "Defining and Analysing Resource Assignments in Business Processes with RAL," in ICSOC, vol. 7084, pp. 477­486, Springer, 2011.
This work was published in ICSOC 2013, vol. 8274, 374-388. It was partially supported by the EU-FP7, the EU Commission, the Spanish and the Andalusian R&D&I programmes (grants 318275, 284860, TIN2009-07366, TIN2012-32273, TIC-5906).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cristina Cabanillas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Vienna University of Economics and Business, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cristina.cabanillas@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José María García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[STI Innsbruck, University of Innsbruck, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ jose.garcia@sti2.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[David Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[druiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Jan Mendling]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Vienna University of Economics and Business, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[jan.mendling@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/012]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una solución para la gestíon e integracíon de Internet de las Cosas en la Nube</title>
		<link>https://biblioteca.sistedes.es/articulo/una-solucion-para-la-gestion-e-integracion-de-internet-de-las-cosas-en-la-nube/</link>
		<pubDate>Sun, 24 Apr 2016 05:30:25 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1011</guid>
		<description></description>
		<content><![CDATA[La falta de estandarización a la hora de conectar dispositivos a Internet del Futuro origina un problema relativamente novedoso en el que aún no se ha definido una línea concreta de actuacíon. En este sentido, el estándar OASIS DPWS (Device Profile for Web Services) está orientado a exponer, con independencia de su capacidad, dispositivos de forma genérica basándose en la pila de protocolos para Servicios Web. Sin embargo, el alcance de la comunicación con dichos dispositivos de forma ubicua se encuentra limitado al uso de discovery proxies, que agregan dispositivos conectados a diferentes redes. Esto dificulta enormemente la vision global de dichos dispositivos, además de delegar en primera instancia todas las tareas de comunicación a un único punto de entrada. En este trabajo, se propone extender el estándar DPWS para permitir la creación de un `repositorio' de dispositivos en la Nube, donde considerando los beneficios de la computación en la Nube, como su capacidad `ilimitada', se almacenen, procesen y orquesten la gran cantidad de dispositivos que constituyen las nuevas aplicaciones de la sociedad de Internet del Futuro.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1011</post_id>
		<post_date><![CDATA[2016-04-24 07:30:25]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 05:30:25]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-solucion-para-la-gestion-e-integracion-de-internet-de-las-cosas-en-la-nube]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="computacion-en-la-nube"><![CDATA[Computación en la Nube]]></category>
		<category domain="post_tag" nicename="dispositivo-como-servicio"><![CDATA[Dispositivo como Servicio]]></category>
		<category domain="post_tag" nicename="dispositivos-heterogeneos"><![CDATA[Dispositivos heterogéneos]]></category>
		<category domain="post_tag" nicename="internet-de-las-cosas"><![CDATA[Internet de las Cosas]]></category>
		<category domain="post_tag" nicename="internet-del-futuro"><![CDATA[Internet del Futuro]]></category>
		<category domain="post_tag" nicename="nube-de-las-cosas"><![CDATA[Nube de las Cosas]]></category>
		<category domain="post_tag" nicename="orquestacion"><![CDATA[Orquestación]]></category>
		<category domain="post_tag" nicename="plataforma-en-la-nube"><![CDATA[Plataforma en la Nube]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1012]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La falta de estandarización a la hora de conectar dispositivos a Internet del Futuro origina un problema relativamente novedoso en el que aún no se ha definido una línea concreta de actuacíon. En este sentido, el estándar OASIS DPWS (Device Profile for Web Services) está orientado a exponer, con independencia de su capacidad, dispositivos de forma genérica basándose en la pila de protocolos para Servicios Web. Sin embargo, el alcance de la comunicación con dichos dispositivos de forma ubicua se encuentra limitado al uso de discovery proxies, que agregan dispositivos conectados a diferentes redes. Esto dificulta enormemente la vision global de dichos dispositivos, además de delegar en primera instancia todas las tareas de comunicación a un único punto de entrada. En este trabajo, se propone extender el estándar DPWS para permitir la creación de un `repositorio' de dispositivos en la Nube, donde considerando los beneficios de la computación en la Nube, como su capacidad `ilimitada', se almacenen, procesen y orquesten la gran cantidad de dispositivos que constituyen las nuevas aplicaciones de la sociedad de Internet del Futuro.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Internet de las Cosas, Internet del Futuro, Orquestación, Computación en la Nube, Nube de las Cosas, Dispositivos heterogéneos, Plataforma en la Nube, Dispositivo como Servicio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Adrían Nieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga Departamento de Lenguajes y Ciencias de la Computacíon, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[adrian@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Cubo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga Departamento de Lenguajes y Ciencias de la Computacíon, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cubo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ernesto Pimentel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga Departamento de Lenguajes y Ciencias de la Computacíon, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ernesto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/011]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Analysis of the Feasibility to Combine CEP and EDA with Machine Learning using the Example of Network Analysis and Surveillance</title>
		<link>https://biblioteca.sistedes.es/articulo/analysis-of-the-feasibility-to-combine-cep-and-eda-with-machine-learning-using-the-example-of-network-analysis-and-surveillance/</link>
		<pubDate>Sun, 24 Apr 2016 05:36:55 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1016</guid>
		<description></description>
		<content><![CDATA[Complex Event Processing (CEP) and Event-driven Architectures (EDA) are modern paradigms for processing data in form of events. Machine Learning (ML) methods offer additional sophisticated means for analyzing data. By combining these technologies it is possible to create even more comprehensive and powerful data analysis and processing systems. We analyze the feasibility of combining CEP and EDA with ML using the example of the application domain of computer networks. We present relevant aspects, a sample use case, an sample architecture, and results of performance benchmarks. Our results indicate that the combination of these technologies increases data processing capabilities and that it is feasible from a performance perspective as well.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1016</post_id>
		<post_date><![CDATA[2016-04-24 07:36:55]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 05:36:55]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analysis-of-the-feasibility-to-combine-cep-and-eda-with-machine-learning-using-the-example-of-network-analysis-and-surveillance]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="complex-event-processing"><![CDATA[Complex Event Processing]]></category>
		<category domain="post_tag" nicename="computer-networks"><![CDATA[Computer Networks]]></category>
		<category domain="post_tag" nicename="event-driven-architecture"><![CDATA[Event-driven Architecture]]></category>
		<category domain="post_tag" nicename="machine-learning"><![CDATA[Machine Learning]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1017]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Complex Event Processing (CEP) and Event-driven Architectures (EDA) are modern paradigms for processing data in form of events. Machine Learning (ML) methods offer additional sophisticated means for analyzing data. By combining these technologies it is possible to create even more comprehensive and powerful data analysis and processing systems. We analyze the feasibility of combining CEP and EDA with ML using the example of the application domain of computer networks. We present relevant aspects, a sample use case, an sample architecture, and results of performance benchmarks. Our results indicate that the combination of these technologies increases data processing capabilities and that it is feasible from a performance perspective as well.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Complex Event Processing, Event-driven Architecture, Machine Learning, Computer Networks]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ruediger Gad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Applied Sciences Frankfurt am Main]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[kappes@fb2.fh-frankfurt.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Martin Kappes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Applied Sciences Frankfurt am Main]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[rgad@fb2.fh-frankfurt.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Cádiz, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/020]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SLA4DQ-I8K: Acuerdos a Nivel de Servicio para Calidad de Datos en Intercambios de Datos Maestros regulados por ISO 8000-1x0</title>
		<link>https://biblioteca.sistedes.es/articulo/sla4dq-i8k-acuerdos-a-nivel-de-servicio-para-calidad-de-datos-en-intercambios-de-datos-maestros-regulados-por-iso-8000-1x0/</link>
		<pubDate>Sun, 24 Apr 2016 05:40:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1019</guid>
		<description></description>
		<content><![CDATA[Los datos son uno de los activos más importantes de las organizaciones. Prueba de ello son las iniciativas que están surgiendo para disponer y analizar la mayor cantidad de datos posibles (efecto Big Data), pudiendo así poder descubrir patrones de comportamiento de posibles clientes. Así es frecuente que las organizaciones adquieran datos de terceras partes, datos que son usados como base para los procesos de negocio. Pero, en general, si los datos adquiridos no tienen un nivel de calidad adecuado, entonces no podrá extraerse de ellos el máximo rendimiento. Para evitar esto, es posible establecer acuerdos a niveles de servicio para la adquisición de datos, que es el principal objeto de este artículo. Para ello, se puede usar ISO 8000 partes 100 a 140, que tratan específicamente sobre el intercambio de datos maestros. Para facilitar dicho intercambio de datos, proponemos el uso de un framework que permite combinar los servicios web que satisfacen los correspondientes requisitos de la familia de estándares. Dicho framework consiste en dos componentes: I8K ­ una arquitectura de servicio ­ e ICS-API ­ una interfaz de programación de aplicaciones que permite usar I8K-. La principal aportación de este artículo radica en describir cómo usar el framework para implementar los aspectos tecnológicos de los acuerdos a niveles de servicio, cuando la calidad de datos tiene que ser tenida en cuenta durante el intercambio de datos como parte de la operativa.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1019</post_id>
		<post_date><![CDATA[2016-04-24 07:40:54]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 05:40:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[sla4dq-i8k-acuerdos-a-nivel-de-servicio-para-calidad-de-datos-en-intercambios-de-datos-maestros-regulados-por-iso-8000-1x0]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="acuerdo-a-nivel-de-servicio"><![CDATA[Acuerdo a nivel de servicio]]></category>
		<category domain="post_tag" nicename="calidad-de-datos"><![CDATA[Calidad de Datos]]></category>
		<category domain="post_tag" nicename="i8k"><![CDATA[I8K]]></category>
		<category domain="post_tag" nicename="intercambio-de-datos-maestros"><![CDATA[Intercambio de Datos Maestros]]></category>
		<category domain="post_tag" nicename="iso-8000-1x0"><![CDATA[ISO 8000-1x0]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1020]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los datos son uno de los activos más importantes de las organizaciones. Prueba de ello son las iniciativas que están surgiendo para disponer y analizar la mayor cantidad de datos posibles (efecto Big Data), pudiendo así poder descubrir patrones de comportamiento de posibles clientes. Así es frecuente que las organizaciones adquieran datos de terceras partes, datos que son usados como base para los procesos de negocio. Pero, en general, si los datos adquiridos no tienen un nivel de calidad adecuado, entonces no podrá extraerse de ellos el máximo rendimiento. Para evitar esto, es posible establecer acuerdos a niveles de servicio para la adquisición de datos, que es el principal objeto de este artículo. Para ello, se puede usar ISO 8000 partes 100 a 140, que tratan específicamente sobre el intercambio de datos maestros. Para facilitar dicho intercambio de datos, proponemos el uso de un framework que permite combinar los servicios web que satisfacen los correspondientes requisitos de la familia de estándares. Dicho framework consiste en dos componentes: I8K ­ una arquitectura de servicio ­ e ICS-API ­ una interfaz de programación de aplicaciones que permite usar I8K-. La principal aportación de este artículo radica en describir cómo usar el framework para implementar los aspectos tecnológicos de los acuerdos a niveles de servicio, cuando la calidad de datos tiene que ser tenida en cuenta durante el intercambio de datos como parte de la operativa.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Calidad de Datos , Acuerdo a nivel de servicio , ISO 8000-1x0 , Intercambio de Datos Maestros , I8K]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ismael Caballero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Ismael.Caballero,@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Isabel Bermejo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Isabel.Bermejo@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Luisa Parody]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lparody@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Mª Teresa Gómez López]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[maytegomez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Rafael M. Gasca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[gasca@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[Mario.Piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/018]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una revisión de la notación PPINOT para indicadores de rendimiento mediante su aplicación a un caso real</title>
		<link>https://biblioteca.sistedes.es/articulo/una-revision-de-la-notacion-ppinot-para-indicadores-de-rendimiento-mediante-su-aplicacion-a-un-caso-real/</link>
		<pubDate>Sun, 24 Apr 2016 05:43:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1022</guid>
		<description></description>
		<content><![CDATA[Cada vez son más numerosas las organizaciones orientadas a procesos que, para conseguir sus objetivos, necesitan modelar los procesos de negocio (PN) y evaluar su rendimiento. El modelado de procesos hace posible el control del proceso durante su ejecución permitiendo su posterior análisis y mejora. Un elemento clave para llevar a cabo esa mejora son los indicadores de rendimiento de proceso PPIs (Process Performance Indicators) que proporcionan información sobre la ejecución del proceso (por ejemplo medidas de tiempo o del estado de los elementos del proceso). La notación PPINOT permite representar de forma gráfica dichos indicadores sobre los elementos del PN y calcular su valor a partir de los datos generados durante la ejecución del proceso. Además de la notación gráfica, existe una notación basada en plantillas que permite la definición textual de los PPIs. En este artículo se presenta una revisión de PPINOT mediante su aplicación a un proceso híbrido (en parte humano, en parte automatizado). Para ello se ha modelado con BPMN el proceso de gestión de correo electrónico del SIC (Servicio de Informática y Comunicaciones) de la US (Universidad de Sevilla) y se han especificado en PPINOT parte del panel de indicadores definido por esta organización. Tras la especificación, se ha visto que la notación se adapta a este tipo de procesos y se han identificado algunas posibles mejoras en la misma.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1022</post_id>
		<post_date><![CDATA[2016-04-24 07:43:54]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 05:43:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-revision-de-la-notacion-ppinot-para-indicadores-de-rendimiento-mediante-su-aplicacion-a-un-caso-real]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="gestion-de-procesos-de-negocio"><![CDATA[gestión de procesos de negocio]]></category>
		<category domain="post_tag" nicename="indicadores-clave-de-rendimiento"><![CDATA[indicadores clave de rendimiento]]></category>
		<category domain="post_tag" nicename="indicadores-de-rendimiento-de-proceso"><![CDATA[indicadores de rendimiento de proceso]]></category>
		<category domain="post_tag" nicename="rendimiento-de-procesos"><![CDATA[rendimiento de procesos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1023]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Cada vez son más numerosas las organizaciones orientadas a procesos que, para conseguir sus objetivos, necesitan modelar los procesos de negocio (PN) y evaluar su rendimiento. El modelado de procesos hace posible el control del proceso durante su ejecución permitiendo su posterior análisis y mejora. Un elemento clave para llevar a cabo esa mejora son los indicadores de rendimiento de proceso PPIs (Process Performance Indicators) que proporcionan información sobre la ejecución del proceso (por ejemplo medidas de tiempo o del estado de los elementos del proceso). La notación PPINOT permite representar de forma gráfica dichos indicadores sobre los elementos del PN y calcular su valor a partir de los datos generados durante la ejecución del proceso. Además de la notación gráfica, existe una notación basada en plantillas que permite la definición textual de los PPIs. En este artículo se presenta una revisión de PPINOT mediante su aplicación a un proceso híbrido (en parte humano, en parte automatizado). Para ello se ha modelado con BPMN el proceso de gestión de correo electrónico del SIC (Servicio de Informática y Comunicaciones) de la US (Universidad de Sevilla) y se han especificado en PPINOT parte del panel de indicadores definido por esta organización. Tras la especificación, se ha visto que la notación se adapta a este tipo de procesos y se han identificado algunas posibles mejoras en la misma.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[indicadores de rendimiento de proceso, indicadores clave de rendimiento, gestión de procesos de negocio, rendimiento de procesos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[M. Cruz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cruz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[B. Bernárdez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[beat@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[A. del-Río-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[adeladelrio@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[A. Durán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[amador@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/019]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Data-Oriented Declarative Language for Optimizing Business Processes</title>
		<link>https://biblioteca.sistedes.es/articulo/data-oriented-declarative-language-for-optimizing-business-processes/</link>
		<pubDate>Sun, 24 Apr 2016 05:45:40 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1025</guid>
		<description></description>
		<content><![CDATA[Business process modelling constitutes an essential and crucial task in the Business Process Management. Typically, business processes, henceforth referred to as BP, are specified in an imperative manner, which define exactly how things have to be performed. But sometimes, a BP may be exposed to different environments and subjected to many conditions in which not always a sequence of activities can be described at design time. This is the reason why several authors have proposed languages to define BP as declarative models. These declarative languages tend to be used to describe the possible execution order of the activities, allowed or prohibited, instead of the exact order of the activities.
There are a significant number of researches that detect the necessity to include the data description into the BP model. Unfortunately this effort has only been applied to imperative models, not being the declarative models the focus of the studies, more centred on the order of activities. The role of data in declarative languages has not been very relevant, mostly limited to describe the execution or not of an activity, depending on the value of a variable of the dataflow. Unfortunately, none of them is worried about a declarative description of exchanged data between the activities, and how they can influence the model.
In this work, an analysis of the declarative languages found in the literature has been made in great depth. The analysis includes an study of how the most important declarative languages address data management, by means of the formalism for reasoning that they used (Linear Temporal Logic, Event Calculus,...); the capacity to include the data perspective; and the use of the declarative languages (validation, construction and/or assistance). Thanks to this analysis, the necessity to define a new language where the data aspects take more relevant place is demonstrated. In order to solve this lack in declarative languages, we propose a Data-Oriented Optimization LanguagE, called DOODLE, that represents graphically a declarative model which includes the BP requirements referring to data description. This new point of view of declarative languages focused on data permits to represent declaratively, the model of a business process according to
This work has been published in the 22nd International Conference on Information Systems Development (ISD 2013), ranked as A in ERA and CORE Conference Rankings. This work has been partially funded by the Ministry of Science and Technology of Spain (TIN2009-13714) and the European Regional Development Fund (ERDF/FEDER).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1025</post_id>
		<post_date><![CDATA[2016-04-24 07:45:40]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 05:45:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[data-oriented-declarative-language-for-optimizing-business-processes]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Business process modelling constitutes an essential and crucial task in the Business Process Management. Typically, business processes, henceforth referred to as BP, are specified in an imperative manner, which define exactly how things have to be performed. But sometimes, a BP may be exposed to different environments and subjected to many conditions in which not always a sequence of activities can be described at design time. This is the reason why several authors have proposed languages to define BP as declarative models. These declarative languages tend to be used to describe the possible execution order of the activities, allowed or prohibited, instead of the exact order of the activities.
There are a significant number of researches that detect the necessity to include the data description into the BP model. Unfortunately this effort has only been applied to imperative models, not being the declarative models the focus of the studies, more centred on the order of activities. The role of data in declarative languages has not been very relevant, mostly limited to describe the execution or not of an activity, depending on the value of a variable of the dataflow. Unfortunately, none of them is worried about a declarative description of exchanged data between the activities, and how they can influence the model.
In this work, an analysis of the declarative languages found in the literature has been made in great depth. The analysis includes an study of how the most important declarative languages address data management, by means of the formalism for reasoning that they used (Linear Temporal Logic, Event Calculus,...); the capacity to include the data perspective; and the use of the declarative languages (validation, construction and/or assistance). Thanks to this analysis, the necessity to define a new language where the data aspects take more relevant place is demonstrated. In order to solve this lack in declarative languages, we propose a Data-Oriented Optimization LanguagE, called DOODLE, that represents graphically a declarative model which includes the BP requirements referring to data description. This new point of view of declarative languages focused on data permits to represent declaratively, the model of a business process according to
This work has been published in the 22nd International Conference on Information Systems Development (ISD 2013), ranked as A in ERA and CORE Conference Rankings. This work has been partially funded by the Ministry of Science and Technology of Spain (TIN2009-13714) and the European Regional Development Fund (ERDF/FEDER).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Luisa Parody]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[lparody@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[María Teresa Gómez-López]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[maytegomez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Rafael M. Gasca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gasca@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1026]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/017]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Apoyo a la Toma de Decisiones en la Compra de IaaS</title>
		<link>https://biblioteca.sistedes.es/articulo/apoyo-a-la-toma-de-decisiones-en-la-compra-de-iaas/</link>
		<pubDate>Sun, 24 Apr 2016 05:47:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1028</guid>
		<description></description>
		<content><![CDATA[La dificultad para decidir la compra de un IaaS (Infrastructure as a Service) depende de la complejidad de las opciones de compra dadas por su proveedor y de la complejidad del plan del cliente que quiere realizarla. Es habitual que estos tipos de servicios ofrezcan muchas configuraciones de uso diferentes, y para cada una de ellas sea posible disponer de varias opciones de compra. De este modo, decidir la mejor compra se convierte en una tarea que consume mucho tiempo, tediosa y propensa a errores. En este trabajo inicial, caracterizamos el problema con un caso de estudio ilustrativo y presentamos los desafíos inmediatos para mejorar las herramientas de soporte actualmente disponibles.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1028</post_id>
		<post_date><![CDATA[2016-04-24 07:47:50]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 05:47:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[apoyo-a-la-toma-de-decisiones-en-la-compra-de-iaas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="iaas"><![CDATA[IaaS]]></category>
		<category domain="post_tag" nicename="opciones-de-compra"><![CDATA[Opciones de Compra]]></category>
		<category domain="post_tag" nicename="sla"><![CDATA[SLA]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1029]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La dificultad para decidir la compra de un IaaS (Infrastructure as a Service) depende de la complejidad de las opciones de compra dadas por su proveedor y de la complejidad del plan del cliente que quiere realizarla. Es habitual que estos tipos de servicios ofrezcan muchas configuraciones de uso diferentes, y para cada una de ellas sea posible disponer de varias opciones de compra. De este modo, decidir la mejor compra se convierte en una tarea que consume mucho tiempo, tediosa y propensa a errores. En este trabajo inicial, caracterizamos el problema con un caso de estudio ilustrativo y presentamos los desafíos inmediatos para mejorar las herramientas de soporte actualmente disponibles.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[IaaS, Opciones de Compra, SLA]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Octavio Martín-Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática ­ Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[omartindiaz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática ­ Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática ­ Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2014/016]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Aplicación de Test Process Improvement (TPI) a un Área de Pruebas de una Empresa que utiliza Scrum: Lecciones Aprendidas</title>
		<link>https://biblioteca.sistedes.es/articulo/aplicacion-de-test-process-improvement-tpi-a-un-area-de-pruebas-de-una-empresa-que-utiliza-scrum-lecciones-aprendidas/</link>
		<pubDate>Sun, 24 Apr 2016 16:59:23 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1035</guid>
		<description></description>
		<content><![CDATA[En la industria de software ha habido un gran crecimiento de propuestas que buscan mejorar la productividad y calidad en las organizaciones desarrolladoras de software; en particular, en la gestión de proyectos y en el proceso técnico. En Perú, por un lado Scrum representa una propuesta que viene ganando aceptación en distintas organizaciones que ya han iniciado su adopción; y de otro lado, algunas organizaciones han optado por trabajar con unidades especializadas como las áreas de pruebas de software. Esta situación vienen configurando escenarios algo complicados en las empresas pues adoptar Scrum a unidades de pruebas que buscan ser competitivos es un tema poco tratado en la industria en el Perú y en varios casos no ha funcionado como se espera. Este artículo presenta las lecciones aprendidas en la aplicación del modelo TPI (Test Process Improvement) para mejorar la productividad de un área de pruebas de software de una empresa que desarrolla software y utiliza Scrum para la gestión de los proyectos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1035</post_id>
		<post_date><![CDATA[2016-04-24 18:59:23]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 16:59:23]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[aplicacion-de-test-process-improvement-tpi-a-un-area-de-pruebas-de-una-empresa-que-utiliza-scrum-lecciones-aprendidas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="scrum-test-process-improvement"><![CDATA[Scrum Test Process Improvement]]></category>
		<category domain="post_tag" nicename="software-process-improvement"><![CDATA[Software Process Improvement]]></category>
		<category domain="post_tag" nicename="tpi"><![CDATA[TPI]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1036]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En la industria de software ha habido un gran crecimiento de propuestas que buscan mejorar la productividad y calidad en las organizaciones desarrolladoras de software; en particular, en la gestión de proyectos y en el proceso técnico. En Perú, por un lado Scrum representa una propuesta que viene ganando aceptación en distintas organizaciones que ya han iniciado su adopción; y de otro lado, algunas organizaciones han optado por trabajar con unidades especializadas como las áreas de pruebas de software. Esta situación vienen configurando escenarios algo complicados en las empresas pues adoptar Scrum a unidades de pruebas que buscan ser competitivos es un tema poco tratado en la industria en el Perú y en varios casos no ha funcionado como se espera. Este artículo presenta las lecciones aprendidas en la aplicación del modelo TPI (Test Process Improvement) para mejorar la productividad de un área de pruebas de software de una empresa que desarrolla software y utiliza Scrum para la gestión de los proyectos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Software Process Improvement, Scrum Test Process Improvement, TPI]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cecilia García García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Facultad de Ciencias e Ingeniería ­ Pontificia Universidad Católica del Perú Av. Universitaria 1801, San Miguel, Lima 32, Perú.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[garcia.cecilia@pucp.edu.pe]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Abraham Dávila Ramón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería ­ Pontificia Universidad Católica del Perú Av. Universitaria 1801, San Miguel, Lima 32, Perú.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[abraham.davila@pucp.edu.pe]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/010]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>ProDec Serious game para la formación y evaluación en gestión de proyectos software</title>
		<link>https://biblioteca.sistedes.es/articulo/prodec-serious-game-para-la-formacion-y-evaluacion-en-gestion-de-proyectos-software/</link>
		<pubDate>Sun, 24 Apr 2016 17:01:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1038</guid>
		<description></description>
		<content><![CDATA[ Los estudios realizados han permitido observar la carencia de herramientas que permiten la formación y evaluación de los alumnos en la planificación y gestión de proyectos software. ProDec (Project Decision) es un "serious game" creado con la intención de formar y evaluar a los alumnos en dicho ámbito. Su principal objetivo es que los alumnos adquieran cierta pericia a la hora de tomar decisiones frente a problemas que pueden surgir a lo largo del ciclo de vida en la gestión de un proyecto software, permitiendo, de este modo, que los alumnos salgan al mundo laboral con cierta habilidad práctica en la materia. ProDec ha sido desarrollado como herramienta de soporte para la formación en dirección y gestión de proyectos software y como aplicación de apoyo al profesorado para la evaluación de las competencias que los alumnos deben adquirir. En la actualidad, se utiliza en la asignatura Dirección y Gestión de Proyectos Software de tercero de Grado en Ingeniería Informática de la Universidad de Cádiz.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1038</post_id>
		<post_date><![CDATA[2016-04-24 19:01:52]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 17:01:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[prodec-serious-game-para-la-formacion-y-evaluacion-en-gestion-de-proyectos-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="serious-games-formacion-en-gestion-de-proyectos-software-ingenieria-del-software"><![CDATA[Serious Games; Formación en gestión de proyectos software; Ingeniería del Software]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1039]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[ Los estudios realizados han permitido observar la carencia de herramientas que permiten la formación y evaluación de los alumnos en la planificación y gestión de proyectos software. ProDec (Project Decision) es un "serious game" creado con la intención de formar y evaluar a los alumnos en dicho ámbito. Su principal objetivo es que los alumnos adquieran cierta pericia a la hora de tomar decisiones frente a problemas que pueden surgir a lo largo del ciclo de vida en la gestión de un proyecto software, permitiendo, de este modo, que los alumnos salgan al mundo laboral con cierta habilidad práctica en la materia. ProDec ha sido desarrollado como herramienta de soporte para la formación en dirección y gestión de proyectos software y como aplicación de apoyo al profesorado para la evaluación de las competencias que los alumnos deben adquirir. En la actualidad, se utiliza en la asignatura Dirección y Gestión de Proyectos Software de tercero de Grado en Ingeniería Informática de la Universidad de Cádiz.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Serious Games; Formación en gestión de proyectos software; Ingeniería del Software]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alejandro Calderón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Mejora del Proceso Software y Métodos Formales Departamento de Ingeniería Informática Universidad de Cádiz C/ Chile, 1, 11003 - Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alejandro.calderonsanchez@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mercedes Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Mejora del Proceso Software y Métodos Formales Departamento de Ingeniería Informática Universidad de Cádiz C/ Chile, 1, 11003 - Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mercedes.ruiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/009]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A HCI Technique for Improving Requirements Elicitation</title>
		<link>https://biblioteca.sistedes.es/articulo/a-hci-technique-for-improving-requirements-elicitation/</link>
		<pubDate>Sun, 24 Apr 2016 17:04:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1041</guid>
		<description></description>
		<content><![CDATA[Human computer interaction (HCI) uses development processes and techniques to assure that software product usability complies with minimum requirements. The Personas technique [3] gathers, analyses and synthesizes information related to the users that are to interact with the software system. This technique helps to focus software analysis and design on end user features and goals. However, it shares the shortcomings of other HCI techniques: it has no detailed definition of activities and products. These problems make the introduction of Personas into the software engineering (SE) requirements stage overly complex and unclear for developers. In order to design and implement a usable system, there should, according to HCI, be an understanding not only of users' needs and goals but also of their characteristics and capabilities. The understanding of the people that interact with the system should constitute the groundwork for software development. The SE requirements activity could be improved by incorporating Personas technique tasks to understand the user. The goal of our research is to modify Personas to readily build the technique into the requirements stage of regular SE developments.
We studied Cooper's version of the Personas technique [3] and set out to apply this technique in a case study [2]. From the very outset, we had trouble applying the technique. For example, the first step of the technique recommended by Cooper is Identify Behavioural Variables, that is, Cooper assumes that users have already been researched and the gathered data have been roughly organized. This task is not however explicitly mentioned in his description of Personas. The user study necessary to extract behavioural variables is not an altogether straightforward step and should be specified rather than implied as the technique's first activity. Additionally, some technique activities, like Identify Significant Behaviour Patterns and Check for Completeness and Redundancy, fail to specify any output product. Finally, the final technique outputs are not related to the software engineering requirements stage. To be able to build Personas into routine SE developments, it is necessary to define activities and products associated with each activity. For each of the identified limitations, we devised an improvement to be built into Personas. We opted to incorporate these improvements into the latest version of the Personas technique published by Cooper et al. [3]. The grounds for this choice were: (i) Cooper made the original proposal; (ii) this proposal was the groundwork for research by other authors; and (iii) this proposal has been successfully used in a number of real projects. In [1], we incorporated these improvements into a SE version of Personas. Our proposal is composed of a group of activities and their associated inputs and outputs that, together, lead to the creation of personas [1]. As part of the first new activity, State Hypotheses for Personas, for example, a List of Hypotheses for the Personas to be created should be generated, and interviews should be designed and held with potential users. The responses from the Transcribed Interviews should then be used to gather the information required to carry out other activities. Second, as part of the Identify Behavioural Variables activity, we propose a new activity for synthesizing each response to the interviews held in the previous activity as behavioural variables. Third, we have defined a new activity that links the user research using Personas with the remainder of the requirements stage: Build Use Cases. This activity should output an Annotated Use Case Diagram. This diagram is based on the traditional use case diagram, to which we add a brief description of each persona involved in the use case. We applied our proposed technique to several case studies for validation [1]. Additionally, we designed and implemented a prototype tool to support the proposed Personas technique.
The improved Personas avoids the obstacles encountered by an average software developer unfamiliar with HCI techniques applying the original Personas. We think it is worthwhile adapting Personas for integration into SE development process. The integration of Personas into the SE requirements stage could improve the understanding of what the software product should do and how it should behave. The Personas technique appears to help focus the software analysis and design activities on end user characteristics and goals. We have enriched the SE requirements process by incorporating Personas activities into requirements activities. Requirements elicitation and requirements analysis are the requirements engineering activities most affected by incorporating Personas.
Acknowledgements. This work has been funded by the Spanish Ministry of Science and Innovation as part of the Tecnologías para la Replicación y Síntesis de Experimentos en IS (TIN2011-23216) and Go Lite (TIN2011-24139), and by Community of Madrid R&D program e-Madrid project (S2009/TIC-1650).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1041</post_id>
		<post_date><![CDATA[2016-04-24 19:04:15]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 17:04:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-hci-technique-for-improving-requirements-elicitation]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1042]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Human computer interaction (HCI) uses development processes and techniques to assure that software product usability complies with minimum requirements. The Personas technique [3] gathers, analyses and synthesizes information related to the users that are to interact with the software system. This technique helps to focus software analysis and design on end user features and goals. However, it shares the shortcomings of other HCI techniques: it has no detailed definition of activities and products. These problems make the introduction of Personas into the software engineering (SE) requirements stage overly complex and unclear for developers. In order to design and implement a usable system, there should, according to HCI, be an understanding not only of users' needs and goals but also of their characteristics and capabilities. The understanding of the people that interact with the system should constitute the groundwork for software development. The SE requirements activity could be improved by incorporating Personas technique tasks to understand the user. The goal of our research is to modify Personas to readily build the technique into the requirements stage of regular SE developments.
We studied Cooper's version of the Personas technique [3] and set out to apply this technique in a case study [2]. From the very outset, we had trouble applying the technique. For example, the first step of the technique recommended by Cooper is Identify Behavioural Variables, that is, Cooper assumes that users have already been researched and the gathered data have been roughly organized. This task is not however explicitly mentioned in his description of Personas. The user study necessary to extract behavioural variables is not an altogether straightforward step and should be specified rather than implied as the technique's first activity. Additionally, some technique activities, like Identify Significant Behaviour Patterns and Check for Completeness and Redundancy, fail to specify any output product. Finally, the final technique outputs are not related to the software engineering requirements stage. To be able to build Personas into routine SE developments, it is necessary to define activities and products associated with each activity. For each of the identified limitations, we devised an improvement to be built into Personas. We opted to incorporate these improvements into the latest version of the Personas technique published by Cooper et al. [3]. The grounds for this choice were: (i) Cooper made the original proposal; (ii) this proposal was the groundwork for research by other authors; and (iii) this proposal has been successfully used in a number of real projects. In [1], we incorporated these improvements into a SE version of Personas. Our proposal is composed of a group of activities and their associated inputs and outputs that, together, lead to the creation of personas [1]. As part of the first new activity, State Hypotheses for Personas, for example, a List of Hypotheses for the Personas to be created should be generated, and interviews should be designed and held with potential users. The responses from the Transcribed Interviews should then be used to gather the information required to carry out other activities. Second, as part of the Identify Behavioural Variables activity, we propose a new activity for synthesizing each response to the interviews held in the previous activity as behavioural variables. Third, we have defined a new activity that links the user research using Personas with the remainder of the requirements stage: Build Use Cases. This activity should output an Annotated Use Case Diagram. This diagram is based on the traditional use case diagram, to which we add a brief description of each persona involved in the use case. We applied our proposed technique to several case studies for validation [1]. Additionally, we designed and implemented a prototype tool to support the proposed Personas technique.
The improved Personas avoids the obstacles encountered by an average software developer unfamiliar with HCI techniques applying the original Personas. We think it is worthwhile adapting Personas for integration into SE development process. The integration of Personas into the SE requirements stage could improve the understanding of what the software product should do and how it should behave. The Personas technique appears to help focus the software analysis and design activities on end user characteristics and goals. We have enriched the SE requirements process by incorporating Personas activities into requirements activities. Requirements elicitation and requirements analysis are the requirements engineering activities most affected by incorporating Personas.
Acknowledgements. This work has been funded by the Spanish Ministry of Science and Innovation as part of the Tecnologías para la Replicación y Síntesis de Experimentos en IS (TIN2011-23216) and Go Lite (TIN2011-24139), and by Community of Madrid R&D program e-Madrid project (S2009/TIC-1650).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[John W. Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad Autónoma de Madrid Calle Francisco Tomás y Valiente 11, 28049 Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[john.castro@estudiante.uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Silvia T. Acuña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad Autónoma de Madrid Calle Francisco Tomás y Valiente 11, 28049 Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[silvia.acunna@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Natalia Juristo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática, Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[natalia@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/008]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Propuesta para la transformación de Administraciones Públicas en organizaciones basadas en SOA</title>
		<link>https://biblioteca.sistedes.es/articulo/propuesta-para-la-transformacion-de-administraciones-publicas-en-organizaciones-basadas-en-soa/</link>
		<pubDate>Sun, 24 Apr 2016 17:06:39 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1044</guid>
		<description></description>
		<content><![CDATA[ Hoy en día las Arquitecturas Orientadas a Servicios (SOA) están ampliamente difundidas en entornos empresariales. Sin embargo en las Administraciones Públicas las implantaciones del paradigma SOA están incompletas, impidiendo a estas organizaciones prestar de forma eficiente y eficaz los servicios públicos, ya que no han sido transformadas atendiendo a su naturaleza jurídica. Este artículo presenta una propuesta metodológica para la transformación de Administraciones Públicas en organizaciones con capacidad para ser gobernadas y operadas bajo paradigma SOA, completamente alineada con el Gobierno Electrónico, que puedan prestar de forma eficiente y eficaz los servicios públicos que les confiere su ordenamiento jurídico particular.
Para realizar esta transformación se propone un meta-modelo objetivo SOA, que podrá ser instanciado a través de un proceso iterativo e incremental basado en el análisis de imperativos y partiendo del contexto de negocio particular de cada Administración Pública.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1044</post_id>
		<post_date><![CDATA[2016-04-24 19:06:39]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 17:06:39]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[propuesta-para-la-transformacion-de-administraciones-publicas-en-organizaciones-basadas-en-soa]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="administracion-publica"><![CDATA[Administración Pública]]></category>
		<category domain="post_tag" nicename="gobierno-electronico"><![CDATA[Gobierno Electrónico]]></category>
		<category domain="post_tag" nicename="metodologia"><![CDATA[Metodología]]></category>
		<category domain="post_tag" nicename="oa"><![CDATA[OA]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1045]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[ Hoy en día las Arquitecturas Orientadas a Servicios (SOA) están ampliamente difundidas en entornos empresariales. Sin embargo en las Administraciones Públicas las implantaciones del paradigma SOA están incompletas, impidiendo a estas organizaciones prestar de forma eficiente y eficaz los servicios públicos, ya que no han sido transformadas atendiendo a su naturaleza jurídica. Este artículo presenta una propuesta metodológica para la transformación de Administraciones Públicas en organizaciones con capacidad para ser gobernadas y operadas bajo paradigma SOA, completamente alineada con el Gobierno Electrónico, que puedan prestar de forma eficiente y eficaz los servicios públicos que les confiere su ordenamiento jurídico particular.
Para realizar esta transformación se propone un meta-modelo objetivo SOA, que podrá ser instanciado a través de un proceso iterativo e incremental basado en el análisis de imperativos y partiendo del contexto de negocio particular de cada Administración Pública.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[OA, Gobierno Electrónico, Administración Pública, Metodología]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[J. Sedeño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Agencia Andaluza de Instituciones Culturales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jorge.sedeno@juntadeandalucia.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[C.J. Torrecilla-Salinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[carlos.torrecilla@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[M.J.Escalona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mjescalona@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[M. Mejías]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[risoto@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/007]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Identificación de interacciones entre las características de calidad del software</title>
		<link>https://biblioteca.sistedes.es/articulo/identificacion-de-interacciones-entre-las-caracteristicas-de-calidad-del-software/</link>
		<pubDate>Sun, 24 Apr 2016 17:09:11 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1047</guid>
		<description></description>
		<content><![CDATA[Las interacciones entre atributos de calidad del software pueden ser conflictivas, situación que podría dificultar que el software cumpla con las expectativas de los participantes. Los conflictos entre los requisitos de calidad pueden identificarse al revisar tablas de interacción que muestren el tipo de contribución potencial que tendría una característica de calidad sobre otra. Por tanto, realizamos una revisión de la literatura para recopilar las tablas de interacción publicadas. Tras la revisión de los artículos seleccionados, proponemos una técnica para construir tablas de interacción, la cual fue aplicada en los modelos de calidad de usabilidad, mantenibilidad y seguridad. Con la intención de corroborar la información de las tablas, realizamos una encuesta exploratoria cuyo objetivo es determinar si las empresas advierten las interacciones, y en su caso, conocer cómo las gestionan. Los resultados señalan que este es un tema de interés y que la práctica actual requiere de soporte metodológico adecuado.
Palabras clave: requisitos de calidad del software, interacción entre características de calidad, conflicto entre características de calidad, tablas de interacción.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1047</post_id>
		<post_date><![CDATA[2016-04-24 19:09:11]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 17:09:11]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[identificacion-de-interacciones-entre-las-caracteristicas-de-calidad-del-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1048]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las interacciones entre atributos de calidad del software pueden ser conflictivas, situación que podría dificultar que el software cumpla con las expectativas de los participantes. Los conflictos entre los requisitos de calidad pueden identificarse al revisar tablas de interacción que muestren el tipo de contribución potencial que tendría una característica de calidad sobre otra. Por tanto, realizamos una revisión de la literatura para recopilar las tablas de interacción publicadas. Tras la revisión de los artículos seleccionados, proponemos una técnica para construir tablas de interacción, la cual fue aplicada en los modelos de calidad de usabilidad, mantenibilidad y seguridad. Con la intención de corroborar la información de las tablas, realizamos una encuesta exploratoria cuyo objetivo es determinar si las empresas advierten las interacciones, y en su caso, conocer cómo las gestionan. Los resultados señalan que este es un tema de interés y que la práctica actual requiere de soporte metodológico adecuado.
Palabras clave: requisitos de calidad del software, interacción entre características de calidad, conflicto entre características de calidad, tablas de interacción.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Gabriel Alberto García-Mireles]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Matemáticas, Universidad de Sonora Blvd. Encinas y Rosales s/n col. Centro, 83000 Hermosillo, Sonora, México]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mireles@gauss.mat.uson.mx]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ma Ángeles Moraga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha, Paseo de la Universidad 4, 13071, Ciudad Real, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[MariaAngeles.Moraga@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Félix García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha, Paseo de la Universidad 4, 13071, Ciudad Real, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Felix.Garcia@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha, Paseo de la Universidad 4, 13071, Ciudad Real, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Mario.Piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/006]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Timed Automata and Model Checking to Verify Business Processes</title>
		<link>https://biblioteca.sistedes.es/articulo/timed-automata-and-model-checking-to-verify-business-processes/</link>
		<pubDate>Sun, 24 Apr 2016 17:11:17 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1050</guid>
		<description></description>
		<content><![CDATA[Currently, the use of Software Engineering methods has been shown to be useful in improving business modelling techniques as a result of their application to Business Process (BP)­modelling initiatives. Nowadays when the business process needs to be supported by Information Technology, the Unified Modeling Language (UML) is widely used for modelling. This paper presents the use of Timed Automata (TA) and Model Checking (MC) by their application to an example of a BP enterprise­project related to the Customer Relationship Management (CRM) business. The Uppaal tool is used in this work. With this proposal, the analysts and designers are supported in the development of the BP­task model associated with a BP design by using UML as the main modelling language. The application of the proposal is aimed at ensuring the correctness of the BP­task model with respect to the initial property specification derived from the business rules.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1050</post_id>
		<post_date><![CDATA[2016-04-24 19:11:17]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 17:11:17]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[timed-automata-and-model-checking-to-verify-business-processes]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="business-process"><![CDATA[Business process]]></category>
		<category domain="post_tag" nicename="model-checking"><![CDATA[Model checking]]></category>
		<category domain="post_tag" nicename="timed-automata"><![CDATA[Timed automata]]></category>
		<category domain="post_tag" nicename="uppaal-tool"><![CDATA[Uppaal tool]]></category>
		<category domain="post_tag" nicename="verification"><![CDATA[Verification]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Currently, the use of Software Engineering methods has been shown to be useful in improving business modelling techniques as a result of their application to Business Process (BP)­modelling initiatives. Nowadays when the business process needs to be supported by Information Technology, the Unified Modeling Language (UML) is widely used for modelling. This paper presents the use of Timed Automata (TA) and Model Checking (MC) by their application to an example of a BP enterprise­project related to the Customer Relationship Management (CRM) business. The Uppaal tool is used in this work. With this proposal, the analysts and designers are supported in the development of the BP­task model associated with a BP design by using UML as the main modelling language. The application of the proposal is aimed at ensuring the correctness of the BP­task model with respect to the initial property specification derived from the business rules.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Timed automata, Model checking, Verification, Business process, Uppaal tool]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Luis E. Mendoza Morales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Processes and Systems Department, Simo´n Bol´ivar University, P.O. box 89000, Baruta, Caracas 1080-A, Venezuela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[lmendoza@usb.ve]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Guaraná: Integración de Aplicaciones en la Nube</title>
		<link>https://biblioteca.sistedes.es/articulo/guarana-integracion-de-aplicaciones-en-la-nube/</link>
		<pubDate>Sun, 24 Apr 2016 17:13:17 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1052</guid>
		<description></description>
		<content><![CDATA[El crecimiento tecnológico de las empresas ha provocado un aumento significativo del número de recursos informáticos del que dependen. El ecosistema software habitual de una empresa cuenta con sistemas y plataformas muy heterogéneas con interfaces de comunicación incompatibles. En los últimos años, este crecimiento ha provocado la necesidad de sincronizar información o generar funcionalidad adicional entre las diversas aplicaciones del ecosistema con el objetivo de mejorar los procesos de negocio de las empresas. Históricamente los proyectos de integración de aplicaciones empresariales han sido complejos y costosos, con una tasa de fracaso muy elevada. La tecnología de integración Guaraná proporciona herramientas de apoyo a los ingenieros de integración en cada fase del proyecto, permitiendo así, reducir la complejidad y el coste de los mismos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1052</post_id>
		<post_date><![CDATA[2016-04-24 19:13:17]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 17:13:17]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[guarana-integracion-de-aplicaciones-en-la-nube]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="bus-de-servicios-empresariales"><![CDATA[Bus de Servicios Empresariales]]></category>
		<category domain="post_tag" nicename="cloud-computing"><![CDATA[Cloud Computing]]></category>
		<category domain="post_tag" nicename="integracion-de-aplicaciones"><![CDATA[Integración de Aplicaciones]]></category>
		<category domain="post_tag" nicename="lenguaje-especifico-de-dominio"><![CDATA[Lenguaje Específico de Dominio]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1053]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El crecimiento tecnológico de las empresas ha provocado un aumento significativo del número de recursos informáticos del que dependen. El ecosistema software habitual de una empresa cuenta con sistemas y plataformas muy heterogéneas con interfaces de comunicación incompatibles. En los últimos años, este crecimiento ha provocado la necesidad de sincronizar información o generar funcionalidad adicional entre las diversas aplicaciones del ecosistema con el objetivo de mejorar los procesos de negocio de las empresas. Históricamente los proyectos de integración de aplicaciones empresariales han sido complejos y costosos, con una tasa de fracaso muy elevada. La tecnología de integración Guaraná proporciona herramientas de apoyo a los ingenieros de integración en cada fase del proyecto, permitiendo así, reducir la complejidad y el coste de los mismos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Integración de Aplicaciones, Bus de Servicios Empresariales, Lenguaje Especifico de Dominio, Cloud Computing]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Carlos Yerga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Intelligent Integration Factory S.L. Parque Científico Tecnológico de Huelva, Módulo 5 Calle Industria 59, 21110, Aljaraque (Huelva)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jose.carlos.yerga@i2factory.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Luis Arjona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Intelligent Integration Factory S.L. Parque Científico Tecnológico de Huelva, Módulo 5 Calle Industria 59, 21110, Aljaraque (Huelva)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jose.luis.arjona@i2factory.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Antonio Garrido]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Intelligent Integration Factory S.L. Parque Científico Tecnológico de Huelva, Módulo 5 Calle Industria 59, 21110, Aljaraque (Huelva)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juan.antonio.garrido@i2factory.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Gestión de Procesos en Organizaciones De Desarrollo de Software: Un Enfoque Basado en Modelos</title>
		<link>https://biblioteca.sistedes.es/articulo/gestion-de-procesos-en-organizaciones-de-desarrollo-de-software-un-enfoque-basado-en-modelos/</link>
		<pubDate>Sun, 24 Apr 2016 17:16:30 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1055</guid>
		<description></description>
		<content><![CDATA[La Gestión de Procesos de Negocio (Business Process Management, BPM) se centra en la definicíon, orquestación, documentación y mejora de los procesos de negocio en una organización. En los últimos años, siguiendo recomendaciones internacionales y gúias de buenas prácticas en el desarrollo de software, las empresas de software están adoptando el BPM como mecanismo para controlar y definir cómo construir sistemas software. Sin embargo, su aplicación en este contexto de negocio no es simple debido a que el desarrollo de software está en constante evolución y a menudo incorpora novedades en los ciclos de vida, tecnologías o equipos de desarrollo, entre otros aspectos. En este trabajo se evalúa cómo un enfoque basado en modelos puede facilitar la aplicación de BPM en las organizaciones de desarrollo de software. Para ello, en primer lugar se expone una revisión de los estándares y propuestas existentes para definir procesos de software. A continuación presentamos un metamodelo de definicíon de procesos que se ha integrado en una herramienta mediante un perfil UML. Finalmente, se mostrará el resultado a través de NDTQ Framework, una solución actualmente en uso en varias organizaciones de software. Se concluye el trabajo con la presentación de nuevas líneas de investigación abiertas, orientadas a extender este enfoque a otros entornos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1055</post_id>
		<post_date><![CDATA[2016-04-24 19:16:30]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 17:16:30]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[gestion-de-procesos-en-organizaciones-de-desarrollo-de-software-un-enfoque-basado-en-modelos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="enfoques-basados-en-modelos"><![CDATA[Enfoques Basados en Modelos]]></category>
		<category domain="post_tag" nicename="modelado-de-procesos"><![CDATA[Modelado de Procesos]]></category>
		<category domain="post_tag" nicename="proceso-software"><![CDATA[Proceso Software]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1056]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La Gestión de Procesos de Negocio (Business Process Management, BPM) se centra en la definicíon, orquestación, documentación y mejora de los procesos de negocio en una organización. En los últimos años, siguiendo recomendaciones internacionales y gúias de buenas prácticas en el desarrollo de software, las empresas de software están adoptando el BPM como mecanismo para controlar y definir cómo construir sistemas software. Sin embargo, su aplicación en este contexto de negocio no es simple debido a que el desarrollo de software está en constante evolución y a menudo incorpora novedades en los ciclos de vida, tecnologías o equipos de desarrollo, entre otros aspectos. En este trabajo se evalúa cómo un enfoque basado en modelos puede facilitar la aplicación de BPM en las organizaciones de desarrollo de software. Para ello, en primer lugar se expone una revisión de los estándares y propuestas existentes para definir procesos de software. A continuación presentamos un metamodelo de definicíon de procesos que se ha integrado en una herramienta mediante un perfil UML. Finalmente, se mostrará el resultado a través de NDTQ Framework, una solución actualmente en uso en varias organizaciones de software. Se concluye el trabajo con la presentación de nuevas líneas de investigación abiertas, orientadas a extender este enfoque a otros entornos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Proceso Software, Enfoques Basados en Modelos, Modelado de Procesos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[L. García-Borgoñón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto Tecnológico de Aragón, c/ María de Luna 7, 50018 Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[laurag@ita.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[J.A. García-García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Av. Reina Mercedes S/N, 41012 Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[julian.garcia@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[M. Alba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Av. Reina Mercedes S/N, 41012 Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuel.alba@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[F.J. Domínguez-Mayo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Av. Reina Mercedes S/N, 41012 Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[fjdominguez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/003]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Desafíos de la Mejora de Procesos de Negocio recuperados mediante ingeniería inversa</title>
		<link>https://biblioteca.sistedes.es/articulo/desafios-de-la-mejora-de-procesos-de-negocio-recuperados-mediante-ingenieria-inversa/</link>
		<pubDate>Sun, 24 Apr 2016 17:18:55 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1058</guid>
		<description></description>
		<content><![CDATA[Con el fin de realizar una adecuada gestión de sus procesos, las empresas cada vez están más interesadas en disponer de procesos de negocio que presenten grados de calidad óptimos. Estos procesos de negocio que son ejecutados por las empresas son a menudo obtenidos utilizando técnicas de ingeniería inversa a partir de sus propios sistemas de información. Sin embargo, estos modelos de procesos de negocio que son obtenidos suelen tener un grado menor de calidad debido a la pérdida semántica que conllevan, y no siempre corresponden a representaciones exactas de los procesos de negocio actuales. En este trabajo se presentan todos los problemas detectados que deben ser abordados para mejorar la calidad de los procesos de negocio especialmente recuperados mediante ingeniería inversa. Entre estos dichos problemas se encuentran la no recuperación automática de elementos relevantes en el modelo o la recuperación de elementos que no son relevantes, el exceso de elementos de granularidad fina que disminuye el nivel de abstracción, entre otros. Este trabajo también sugiere una técnica para mejorar un modelo de procesos de negocio a lo largo de tres fases: reparación, refactorización y mejora semántica.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1058</post_id>
		<post_date><![CDATA[2016-04-24 19:18:55]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 17:18:55]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[desafios-de-la-mejora-de-procesos-de-negocio-recuperados-mediante-ingenieria-inversa]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="desafios-de-procesos-de-negocio"><![CDATA[Desafíos de procesos de negocio]]></category>
		<category domain="post_tag" nicename="entendibilidad"><![CDATA[Entendibilidad]]></category>
		<category domain="post_tag" nicename="modelos-de-procesos-de-negocio"><![CDATA[Modelos de procesos de negocio]]></category>
		<category domain="post_tag" nicename="modificabilidad"><![CDATA[Modificabilidad]]></category>
		<category domain="post_tag" nicename="refactorizacion"><![CDATA[Refactorización]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1059]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Con el fin de realizar una adecuada gestión de sus procesos, las empresas cada vez están más interesadas en disponer de procesos de negocio que presenten grados de calidad óptimos. Estos procesos de negocio que son ejecutados por las empresas son a menudo obtenidos utilizando técnicas de ingeniería inversa a partir de sus propios sistemas de información. Sin embargo, estos modelos de procesos de negocio que son obtenidos suelen tener un grado menor de calidad debido a la pérdida semántica que conllevan, y no siempre corresponden a representaciones exactas de los procesos de negocio actuales. En este trabajo se presentan todos los problemas detectados que deben ser abordados para mejorar la calidad de los procesos de negocio especialmente recuperados mediante ingeniería inversa. Entre estos dichos problemas se encuentran la no recuperación automática de elementos relevantes en el modelo o la recuperación de elementos que no son relevantes, el exceso de elementos de granularidad fina que disminuye el nivel de abstracción, entre otros. Este trabajo también sugiere una técnica para mejorar un modelo de procesos de negocio a lo largo de tres fases: reparación, refactorización y mejora semántica.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Modelos de procesos de negocio, Desafíos de procesos de negocio, Refactorización, Entendibilidad, Modificabilidad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Fernández-Ropero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de la Información, Universidad de Castilla-La Mancha Paseo de la Universidad 4, 13071. Ciudad Real, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[marias.fernandez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ricardo Pérez-Castillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de la Información, Universidad de Castilla-La Mancha Paseo de la Universidad 4, 13071. Ciudad Real, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ricardo.pdelcastillo@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de la Información, Universidad de Castilla-La Mancha Paseo de la Universidad 4, 13071. Ciudad Real, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mario.piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/002]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Event Correlation in Non-Process-Aware Systems</title>
		<link>https://biblioteca.sistedes.es/articulo/event-correlation-in-non-process-aware-systems/</link>
		<pubDate>Sun, 24 Apr 2016 17:21:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1061</guid>
		<description></description>
		<content><![CDATA[Since business processes supported by traditional systems are implicitly defined, correlating events into the appropriate process instance is not trivial. This challenge is known as the event correlation problem. This paper presents an adaptation of an existing event correlation algorithm and incorporates it into a technique to collect event logs from the execution of traditional information systems. The technique first instruments the source code to collect events together with some candidate correlation attributes. Secondly, the algorithm is applied to the dataset of events to discover the best correlation conditions. Event logs are then built using such conditions. The technique has been semi-automated to facilitate its validation through an industrial case study involving a writer management system and a healthcare evaluation system. The study demonstrates that the technique is able to discover the correlation set and obtain well-formed event logs enabling business process mining techniques to be applied to traditional information systems.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1061</post_id>
		<post_date><![CDATA[2016-04-24 19:21:54]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 17:21:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[event-correlation-in-non-process-aware-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="case-study"><![CDATA[Case Study]]></category>
		<category domain="post_tag" nicename="event-correlation"><![CDATA[Event Correlation]]></category>
		<category domain="post_tag" nicename="event-model"><![CDATA[Event Model]]></category>
		<category domain="post_tag" nicename="process-mining"><![CDATA[Process Mining]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1062]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Since business processes supported by traditional systems are implicitly defined, correlating events into the appropriate process instance is not trivial. This challenge is known as the event correlation problem. This paper presents an adaptation of an existing event correlation algorithm and incorporates it into a technique to collect event logs from the execution of traditional information systems. The technique first instruments the source code to collect events together with some candidate correlation attributes. Secondly, the algorithm is applied to the dataset of events to discover the best correlation conditions. Event logs are then built using such conditions. The technique has been semi-automated to facilitate its validation through an industrial case study involving a writer management system and a healthcare evaluation system. The study demonstrates that the technique is able to discover the correlation set and obtain well-formed event logs enabling business process mining techniques to be applied to traditional information systems.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Process Mining, Event Correlation, Event Model, Case Study]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ricardo Pérez-Castillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información (ITSI) University of Castilla-La Mancha Paseo de la Universidad 4 13071, Ciudad Real, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ricardo.pdelcastillo@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Barbara Weber]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Innsbruck Technikerstraße 21a, 6020, Innsbruck, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[barbara.weber@uibk.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ignacio García-Rodríguez de Guzmán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información (ITSI) University of Castilla-La Mancha Paseo de la Universidad 4 13071, Ciudad Real, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ignacio.grodriguez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información (ITSI) University of Castilla-La Mancha Paseo de la Universidad 4 13071, Ciudad Real, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mario.piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Jakob Pinggera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Innsbruck Technikerstraße 21a, 6020, Innsbruck, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[jakob.pinggera@uibk.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/001]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SOLID: una Arquitectura para la Gestión de Big Semantic Data en Tiempo Real</title>
		<link>https://biblioteca.sistedes.es/articulo/solid-una-arquitectura-para-la-gestion-de-big-semantic-data-en-tiempo-real/</link>
		<pubDate>Sun, 24 Apr 2016 17:26:46 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1064</guid>
		<description></description>
		<content><![CDATA[La gestión de grandes colecciones de datos (Big Data) es un proceso crítico en entornos de explotación en tiempo real ya que las arquitecturas batch, que garantizan un comportamiento escalable, ofrecen unos tiempos de respuesta insuficientes para los requisitos de rendimiento que se presentan en dichos entornos. En este artículo se estudia esta problemática, de acuerdo a las necesidades planteadas por aquellos sistemas de información en los que se forman y exponen grandes colecciones de RDF (Big Semantic Data) en tiempo real. Nuestra propuesta es una nueva arquitectura (SOLID) que áisla la complejidad de almacenar grandes colecciones de datos y las necesidades específicas de insertar y consultar Big Semantic Data en tiempo real. La base tecnológica de SOLID comprende el uso de RDF/HDT para el almacenamiento auto-indexado de los datos y tecnología NoSQL para su gestión en tiempo real. Nuestros resultados experimentales muestran la eficiencia de cada una de las capas de datos y su integración mediante dos capas software adicionales que garantizan la escalabilidad de SOLID.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1064</post_id>
		<post_date><![CDATA[2016-04-24 19:26:46]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 17:26:46]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[solid-una-arquitectura-para-la-gestion-de-big-semantic-data-en-tiempo-real]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1067]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La gestión de grandes colecciones de datos (Big Data) es un proceso crítico en entornos de explotación en tiempo real ya que las arquitecturas batch, que garantizan un comportamiento escalable, ofrecen unos tiempos de respuesta insuficientes para los requisitos de rendimiento que se presentan en dichos entornos. En este artículo se estudia esta problemática, de acuerdo a las necesidades planteadas por aquellos sistemas de información en los que se forman y exponen grandes colecciones de RDF (Big Semantic Data) en tiempo real. Nuestra propuesta es una nueva arquitectura (SOLID) que áisla la complejidad de almacenar grandes colecciones de datos y las necesidades específicas de insertar y consultar Big Semantic Data en tiempo real. La base tecnológica de SOLID comprende el uso de RDF/HDT para el almacenamiento auto-indexado de los datos y tecnología NoSQL para su gestión en tiempo real. Nuestros resultados experimentales muestran la eficiencia de cada una de las capas de datos y su integración mediante dos capas software adicionales que garantizan la escalabilidad de SOLID.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Mario Arias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Digital Enterprise Research Institute (DERI), National University of Ireland, Galway (Ireland) 2 ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mario.arias@deri.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carlos E. Cuesta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[VorTIC3 Research Group, Dept. de Lenguajes y Sistemas Informáticos II, Universidad Rey Juan Carlos, Madrid (España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[carlos.cuesta@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier D. Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DataWeb Research, Dept. de Informática, Universidad de Valladolid, Valladolid (España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jfergar@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Miguel A. Martínez-Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[DataWeb Research, Dept. de Informática, Universidad de Valladolid, Valladolid (España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[migumar2@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/014]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Trace Metamodel Proposal based on the Model Driven Architecture Framework for the Traceability of User Requirements in Data Warehouses</title>
		<link>https://biblioteca.sistedes.es/articulo/a-trace-metamodel-proposal-based-on-the-model-driven-architecture-framework-for-the-traceability-of-user-requirements-in-data-warehouses/</link>
		<pubDate>Sun, 24 Apr 2016 17:28:42 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1069</guid>
		<description></description>
		<content><![CDATA[Data warehouses (DW) integrate several heterogeneous data sources in multidimensional structures (i.e. facts and dimensions) in support of the decisionmaking process in Business Intelligence. Therefore, the development of the DW is a complex process that must be carefully planned in order to meet user needs. In order to develop the DW, three different approaches, similar to the existing ones in Software Engineering (bottom-up or supply-driven, top-down or demanddriven, and hybrid), were proposed [1]. The hybrid approach makes use of both data sources and user requirements, and avoids missing information from one of the two sources until the DW is already built.
However, by following the hybrid approach a new problem arises. DW elements are merged to consider the information from both requirements and data sources, each named using a different terminology. In turn, implicit traceability is lost, thus hurting requirements validation, making us unable to trace each requirement, and dramatically increasing the cost of introducing changes.
In order to solve this problem, in this paper, we perform a thorough review of literature on traceability, and, due to the special idiosyncrasy of DW development, we propose a novel trace metamodel specifically tailored to face several challenges: (i) connecting multiple sources with multiple targets in a meaningful way, as requirements need to be reconciled with data sources that may, or may not, match the expectations of the users. (ii) Being weakly coupled with DW models, as these models can change since there is no standard. Finally, (iii) minimizing the overhead introduced in the development process with the inclusion of traceability, by defining how traces should be generated in an automatic way, and maintaining them without user intervention wherever possible.
First, we introduce the semantics included in the metamodel, to cover the different relationships involved in DW development. Then, we describe how traces can be integrated within DW development by means of trace models. Afterwards, we show how these trace models can be aligned with the Model Driven Architecture (MDA) framework in order to semi-automatically generate traces within the DW development process. We show how to generate traces from user requirements to conceptual DW models by means of Query/View/Transformation (QVT) rules, thus saving time and costs required to record traces. Furthermore, we also describe how traces can be maintained without requiring human intervention when changes are introduced into the DW. Additionally, we show how the framework can be implemented within the Eclipse platform and how the results are integrated into a DW development approach.
In order to show the applicability of our proposal, we show an example of application based on a real case study with another university that involved designing several data marts for educational analysis. As shown in Figure 1, our framework allows us to trace each requirement, as well as any modifications, to its corresponding elements in the DW. The great benefit of our proposal is the improvement in requirements validation as well as being able to easily assess the impact of changes and regenerate the affected parts.
Our plans for the immediate future are developing a new set of QVT rules to explore the relationships between the conceptual and logical models, and explore the potential of using the information recorded in the traces in order to support automated analysis. We will also complete our development of the traceability framework in order to make the maintenance of traces as automatic as possible.
Acknowledgments This work has been partially supported by the MESOLAP (TIN2010-14860) and SERENIDAD (PEII-11-0327-7035) projects from the Spanish Ministry of Education and the Junta de Comunidades de Castilla La Mancha. Alejandro Maté is funded by the Generalitat Valenciana under the grant ACIF/2010/298.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1069</post_id>
		<post_date><![CDATA[2016-04-24 19:28:42]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 17:28:42]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-trace-metamodel-proposal-based-on-the-model-driven-architecture-framework-for-the-traceability-of-user-requirements-in-data-warehouses]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1070]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Data warehouses (DW) integrate several heterogeneous data sources in multidimensional structures (i.e. facts and dimensions) in support of the decisionmaking process in Business Intelligence. Therefore, the development of the DW is a complex process that must be carefully planned in order to meet user needs. In order to develop the DW, three different approaches, similar to the existing ones in Software Engineering (bottom-up or supply-driven, top-down or demanddriven, and hybrid), were proposed [1]. The hybrid approach makes use of both data sources and user requirements, and avoids missing information from one of the two sources until the DW is already built.
However, by following the hybrid approach a new problem arises. DW elements are merged to consider the information from both requirements and data sources, each named using a different terminology. In turn, implicit traceability is lost, thus hurting requirements validation, making us unable to trace each requirement, and dramatically increasing the cost of introducing changes.
In order to solve this problem, in this paper, we perform a thorough review of literature on traceability, and, due to the special idiosyncrasy of DW development, we propose a novel trace metamodel specifically tailored to face several challenges: (i) connecting multiple sources with multiple targets in a meaningful way, as requirements need to be reconciled with data sources that may, or may not, match the expectations of the users. (ii) Being weakly coupled with DW models, as these models can change since there is no standard. Finally, (iii) minimizing the overhead introduced in the development process with the inclusion of traceability, by defining how traces should be generated in an automatic way, and maintaining them without user intervention wherever possible.
First, we introduce the semantics included in the metamodel, to cover the different relationships involved in DW development. Then, we describe how traces can be integrated within DW development by means of trace models. Afterwards, we show how these trace models can be aligned with the Model Driven Architecture (MDA) framework in order to semi-automatically generate traces within the DW development process. We show how to generate traces from user requirements to conceptual DW models by means of Query/View/Transformation (QVT) rules, thus saving time and costs required to record traces. Furthermore, we also describe how traces can be maintained without requiring human intervention when changes are introduced into the DW. Additionally, we show how the framework can be implemented within the Eclipse platform and how the results are integrated into a DW development approach.
In order to show the applicability of our proposal, we show an example of application based on a real case study with another university that involved designing several data marts for educational analysis. As shown in Figure 1, our framework allows us to trace each requirement, as well as any modifications, to its corresponding elements in the DW. The great benefit of our proposal is the improvement in requirements validation as well as being able to easily assess the impact of changes and regenerate the affected parts.
Our plans for the immediate future are developing a new set of QVT rules to explore the relationships between the conceptual and logical models, and explore the potential of using the information recorded in the traces in order to support automated analysis. We will also complete our development of the traceability framework in order to make the maintenance of traces as automatic as possible.
Acknowledgments This work has been partially supported by the MESOLAP (TIN2010-14860) and SERENIDAD (PEII-11-0327-7035) projects from the Spanish Ministry of Education and the Junta de Comunidades de Castilla La Mancha. Alejandro Maté is funded by the Generalitat Valenciana under the grant ACIF/2010/298.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alejandro Maté]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Lucentia Research Group, Department of Software and Computing Systems, University of Alicante, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[amate@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Trujillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Lucentia Research Group, Department of Software and Computing Systems, University of Alicante, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jtrujillo@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/013]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Exploiting SIMD instructions in current processors to improve classical string algorithms</title>
		<link>https://biblioteca.sistedes.es/articulo/exploiting-simd-instructions-in-current-processors-to-improve-classical-string-algorithms/</link>
		<pubDate>Sun, 24 Apr 2016 17:31:12 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1072</guid>
		<description></description>
		<content><![CDATA[Algorithms and data structures for efficient representation and processing of large databases can be combined with advances in computer architecture, as hardware-aware implementations that exploit particular hardware features. For example, many algorithms have been adapted to exploit the architecture of GPUs, FPGAs, or general-purpose CPUs providing instructions included for particular application domains.
In this paper we explore how the Intel SSE4.2 (Streaming SIMD Extensions) SIMD (Single Instruction Multiple Data) instructions included in Intel/AMD processors can improve the performance of algorithms for text indexing and searching. The SSE4.2 instruction subset provides instructions for text processing. Our implementations are mainly based on the followings: POPCOUNT counts the number of 1 bits in a word of up to 64 bits, PCMPESTRI compares two strings of length up to 16 bytes and returns the result as a binary mask.
Despite the benefits these features can bring to text processing, they have been rarely used or evaluated in the existing literature. We present case studies and experimental results that show how much text/string algorithms can benefit from the SIMD extensions. Particularly, we focus on the rank and select operations in sequences of bits and bytes, and the Horspool string search algorithm.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1072</post_id>
		<post_date><![CDATA[2016-04-24 19:31:12]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 17:31:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[exploiting-simd-instructions-in-current-processors-to-improve-classical-string-algorithms]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1073]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Algorithms and data structures for efficient representation and processing of large databases can be combined with advances in computer architecture, as hardware-aware implementations that exploit particular hardware features. For example, many algorithms have been adapted to exploit the architecture of GPUs, FPGAs, or general-purpose CPUs providing instructions included for particular application domains.
In this paper we explore how the Intel SSE4.2 (Streaming SIMD Extensions) SIMD (Single Instruction Multiple Data) instructions included in Intel/AMD processors can improve the performance of algorithms for text indexing and searching. The SSE4.2 instruction subset provides instructions for text processing. Our implementations are mainly based on the followings: POPCOUNT counts the number of 1 bits in a word of up to 64 bits, PCMPESTRI compares two strings of length up to 16 bytes and returns the result as a binary mask.
Despite the benefits these features can bring to text processing, they have been rarely used or evaluated in the existing literature. We present case studies and experimental results that show how much text/string algorithms can benefit from the SIMD extensions. Particularly, we focus on the rank and select operations in sequences of bits and bytes, and the Horspool string search algorithm.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Susana Ladra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Database Laboratory. Universidade da Coruña, Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[sladra@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Oscar Pedreira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Database Laboratory. Universidade da Coruña, Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[opedreira@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose Duato]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Parallel Architectures Group, Universitat Politécnica de Valéncia, Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jduato@disca.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Nieves R. Brisaboa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Database Laboratory. Universidade da Coruña, Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[brisaboa@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/012]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Aplicaciones Semánticas basadas en RDF/HDT</title>
		<link>https://biblioteca.sistedes.es/articulo/aplicaciones-semanticas-basadas-en-rdfhdt/</link>
		<pubDate>Sun, 24 Apr 2016 17:34:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1075</guid>
		<description></description>
		<content><![CDATA[La utilización de RDF, como modelo lógico de datos, ha crecido en los últimos años gracias a proyectos relacionados con la Web Semántica y Open Data. A pesar del volumen de estas colecciones, la serialización de RDF se ha seguido realizando con formatos textuales concebidos para su propósito original: describir pequeños conjuntos de metadatos. Esto supone un gasto innecesario en recursos de almacenamiento y ancho de banda, aparte de hacer más complejos los procesos de procesamiento e indexación. RDF/HDT (Header, Dictionary, Triples) es un formato binario que serializa RDF en espacio comprimido y provee soporte nativo para la búsqueda y navegación de los datos a través de una configuración específica de estructuras de datos compactas. Este artículo analiza el alcance de RDF/HDT desde una perspectiva práctica, en la se que presenta el proyecto rdfhdt.org y se revisan las herramientas que hemos desarrollado para la gestión, consulta y visualización de RDF, utilizando RDF/HDT en escenarios tradicionales junto con algunos resultados iniciales en dispositivos móviles.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1075</post_id>
		<post_date><![CDATA[2016-04-24 19:34:02]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 17:34:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[aplicaciones-semanticas-basadas-en-rdfhdt]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1076]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La utilización de RDF, como modelo lógico de datos, ha crecido en los últimos años gracias a proyectos relacionados con la Web Semántica y Open Data. A pesar del volumen de estas colecciones, la serialización de RDF se ha seguido realizando con formatos textuales concebidos para su propósito original: describir pequeños conjuntos de metadatos. Esto supone un gasto innecesario en recursos de almacenamiento y ancho de banda, aparte de hacer más complejos los procesos de procesamiento e indexación. RDF/HDT (Header, Dictionary, Triples) es un formato binario que serializa RDF en espacio comprimido y provee soporte nativo para la búsqueda y navegación de los datos a través de una configuración específica de estructuras de datos compactas. Este artículo analiza el alcance de RDF/HDT desde una perspectiva práctica, en la se que presenta el proyecto rdfhdt.org y se revisan las herramientas que hemos desarrollado para la gestión, consulta y visualización de RDF, utilizando RDF/HDT en escenarios tradicionales junto con algunos resultados iniciales en dispositivos móviles.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Mario Arias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Digital Enterprise Research Institute (DERI), National University of Ireland, Galway (Ireland)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mario.arias@deri.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier D. Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[DataWeb Research, Dept. de Informática, Universdad de Valladolid, Valladolid (España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jfergar@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Miguel A. Martínez-Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DataWeb Research, Dept. de Informática, Universdad de Valladolid, Valladolid (España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[migumar2@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/011]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Propuesta para Guiar el Desarrollo de Software Mediante el Uso de Técnicas Procedentes de los Sistemas Educativos Adaptativos</title>
		<link>https://biblioteca.sistedes.es/articulo/propuesta-para-guiar-el-desarrollo-de-software-mediante-el-uso-de-tecnicas-procedentes-de-los-sistemas-educativos-adaptativos/</link>
		<pubDate>Sun, 24 Apr 2016 17:37:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1081</guid>
		<description></description>
		<content><![CDATA[Lo que se presenta en este artículo, es una aproximación a la aplicación de una herramienta empleada y validada en el ámbito académico para el aprendizaje de la Programación, y centrada fundamentalmente en la calidad del código fuente y la definición de flujos de actividades. Para ello, aplica conceptos tomados de los Sistemas Tutores Inteligentes permitiendo la aplicación de análisis estático de código a través de métricas software empleando Lógica Difusa, además de contar con servicios de definición y seguimiento de flujos de las actividades de los desarrolladores.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1081</post_id>
		<post_date><![CDATA[2016-04-24 19:37:53]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 17:37:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[propuesta-para-guiar-el-desarrollo-de-software-mediante-el-uso-de-tecnicas-procedentes-de-los-sistemas-educativos-adaptativos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="calidad-software"><![CDATA[Calidad Software]]></category>
		<category domain="post_tag" nicename="eclipse"><![CDATA[Eclipse]]></category>
		<category domain="post_tag" nicename="flujos-de-actividades"><![CDATA[Flujos de Actividades]]></category>
		<category domain="post_tag" nicename="logica-difusa"><![CDATA[Lógica Difusa]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1082]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Lo que se presenta en este artículo, es una aproximación a la aplicación de una herramienta empleada y validada en el ámbito académico para el aprendizaje de la Programación, y centrada fundamentalmente en la calidad del código fuente y la definición de flujos de actividades. Para ello, aplica conceptos tomados de los Sistemas Tutores Inteligentes permitiendo la aplicación de análisis estático de código a través de métricas software empleando Lógica Difusa, además de contar con servicios de definición y seguimiento de flujos de las actividades de los desarrolladores.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Calidad Software, Lógica Difusa, Flujos de Actividades, Eclipse]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Jurado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departament d'Informàtica i Enginyeria Industrial Escola Politècnica Superior, Universitat de LLeida C/Jaume II, 69, Campus Cappont, E-25001 Lleida (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Francisco.Jurado@diei.udl.cat]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miguel A. Redondo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Tecnologías y Sistemas de Información Escuela Superior de Informática, Universidad de Castilla-La Mancha Paseo de la Universidad, 4, 13071 Ciudad Real (España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Miguel.Redondo@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Tecnologías y Sistemas de Información Escuela Superior de Informática, Universidad de Castilla-La Mancha Paseo de la Universidad, 4, 13071 Ciudad Real (España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Manuel.Ortega@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/022]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SLACT: a Test Case Generation Tool for Service Level Agreements</title>
		<link>https://biblioteca.sistedes.es/articulo/slact-a-test-case-generation-tool-for-service-level-agreements/</link>
		<pubDate>Sun, 24 Apr 2016 17:40:21 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1084</guid>
		<description></description>
		<content><![CDATA[SLACT (SLA Combinatorial Testing) tool addresses the testing of Service Level Agreements (SLAs) in the context of applications developed under the Service Oriented Architectures paradigm. From the specification of the SLA, it automatically identifies a set of test requirements that are suitably combined in order to generate feasible and executable test cases. To perform the combinations, SLACT implements standard testing techniques such as the Classification Tree Method (CTM) and Combinatorial Testing.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1084</post_id>
		<post_date><![CDATA[2016-04-24 19:40:21]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 17:40:21]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[slact-a-test-case-generation-tool-for-service-level-agreements]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="classification-tree-method"><![CDATA[Classification Tree Method]]></category>
		<category domain="post_tag" nicename="combinatorial-testing"><![CDATA[Combinatorial Testing]]></category>
		<category domain="post_tag" nicename="service-based-applications"><![CDATA[Service Based Applications]]></category>
		<category domain="post_tag" nicename="slas"><![CDATA[SLAs]]></category>
		<category domain="post_tag" nicename="software-testing"><![CDATA[Software Testing]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1085]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[SLACT (SLA Combinatorial Testing) tool addresses the testing of Service Level Agreements (SLAs) in the context of applications developed under the Service Oriented Architectures paradigm. From the specification of the SLA, it automatically identifies a set of test requirements that are suitably combined in order to generate feasible and executable test cases. To perform the combinations, SLACT implements standard testing techniques such as the Classification Tree Method (CTM) and Combinatorial Testing.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Software Testing, Service Based Applications, SLAs, Classification Tree Method, Combinatorial Testing]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Marcos Palacios]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science University of Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[palaciosmarcos@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Robles]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science University of Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[probles@clin.lsi.uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José García-Fanjul]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science University of Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jgfanjul@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science University of Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/021]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>DruidaTest: Herramienta para pruebas de cobertura en aplicaciones de bases de datos</title>
		<link>https://biblioteca.sistedes.es/articulo/druidatest-herramienta-para-pruebas-de-cobertura-en-aplicaciones-de-bases-de-datos/</link>
		<pubDate>Sun, 24 Apr 2016 17:46:24 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1087</guid>
		<description></description>
		<content><![CDATA[Una de las tareas más laboriosas que se llevan a cabo durante el diseño de casos de prueba para una aplicación de bases de datos es la preparación de un conjunto adecuado de datos de prueba, el cual permita cubrir los diversos aspectos del comportamiento de dicha aplicación. Estos datos deben incluir la información almacenada en la base de datos y los valores suministrados por el usuario en el interfaz de usuario. En este artículo, se presenta la herramienta DruidaTest, la cual permite guiar la generación de datos de prueba a partir de la especificación del sistema, utilizando un criterio de suficiencia basado en MCDC. Para alcanzar este propósito DruidaTest utiliza un modelo denominado IDM (Integrated Data Model), que integra la estructura de la base de datos y el interfaz de usuario, y un modelo denominado IRM (Integrated Rules Model), que representa la funcionalidad requerida mediante un conjunto de reglas de negocio escritas en términos del IDM. DruidaTest procesa estos modelos para derivar las situaciones de interés a ser probadas (requisitos de prueba), evalúa automáticamente la cobertura alcanzada y proporciona retroalimentación al ingeniero de pruebas para que pueda incrementar la cobertura. ]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1087</post_id>
		<post_date><![CDATA[2016-04-24 19:46:24]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 17:46:24]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[druidatest-herramienta-para-pruebas-de-cobertura-en-aplicaciones-de-bases-de-datos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="datos-de-prueba"><![CDATA[datos de prueba]]></category>
		<category domain="post_tag" nicename="evaluacion-de-la-cobertura"><![CDATA[evaluación de la cobertura]]></category>
		<category domain="post_tag" nicename="herramienta"><![CDATA[Herramienta]]></category>
		<category domain="post_tag" nicename="mcdc"><![CDATA[MCDC]]></category>
		<category domain="post_tag" nicename="model-based-testing"><![CDATA[model-based testing]]></category>
		<category domain="post_tag" nicename="pruebas-basadas-en-la-especificacion"><![CDATA[pruebas basadas en la especificación]]></category>
		<category domain="post_tag" nicename="pruebas-de-caja-negra"><![CDATA[pruebas de caja negra]]></category>
		<category domain="post_tag" nicename="pruebas-sobre-bases-de-datos"><![CDATA[pruebas sobre bases de datos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1088]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Una de las tareas más laboriosas que se llevan a cabo durante el diseño de casos de prueba para una aplicación de bases de datos es la preparación de un conjunto adecuado de datos de prueba, el cual permita cubrir los diversos aspectos del comportamiento de dicha aplicación. Estos datos deben incluir la información almacenada en la base de datos y los valores suministrados por el usuario en el interfaz de usuario. En este artículo, se presenta la herramienta DruidaTest, la cual permite guiar la generación de datos de prueba a partir de la especificación del sistema, utilizando un criterio de suficiencia basado en MCDC. Para alcanzar este propósito DruidaTest utiliza un modelo denominado IDM (Integrated Data Model), que integra la estructura de la base de datos y el interfaz de usuario, y un modelo denominado IRM (Integrated Rules Model), que representa la funcionalidad requerida mediante un conjunto de reglas de negocio escritas en términos del IDM. DruidaTest procesa estos modelos para derivar las situaciones de interés a ser probadas (requisitos de prueba), evalúa automáticamente la cobertura alcanzada y proporciona retroalimentación al ingeniero de pruebas para que pueda incrementar la cobertura. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[herramienta, pruebas sobre bases de datos, pruebas basadas en la especificación, pruebas de caja negra, datos de prueba, evaluación de la cobertura, MCDC, model-based testing]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Raquel Blanco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo Campus de Gijón s/n, 33204 Gijón-Asturias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rblanco@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo Campus de Gijón s/n, 33204 Gijón-Asturias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Rubén V. Seco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo Campus de Gijón s/n, 33204 Gijón-Asturias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[valdesruben@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/020]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación Genética de Casos de Prueba para Composiciones WS-BPEL</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-genetica-de-casos-de-prueba-para-composiciones-ws-bpel/</link>
		<pubDate>Sun, 24 Apr 2016 17:48:56 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1090</guid>
		<description></description>
		<content><![CDATA[La generación automática de casos de prueba juega un papel de gran importancia dentro de la prueba de software. En concreto, la prueba basada en búsqueda genera casos de prueba codificando un criterio de cobertura como una función de aptitud que guía la búsqueda. De hecho, los algoritmos genéticos han sido aplicados con éxito a la prueba basada en búsqueda utilizando principalmente criterios de cobertura estructural. Este trabajo presenta un generador de casos de prueba para composiciones WS-BPEL denominado Rodan que está basado en un algoritmo genético. Su objetivo es generar casos de prueba que maten a los mutantes producidos a partir de la composición a probar. El algoritmo genético diseñado adopta algunas de las características de los algoritmos bacteriológicos, también propuestos para la generación de casos de prueba. Hemos aplicado Rodan a una composición WS-BPEL, comparando nuestra técnica con la generación aleatoria de casos de prueba y concluyéndose que con nuestra técnica se obtienen resultados prometedores.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1090</post_id>
		<post_date><![CDATA[2016-04-24 19:48:56]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 17:48:56]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-genetica-de-casos-de-prueba-para-composiciones-ws-bpel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1091]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La generación automática de casos de prueba juega un papel de gran importancia dentro de la prueba de software. En concreto, la prueba basada en búsqueda genera casos de prueba codificando un criterio de cobertura como una función de aptitud que guía la búsqueda. De hecho, los algoritmos genéticos han sido aplicados con éxito a la prueba basada en búsqueda utilizando principalmente criterios de cobertura estructural. Este trabajo presenta un generador de casos de prueba para composiciones WS-BPEL denominado Rodan que está basado en un algoritmo genético. Su objetivo es generar casos de prueba que maten a los mutantes producidos a partir de la composición a probar. El algoritmo genético diseñado adopta algunas de las características de los algoritmos bacteriológicos, también propuestos para la generación de casos de prueba. Hemos aplicado Rodan a una composición WS-BPEL, comparando nuestra técnica con la generación aleatoria de casos de prueba y concluyéndose que con nuestra técnica se obtienen resultados prometedores.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonia Estero-Botaro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Chile 1, 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[antonia.estero@uca.es ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio García-Domínguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Chile 1, 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[antonio.garciadominguez@uca.es ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan José Domínguez-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Chile 1, 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanjose.dominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Francisco Palomo-Lozano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Chile 1, 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[francisco.palomo@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Chile 1, 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/019]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>On the Effectiveness of UML Sequence Diagrams in the Comprehension of Functional Requirements</title>
		<link>https://biblioteca.sistedes.es/articulo/on-the-effectiveness-of-uml-sequence-diagrams-in-the-comprehension-of-functional-requirements/</link>
		<pubDate>Sun, 24 Apr 2016 17:51:37 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1093</guid>
		<description></description>
		<content><![CDATA[ Modeling is a fundamental activity within the requirements engineering process and concerns the construction of abstract descriptions of requirements that are amenable to interpretation and validation. Empirical evidence about which modeling technique helps to improve the comprehension of functional requirements is needed. This paper presents the results of a family of experiments conducted with students and professionals to investigate whether the comprehension of functional requirements is influenced by the use of dynamic models that are represented by means of UML sequence diagrams. The family contains five experiments performed in different locations and with 112 participants of different abilities and levels of experience with UML. The results show that sequence diagrams improve the comprehension of functional requirements in the case of high ability and more experienced participants.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1093</post_id>
		<post_date><![CDATA[2016-04-24 19:51:37]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 17:51:37]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[on-the-effectiveness-of-uml-sequence-diagrams-in-the-comprehension-of-functional-requirements]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="comprehension"><![CDATA[Comprehension]]></category>
		<category domain="post_tag" nicename="family-of-experiments"><![CDATA[Family of experiments]]></category>
		<category domain="post_tag" nicename="uml-sequence-diagrams"><![CDATA[UML sequence diagrams]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1094]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[ Modeling is a fundamental activity within the requirements engineering process and concerns the construction of abstract descriptions of requirements that are amenable to interpretation and validation. Empirical evidence about which modeling technique helps to improve the comprehension of functional requirements is needed. This paper presents the results of a family of experiments conducted with students and professionals to investigate whether the comprehension of functional requirements is influenced by the use of dynamic models that are represented by means of UML sequence diagrams. The family contains five experiments performed in different locations and with 112 participants of different abilities and levels of experience with UML. The results show that sequence diagrams improve the comprehension of functional requirements in the case of high ability and more experienced participants.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[UML sequence diagrams, comprehension, family of experiments]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Silvia Abrahão]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Information Systems and Computation Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[sabrahao@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carmine Gravino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dipartimento di Matematica e Informatica, University of Salerno, Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gravino@unisa.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Emilio Insfrán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Information Systems and Computation Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[einsfran@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Giuseppe Scanniello]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dipartimento di Matematica, Informatica e Economia, University of Basilicata, Italy ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[giuseppe.scanniello@unibas.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Genoveffa Tortora]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Dipartimento di Matematica e Informatica, University of Salerno, Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[tortora@unisa.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/018]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>On the Relationship of Concern Metrics and Requirements Maintainability</title>
		<link>https://biblioteca.sistedes.es/articulo/on-the-relationship-of-concern-metrics-and-requirements-maintainability/</link>
		<pubDate>Sun, 24 Apr 2016 22:55:25 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1097</guid>
		<description></description>
		<content><![CDATA[Maintainability is one of the most essential quality attributes as maintenance tasks consume a high proportion of the total effort spent in the software life cycle. A significant impediment to maintenance is the level of interconnection between modules. Crosscutting is a special kind of relationship that generates undesired non-syntactical interactions between modules, e.g. it has been observed that changeability and stability attributes are often negatively affected by the presence of crosscutting. However, most of the systematic studies about crosscutting concentrate on the analysis of source code, when architectural decisions have already been made and there is little or no knowledge about how characteristics of crosscutting concerns, observable in early artifacts, are correlated with maintainability. The goal of this paper is to understand how the presence of crosscutting concerns affects changeability and stability of software artifacts at requirements level. As the problem of crosscutting concerns is usually described in terms of scattering and tangling, the following main research question (MRQ) drove our research method:
MRQ: How do scattering, tangling and crosscutting affect the requirements maintainability?
To address this main research question, the following sub-questions (RQ1 ­ RQ3) were considered and analyzed taking as case studies three Software Product Lines:
* Work supported in part by the European Commission grant IST-2-004349: European Network of Excellence on AOSD (AOSD-Europe), by Ministerio de Ciencia e Investigación from Spain under contract TIN2011-27340 and Gobierno de Extremadura (GR-10129) and European Regional Development Fund (ERDF).
adfa, p. 1, 2011. © Springer-Verlag Berlin Heidelberg 2011]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1097</post_id>
		<post_date><![CDATA[2016-04-25 00:55:25]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 22:55:25]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[on-the-relationship-of-concern-metrics-and-requirements-maintainability]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1098]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Maintainability is one of the most essential quality attributes as maintenance tasks consume a high proportion of the total effort spent in the software life cycle. A significant impediment to maintenance is the level of interconnection between modules. Crosscutting is a special kind of relationship that generates undesired non-syntactical interactions between modules, e.g. it has been observed that changeability and stability attributes are often negatively affected by the presence of crosscutting. However, most of the systematic studies about crosscutting concentrate on the analysis of source code, when architectural decisions have already been made and there is little or no knowledge about how characteristics of crosscutting concerns, observable in early artifacts, are correlated with maintainability. The goal of this paper is to understand how the presence of crosscutting concerns affects changeability and stability of software artifacts at requirements level. As the problem of crosscutting concerns is usually described in terms of scattering and tangling, the following main research question (MRQ) drove our research method:
MRQ: How do scattering, tangling and crosscutting affect the requirements maintainability?
To address this main research question, the following sub-questions (RQ1 ­ RQ3) were considered and analyzed taking as case studies three Software Product Lines:
* Work supported in part by the European Commission grant IST-2-004349: European Network of Excellence on AOSD (AOSD-Europe), by Ministerio de Ciencia e Investigación from Spain under contract TIN2011-27340 and Gobierno de Extremadura (GR-10129) and European Regional Development Fund (ERDF).
adfa, p. 1, 2011. © Springer-Verlag Berlin Heidelberg 2011]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José M. Conejero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group University of Extremadura. Avda. de la Universidad, s/n, 10071, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[chemacm@unex.es)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group University of Extremadura. Avda. de la Universidad, s/n, 10071, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanher@unex.es)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Elena Jurado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group University of Extremadura. Avda. de la Universidad, s/n, 10071, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[elenajur@unex.es)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Eduardo Figueiredo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Computing Department, Federal University of Minas Gerais, Brazil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[figueiredo@dcc.ufmg.br]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Alessandro Garcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Informatics Department, Pontifical Catholic University of Rio de Janeiro, Brazil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[afgarcia@inf.puc-rio.br]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/017]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación de Prueba Rendimiento a Partir de Pruebas Funcionales para Sistemas Web</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-de-prueba-rendimiento-a-partir-de-pruebas-funcionales-para-sistemas-web/</link>
		<pubDate>Sun, 24 Apr 2016 22:58:39 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1100</guid>
		<description></description>
		<content><![CDATA[Las pruebas de rendimiento consisten en simular carga en el sistema bajo pruebas para analizar el desempeño de la infraestructura durante la ejecución de la prueba, pudiendo encontrar cuellos de botella y oportunidades de mejora. Para la simulación se utilizan herramientas específicas, en las que se debe automatizar las acciones que generarán esa carga, esto es: las interacciones entre el usuario y el servidor. Para poder simular muchos usuarios con poca infraestructura de pruebas, se automatizan las interacciones a nivel de protocolo (en scripts), lo cual hace que la automatización sea más compleja (en cuanto al trabajo necesario para su preparación) que la automatización de pruebas funcionales, que se realiza a nivel de interfaz gráfica. Generalmente la tarea de automatización consume entre el 30% y el 50% del esfuerzo de un proyecto de pruebas de rendimiento. En este artículo presentamos la herramienta desarrollada para seguir un nuevo enfoque para generar scripts para pruebas de rendimiento a partir de scripts de pruebas funcionales. La herramienta implementada ya ha sido puesta en funcionamiento en proyectos reales, de los cuales se muestran los principales resultados que reflejan mayor flexibilidad y menor costo de automatización.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1100</post_id>
		<post_date><![CDATA[2016-04-25 00:58:39]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 22:58:39]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-de-prueba-rendimiento-a-partir-de-pruebas-funcionales-para-sistemas-web]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="pruebas-de-rendimiento"><![CDATA[Pruebas de Rendimiento]]></category>
		<category domain="post_tag" nicename="pruebas-de-sistemas-de-informacion"><![CDATA[Pruebas de Sistemas de Información]]></category>
		<category domain="post_tag" nicename="pruebas-de-software"><![CDATA[Pruebas de Software]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1101]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las pruebas de rendimiento consisten en simular carga en el sistema bajo pruebas para analizar el desempeño de la infraestructura durante la ejecución de la prueba, pudiendo encontrar cuellos de botella y oportunidades de mejora. Para la simulación se utilizan herramientas específicas, en las que se debe automatizar las acciones que generarán esa carga, esto es: las interacciones entre el usuario y el servidor. Para poder simular muchos usuarios con poca infraestructura de pruebas, se automatizan las interacciones a nivel de protocolo (en scripts), lo cual hace que la automatización sea más compleja (en cuanto al trabajo necesario para su preparación) que la automatización de pruebas funcionales, que se realiza a nivel de interfaz gráfica. Generalmente la tarea de automatización consume entre el 30% y el 50% del esfuerzo de un proyecto de pruebas de rendimiento. En este artículo presentamos la herramienta desarrollada para seguir un nuevo enfoque para generar scripts para pruebas de rendimiento a partir de scripts de pruebas funcionales. La herramienta implementada ya ha sido puesta en funcionamiento en proyectos reales, de los cuales se muestran los principales resultados que reflejan mayor flexibilidad y menor costo de automatización.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Pruebas de Software, Pruebas de Sistemas de Información, Pruebas de Rendimiento]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Federico Toledo Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Abstracta, Uruguay]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ftoledo@abstracta.com.uy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Matías Reina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Abstracta, Uruguay]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mreina@abstracta.com.uy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Fabián Baptista]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Abstracta, Uruguay]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fbaptista@abstracta.com.uy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Macario Polo Usaola]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[macario.polo@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Beatriz Pérez Lamancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de la República, Uruguay]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[bperez@fing.edu.uy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/016]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Gestión de Calidad de Datos en la Combinación de Actividades dentro del Marco de los Procesos de Negocio</title>
		<link>https://biblioteca.sistedes.es/articulo/gestion-de-calidad-de-datos-en-la-combinacion-de-actividades-dentro-del-marco-de-los-procesos-de-negocio/</link>
		<pubDate>Sun, 24 Apr 2016 23:01:39 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1103</guid>
		<description></description>
		<content><![CDATA[Los procesos de negocio ofrecen la infraestructura necesaria para la combinación de distintas actividades en un único proceso. Dicha combinación puede implicar el intercambio de datos entre las mismas, de forma que la calidad de datos toma una especial relevancia. Si los datos que utilizan las actividades involucradas no tienen el nivel de calidad adecuado, el resultado generado por el proceso podría no ser ni fiable ni usable por el usuario final. Una forma de garantizar la confiabilidad en los datos es mediante una certificación de su nivel de calidad. La certificación de los niveles de calidad de los datos que deben manejar las actividades que se combinan, puede ser descrita mediante el uso de la familia de estándares ISO/IEC 8000-100. El uso de esta certificación supone una nueva restricción que ha de tenerse en cuenta a la hora de buscar el resultado global en la combinación de actividades. En este artículo se propone el diseño y la implementación de una Arquitectura de Servicios llamada I8K, que se encarga del proceso de evaluación y certificación de los datos, y de como ésta se ha aplicado a un ejemplo motivador sobre la combinacíon de actividades para la organización de un viaje, que implica la búsqueda de billete de avión, estancia en hotel, y opcionalmente el alquiler de coches.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1103</post_id>
		<post_date><![CDATA[2016-04-25 01:01:39]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 23:01:39]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[gestion-de-calidad-de-datos-en-la-combinacion-de-actividades-dentro-del-marco-de-los-procesos-de-negocio]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="arquitectura-de-servicios"><![CDATA[Arquitectura de Servicios]]></category>
		<category domain="post_tag" nicename="calidad-de-datos"><![CDATA[Calidad de Datos]]></category>
		<category domain="post_tag" nicename="combinacion-de-actividades"><![CDATA[Combinación de Actividades]]></category>
		<category domain="post_tag" nicename="iso-8000-100"><![CDATA[ISO 8000-100]]></category>
		<category domain="post_tag" nicename="procesos-de-negocio"><![CDATA[Procesos de Negocio]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1104]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los procesos de negocio ofrecen la infraestructura necesaria para la combinación de distintas actividades en un único proceso. Dicha combinación puede implicar el intercambio de datos entre las mismas, de forma que la calidad de datos toma una especial relevancia. Si los datos que utilizan las actividades involucradas no tienen el nivel de calidad adecuado, el resultado generado por el proceso podría no ser ni fiable ni usable por el usuario final. Una forma de garantizar la confiabilidad en los datos es mediante una certificación de su nivel de calidad. La certificación de los niveles de calidad de los datos que deben manejar las actividades que se combinan, puede ser descrita mediante el uso de la familia de estándares ISO/IEC 8000-100. El uso de esta certificación supone una nueva restricción que ha de tenerse en cuenta a la hora de buscar el resultado global en la combinación de actividades. En este artículo se propone el diseño y la implementación de una Arquitectura de Servicios llamada I8K, que se encarga del proceso de evaluación y certificación de los datos, y de como ésta se ha aplicado a un ejemplo motivador sobre la combinacíon de actividades para la organización de un viaje, que implica la búsqueda de billete de avión, estancia en hotel, y opcionalmente el alquiler de coches.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Calidad de Datos, ISO 8000-100, Arquitectura de Servicios, Procesos de Negocio, Combinación de Actividades]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Isabel Bermejo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Informacíon, Universidad de Castilla La-Mancha, Paseo de la Universidad 4, 13071, Ciudad Real (España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Isabel.Bermejo@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Luisa Parody]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla Avda. de la Reina Mercedes s/n, 41012, Sevilla (España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[lparody@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ismael Caballero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Informacíon, Universidad de Castilla La-Mancha, Paseo de la Universidad 4, 13071, Ciudad Real (España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Ismael.Caballero@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[María Teresa Gómez-López]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla Avda. de la Reina Mercedes s/n, 41012, Sevilla (España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[maytegomez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Rafael M. Gasca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla Avda. de la Reina Mercedes s/n, 41012, Sevilla (España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[gasca@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/015]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Wiki Scafolding: Aligning wikis with the corporate strategy</title>
		<link>https://biblioteca.sistedes.es/articulo/wiki-scaolding-aligning-wikis-with-the-corporate-strategy/</link>
		<pubDate>Sun, 24 Apr 2016 23:06:30 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1108</guid>
		<description></description>
		<content><![CDATA[1 An outline about the rationales and contribution of this work  Companies are increasingly realizing the benets of wikis [2]. As any other In-  formation System, the interplay of technology, work practice, and organization  is paramount to achieve successful wiki deployments. Documentation, organi-  grams, project milestones are all there by the time the wiki is created. This  Wikipediacontrasts with open wikis (e.g.,  ) where the community did not exist  prior to the wiki. As a result, corporate wikis (i.e., wikis host by an existing  organization) might be tuned at the onset to the already existing information  ecosystem. This is the assumption behind Wiki Scaolding. Next paragraphs  Whatintroduce the what, the why and the how of this term. .  Wiki Scaolding stands for a wiki installation (a.k.a. a wiki project)  that is available from the wiki's onset, before any contribution is made. Such  installation mirrors the practices of the hosting organization. Some examples  follow: (1) company schedulings might impact the pace at which wiki articles are  provided (e.g., deadlines, project milestones); (2) products, services, customers  or established terminology within an organization might become categories to  classify wiki articles; (3) employees eligible to contribute, and their access control  permissions, might be based on the company's organigram. A Wiki Scaolding  Whycaptures this setting as a wiki installation. . The fact that wikis facilitate knowledge creation does not imply that  such knowledge comes out of the blue. Both, the paralysis of facing an empty  article and the lack of a holistic view of the wiki content, might prevent grassroot  initiatives from  getting o  the ground. At this respect, Wiki Scaolding  brings three main benets:  1. Wikis are frequently a bottom-up phenomenon whereby the wiki is introduced by an individual employee or a small group within the organization without the support of management. This approach may be useful to uncover hidden knowledge or hidden ways-of-working in a dynamic and unplanned way. However, it might fail in having a strategic intent. A lack of strategy might result in no clear guidelines about what, how and who should contribute. If so, Wiki Scaolding forces to think about these concerns right from the beginning.  Wiki Scaolding promotes user engagement. In a corporate setting, a wiki  article might require some permissions, be subject to a deadline, belong to  some wiki categories, or follow a given template. All these aspects might  not be directly related with the article's content as such, yet they frame the  contribution. Setting this frame is cumbersome and delays users in putting  their wheels in motion (e.g., start to edit the article). Wiki Scaolding  permits this frame to be available by the time contributors start their articles.  3. Wiki Scaolding as a wiki map. The  rules of practice that govern a site  (i.e., roles, access rights, templates, etc) should be easily accessible to new-  comers. So far, this information is scattered around the wiki, and frequently  READMEhidden in administrative pages. At best, a  page can provide some  textual description of these practices. Wiki Scaolding can play the role of  an initial  practice sitemap . Newcomers can consult the scaolding to have  an eye-bird view of the rules that govern the wiki's operation.  How. We introduce the notion of Wiki Scaolding, and advocate for the use of Wiki Scaolding Lan-DSLs as the engineer means. Specically, we introduce the guage (WSL) (pronounced whistle). WSL is built on top of FreeMind [1], a pop-  ular, open source tool to create mind maps. You create your scaolding by draw-  ing mind maps. Next, you can export your mind map as a Wiki Scaolding: a  new wiki is created along the lines of the directives of the scaolding (see a video  of WSL at work at http://vimeo.com/31548363). The source code, examples  and installation instructions can be found at http: // www. onekin. org/ wsl .  FreeMindAlternatively, WSL source code is also available in the ocial  repos-  itory http://bit.ly/xsA040. The extension of this work to handle wiki refac-  toring is also available at [3].  Acknowledgments This work is co-supported by the Spanish Ministry of Ed- (Scrip-ucation, and the European Social Fund under contract TIN2011-23839 tongue). Puente has a doctoral grant from the Spanish Ministry of Science & Education.
References]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1108</post_id>
		<post_date><![CDATA[2016-04-25 01:06:30]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 23:06:30]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[wiki-scaolding-aligning-wikis-with-the-corporate-strategy]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1109]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[1 An outline about the rationales and contribution of this work  Companies are increasingly realizing the benets of wikis [2]. As any other In-  formation System, the interplay of technology, work practice, and organization  is paramount to achieve successful wiki deployments. Documentation, organi-  grams, project milestones are all there by the time the wiki is created. This  Wikipediacontrasts with open wikis (e.g.,  ) where the community did not exist  prior to the wiki. As a result, corporate wikis (i.e., wikis host by an existing  organization) might be tuned at the onset to the already existing information  ecosystem. This is the assumption behind Wiki Scaolding. Next paragraphs  Whatintroduce the what, the why and the how of this term. .  Wiki Scaolding stands for a wiki installation (a.k.a. a wiki project)  that is available from the wiki's onset, before any contribution is made. Such  installation mirrors the practices of the hosting organization. Some examples  follow: (1) company schedulings might impact the pace at which wiki articles are  provided (e.g., deadlines, project milestones); (2) products, services, customers  or established terminology within an organization might become categories to  classify wiki articles; (3) employees eligible to contribute, and their access control  permissions, might be based on the company's organigram. A Wiki Scaolding  Whycaptures this setting as a wiki installation. . The fact that wikis facilitate knowledge creation does not imply that  such knowledge comes out of the blue. Both, the paralysis of facing an empty  article and the lack of a holistic view of the wiki content, might prevent grassroot  initiatives from  getting o  the ground. At this respect, Wiki Scaolding  brings three main benets:  1. Wikis are frequently a bottom-up phenomenon whereby the wiki is introduced by an individual employee or a small group within the organization without the support of management. This approach may be useful to uncover hidden knowledge or hidden ways-of-working in a dynamic and unplanned way. However, it might fail in having a strategic intent. A lack of strategy might result in no clear guidelines about what, how and who should contribute. If so, Wiki Scaolding forces to think about these concerns right from the beginning. Wiki Scaolding promotes user engagement. In a corporate setting, a wiki  article might require some permissions, be subject to a deadline, belong to  some wiki categories, or follow a given template. All these aspects might  not be directly related with the article's content as such, yet they frame the  contribution. Setting this frame is cumbersome and delays users in putting  their wheels in motion (e.g., start to edit the article). Wiki Scaolding  permits this frame to be available by the time contributors start their articles.  3. Wiki Scaolding as a wiki map. The  rules of practice that govern a site  (i.e., roles, access rights, templates, etc) should be easily accessible to new-  comers. So far, this information is scattered around the wiki, and frequently  READMEhidden in administrative pages. At best, a  page can provide some  textual description of these practices. Wiki Scaolding can play the role of  an initial  practice sitemap . Newcomers can consult the scaolding to have  an eye-bird view of the rules that govern the wiki's operation.  How. We introduce the notion of Wiki Scaolding, and advocate for the use of Wiki Scaolding Lan-DSLs as the engineer means. Specically, we introduce the guage (WSL) (pronounced whistle). WSL is built on top of FreeMind [1], a pop-  ular, open source tool to create mind maps. You create your scaolding by draw-  ing mind maps. Next, you can export your mind map as a Wiki Scaolding: a  new wiki is created along the lines of the directives of the scaolding (see a video  of WSL at work at http://vimeo.com/31548363). The source code, examples  and installation instructions can be found at http: // www. onekin. org/ wsl .  FreeMindAlternatively, WSL source code is also available in the ocial  repos-  itory http://bit.ly/xsA040. The extension of this work to handle wiki refac-  toring is also available at [3].  Acknowledgments This work is co-supported by the Spanish Ministry of Ed- (Scrip-ucation, and the European Social Fund under contract TIN2011-23839 tongue). Puente has a doctoral grant from the Spanish Ministry of Science & Education.
References]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Oscar Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ONEKIN Research Group, University of the Basque Country (UPV/EHU), San Sebastián, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[oscar.diaz@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Gorka Puente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ONEKIN Research Group, University of the Basque Country (UPV/EHU), San Sebastián, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gorka.puente@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/040]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Retos Actuales en el Desarrollo de Lenguajes Específicos del Dominio</title>
		<link>https://biblioteca.sistedes.es/articulo/retos-actuales-en-el-desarrollo-de-lenguajes-especificos-del-dominio/</link>
		<pubDate>Sun, 24 Apr 2016 23:08:20 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1112</guid>
		<description></description>
		<content><![CDATA[Los Lenguajes Específicos del Dominio (Domain-Specific Languages, DSLs) son lenguajes especialmente concebidos y diseñados para trabajar con los conceptos de un dominio particular. La potencia ofrecida por los DSL para definir soluciones en un dominio fomenta la productividad y mantenibilidad, entre otros beneficios. En los últimos años, los avances de las herramientas de desarrollo de DSLs han permitido que la creación de nuevos lenguajes sea una alternativa real en determinados dominios dentro del desarrollo de software industrial. Sin embargo, creemos que todavía existen limitaciones que dificultan una adopción más generalizada por parte de la industria. En este trabajo presentamos nuestra experiencia en el desarrollo de varios DSLs en un contexto real industrial, como son los sistemas embebidos, donde ponemos en relieve las dificultades encontradas. A partir de estas limitaciones identificamos los principales retos que creemos podrían mejorar la forma de crear DSLs, favoreciendo su adopción industrial.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1112</post_id>
		<post_date><![CDATA[2016-04-25 01:08:20]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 23:08:20]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[retos-actuales-en-el-desarrollo-de-lenguajes-especificos-del-dominio]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1113]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los Lenguajes Específicos del Dominio (Domain-Specific Languages, DSLs) son lenguajes especialmente concebidos y diseñados para trabajar con los conceptos de un dominio particular. La potencia ofrecida por los DSL para definir soluciones en un dominio fomenta la productividad y mantenibilidad, entre otros beneficios. En los últimos años, los avances de las herramientas de desarrollo de DSLs han permitido que la creación de nuevos lenguajes sea una alternativa real en determinados dominios dentro del desarrollo de software industrial. Sin embargo, creemos que todavía existen limitaciones que dificultan una adopción más generalizada por parte de la industria. En este trabajo presentamos nuestra experiencia en el desarrollo de varios DSLs en un contexto real industrial, como son los sistemas embebidos, donde ponemos en relieve las dificultades encontradas. A partir de estas limitaciones identificamos los principales retos que creemos podrían mejorar la forma de crear DSLs, favoreciendo su adopción industrial.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Luis Cánovas Izquierdo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[AtlanMod, é cole des Mines de Nantes ­ INRIA ­ LINA, Nantes, Francia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[javier.canovas@inria.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Salvador Trujillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[IK4-IKERLAN, Mondragón, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[strujillo@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/039]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Concurrent Model Transformations with Linda</title>
		<link>https://biblioteca.sistedes.es/articulo/concurrent-model-transformations-with-linda/</link>
		<pubDate>Sun, 24 Apr 2016 23:11:24 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1115</guid>
		<description></description>
		<content><![CDATA[Nowadays, model transformations languages and engines use a sequential execution model. This is, only one execution thread deals with the whole transformation. However, model transformations dealing with very large models, such as those used in biology or aerospace applications, require concurrent solutions in order to speed up their performance. In this ongoing work we explore the use of Linda for implementing a set of basic mechanisms to enable concurrent model transformations, and present our initial results.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1115</post_id>
		<post_date><![CDATA[2016-04-25 01:11:24]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 23:11:24]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[concurrent-model-transformations-with-linda]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="concurrency"><![CDATA[Concurrency]]></category>
		<category domain="post_tag" nicename="linda"><![CDATA[Linda]]></category>
		<category domain="post_tag" nicename="model-transformation"><![CDATA[Model Transformation]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1116]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Nowadays, model transformations languages and engines use a sequential execution model. This is, only one execution thread deals with the whole transformation. However, model transformations dealing with very large models, such as those used in biology or aerospace applications, require concurrent solutions in order to speed up their performance. In this ongoing work we explore the use of Linda for implementing a set of basic mechanisms to enable concurrent model transformations, and present our initial results.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Model transformation, concurrency, Linda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Loli Burgueño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[GISUM/Atenea Research Group. Universidad de Málaga (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[loli@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Troya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[GISUM/Atenea Research Group. Universidad de Málaga (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[javiertc@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Vallecillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[GISUM/Atenea Research Group. Universidad de Málaga (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[av@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/037]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/038]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>AMAD-ATL: A tool for dynamically composing new model transformations at runtime</title>
		<link>https://biblioteca.sistedes.es/articulo/amad-atl-a-tool-for-dynamically-composing-new-model-transformations-at-runtime/</link>
		<pubDate>Sun, 24 Apr 2016 23:14:13 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1118</guid>
		<description></description>
		<content><![CDATA[ATL is one of the most widely used model-to-model transformation languages. Often, software designers and developers using MDE techniques have difficulties executing ATL transformations outside the Eclipse platform. An advantage of implementing these transformations in a standalone way is that they can be used for handling models at runtime. This paper presents a web tool which uses ATL and EMF libraries to provide model transformation and model validation services. These functionalities are used to implement an adaptation process built up from a set of M2M transformations aimed to dynamically generate a new M2M transformation (which does not exist a priori) from a rule repository model. This new transformation is responsible for adapting component-based software systems. The web tool also offers a GUI to test and verify the adaptation process.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1118</post_id>
		<post_date><![CDATA[2016-04-25 01:14:13]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 23:14:13]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[amad-atl-a-tool-for-dynamically-composing-new-model-transformations-at-runtime]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="adaptation"><![CDATA[adaptation]]></category>
		<category domain="post_tag" nicename="atl"><![CDATA[ATL]]></category>
		<category domain="post_tag" nicename="hot"><![CDATA[HOT]]></category>
		<category domain="post_tag" nicename="m2m"><![CDATA[M2M]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="standalone"><![CDATA[standalone]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1119]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[ATL is one of the most widely used model-to-model transformation languages. Often, software designers and developers using MDE techniques have difficulties executing ATL transformations outside the Eclipse platform. An advantage of implementing these transformations in a standalone way is that they can be used for handling models at runtime. This paper presents a web tool which uses ATL and EMF libraries to provide model transformation and model validation services. These functionalities are used to implement an adaptation process built up from a set of M2M transformations aimed to dynamically generate a new M2M transformation (which does not exist a priori) from a rule repository model. This new transformation is responsible for adapting component-based software systems. The web tool also offers a GUI to test and verify the adaptation process.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[MDE, adaptation, M2M, ATL, HOT, standalone]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Criado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, University of Almería, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[javi.criado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Diego Rodríguez-Gracia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, University of Almería, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[diegorg@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Luis Iribarne]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, University of Almería, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[luis.iribarne@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Nicolás Padilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, University of Almería, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[npadilla@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/036]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una valoracíon de la Modernizacíon de Software Dirigida por Modelos</title>
		<link>https://biblioteca.sistedes.es/articulo/una-valoracion-de-la-modernizacion-de-software-dirigida-por-modelos/</link>
		<pubDate>Sun, 24 Apr 2016 23:16:57 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1121</guid>
		<description></description>
		<content><![CDATA[Las técnicas de la Ingeniería de Software Dirigida por Modelos son aplicables a la modernización de software. Los modelos son muy apropiados como representaciones abstractas de los sistemas a modernizar y las transformaciones de modelos automatizan las tareas de los procesos de modernización. A lo largo de la pasada década, estas técnicas se han aplicado en diversos escenarios de modernización, especialmente en migración de aplicaciones. Nuestro grupo de investigación ha participado en dos proyectos de migración con empresas, y como resultado de esta experiencia, en este trabajo presentamos una valoración de la modernización basada en modelos, destacando una serie de ventajas e inconvenientes.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1121</post_id>
		<post_date><![CDATA[2016-04-25 01:16:57]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 23:16:57]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-valoracion-de-la-modernizacion-de-software-dirigida-por-modelos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1122]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las técnicas de la Ingeniería de Software Dirigida por Modelos son aplicables a la modernización de software. Los modelos son muy apropiados como representaciones abstractas de los sistemas a modernizar y las transformaciones de modelos automatizan las tareas de los procesos de modernización. A lo largo de la pasada década, estas técnicas se han aplicado en diversos escenarios de modernización, especialmente en migración de aplicaciones. Nuestro grupo de investigación ha participado en dos proyectos de migración con empresas, y como resultado de esta experiencia, en este trabajo presentamos una valoración de la modernización basada en modelos, destacando una serie de ventajas e inconvenientes.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Oscar Sánchez Ramón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática y Sistemas Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[osanchez@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francisco Javier Bermúdez Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática y Sistemas Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fjavier@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesús García Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática y Sistemas Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jmolina@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/035]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Analizando la eficacia cognitiva de WebML</title>
		<link>https://biblioteca.sistedes.es/articulo/analizando-la-eficacia-cognitiva-de-webml/</link>
		<pubDate>Sun, 24 Apr 2016 23:20:42 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1124</guid>
		<description></description>
		<content><![CDATA[WebML es un lenguaje específico de dominio para el desarrollo de aplicaciones Web que proporciona construcciones para modelar el contenido, el comportamiento y la navegación de la aplicación a generar. Como en el caso de cualquier otro lenguaje visual, su notación, que asocia una representación gráfica a los conceptos del lenguaje, es un elemento clave de WebML. En el momento de su especificación, los símbolos gráficos que utiliza WebML fueron definidos únicamente con la idea de proporcionar artefactos de modelado simples y expresivos, pero sin adoptar un enfoque científico y riguroso. Con el fin de ilustrar esta limitación e identificar algunos puntos de mejora, este trabajo analiza la notación visual de WebML bajo el marco que definen los principios recogidos en una sólida y conocida teoría científica sobre la eficacia cognitiva de las notaciones visuales. Como resultado se ha identificado un conjunto de posibles mejoras que requerirán de una validación empírica.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1124</post_id>
		<post_date><![CDATA[2016-04-25 01:20:42]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 23:20:42]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analizando-la-eficacia-cognitiva-de-webml]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="dsl"><![CDATA[DSL]]></category>
		<category domain="post_tag" nicename="eficacia-cognitiva"><![CDATA[Eficacia Cognitiva]]></category>
		<category domain="post_tag" nicename="notacion-visual"><![CDATA[Notacíon Visual]]></category>
		<category domain="post_tag" nicename="webml"><![CDATA[WebML]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1125]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[WebML es un lenguaje específico de dominio para el desarrollo de aplicaciones Web que proporciona construcciones para modelar el contenido, el comportamiento y la navegación de la aplicación a generar. Como en el caso de cualquier otro lenguaje visual, su notación, que asocia una representación gráfica a los conceptos del lenguaje, es un elemento clave de WebML. En el momento de su especificación, los símbolos gráficos que utiliza WebML fueron definidos únicamente con la idea de proporcionar artefactos de modelado simples y expresivos, pero sin adoptar un enfoque científico y riguroso. Con el fin de ilustrar esta limitación e identificar algunos puntos de mejora, este trabajo analiza la notación visual de WebML bajo el marco que definen los principios recogidos en una sólida y conocida teoría científica sobre la eficacia cognitiva de las notaciones visuales. Como resultado se ha identificado un conjunto de posibles mejoras que requerirán de una validación empírica.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[DSL, WebML, Notación Visual, Eficacia Cognitiva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos II, Universidad Rey Juan Carlos, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[david.granada@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan M. Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos II, Universidad Rey Juan Carlos, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Marco Brambilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dipartimento di Elettronica e Informazione, Politecnico di Milano, Italia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mbrambil@elet.polimi.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Verónica Bollati]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos II, Universidad Rey Juan Carlos, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[veronica.bollati@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos II, Universidad Rey Juan Carlos, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/034]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>On the Modular Specification of NFPs: A Case Study</title>
		<link>https://biblioteca.sistedes.es/articulo/on-the-modular-specification-of-nfps-a-case-study/</link>
		<pubDate>Sun, 24 Apr 2016 23:24:31 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1127</guid>
		<description></description>
		<content><![CDATA[The modular specification of non-functional properties of systems is a current challenge of Software Engineering, for which no clear solution exists. However, in the case of Domain-Specific Languages some successful proposals are starting to emerge, combining model-driven techniques with aspect-weaving mechanisms. In this paper we show one of these approaches in practice, and present the implementation we have developed to fully support it. We apply our approach for the specification and monitoring of non-functional properties using observers to a case study, illustrating how generic observers defining nonfunctional properties can be defined in an independent manner. Then, correspondences between these observers and the domain-specific model of the system can be established, and then weaved into a unified system specification using an ATL model transformation. Such a unified specification can also be analyzed in a natural way to obtain the required non-functional properties of the system.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1127</post_id>
		<post_date><![CDATA[2016-04-25 01:24:31]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 23:24:31]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[on-the-modular-specification-of-nfps-a-case-study]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="domain-specific-languages"><![CDATA[Domain Specific Languages]]></category>
		<category domain="post_tag" nicename="model-transformations"><![CDATA[model transformations]]></category>
		<category domain="post_tag" nicename="non-functional-properties"><![CDATA[Non-functional Properties]]></category>
		<category domain="post_tag" nicename="weaving-mechanisms"><![CDATA[weaving mechanisms]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1128]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The modular specification of non-functional properties of systems is a current challenge of Software Engineering, for which no clear solution exists. However, in the case of Domain-Specific Languages some successful proposals are starting to emerge, combining model-driven techniques with aspect-weaving mechanisms. In this paper we show one of these approaches in practice, and present the implementation we have developed to fully support it. We apply our approach for the specification and monitoring of non-functional properties using observers to a case study, illustrating how generic observers defining nonfunctional properties can be defined in an independent manner. Then, correspondences between these observers and the domain-specific model of the system can be established, and then weaved into a unified system specification using an ATL model transformation. Such a unified specification can also be analyzed in a natural way to obtain the required non-functional properties of the system.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[non-functional properties, domain-specific languages, model transformations, weaving mechanisms]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Moreno-Delgado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[GISUM/Atenea Research Group. Universidad de Málaga (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[amoreno@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Troya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[GISUM/Atenea Research Group. Universidad de Málaga (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[javiertc@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco Durán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[GISUM/Atenea Research Group. Universidad de Málaga (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[duran@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Vallecillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[GISUM/Atenea Research Group. Universidad de Málaga (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[av@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/033]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Estrategia de Reutilización en un Proceso de Modernizacíon Dirigido por Modelos de Aplicaciones Web</title>
		<link>https://biblioteca.sistedes.es/articulo/estrategia-de-reutilizacion-en-un-proceso-de-modernizacion-dirigido-por-modelos-de-aplicaciones-web/</link>
		<pubDate>Sun, 24 Apr 2016 23:29:12 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1130</guid>
		<description></description>
		<content><![CDATA[as Rich Internet Applications (RIA) ofrecen una mejor calidad en la interaccíon con el usuario, además de una optimización de las conexiones con el servidor, comparadas con las aplicaciones Web heredadas (AWHs). El proyecto MIGRARIA define un proceso de modernización dirigido por modelos para la generación de clientes RIA a partir de aplicaciones Web heredadas. La primera fase del proyecto consiste en un proceso de reingeniería de las AWHs, para la representación de éstas mediante un modelo independiente de la tecnología. El objetivo de este trabajo es el estudio de estrategias de reutilizacíon de este proceso para casos en los que se utilicen diferentes convenios o tecnologías de origen. Keywords: MDE, Model Driven Modernization, model transformations, reuse mechanisms]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1130</post_id>
		<post_date><![CDATA[2016-04-25 01:29:12]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 23:29:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[estrategia-de-reutilizacion-en-un-proceso-de-modernizacion-dirigido-por-modelos-de-aplicaciones-web]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1131]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[as Rich Internet Applications (RIA) ofrecen una mejor calidad en la interaccíon con el usuario, además de una optimización de las conexiones con el servidor, comparadas con las aplicaciones Web heredadas (AWHs). El proyecto MIGRARIA define un proceso de modernización dirigido por modelos para la generación de clientes RIA a partir de aplicaciones Web heredadas. La primera fase del proyecto consiste en un proceso de reingeniería de las AWHs, para la representación de éstas mediante un modelo independiente de la tecnología. El objetivo de este trabajo es el estudio de estrategias de reutilizacíon de este proceso para casos en los que se utilicen diferentes convenios o tecnologías de origen. Keywords: MDE, Model Driven Modernization, model transformations, reuse mechanisms]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Víctor M. Pavón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura, Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[victorpavon@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando Macías]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura, Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fernandomacias@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Roberto Rodríguez-Echeverría]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura, Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[rre@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Fernando Sánchez-Figueroa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura, Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[fernando@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/032]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Añadiendo soporte para la generación de trazas en transformaciones ATL: impacto sobre la calidad</title>
		<link>https://biblioteca.sistedes.es/articulo/anadiendo-soporte-para-la-generacion-de-trazas-en-transformaciones-atl-impacto-sobre-la-calidad/</link>
		<pubDate>Sun, 24 Apr 2016 23:33:27 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1133</guid>
		<description></description>
		<content><![CDATA[Los benecios que aporta la gestión y el análisis de la información de trazabilidad, hacen que se convierta en una característica deseable en cualquier propuesta de ingeniería software. Más aún si su incorporación se hace de forma autónoma y sin incrementar el trabajo de los desarrolladores. No obstante, la incorporación de trazabilidad a un proyecto software siempre supone unos costes. En el contexto de la ingeniería dirigida por modelos, existen varias propuestas que permiten generar modelos de trazas a partir de transformaciones de modelos. Sin embargo ¾cuál es el coste de este proceso? ¾cómo afecta a la calidad de las transformaciones? En este trabajo tratamos de responder cuantitativamente a estas cuestiones para un caso concreto: el enriquecimiento de transformaciones ATL con capacidades de producción de modelos de trazas que soporta el framework iTrace.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1133</post_id>
		<post_date><![CDATA[2016-04-25 01:33:27]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 23:33:27]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[anadiendo-soporte-para-la-generacion-de-trazas-en-transformaciones-atl-impacto-sobre-la-calidad]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="ingenieria-dirigida-por-modelos"><![CDATA[Ingeniería Dirigida por Modelos]]></category>
		<category domain="post_tag" nicename="metricas-de-calidad"><![CDATA[métricas de calidad]]></category>
		<category domain="post_tag" nicename="transformaciones-de-modelos"><![CDATA[Transformaciones de Modelos]]></category>
		<category domain="post_tag" nicename="trazabilidad"><![CDATA[Trazabilidad]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1134]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los benecios que aporta la gestión y el análisis de la información de trazabilidad, hacen que se convierta en una característica deseable en cualquier propuesta de ingeniería software. Más aún si su incorporación se hace de forma autónoma y sin incrementar el trabajo de los desarrolladores. No obstante, la incorporación de trazabilidad a un proyecto software siempre supone unos costes. En el contexto de la ingeniería dirigida por modelos, existen varias propuestas que permiten generar modelos de trazas a partir de transformaciones de modelos. Sin embargo ¾cuál es el coste de este proceso? ¾cómo afecta a la calidad de las transformaciones? En este trabajo tratamos de responder cuantitativamente a estas cuestiones para un caso concreto: el enriquecimiento de transformaciones ATL con capacidades de producción de modelos de trazas que soporta el framework iTrace.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Trazabilidad, Ingeniería Dirigida por Modelos, Transformaciones de Modelos, Métricas de Calidad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Iván Santiago]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos, Avda. Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ivan.santiago@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan M. Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos, Avda. Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Valeria de Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos, Avda. Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[valeria.decastro@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos, Avda. Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/031]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Visualizaciones de Datos Adaptativas: Un Enfoque Basado en Modelos Orientado a Mejorar la Experiencia del Usuario</title>
		<link>https://biblioteca.sistedes.es/articulo/visualizaciones-de-datos-adaptativas-un-enfoque-basado-en-modelos-orientado-a-mejorar-la-experiencia-del-usuario/</link>
		<pubDate>Sun, 24 Apr 2016 23:37:14 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1136</guid>
		<description></description>
		<content><![CDATA[En la actualidad, son cada vez más las aplicaciones que utilizan técnicas de visualización de datos para presentar información a los usuarios. La complejidad de estas técnicas aumenta a medida que es necesario tener en cuenta factores como la creciente variedad de dispositivos de visualización disponibles en el mercado, la gran cantidad y diversidad de las fuentes de datos de interés y los distintos perfiles de usuario y casos de uso en los que estas técnicas encuentran aplicación. En este trabajo se muestra cómo el uso combinado de técnicas basadas en modelos y de desarrollo de software adaptativo, facilita el diseño e implementación de los sistemas de visualización, dotándoles de capacidad para adaptarse, en tiempo de ejecución, a situaciones y requisitos de usuario cambiantes. Como parte central del artículo se ha incluido un caso de estudio a través del cual se van presentando los principales elementos de la propuesta y en base al cual se hace una primera valoración de sus beneficios.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1136</post_id>
		<post_date><![CDATA[2016-04-25 01:37:14]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 23:37:14]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[visualizaciones-de-datos-adaptativas-un-enfoque-basado-en-modelos-orientado-a-mejorar-la-experiencia-del-usuario]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="sistemas-adaptativos"><![CDATA[Sistemas Adaptativos]]></category>
		<category domain="post_tag" nicename="visualizacion-de-datos"><![CDATA[Visualización de Datos]]></category>
		<category domain="post_tag" nicename="visualligence"><![CDATA[visualligence]]></category>
		<category domain="post_tag" nicename="vml"><![CDATA[VML]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1137]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En la actualidad, son cada vez más las aplicaciones que utilizan técnicas de visualización de datos para presentar información a los usuarios. La complejidad de estas técnicas aumenta a medida que es necesario tener en cuenta factores como la creciente variedad de dispositivos de visualización disponibles en el mercado, la gran cantidad y diversidad de las fuentes de datos de interés y los distintos perfiles de usuario y casos de uso en los que estas técnicas encuentran aplicación. En este trabajo se muestra cómo el uso combinado de técnicas basadas en modelos y de desarrollo de software adaptativo, facilita el diseño e implementación de los sistemas de visualización, dotándoles de capacidad para adaptarse, en tiempo de ejecución, a situaciones y requisitos de usuario cambiantes. Como parte central del artículo se ha incluido un caso de estudio a través del cual se van presentando los principales elementos de la propuesta y en base al cual se hace una primera valoración de sus beneficios.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Visualización de Datos, Sistemas Adaptativos, visualligence, VML]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rober Morales-Chaparro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group (QSEG), Universidad de Extremadura, Avda. de la Universidad S/N, 10003 Cáceres, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[robermorales@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan F. Inglés-Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Tecnologías de la Información y Comunicaciones, Universidad Politécnica de Cartagena, Edificio Antigones, 30202 Cartagena, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanfran.ingles@upct.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Fernando Sánchez-Figueroa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group (QSEG), Universidad de Extremadura, Avda. de la Universidad S/N, 10003 Cáceres, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fernando@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Cristina Vicente-Chicote]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group (QSEG), Universidad de Extremadura, Avda. de la Universidad S/N, 10003 Cáceres, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[cristinav@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/030]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un Enfoque Basado en Modelos para la Toma de Decisiones Colaborativa en la Cadena de Suministro</title>
		<link>https://biblioteca.sistedes.es/articulo/un-enfoque-basado-en-modelos-para-la-toma-de-decisiones-colaborativa-en-la-cadena-de-suministro/</link>
		<pubDate>Sun, 24 Apr 2016 23:40:44 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1139</guid>
		<description></description>
		<content><![CDATA[En el entorno empresarial actual la colaboración en la toma de decisiones se ha convertido en un elemento clave para mejorar la competividad. Hay numerosos estudios orientados a crear modelos formales de procesos en la CdS para analizarlos, simularlos y optimizarlos, si bien no han tenido un enfoque inter-organizacional. La ingeniería del software dirigida por modelos (MDE, del inglés Model Driven Engineering) se basa en la generacíon de metamodelos y en transformaciones entre los mismos. Este trabajo propone el uso de un enfoque basado en modelos para representar procesos de una CdS, con el objetivo de facilitar la toma de decisiones de forma colaborativa y aplicarlo a un entorno real. En este trabajo emergente se presenta el problema a resolver, el estado del arte, la metodología que vamos a seguir y los principales resultados que esperamos obtener con nuestra investigación.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1139</post_id>
		<post_date><![CDATA[2016-04-25 01:40:44]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 23:40:44]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-enfoque-basado-en-modelos-para-la-toma-de-decisiones-colaborativa-en-la-cadena-de-suministro]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="enfoque-basado-en-modelos"><![CDATA[Enfoque Basado en Modelos]]></category>
		<category domain="post_tag" nicename="gestion-de-la-cadena-de-suministro"><![CDATA[Gestión de la Cadena de Suministro]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<category domain="post_tag" nicename="supply-chain-management"><![CDATA[Supply Chain Management]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1140]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En el entorno empresarial actual la colaboración en la toma de decisiones se ha convertido en un elemento clave para mejorar la competividad. Hay numerosos estudios orientados a crear modelos formales de procesos en la CdS para analizarlos, simularlos y optimizarlos, si bien no han tenido un enfoque inter-organizacional. La ingeniería del software dirigida por modelos (MDE, del inglés Model Driven Engineering) se basa en la generacíon de metamodelos y en transformaciones entre los mismos. Este trabajo propone el uso de un enfoque basado en modelos para representar procesos de una CdS, con el objetivo de facilitar la toma de decisiones de forma colaborativa y aplicarlo a un entorno real. En este trabajo emergente se presenta el problema a resolver, el estado del arte, la metodología que vamos a seguir y los principales resultados que esperamos obtener con nuestra investigación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Gestión de la Cadena de Suministro, Enfoque Basado en Modelos, Supply Chain Management, Model Driven Engineering]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[M.A. Barcelona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto Tecnológico de Aragón, c/ María de Luna 7, 50018 Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mabarcelona@ita.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[M.J. Escalona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Av. Reina Mercedes S/N, 41012 Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mjescalona@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[I. Ramos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Av. Reina Mercedes S/N, 41012 Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[iramos@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/029]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>PseudoDSL: Un lenguaje generativo para el aprendizaje de pseudocódigo</title>
		<link>https://biblioteca.sistedes.es/articulo/pseudodsl-un-lenguaje-generativo-para-el-aprendizaje-de-pseudocodigo/</link>
		<pubDate>Sun, 24 Apr 2016 23:43:57 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1142</guid>
		<description></description>
		<content><![CDATA[Este trabajo describe un lenguaje específico de pseudocódigo que incluye todos los elementos necesarios para la definición y diseño de algoritmos. Además, se ha construido una herramienta para el diseño, validación y compilación de los algoritmos escritos con este lenguaje. La herramienta, desarrollada bajo el enfoque Model-Driven Development, es capaz de generar código ejecutable C++ equivalente al algoritmo de entrada.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1142</post_id>
		<post_date><![CDATA[2016-04-25 01:43:57]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 23:43:57]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[pseudodsl-un-lenguaje-generativo-para-el-aprendizaje-de-pseudocodigo]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="desarrollo-dirigido-por-modelos"><![CDATA[Desarrollo dirigido por modelos]]></category>
		<category domain="post_tag" nicename="eclipse"><![CDATA[Eclipse]]></category>
		<category domain="post_tag" nicename="mdd"><![CDATA[MDD]]></category>
		<category domain="post_tag" nicename="pseudocodigo"><![CDATA[Pseudocódigo]]></category>
		<category domain="post_tag" nicename="xtext"><![CDATA[Xtext]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1143]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este trabajo describe un lenguaje específico de pseudocódigo que incluye todos los elementos necesarios para la definición y diseño de algoritmos. Además, se ha construido una herramienta para el diseño, validación y compilación de los algoritmos escritos con este lenguaje. La herramienta, desarrollada bajo el enfoque Model-Driven Development, es capaz de generar código ejecutable C++ equivalente al algoritmo de entrada.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Pseudocódigo, Desarrollo Dirigido por Modelos, Eclipse, Xtext, MDD]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Jesús Marente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática. Universidad de Cádiz, C. Chile no1. Cádiz (España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jose.marenteflorin@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Ruiz-Piulestan]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática. Universidad de Cádiz, C. Chile no1. Cádiz (España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sergio.ruizpiulestan@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Iván Ruiz-Rube]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática. Universidad de Cádiz, C. Chile no1. Cádiz (España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ivan.ruiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Dodero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática. Universidad de Cádiz, C. Chile no1. Cádiz (España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juanma.dodero@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/028]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>From Teleo-Reactive specifications to architectural components: A model-driven approach</title>
		<link>https://biblioteca.sistedes.es/articulo/from-teleo-reactive-specifications-to-architectural-components-a-model-driven-approach/</link>
		<pubDate>Sun, 24 Apr 2016 23:46:24 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1145</guid>
		<description></description>
		<content><![CDATA[This article describes a systematic approach that allows architectural models with structural descriptions and behaviour to be derived from TeleoReactive (TR) programs. The work is integrated in C-Forge [1], a toolchain for the development of reactive systems based on the use of frameworks, design patterns and code generation through model transformations, which has been used as the target for the integration of TR-specifications. This toolchain revolves around a modelling language for component-based applications, where component behaviour is modelled by means of state-machines, which decide the code the component will execute in response to messages coming from other application components and to internal computations.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1145</post_id>
		<post_date><![CDATA[2016-04-25 01:46:24]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 23:46:24]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[from-teleo-reactive-specifications-to-architectural-components-a-model-driven-approach]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1146]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This article describes a systematic approach that allows architectural models with structural descriptions and behaviour to be derived from TeleoReactive (TR) programs. The work is integrated in C-Forge [1], a toolchain for the development of reactive systems based on the use of frameworks, design patterns and code generation through model transformations, which has been used as the target for the integration of TR-specifications. This toolchain revolves around a modelling language for component-based applications, where component behaviour is modelled by means of state-machines, which decide the code the component will execute in response to messages coming from other application components and to internal computations.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[División de Sistemas e Ingeniería Electrónica (DSIE) Universidad Politécnica de Cartagena, 30.202 Cartagena, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pedro.sanchez@upct.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Diego Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[División de Sistemas e Ingeniería Electrónica (DSIE) Universidad Politécnica de Cartagena, 30.202 Cartagena, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José Miguel Morales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[División de Sistemas e Ingeniería Electrónica (DSIE) Universidad Politécnica de Cartagena, 30.202 Cartagena, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Pedro Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[División de Sistemas e Ingeniería Electrónica (DSIE) Universidad Politécnica de Cartagena, 30.202 Cartagena, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/027]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación Automática de Vistas de Control para Herramientas de Desarrollo de Software Dirigido por Modelos en Eclipse</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-automatica-de-vistas-de-control-para-herramientas-de-desarrollo-de-software-dirigido-por-modelos-en-eclipse/</link>
		<pubDate>Sun, 24 Apr 2016 23:49:03 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1148</guid>
		<description></description>
		<content><![CDATA[Este trabajo presenta un entorno de modelado que permite generar automáticamente vistas de control para herramientas de Desarrollo de Software Dirigido por Modelos (DSDM) en Eclipse. Estas vistas muestran, a través de un diagrama de flujo, el proceso que deben seguir los usuarios para llevar a cabo una determinada tarea. El propósito de las vistas generadas es facilitar la integración de varias herramientas relacionadas con la gestión (creación, validación, transformación, etc.) de modelos, mejorando su usabilidad, sobre todo, para usuarios no expertos en los procesos de DSDM con Eclipse.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1148</post_id>
		<post_date><![CDATA[2016-04-25 01:49:03]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 23:49:03]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-automatica-de-vistas-de-control-para-herramientas-de-desarrollo-de-software-dirigido-por-modelos-en-eclipse]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1149]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este trabajo presenta un entorno de modelado que permite generar automáticamente vistas de control para herramientas de Desarrollo de Software Dirigido por Modelos (DSDM) en Eclipse. Estas vistas muestran, a través de un diagrama de flujo, el proceso que deben seguir los usuarios para llevar a cabo una determinada tarea. El propósito de las vistas generadas es facilitar la integración de varias herramientas relacionadas con la gestión (creación, validación, transformación, etc.) de modelos, mejorando su usabilidad, sobre todo, para usuarios no expertos en los procesos de DSDM con Eclipse.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Domingo J. Pérez-Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Cartagena, Edificio Antigones, 30202 Cartagena, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[domingo.jperez@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan F. Inglés-Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Cartagena, Edificio Antigones, 30202 Cartagena, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanfran.ingles@upct.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Cristina Vicente-Chicote]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group (QSEG), Universidad de Extremadura, Avda. de la Universidad S/N, 10003 Cáceres, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[cristinav@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/026]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Data Modeler: Herramienta Open Source de modelado de datos</title>
		<link>https://biblioteca.sistedes.es/articulo/data-modeler-herramienta-open-source-de-modelado-de-datos/</link>
		<pubDate>Sun, 24 Apr 2016 23:51:44 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1151</guid>
		<description></description>
		<content><![CDATA[En el presente documento se detalla por qué se decidió abordar la construcción de una herramienta de modelado de datos físicos, usando técnicas y tecnologías de diseño orientado a modelos basadas en los estándares de la plataforma Eclipse. Detallaremos qué características la hacen especialmente útil y potente tanto para la industria como para el mundo académico junto con las arquitectura y tecnologías utilizadas. Finalmente resumiremos el estado actual y el plan de evolución.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1151</post_id>
		<post_date><![CDATA[2016-04-25 01:51:44]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 23:51:44]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[data-modeler-herramienta-open-source-de-modelado-de-datos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="base-de-datos"><![CDATA[base de datos]]></category>
		<category domain="post_tag" nicename="eclipse"><![CDATA[Eclipse]]></category>
		<category domain="post_tag" nicename="editor"><![CDATA[Editor]]></category>
		<category domain="post_tag" nicename="emf"><![CDATA[EMF]]></category>
		<category domain="post_tag" nicename="gmf"><![CDATA[GMF]]></category>
		<category domain="post_tag" nicename="integracion"><![CDATA[Integración]]></category>
		<category domain="post_tag" nicename="modelado-de-datos"><![CDATA[Modelado de Datos]]></category>
		<category domain="post_tag" nicename="tooling"><![CDATA[Tooling]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1152]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En el presente documento se detalla por qué se decidió abordar la construcción de una herramienta de modelado de datos físicos, usando técnicas y tecnologías de diseño orientado a modelos basadas en los estándares de la plataforma Eclipse. Detallaremos qué características la hacen especialmente útil y potente tanto para la industria como para el mundo académico junto con las arquitectura y tecnologías utilizadas. Finalmente resumiremos el estado actual y el plan de evolución.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Modelado de Datos, Editor, Integración, Eclipse, EMF, GMF, Tooling, Base de Datos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ramón Viñas Ávalos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Área TC-Laboratorio Middleware, Departamento Banksphere Core, VegaIsban, Grupo Santander España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rvinasav@isban.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Rubén de Dios Barbero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Área TC-Laboratorio Middleware, Departamento Banksphere Core, VegaIsban, Grupo Santander España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[rdediosb@isban.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/025]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>GMF Simple Map Editor.</title>
		<link>https://biblioteca.sistedes.es/articulo/gmf-simple-map-editor/</link>
		<pubDate>Sun, 24 Apr 2016 23:55:19 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1154</guid>
		<description></description>
		<content><![CDATA[El uso de herramientas basadas en modelos para el desarrollo de software mejoran la productividad y la calidad de los productos, especialmente cuando se trata de modelos especificos de cada dominio (DSM). Cuando una organización introduce en sus procesos una aproximación basada en modelos (MDE) cada vez produce o demanda más lenguajes abstractos que trabajen con conceptos más cercanos al dominio de las aplicaciones, lenguajes especificos de domino (DSL). Sin embargo, proporcionar herramientas de modelado gráfico (con su propia sintaxis) que faciliten al usuario la edición de dichos modelos es muy costoso en tiempo y recursos. El SimpleMap Editor, que se incluirá en el GMF Tooling, proporciona un entorno visual que permite construir con facilidad editores gráficos para cualquier DSL.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1154</post_id>
		<post_date><![CDATA[2016-04-25 01:55:19]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 23:55:19]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[gmf-simple-map-editor]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="gmf"><![CDATA[GMF]]></category>
		<category domain="post_tag" nicename="lenguajes-especificos-de-dominio"><![CDATA[Lenguajes Específicos de Dominio]]></category>
		<category domain="post_tag" nicename="productividad"><![CDATA[Productividad]]></category>
		<category domain="post_tag" nicename="tooling"><![CDATA[Tooling]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1155]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El uso de herramientas basadas en modelos para el desarrollo de software mejoran la productividad y la calidad de los productos, especialmente cuando se trata de modelos especificos de cada dominio (DSM). Cuando una organización introduce en sus procesos una aproximación basada en modelos (MDE) cada vez produce o demanda más lenguajes abstractos que trabajen con conceptos más cercanos al dominio de las aplicaciones, lenguajes especificos de domino (DSL). Sin embargo, proporcionar herramientas de modelado gráfico (con su propia sintaxis) que faciliten al usuario la edición de dichos modelos es muy costoso en tiempo y recursos. El SimpleMap Editor, que se incluirá en el GMF Tooling, proporciona un entorno visual que permite construir con facilidad editores gráficos para cualquier DSL.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[GMF, Tooling, Lenguajes Específicos de Dominio, Productividad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rubén de Dios Barbero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Área TC-Laboratorio Middleware, Departamento Banksphere Core, Vega, ISBAN S.L. Grupo Santander (España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rdediosb@isban.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ramón Viñas Avalos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Área TC-Laboratorio Middleware, Departamento Banksphere Core, Vega, ISBAN S.L. Grupo Santander (España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[rvinasav@isban.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/024]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Integración de indicadores internos y externos mediante generación semi-automática de código</title>
		<link>https://biblioteca.sistedes.es/articulo/integracion-de-indicadores-internos-y-externos-mediante-generacion-semi-automatica-de-codigo/</link>
		<pubDate>Sun, 24 Apr 2016 23:58:40 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1157</guid>
		<description></description>
		<content><![CDATA[onitorizar los Indicadores Clave de Desempeño en una organización es un aspecto clave que nos permite adoptar decisiones estratégicas basadas en información cuantitativa fidedigna. En la Inteligencia de Negocio (Business Intelligence, BI) tradicional, el análisis es una tarea compleja, ya que si un indicador falla no se conocen claramente todos los objetivos de negocio que están siendo afectados. A estas dificultades ha de añadirse el uso, cada vez más habitual, de datos externos, que suelen estar hospedados por terceras partes. De esta forma el análisis se convierte en una amalgama de datos heterogéneos proporcionados por Indicadores Internos y Externos que, difícilmente se encuentran alineados con la estrategia de negocio y, por tanto, dificultan aún más el control de los procesos. En este artículo, proponemos una aproximación para permitir la integración Indicadores Externos e Internos de la empresa. Gracias a nuestra aproximación se podrá consultar datos de fuentes externas junto las internas y por tanto, se simplifica la tarea de análisis.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1157</post_id>
		<post_date><![CDATA[2016-04-25 01:58:40]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 23:58:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[integracion-de-indicadores-internos-y-externos-mediante-generacion-semi-automatica-de-codigo]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="api"><![CDATA[API]]></category>
		<category domain="post_tag" nicename="estrategia-de-negocio"><![CDATA[Estrategia de negocio]]></category>
		<category domain="post_tag" nicename="inteligencia-de-negocio"><![CDATA[Inteligencia de negocio]]></category>
		<category domain="post_tag" nicename="kpi"><![CDATA[KPI]]></category>
		<category domain="post_tag" nicename="metamodelado"><![CDATA[Metamodelado]]></category>
		<category domain="post_tag" nicename="rest"><![CDATA[REST]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1158]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[onitorizar los Indicadores Clave de Desempeño en una organización es un aspecto clave que nos permite adoptar decisiones estratégicas basadas en información cuantitativa fidedigna. En la Inteligencia de Negocio (Business Intelligence, BI) tradicional, el análisis es una tarea compleja, ya que si un indicador falla no se conocen claramente todos los objetivos de negocio que están siendo afectados. A estas dificultades ha de añadirse el uso, cada vez más habitual, de datos externos, que suelen estar hospedados por terceras partes. De esta forma el análisis se convierte en una amalgama de datos heterogéneos proporcionados por Indicadores Internos y Externos que, difícilmente se encuentran alineados con la estrategia de negocio y, por tanto, dificultan aún más el control de los procesos. En este artículo, proponemos una aproximación para permitir la integración Indicadores Externos e Internos de la empresa. Gracias a nuestra aproximación se podrá consultar datos de fuentes externas junto las internas y por tanto, se simplifica la tarea de análisis.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[KPI, Estrategia de negocio, REST, API, Metamodelado, Inteligencia de negocio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Elisa de Gregorio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Lucentia Research Group Department of Software and Computing Systems University of Alicante ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[edg12@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alejandro Maté]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Lucentia Research Group Department of Software and Computing Systems University of Alicante ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[amate@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Trujillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Lucentia Research Group Department of Software and Computing Systems University of Alicante ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jtrujillo@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/023]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Analyzing the Understandability of Requirements Engineering Languages for CSCW Systems: A Family of Experiments</title>
		<link>https://biblioteca.sistedes.es/articulo/analyzing-the-understandability-of-requirements-engineering-languages-for-cscw-systems-a-family-of-experiments/</link>
		<pubDate>Mon, 25 Apr 2016 00:05:28 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1162</guid>
		<description></description>
		<content><![CDATA[Context of the proposal: Collaborative Systems
Nowadays, even classic applications like text processors are collaborative. For instance, Google Docs [2] enables several users to edit a text document simultaneously . These collaborative text processors are a good example of CSCW (Computer Supported Cooperative Work) systems [3], which are systems whose users can perform collaboration, communication and coordination tasks (3C). Collaborative systems, in a similar way to classical single-user systems, have to be specified by means of a set of requirements, whose accuracy and suitability are key to achieve the quality of the developed system. The main difference between the requirements of single-user systems and CSCW systems is the highly non-functional nature of the latter, because of the users' need of being aware of the presence of other users with whom to perform the above mentioned 3C tasks, that is, the Workspace Awareness (WA). In order to deal with the specification of this special type of systems, we conducted several empirical evaluations in order to check which is the most adequate Requirements Engineering technique to model both awareness and quality requirements of CSCW systems. We concluded that the i* Framework [1], was the most promising one. However, we identified several issues when modeling collaborative systems with this language that led us to extend the original i* language by creating CSRML (Collaborative Systems Requirements Modeling Language) [4] and evaluate it empirically.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1162</post_id>
		<post_date><![CDATA[2016-04-25 02:05:28]]></post_date>
		<post_date_gmt><![CDATA[2016-04-25 00:05:28]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analyzing-the-understandability-of-requirements-engineering-languages-for-cscw-systems-a-family-of-experiments]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1163]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Context of the proposal: Collaborative Systems
Nowadays, even classic applications like text processors are collaborative. For instance, Google Docs [2] enables several users to edit a text document simultaneously . These collaborative text processors are a good example of CSCW (Computer Supported Cooperative Work) systems [3], which are systems whose users can perform collaboration, communication and coordination tasks (3C). Collaborative systems, in a similar way to classical single-user systems, have to be specified by means of a set of requirements, whose accuracy and suitability are key to achieve the quality of the developed system. The main difference between the requirements of single-user systems and CSCW systems is the highly non-functional nature of the latter, because of the users' need of being aware of the presence of other users with whom to perform the above mentioned 3C tasks, that is, the Workspace Awareness (WA). In order to deal with the specification of this special type of systems, we conducted several empirical evaluations in order to check which is the most adequate Requirements Engineering technique to model both awareness and quality requirements of CSCW systems. We concluded that the i* Framework [1], was the most promising one. However, we identified several issues when modeling collaborative systems with this language that led us to extend the original i* language by creating CSRML (Collaborative Systems Requirements Modeling Language) [4] and evaluate it empirically.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel A. Teruel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[LoUISE, Departamento de Sistemas Informáticos, Universidad de Castilla-La Mancha, Avda. España s/n Albacete 02071]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[miguel@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Elena Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[LoUISE, Departamento de Sistemas Informáticos, Universidad de Castilla-La Mancha, Avda. España s/n Albacete 02071]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[enavarro@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Víctor López-Jaquero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[LoUISE, Departamento de Sistemas Informáticos, Universidad de Castilla-La Mancha, Avda. España s/n Albacete 02071]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[victor@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Francisco Montero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[LoUISE, Departamento de Sistemas Informáticos, Universidad de Castilla-La Mancha, Avda. España s/n Albacete 02071]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[fmontero@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Javier Jaén]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[ISSI, Dpto. de Sistemas Informáticos y Computación, Universitat Politècnica de Valencia Avda. de los Naranjos s/n, Valencia (Spain) ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[fjaen@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Pascual González]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[LoUISE, Departamento de Sistemas Informáticos, Universidad de Castilla-La Mancha, Avda. España s/n Albacete 02071]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[pgonzalez@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/047]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia el uso de modelos en la selección e integración de Web APIs</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-el-uso-de-modelos-en-la-seleccion-e-integracion-de-web-apis/</link>
		<pubDate>Mon, 25 Apr 2016 00:08:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1165</guid>
		<description></description>
		<content><![CDATA[Este trabajo constituye una propuesta de ingeniería dirigida por modelos para dotar a desarrolladores Web de mecanismos para tomar decisiones informadas a la hora de seleccionar e integrar Web APIs. El objetivo de este trabajo es la definición de características cualitativas que intervienen en la integración de las Web APIs, y la definición de medidas basadas en análisis estructural que permitan la comparación entre de las mismas a través de sus operaciones. La propuesta emplea técnicas de metamodelado para lograr homogeneizar la representación de las Web APIs y así poder establecer mediciones independientemente de cómo se hayan implementado. Con el fin de realizar estas mediciones se aplican técnicas de análisis estructural, obteniendo criterios en los que se deben apoyar los desarrolladores para seleccionar las mejores combinaciones de Web APIs.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1165</post_id>
		<post_date><![CDATA[2016-04-25 02:08:01]]></post_date>
		<post_date_gmt><![CDATA[2016-04-25 00:08:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-el-uso-de-modelos-en-la-seleccion-e-integracion-de-web-apis]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="analisis-estructural"><![CDATA[análisis estructural]]></category>
		<category domain="post_tag" nicename="datos-abiertos"><![CDATA[datos abiertos]]></category>
		<category domain="post_tag" nicename="ingenieria-web"><![CDATA[Ingeniería Web]]></category>
		<category domain="post_tag" nicename="metamodelo"><![CDATA[metamodelo]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1166]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este trabajo constituye una propuesta de ingeniería dirigida por modelos para dotar a desarrolladores Web de mecanismos para tomar decisiones informadas a la hora de seleccionar e integrar Web APIs. El objetivo de este trabajo es la definición de características cualitativas que intervienen en la integración de las Web APIs, y la definición de medidas basadas en análisis estructural que permitan la comparación entre de las mismas a través de sus operaciones. La propuesta emplea técnicas de metamodelado para lograr homogeneizar la representación de las Web APIs y así poder establecer mediciones independientemente de cómo se hayan implementado. Con el fin de realizar estas mediciones se aplican técnicas de análisis estructural, obteniendo criterios en los que se deben apoyar los desarrolladores para seleccionar las mejores combinaciones de Web APIs.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[datos abiertos, análisis estructural, metamodelo, ingeniería web]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rolando Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dept. of Computer Science, University of Matanzas "Camilo Cienfuegos", Cuba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rolando.rodriguez@umcc.cu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Irene Garrigós]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos Universidad de Alicante, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[igarrigos@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose-Norberto Mazón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos Universidad de Alicante, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jnmazon@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/046]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Formalism for Specifying and Executing Transactional Semantic Web Services</title>
		<link>https://biblioteca.sistedes.es/articulo/a-formalism-for-specifying-and-executing-transactional-semantic-web-services/</link>
		<pubDate>Mon, 25 Apr 2016 00:12:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1168</guid>
		<description></description>
		<content><![CDATA[We propose a formalism for specifying and executing semantic web services in a transactional way. The formalism is based on the following elements: (1) the service is part of an agent with state codified by positive facts. The set of possible states during the agent's lifetime is constrained by an invariant. (2) Two types of services are considered: services which can change the agent's state (stateful service) and services which can not (stateless service). The first ones include in their specifications a transaction written in Transaction Logic and therefore operationally interpreted by sequences of states. (3) The execution of the stateful service may generate inconsistencies (states that do not satisfy the invariant). (4) We propose to repair inconsistencies by making use of a chase procedure. (5) According to transactional semantics, a service execution is undone if a repair is not possible. Keywords: chase, invariant, pre-condition, post-condition, query, service execution, semantic web service, state, transaction.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1168</post_id>
		<post_date><![CDATA[2016-04-25 02:12:53]]></post_date>
		<post_date_gmt><![CDATA[2016-04-25 00:12:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-formalism-for-specifying-and-executing-transactional-semantic-web-services]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1169]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We propose a formalism for specifying and executing semantic web services in a transactional way. The formalism is based on the following elements: (1) the service is part of an agent with state codified by positive facts. The set of possible states during the agent's lifetime is constrained by an invariant. (2) Two types of services are considered: services which can change the agent's state (stateful service) and services which can not (stateless service). The first ones include in their specifications a transaction written in Transaction Logic and therefore operationally interpreted by sequences of states. (3) The execution of the stateful service may generate inconsistencies (states that do not satisfy the invariant). (4) We propose to repair inconsistencies by making use of a chase procedure. (5) According to transactional semantics, a service execution is undone if a repair is not possible. Keywords: chase, invariant, pre-condition, post-condition, query, service execution, semantic web service, state, transaction.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco J. Galán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[High Technical School of Software and Computer Engineering. University of Seville. Seville, Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ahmed Riveras]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[High Technical School of Software and Computer Engineering. University of Seville. Seville, Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/045]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>WikiLayer: A DSL for Wikipedia Annotation</title>
		<link>https://biblioteca.sistedes.es/articulo/wikilayer-a-dsl-for-wikipedia-annotation/</link>
		<pubDate>Mon, 25 Apr 2016 00:30:23 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1171</guid>
		<description></description>
		<content><![CDATA[Reading Wikipedia can be the entry to more involved activities (e.g. editing). However, the jump from reading to editing could be too big for some wikipedians who can be intimidated by exposing their content to public scrutiny. Annotating might foster not only reading but be the prelude to editing. Different Web annotation tools exist (e.g. Evernote). Being a Web application, Wikipedia can benefit from these tools. However, general-purpose annotation tools do not make annotation a natural gesture within Wikipedia. That is, annotation editing, rendering or retrieval in e.g. Evernote is dissociated from the editing, rendering or location of articles in Wikipedia. This demo shows WikiLayer, a Firefox extension that supports Wikipedia-specific annotation (hereafter referred to as wikinotes). The approach is characterised as follows: (1) annotation content can be wikitext formatted or obtained through transclusion; (2) annotation rendering is seamlessly integrated within the Wikipedia front-end; (3) annotation editing, management and sharing is achieved without leaving Wikipedia. WikiLayer is realized as a DSL available as a Firefox extension at http://webaugmentation.org/wikilayer.xpi. Examples can be found at http://tinyurl.com/icwikinoteexamples.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1171</post_id>
		<post_date><![CDATA[2016-04-25 02:30:23]]></post_date>
		<post_date_gmt><![CDATA[2016-04-25 00:30:23]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[wikilayer-a-dsl-for-wikipedia-annotation]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1172]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Reading Wikipedia can be the entry to more involved activities (e.g. editing). However, the jump from reading to editing could be too big for some wikipedians who can be intimidated by exposing their content to public scrutiny. Annotating might foster not only reading but be the prelude to editing. Different Web annotation tools exist (e.g. Evernote). Being a Web application, Wikipedia can benefit from these tools. However, general-purpose annotation tools do not make annotation a natural gesture within Wikipedia. That is, annotation editing, rendering or retrieval in e.g. Evernote is dissociated from the editing, rendering or location of articles in Wikipedia. This demo shows WikiLayer, a Firefox extension that supports Wikipedia-specific annotation (hereafter referred to as wikinotes). The approach is characterised as follows: (1) annotation content can be wikitext formatted or obtained through transclusion; (2) annotation rendering is seamlessly integrated within the Wikipedia front-end; (3) annotation editing, management and sharing is achieved without leaving Wikipedia. WikiLayer is realized as a DSL available as a Firefox extension at http://webaugmentation.org/wikilayer.xpi. Examples can be found at http://tinyurl.com/icwikinoteexamples.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cristóbal Arellano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ONEKIN Research Group, University of the Basque Country (UPV/EHU), San Sebastián, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cristobal.arellano@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Oscar Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ONEKIN Research Group, University of the Basque Country (UPV/EHU), San Sebastián, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[oscar.diaz@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/044]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Distribucíon de interfaces de usuario utilizando Proxywork</title>
		<link>https://biblioteca.sistedes.es/articulo/distribucion-de-interfaces-de-usuario-utilizando-proxywork/</link>
		<pubDate>Mon, 25 Apr 2016 00:33:11 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1174</guid>
		<description></description>
		<content><![CDATA[Este artículo presenta el sistema Proxywork, que permite a los usuarios distribuir los componentes de interfaces Web en diferentes pantallas. La distribucíon de la interfaz se controla a través de un conjunto de operaciones (mostrar, ocultar, copiar, mover, etc.) que se realizan sobre la página Web afectada. Estas operaciones se agregan a los componentes de la página Web de manera dinámica en tiempo de ejecución. Dicha acción es llevada a cabo a través del proxy Proxywork. Como consecuencia las páginas Web no requieren ninguna información adicional para distribuirse entre diferentes pantallas. Para ilustrar el comportamiento del sistema, presentamos dos pruebas de concepto realizadas con un activo experimental del prototipo sobre el sitio Web de la Universidad de Castilla-La Mancha, el cual dividiremos entre pantallas que se ejecutan en diferentes plataformas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1174</post_id>
		<post_date><![CDATA[2016-04-25 02:33:11]]></post_date>
		<post_date_gmt><![CDATA[2016-04-25 00:33:11]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[distribucion-de-interfaces-de-usuario-utilizando-proxywork]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="aplicaciones-web"><![CDATA[Aplicaciones Web]]></category>
		<category domain="post_tag" nicename="interaccion-persona-ordenador"><![CDATA[Interacción Persona-Ordenador]]></category>
		<category domain="post_tag" nicename="interfaces-de-usuario-distribuidas"><![CDATA[Interfaces de Usuario distribuidas]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo presenta el sistema Proxywork, que permite a los usuarios distribuir los componentes de interfaces Web en diferentes pantallas. La distribucíon de la interfaz se controla a través de un conjunto de operaciones (mostrar, ocultar, copiar, mover, etc.) que se realizan sobre la página Web afectada. Estas operaciones se agregan a los componentes de la página Web de manera dinámica en tiempo de ejecución. Dicha acción es llevada a cabo a través del proxy Proxywork. Como consecuencia las páginas Web no requieren ninguna información adicional para distribuirse entre diferentes pantallas. Para ilustrar el comportamiento del sistema, presentamos dos pruebas de concepto realizadas con un activo experimental del prototipo sobre el sitio Web de la Universidad de Castilla-La Mancha, el cual dividiremos entre pantallas que se ejecutan en diferentes plataformas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Interacción Persona-Ordenador, Interfaces de Usuario distribuidas, Aplicaciones Web]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro G. Villanueva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha, Escuela Superior de Ingeniería Informática, Av. España S/N. Campus Universitario (02071) Albacete, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pedro.gonzalez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ricardo Tesoriero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha, Escuela Superior de Ingeniería Informática, Av. España S/N. Campus Universitario (02071) Albacete, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ricardo.tesoriero@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José A. Gallud]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha, Escuela Superior de Ingeniería Informática, Av. España S/N. Campus Universitario (02071) Albacete, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jose.gallud@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/043]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Proxywork: Distribucíon de Aplicaciones Web</title>
		<link>https://biblioteca.sistedes.es/articulo/proxywork-distribucion-de-aplicaciones-web/</link>
		<pubDate>Mon, 25 Apr 2016 00:35:59 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1176</guid>
		<description></description>
		<content><![CDATA[Este artículo presenta el sistema Proxywork, que permite a los usuarios distribuir los componentes de interfaces Web en diferentes pantallas. La distribucíon de la interfaz se controla a través de un conjunto de operaciones (mostrar, ocultar, copiar, mover, etc.) que se realizan sobre la página Web afectada. Estas operaciones se agregan a los componentes de la página Web de manera dinámica en tiempo de ejecución. Dicha acción es llevada a cabo a través del proxy Proxywork. Como consecuencia las páginas Web no requieren ninguna información adicional para distribuirse entre diferentes pantallas. Para ilustrar el comportamiento del sistema, utilizamos como caso de estudio el sitio Web de la Universidad de Castilla-La Mancha, el cual dividiremos entre pantallas que se ejecutan en diferentes plataformas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1176</post_id>
		<post_date><![CDATA[2016-04-25 02:35:59]]></post_date>
		<post_date_gmt><![CDATA[2016-04-25 00:35:59]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[proxywork-distribucion-de-aplicaciones-web]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="aplicaciones-web"><![CDATA[Aplicaciones Web]]></category>
		<category domain="post_tag" nicename="interaccion-persona-ordenador"><![CDATA[Interacción Persona-Ordenador]]></category>
		<category domain="post_tag" nicename="interfaces-de-usuario-distribuidas"><![CDATA[Interfaces de Usuario distribuidas]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo presenta el sistema Proxywork, que permite a los usuarios distribuir los componentes de interfaces Web en diferentes pantallas. La distribucíon de la interfaz se controla a través de un conjunto de operaciones (mostrar, ocultar, copiar, mover, etc.) que se realizan sobre la página Web afectada. Estas operaciones se agregan a los componentes de la página Web de manera dinámica en tiempo de ejecución. Dicha acción es llevada a cabo a través del proxy Proxywork. Como consecuencia las páginas Web no requieren ninguna información adicional para distribuirse entre diferentes pantallas. Para ilustrar el comportamiento del sistema, utilizamos como caso de estudio el sitio Web de la Universidad de Castilla-La Mancha, el cual dividiremos entre pantallas que se ejecutan en diferentes plataformas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Interacción Persona-Ordenador, Interfaces de Usuario distribuidas, Aplicaciones Web]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro G. Villanueva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha, Escuela Superior de Ingeniería Informática, Av. España S/N. Campus Universitario (02071) Albacete, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pedro.gonzalez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ricardo Tesoriero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha, Escuela Superior de Ingeniería Informática, Av. España S/N. Campus Universitario (02071) Albacete, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ricardo.tesoriero@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José A. Gallud]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha, Escuela Superior de Ingeniería Informática, Av. España S/N. Campus Universitario (02071) Albacete, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jose.gallud@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/042]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Sistema Interactivo Basado en Interfaces de Usuario Tangibles y Distribuidas para la Mejora de Habilidades Cognitivas</title>
		<link>https://biblioteca.sistedes.es/articulo/sistema-interactivo-basado-en-interfaces-de-usuario-tangibles-y-distribuidas-para-la-mejora-de-habilidades-cognitivas/</link>
		<pubDate>Mon, 25 Apr 2016 00:39:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1178</guid>
		<description></description>
		<content><![CDATA[Hoy en día un 3% de la población mundial sufre algún tipo de discapacidad intelectual. Las últimas investigaciones sobre plasticidad cerebral subrayan que a través de terapias basadas en estimulación cognitiva, los usuarios son capaces de mejorar positivamente las destrezas menos desarrolladas. En este artículo se presentan una serie de juegos de estimulación cognitiva desarrollados para un entorno multi-dispositivo y basado en interfaces de usuario tangibles y distribuidas. El sistema denominado TraInAb (Training Intellectual Abilities) se compone de una interfaz principal proyectada en la pared con el fin de facilitar la visualización y la colaboración entre varios jugadores a la vez. Los usuarios disponen de interfaces tangibles en forma de objetos cotidianos y conocidos para interactuar con el juego de una forma sencilla y natural de modo que eliminamos la barrera tecnológica y permitimos entrenar capacidades cognitivas de forma divertida a través de juegos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1178</post_id>
		<post_date><![CDATA[2016-04-25 02:39:06]]></post_date>
		<post_date_gmt><![CDATA[2016-04-25 00:39:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[sistema-interactivo-basado-en-interfaces-de-usuario-tangibles-y-distribuidas-para-la-mejora-de-habilidades-cognitivas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="estimulacion-cognitiva"><![CDATA[Estimulación Cognitiva]]></category>
		<category domain="post_tag" nicename="interfaces-de-usuario-distribuidas"><![CDATA[Interfaces de Usuario distribuidas]]></category>
		<category domain="post_tag" nicename="interfaces-tangibles"><![CDATA[Interfaces Tangibles]]></category>
		<category domain="post_tag" nicename="tecnologia-nfc"><![CDATA[Tecnología NFC]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1179]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Hoy en día un 3% de la población mundial sufre algún tipo de discapacidad intelectual. Las últimas investigaciones sobre plasticidad cerebral subrayan que a través de terapias basadas en estimulación cognitiva, los usuarios son capaces de mejorar positivamente las destrezas menos desarrolladas. En este artículo se presentan una serie de juegos de estimulación cognitiva desarrollados para un entorno multi-dispositivo y basado en interfaces de usuario tangibles y distribuidas. El sistema denominado TraInAb (Training Intellectual Abilities) se compone de una interfaz principal proyectada en la pared con el fin de facilitar la visualización y la colaboración entre varios jugadores a la vez. Los usuarios disponen de interfaces tangibles en forma de objetos cotidianos y conocidos para interactuar con el juego de una forma sencilla y natural de modo que eliminamos la barrera tecnológica y permitimos entrenar capacidades cognitivas de forma divertida a través de juegos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Estimulación Cognitiva, Tecnología NFC, Interfaces Tangibles, Interfaces de Usuario Distribuidas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Elena de la Guía]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos, Universidad de Castilla-La Mancha, 02071, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Mariaelena.guiauclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[María D. Lozano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos, Universidad de Castilla-La Mancha, 02071, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[maria.lozanouclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Víctor M. R. Penichet]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos, Universidad de Castilla-La Mancha, 02071, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[victor.penichetuclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/041]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Identificacíon de Componentes en Arquitecturas Software Mediante Programacíon Evolutiva</title>
		<link>https://biblioteca.sistedes.es/articulo/identificacion-de-componentes-en-arquitecturas-software-mediante-programacion-evolutiva/</link>
		<pubDate>Mon, 25 Apr 2016 00:51:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1183</guid>
		<description></description>
		<content><![CDATA[El análisis arquitectónico constituye una tarea indispensable en los grandes sistemas software, pues dedica su esfuerzo a encontrar soluciones de diseño de alto nivel que cumplan requisitos de desempeño, acoplamiento, cohesíon o reutilizacíon, entre otros. Sin embargo, aspectos como la experiencia del arquitecto software o la complejidad del sistema repercuten en el resultado. La Inteligencia Artificial (IA) aporta un marco novedoso para el desarrollo de herramientas semi-automáticas en este dominio. En general, el área de SBSE (Search-Based Software Engineering) plantea considerar los retos de la Ingeniería del Software como problemas de optimizacíon y búsqueda. Este trabajo presenta una nueva propuesta para la identificación de arquitecturas basadas en componentes a partir de representaciones cercanas al experto y haciendo uso de la metaheurística de Programacíon Evolutiva (EP). Además, discute los principales retos a los que se enfrenta este tipo de soluciones y desarrolla un estudio experimental que aporta resultados prometedores.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1183</post_id>
		<post_date><![CDATA[2016-04-25 02:51:54]]></post_date>
		<post_date_gmt><![CDATA[2016-04-25 00:51:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[identificacion-de-componentes-en-arquitecturas-software-mediante-programacion-evolutiva]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="arquitecturas-basadas-en-componentes"><![CDATA[Arquitecturas basadas en componentes]]></category>
		<category domain="post_tag" nicename="programacion-evolutiva"><![CDATA[Programacíon Evolutiva]]></category>
		<category domain="post_tag" nicename="sbse"><![CDATA[SBSE]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1184]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El análisis arquitectónico constituye una tarea indispensable en los grandes sistemas software, pues dedica su esfuerzo a encontrar soluciones de diseño de alto nivel que cumplan requisitos de desempeño, acoplamiento, cohesíon o reutilizacíon, entre otros. Sin embargo, aspectos como la experiencia del arquitecto software o la complejidad del sistema repercuten en el resultado. La Inteligencia Artificial (IA) aporta un marco novedoso para el desarrollo de herramientas semi-automáticas en este dominio. En general, el área de SBSE (Search-Based Software Engineering) plantea considerar los retos de la Ingeniería del Software como problemas de optimizacíon y búsqueda. Este trabajo presenta una nueva propuesta para la identificación de arquitecturas basadas en componentes a partir de representaciones cercanas al experto y haciendo uso de la metaheurística de Programacíon Evolutiva (EP). Además, discute los principales retos a los que se enfrenta este tipo de soluciones y desarrolla un estudio experimental que aporta resultados prometedores.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Arquitecturas basadas en componentes, SBSE, Programacíon Evolutiva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aurora Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico Universidad de Córdoba, Campus de Rabanales, 14071 Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aramirez@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Raúl Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico Universidad de Córdoba, Campus de Rabanales, 14071 Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sebastían Ventura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico Universidad de Córdoba, Campus de Rabanales, 14071 Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sventura@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/053]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>MULTICLAPP: A framework for modeling and developing multicloud migratable applications</title>
		<link>https://biblioteca.sistedes.es/articulo/multiclapp-a-framework-for-modeling-and-developing-multicloud-migratable-applications/</link>
		<pubDate>Mon, 25 Apr 2016 00:55:33 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1186</guid>
		<description></description>
		<content><![CDATA[Developing software for the cloud usually implies using the tools and libraries supplied by cloud vendors for each of their platforms. This strongly couples the software to specific platforms and penalizes its migration or interoperability with external cloud services, in what is known as vendor lock-in. Under these circumstances multicloud applications become difficult to build and maintain since they require multidisciplinary teams with expertise on multiple platforms, and the redevelopment of some components if the cloud deployment scenario is altered. The MULTICLAPP framework described in this paper tackles these issues by presenting a three-stage development process that allows multicloud applications to be developed without being coupled to any concrete vendor. MDE and adaptation techniques are used throughout the software development stages in order to abstract the software from each vendor's service specifications. As a result of this, multicloud applications or their subcomponents can be reassigned to different cloud platforms without having to undergo a partial or complete redevelopment process.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1186</post_id>
		<post_date><![CDATA[2016-04-25 02:55:33]]></post_date>
		<post_date_gmt><![CDATA[2016-04-25 00:55:33]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[multiclapp-a-framework-for-modeling-and-developing-multicloud-migratable-applications]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1187]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Developing software for the cloud usually implies using the tools and libraries supplied by cloud vendors for each of their platforms. This strongly couples the software to specific platforms and penalizes its migration or interoperability with external cloud services, in what is known as vendor lock-in. Under these circumstances multicloud applications become difficult to build and maintain since they require multidisciplinary teams with expertise on multiple platforms, and the redevelopment of some components if the cloud deployment scenario is altered. The MULTICLAPP framework described in this paper tackles these issues by presenting a three-stage development process that allows multicloud applications to be developed without being coupled to any concrete vendor. MDE and adaptation techniques are used throughout the software development stages in order to abstract the software from each vendor's service specifications. As a result of this, multicloud applications or their subcomponents can be reassigned to different cloud platforms without having to undergo a partial or complete redevelopment process.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Joaqúin Guillén]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Gloin, Calle de las Ocas 2, Cáceres, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jguillen@gloin.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Miranda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Gloin, Calle de las Ocas 2, Cáceres, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jmiranda@gloin.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Information Technology and Telematic Systems Engineering, University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science, University of Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/052]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Configuring a Context-Aware Middleware for Wireless Sensor Networks</title>
		<link>https://biblioteca.sistedes.es/articulo/configuring-a-context-aware-middleware-for-wireless-sensor-networks/</link>
		<pubDate>Mon, 25 Apr 2016 00:58:13 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1189</guid>
		<description></description>
		<content><![CDATA[In the Future Internet, applications based on Wireless Sensor Networks will have to support reconfiguration with minimum human intervention, depending on dynamic context changes in their environment. These situations create a need for building these applications as adaptive software and including techniques that allow the context acquisition and decisions about adaptation. However, contexts use to be made up of complex information acquired from heterogeneous devices and user characteristics, making them difficult to manage. So, instead of building context-aware applications from scratch, we propose to use FamiWare, a family of middleware for Ambient Intelligence specifically designed to be aware of contexts in sensor and smartphone devices. It provides both, several monitoring services to acquire contexts from devices and users, and a context-awareness service to analyze and detect context changes. However, the current version of FamiWare does not allow the automatic incorporation related to the management of new contexts into the FamiWare family. To overcome this shortcoming, in this work, we first present how to model the context using a metamodel to define the contexts that must to be taken into account in an instantiation of FamiWare for a certain Ambient Intelligence system. Then, to configure a new context-aware version of FamiWare and to generate code ready-to-install within heterogeneous devices, we define a mapping that automatically transforms metamodel elements defining contexts into elements of the FamiWare family, and we also use the FamiWare configuration process to customize the new context-aware variant. Finally, we evaluate the benefits of our process, and we analyze both that the new version of the middleware works as expected and that it manages the contexts in an efficient way.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1189</post_id>
		<post_date><![CDATA[2016-04-25 02:58:13]]></post_date>
		<post_date_gmt><![CDATA[2016-04-25 00:58:13]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[configuring-a-context-aware-middleware-for-wireless-sensor-networks]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1190]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In the Future Internet, applications based on Wireless Sensor Networks will have to support reconfiguration with minimum human intervention, depending on dynamic context changes in their environment. These situations create a need for building these applications as adaptive software and including techniques that allow the context acquisition and decisions about adaptation. However, contexts use to be made up of complex information acquired from heterogeneous devices and user characteristics, making them difficult to manage. So, instead of building context-aware applications from scratch, we propose to use FamiWare, a family of middleware for Ambient Intelligence specifically designed to be aware of contexts in sensor and smartphone devices. It provides both, several monitoring services to acquire contexts from devices and users, and a context-awareness service to analyze and detect context changes. However, the current version of FamiWare does not allow the automatic incorporation related to the management of new contexts into the FamiWare family. To overcome this shortcoming, in this work, we first present how to model the context using a metamodel to define the contexts that must to be taken into account in an instantiation of FamiWare for a certain Ambient Intelligence system. Then, to configure a new context-aware version of FamiWare and to generate code ready-to-install within heterogeneous devices, we define a mapping that automatically transforms metamodel elements defining contexts into elements of the FamiWare family, and we also use the FamiWare configuration process to customize the new context-aware variant. Finally, we evaluate the benefits of our process, and we analyze both that the new version of the middleware works as expected and that it manages the contexts in an efficient way.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Nadia Gamez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto de Lenguajes y Ciencias de la Computación, Universidad de Málaga ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[nadia@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Cubo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto de Lenguajes y Ciencias de la Computación, Universidad de Málaga ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cubo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto de Lenguajes y Ciencias de la Computación, Universidad de Málaga ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ernesto Pimentel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto de Lenguajes y Ciencias de la Computación, Universidad de Málaga ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[ernesto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/051]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>On the Effectiveness, Efficiency and Perceived Utility of Architecture Evaluation Methods: A Replication Study</title>
		<link>https://biblioteca.sistedes.es/articulo/on-the-effectiveness-efficiency-and-perceived-utility-of-architecture-evaluation-methods-a-replication-study/</link>
		<pubDate>Mon, 25 Apr 2016 01:00:41 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1192</guid>
		<description></description>
		<content><![CDATA[In this paper we describe the results of a replication study for comparing the effectiveness, efficiency and perceived utility of the quality-driven product architecture derivation and improvement method (QuaDAI), an architecture derivation and evaluation method that we presented in recent works, as opposed to the Architecture Tradeoff Analysis Method (ATAM), a well-known architectural evaluation method used in industry. The results of the original experiment (conducted with undergraduate students) showed that QuaDAI was found to be more efficient and was perceived as easier to use than ATAM. However, although QuaDAI performed better than ATAM, we could not confirm the other variables, as the differences between both methods were not statistically significant. Therefore the goal of the replication was to verify these findings with a group of more experienced students. In the replication study QuaDAI also performed better than ATAM, but as opposed to the original study, all the variables proved to be statistically significant.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1192</post_id>
		<post_date><![CDATA[2016-04-25 03:00:41]]></post_date>
		<post_date_gmt><![CDATA[2016-04-25 01:00:41]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[on-the-effectiveness-efficiency-and-perceived-utility-of-architecture-evaluation-methods-a-replication-study]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="architecture-evaluation-methods"><![CDATA[Architecture Evaluation Methods]]></category>
		<category domain="post_tag" nicename="atam"><![CDATA[ATAM]]></category>
		<category domain="post_tag" nicename="controlled-experiment"><![CDATA[Controlled Experiment]]></category>
		<category domain="post_tag" nicename="experiment-replication"><![CDATA[Experiment Replication]]></category>
		<category domain="post_tag" nicename="quality-attributes"><![CDATA[Quality Attributes]]></category>
		<category domain="post_tag" nicename="software-architecture"><![CDATA[Software Architecture]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1193]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper we describe the results of a replication study for comparing the effectiveness, efficiency and perceived utility of the quality-driven product architecture derivation and improvement method (QuaDAI), an architecture derivation and evaluation method that we presented in recent works, as opposed to the Architecture Tradeoff Analysis Method (ATAM), a well-known architectural evaluation method used in industry. The results of the original experiment (conducted with undergraduate students) showed that QuaDAI was found to be more efficient and was perceived as easier to use than ATAM. However, although QuaDAI performed better than ATAM, we could not confirm the other variables, as the differences between both methods were not statistically significant. Therefore the goal of the replication was to verify these findings with a group of more experienced students. In the replication study QuaDAI also performed better than ATAM, but as opposed to the original study, all the variables proved to be statistically significant.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Controlled Experiment, Experiment Replication, Software Architecture, Architecture Evaluation Methods, Quality Attributes, ATAM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier González-Huerta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ISSI Research Group, Universitat Politècnica de València Camino de Vera, s/n, 46022, Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jagonzalez@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Emilio Insfrán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ISSI Research Group, Universitat Politècnica de València Camino de Vera, s/n, 46022, Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[einsfran@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Silvia Abrahão]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ISSI Research Group, Universitat Politècnica de València Camino de Vera, s/n, 46022, Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sabrahao@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/050]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Embedded Software Product Lines: Domain and Application Engineering Model-based Analysis Processes</title>
		<link>https://biblioteca.sistedes.es/articulo/embedded-software-product-lines-domain-and-application-engineering-model-based-analysis-processes/</link>
		<pubDate>Mon, 25 Apr 2016 01:03:21 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1195</guid>
		<description></description>
		<content><![CDATA[Nowadays, embedded systems are gaining importance. At the same time, the development of their software is increasing its complexity, having to deal with quality, cost, and time-to-market issues among others. With stringent quality requirements such as performance, early verification and validation become critical in these systems. In this regard, advanced development paradigms such as model-driven engineering (MDE) and software product line engineering (SPLE) bring considerable benefits to the development and validation of embedded system software. However, these benefits come at the cost of increasing process complexity.
This work presents a process based on UML and MARTE for the analysis of embedded model-driven product lines. It specifies the tasks, the involved roles, and the work products that form the process and how it is integrated in the more general development process.
In order to manage and perform model analysis for ensuring the quality of the products of the Software Product Line (SPL), it is necessary to establish a process with the aim of tackling the complexity. Following established product line development practices, two separate processes were defined for model based analysis:
 Model based Analysis Process in Domain Engineering: This process sets the infrastructure to perform the analysis of the products of the product line. That is, it defines the analysis core assets.

Model based Analysis Process in Application Engineering: Based on the above mentioned analysis core assets, this process specifies how they are applied to perform model analysis.
1.1 Model based Analysis Process in Domain Engineering
If the goal is to develop and analyze an embedded SPL, the core assets developed in Domain Engineering (e.g., models, as MDE is applied), must be prepared to perform analysis later on. This is the aim of the Model based Analysis Process in Domain Engineering. This process takes the feature model and the design models as input and outputs core assets that will serve as the building blocks for model analysis in Application Engineering.
The following tasks are performed:  Feature Model Elaboration: The variability in functionalities and quality attributes is defined using a feature model.  Allocation Variability Elaboration: An allocation variability branch is added to the Feature model to add variability in deployment.  Analysis Variability Elaboration: An analysis variability branch is added to the Feature model to add information related to critical scenarios to be analyzed and analysis types for each quality attribute defined before.  Real-Time Specification: The SPL design models must be annotated with temporal information (performance...) using MARTE profile (considering also variability).  Transformation Definition: To be able to generate the analysis models automatically, the required transformations must be defined. This task is performed once as the defined transformations can be reused.
1.2 Model based Analysis Process in Application Engineering
Previously developed core assets in Domain Engineering are used in Application Engineering process to perform model analyses, prioritizing the critical scenarios of each specific product model of the SPL.
Desired features must be selected from the different branches of the feature model. In this way, the specific product model configuration is defined considering the specified constraints. This model will be used to obtain the specific instances of Analysis Models using the defined transformations to get the specific product analysis model derived from the SPL design models.
1.3 Tools
Existing tools that support the tasks to be performed in the process are also described. A classification of such tools and a study of traceability among them are provided, allowing engineering teams to choose the most adequate chain of tools to support the process.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1195</post_id>
		<post_date><![CDATA[2016-04-25 03:03:21]]></post_date>
		<post_date_gmt><![CDATA[2016-04-25 01:03:21]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[embedded-software-product-lines-domain-and-application-engineering-model-based-analysis-processes]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1196]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Nowadays, embedded systems are gaining importance. At the same time, the development of their software is increasing its complexity, having to deal with quality, cost, and time-to-market issues among others. With stringent quality requirements such as performance, early verification and validation become critical in these systems. In this regard, advanced development paradigms such as model-driven engineering (MDE) and software product line engineering (SPLE) bring considerable benefits to the development and validation of embedded system software. However, these benefits come at the cost of increasing process complexity.
This work presents a process based on UML and MARTE for the analysis of embedded model-driven product lines. It specifies the tasks, the involved roles, and the work products that form the process and how it is integrated in the more general development process.
In order to manage and perform model analysis for ensuring the quality of the products of the Software Product Line (SPL), it is necessary to establish a process with the aim of tackling the complexity. Following established product line development practices, two separate processes were defined for model based analysis:
 Model based Analysis Process in Domain Engineering: This process sets the infrastructure to perform the analysis of the products of the product line. That is, it defines the analysis core assets.

Model based Analysis Process in Application Engineering: Based on the above mentioned analysis core assets, this process specifies how they are applied to perform model analysis.
1.1 Model based Analysis Process in Domain Engineering
If the goal is to develop and analyze an embedded SPL, the core assets developed in Domain Engineering (e.g., models, as MDE is applied), must be prepared to perform analysis later on. This is the aim of the Model based Analysis Process in Domain Engineering. This process takes the feature model and the design models as input and outputs core assets that will serve as the building blocks for model analysis in Application Engineering.
The following tasks are performed:  Feature Model Elaboration: The variability in functionalities and quality attributes is defined using a feature model.  Allocation Variability Elaboration: An allocation variability branch is added to the Feature model to add variability in deployment.  Analysis Variability Elaboration: An analysis variability branch is added to the Feature model to add information related to critical scenarios to be analyzed and analysis types for each quality attribute defined before.  Real-Time Specification: The SPL design models must be annotated with temporal information (performance...) using MARTE profile (considering also variability).  Transformation Definition: To be able to generate the analysis models automatically, the required transformations must be defined. This task is performed once as the defined transformations can be reused.
1.2 Model based Analysis Process in Application Engineering
Previously developed core assets in Domain Engineering are used in Application Engineering process to perform model analyses, prioritizing the critical scenarios of each specific product model of the SPL.
Desired features must be selected from the different branches of the feature model. In this way, the specific product model configuration is defined considering the specified constraints. This model will be used to obtain the specific instances of Analysis Models using the defined transformations to get the specific product analysis model derived from the SPL design models.
1.3 Tools
Existing tools that support the tasks to be performed in the process are also described. A classification of such tools and a study of traceability among them are provided, allowing engineering teams to choose the most adequate chain of tools to support the process.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Lorea Belategi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Mondragon Unibertsitatea, Goiru 2, 20500, Mondragón, Spain1 ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[lbelategui@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Goiuria Sagardui]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Mondragon Unibertsitatea, Goiru 2, 20500, Mondragón, Spain1 ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gsagardui@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Leire Etxeberria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Mondragon Unibertsitatea, Goiru 2, 20500, Mondragón, Spain1 ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[letxeberria@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Maider Azanza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country UPV/EHU, San Sebastián, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[maider.azanza@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/049]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modelando y Gestionando la Variabilidad de los Sistemas de Inteligencia Ambiental con CVL</title>
		<link>https://biblioteca.sistedes.es/articulo/modelando-y-gestionando-la-variabilidad-de-los-sistemas-de-inteligencia-ambiental-con-cvl/</link>
		<pubDate>Mon, 25 Apr 2016 01:05:24 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1198</guid>
		<description></description>
		<content><![CDATA[Las Líneas de Productos Software son una tecnología adecuada para gestionar la variabilidad inherente de los sistemas de Inteligencia Ambiental (AmI). Proponemos aplicar los conceptos de la ingeniería de líneas de producto a nivel de middleware para proporcionar configuraciones adaptadas a cada dispositivo de un determinado sistema AmI. Además de por la variabilidad, el dominio AmI está caracterizado por la necesidad de adaptar el sistema a los recursos escasos que suelen poseer los dispositivos AmI. Normalmente, en este domino, que también engloba los sistemas empotrados, estos problemas se suelen resolver a nivel de código. Pero nosotros consideramos que los modelos pueden ser claves para automatizar la generación de configuraciones de middlewares a medida y también para reconfigurar dicho middleware en tiempo de ejecución. Entonces, proponemos el uso de CVL (Common Variability Language), un lenguaje de modelado de la variabilidad genérico, para modelar una familia de middlewares para AmI, gestionando la variabilidad tanto en tiempo de diseño como en tiempo de ejecución.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1198</post_id>
		<post_date><![CDATA[2016-04-25 03:05:24]]></post_date>
		<post_date_gmt><![CDATA[2016-04-25 01:05:24]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modelando-y-gestionando-la-variabilidad-de-los-sistemas-de-inteligencia-ambiental-con-cvl]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="ambientes-inteligentes"><![CDATA[Ambientes Inteligentes]]></category>
		<category domain="post_tag" nicename="lenguajes-de-modelado-de-la-variabilidad"><![CDATA[Lenguajes de Modelado de la Variabilidad]]></category>
		<category domain="post_tag" nicename="lineas-de-producto-software"><![CDATA[Líneas de Producto Software]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1199]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las Líneas de Productos Software son una tecnología adecuada para gestionar la variabilidad inherente de los sistemas de Inteligencia Ambiental (AmI). Proponemos aplicar los conceptos de la ingeniería de líneas de producto a nivel de middleware para proporcionar configuraciones adaptadas a cada dispositivo de un determinado sistema AmI. Además de por la variabilidad, el dominio AmI está caracterizado por la necesidad de adaptar el sistema a los recursos escasos que suelen poseer los dispositivos AmI. Normalmente, en este domino, que también engloba los sistemas empotrados, estos problemas se suelen resolver a nivel de código. Pero nosotros consideramos que los modelos pueden ser claves para automatizar la generación de configuraciones de middlewares a medida y también para reconfigurar dicho middleware en tiempo de ejecución. Entonces, proponemos el uso de CVL (Common Variability Language), un lenguaje de modelado de la variabilidad genérico, para modelar una familia de middlewares para AmI, gestionando la variabilidad tanto en tiempo de diseño como en tiempo de ejecución.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Líneas de Producto Software, Ambientes Inteligentes, Lenguajes de Modelado de la Variabilidad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Nadia Gámez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[nadia,@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2013/048]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Leveraging EDA and CEP for Integrating Low-level Network Analysis Methods into</title>
		<link>https://biblioteca.sistedes.es/articulo/leveraging-eda-and-cep-for-integrating-low-level-network-analysis-methods-into/</link>
		<pubDate>Sat, 14 May 2016 01:34:43 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1248</guid>
		<description></description>
		<content><![CDATA[Computer networks are crucial for the operation of Information Technology (IT) infrastructures. For assuring and maintaining the functionality of networks and with this of IT systems in general, accurate and up-to-date information about networks and the incidents in them is of vital importance. To allow a proper, accurate, and timely assessment this information must be efficiently communicated to the relevant analysis applications that rely on it. In this paper we propose an approach on obtaining and efficiently communicating information gathered with means of low-level network analysis methods from spatially distributed and heterogeneous data sources. Thereby, we leverage existing technologies from the fields of network analysis, Event-driven Architecture (EDA), and Complex Event Processing (CEP) and combine these into a novel distributed network analysis system approach that can be integrated into todays, modern, distributed IT architectures.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1248</post_id>
		<post_date><![CDATA[2016-05-14 03:34:43]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 01:34:43]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[leveraging-eda-and-cep-for-integrating-low-level-network-analysis-methods-into]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cep"><![CDATA[CEP]]></category>
		<category domain="post_tag" nicename="eda"><![CDATA[EDA]]></category>
		<category domain="post_tag" nicename="network-analysis"><![CDATA[network analysis]]></category>
		<category domain="post_tag" nicename="network-surveillance"><![CDATA[network surveillance]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1249]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Computer networks are crucial for the operation of Information Technology (IT) infrastructures. For assuring and maintaining the functionality of networks and with this of IT systems in general, accurate and up-to-date information about networks and the incidents in them is of vital importance. To allow a proper, accurate, and timely assessment this information must be efficiently communicated to the relevant analysis applications that rely on it. In this paper we propose an approach on obtaining and efficiently communicating information gathered with means of low-level network analysis methods from spatially distributed and heterogeneous data sources. Thereby, we leverage existing technologies from the fields of network analysis, Event-driven Architecture (EDA), and Complex Event Processing (CEP) and combine these into a novel distributed network analysis system approach that can be integrated into todays, modern, distributed IT architectures.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[network analysis, network surveillance, EDA, CEP]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rüdiger Gad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Applied Sciences Frankfurt am Main Nibelungenplatz 1, 60318 Frankfurt am Main, Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rgad@fb2.fh-frankfurt.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science and Engineering, University of Cádiz, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Martin Kappes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Applied Sciences Frankfurt am Main Nibelungenplatz 1, 60318 Frankfurt am Main, Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[kappes@fb2.fh-frankfurt.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science and Engineering, University of Cádiz, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/002]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una solucíon SOA para ejecutar workflows científicos en entornos Grid heterogéneos</title>
		<link>https://biblioteca.sistedes.es/articulo/una-solucion-soa-para-ejecutar-workflows-cientificos-en-entornos-grid-heterogeneos/</link>
		<pubDate>Sat, 14 May 2016 01:39:42 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1251</guid>
		<description></description>
		<content><![CDATA[La posibilidad de ejecutar un mismo workflow científico en distintos entornos Grid heterogéneos todavía es, a día de hoy, un reto abierto. Aunque la orientacíon a servicios permite allanar el camino, las propuestas existentes exigen un papel activo por parte de los programadores, que deben seleccionar el entorno de ejecucíon a utilizar en todas las tareas del workflow de manera estática. Como consecuencia, estas soluciones limitan la utilizacíon de diversos entornos de computacíon de forma conjunta. En este trabajo se pretende ir un paso más allá, liberando al programador de la selección del entorno de ejecución y permitiendo ejecutar workflows en múltiples entornos de computacíon heterogéneos. Para ello, se propone un servicio de computacíon que permite programar workflows independientemente del entorno de ejecucíon y a distintos niveles de abstraccíon a través de diferentes lenguajes orientados a servicios. Asimismo, el servicio permite integrar varios entornos Grid heterogéneos, mejorando su aprovechamiento mediante una estrategia de meta-scheduling basada en simulación que permite decidir el entorno de ejecucíon más adecuado para cada tarea. Como caso de uso, el workflow de análisis Inspiral es ejecutado sobre dos entornos heterogéneos, mejorando el rendimiento de la ejecucíon del workflow.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1251</post_id>
		<post_date><![CDATA[2016-05-14 03:39:42]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 01:39:42]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-solucion-soa-para-ejecutar-workflows-cientificos-en-entornos-grid-heterogeneos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="grid"><![CDATA[Grid]]></category>
		<category domain="post_tag" nicename="integracion-de-sistemas-heterogeneos"><![CDATA[integracíon de sistemas heterogéneos]]></category>
		<category domain="post_tag" nicename="orientacion-a-servicios"><![CDATA[Orientación a servicios]]></category>
		<category domain="post_tag" nicename="workflows-cientificos"><![CDATA[Workflows científicos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1252]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La posibilidad de ejecutar un mismo workflow científico en distintos entornos Grid heterogéneos todavía es, a día de hoy, un reto abierto. Aunque la orientacíon a servicios permite allanar el camino, las propuestas existentes exigen un papel activo por parte de los programadores, que deben seleccionar el entorno de ejecucíon a utilizar en todas las tareas del workflow de manera estática. Como consecuencia, estas soluciones limitan la utilizacíon de diversos entornos de computacíon de forma conjunta. En este trabajo se pretende ir un paso más allá, liberando al programador de la selección del entorno de ejecución y permitiendo ejecutar workflows en múltiples entornos de computacíon heterogéneos. Para ello, se propone un servicio de computacíon que permite programar workflows independientemente del entorno de ejecucíon y a distintos niveles de abstraccíon a través de diferentes lenguajes orientados a servicios. Asimismo, el servicio permite integrar varios entornos Grid heterogéneos, mejorando su aprovechamiento mediante una estrategia de meta-scheduling basada en simulación que permite decidir el entorno de ejecucíon más adecuado para cada tarea. Como caso de uso, el workflow de análisis Inspiral es ejecutado sobre dos entornos heterogéneos, mejorando el rendimiento de la ejecucíon del workflow.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Workflows científicos, orientacíon a servicios, Grid, integracíon de sistemas heterogéneos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/003]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Sergio Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Ingeniería de Aragón (I3A) Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[shernandez@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Fabra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Ingeniería de Aragón (I3A) Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jfabra@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pedro Alvarez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Ingeniería de Aragón (I3A) Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[alvaper@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Joaqúin Ezpeleta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Ingeniería de Aragón (I3A) Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[ezpeleta@unizar.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>CumuloNimbo Una Plataforma como Servicio con Procesamiento Transaccional Altamente Escalable</title>
		<link>https://biblioteca.sistedes.es/articulo/cumulonimbo-una-plataforma-como-servicio-con-procesamiento-transaccional-altamente-escalable/</link>
		<pubDate>Sat, 14 May 2016 01:43:57 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1254</guid>
		<description></description>
		<content><![CDATA[El modelo de computacíon en la nube (cloud computing) ha ganado mucha popularidad en los últimos años, prueba de ello es la cantidad de productos que distintas empresas han lanzado para ofrecer software, capacidad de procesamiento y servicios en la nube. Para una empresa el mover sus aplicaciones a la nube, con el fin de garantizar disponibilidad y escalabilidad de las mismas y un ahorro de costes, no es una tarea fácil. El principal problema es que las aplicaciones tienen que ser rediseñadas porque las plataformas de computacíon en la nube presentan restricciones que no tienen los entornos tradicionales. En este artículo presentamos CumuloNimbo, una plataforma para computacíon en la nube que permite la ejecución y migracíon de manera transparente de aplicaciones multi-capa en la nube. Una de las principales características de CumuloNimbo es la gestíon de transacciones altamente escalable y coherente. El artículo describe la arquitectura del sistema, así como una evaluacíon de la escalabilidad del mismo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1254</post_id>
		<post_date><![CDATA[2016-05-14 03:43:57]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 01:43:57]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[cumulonimbo-una-plataforma-como-servicio-con-procesamiento-transaccional-altamente-escalable]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1257]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/004]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El modelo de computacíon en la nube (cloud computing) ha ganado mucha popularidad en los últimos años, prueba de ello es la cantidad de productos que distintas empresas han lanzado para ofrecer software, capacidad de procesamiento y servicios en la nube. Para una empresa el mover sus aplicaciones a la nube, con el fin de garantizar disponibilidad y escalabilidad de las mismas y un ahorro de costes, no es una tarea fácil. El principal problema es que las aplicaciones tienen que ser rediseñadas porque las plataformas de computacíon en la nube presentan restricciones que no tienen los entornos tradicionales. En este artículo presentamos CumuloNimbo, una plataforma para computacíon en la nube que permite la ejecución y migracíon de manera transparente de aplicaciones multi-capa en la nube. Una de las principales características de CumuloNimbo es la gestíon de transacciones altamente escalable y coherente. El artículo describe la arquitectura del sistema, así como una evaluacíon de la escalabilidad del mismo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ricardo Jiménez-Peris]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rjimenez@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Marta Patiño-Martínez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mpatino@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ivan Brondino ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ibrondino@fi.upm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un Método de Generación de Pruebas de Rendimiento para Múltiples Tecnologías desde Modelos UML con Anotaciones MARTE</title>
		<link>https://biblioteca.sistedes.es/articulo/un-metodo-de-generacion-de-pruebas-de-rendimiento-para-multiples-tecnologias-desde-modelos-uml-con-anotaciones-marte/</link>
		<pubDate>Sat, 14 May 2016 01:48:28 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1259</guid>
		<description></description>
		<content><![CDATA[Obtener el rendimiento esperado de un flujo de trabajo sería más fácil si cada tarea incluyera sus propias especificaciones. Sin embargo, normalmente sólo se dan requisitos globales de rendimiento, obligando a los diseñadores a inferir los requisitos locales a mano. En trabajos anteriores presentamos dos algoritmos que automáticamente inferían restricciones locales de rendimiento a partir de diagramas de actividad Unified Modelling Language anotados mediante el perfil Modelling and Analysis of Real-Time and Embedded Systems. En este trabajo presentamos un método para usar estas anotaciones para generar casos de prueba de rendimiento para múltiples tecnologías, relacionando el modelo de rendimiento con modelos de diseño e implementación. Mostramos cómo se podría aplicar a código Java y a composiciones de servicios mediante tecnologías existentes de código abierto, y estudiamos las tareas a realizar para su implementación y las similitudes y diferencias con otras propuestas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1259</post_id>
		<post_date><![CDATA[2016-05-14 03:48:28]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 01:48:28]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-metodo-de-generacion-de-pruebas-de-rendimiento-para-multiples-tecnologias-desde-modelos-uml-con-anotaciones-marte]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="ingenieria-dirigida-por-modelos"><![CDATA[Ingeniería Dirigida por Modelos]]></category>
		<category domain="post_tag" nicename="marte"><![CDATA[MARTE]]></category>
		<category domain="post_tag" nicename="rendimiento-del-software"><![CDATA[rendimiento del software]]></category>
		<category domain="post_tag" nicename="servicios-web"><![CDATA[servicios web]]></category>
		<category domain="post_tag" nicename="uml"><![CDATA[UML]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Obtener el rendimiento esperado de un flujo de trabajo sería más fácil si cada tarea incluyera sus propias especificaciones. Sin embargo, normalmente sólo se dan requisitos globales de rendimiento, obligando a los diseñadores a inferir los requisitos locales a mano. En trabajos anteriores presentamos dos algoritmos que automáticamente inferían restricciones locales de rendimiento a partir de diagramas de actividad Unified Modelling Language anotados mediante el perfil Modelling and Analysis of Real-Time and Embedded Systems. En este trabajo presentamos un método para usar estas anotaciones para generar casos de prueba de rendimiento para múltiples tecnologías, relacionando el modelo de rendimiento con modelos de diseño e implementación. Mostramos cómo se podría aplicar a código Java y a composiciones de servicios mediante tecnologías existentes de código abierto, y estudiamos las tareas a realizar para su implementación y las similitudes y diferencias con otras propuestas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[rendimiento del software, Servicios Web, ingeniería dirigida por modelos, MARTE, UML]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio García Domínguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Escuela Superior de Ingeniería C/Chile 1, CP 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[antonio.garciadominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Escuela Superior de Ingeniería C/Chile 1, CP 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1261]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>PLATAFORMA DE COMPUTACION GENERICA BASADA EN SERVICIOS WEB PARA PROBLEMAS DE CONTEO DE CELULAS</title>
		<link>https://biblioteca.sistedes.es/articulo/plataforma-de-computacion-generica-basada-en-servicios-web-para-problemas-de-conteo-de-celulas/</link>
		<pubDate>Sat, 14 May 2016 01:53:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1262</guid>
		<description></description>
		<content><![CDATA[El procesado y análisis de imágenes de células es una tarea vital en los laboratorios de cualquier campo de las ciencias de la salud. Obtener información de esas imágenes, como el número de células que cumplan una serie de requerimientos, es una tarea muy extendida que se realiza principalmente por técnicos de laboratorio, apoyados frecuentemente por algún tipo de software adaptado a los requerimientos del experimento. En este trabajo planteamos el desarrollo de una plataforma basada en servicios web orientada a problemas de conteo de células. Haciendo uso del framework de desarrollo para servicios web OpenCF integramos en un mismo entorno servicios orientados al procesado y clasificacíon de la imagen, el conteo de las células que cumplan una serie de parámetros y el post-procesado de los datos (generación de gráficas, hojas de datos, etc). Añadimos a dicha plataforma una interfaz gráfica para poder lanzar procesos con conjuntos de imágenes, así como servicios web para la ejecucíon de las distintas tareas desde un cliente orientado a servicios web.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1262</post_id>
		<post_date><![CDATA[2016-05-14 03:53:09]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 01:53:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[plataforma-de-computacion-generica-basada-en-servicios-web-para-problemas-de-conteo-de-celulas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1263]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El procesado y análisis de imágenes de células es una tarea vital en los laboratorios de cualquier campo de las ciencias de la salud. Obtener información de esas imágenes, como el número de células que cumplan una serie de requerimientos, es una tarea muy extendida que se realiza principalmente por técnicos de laboratorio, apoyados frecuentemente por algún tipo de software adaptado a los requerimientos del experimento. En este trabajo planteamos el desarrollo de una plataforma basada en servicios web orientada a problemas de conteo de células. Haciendo uso del framework de desarrollo para servicios web OpenCF integramos en un mismo entorno servicios orientados al procesado y clasificacíon de la imagen, el conteo de las células que cumplan una serie de parámetros y el post-procesado de los datos (generación de gráficas, hojas de datos, etc). Añadimos a dicha plataforma una interfaz gráfica para poder lanzar procesos con conjuntos de imágenes, así como servicios web para la ejecucíon de las distintas tareas desde un cliente orientado a servicios web.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[J. C. Castillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Estadística, Investigacíon Operativa y Computacíon, Universidad de la Laguna, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jcastill@ull.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[F. Almeida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Estadística, Investigacíon Operativa y Computacíon, Universidad de la Laguna, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[falmeida@ull.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[V. Blanco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Estadística, Investigacíon Operativa y Computacíon, Universidad de la Laguna, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[vblanco@ull.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[M.C. Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Estadística, Investigacíon Operativa y Computacíon, Universidad de la Laguna, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Carmen.Ramirez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/006]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Definición y Aplicación de un proceso de Modernización y Evolución al Sistema de Gestión de Nombres de Dominios .es</title>
		<link>https://biblioteca.sistedes.es/articulo/definicion-y-aplicacion-de-un-proceso-de-modernizacion-y-evolucion-al-sistema-de-gestion-de-nombres-de-dominios-es/</link>
		<pubDate>Sat, 14 May 2016 01:56:19 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1265</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1265</post_id>
		<post_date><![CDATA[2016-05-14 03:56:19]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 01:56:19]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[definicion-y-aplicacion-de-un-proceso-de-modernizacion-y-evolucion-al-sistema-de-gestion-de-nombres-de-dominios-es]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1266]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/007]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jorge Moratalla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Clasificación de los Servicios Web de Negocio Corporativos basada en la Funcionalidad Horizontal de las Organizaciones</title>
		<link>https://biblioteca.sistedes.es/articulo/clasificacion-de-los-servicios-web-de-negocio-corporativos-basada-en-la-funcionalidad-horizontal-de-las-organizaciones/</link>
		<pubDate>Sat, 14 May 2016 02:04:04 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1268</guid>
		<description></description>
		<content><![CDATA[Durante los últimos años, la Arquitecturas Orientadas a Servicios (SOA) y la Computación Orienta a Servicios (SOC) se han convertido en áreas de investigación [1-3] que proponen nuevos paradigmas en el tratamiento de la complejidad de las aplicaciones distribuidas. En este contexto, las Arquitecturas Orientadas a Servicios (SOA) son un medio de captura de principios, guías y técnicas que proporcionan un modelo para el desarrollo de estas aplicaciones dentro de una arquitectura. En el desarrollo de 3 proyectos en grandes organizaciones de entre 2000 y 5000 empleados se ha detectado que se pueden mejorar las fases de análisis y diseño de los proyectos que plantean la implantación de arquitecturas empresariales gracias a la aplicación de Frameworks comunes [4-7]. Los proyectos analizados sirven de base como evidencia del buen funcionamiento de la propuesta de este estudio y responden a diferentes casos de negocio tales como la implantación de una arquitectura de movilidad, la reingeniería de la arquitectura de gestión de errores técnicos y de negocio en una organización de "core" de negocio bancario y la implantación de una arquitectura de procesos de negocio en una organización cuyo negocio es la gestión de contenidos.
Actualmente, las metodologías y tipologías existentes son generalistas [8-14], dejando de lado los conceptos más puramente prácticos y cercanos al negocio y las características tecnológicas que rigen las organizaciones.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1268</post_id>
		<post_date><![CDATA[2016-05-14 04:04:04]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 02:04:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[clasificacion-de-los-servicios-web-de-negocio-corporativos-basada-en-la-funcionalidad-horizontal-de-las-organizaciones]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Durante los últimos años, la Arquitecturas Orientadas a Servicios (SOA) y la Computación Orienta a Servicios (SOC) se han convertido en áreas de investigación [1-3] que proponen nuevos paradigmas en el tratamiento de la complejidad de las aplicaciones distribuidas. En este contexto, las Arquitecturas Orientadas a Servicios (SOA) son un medio de captura de principios, guías y técnicas que proporcionan un modelo para el desarrollo de estas aplicaciones dentro de una arquitectura. En el desarrollo de 3 proyectos en grandes organizaciones de entre 2000 y 5000 empleados se ha detectado que se pueden mejorar las fases de análisis y diseño de los proyectos que plantean la implantación de arquitecturas empresariales gracias a la aplicación de Frameworks comunes [4-7]. Los proyectos analizados sirven de base como evidencia del buen funcionamiento de la propuesta de este estudio y responden a diferentes casos de negocio tales como la implantación de una arquitectura de movilidad, la reingeniería de la arquitectura de gestión de errores técnicos y de negocio en una organización de "core" de negocio bancario y la implantación de una arquitectura de procesos de negocio en una organización cuyo negocio es la gestión de contenidos.
Actualmente, las metodologías y tipologías existentes son generalistas [8-14], dejando de lado los conceptos más puramente prácticos y cercanos al negocio y las características tecnológicas que rigen las organizaciones.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel A. González Serrano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Autónoma de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[miguela.gonzalez@estudiante.uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Diana Pérez-Marín]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Rey Juan Carlos, Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[diana.perez@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Miren Idoia Alarcón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Autónoma de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[idoia.alarcon@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1270]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/008]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Guías para el Modelado de Procesos de Negocio</title>
		<link>https://biblioteca.sistedes.es/articulo/guias-para-el-modelado-de-procesos-de-negocio/</link>
		<pubDate>Sat, 14 May 2016 02:08:16 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1271</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1271</post_id>
		<post_date><![CDATA[2016-05-14 04:08:16]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 02:08:16]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[guias-para-el-modelado-de-procesos-de-negocio]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1272]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Laura Sanchez-Gonzalez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francisco Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Félix García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/009]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A proposal on service execution measures for the improvement of business processes realized by services</title>
		<link>https://biblioteca.sistedes.es/articulo/a-proposal-on-service-execution-measures-for-the-improvement-of-business-processes-realized-by-services/</link>
		<pubDate>Sat, 14 May 2016 02:13:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1274</guid>
		<description></description>
		<content><![CDATA[The realization of business processes (BPs) by means of services provides the basis for separating their definition from the technologies that implement them. Services can implement an activity, a sub-process or a complete BP, and can be integrated easily into the BP execution without the interoperability problems that had to be solved formerly for systems to achieve integration. A key aspect for the improvement of BPs is to measure their real execution to assess whether they are performing as expected, including the services realizing them. We have defined a BP Execution Measurement Model (BPEMM) in the context of MINERVA framework for the continuous improvement of BPs, which provides execution measures for BPs implemented by services. In this paper we present our vision for the measurement of services execution -for internal and external services- invoked from BPs.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1274</post_id>
		<post_date><![CDATA[2016-05-14 04:13:50]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 02:13:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-proposal-on-service-execution-measures-for-the-improvement-of-business-processes-realized-by-services]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="business-processservices-improvement"><![CDATA[business process/services improvement]]></category>
		<category domain="post_tag" nicename="execution-measurement"><![CDATA[execution measurement]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1275]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The realization of business processes (BPs) by means of services provides the basis for separating their definition from the technologies that implement them. Services can implement an activity, a sub-process or a complete BP, and can be integrated easily into the BP execution without the interoperability problems that had to be solved formerly for systems to achieve integration. A key aspect for the improvement of BPs is to measure their real execution to assess whether they are performing as expected, including the services realizing them. We have defined a BP Execution Measurement Model (BPEMM) in the context of MINERVA framework for the continuous improvement of BPs, which provides execution measures for BPs implemented by services. In this paper we present our vision for the measurement of services execution -for internal and external services- invoked from BPs.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[business process/services improvement, execution measurement]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Andrea Delgado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Computer Science Institute, Faculty of Engineering, University of the Republica, Julio Herrera y Reissig 565, 11300, Montevideo, Uruguay ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ adelgado@fing.edu.uy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Barbara Weber]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Quality Engineering Research Group, Computer Science Institute, University of Innsbruck, Technikerstraße 21a, 6020, Innsbruck, Austria ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[barbara.weber@uibk.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Institute of Information Technologies and Systems, University of Castilla ­ La Mancha, Camino de Moledores s/n, 13051, Ciudad Real, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[francisco.ruizg@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ignacio García-Rodríguez de Guzmán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Institute of Information Technologies and Systems, University of Castilla ­ La Mancha, Camino de Moledores s/n, 13051, Ciudad Real, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[ignacio.grodriguez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/010]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Feature Modeling to deal with Variability in Business Process Perspectives</title>
		<link>https://biblioteca.sistedes.es/articulo/feature-modeling-to-deal-with-variability-in-business-process-perspectives/</link>
		<pubDate>Sat, 14 May 2016 02:16:14 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1277</guid>
		<description></description>
		<content><![CDATA[The construction of Business Process (BP) models entails big challenges, especially when BPs contain many variations. In addition, BPs can be seen from different perspectives, i.e., the behavioral (i.e., control-flow), the organizational (i.e., resources distribution), or the informational (data-flow) perspectives among others. Depending on the context where the BP is taken place, we may found variability in any of these perspectives. Different approaches to model variability in BP perspectives have already been proposed. However, these approaches are highly tight to the modeling language. In addition, they focus mainly on the behavioral perspective. To deal with variability in other BP perspectives in a more flexible manner, this work proposes an approach based on feature models. These models do not only allow enhancing expressiveness regarding BP variability, but also the maintenance and understanding of the resulting process model.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1277</post_id>
		<post_date><![CDATA[2016-05-14 04:16:14]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 02:16:14]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[feature-modeling-to-deal-with-variability-in-business-process-perspectives]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="business-process-modeling"><![CDATA[Business Process Modeling]]></category>
		<category domain="post_tag" nicename="business-process-variability"><![CDATA[Business Process Variability]]></category>
		<category domain="post_tag" nicename="feature-models"><![CDATA[Feature Models]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1278]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The construction of Business Process (BP) models entails big challenges, especially when BPs contain many variations. In addition, BPs can be seen from different perspectives, i.e., the behavioral (i.e., control-flow), the organizational (i.e., resources distribution), or the informational (data-flow) perspectives among others. Depending on the context where the BP is taken place, we may found variability in any of these perspectives. Different approaches to model variability in BP perspectives have already been proposed. However, these approaches are highly tight to the modeling language. In addition, they focus mainly on the behavioral perspective. To deal with variability in other BP perspectives in a more flexible manner, this work proposes an approach based on feature models. These models do not only allow enhancing expressiveness regarding BP variability, but also the maintenance and understanding of the resulting process model.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Business Process Modeling, Business Process Variability, Feature Models]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/011]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Clara Ayora]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro de Investigacíon en Métodos de Produccíon de Software Universitat Politécnica de Valéncia Camino de Vera s/n, 46022 Valencia, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cayora@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Victoria Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro de Investigacíon en Métodos de Produccíon de Software Universitat Politécnica de Valéncia Camino de Vera s/n, 46022 Valencia, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[vtorres@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro de Investigacíon en Métodos de Produccíon de Software Universitat Politécnica de Valéncia Camino de Vera s/n, 46022 Valencia, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pele@pros.upv.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>PPINOT: A Tool for the Definition and Analysis of Process Performance Indicators</title>
		<link>https://biblioteca.sistedes.es/articulo/ppinot-a-tool-for-the-definition-and-analysis-of-process-performance-indicators/</link>
		<pubDate>Sat, 14 May 2016 02:19:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1280</guid>
		<description></description>
		<content><![CDATA[ key aspect in any process-oriented organisation is the evaluation of process performance for the achievement of its strategic and operational goals. Process Performance Indicators (PPIs) are a key asset to carry out this evaluation, and, therefore, having an appropriate definition of these PPIs is crucial. After a careful review of the literature related and a study of the current picture in different real organisations, we conclude that there not exists any proposal that allows to define PPIs in a way that is unambiguous and highly expressive, understandable by technical and non-technical users and traceable with the business process (BP). Furthermore, it is also increasingly important to provide these PPI definitions with support to automated analysis allowing to extract implicit information from them and their relationships with the BP. In this work we present PPINOT, a tool that allows the graphical definition of PPIs together with their corresponding business processes, and their subsequent automated analysis.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1280</post_id>
		<post_date><![CDATA[2016-05-14 04:19:54]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 02:19:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[ppinot-a-tool-for-the-definition-and-analysis-of-process-performance-indicators]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1281]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[ key aspect in any process-oriented organisation is the evaluation of process performance for the achievement of its strategic and operational goals. Process Performance Indicators (PPIs) are a key asset to carry out this evaluation, and, therefore, having an appropriate definition of these PPIs is crucial. After a careful review of the literature related and a study of the current picture in different real organisations, we conclude that there not exists any proposal that allows to define PPIs in a way that is unambiguous and highly expressive, understandable by technical and non-technical users and traceable with the business process (BP). Furthermore, it is also increasingly important to provide these PPI definitions with support to automated analysis allowing to extract implicit information from them and their relationships with the BP. In this work we present PPINOT, a tool that allows the graphical definition of PPIs together with their corresponding business processes, and their subsequent automated analysis.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/012]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Adela del-Río-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[adeladelrio@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Cristina Cabanillas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cristinacabanillas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Desarrollo de puentes tecnológicos para soportar el modelado de interfaces de servicio</title>
		<link>https://biblioteca.sistedes.es/articulo/desarrollo-de-puentes-tecnologicos-para-soportar-el-modelado-de-interfaces-de-servicio/</link>
		<pubDate>Sat, 14 May 2016 02:25:03 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1283</guid>
		<description></description>
		<content><![CDATA[ Este trabajo presenta el desarrollo de puentes tecnológicos que permiten extraer modelos de Descripciones Abstractas de Servicios a partir de especificaciones WSDL existentes y viceversa. Para ello, se presentan un conjunto de DSLs que se utilizan para la elaboración de algunos modelos intermedios durante el proceso de extracción y las transformaciones de modelos que los conectan, automatizando el proceso. Los modelos obtenidos permiten implementar cualquier proceso de razonamiento acerca de la interfaz de uno o varios servicios utilizando técnicas propias de la Ingeniería Dirigida por Modelos, como transformaciones, validadores, etc. Así, este trabajo proporciona una base tecnológica sobre la que abordar nuevas propuestas metodológicas en el futuro.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1283</post_id>
		<post_date><![CDATA[2016-05-14 04:25:03]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 02:25:03]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[desarrollo-de-puentes-tecnologicos-para-soportar-el-modelado-de-interfaces-de-servicio]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="dsl"><![CDATA[DSL]]></category>
		<category domain="post_tag" nicename="ingenieria-dirigida-por-modelos"><![CDATA[Ingeniería Dirigida por Modelos]]></category>
		<category domain="post_tag" nicename="interfaz-de-servicio"><![CDATA[Interfaz de Servicio]]></category>
		<category domain="post_tag" nicename="transformaciones-de-modelos"><![CDATA[Transformaciones de Modelos]]></category>
		<category domain="post_tag" nicename="wsdl"><![CDATA[WSDL]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1284]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[ Este trabajo presenta el desarrollo de puentes tecnológicos que permiten extraer modelos de Descripciones Abstractas de Servicios a partir de especificaciones WSDL existentes y viceversa. Para ello, se presentan un conjunto de DSLs que se utilizan para la elaboración de algunos modelos intermedios durante el proceso de extracción y las transformaciones de modelos que los conectan, automatizando el proceso. Los modelos obtenidos permiten implementar cualquier proceso de razonamiento acerca de la interfaz de uno o varios servicios utilizando técnicas propias de la Ingeniería Dirigida por Modelos, como transformaciones, validadores, etc. Así, este trabajo proporciona una base tecnológica sobre la que abordar nuevas propuestas metodológicas en el futuro.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[WSDL, Interfaz de Servicio, Ingeniería Dirigida por Modelos, Transformaciones de Modelos, DSL.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jenifer Verde]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jenifer.verde@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan M. Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Veronica Bollati]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[veronica.bollati@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/013]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Abstract Transaction Model for Testing the Web Services Transactions</title>
		<link>https://biblioteca.sistedes.es/articulo/an-abstract-transaction-model-for-testing-the-web-services-transactions/</link>
		<pubDate>Sat, 14 May 2016 02:27:40 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1286</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1286</post_id>
		<post_date><![CDATA[2016-05-14 04:27:40]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 02:27:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-abstract-transaction-model-for-testing-the-web-services-transactions]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1287]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/014]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Aplicación de la técnica de pruebas metamórficas a una composicíon de servicios: Metasearch</title>
		<link>https://biblioteca.sistedes.es/articulo/aplicacion-de-la-tecnica-de-pruebas-metamorficas-a-una-composicion-de-servicios-metasearch/</link>
		<pubDate>Sat, 14 May 2016 02:30:43 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1289</guid>
		<description></description>
		<content><![CDATA[Debido a que las técnicas de prueba tradicionales no están adaptadas a las características peculiares de los servicios web, se hace necesario el diseño de nuevas técnicas que ayuden en este ámbito. En un trabajo previo se propuso las pruebas metamórficas como una técnica válida para aplicar a composiciones de servicios web en WS-BPEL. En este trabajo se aplica la arquitectura propuesta allí a la composicíon de servicios Metasearch, que por su complejidad requiere un análisis detallado. Se incluye el estudio y especificacíon de las relaciones metamórficas para esta composicíon. Así mismo, se añade una comparativa de otras composiciones estudiadas que muestra resultados prometedores.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1289</post_id>
		<post_date><![CDATA[2016-05-14 04:30:43]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 02:30:43]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[aplicacion-de-la-tecnica-de-pruebas-metamorficas-a-una-composicion-de-servicios-metasearch]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="pruebas-metamorficas"><![CDATA[pruebas metamórficas]]></category>
		<category domain="post_tag" nicename="servicios-web"><![CDATA[servicios web]]></category>
		<category domain="post_tag" nicename="ws-bpel"><![CDATA[WS-BPEL]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1290]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Debido a que las técnicas de prueba tradicionales no están adaptadas a las características peculiares de los servicios web, se hace necesario el diseño de nuevas técnicas que ayuden en este ámbito. En un trabajo previo se propuso las pruebas metamórficas como una técnica válida para aplicar a composiciones de servicios web en WS-BPEL. En este trabajo se aplica la arquitectura propuesta allí a la composicíon de servicios Metasearch, que por su complejidad requiere un análisis detallado. Se incluye el estudio y especificacíon de las relaciones metamórficas para esta composicíon. Así mismo, se añade una comparativa de otras composiciones estudiadas que muestra resultados prometedores.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[pruebas metamórficas, servicios web, WS-BPEL]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ma del Carmen de Castro Cabrera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Escuela Superior de Ingeniería C/ Chile 1, CP 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[maricarmen.decastro@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Azahara Camacho Magriñán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Escuela Superior de Ingeniería C/ Chile 1, CP 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[azahara.camachmagri@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Escuela Superior de Ingeniería C/ Chile 1, CP 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/015]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SALMonADA: A Platform for Monitoring and Explaining Violations of WS­Agreement­Compliant</title>
		<link>https://biblioteca.sistedes.es/articulo/salmonada-a-platform-for-monitoring-and-explaining-violations-of-ws%c2%adagreement%c2%adcompliant/</link>
		<pubDate>Sat, 14 May 2016 02:35:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1292</guid>
		<description></description>
		<content><![CDATA[Several research frameworks in both academy and industry aim at monitoring conditions stated in Service Level Agreements (SLAs). However, up to our knowledge, none of them present reasoning capabilities over the SLA with a clear explanation of the concrete statements that violate the agreement. In this paper we present SALMonADA, a platform to monitor SLAs specified with WS­Agreement , that provides agreement violations explanations by pointing both: violated terms of the WS­Agreement document, and violating measures of a monitoring management document.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1292</post_id>
		<post_date><![CDATA[2016-05-14 04:35:15]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 02:35:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[salmonada-a-platform-for-monitoring-and-explaining-violations-of-ws%c2%adagreement%c2%adcompliant]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1293]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Several research frameworks in both academy and industry aim at monitoring conditions stated in Service Level Agreements (SLAs). However, up to our knowledge, none of them present reasoning capabilities over the SLA with a clear explanation of the concrete statements that violate the agreement. In this paper we present SALMonADA, a platform to monitor SLAs specified with WS­Agreement , that provides agreement violations explanations by pointing both: violated terms of the WS­Agreement document, and violating measures of a monitoring management document.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[C. Müller1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville, LSI ISA research group, http://www.isa.us.es/, Seville (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cmuller@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[M. Oriol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Technical University of Catalunya GESSI research group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[moriol@lsi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[M. Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Technical University of Catalunya GESSI research group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mrodrigues@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[X. Franch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Technical University of Catalunya GESSI research group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[franch@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[J. Marco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Technical University of Catalunya GESSI research group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[jmarco@lsi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[M. Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Seville, LSI ISA research group, http://www.isa.us.es/, Seville (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[A. Ruiz­Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[University of Seville, LSI ISA research group, http://www.isa.us.es/, Seville (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/016]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SOA4All Integrated Ranking A Preference-based, Holistic Implementation</title>
		<link>https://biblioteca.sistedes.es/articulo/soa4all-integrated-ranking-a-preference-based-holistic-implementation/</link>
		<pubDate>Sat, 14 May 2016 02:38:19 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1295</guid>
		<description></description>
		<content><![CDATA[There exist many available service ranking implementations, each one providing ad hoc preference models that offer different levels of expressiveness. Consequently, applying a single implementation to a particular scenario constrains the user to define preferences based on the underlying formalisms. Furthermore, preferences from different ranking implementation's model cannot be combined in general, due to interoperability issues. In this article we present an integrated ranking implementation that enables the combination of three different ranking implementations developed within the EU FP7 SOA4All project. Our solution has been developed using PURI, a Preference-based Universal Ranking Integration framework that is based on a common, holistic preference model that allows to exploit synergies from the integrated ranking implementations, offering a single user interface to define preferences that acts as a fa¸cade to the integrated ranking implementation.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1295</post_id>
		<post_date><![CDATA[2016-05-14 04:38:19]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 02:38:19]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[soa4all-integrated-ranking-a-preference-based-holistic-implementation]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="preference-models"><![CDATA[Preference Models]]></category>
		<category domain="post_tag" nicename="ranking-tools"><![CDATA[Ranking Tools]]></category>
		<category domain="post_tag" nicename="semantic-web-services"><![CDATA[Semantic Web Services]]></category>
		<category domain="post_tag" nicename="systems-integration"><![CDATA[Systems Integration]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1296]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[There exist many available service ranking implementations, each one providing ad hoc preference models that offer different levels of expressiveness. Consequently, applying a single implementation to a particular scenario constrains the user to define preferences based on the underlying formalisms. Furthermore, preferences from different ranking implementation's model cannot be combined in general, due to interoperability issues. In this article we present an integrated ranking implementation that enables the combination of three different ranking implementations developed within the EU FP7 SOA4All project. Our solution has been developed using PURI, a Preference-based Universal Ranking Integration framework that is based on a common, holistic preference model that allows to exploit synergies from the integrated ranking implementations, offering a single user interface to define preferences that acts as a fa¸cade to the integrated ranking implementation.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Semantic Web Services, Ranking Tools, Systems Integration, Preference Models]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José María García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville Escuela Técnica Superior de Ingeniería Informática Av. Reina Mercedes s/n, 41012 Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[josemgarcia@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville Escuela Técnica Superior de Ingeniería Informática Av. Reina Mercedes s/n, 41012 Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville Escuela Técnica Superior de Ingeniería Informática Av. Reina Mercedes s/n, 41012 Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/017]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Synthesis of Secure Adaptors</title>
		<link>https://biblioteca.sistedes.es/articulo/synthesis-of-secure-adaptors/</link>
		<pubDate>Sat, 14 May 2016 02:41:34 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1298</guid>
		<description></description>
		<content><![CDATA[Security is considered one of the main challenges for software oriented architectures (SOA) [1,2]. For this reason, several standards have been developed around WS-Security. However, these security standards usually hinder interoperability, one of the main pillars of Web service technologies. Software adaptation [3] is a sound solution where an adaptor is deployed in the middle of the communication to overcome signature, behavioural and QoS incompatibilities between services. This is particularly important when dealing with stateful services (such as Windows Workflows or WS-BPEL processes) where any mismatch in the sequence of messages might lead the orchestration to a deadlock situation. We proposed security adaptation contracts [4] as concise and versatile specifications of how such incompatibilities must be solved. Nonetheless, synthesising an adaptor compliant with a given contract is not an easy task where concurrency issues must be kept in mind and security attacks must be analysed and prevented. In this paper, we present an adaptor synthesis, verification and refinement process based on security adaptation contracts which succeeds in overcoming incompatibilities among services and prevents secrecy attacks. We extended the ITACA toolbox [5] for synthesis and deadlock analysis and we integrated it with a variant of CCS [6], called Crypto-CCS [7], to verify and refine adaptors based on partial model checking and logical satisfiability techniques.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1298</post_id>
		<post_date><![CDATA[2016-05-14 04:41:34]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 02:41:34]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[synthesis-of-secure-adaptors]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1299]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Security is considered one of the main challenges for software oriented architectures (SOA) [1,2]. For this reason, several standards have been developed around WS-Security. However, these security standards usually hinder interoperability, one of the main pillars of Web service technologies. Software adaptation [3] is a sound solution where an adaptor is deployed in the middle of the communication to overcome signature, behavioural and QoS incompatibilities between services. This is particularly important when dealing with stateful services (such as Windows Workflows or WS-BPEL processes) where any mismatch in the sequence of messages might lead the orchestration to a deadlock situation. We proposed security adaptation contracts [4] as concise and versatile specifications of how such incompatibilities must be solved. Nonetheless, synthesising an adaptor compliant with a given contract is not an easy task where concurrency issues must be kept in mind and security attacks must be analysed and prevented. In this paper, we present an adaptor synthesis, verification and refinement process based on security adaptation contracts which succeeds in overcoming incompatibilities among services and prevents secrecy attacks. We extended the ITACA toolbox [5] for synthesis and deadlock analysis and we integrated it with a variant of CCS [6], called Crypto-CCS [7], to verify and refine adaptors based on partial model checking and logical satisfiability techniques.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[J.A. Martín]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[E.T.S. Ingeniería Informática, Universidad de Málaga, Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jamartin@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[F. Martinelli]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Istituto di Informatica e Telematica, National Research Council, Pisa, Italy ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Fabio.Martinelli@iit.cnr.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[E. Pimentel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[E.T.S. Ingeniería Informática, Universidad de Málaga, Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ernesto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/018]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Detección de Ataques de Seguridad mediante la Integración de CEP y SOA 2.0</title>
		<link>https://biblioteca.sistedes.es/articulo/deteccion-de-ataques-de-seguridad-mediante-la-integracion-de-cep-y-soa-2-0/</link>
		<pubDate>Sat, 14 May 2016 02:49:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1301</guid>
		<description></description>
		<content><![CDATA[La seguridad informática cada día cobra mayor importancia debido al incremento de ataques que se realizan tanto para intentar acceder a los datos críticos como para detener procesos esenciales en los sistemas. Así pues, la detección temprana de estos ataques es fundamental para asegurar la integridad, disponibilidad y confidencialidad de la información. En este artículo desarrollamos un sistema que integra SOA 2.0 junto con un motor de procesamiento de eventos complejos (CEP) y un sistema de detección de intrusiones (IDS) para detectar inmediatamente las amenazas de seguridad que se produzcan en sistemas complejos y heterogéneos, así como ponerlas en conocimiento a los responsables de seguridad. Estos tomarán las medidas oportunas para reducir el impacto de estas situaciones. Los resultados experimentales obtenidos demuestran que nuestro enfoque, que integra SOA 2.0 con CEP e IDS, es una buena alternativa para el campo de la seguridad informática.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1301</post_id>
		<post_date><![CDATA[2016-05-14 04:49:48]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 02:49:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[deteccion-de-ataques-de-seguridad-mediante-la-integracion-de-cep-y-soa-2-0]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="amenaza"><![CDATA[amenaza]]></category>
		<category domain="post_tag" nicename="cep"><![CDATA[CEP]]></category>
		<category domain="post_tag" nicename="ids"><![CDATA[IDS]]></category>
		<category domain="post_tag" nicename="seguridad"><![CDATA[seguridad]]></category>
		<category domain="post_tag" nicename="snort"><![CDATA[Snort]]></category>
		<category domain="post_tag" nicename="soa-2-0"><![CDATA[SOA 2.0]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1302]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La seguridad informática cada día cobra mayor importancia debido al incremento de ataques que se realizan tanto para intentar acceder a los datos críticos como para detener procesos esenciales en los sistemas. Así pues, la detección temprana de estos ataques es fundamental para asegurar la integridad, disponibilidad y confidencialidad de la información. En este artículo desarrollamos un sistema que integra SOA 2.0 junto con un motor de procesamiento de eventos complejos (CEP) y un sistema de detección de intrusiones (IDS) para detectar inmediatamente las amenazas de seguridad que se produzcan en sistemas complejos y heterogéneos, así como ponerlas en conocimiento a los responsables de seguridad. Estos tomarán las medidas oportunas para reducir el impacto de estas situaciones. Los resultados experimentales obtenidos demuestran que nuestro enfoque, que integra SOA 2.0 con CEP e IDS, es una buena alternativa para el campo de la seguridad informática.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[CEP, seguridad, amenaza, IDS, Snort, SOA 2.0.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jose Antonio Dorado Cerón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, C/Chile 1, 11002 Cádiz, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jose.doradoce@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, C/Chile 1, 11002 Cádiz, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, C/Chile 1, 11002 Cádiz, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, C/Chile 1, 11002 Cádiz, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/019]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>RAL Solver: a Tool to Facilitate Resource Management in Business Process Models</title>
		<link>https://biblioteca.sistedes.es/articulo/ral-solver-a-tool-to-facilitate-resource-management-in-business-process-models/</link>
		<pubDate>Sat, 14 May 2016 02:55:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1304</guid>
		<description></description>
		<content><![CDATA[Business process (BP) modelling notations tend to stray their attention from resource management, unlike other aspects such as control flow or even data flow. On the one hand, the languages they offer to assign resources to BP activities are usually either little expressive, or hard to use for non-technical users. On the other hand, they barely care about the subsequent analysis of resource assignments, which would enable the detection of problems and/or inefficiency in the use of the resources available in a company. We present RAL Solver, a tool that addresses the two aforementioned issues, and thus: (i) allows the specification of assignments of resources to BP activities in a reasonably simple way; and (ii) provides capabilities to automatically analyse resource assignments at design time, which allows extracting information from BP models, and detecting inconsistencies and assignment conflicts.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1304</post_id>
		<post_date><![CDATA[2016-05-14 04:55:09]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 02:55:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[ral-solver-a-tool-to-facilitate-resource-management-in-business-process-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1305]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Business process (BP) modelling notations tend to stray their attention from resource management, unlike other aspects such as control flow or even data flow. On the one hand, the languages they offer to assign resources to BP activities are usually either little expressive, or hard to use for non-technical users. On the other hand, they barely care about the subsequent analysis of resource assignments, which would enable the detection of problems and/or inefficiency in the use of the resources available in a company. We present RAL Solver, a tool that addresses the two aforementioned issues, and thus: (i) allows the specification of assignments of resources to BP activities in a reasonably simple way; and (ii) provides capabilities to automatically analyse resource assignments at design time, which allows extracting information from BP models, and detecting inconsistencies and assignment conflicts.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cristina Cabanillas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cristinacabanillas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Adela del-Río-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[adeladelrio@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/020]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Summary of &quot;Defining and Analysing Resource Assignments in Business Processes with RAL&quot;</title>
		<link>https://biblioteca.sistedes.es/articulo/summary-of-defining-and-analysing-resource-assignments-in-business-processes-with-ral/</link>
		<pubDate>Sat, 14 May 2016 03:00:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1307</guid>
		<description></description>
		<content><![CDATA[Business processes (BPs) are often analysed in terms of control flow, temporal constraints, data and resources. From all of these aspects, resources have received much less attention than other aspects, specially control flow. Even the standard BP modelling notation (BPMN) does not provide concrete definitions for the resource-related concepts [2]. However, the participation of people in BPs is of utmost importance, both to supervise the execution of automatic activities and to carry out software-aided and/or manual tasks. Therefore, they should be considered when designing and modelling the BPs used in an organization.
In this paper we face human-resource management (resource management for short) in BP models. Firstly, we deal with the assignment of resources to the activities of a BP model, aiming at easing and improving the way resources can be associated with BP activities. Some approaches addressing a similar purpose have been introduced in the last years [3­5], but they are in general either too complex to be used by technically unskilled people, or not expressive enough to provide powerful resource management in workflows (WFs) and BPs.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1307</post_id>
		<post_date><![CDATA[2016-05-14 05:00:09]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 03:00:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[summary-of-defining-and-analysing-resource-assignments-in-business-processes-with-ral]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1308]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Business processes (BPs) are often analysed in terms of control flow, temporal constraints, data and resources. From all of these aspects, resources have received much less attention than other aspects, specially control flow. Even the standard BP modelling notation (BPMN) does not provide concrete definitions for the resource-related concepts [2]. However, the participation of people in BPs is of utmost importance, both to supervise the execution of automatic activities and to carry out software-aided and/or manual tasks. Therefore, they should be considered when designing and modelling the BPs used in an organization.
In this paper we face human-resource management (resource management for short) in BP models. Firstly, we deal with the assignment of resources to the activities of a BP model, aiming at easing and improving the way resources can be associated with BP activities. Some approaches addressing a similar purpose have been introduced in the last years [3­5], but they are in general either too complex to be used by technically unskilled people, or not expressive enough to provide powerful resource management in workflows (WFs) and BPs.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cristina Cabanillas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cristinacabanillas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/021]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Crossing the Software Education Chasm using Software-as-a-Service and Cloud Computing</title>
		<link>https://biblioteca.sistedes.es/articulo/crossing-the-software-education-chasm-using-software-as-a-service-and-cloud-computing/</link>
		<pubDate>Sat, 14 May 2016 03:04:17 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1310</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1310</post_id>
		<post_date><![CDATA[2016-05-14 05:04:17]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 03:04:17]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[crossing-the-software-education-chasm-using-software-as-a-service-and-cloud-computing]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Prof. Armando Fox]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Computer Science Division, University of California, Berkeley]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fox@cs.berkeley.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2012/022]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A formalization in Coq of Launchbury~s natural semantics for lazy evaluation</title>
		<link>https://biblioteca.sistedes.es/articulo/a-formalization-in-coq-of-launchburys-natural-semantics-for-lazy-evaluation/</link>
		<pubDate>Sat, 14 May 2016 16:26:58 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1326</guid>
		<description></description>
		<content><![CDATA[We are working on the implementation of Launchbury~s semantics for lazy evaluation in the proof assistant Coq. We use a locally nameless representation where names are reserved for free variables, while bound variable names are replaced by indices. This avoids the need of -conversion and Barendregt~s variable convention, and facilitates the formalization in Coq. Simultaneous recursive local declarations in the calculus require the management of multibinders and the use of mutually inductive types.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1326</post_id>
		<post_date><![CDATA[2016-05-14 18:26:58]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 16:26:58]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-formalization-in-coq-of-launchburys-natural-semantics-for-lazy-evaluation]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="coq"><![CDATA[Coq]]></category>
		<category domain="post_tag" nicename="formalization"><![CDATA[Formalization]]></category>
		<category domain="post_tag" nicename="lazy-evaluation"><![CDATA[lazy evaluation]]></category>
		<category domain="post_tag" nicename="locally-nameless-representation"><![CDATA[locally nameless representation]]></category>
		<category domain="post_tag" nicename="natural-semantics"><![CDATA[natural semantics]]></category>
		<category domain="post_tag" nicename="proof-assistant"><![CDATA[proof assistant]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1327]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We are working on the implementation of Launchbury~s semantics for lazy evaluation in the proof assistant Coq. We use a locally nameless representation where names are reserved for free variables, while bound variable names are replaced by indices. This avoids the need of -conversion and Barendregt~s variable convention, and facilitates the formalization in Coq. Simultaneous recursive local declarations in the calculus require the management of multibinders and the use of mutually inductive types.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Formalization, locally nameless representation, proof assistant, Coq, natural semantics, lazy evaluation]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Lidia Sánchez-Gil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpt. Sistemas Informáticos y Computación, Facultad de CC. Matemáticas, Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[lidiasg@mat.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mercedes Hidalgo-Herrero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpt. Didáctica de las Matemáticas, Facultad de Educación, Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mhidalgo@edu.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Yolanda Ortega-Mallén]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpt. Sistemas Informáticos y Computación, Facultad de CC. Matemáticas, Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[yolanda@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/001]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Improving the Performance of FD Constraint Solving in a CFLP System</title>
		<link>https://biblioteca.sistedes.es/articulo/improving-the-performance-of-fd-constraint-solving-in-a-cflp-system/</link>
		<pubDate>Sat, 14 May 2016 16:31:30 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1329</guid>
		<description></description>
		<content><![CDATA[Constraint Functional Logic Programming (CFLP) integrates lazy narrowing with constraint solving. It provides a high modeling abstraction, but its solving performance can be penalized by lazy narrowing and solver interface surcharges. As for real-world problems most of the solving time is carried out by solver computations, the system performance can be improved by interfacing state-of-theart external solvers with proven performance. In this work we consider the CFLP system T OY (F D), implemented in SICStus Prolog and supporting Finite Domain (F D) constraints by using its underlying Prolog F D solver. We present a scheme describing how to interface an external CP(F D) solver to T OY (F D), and easily adaptable to other Prolog CLP or CFLP systems. We prove the scheme to be generic enough by interfacing Gecode and ILOG solvers, and we analyze the new performance achieved.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1329</post_id>
		<post_date><![CDATA[2016-05-14 18:31:30]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 16:31:30]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[improving-the-performance-of-fd-constraint-solving-in-a-cflp-system]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="constraint-functional-logic-programming"><![CDATA[Constraint Functional Logic Programming]]></category>
		<category domain="post_tag" nicename="finite-domains-constraint-solving"><![CDATA[Finite Domains Constraint Solving]]></category>
		<category domain="post_tag" nicename="solver-integration"><![CDATA[Solver Integration]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1330]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Constraint Functional Logic Programming (CFLP) integrates lazy narrowing with constraint solving. It provides a high modeling abstraction, but its solving performance can be penalized by lazy narrowing and solver interface surcharges. As for real-world problems most of the solving time is carried out by solver computations, the system performance can be improved by interfacing state-of-theart external solvers with proven performance. In this work we consider the CFLP system T OY (F D), implemented in SICStus Prolog and supporting Finite Domain (F D) constraints by using its underlying Prolog F D solver. We present a scheme describing how to interface an external CP(F D) solver to T OY (F D), and easily adaptable to other Prolog CLP or CFLP systems. We prove the scheme to be generic enough by interfacing Gecode and ILOG solvers, and we analyze the new performance achieved.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Constraint Functional Logic Programming, Finite Domains Constraint Solving, Solver Integration]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ignacio Castiñeiras]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dept. Sistemas Informáticos y Computación Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ncasti@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando Sáenz-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Ingeniería del Software e Inteligencia Artificial Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fernan@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/002]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Tecnología funcional en aplicaciones de televisión interactiva: acceso a redes sociales desde Synthetrick</title>
		<link>https://biblioteca.sistedes.es/articulo/tecnologia-funcional-en-aplicaciones-de-television-interactiva-acceso-a-redes-sociales-desde-synthetrick/</link>
		<pubDate>Sat, 14 May 2016 16:34:47 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1332</guid>
		<description></description>
		<content><![CDATA[En este artículo presentamos una alternativa, basada en el uso de tecnología funcional, al desarrollo e implantación tradicionales de contenidos interactivos para televisión digital. Lo hacemos presentando el desarrollo de Synthsocial, un servicio interactivo de entretenimiento que ofrece acceso a diferentes redes sociales desde la plataforma Synthetrick.
En su concepción original, los servicios interactivos se ejecutan en los set-top boxes (STB), dispositivos instalados por el operador en el hogar del cliente. Con este modelo, el flujo de vídeo se genera y reproduce de forma local directamente en los STB del lado del cliente. Esto presenta graves problemas de dependencia de la plataforma específica y de interoperabilidad con otras distintas, entre otros.
Como solución a dichos problemas, la plataforma Synthetrick propone el uso de un servidor de recursos sintéticos. Con este nuevo enfoque, las aplicaciones se ejecutan en el lado del servidor, donde se genera el flujo de vídeo (conocido como vídeo sintético) que posteriormente es recibido y directamente reproducido por el STB. Los STB, a su vez, interactúan con el servidor enviándole las entradas introducidas por el usuario para que sean tenidas en cuenta en la generación del contenido que se le está presentando al consumidor.
Utilizando como caso de estudio el servicio Synthsocial, no sólo mostramos las ventajas de esta aproximación, sino que recomendamos y discutimos la arquitectura óptima para este tipo de innovadores servicios interactivos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1332</post_id>
		<post_date><![CDATA[2016-05-14 18:34:47]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 16:34:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[tecnologia-funcional-en-aplicaciones-de-television-interactiva-acceso-a-redes-sociales-desde-synthetrick]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="erlang"><![CDATA[Erlang]]></category>
		<category domain="post_tag" nicename="programacion-funcional"><![CDATA[programación funcional]]></category>
		<category domain="post_tag" nicename="servicios-interactivos"><![CDATA[servicios interactivos]]></category>
		<category domain="post_tag" nicename="synthetrick"><![CDATA[synthetrick]]></category>
		<category domain="post_tag" nicename="television-interactiva"><![CDATA[televisión interactiva]]></category>
		<category domain="post_tag" nicename="video-sintetico"><![CDATA[vídeo sintético]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1333]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/003]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este artículo presentamos una alternativa, basada en el uso de tecnología funcional, al desarrollo e implantación tradicionales de contenidos interactivos para televisión digital. Lo hacemos presentando el desarrollo de Synthsocial, un servicio interactivo de entretenimiento que ofrece acceso a diferentes redes sociales desde la plataforma Synthetrick.
En su concepción original, los servicios interactivos se ejecutan en los set-top boxes (STB), dispositivos instalados por el operador en el hogar del cliente. Con este modelo, el flujo de vídeo se genera y reproduce de forma local directamente en los STB del lado del cliente. Esto presenta graves problemas de dependencia de la plataforma específica y de interoperabilidad con otras distintas, entre otros.
Como solución a dichos problemas, la plataforma Synthetrick propone el uso de un servidor de recursos sintéticos. Con este nuevo enfoque, las aplicaciones se ejecutan en el lado del servidor, donde se genera el flujo de vídeo (conocido como vídeo sintético) que posteriormente es recibido y directamente reproducido por el STB. Los STB, a su vez, interactúan con el servidor enviándole las entradas introducidas por el usuario para que sean tenidas en cuenta en la generación del contenido que se le está presentando al consumidor.
Utilizando como caso de estudio el servicio Synthsocial, no sólo mostramos las ventajas de esta aproximación, sino que recomendamos y discutimos la arquitectura óptima para este tipo de innovadores servicios interactivos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[televisión interactiva, servicios interactivos, vídeo sintético, programación funcional, erlang, synthetrick]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Duque]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo MADS ­ Departamento de Computación Universidade da Coruña (A Coruña, España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[david.duque@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Laura M. Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo MADS ­ Departamento de Computación Universidade da Coruña (A Coruña, España)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[lcastro@udc.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Lightweight compilation of (C)LP to JavaScript</title>
		<link>https://biblioteca.sistedes.es/articulo/lightweight-compilation-of-clp-to-javascript/</link>
		<pubDate>Sat, 14 May 2016 16:39:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1335</guid>
		<description></description>
		<content><![CDATA[We present and evaluate a compiler from Prolog (extensions) to JavaScript which makes it possible to use (constraint) logic programming to develop the client side of web applications while being compliant with current industry standards. Targeting JavaScript makes (C)LP programs executable in virtually every modern computing device with no additional software requirements from the point of view of the user. In turn, the use of a very high-level language facilitates the development of high-quality, complex software. The compiler is a back end of the Ciao system and supports most of its features, including its module system and extension mechanism. We demonstrate the maturity of the compiler by testing it with complex code such as a CLP(FD) library written in Prolog with attributed variables. Finally, we validate our proposal by measuring the performance of some LP and CLP(FD) benchmarks running on top of major JavaScript engines.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1335</post_id>
		<post_date><![CDATA[2016-05-14 18:39:48]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 16:39:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[lightweight-compilation-of-clp-to-javascript]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="ciao"><![CDATA[Ciao]]></category>
		<category domain="post_tag" nicename="implementation-of-prolog"><![CDATA[Implementation of Prolog]]></category>
		<category domain="post_tag" nicename="javascript"><![CDATA[JavaScript]]></category>
		<category domain="post_tag" nicename="logic-programming-system"><![CDATA[Logic Programming System]]></category>
		<category domain="post_tag" nicename="modules"><![CDATA[Modules]]></category>
		<category domain="post_tag" nicename="prolog"><![CDATA[Prolog]]></category>
		<category domain="post_tag" nicename="web"><![CDATA[Web]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1336]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/004]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We present and evaluate a compiler from Prolog (extensions) to JavaScript which makes it possible to use (constraint) logic programming to develop the client side of web applications while being compliant with current industry standards. Targeting JavaScript makes (C)LP programs executable in virtually every modern computing device with no additional software requirements from the point of view of the user. In turn, the use of a very high-level language facilitates the development of high-quality, complex software. The compiler is a back end of the Ciao system and supports most of its features, including its module system and extension mechanism. We demonstrate the maturity of the compiler by testing it with complex code such as a CLP(FD) library written in Prolog with attributed variables. Finally, we validate our proposal by measuring the performance of some LP and CLP(FD) benchmarks running on top of major JavaScript engines.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Prolog, Ciao, Logic Programming System, Implementation of Prolog, Modules, JavaScript, Web]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jose F. Morales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute, Madrid (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[josef.morales@imdea.org ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Rémy Haemmerlé]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[School of Computer Science, Technical University of Madrid (UPM), (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[remy@clip.dia.fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Carro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute, Madrid (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuel.carro@imdea.org ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel V. Hermenegildo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute, Madrid (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manuel.hermenegildo@imdea.org ]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Mejora del rendimiento de la depuración declarativa mediante expansión y compresión de bucles</title>
		<link>https://biblioteca.sistedes.es/articulo/mejora-del-rendimiento-de-la-depuracion-declarativa-mediante-expansion-y-compresion-de-bucles/</link>
		<pubDate>Sat, 14 May 2016 16:42:56 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1338</guid>
		<description></description>
		<content><![CDATA[Uno de los principales objetivos en la depuración es reducir al máximo el tiempo necesario para encontrar los errores. En la depuración declarativa este tiempo depende en gran medida del número de preguntas realizadas al usuario por el depurador y, por tanto, reducir el número de preguntas generadas es un objetivo prioritario. En este trabajo demostramos que transformar los bucles del programa a depurar puede tener una influencia importante sobre el rendimiento del depurador. Concretamente, introducimos dos algoritmos que expanden y comprimen la representación interna utilizada por los depuradores declarativos para representar bucles. El resultado es una serie de transformaciones que pueden realizarse automáticamente antes de que el usuario intervenga en la depuración y que producen una mejora considerable a un coste muy bajo. ]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1338</post_id>
		<post_date><![CDATA[2016-05-14 18:42:56]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 16:42:56]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mejora-del-rendimiento-de-la-depuracion-declarativa-mediante-expansion-y-compresion-de-bucles]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="a-rbol-de-ejecucion"><![CDATA[á rbol de ejecución]]></category>
		<category domain="post_tag" nicename="depuracion-declarativa"><![CDATA[Depuración declarativa]]></category>
		<category domain="post_tag" nicename="loop-expansion"><![CDATA[Loop Expansion]]></category>
		<category domain="post_tag" nicename="tree-compression"><![CDATA[Tree Compression]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1339]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/005]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Uno de los principales objetivos en la depuración es reducir al máximo el tiempo necesario para encontrar los errores. En la depuración declarativa este tiempo depende en gran medida del número de preguntas realizadas al usuario por el depurador y, por tanto, reducir el número de preguntas generadas es un objetivo prioritario. En este trabajo demostramos que transformar los bucles del programa a depurar puede tener una influencia importante sobre el rendimiento del depurador. Concretamente, introducimos dos algoritmos que expanden y comprimen la representación interna utilizada por los depuradores declarativos para representar bucles. El resultado es una serie de transformaciones que pueden realizarse automáticamente antes de que el usuario intervenga en la depuración y que producen una mejora considerable a un coste muy bajo. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Depuración declarativa, á rbol de ejecución, Tree Compression, Loop Expansion]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Insa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia Camino de Vera s/n, E-46022 Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[dinsa@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Josep Silva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia Camino de Vera s/n, E-46022 Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jsilva@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[César Tomás]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia Camino de Vera s/n, E-46022 Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ctomas@dsic.upv.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Paralldroid: a source to source translator for development of native AndroidTM applications.</title>
		<link>https://biblioteca.sistedes.es/articulo/paralldroid-a-source-to-source-translator-for-development-of-native-androidtm-applications/</link>
		<pubDate>Sat, 14 May 2016 16:47:04 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1341</guid>
		<description></description>
		<content><![CDATA[The advent of emergent SoCs and MPSocs opens a new era on the small mobile devices (Smartphones, Tablets, ...) in terms of computing capabilities and applications to be addressed. The efficient use of such devices, including the parallel power, is still a challenge for general purpose programmers due to the very high learning curve demanding very specific knowledge of the devices. While some efforts are currently being made, mainly in the scientific scope, the scenario is still quite far from being the desirable for non-scientific applications where very few applications take advantage of the parallel capabilities of the devices. We propose ParallDroid (Framework for Parallelism in AndroidTM), a parallel development framework oriented to general purpose programmers for standard mobile devices. Paralldroid allows the rapid development of Native Android applications. The user just implements a Java class and introduces Paralldroid annotations. The Paralldroid system automatically generates the C/C ++/OpenCL native code for this class. Paralldroid is provided as a plugin integrated in the eclipse IDE, and it works transparently to the user. The ParallDroid transformation model involves source-to-source transformations and skeletal programming. A proof of concept is presented to test the feasibility, productivity and efficiency of the approach on synthetic applications.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1341</post_id>
		<post_date><![CDATA[2016-05-14 18:47:04]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 16:47:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[paralldroid-a-source-to-source-translator-for-development-of-native-androidtm-applications]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="android"><![CDATA[Android]]></category>
		<category domain="post_tag" nicename="soc"><![CDATA[SoC]]></category>
		<category domain="post_tag" nicename="source-to-source-transformation"><![CDATA[source-to-source transformation]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1342]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/006]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The advent of emergent SoCs and MPSocs opens a new era on the small mobile devices (Smartphones, Tablets, ...) in terms of computing capabilities and applications to be addressed. The efficient use of such devices, including the parallel power, is still a challenge for general purpose programmers due to the very high learning curve demanding very specific knowledge of the devices. While some efforts are currently being made, mainly in the scientific scope, the scenario is still quite far from being the desirable for non-scientific applications where very few applications take advantage of the parallel capabilities of the devices. We propose ParallDroid (Framework for Parallelism in AndroidTM), a parallel development framework oriented to general purpose programmers for standard mobile devices. Paralldroid allows the rapid development of Native Android applications. The user just implements a Java class and introduces Paralldroid annotations. The Paralldroid system automatically generates the C/C ++/OpenCL native code for this class. Paralldroid is provided as a plugin integrated in the eclipse IDE, and it works transparently to the user. The ParallDroid transformation model involves source-to-source transformations and skeletal programming. A proof of concept is presented to test the feasibility, productivity and efficiency of the approach on synthetic applications.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[SoC, Android, source-to-source transformation]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alejandro Acosta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpt. Statistics and Computer Science, La Laguna University, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francisco Almeida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpt. Statistics and Computer Science, La Laguna University, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Vicente Blanco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpt. Statistics and Computer Science, La Laguna University, Spain]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Tabling with Support for Relational Features in a Deductive Database</title>
		<link>https://biblioteca.sistedes.es/articulo/tabling-with-support-for-relational-features-in-a-deductive-database/</link>
		<pubDate>Sat, 14 May 2016 17:19:19 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1344</guid>
		<description></description>
		<content><![CDATA[Tabling has been acknowledged as a useful technique in the logic programming arena for enhancing both performance and declarative properties of programs. As well, deductive database implementations benefit from this technique for implementing query solving engines. In this paper, we show how unusual operations in deductive systems can be integrated with tabling. Such operations come from relational database systems in the form of null-related (outer) joins, duplicate support and duplicate elimination. The proposal has been implemented as a proof of concept rather than an efficient system in the Datalog Educational System (DES) using Prolog as a development language and its dynamic database.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1344</post_id>
		<post_date><![CDATA[2016-05-14 19:19:19]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 17:19:19]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[tabling-with-support-for-relational-features-in-a-deductive-database]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="deductive-databases"><![CDATA[Deductive databases]]></category>
		<category domain="post_tag" nicename="des"><![CDATA[DES]]></category>
		<category domain="post_tag" nicename="duplicates"><![CDATA[Duplicates]]></category>
		<category domain="post_tag" nicename="outer-joins"><![CDATA[Outer Joins]]></category>
		<category domain="post_tag" nicename="relational-databases"><![CDATA[Relational databases]]></category>
		<category domain="post_tag" nicename="tabling"><![CDATA[Tabling]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1345]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/007]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Tabling has been acknowledged as a useful technique in the logic programming arena for enhancing both performance and declarative properties of programs. As well, deductive database implementations benefit from this technique for implementing query solving engines. In this paper, we show how unusual operations in deductive systems can be integrated with tabling. Such operations come from relational database systems in the form of null-related (outer) joins, duplicate support and duplicate elimination. The proposal has been implemented as a proof of concept rather than an efficient system in the Datalog Educational System (DES) using Prolog as a development language and its dynamic database.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Tabling, Outer Joins, Duplicates, Relational databases, Deductive databases, DES]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Fernando Sáenz-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de programación declarativa (GPD), Dept. Ingeniería del Software e Inteligencia Artificial, Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Test-Case Generation for SQL Nested Queries with Existential Conditions</title>
		<link>https://biblioteca.sistedes.es/articulo/test-case-generation-for-sql-nested-queries-with-existential-conditions/</link>
		<pubDate>Sat, 14 May 2016 17:27:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1354</guid>
		<description></description>
		<content><![CDATA[This paper presents a test-case generator for SQL queries. Starting with a set of related SQL views that can include existential subqueries in the conditions, the technique finds a database instance that can be used as a test-case for the target view. The proposal reduces the problem of generating the test-cases to a Constraint Satisfaction Problem using finite domain constraints. In particular, we present a new approach for existential conditions that makes possible to find test-cases for a wider set of queries. The soundness and correctness of the technique with respect to a simple operational semantics for SQL queries without aggregates is proven. The theoretical ideas have been implemented in an available prototype.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1354</post_id>
		<post_date><![CDATA[2016-05-14 19:27:49]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 17:27:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[test-case-generation-for-sql-nested-queries-with-existential-conditions]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="constraints"><![CDATA[constraints]]></category>
		<category domain="post_tag" nicename="finite-domains"><![CDATA[finite domains]]></category>
		<category domain="post_tag" nicename="sql"><![CDATA[SQL]]></category>
		<category domain="post_tag" nicename="test-cases"><![CDATA[Test-cases]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1355]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/008]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper presents a test-case generator for SQL queries. Starting with a set of related SQL views that can include existential subqueries in the conditions, the technique finds a database instance that can be used as a test-case for the target view. The proposal reduces the problem of generating the test-cases to a Constraint Satisfaction Problem using finite domain constraints. In particular, we present a new approach for existential conditions that makes possible to find test-cases for a wider set of queries. The soundness and correctness of the technique with respect to a simple operational semantics for SQL queries without aggregates is proven. The theoretical ideas have been implemented in an available prototype.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[SQL, Test-cases, constraints, finite domains]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rafael Caballero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rafa@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Luzón-Martín]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jose.11.10.88@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Tenorio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[senrof21@gmail.com ]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Debugging Fuzzy XPath Queries</title>
		<link>https://biblioteca.sistedes.es/articulo/debbuging-fuzzy-xpath-queries/</link>
		<pubDate>Sat, 14 May 2016 17:46:30 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1357</guid>
		<description></description>
		<content><![CDATA[n this paper we report a preliminary work about XPath debugging. We will describe how we can manipulate an XPath expression in order to obtain a set of alternative XPath expressions that match to a given XML document. For each alternative XPath expression we will give a chance degree that represents the degree in which the expression deviates from the initial expression. Thus, our work is focused on providing the programmer a repertoire of paths that (s)he can use to retrieve answers. The approach has been implemented and tested.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1357</post_id>
		<post_date><![CDATA[2016-05-14 19:46:30]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 17:46:30]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[debbuging-fuzzy-xpath-queries]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="debugging"><![CDATA[Debugging]]></category>
		<category domain="post_tag" nicename="fuzzy-multi-adjoint-logic-programming"><![CDATA[Fuzzy (Multi-adjoint) Logic Programming]]></category>
		<category domain="post_tag" nicename="xpath"><![CDATA[XPath]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1358]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/009]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[n this paper we report a preliminary work about XPath debugging. We will describe how we can manipulate an XPath expression in order to obtain a set of alternative XPath expressions that match to a given XML document. For each alternative XPath expression we will give a chance degree that represents the degree in which the expression deviates from the initial expression. Thus, our work is focused on providing the programmer a repertoire of paths that (s)he can use to retrieve answers. The approach has been implemented and tested.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[XPath, Fuzzy (Multi-adjoint) Logic Programming, Debugging]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús M. Almendros-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Computación Universidad de Almería 04120 Almería (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalmen@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alejandro Luna]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dept. of Computing Systems University of Castilla-La Mancha 02071 Albacete (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Alejandro.Luna@alu.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ginés Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dept. of Computing Systems University of Castilla-La Mancha 02071 Albacete (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Gines.Moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_wp_old_slug]]></meta_key>
			<meta_value><![CDATA[1357]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A General Implementation Framework for Tabled CLP</title>
		<link>https://biblioteca.sistedes.es/articulo/a-general-implementation-framework-for-tabled-clp/</link>
		<pubDate>Sat, 14 May 2016 17:50:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1364</guid>
		<description></description>
		<content><![CDATA[This is a summary of [PCHS12], where a framework to combine tabling evaluation [TS86, War92] and constraint logic programming [JM94] is described (TCLP). This combination has been studied previously from a theoretical point of view [Tom97, Cod95], where it is shown that the constraint domain needs to offer projection and entailment checking operations in order to ensure completeness w.r.t. the declarative semantics. However, existing TCLP frameworks and implementations lack a complete treatment of constraint projection and / or entailment. The novelty of our proposal is that we present a complete implementation framework for TCLP, independent from the constraint solver, which can use either precise or approximate projection and entailment, possibly with optimizations. ]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1364</post_id>
		<post_date><![CDATA[2016-05-14 19:50:49]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 17:50:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-general-implementation-framework-for-tabled-clp]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="constraint-logic-programming"><![CDATA[Constraint Logic Programming]]></category>
		<category domain="post_tag" nicename="implementation"><![CDATA[Implementation]]></category>
		<category domain="post_tag" nicename="performance"><![CDATA[Performance]]></category>
		<category domain="post_tag" nicename="tabling"><![CDATA[Tabling]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1365]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/010]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This is a summary of [PCHS12], where a framework to combine tabling evaluation [TS86, War92] and constraint logic programming [JM94] is described (TCLP). This combination has been studied previously from a theoretical point of view [Tom97, Cod95], where it is shown that the constraint domain needs to offer projection and entailment checking operations in order to ensure completeness w.r.t. the declarative semantics. However, existing TCLP frameworks and implementations lack a complete treatment of constraint projection and / or entailment. The novelty of our proposal is that we present a complete implementation framework for TCLP, independent from the constraint solver, which can use either precise or approximate projection and entailment, possibly with optimizations. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Constraint Logic Programming, Tabling, Implementation, Performance]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Chico de Guzmán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Carro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel V. Hermenegildo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Peter Stuckey]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[NICTA Laboratory, Australia ]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Abstract Diagnosis for Timed Concurrent Constraint programs Abstract</title>
		<link>https://biblioteca.sistedes.es/articulo/abstract-diagnosis-for-timed-concurrent-constraint-programs-abstract/</link>
		<pubDate>Sat, 14 May 2016 17:54:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1367</guid>
		<description></description>
		<content><![CDATA[This short paper is a summary of the published paper [CTV11] where a general framework for the debugging of tccp programs is defined. To this end, a new compact, bottom-up semantics for the language that is well suited for debugging and verification purposes in the context of reactive systems was presented. In order to effectively implement the technique, we also provided an abstract semantics.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1367</post_id>
		<post_date><![CDATA[2016-05-14 19:54:02]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 17:54:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[abstract-diagnosis-for-timed-concurrent-constraint-programs-abstract]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="abstract-diagnosis"><![CDATA[abstract diagnosis]]></category>
		<category domain="post_tag" nicename="abstract-interpretation"><![CDATA[abstract interpretation]]></category>
		<category domain="post_tag" nicename="concurrent-constraint-paradigm"><![CDATA[concurrent constraint paradigm]]></category>
		<category domain="post_tag" nicename="denotational-semantics"><![CDATA[denotational semantics]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[10]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1368]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/011]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This short paper is a summary of the published paper [CTV11] where a general framework for the debugging of tccp programs is defined. To this end, a new compact, bottom-up semantics for the language that is well suited for debugging and verification purposes in the context of reactive systems was presented. In order to effectively implement the technique, we also provided an abstract semantics.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[concurrent constraint paradigm, denotational semantics, abstract diagnosis, abstract interpretation]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[M. Comini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dipartimento di Matematica e Informatica, U. di Udine]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[L. Titolo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dipartimento di Matematica e Informatica, U. di Udine]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[A. Villanueva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politécnica de Valéncia]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An extension to Simply for solving Weighted Constraint Satisfaction Problems with Pseudo-Boolean Constraints</title>
		<link>https://biblioteca.sistedes.es/articulo/an-extension-to-simply-for-solving-weighted-constraint-satisfaction-problems-with-pseudo-boolean-constraints/</link>
		<pubDate>Sat, 14 May 2016 17:57:56 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1370</guid>
		<description></description>
		<content><![CDATA[Max-Simply is a high-level programming framework for modelling and solving weighted CSP. Max-Simply can also deal with meta-constraints, that is, constraints on constraints. The technology currently used to solve the generated problem instances is SMT. In this paper we present a variant of Max-Simply which is able to generate not only SMT instances but also pseudo-Boolean instances for certain modellings. Since there are problems that are more naturally encoded using pseudo-Boolean variables, the possibility of generating pseudo-Boolean instances can result in a more efficient and natural fit in some situations. We illustrate the expressiveness of the Max-Simply language by modelling some problems, and provide promising performance results on the corresponding generated pseudo-Boolean instances using state-of-the-art pseudo-Boolean solvers. ]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1370</post_id>
		<post_date><![CDATA[2016-05-14 19:57:56]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 17:57:56]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-extension-to-simply-for-solving-weighted-constraint-satisfaction-problems-with-pseudo-boolean-constraints]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="csp"><![CDATA[CSP]]></category>
		<category domain="post_tag" nicename="modelling-languages"><![CDATA[Modelling languages]]></category>
		<category domain="post_tag" nicename="pseudo-boolean-constraints"><![CDATA[Pseudo-Boolean constraints]]></category>
		<category domain="post_tag" nicename="weighted-csp"><![CDATA[Weighted CSP]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1371]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/012]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Max-Simply is a high-level programming framework for modelling and solving weighted CSP. Max-Simply can also deal with meta-constraints, that is, constraints on constraints. The technology currently used to solve the generated problem instances is SMT. In this paper we present a variant of Max-Simply which is able to generate not only SMT instances but also pseudo-Boolean instances for certain modellings. Since there are problems that are more naturally encoded using pseudo-Boolean variables, the possibility of generating pseudo-Boolean instances can result in a more efficient and natural fit in some situations. We illustrate the expressiveness of the Max-Simply language by modelling some problems, and provide promising performance results on the corresponding generated pseudo-Boolean instances using state-of-the-art pseudo-Boolean solvers. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Modelling languages, Pseudo-Boolean constraints, CSP, Weighted CSP]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miquel Bofill]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departament d'Informática i Matemática Aplicada Universitat de Girona, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mbofill@ima.udg.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Joan Espasa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departament d'Informática i Matemática Aplicada Universitat de Girona, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jespasa@ima.udg.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Miquel Palahí]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departament d'Informática i Matemática Aplicada Universitat de Girona, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mpalahi@ima.udg.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Mateu Villaret]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departament d'Informática i Matemática Aplicada Universitat de Girona, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[villaret@ima.udg.edu]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Semantics of structured normal logic programs</title>
		<link>https://biblioteca.sistedes.es/articulo/semantics-of-structured-normal-logic-programs/</link>
		<pubDate>Sat, 14 May 2016 18:02:34 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1376</guid>
		<description></description>
		<content><![CDATA[In this paper we provide semantics for normal logic programs enriched with structuring mechanisms and scoping rules. Specifically, we consider constructive negation and expressions of the form QG in goals, where Q is a program unit, G is a goal and  stands for the so-called embedded implication. Allowing the use of these expressions can be seen as adding block structuring to logic programs. In this context, we consider static and dynamic rules for visibility in blocks. In particular, we provide new semantic definitions for the class of normal logic programs with both visibility rules. For the dynamic case we follow a standard approach. We first propose an operational semantics. Then, we define a model-theoretic semantics in terms of ordered structures which are a kind of intuitionistic Beth structures. Finally, an (effective) fixpoint semantics is provided and we prove the equivalence of these three definitions. In order to deal with the static case, we first define an operational semantics and then we present an alternative semantics in terms of a transformation of the given structured programs into flat ones. We finish by showing that this transformation preserves the computed answers of the given static program.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1376</post_id>
		<post_date><![CDATA[2016-05-14 20:02:34]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 18:02:34]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[semantics-of-structured-normal-logic-programs]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="embedded-implication"><![CDATA[embedded implication]]></category>
		<category domain="post_tag" nicename="intuitionistic-structures"><![CDATA[intuitionistic structures]]></category>
		<category domain="post_tag" nicename="normal-logic-programs"><![CDATA[normal logic programs]]></category>
		<category domain="post_tag" nicename="semantics"><![CDATA[Semantics]]></category>
		<category domain="post_tag" nicename="structuring-mechanism"><![CDATA[structuring mechanism]]></category>
		<category domain="post_tag" nicename="visibility-rules"><![CDATA[visibility rules]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1377]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/013]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper we provide semantics for normal logic programs enriched with structuring mechanisms and scoping rules. Specifically, we consider constructive negation and expressions of the form QG in goals, where Q is a program unit, G is a goal and  stands for the so-called embedded implication. Allowing the use of these expressions can be seen as adding block structuring to logic programs. In this context, we consider static and dynamic rules for visibility in blocks. In particular, we provide new semantic definitions for the class of normal logic programs with both visibility rules. For the dynamic case we follow a standard approach. We first propose an operational semantics. Then, we define a model-theoretic semantics in terms of ordered structures which are a kind of intuitionistic Beth structures. Finally, an (effective) fixpoint semantics is provided and we prove the equivalence of these three definitions. In order to deal with the static case, we first define an operational semantics and then we present an alternative semantics in terms of a transformation of the given structured programs into flat ones. We finish by showing that this transformation preserves the computed answers of the given static program.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[semantics, normal logic programs, embedded implication, visibility rules, structuring mechanism, intuitionistic structures]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Edelmira Pasarella]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departament de LSI, Universitat Politécnica de Catalunya, Jordi Girona, 1-3. 08034 Barcelona, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando Orejas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departament de LSI, Universitat Politécnica de Catalunya, Jordi Girona, 1-3. 08034 Barcelona, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Elvira Pino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departament de LSI, Universitat Politécnica de Catalunya, Jordi Girona, 1-3. 08034 Barcelona, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Marisa Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de LSI, Universidad del País Vasco, Paseo Manuel de Lardizabal, 1, Apdo 649, 20080 San Sebastián, Spain]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Regular queries in event systems with bounded uncertainty</title>
		<link>https://biblioteca.sistedes.es/articulo/regular-queries-in-event-systems-with-bounded-uncertainty/</link>
		<pubDate>Sat, 14 May 2016 18:04:47 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1379</guid>
		<description></description>
		<content><![CDATA[In this paper we consider the problem of matching sequences of events against regular expressions when the detection of atomic events is subject to bounded time uncertainty. This work represents an extension of previous work, in which the semantics of matching continuous streams of events was defined for precisely placed atomic events. In this paper we show that the general problem of matching with time uncertainty is, under a reasonable semantics, NP-complete. However, the problem is polynomial if the expression is fixed.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1379</post_id>
		<post_date><![CDATA[2016-05-14 20:04:47]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 18:04:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[regular-queries-in-event-systems-with-bounded-uncertainty]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="event-systems"><![CDATA[event systems]]></category>
		<category domain="post_tag" nicename="regular-expressions"><![CDATA[regular expressions]]></category>
		<category domain="post_tag" nicename="semiorders"><![CDATA[semiorders]]></category>
		<category domain="post_tag" nicename="uncertainty"><![CDATA[uncertainty]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1380]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/014]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper we consider the problem of matching sequences of events against regular expressions when the detection of atomic events is subject to bounded time uncertainty. This work represents an extension of previous work, in which the semantics of matching continuous streams of events was defined for precisely placed atomic events. In this paper we show that the general problem of matching with time uncertainty is, under a reasonable semantics, NP-complete. However, the problem is polynomial if the expression is fixed.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[event systems, uncertainty, regular expressions, semiorders]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Simone Santini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Escuela Politécnica Superior Universidad Autónoma de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[simone.santini@uam.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>String-based Multi-adjoint Lattices for Tracing Fuzzy Logic Computations</title>
		<link>https://biblioteca.sistedes.es/articulo/string-based-multi-adjoint-lattices-for-tracing-fuzzy-logic-computations/</link>
		<pubDate>Sat, 14 May 2016 18:08:16 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1382</guid>
		<description></description>
		<content><![CDATA[Classically, most programming languages use in a predefined way the notion of "string" as an standard data structure for a comfortable management of arbitrary sequences of characters. However, in this paper we assign a different role to this concept: here we are concerned with fuzzy logic programming, a somehow recent paradigm trying to introduce fuzzy logic into logic programming. In this setting, the mathematical concept of multi-adjoint lattice has been successfully exploited into the so-called Multi-adjoint Logic Programming approach, MALP in brief, for modeling flexible notions of truth-degrees beyond the simpler case of true and false. Our main goal points out not only our formal proof verifying that stringbased lattices accomplish with the so-called multi-adjoint property (as well as its Cartesian product with similar structures), but also its correspondence with interesting debugging tasks into the FLOPER system (from "Fuzzy LOgic Programming Environment for Research") developed in our research group.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1382</post_id>
		<post_date><![CDATA[2016-05-14 20:08:16]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 18:08:16]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[string-based-multi-adjoint-lattices-for-tracing-fuzzy-logic-computations]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cartesian-product-of-multi-adjoint-lattices"><![CDATA[Cartesian Product of Multi-adjoint Lattices]]></category>
		<category domain="post_tag" nicename="declarative-debugging"><![CDATA[Declarative Debugging]]></category>
		<category domain="post_tag" nicename="fuzzy-multi-adjoint-logic-programming"><![CDATA[Fuzzy (Multi-adjoint) Logic Programming]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1383]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/015]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Classically, most programming languages use in a predefined way the notion of "string" as an standard data structure for a comfortable management of arbitrary sequences of characters. However, in this paper we assign a different role to this concept: here we are concerned with fuzzy logic programming, a somehow recent paradigm trying to introduce fuzzy logic into logic programming. In this setting, the mathematical concept of multi-adjoint lattice has been successfully exploited into the so-called Multi-adjoint Logic Programming approach, MALP in brief, for modeling flexible notions of truth-degrees beyond the simpler case of true and false. Our main goal points out not only our formal proof verifying that stringbased lattices accomplish with the so-called multi-adjoint property (as well as its Cartesian product with similar structures), but also its correspondence with interesting debugging tasks into the FLOPER system (from "Fuzzy LOgic Programming Environment for Research") developed in our research group.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Cartesian Product of Multi-adjoint Lattices, Fuzzy (Multi-adjoint) Logic Programming, Declarative Debugging]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro J. Morcillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Faculty of Computer Science Engineering University of Castilla-La Mancha 02071 Albacete (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[PedroJ.Morcillo@alu.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ginés Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Faculty of Computer Science Engineering University of Castilla-La Mancha 02071 Albacete (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Gines.Moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jaime Penabad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Faculty of Computer Science Engineering University of Castilla-La Mancha 02071 Albacete (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Jaime.Penabad@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Carlos Vázquez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Faculty of Computer Science Engineering University of Castilla-La Mancha 02071 Albacete (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Carlos.Vazquez@alu.uclm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Constraint-Based Runtime Prediction of SLA Violations in Service Orchestrations (extended abstract)</title>
		<link>https://biblioteca.sistedes.es/articulo/constraint-based-runtime-prediction-of-sla-violations-in-service-orchestrations-extended-abstract/</link>
		<pubDate>Sat, 14 May 2016 18:12:32 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1387</guid>
		<description></description>
		<content><![CDATA[Quality of Service (QoS) attributes, such as execution time, availability, or cost, are critical for the usability of Web services. This in particular applies to service compositions, which are commonly used for implementing more complex, higher level, and/or cross-organizational tasks by assembling loosely-coupled individual service components (often provided and controlled by third parties). The QoS attributes of service compositions depend on the QoS attributes of the service components, as well as on environmental factors and the actual data being handled, and are usually regulated by means of Service-Level Agreements (SLAs), which define the permissible boundaries for the values of the related properties. Predicting whether an SLA will be violated for a given executing instance of a service composition is therefore very important. Such a prediction can be used for preventing or mitigating the consequences of SLA violations ahead of time.
We propose a method whereby constraints that model SLA conformance and violation are derived at any given point of the execution of a service composition. These constraints are generated using the structure of the composition and properties of the component services, which can be either known or measured empirically. Violation of these constraints means that the corresponding scenario is unfeasible, while satisfaction gives values for the constrained variables (start / end times for activities, or number of loop iterations) which make the scenario possible. These results can be used to perform optimized service matching or trigger preventive adaptation or healing.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1387</post_id>
		<post_date><![CDATA[2016-05-14 20:12:32]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 18:12:32]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[constraint-based-runtime-prediction-of-sla-violations-in-service-orchestrations-extended-abstract]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1388]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/016]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Quality of Service (QoS) attributes, such as execution time, availability, or cost, are critical for the usability of Web services. This in particular applies to service compositions, which are commonly used for implementing more complex, higher level, and/or cross-organizational tasks by assembling loosely-coupled individual service components (often provided and controlled by third parties). The QoS attributes of service compositions depend on the QoS attributes of the service components, as well as on environmental factors and the actual data being handled, and are usually regulated by means of Service-Level Agreements (SLAs), which define the permissible boundaries for the values of the related properties. Predicting whether an SLA will be violated for a given executing instance of a service composition is therefore very important. Such a prediction can be used for preventing or mitigating the consequences of SLA violations ahead of time.
We propose a method whereby constraints that model SLA conformance and violation are derived at any given point of the execution of a service composition. These constraints are generated using the structure of the composition and properties of the component services, which can be either known or measured empirically. Violation of these constraints means that the corresponding scenario is unfeasible, while satisfaction gives values for the constrained variables (start / end times for activities, or number of loop iterations) which make the scenario possible. These results can be used to perform optimized service matching or trigger preventive adaptation or healing.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Dragan Ivanovic]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[idragan@clip.dia.fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Carro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mcarro@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Hermenegildo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[herme@fi.upm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>PTL: A Prolog-based Model Transformation Language</title>
		<link>https://biblioteca.sistedes.es/articulo/ptl-a-prolog-based-model-transformation-language/</link>
		<pubDate>Sat, 14 May 2016 18:42:45 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1390</guid>
		<description></description>
		<content><![CDATA[In this paper we present a model transformation language based on logic programming. The language, called PTL (Prolog-based Transformation Language), can be considered as an hybrid language in which ATL-style rules are combined with logic rules for defining transformations. ATL-style rules are used to define mappings from source models to target models while logic rules are used as helpers. The proposal has been implemented so that a Prolog program is automatically obtained from a PTL program. We have equipped our language with debugging and tracing capabilities which help developers to detect programming errors in PTL rules.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1390</post_id>
		<post_date><![CDATA[2016-05-14 20:42:45]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 18:42:45]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[ptl-a-prolog-based-model-transformation-language]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="logic-programming"><![CDATA[Logic Programming]]></category>
		<category domain="post_tag" nicename="mdd"><![CDATA[MDD]]></category>
		<category domain="post_tag" nicename="software-engineering"><![CDATA[software engineering]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1391]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/017]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper we present a model transformation language based on logic programming. The language, called PTL (Prolog-based Transformation Language), can be considered as an hybrid language in which ATL-style rules are combined with logic rules for defining transformations. ATL-style rules are used to define mappings from source models to target models while logic rules are used as helpers. The proposal has been implemented so that a Prolog program is automatically obtained from a PTL program. We have equipped our language with debugging and tracing capabilities which help developers to detect programming errors in PTL rules.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[MDD, Logic Programming, Software Engineering]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús M. Almendros-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Computación Universidad de Almería 04120-Almería (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalmen@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Luis Iribarne]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Computación Universidad de Almería 04120-Almería (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[luis.iribarne@ual.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Intérprete PsiXML para gramáticas de mini-Lenguajes XML en aplicaciones Web</title>
		<link>https://biblioteca.sistedes.es/articulo/interprete-psixml-para-gramaticas-de-mini-lenguajes-xml-en-aplicaciones-web/</link>
		<pubDate>Sat, 14 May 2016 18:45:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1393</guid>
		<description></description>
		<content><![CDATA[El uso de lenguajes y protocolos XML es una de las herramientas de trabajo más explotadas para la creación de aplicaciones Web. Lenguajes basados en XML como ASP.NET o Java Server Face, en combinación con lenguajes robustos de programación como C# y Java, respectivamente, se emplean con frecuencia para generar páginas dinámicas en la arquitectura servidor de un sistema. Por su parte, considerado como metalenguaje, XML permite definir gramáticas como XSLT, MathML, SVG, y/o SMIL que enriquecen el modelo de presentación de la página web. Actualmente la web 2.0 nos ofrece tecnologías, servicios y herramientas que permiten construir páginas verdaderamente funcionales, agradables y usables en la arquitectura cliente. En este trabajo combinamos la definición de una gramática de lenguaje específico XML con los beneficios de un intérprete de lenguaje de programación. Introducimos el concepto de mini-lenguaje XML como aquellas gramáticas basadas en un conjunto de tags asociados a un modelo de diagramas de clases, evaluables sobre un intérprete especializado XML. Este intérprete puede ser usado en diferentes facetas de una aplicación Web como componente reutilizable en el sistema. Incluiremos como caso de estudio el diseño de una página Web para el manejo de diferentes fuentes Web, en particular fuentes RSS.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1393</post_id>
		<post_date><![CDATA[2016-05-14 20:45:54]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 18:45:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[interprete-psixml-para-gramaticas-de-mini-lenguajes-xml-en-aplicaciones-web]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="fuentes-rss"><![CDATA[Fuentes RSS]]></category>
		<category domain="post_tag" nicename="gramaticas-de-lenguajes-xml"><![CDATA[Gramáticas de Lenguajes XML]]></category>
		<category domain="post_tag" nicename="interprete-de-programacion"><![CDATA[Intérprete de Programación]]></category>
		<category domain="post_tag" nicename="lenguajes-xml"><![CDATA[Lenguajes XML]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1394]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/018]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El uso de lenguajes y protocolos XML es una de las herramientas de trabajo más explotadas para la creación de aplicaciones Web. Lenguajes basados en XML como ASP.NET o Java Server Face, en combinación con lenguajes robustos de programación como C# y Java, respectivamente, se emplean con frecuencia para generar páginas dinámicas en la arquitectura servidor de un sistema. Por su parte, considerado como metalenguaje, XML permite definir gramáticas como XSLT, MathML, SVG, y/o SMIL que enriquecen el modelo de presentación de la página web. Actualmente la web 2.0 nos ofrece tecnologías, servicios y herramientas que permiten construir páginas verdaderamente funcionales, agradables y usables en la arquitectura cliente. En este trabajo combinamos la definición de una gramática de lenguaje específico XML con los beneficios de un intérprete de lenguaje de programación. Introducimos el concepto de mini-lenguaje XML como aquellas gramáticas basadas en un conjunto de tags asociados a un modelo de diagramas de clases, evaluables sobre un intérprete especializado XML. Este intérprete puede ser usado en diferentes facetas de una aplicación Web como componente reutilizable en el sistema. Incluiremos como caso de estudio el diseño de una página Web para el manejo de diferentes fuentes Web, en particular fuentes RSS.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Intérprete de Programación, Lenguajes XML, Gramáticas de Lenguajes XML, Fuentes RSS]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Enrique Chavarriaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Escuela Politécnica Superior. Universidad Autónoma de Madrid Avda. Tomás y Valiente 11. 28049 Madrid.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jesusenrique.chavarriaga@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando Díez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Escuela Politécnica Superior. Universidad Autónoma de Madrid Avda. Tomás y Valiente 11. 28049 Madrid.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fernando.diez@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alfonso Díez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[BET Value SLR Fuentes 10. 28013 Madrid. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[adiez@betvalue.com]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Invariant-Free Clausal Temporal Resolution</title>
		<link>https://biblioteca.sistedes.es/articulo/invariant-free-clausal-temporal-resolution/</link>
		<pubDate>Sat, 14 May 2016 18:52:24 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1399</guid>
		<description></description>
		<content><![CDATA[We provide an extended abstract of the paper with the same title and authors that is going to appear in Journal of Automated Reasoning (Online from December 2th, 2011).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1399</post_id>
		<post_date><![CDATA[2016-05-14 20:52:24]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 18:52:24]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[invariant-free-clausal-temporal-resolution]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="clausal-normal-form"><![CDATA[Clausal Normal Form]]></category>
		<category domain="post_tag" nicename="invariant-free"><![CDATA[Invariant-free]]></category>
		<category domain="post_tag" nicename="resolution"><![CDATA[Resolution]]></category>
		<category domain="post_tag" nicename="temporal-logic"><![CDATA[Temporal Logic]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1400]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/019]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We provide an extended abstract of the paper with the same title and authors that is going to appear in Journal of Automated Reasoning (Online from December 2th, 2011).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Temporal Logic, Resolution, Invariant-free, Clausal Normal Form]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[J. Gaintzarain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[The University of the Basque Country, 48012-Bilbao, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[M. Hermo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[The University of the Basque Country, 20080-San Sebastián, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[P. Lucio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[The University of the Basque Country, 20080-San Sebastián, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[M. Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[The University of the Basque Country, 20080-San Sebastián, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[F. Orejas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Technical University of Catalonia, 08034-Barcelona, Spain]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Testing Temporal Logic on Infinite Java Traces</title>
		<link>https://biblioteca.sistedes.es/articulo/testing-temporal-logic-on-infinite-java-traces/</link>
		<pubDate>Sat, 14 May 2016 18:55:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1402</guid>
		<description></description>
		<content><![CDATA[This paper summarizes an approach for testing reactive and concurrent Java programs which combines model checking and runtime monitoring. We use a model checker for two purposes. On the one hand, it analyzes multiple program executions by generating test input parameters. On the other hand, it checks each program execution against a linear temporal logic (LTL) property. The paper presents two methods to abstract the Java states that allow efficient testing of LTL. One of this methods supports the detection of cycles to test LTL on potentially infinite Java execution traces. Runtime monitoring is used to generate the Java execution traces to be considered as input of the model checker. Our current implementation in the tool TJT uses Spin as the model checker and the Java Debug Interface (JDI) for runtime monitoring. TJT is presented as a plug-in for Eclipse and it has been successfully applied to complex public Java programs.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1402</post_id>
		<post_date><![CDATA[2016-05-14 20:55:49]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 18:55:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[testing-temporal-logic-on-infinite-java-traces]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="model-checking"><![CDATA[Model checking]]></category>
		<category domain="post_tag" nicename="runtime-monitoring"><![CDATA[runtime monitoring]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/020]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper summarizes an approach for testing reactive and concurrent Java programs which combines model checking and runtime monitoring. We use a model checker for two purposes. On the one hand, it analyzes multiple program executions by generating test input parameters. On the other hand, it checks each program execution against a linear temporal logic (LTL) property. The paper presents two methods to abstract the Java states that allow efficient testing of LTL. One of this methods supports the detection of cycles to test LTL on potentially infinite Java execution traces. Runtime monitoring is used to generate the Java execution traces to be considered as input of the model checker. Our current implementation in the tool TJT uses Spin as the model checker and the Java Debug Interface (JDI) for runtime monitoring. TJT is presented as a plug-in for Eclipse and it has been successfully applied to complex public Java programs.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[testing, model checking, runtime monitoring]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Damián Adalid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación University of Málaga Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[damian@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alberto Salmerón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación University of Málaga Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[salmeron@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[María del Mar Gallardo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación University of Málaga Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gallardo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[ Damián Adalid, Alberto Salmerón, María del Mar Gallardo and Pedro Merino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación University of Málaga Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[pedro@lcc.uma.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Analyzing Hybrid Systems with JPF</title>
		<link>https://biblioteca.sistedes.es/articulo/analyzing-hybrid-systems-with-jpf/</link>
		<pubDate>Sat, 14 May 2016 18:59:29 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1405</guid>
		<description></description>
		<content><![CDATA[Hybrid systems are characterized by combining discrete and continuous behaviors. Verification of hybrid systems is, in general, a difficult task due to the potential complexity of the continuous dynamics. Currently, there are different formalisms and tools which are able to analyze specific types of hybrid systems, model checking being one of the most used approaches. In this paper, we propose an extension of the discrete model checker Java Path Finder in order to analyze hybrid systems. We apply a general methodology which has been successfully used to extend SPIN. This methodology is non-intrusive, and uses external libraries, such as Parma Polyhedra Library, to abstract the continuous behavior of the hybrid system independent to the underlying model checker.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1405</post_id>
		<post_date><![CDATA[2016-05-14 20:59:29]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 18:59:29]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analyzing-hybrid-systems-with-jpf]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="hybrid-systems"><![CDATA[Hybrid systems]]></category>
		<category domain="post_tag" nicename="jpf"><![CDATA[JPF]]></category>
		<category domain="post_tag" nicename="model-checking"><![CDATA[Model checking]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1406]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/021]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Hybrid systems are characterized by combining discrete and continuous behaviors. Verification of hybrid systems is, in general, a difficult task due to the potential complexity of the continuous dynamics. Currently, there are different formalisms and tools which are able to analyze specific types of hybrid systems, model checking being one of the most used approaches. In this paper, we propose an extension of the discrete model checker Java Path Finder in order to analyze hybrid systems. We apply a general methodology which has been successfully used to extend SPIN. This methodology is non-intrusive, and uses external libraries, such as Parma Polyhedra Library, to abstract the continuous behavior of the hybrid system independent to the underlying model checker.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ Hybrid systems, model checking, JPF]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Laura Panizo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Málaga, Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[laurapanizo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[María-del-Mar Gallardo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Málaga, Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gallardo@lcc.uma.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Strategy-Driven Graph Transformations in PORGY</title>
		<link>https://biblioteca.sistedes.es/articulo/strategy-driven-graph-transformations-in-porgy/</link>
		<pubDate>Sat, 14 May 2016 19:02:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1410</guid>
		<description></description>
		<content><![CDATA[PORGY [2] is a visual and interactive tool designed to facilitate the specification and analysis of complex systems. PORGY uses graphs to represent the system modelled, and graph rewrite rules guided by strategies to describe the dynamics of the system.
Graphical languages are widely used for describing complex structures in a visual and intuitive way in a variety of domains, such as software modelling (e.g., UML diagrams), representation of proofs (e.g., proof nets), microprocessor design, XML documents, communication networks, and biological systems, amongst others. Graph transformations (or graph rewriting) are used to define the behaviour of the system modelled. From a theoretical point of view, graph rewriting has solid logic, algebraic and categorical foundations [3, 9], and from a practical point of view, it has many applications in specification, programming, and simulation [4, 5].
When the graphs are large or growing via transformations, or when the number of transformation rules is important, being able to directly interact with the rewriting system becomes crucial to understand the changes in the graph structure. From a naïve point of view, the output of a graph rewriting system is a dynamic graph: a sequence of graphs obtained through a series of modifications (addition/deletion of nodes/edges). However, the study of a rewriting system is actually much more complex. Reasoning about the system's properties actually involves testing various rewriting scenarios, backtracking to a previously computed graph, possibly updating rules, etc. PORGY, developed in collaboration with INRIA Bordeaux-Sud Ouest (http://gravite.labri.fr/?Projects_%2F_Grants:Porgy:Download), addresses these issues.
Our approach is based on the use of port graphs and port graph rewriting rules [1]. Port-graphs are a specific class of labelled graphs introduced as an abstract representation of proteins, and used to model biochemical interactions and autonomous systems. We illustrate this concept by using port graph transformations to model biochemical systems (biochemical interactions that take part in the regulation of cell proliferation and transformation) and interaction nets. These case studies illustrate the need for highly dynamic graphs, and highlight interesting challenges for graph visualisation. PORGY provides support for the initial task of defining a set of graph rewriting rules, and the graph representing the initial state of the system (the "initial model" in PORGY's terminology), using a visual editor.
Other crucial issues concern when and where rules are applied. To address this problem, PORGY provides a strategy language to constrain the rewriting derivations, generalising the control structures used in graph-based tools such as PROGRES [10] and GP [8], and rewritebased programming languages such as Stratego and ELAN. In particular, the strategy language includes control structures that facilitate the implementation of graph traversal algorithms, thanks to the explicit definition of "positions" in a graph, where rules can be applied (we refer the reader
M.M. Gallardo, M. Villaret, L. Iribarne (Eds.): PROLE'2012, pp. 253-254, ISBN:978-84-15487-27-2. Jornadas SISTEDES'2012, Almería 17-19 sept. 2012, Universidad de Almería.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1410</post_id>
		<post_date><![CDATA[2016-05-14 21:02:54]]></post_date>
		<post_date_gmt><![CDATA[2016-05-14 19:02:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[strategy-driven-graph-transformations-in-porgy]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1411]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2012/022]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[PORGY [2] is a visual and interactive tool designed to facilitate the specification and analysis of complex systems. PORGY uses graphs to represent the system modelled, and graph rewrite rules guided by strategies to describe the dynamics of the system.
Graphical languages are widely used for describing complex structures in a visual and intuitive way in a variety of domains, such as software modelling (e.g., UML diagrams), representation of proofs (e.g., proof nets), microprocessor design, XML documents, communication networks, and biological systems, amongst others. Graph transformations (or graph rewriting) are used to define the behaviour of the system modelled. From a theoretical point of view, graph rewriting has solid logic, algebraic and categorical foundations [3, 9], and from a practical point of view, it has many applications in specification, programming, and simulation [4, 5].
When the graphs are large or growing via transformations, or when the number of transformation rules is important, being able to directly interact with the rewriting system becomes crucial to understand the changes in the graph structure. From a naïve point of view, the output of a graph rewriting system is a dynamic graph: a sequence of graphs obtained through a series of modifications (addition/deletion of nodes/edges). However, the study of a rewriting system is actually much more complex. Reasoning about the system's properties actually involves testing various rewriting scenarios, backtracking to a previously computed graph, possibly updating rules, etc. PORGY, developed in collaboration with INRIA Bordeaux-Sud Ouest (http://gravite.labri.fr/?Projects_%2F_Grants:Porgy:Download), addresses these issues.
Our approach is based on the use of port graphs and port graph rewriting rules [1]. Port-graphs are a specific class of labelled graphs introduced as an abstract representation of proteins, and used to model biochemical interactions and autonomous systems. We illustrate this concept by using port graph transformations to model biochemical systems (biochemical interactions that take part in the regulation of cell proliferation and transformation) and interaction nets. These case studies illustrate the need for highly dynamic graphs, and highlight interesting challenges for graph visualisation. PORGY provides support for the initial task of defining a set of graph rewriting rules, and the graph representing the initial state of the system (the "initial model" in PORGY's terminology), using a visual editor.
Other crucial issues concern when and where rules are applied. To address this problem, PORGY provides a strategy language to constrain the rewriting derivations, generalising the control structures used in graph-based tools such as PROGRES [10] and GP [8], and rewritebased programming languages such as Stratego and ELAN. In particular, the strategy language includes control structures that facilitate the implementation of graph traversal algorithms, thanks to the explicit definition of "positions" in a graph, where rules can be applied (we refer the reader
M.M. Gallardo, M. Villaret, L. Iribarne (Eds.): PROLE'2012, pp. 253-254, ISBN:978-84-15487-27-2. Jornadas SISTEDES'2012, Almería 17-19 sept. 2012, Universidad de Almería.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Maribel Fernández]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Crossing the Software Education Chasm using Software-as-a-Service and Cloud Computing</title>
		<link>https://biblioteca.sistedes.es/articulo/crossing-the-software-education-chasm-using-software-as-a-service-and-cloud-computing-2/</link>
		<pubDate>Sun, 15 May 2016 14:52:59 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1420</guid>
		<description></description>
		<content><![CDATA[Via the remarkable alignment of cloud computing, software as a service (SaaS), and Agile development, the future of software has been revolutionized in a way that also allows us to teach it more effectively. Over the past 3 years we have been reinventing UC Berkeley's undergraduate software engineering course to cross the long-standing chasm between what many academic courses have traditionally offered and the skills that software employers expect in new hires: enhancing legacy code, working with nontechnical customers, and effective testing. In our course, "two-pizza teams" of 4 to 6 students create a prototype application specified by real customers (primarily nonprofit organizations) and deploy it on the public cloud using the Rails framework and Agile techniques. Students employ user stories and behavior-driven design to reach agreement with the customer and test-driven development to reduce mistakes. During four 2-week iterations, they continuously refine the prototype based on customer feedback, experiencing the entire software lifecycle­requirements gathering, testing, development, deployment, and enhancement­multiple times during a 14-week semester. Because of Rails' first-rate tools for testing and code quality, students learn by doing rather than listening, and instructors can concretely measure student progress. We have also successfully repurposed those same tools to support nontrivial machine grading of complete programming assignments, allowing us to scale the on-campus course from 35 to 115 students and offer a Massively Open Online Course (MOOC) to over 50,000 students. Indeed, to support instructors interested in adopting our techniques in their classes, we provide not only an inexpensive textbook and prerecorded video lectures to complement the curriculum, but also a set of questions and programming assignments that includes free autograding. Our experience has been that students love the course because they learn real-world skills while working with a real customer, instructors love it because students actually practice what they learn rather than listening to lecture and then coding the way they always have, and employers love it because students acquire vital skills missing from previous software engineering courses.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1420</post_id>
		<post_date><![CDATA[2016-05-15 16:52:59]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 14:52:59]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[crossing-the-software-education-chasm-using-software-as-a-service-and-cloud-computing-2]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1421]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/001]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Via the remarkable alignment of cloud computing, software as a service (SaaS), and Agile development, the future of software has been revolutionized in a way that also allows us to teach it more effectively. Over the past 3 years we have been reinventing UC Berkeley's undergraduate software engineering course to cross the long-standing chasm between what many academic courses have traditionally offered and the skills that software employers expect in new hires: enhancing legacy code, working with nontechnical customers, and effective testing. In our course, "two-pizza teams" of 4 to 6 students create a prototype application specified by real customers (primarily nonprofit organizations) and deploy it on the public cloud using the Rails framework and Agile techniques. Students employ user stories and behavior-driven design to reach agreement with the customer and test-driven development to reduce mistakes. During four 2-week iterations, they continuously refine the prototype based on customer feedback, experiencing the entire software lifecycle­requirements gathering, testing, development, deployment, and enhancement­multiple times during a 14-week semester. Because of Rails' first-rate tools for testing and code quality, students learn by doing rather than listening, and instructors can concretely measure student progress. We have also successfully repurposed those same tools to support nontrivial machine grading of complete programming assignments, allowing us to scale the on-campus course from 35 to 115 students and offer a Massively Open Online Course (MOOC) to over 50,000 students. Indeed, to support instructors interested in adopting our techniques in their classes, we provide not only an inexpensive textbook and prerecorded video lectures to complement the curriculum, but also a set of questions and programming assignments that includes free autograding. Our experience has been that students love the course because they learn real-world skills while working with a real customer, instructors love it because students actually practice what they learn rather than listening to lecture and then coding the way they always have, and employers love it because students acquire vital skills missing from previous software engineering courses.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Armando Fox]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modelado Seguro de Consultas OLAP y su Evolución</title>
		<link>https://biblioteca.sistedes.es/articulo/modelado-seguro-de-consultas-olap-y-su-evolucion/</link>
		<pubDate>Sun, 15 May 2016 14:58:19 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1423</guid>
		<description></description>
		<content><![CDATA[La seguridad de la información es un aspecto crítico para las organizaciones. Los almacenes de datos manejan información histórica altamente sensible, ya que además de ser el apoyo a la toma de decisiones estratégicas suele incluir datos personales protegidos por ley. Por lo tanto, esta información ha de ser asegurada garantizando que los usuarios finales encargados de la toma de decisiones no accedan ni infieran información no autorizada en sus consultas al almacén mediante aplicaciones OLAP. Este artículo presenta una propuesta para el modelado seguro de consultas OLAP en la que se modelan tanto consultas OLAP sensibles, como su posible evolución mediante la aplicación de operaciones OLAP. Esta propuesta permite por lo tanto establecer la información que le ha de ser proporcionada al usuario en cada momento de su interacción con el almacén, teniendo en cuenta la información que ha ido conociendo previamente para limitar así el riesgo de inferencias.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1423</post_id>
		<post_date><![CDATA[2016-05-15 16:58:19]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 14:58:19]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modelado-seguro-de-consultas-olap-y-su-evolucion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="almacenes-de-datos"><![CDATA[Almacenes de Datos]]></category>
		<category domain="post_tag" nicename="evolucion-de-consultas"><![CDATA[Evolución de Consultas]]></category>
		<category domain="post_tag" nicename="modelo-de-estados"><![CDATA[Modelo de Estados.]]></category>
		<category domain="post_tag" nicename="olap"><![CDATA[OLAP]]></category>
		<category domain="post_tag" nicename="seguridad"><![CDATA[seguridad]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/002]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La seguridad de la información es un aspecto crítico para las organizaciones. Los almacenes de datos manejan información histórica altamente sensible, ya que además de ser el apoyo a la toma de decisiones estratégicas suele incluir datos personales protegidos por ley. Por lo tanto, esta información ha de ser asegurada garantizando que los usuarios finales encargados de la toma de decisiones no accedan ni infieran información no autorizada en sus consultas al almacén mediante aplicaciones OLAP. Este artículo presenta una propuesta para el modelado seguro de consultas OLAP en la que se modelan tanto consultas OLAP sensibles, como su posible evolución mediante la aplicación de operaciones OLAP. Esta propuesta permite por lo tanto establecer la información que le ha de ser proporcionada al usuario en cada momento de su interacción con el almacén, teniendo en cuenta la información que ha ido conociendo previamente para limitar así el riesgo de inferencias.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Almacenes de Datos, OLAP, Seguridad, Evolución de Consultas, Modelo de Estados.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Blanco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dep. de Matemáticas, Estadística y Computación. Facultad de Ciencias. Grupo GSyA. Universidad de Cantabria. Av. De los Castros s/n. 39071. Santander. Spain. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Carlos.Blanco@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Eduardo Fernández-Medina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dep. de Tecnologías y Sistemas de Información. Escuela Superior de Informática. Grupo GSyA. Universidad de Castilla-La Mancha. Paseo de la Universidad, 4. 13071. Ciudad Real. Spain. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Eduardo.Fdezmedina@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Trujillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dep. de Lenguajes y Sistemas de Información. Facultad de Informática. Grupo LUCENTIA. Universidad de Alicante. San Vicente s/n. 03690. Alicante. Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jtrujillo@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jan Jurjens]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Germany TU Dortmund & Fraunhofer ISST. Alemania.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jan.jurjens@cs.tu-dortmund.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1425]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modelado y Generacíon Automática de Requisitos de Cuadros de Mando</title>
		<link>https://biblioteca.sistedes.es/articulo/modelado-y-generacion-automatica-de-requisitos-de-cuadros-de-mando/</link>
		<pubDate>Sun, 15 May 2016 15:02:32 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1426</guid>
		<description></description>
		<content><![CDATA[La Inteligencia de Negocio (IN) utiliza grandes cantidades de información procedentes de fuentes heterogéneas que tradicionalmente se encuentran integradas en un Almacén de Datos (AD). De forma general, se ha prestado especial atención al proceso de diseño e implementacíon del AD desde el punto de vista de la informacíon a almacenar. Sin embargo, hasta el momento son pocas las aproximaciones que priorizan las necesidades de explotacíon de la informacíon por parte de los tomadores de decisíon. De esta forma, los tomadores de decisíon cuentan con los datos necesarios pero no son capaces de utilizarlos de forma óptima, ni relacionarlos con la estrategia de negocio. En este artículo, proponemos un metamodelo para el diseño de cuadros de mando, que permite a los diseñadores capturar las necesidades de datos de los tomadores de decisión y, posteriormente, obtener la implementacíon correspondiente en la plataforma de IN objetivo. De esta forma, las necesidades de información y explotación de los usuarios finales gúian el proceso de diseño de los cuadros de mando, con el objetivo de aumentar la satisfaccíon de los usuarios finales.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1426</post_id>
		<post_date><![CDATA[2016-05-15 17:02:32]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 15:02:32]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modelado-y-generacion-automatica-de-requisitos-de-cuadros-de-mando]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="almacenes-de-datos"><![CDATA[Almacenes de Datos]]></category>
		<category domain="post_tag" nicename="cuadros-de-mando"><![CDATA[Cuadros de mando]]></category>
		<category domain="post_tag" nicename="mda"><![CDATA[MDA]]></category>
		<category domain="post_tag" nicename="modelado-conceptual"><![CDATA[Modelado conceptual]]></category>
		<category domain="post_tag" nicename="requisitos"><![CDATA[Requisitos]]></category>
		<category domain="post_tag" nicename="visualizacion-de-datos"><![CDATA[Visualización de Datos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1427]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/003]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La Inteligencia de Negocio (IN) utiliza grandes cantidades de información procedentes de fuentes heterogéneas que tradicionalmente se encuentran integradas en un Almacén de Datos (AD). De forma general, se ha prestado especial atención al proceso de diseño e implementacíon del AD desde el punto de vista de la informacíon a almacenar. Sin embargo, hasta el momento son pocas las aproximaciones que priorizan las necesidades de explotacíon de la informacíon por parte de los tomadores de decisíon. De esta forma, los tomadores de decisíon cuentan con los datos necesarios pero no son capaces de utilizarlos de forma óptima, ni relacionarlos con la estrategia de negocio. En este artículo, proponemos un metamodelo para el diseño de cuadros de mando, que permite a los diseñadores capturar las necesidades de datos de los tomadores de decisión y, posteriormente, obtener la implementacíon correspondiente en la plataforma de IN objetivo. De esta forma, las necesidades de información y explotación de los usuarios finales gúian el proceso de diseño de los cuadros de mando, con el objetivo de aumentar la satisfaccíon de los usuarios finales.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Cuadros de mando, Almacenes de datos, Requisitos, Visualizacíon de datos, Modelado conceptual, MDA]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Elisa de Gregorio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Lucentia Research Group Department of Software and Computing Systems University of Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[edg12@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alejandro Maté]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Lucentia Research Group Department of Software and Computing Systems University of Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[amate@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Hector Llorens]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Lucentia Research Group Department of Software and Computing Systems University of Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[hllorens@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Trujillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Lucentia Research Group Department of Software and Computing Systems University of Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jtrujillo@dlsi.ua.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>MiningDeepWeb: Herramienta para la Extracción de Información en la Web Profunda mediante técnicas de minería de datos</title>
		<link>https://biblioteca.sistedes.es/articulo/miningdeepweb-herramienta-para-la-extraccion-de-informacion-en-la-web-profunda-mediante-tecnicas-de-mineria-de-datos/</link>
		<pubDate>Sun, 15 May 2016 15:05:12 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1429</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1429</post_id>
		<post_date><![CDATA[2016-05-15 17:05:12]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 15:05:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[miningdeepweb-herramienta-para-la-extraccion-de-informacion-en-la-web-profunda-mediante-tecnicas-de-mineria-de-datos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1430]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Open Business Intelligence: uso amigable de técnicas de inteligencia de negocio sobre datos abiertos</title>
		<link>https://biblioteca.sistedes.es/articulo/open-business-intelligence-uso-amigable-de-tecnicas-de-inteligencia-de-negocio-sobre-datos-abiertos/</link>
		<pubDate>Sun, 15 May 2016 15:09:22 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1432</guid>
		<description></description>
		<content><![CDATA[La ciudadanía reclama un comportamiento cada vez más transparente de las instituciones públicas. Esta transparencia implica la necesidad de tener disponibles datos cuyo análisis permita a la ciudadanía una participacíon más activa con el objetivo de proveer el mayor beneficio a la sociedad en su conjunto. Por lo tanto, los datos públicos deben estar disponibles libremente para su reutilizacíon y redistribucíon, es decir, deben ser datos abiertos. Estos datos abiertos, normalmente se comparten como datos crudos ("raw data") lo que dificulta al ciudadano medio su análisis para obtener conocimiento útil. Se necesita, entonces, mecanismos que permitan a los ciudadanos comprender y analizar los datos públicos de una manera amigable y sencilla. Con esta finalidad, en este artículo se presenta el concepto de Open Business Intelligence (OpenBI). OpenBI facilita a los usuarios no expertos (i) el análisis y visualizacíon de datos abiertos generando de manera sencilla informes, análisis multidimensional, cuadros de mando o minería de datos, (ii) la reutilizacíon, como datos abiertos, de la informacíon y conocimiento adquirido.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1432</post_id>
		<post_date><![CDATA[2016-05-15 17:09:22]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 15:09:22]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[open-business-intelligence-uso-amigable-de-tecnicas-de-inteligencia-de-negocio-sobre-datos-abiertos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1433]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/005]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La ciudadanía reclama un comportamiento cada vez más transparente de las instituciones públicas. Esta transparencia implica la necesidad de tener disponibles datos cuyo análisis permita a la ciudadanía una participacíon más activa con el objetivo de proveer el mayor beneficio a la sociedad en su conjunto. Por lo tanto, los datos públicos deben estar disponibles libremente para su reutilizacíon y redistribucíon, es decir, deben ser datos abiertos. Estos datos abiertos, normalmente se comparten como datos crudos ("raw data") lo que dificulta al ciudadano medio su análisis para obtener conocimiento útil. Se necesita, entonces, mecanismos que permitan a los ciudadanos comprender y analizar los datos públicos de una manera amigable y sencilla. Con esta finalidad, en este artículo se presenta el concepto de Open Business Intelligence (OpenBI). OpenBI facilita a los usuarios no expertos (i) el análisis y visualizacíon de datos abiertos generando de manera sencilla informes, análisis multidimensional, cuadros de mando o minería de datos, (ii) la reutilizacíon, como datos abiertos, de la informacíon y conocimiento adquirido.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jose-Norberto Mazón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de investigacíon WaKe, Dept. de Lenguajes y Sistemas Informáticos Universidad de Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jnmazon@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose Jacobo Zubcoff]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de investigacíon WaKe, Dept. de Ciencias del Mar y Biología Aplicada Universidad de Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jose.zubcoff@ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Irene Garrigós]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de investigacíon WaKe, Dept. de Lenguajes y Sistemas Informáticos Universidad de Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[igarrigos@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Roberto Espinosa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de investigacíon WaKe, Dept. de Informática Universidad de Matanzas "Camilo Cienfuegos", Cuba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[roberto.espinosa@umcc.cu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Rolando Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Grupo de investigacíon WaKe, Dept. de Informática Universidad de Matanzas "Camilo Cienfuegos", Cuba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[rolando.rodriguez@umcc.cu]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Diseño de un sistema de telerehabilitación basado en Kinect</title>
		<link>https://biblioteca.sistedes.es/articulo/diseno-de-un-sistema-de-telerehabilitacion-basado-en-kinect/</link>
		<pubDate>Sun, 15 May 2016 15:12:30 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1435</guid>
		<description></description>
		<content><![CDATA[El envejecimiento de la población y la mayor supervivencia frente a enfermedades que dejan secuelas físicas son aspectos que suponen un reto en el contexto de una gestión sanitaria eficiente. Es por ello que en la actualidad se están desarrollando sistemas de telerehabilitación que permiten el seguimiento y apoyo de sesiones de fisioterapia realizadas en el hogar, que sin disminuir la calidad del servicio proporcionado, permiten ahorrar costos sanitarios. Nuestra propuesta es crear un sistema de telerehabilitación basado en Kinect, que a diferencia de otras tecnologías existentes, permite que la persona que debe realizar la rehabilitación no tenga que llevar ningún tipo de sensor en el cuerpo y donde la interacción sea únicamente gestual. Así nuestra propuesta va encaminada por un lado, hacia un reconocimiento local de movimientos y gestos con el fin de evaluar automáticamente los ejercicios terapéuticos realizados por la persona y por otro lado, hacia una comunicación externa con el fisioterapeuta. Otras funcionalidades novedosas del sistema propuesto son: 1. la posibilidad de incorporar nuevos ejercicios de manera simple y acorde al esquema que se sigue en las terapias convencionales, 2. permitir la modificación automática de la terapia o sugerir cambios en función de los resultados de la persona. Tanto en la evaluación de ejercicios como en el análisis de datos se hace uso de técnicas de reconocimiento de gestos, movimientos y análisis estadístico.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1435</post_id>
		<post_date><![CDATA[2016-05-15 17:12:30]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 15:12:30]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[diseno-de-un-sistema-de-telerehabilitacion-basado-en-kinect]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="kinect"><![CDATA[Kinect]]></category>
		<category domain="post_tag" nicename="reconocimiento-de-actividades"><![CDATA[Reconocimiento de actividades]]></category>
		<category domain="post_tag" nicename="seguimiento-de-movimiento"><![CDATA[Seguimiento de movimiento]]></category>
		<category domain="post_tag" nicename="telerehabilitacion"><![CDATA[Telerehabilitación]]></category>
		<category domain="post_tag" nicename="terapia-virtual"><![CDATA[Terapia virtual]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/006]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El envejecimiento de la población y la mayor supervivencia frente a enfermedades que dejan secuelas físicas son aspectos que suponen un reto en el contexto de una gestión sanitaria eficiente. Es por ello que en la actualidad se están desarrollando sistemas de telerehabilitación que permiten el seguimiento y apoyo de sesiones de fisioterapia realizadas en el hogar, que sin disminuir la calidad del servicio proporcionado, permiten ahorrar costos sanitarios. Nuestra propuesta es crear un sistema de telerehabilitación basado en Kinect, que a diferencia de otras tecnologías existentes, permite que la persona que debe realizar la rehabilitación no tenga que llevar ningún tipo de sensor en el cuerpo y donde la interacción sea únicamente gestual. Así nuestra propuesta va encaminada por un lado, hacia un reconocimiento local de movimientos y gestos con el fin de evaluar automáticamente los ejercicios terapéuticos realizados por la persona y por otro lado, hacia una comunicación externa con el fisioterapeuta. Otras funcionalidades novedosas del sistema propuesto son: 1. la posibilidad de incorporar nuevos ejercicios de manera simple y acorde al esquema que se sigue en las terapias convencionales, 2. permitir la modificación automática de la terapia o sugerir cambios en función de los resultados de la persona. Tanto en la evaluación de ejercicios como en el análisis de datos se hace uso de técnicas de reconocimiento de gestos, movimientos y análisis estadístico.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Telerehabilitación, Kinect, Seguimiento de movimiento, Terapia virtual, Reconocimiento de actividades]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Antón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos. UPV/EHU. Paseo Manuel de Lardizabal, 1 Donostia, 20018 - San Sebastián]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[danton004@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alfredo Goñi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos. UPV/EHU. Paseo Manuel de Lardizabal, 1 Donostia, 20018 - San Sebastián]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[alfredo@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Arantza Illarramendi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos. UPV/EHU. Paseo Manuel de Lardizabal, 1 Donostia, 20018 - San Sebastián]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[a.illarramendi@ehu.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Integración de observaciones medioambientales: Solución inicial y retos futuros</title>
		<link>https://biblioteca.sistedes.es/articulo/integracion-de-observaciones-medioambientales-solucion-inicial-y-retos-futuros/</link>
		<pubDate>Sun, 15 May 2016 15:18:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1437</guid>
		<description></description>
		<content><![CDATA[En este trabajo se presenta una solucíon inicial para la integración de fuentes de datos de observacíon en aplicaciones de tipo medioambiental. La solucíon se basa en la utilizacíon de una arquitectura típica mediador/wrapper combinada con modelos de datos e interfaces estándar definidos en la iniciativa Sensor Web Enablement (SWE) del Open Geospatial Consortium (OGC). Los retos futuros van en la dirección de simplificar la incorporacíon de nuevas fuentes de datos en el sistema, simplificando el desarrollo de los wrappers y proporcionando mecanismos más avanzados para la definicíon de relaciones semánticas entre elementos locales y globales.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1437</post_id>
		<post_date><![CDATA[2016-05-15 17:18:48]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 15:18:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[integracion-de-observaciones-medioambientales-solucion-inicial-y-retos-futuros]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="arquitecturas-mediadorwrapper"><![CDATA[Arquitecturas Mediador/Wrapper]]></category>
		<category domain="post_tag" nicename="gestion-de-datos-medioambientales"><![CDATA[Gestíon de datos Medioambientales]]></category>
		<category domain="post_tag" nicename="integracion-de-datos"><![CDATA[Integración de datos]]></category>
		<category domain="post_tag" nicename="interoperabilidad-espacial"><![CDATA[Interoperabilidad Espacial]]></category>
		<category domain="post_tag" nicename="sensor-web"><![CDATA[Sensor Web]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1438]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/007]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este trabajo se presenta una solucíon inicial para la integración de fuentes de datos de observacíon en aplicaciones de tipo medioambiental. La solucíon se basa en la utilizacíon de una arquitectura típica mediador/wrapper combinada con modelos de datos e interfaces estándar definidos en la iniciativa Sensor Web Enablement (SWE) del Open Geospatial Consortium (OGC). Los retos futuros van en la dirección de simplificar la incorporacíon de nuevas fuentes de datos en el sistema, simplificando el desarrollo de los wrappers y proporcionando mecanismos más avanzados para la definicíon de relaciones semánticas entre elementos locales y globales.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Integración de datos, Sensor Web, Gestíon de datos Medioambientales, Arquitecturas Mediador/Wrapper, Interoperabilidad Espacial]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel A. Regueiro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Gráficos por Computador e Ingeniería de Datos (COGRADE), Instituto de Investigaciones Tecnológicas, Universidade de Santiago de Compostela Constantino Candeira S/N, Santiago de Compostela ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[manuelantonio.regueiro@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sebastián Villarroya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Gráficos por Computador e Ingeniería de Datos (COGRADE), Instituto de Investigaciones Tecnológicas, Universidade de Santiago de Compostela Constantino Candeira S/N, Santiago de Compostela ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sebastian.villarroya@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Gabriel Sanmartín]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Gráficos por Computador e Ingeniería de Datos (COGRADE), Instituto de Investigaciones Tecnológicas, Universidade de Santiago de Compostela Constantino Candeira S/N, Santiago de Compostela ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gabriel.sanmartin@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José R.R. Viqueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Gráficos por Computador e Ingeniería de Datos (COGRADE), Instituto de Investigaciones Tecnológicas, Universidade de Santiago de Compostela Constantino Candeira S/N, Santiago de Compostela ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jrr.viqueira@usc.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Análisis espacio-temporal en sistemas de bases de datos lógico-funcionales</title>
		<link>https://biblioteca.sistedes.es/articulo/analisis-espacio-temporal-en-sistemas-de-bases-de-datos-logico-funcionales/</link>
		<pubDate>Sun, 15 May 2016 15:22:22 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1440</guid>
		<description></description>
		<content><![CDATA[En este artículo se describe de forma muy breve un nuevo lenguaje para análisis de datos espacio-temporales. El lenguaje se basa en un modelo de datos funcional cuya estructura de datos (llamada MappingSet) almacena conjuntos de funciones con dominios idénticos. La sintaxis XML del lenguaje combina el cálculo relacional en la especificacíon de los dominios de los MappingSets y el paradigma funcional en la especificacíon de las funciones. La simplicidad del modelo facilita la implementacíon actual de un servicio web de análisis espacial.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1440</post_id>
		<post_date><![CDATA[2016-05-15 17:22:22]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 15:22:22]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analisis-espacio-temporal-en-sistemas-de-bases-de-datos-logico-funcionales]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="analisis-espacio-temporal"><![CDATA[Análisis espacio-temporal]]></category>
		<category domain="post_tag" nicename="bases-de-datos-espacio-temporales"><![CDATA[Bases de datos espacio-temporales]]></category>
		<category domain="post_tag" nicename="lenguajes-de-consulta"><![CDATA[Lenguajes de consulta]]></category>
		<category domain="post_tag" nicename="modelado-de-datos"><![CDATA[Modelado de Datos]]></category>
		<category domain="post_tag" nicename="sistemas-de-informacion-geografica"><![CDATA[Sistemas de Informacíon Geográfica]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/008]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este artículo se describe de forma muy breve un nuevo lenguaje para análisis de datos espacio-temporales. El lenguaje se basa en un modelo de datos funcional cuya estructura de datos (llamada MappingSet) almacena conjuntos de funciones con dominios idénticos. La sintaxis XML del lenguaje combina el cálculo relacional en la especificacíon de los dominios de los MappingSets y el paradigma funcional en la especificacíon de las funciones. La simplicidad del modelo facilita la implementacíon actual de un servicio web de análisis espacial.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Sebastían Villarroya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Gráficos por Computador e Ingeniería de Datos (COGRADE), Instituto de Investigaciones Tecnológicas, Universidade de Santiago de Compostela Constantino Candeira S/N, Santiago de Compostela ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[sebastian.villarroya@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Gabriel Alvarez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Gráficos por Computador e Ingeniería de Datos (COGRADE), Instituto de Investigaciones Tecnológicas, Universidade de Santiago de Compostela Constantino Candeira S/N, Santiago de Compostela ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gabriel.alvarez@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Roi Méndez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Gráficos por Computador e Ingeniería de Datos (COGRADE), Instituto de Investigaciones Tecnológicas, Universidade de Santiago de Compostela Constantino Candeira S/N, Santiago de Compostela ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[roi.mendez@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José R.R. Viqueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Gráficos por Computador e Ingeniería de Datos (COGRADE), Instituto de Investigaciones Tecnológicas, Universidade de Santiago de Compostela Constantino Candeira S/N, Santiago de Compostela ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jrr.viqueira@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1441]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Social Pathway Annotation: Extensions of the Systems Biology Metabolic Modelling Assistant</title>
		<link>https://biblioteca.sistedes.es/articulo/social-pathway-annotation-extensions-of-the-systems-biology-metabolic-modelling-assistant/</link>
		<pubDate>Sun, 15 May 2016 15:26:55 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1443</guid>
		<description></description>
		<content><![CDATA[High-throughput experiments have produced large amounts of heterogeneous data in the life sciences. The integration of data in the life sciences is a key component in the analysis of biological processes. These data may contain errors, but the curation of the vast amount of data generated in the "omic" era cannot be done by individual researchers. To address this problem, community-driven tools could be used to assist with data analysis. In this paper, we focus on a tool with social networking capabilities built on top of the SBMM (Systems Biology Metabolic Modelling) Assistant to enable the collaborative improvement of metabolic pathway models (the application is freely available at http://sbmm.uma.es/SPA).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1443</post_id>
		<post_date><![CDATA[2016-05-15 17:26:55]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 15:26:55]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[social-pathway-annotation-extensions-of-the-systems-biology-metabolic-modelling-assistant]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="data-integration"><![CDATA[Data Integration]]></category>
		<category domain="post_tag" nicename="life-sciences"><![CDATA[Life Sciences]]></category>
		<category domain="post_tag" nicename="social-data-curation"><![CDATA[Social Data Curation]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1444]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[High-throughput experiments have produced large amounts of heterogeneous data in the life sciences. The integration of data in the life sciences is a key component in the analysis of biological processes. These data may contain errors, but the curation of the vast amount of data generated in the "omic" era cannot be done by individual researchers. To address this problem, community-driven tools could be used to assist with data analysis. In this paper, we focus on a tool with social networking capabilities built on top of the SBMM (Systems Biology Metabolic Modelling) Assistant to enable the collaborative improvement of metabolic pathway models (the application is freely available at http://sbmm.uma.es/SPA).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Social Data Curation, Life Sciences, Data Integration]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ismael Navas-Delgado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Computer Languages and Computing Science Department, University of Malaga, Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alejandro del Real-Chicharro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Molecular Biology and Biochemistry Department. University of Malaga, Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Miguel Ángel Medina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Molecular Biology and Biochemistry Department. University of Malaga, Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Francisca Sánchez-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Molecular Biology and Biochemistry Department. University of Malaga, Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[José F. Aldana-Montes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Computer Languages and Computing Science Department, University of Malaga, Spain.]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una estructura Métrica Genérica para Búsquedas por Rango sobre una Plataforma Multi-GPU</title>
		<link>https://biblioteca.sistedes.es/articulo/una-estructura-metrica-generica-para-busquedas-por-rango-sobre-una-plataforma-multi-gpu/</link>
		<pubDate>Sun, 15 May 2016 15:31:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1446</guid>
		<description></description>
		<content><![CDATA[Actualmente, la búsqueda por similitud en espacios métricos es de interés para la comunidad científica debido a sus múltiples campos de aplicacíon, como reconocimiento de patrones y recuperacíon de la información, entre otros. El uso de índices métricos proporciona un aumento en la eficiencia durante los procesos de búsqueda mediante la reduccíon del número de evaluaciones de distancia. Sin embargo, para aplicaciones reales donde el volumen de datos a procesar es masivo, el tiempo de resolucíon de una consulta es altamente costoso. En este sentido, el procesamiento paralelo permite disminuir los tiempos de búsqueda. Para este propósito, modernas plataformas basadas en GPU/multi-GPU proporcionan impresionantes ratios coste/rendimiento. En este artículo se presenta un análisis experimental de un conjunto de estructuras métricas en sus versiones secuenciales para posteriormente ser evaluadas bajo una plataforma basada en GPU. Finalmente la mejor alternativa es implementada sobre múltiples GPUs. Como conclusíon, una estructura métrica genérica presenta las mejores propiedades para este tipo de plataforma logrando rendimientos que superan en 32 veces los tiempos obtenidos con la mejor versíon secuencial.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1446</post_id>
		<post_date><![CDATA[2016-05-15 17:31:15]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 15:31:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-estructura-metrica-generica-para-busquedas-por-rango-sobre-una-plataforma-multi-gpu]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="busqueda-por-similitud"><![CDATA[Búsqueda por Similitud]]></category>
		<category domain="post_tag" nicename="espacios-metricos"><![CDATA[espacios métricos]]></category>
		<category domain="post_tag" nicename="plataformas-multi-gpu"><![CDATA[plataformas multi-GPU]]></category>
		<category domain="post_tag" nicename="procesamiento-paralelo"><![CDATA[procesamiento paralelo]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1447]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/010]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Actualmente, la búsqueda por similitud en espacios métricos es de interés para la comunidad científica debido a sus múltiples campos de aplicacíon, como reconocimiento de patrones y recuperacíon de la información, entre otros. El uso de índices métricos proporciona un aumento en la eficiencia durante los procesos de búsqueda mediante la reduccíon del número de evaluaciones de distancia. Sin embargo, para aplicaciones reales donde el volumen de datos a procesar es masivo, el tiempo de resolucíon de una consulta es altamente costoso. En este sentido, el procesamiento paralelo permite disminuir los tiempos de búsqueda. Para este propósito, modernas plataformas basadas en GPU/multi-GPU proporcionan impresionantes ratios coste/rendimiento. En este artículo se presenta un análisis experimental de un conjunto de estructuras métricas en sus versiones secuenciales para posteriormente ser evaluadas bajo una plataforma basada en GPU. Finalmente la mejor alternativa es implementada sobre múltiples GPUs. Como conclusíon, una estructura métrica genérica presenta las mejores propiedades para este tipo de plataforma logrando rendimientos que superan en 32 veces los tiempos obtenidos con la mejor versíon secuencial.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Búsqueda por Similitud, espacios métricos, procesamiento paralelo, plataformas multi-GPU]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Roberto Uribe-Paredes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería en Computación, Universidad de Magallanes, Punta Arenas, Chile.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[roberto.uribeparedes@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Enrique Arias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos, Universidad de Castilla La Mancha, Albacete, España.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[enrique.aria@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Diego Cazorla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos, Universidad de Castilla La Mancha, Albacete, España.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[diego.cazorla@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José L. Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos, Universidad de Castilla La Mancha, Albacete, España.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jose.sgarcia@uclm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Practical Representations for Web and Social Graphs</title>
		<link>https://biblioteca.sistedes.es/articulo/practical-representations-for-web-and-social-graphs/</link>
		<pubDate>Sun, 15 May 2016 15:33:22 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1449</guid>
		<description></description>
		<content><![CDATA[Graphs are a natural way of modeling connections among Web pages in a network or people according to a criteria like friendship, co-authorship, etc. Many algorithms that compute and infer interesting facts out of these networks work directly over these graphs. Some examples of this are Connected components, HITS, PageRank, spamdetection, among others. In social networks, graph mining also enables the study of populations behavior. Successful graph mining not only enables segmentation of users but also prediction of behavior. Link analysis and graph mining remains an area of high interest and development.
These human-generated graphs are growing at an amazing pace, and their representation in main memory, secondary memory, and distributed systems are getting more and more attention. Furthermore, space-efficient representations for these graphs have succeeded at exploiting regularities that are particular to the domain. In the case of Web graphs the main properties exploited are the locality of reference, skewed in/out-degree, and similarity of adjacency lists among nodes of the same domain. In social networks, there is a tendency towards forming cliques in the network.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1449</post_id>
		<post_date><![CDATA[2016-05-15 17:33:22]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 15:33:22]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[practical-representations-for-web-and-social-graphs]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1450]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/011]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Graphs are a natural way of modeling connections among Web pages in a network or people according to a criteria like friendship, co-authorship, etc. Many algorithms that compute and infer interesting facts out of these networks work directly over these graphs. Some examples of this are Connected components, HITS, PageRank, spamdetection, among others. In social networks, graph mining also enables the study of populations behavior. Successful graph mining not only enables segmentation of users but also prediction of behavior. Link analysis and graph mining remains an area of high interest and development.
These human-generated graphs are growing at an amazing pace, and their representation in main memory, secondary memory, and distributed systems are getting more and more attention. Furthermore, space-efficient representations for these graphs have succeeded at exploiting regularities that are particular to the domain. In the case of Web graphs the main properties exploited are the locality of reference, skewed in/out-degree, and similarity of adjacency lists among nodes of the same domain. In social networks, there is a tendency towards forming cliques in the network.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Claude]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ University of Waterloo, Canada. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fclaude@cs.uwaterloo.ca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[usana Ladra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña, Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sladra@udc.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Reducción de la Complejidad Externa en Búsquedas por Similitud usando Técnicas de Clustering</title>
		<link>https://biblioteca.sistedes.es/articulo/reduccion-de-la-complejidad-externa-en-busquedas-por-similitud-usando-tecnicas-de-clustering/</link>
		<pubDate>Sun, 15 May 2016 15:37:21 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1452</guid>
		<description></description>
		<content><![CDATA[La búsqueda por similitud tiene como finalidad determinar los objetos más semejantes o cercanos a uno dado. Los espacios métricos constituyen un modelo matemático que permite formalizar dicha búsqueda y que han dado lugar a diversos métodos, que tienen como objetivo principal reducir el número de evaluaciones de la función de distancia y el tamaño del índice. Las soluciones existentes son métodos basados en pivotes, que obtienen un número reducido de evaluaciones pero requieren cantidades importantes de espacio, y métodos basados en clustering, que necesitan poco espacio pero incrementan el número de evaluaciones. En este trabajo presentamos una nueva estrategia de clustering con sus algoritmos para búsquedas por rango y kNN que, reduciendo progresivamente el tamaño del cluster, disminuye significativamente la complejidad externa, un componente de la complejidad de los métodos existentes, con lo que se reduce el número de evaluaciones de la función de distancia.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1452</post_id>
		<post_date><![CDATA[2016-05-15 17:37:21]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 15:37:21]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[reduccion-de-la-complejidad-externa-en-busquedas-por-similitud-usando-tecnicas-de-clustering]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="espacios-metricos"><![CDATA[espacios métricos]]></category>
		<category domain="post_tag" nicename="reduccion-de-cluster"><![CDATA[Reducción de cluster]]></category>
		<category domain="post_tag" nicename="usqueda-por-similitud"><![CDATA[úsqueda por similitud]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1453]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La búsqueda por similitud tiene como finalidad determinar los objetos más semejantes o cercanos a uno dado. Los espacios métricos constituyen un modelo matemático que permite formalizar dicha búsqueda y que han dado lugar a diversos métodos, que tienen como objetivo principal reducir el número de evaluaciones de la función de distancia y el tamaño del índice. Las soluciones existentes son métodos basados en pivotes, que obtienen un número reducido de evaluaciones pero requieren cantidades importantes de espacio, y métodos basados en clustering, que necesitan poco espacio pero incrementan el número de evaluaciones. En este trabajo presentamos una nueva estrategia de clustering con sus algoritmos para búsquedas por rango y kNN que, reduciendo progresivamente el tamaño del cluster, disminuye significativamente la complejidad externa, un componente de la complejidad de los métodos existentes, con lo que se reduce el número de evaluaciones de la función de distancia.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[úsqueda por similitud, Espacios métricos, Reducción de cluster]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Luis G. Ares]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de Datos, Universidade da Coruña Campus de Elviña s/n, 15071, A Coruña, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[lgares@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Nieves R. Brisaboa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de Datos, Universidade da Coruña Campus de Elviña s/n, 15071, A Coruña, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[brisaboa@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alberto Ordoñez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de Datos, Universidade da Coruña Campus de Elviña s/n, 15071, A Coruña, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[alberto.ordonez@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Oscar Pedreira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de Datos, Universidade da Coruña Campus de Elviña s/n, 15071, A Coruña, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[opedreira@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/012]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>NASS: A Semantic Annotation Tool for Media</title>
		<link>https://biblioteca.sistedes.es/articulo/nass-a-semantic-annotation-tool-for-media/</link>
		<pubDate>Sun, 15 May 2016 15:41:35 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1455</guid>
		<description></description>
		<content><![CDATA[Nowadays media companies have serious difficulties for managing large amounts of news from agencies and self-made articles. Journalists and documentalists must face categorization tasks every day. There is also an additional difficulty due to the usual large size of the list of words in a thesaurus, which is the typical tool used to tag news in the media. In this paper, we present a new method to tackle the problem of information extraction over a set of texts where the annotation must be composed by thesaurus elements. The method consists of applying lemmatization, obtaining keywords, and finally using a combination of Support Vector Machines (SVM), ontologies and heuristics to deduce appropriate tags for the annotation. We carried out a detailed evaluation of our method with a real set of changing news and we compared out tagging with the annotation performed by a real documentation department, obtaining really promising results.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1455</post_id>
		<post_date><![CDATA[2016-05-15 17:41:35]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 15:41:35]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[nass-a-semantic-annotation-tool-for-media]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="semantic-tagging-and-classification-information-extraction-nlp-svm-ontologies-text-classification-media-news"><![CDATA[Semantic tagging and classification; Information Extraction; NLP; SVM; Ontologies; Text classification; Media; News]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1456]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/013]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Nowadays media companies have serious difficulties for managing large amounts of news from agencies and self-made articles. Journalists and documentalists must face categorization tasks every day. There is also an additional difficulty due to the usual large size of the list of words in a thesaurus, which is the typical tool used to tag news in the media. In this paper, we present a new method to tackle the problem of information extraction over a set of texts where the annotation must be composed by thesaurus elements. The method consists of applying lemmatization, obtaining keywords, and finally using a combination of Support Vector Machines (SVM), ontologies and heuristics to deduce appropriate tags for the annotation. We carried out a detailed evaluation of our method with a real set of changing news and we compared out tagging with the annotation performed by a real documentation department, obtaining really promising results.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Semantic tagging and classification; Information Extraction; NLP; SVM; Ontologies; Text classification; Media; News]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Angel L. Garrido]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo Heraldo - Grupo La Informacíon. Zaragoza - Pamplona, Spain. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ogomez@heraldo.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Oscar Gómez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo Heraldo - Grupo La Informacíon. Zaragoza - Pamplona, Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ogomez@heraldo.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sergio Ilarri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[IIS Department, University of Zaragoza, Zaragoza, Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[silarri@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Eduardo Mena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[IIS Department, University of Zaragoza, Zaragoza, Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[emena@unizar.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Políticas de Seguridad en Sistemas Workflow Colaborativos</title>
		<link>https://biblioteca.sistedes.es/articulo/politicas-de-seguridad-en-sistemas-workflow-colaborativos/</link>
		<pubDate>Sun, 15 May 2016 15:45:42 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1460</guid>
		<description></description>
		<content><![CDATA[En los sistemas workflow colaborativos, además de los requisitos de seguridad tradicionales como la disponibilidad, la integridad y la confidencialidad, nos encontramos con una serie de requisitos de seguridad específicos que deben considerarse. La inclusión de estos requisitos de seguridad es un proceso costoso que puede reducirse si se tienen en cuentan la definición y la coordinación de políticas de seguridad específicas para estos sistemas. En este trabajo presentamos un análisis inicial de los requisitos que consideramos son necesarios para la definición de políticas de seguridad en workflows colaborativos dentro del marco de una arquitectura basada en servicios web con objeto de facilitar la especificación, gestión, y verificación de dichas políticas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1460</post_id>
		<post_date><![CDATA[2016-05-15 17:45:42]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 15:45:42]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[politicas-de-seguridad-en-sistemas-workflow-colaborativos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="politicas-de-seguridad"><![CDATA[Políticas de seguridad]]></category>
		<category domain="post_tag" nicename="rbac"><![CDATA[RBAC]]></category>
		<category domain="post_tag" nicename="sistemas-colaborativos"><![CDATA[Sistemas colaborativos]]></category>
		<category domain="post_tag" nicename="workflow"><![CDATA[Workflow]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1461]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/014]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los sistemas workflow colaborativos, además de los requisitos de seguridad tradicionales como la disponibilidad, la integridad y la confidencialidad, nos encontramos con una serie de requisitos de seguridad específicos que deben considerarse. La inclusión de estos requisitos de seguridad es un proceso costoso que puede reducirse si se tienen en cuentan la definición y la coordinación de políticas de seguridad específicas para estos sistemas. En este trabajo presentamos un análisis inicial de los requisitos que consideramos son necesarios para la definición de políticas de seguridad en workflows colaborativos dentro del marco de una arquitectura basada en servicios web con objeto de facilitar la especificación, gestión, y verificación de dichas políticas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Sistemas colaborativos, Workflow, RBAC , Políticas de seguridad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[M. Sánchez Román]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos ,Universidad de Granada.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[miguesr@ugr.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[B. Jiménez Valverde]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos ,Universidad de Granada.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[beajv@ugr.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[F.L. Gutiérrez Vela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos ,Universidad de Granada.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fgutierr@ugr.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[P. Paderewski]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos ,Universidad de Granada.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[patricia@ugr.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Redes Sociales: Estrategia de Marketing para la pequeña empresa</title>
		<link>https://biblioteca.sistedes.es/articulo/redes-sociales-estrategia-de-marketing-para-la-pequena-empresa/</link>
		<pubDate>Sun, 15 May 2016 15:48:47 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1463</guid>
		<description></description>
		<content><![CDATA[En la última década las redes sociales se han convertido en el fenómeno de moda en Internet, abarcando prácticamente todos los ámbitos de la actividad humana, y permitiendo alinear voces, conciencias y acciones de manera simple, lo cual se ve reflejado en el mundo empresarial de forma directa, ya que los clientes pueden ejercer fuerzas a favor o en contra de las marcas y compañías a una velocidad vertiginosa. En este nuevo escenario toda empresa, y en particular la pequeña empresa, debe hacer notar su presencia en las mismas, con el fin de que el cliente se sienta partícipe de nuestro plan de negocio. Con este trabajo, nuestra intención, es mostrar la evolución de las redes sociales en España en los últimos años, para proponer una Estrategia de Marketing que partiendo de las preferencias y comentarios de los españoles en estos entornos, permita integrar a un pequeño negocio en la plataforma social adecuada, a un bajo coste, pero con una óptima capacidad de atracción del consumidor, ya que hasta el momento no existen líneas directrices de cómo adoptar el uso de las Redes Sociales en Pymes.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1463</post_id>
		<post_date><![CDATA[2016-05-15 17:48:47]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 15:48:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[redes-sociales-estrategia-de-marketing-para-la-pequena-empresa]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="evolucion"><![CDATA[evolución]]></category>
		<category domain="post_tag" nicename="marketing-digital"><![CDATA[marketing digital]]></category>
		<category domain="post_tag" nicename="redes-sociales"><![CDATA[Redes sociales]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1464]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/015]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En la última década las redes sociales se han convertido en el fenómeno de moda en Internet, abarcando prácticamente todos los ámbitos de la actividad humana, y permitiendo alinear voces, conciencias y acciones de manera simple, lo cual se ve reflejado en el mundo empresarial de forma directa, ya que los clientes pueden ejercer fuerzas a favor o en contra de las marcas y compañías a una velocidad vertiginosa. En este nuevo escenario toda empresa, y en particular la pequeña empresa, debe hacer notar su presencia en las mismas, con el fin de que el cliente se sienta partícipe de nuestro plan de negocio. Con este trabajo, nuestra intención, es mostrar la evolución de las redes sociales en España en los últimos años, para proponer una Estrategia de Marketing que partiendo de las preferencias y comentarios de los españoles en estos entornos, permita integrar a un pequeño negocio en la plataforma social adecuada, a un bajo coste, pero con una óptima capacidad de atracción del consumidor, ya que hasta el momento no existen líneas directrices de cómo adoptar el uso de las Redes Sociales en Pymes.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Redes Sociales, evolución, marketing digital]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Joaquina Martín-Albo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información (ITSI) Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jmartinalbo@hotmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Coral Calero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información (ITSI) Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Coral.Calero@uclm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Sm4RIA Extension for OIDE: Desarrollo de Rich Internet Applications en la Web Semántica</title>
		<link>https://biblioteca.sistedes.es/articulo/sm4ria-extension-for-oide-desarrollo-de-rich-internet-applications-en-la-web-semantica/</link>
		<pubDate>Sun, 15 May 2016 16:02:36 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1466</guid>
		<description></description>
		<content><![CDATA[El presente artículo describe la extensión Sm4RIA para la herrarmienta OIDE (OOH4RIA Integrated Development Environment), que implementa la metodología Sm4RIA en dicha herramienta . La aplicación, basada en el entorno Eclipse, soporta el desarrollo de los modelos Sm4RIA y los procesos de transformación (modelo a modelo y modelo a texto) que facilitan la generación de una aplicación RIA semántica, la cual puede compartir datos en forma de Linked Data y puede consumir datos desde la red de Linked Data. Además, de forma complementaria a la aproximación Sm4RIA original, la herramienta incluye mecanismos para la generación de interfaces RIA a partir de ontologías y para la generación automática de vistas de administración de las aplicaciones diseñadas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1466</post_id>
		<post_date><![CDATA[2016-05-15 18:02:36]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 16:02:36]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[sm4ria-extension-for-oide-desarrollo-de-rich-internet-applications-en-la-web-semantica]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1467]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/016]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El presente artículo describe la extensión Sm4RIA para la herrarmienta OIDE (OOH4RIA Integrated Development Environment), que implementa la metodología Sm4RIA en dicha herramienta . La aplicación, basada en el entorno Eclipse, soporta el desarrollo de los modelos Sm4RIA y los procesos de transformación (modelo a modelo y modelo a texto) que facilitan la generación de una aplicación RIA semántica, la cual puede compartir datos en forma de Linked Data y puede consumir datos desde la red de Linked Data. Además, de forma complementaria a la aproximación Sm4RIA original, la herramienta incluye mecanismos para la generación de interfaces RIA a partir de ontologías y para la generación automática de vistas de administración de las aplicaciones diseñadas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús M. Hermida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Alicante Apartado de Correos 99, E-03080 Alicante, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jhermida@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Santiago Meliá]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Alicante Apartado de Correos 99, E-03080 Alicante, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sant@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Andrés Montoyo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Alicante Apartado de Correos 99, E-03080 Alicante, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[montoyo@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jaime Gómez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Alicante Apartado de Correos 99, E-03080 Alicante, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jgomez@dlsi.ua.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>TOUCHE CASE Tool: A Task-Oriented and UserCentered Case Tool to Develop Groupware Applications</title>
		<link>https://biblioteca.sistedes.es/articulo/touche-case-tool-a-task-oriented-and-usercentered-case-tool-to-develop-groupware-applications/</link>
		<pubDate>Sun, 15 May 2016 16:05:16 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1469</guid>
		<description></description>
		<content><![CDATA[TOUCHE es un modelo de proceso y una metodología para el desarrollo de interfaces de usuario para aplicaciones groupware desde la elicitación de requisitos hasta su implementación, considerando las características y particularidades de estos sistemas colaborativos desde el inicio. El estudio de los conceptos específicos ha concluido con un modelo conceptual de términos y relaciones sobre el que se asienta el modelo de proceso propuesto. Para soportar este proceso se presenta TOUCHE CASE Tool, una herramienta CASE que permite automatizar dicho proceso de desarrollo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1469</post_id>
		<post_date><![CDATA[2016-05-15 18:05:16]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 16:05:16]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[touche-case-tool-a-task-oriented-and-usercentered-case-tool-to-develop-groupware-applications]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1470]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/017]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[TOUCHE es un modelo de proceso y una metodología para el desarrollo de interfaces de usuario para aplicaciones groupware desde la elicitación de requisitos hasta su implementación, considerando las características y particularidades de estos sistemas colaborativos desde el inicio. El estudio de los conceptos específicos ha concluido con un modelo conceptual de términos y relaciones sobre el que se asienta el modelo de proceso propuesto. Para soportar este proceso se presenta TOUCHE CASE Tool, una herramienta CASE que permite automatizar dicho proceso de desarrollo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Víctor M. R. Penichet]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha. Departamento de Sistemas Informáticos Av. España S/N, Campus Universitario de Albacete, (02071), Albacete, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[victor.penichet@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ María D. Lozano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha. Departamento de Sistemas Informáticos Av. España S/N, Campus Universitario de Albacete, (02071), Albacete, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[maria.lozano@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José A. Gallud]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha. Departamento de Sistemas Informáticos Av. España S/N, Campus Universitario de Albacete, (02071), Albacete, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jose.gallud@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ricardo Tesoriero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha. Departamento de Sistemas Informáticos Av. España S/N, Campus Universitario de Albacete, (02071), Albacete, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[ricardo.tesoriero@uclm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>CSRML Tool: una Herramienta para el Modelado de Requisitos de Sistemas Colaborativos</title>
		<link>https://biblioteca.sistedes.es/articulo/csrml-tool-una-herramienta-para-el-modelado-de-requisitos-de-sistemas-colaborativos/</link>
		<pubDate>Sun, 15 May 2016 16:18:20 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1473</guid>
		<description></description>
		<content><![CDATA[Cada vez más aplicaciones incluyen algún tipo de soporte a la realización de tareas colaborativas. Como para cualquier otro tipo de sistema, una especificación de requisitos precisa es uno de los pilares básicos en el desarrollo de este tipo de sistemas con soporte a la colaboración. Sin embargo, este tipo de sistemas poseen un tipo especial de requisitos difícil de especificar con las técnicas de Ingeniería de Requisitos (IR) tradicionales. Estudios experimentales previos muestran que la especificación del conocimiento o la percepción de una situación o hecho (awareness), necesarios para que los usuarios puedan llevar a cabo tareas colaborativas, puede ser excesivamente compleja, o incluso incompleta, cuando se usan la técnicas clásicas de IR. Para solventar este problema, se ha desarrollado CSRML (Collaborative Systems Requirements Modeling Language), una extensión del lenguaje orientado a objetivos i* para especificar requisitos de sistemas colaborativos. En este trabajo se presenta CSRML Tool: una herramienta que da soporte al lenguaje CSRML. Gracias a esta herramienta, se podrán modelar los distintos diagramas que conforman la especificación de los requisitos de un sistema colaborativo utilizando CSRML, así como comprobar la validez de los mismos con respecto al meta-modelo de CSRML.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1473</post_id>
		<post_date><![CDATA[2016-05-15 18:18:20]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 16:18:20]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[csrml-tool-una-herramienta-para-el-modelado-de-requisitos-de-sistemas-colaborativos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="csrml"><![CDATA[CSRML]]></category>
		<category domain="post_tag" nicename="ingenieria-de-requisitos"><![CDATA[ingeniería de requisitos]]></category>
		<category domain="post_tag" nicename="sistemas-colaborativos"><![CDATA[Sistemas colaborativos]]></category>
		<category domain="post_tag" nicename="visual-studio"><![CDATA[Visual Studio]]></category>
		<category domain="post_tag" nicename="visualization-and-modeling-sdk"><![CDATA[Visualization and Modeling SDK]]></category>
		<category domain="post_tag" nicename="workspace-awareness"><![CDATA[Workspace Awareness]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1474]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/018]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Cada vez más aplicaciones incluyen algún tipo de soporte a la realización de tareas colaborativas. Como para cualquier otro tipo de sistema, una especificación de requisitos precisa es uno de los pilares básicos en el desarrollo de este tipo de sistemas con soporte a la colaboración. Sin embargo, este tipo de sistemas poseen un tipo especial de requisitos difícil de especificar con las técnicas de Ingeniería de Requisitos (IR) tradicionales. Estudios experimentales previos muestran que la especificación del conocimiento o la percepción de una situación o hecho (awareness), necesarios para que los usuarios puedan llevar a cabo tareas colaborativas, puede ser excesivamente compleja, o incluso incompleta, cuando se usan la técnicas clásicas de IR. Para solventar este problema, se ha desarrollado CSRML (Collaborative Systems Requirements Modeling Language), una extensión del lenguaje orientado a objetivos i* para especificar requisitos de sistemas colaborativos. En este trabajo se presenta CSRML Tool: una herramienta que da soporte al lenguaje CSRML. Gracias a esta herramienta, se podrán modelar los distintos diagramas que conforman la especificación de los requisitos de un sistema colaborativo utilizando CSRML, así como comprobar la validez de los mismos con respecto al meta-modelo de CSRML.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ingeniería de requisitos, sistemas colaborativos, workspace awareness, Visualization and Modeling SDK, Visual Studio, CSRML]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel A. Teruel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[LoUISE, Instituto de Investigación en Informática, Universidad de Castilla - La Mancha ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[miguel@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Elena Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[LoUISE, Instituto de Investigación en Informática, Universidad de Castilla - La Mancha ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[enavarro@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Víctor López-Jaquero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[LoUISE, Instituto de Investigación en Informática, Universidad de Castilla - La Mancha ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[victor@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Francisco Montero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[LoUISE, Instituto de Investigación en Informática, Universidad de Castilla - La Mancha ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[fmontero@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Pascual González]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[LoUISE, Instituto de Investigación en Informática, Universidad de Castilla - La Mancha ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[pgonzalez@dsi.uclm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una arquitectura para el desarrollo de videojuegos educativos con actividades colaborativas</title>
		<link>https://biblioteca.sistedes.es/articulo/una-arquitectura-para-el-desarrollo-de-videojuegos-educativos-con-actividades-colaborativas/</link>
		<pubDate>Sun, 15 May 2016 16:25:10 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1476</guid>
		<description></description>
		<content><![CDATA[En este trabajo se abordan dos de los elementos claves de la técnica de aprendizaje colaborativo y de su utilización como base del proceso de aprendizaje en un videojuego educativo. El primero se refiere a la necesidad de los profesores de tener un registro de la evolución de sus estudiantes, no sólo del resultado final, sino también del proceso seguido en las tareas afrontadas durante el aprendizaje. El segundo objetivo, muy ligado al anterior, se refiere a la necesidad de analizar la interacción que tiene lugar entre los jugadores con el fin de evaluar cómo ésta afecta al aprendizaje. Para ello, se presenta una arquitectura que utiliza un conjunto de modelos que permite desarrollar videojuegos educativos efectivos, y concretamente, videojuegos educativos en grupo que implementen tareas colaborativas. Esta arquitectura, llamada PLAGER-VG (PLAtform for managinG Educational multiplayeR Video Games), permite diseñar, monitorizar y adaptar procesos de aprendizaje colaborativo soportados por videojuegos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1476</post_id>
		<post_date><![CDATA[2016-05-15 18:25:10]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 16:25:10]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-arquitectura-para-el-desarrollo-de-videojuegos-educativos-con-actividades-colaborativas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="aprendizaje-colaborativo"><![CDATA[Aprendizaje Colaborativo]]></category>
		<category domain="post_tag" nicename="arquitecturas"><![CDATA[Arquitecturas]]></category>
		<category domain="post_tag" nicename="modelado"><![CDATA[Modelado]]></category>
		<category domain="post_tag" nicename="videojuegos-educativos"><![CDATA[Videojuegos educativos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1477]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/019]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este trabajo se abordan dos de los elementos claves de la técnica de aprendizaje colaborativo y de su utilización como base del proceso de aprendizaje en un videojuego educativo. El primero se refiere a la necesidad de los profesores de tener un registro de la evolución de sus estudiantes, no sólo del resultado final, sino también del proceso seguido en las tareas afrontadas durante el aprendizaje. El segundo objetivo, muy ligado al anterior, se refiere a la necesidad de analizar la interacción que tiene lugar entre los jugadores con el fin de evaluar cómo ésta afecta al aprendizaje. Para ello, se presenta una arquitectura que utiliza un conjunto de modelos que permite desarrollar videojuegos educativos efectivos, y concretamente, videojuegos educativos en grupo que implementen tareas colaborativas. Esta arquitectura, llamada PLAGER-VG (PLAtform for managinG Educational multiplayeR Video Games), permite diseñar, monitorizar y adaptar procesos de aprendizaje colaborativo soportados por videojuegos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Videojuegos educativos, Aprendizaje Colaborativo, Arquitecturas, Modelado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[N. Padilla Zea]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos. Laboratorio de Investigación en Videojuegos y E-learning. Grupo GEDES. Universidad de Granada.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[npadilla@ugr.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[P. Paderewski]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos. Laboratorio de Investigación en Videojuegos y E-learning. Grupo GEDES. Universidad de Granada.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[patricia@ugr.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[F.L. Gutiérrez Vela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos. Laboratorio de Investigación en Videojuegos y E-learning. Grupo GEDES. Universidad de Granada.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fgutierr@ugr.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[N. Medina Medina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos. Laboratorio de Investigación en Videojuegos y E-learning. Grupo GEDES. Universidad de Granada.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[nmedina@ugr.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Implementación de una Solución Reutilizable para una Funcionalidad de Usabilidad</title>
		<link>https://biblioteca.sistedes.es/articulo/implementacion-de-una-solucion-reutilizable-para-una-funcionalidad-de-usabilidad/</link>
		<pubDate>Sun, 15 May 2016 16:28:00 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1479</guid>
		<description></description>
		<content><![CDATA[La usabilidad es un atributo de calidad y un aspecto crítico en los sistemas de software. Se ha establecido que algunas de las recomendaciones para mejorar la usabilidad dadas desde el campo de la Interacción Persona Ordenador tienen impacto en el diseño de software. En este artículo presentamos la implementación de una solución reutilizable para realizar una funcionalidad de usabilidad con alto impacto en el diseño: Abortar Operación. Desarrollamos tres aplicaciones web como casos de estudio, incluimos esta funcionalidad de usabilidad y buscamos elementos comunes en las implementaciones. Encontramos escenarios de aplicación, responsabilidades, clases, métodos, atributos y trozos de código comunes en los tres desarrollos. Con base en estos hallazgos, proponemos elementos reutilizables para incorporar la funcionalidad de usabilidad en el análisis, diseño y programación. Formalizamos la solución como un patrón de diseño y patrones de programación en tres lenguajes: PHP 5, Java y Visual Basic .NET.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1479</post_id>
		<post_date><![CDATA[2016-05-15 18:28:00]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 16:28:00]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[implementacion-de-una-solucion-reutilizable-para-una-funcionalidad-de-usabilidad]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="abortar-operacion"><![CDATA[Abortar operación]]></category>
		<category domain="post_tag" nicename="patron-de-diseno"><![CDATA[Patrón de diseño]]></category>
		<category domain="post_tag" nicename="patron-de-programacion"><![CDATA[Patrón de programación]]></category>
		<category domain="post_tag" nicename="usabilidad-del-software"><![CDATA[Usabilidad del software]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1480]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/020]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La usabilidad es un atributo de calidad y un aspecto crítico en los sistemas de software. Se ha establecido que algunas de las recomendaciones para mejorar la usabilidad dadas desde el campo de la Interacción Persona Ordenador tienen impacto en el diseño de software. En este artículo presentamos la implementación de una solución reutilizable para realizar una funcionalidad de usabilidad con alto impacto en el diseño: Abortar Operación. Desarrollamos tres aplicaciones web como casos de estudio, incluimos esta funcionalidad de usabilidad y buscamos elementos comunes en las implementaciones. Encontramos escenarios de aplicación, responsabilidades, clases, métodos, atributos y trozos de código comunes en los tres desarrollos. Con base en estos hallazgos, proponemos elementos reutilizables para incorporar la funcionalidad de usabilidad en el análisis, diseño y programación. Formalizamos la solución como un patrón de diseño y patrones de programación en tres lenguajes: PHP 5, Java y Visual Basic .NET.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Usabilidad del software, Abortar operación, Patrón de diseño, Patrón de programación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francy D. Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática, Universidad Politécnica de Madrid, Campus de Montegancedo s/n, 28660 Boadilla del Monte, Madrid, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fd.rodriguez@alumnos.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Silvia T. Acuña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad Autónoma de Madrid, Calle Francisco Tomás y Valiente 11, 28049, Madrid, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[silvia.acunna@uam.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An experience migrating a Cairngorm based Rich Internet Application from Flex to HTML5</title>
		<link>https://biblioteca.sistedes.es/articulo/an-experience-migrating-a-cairngorm-based-rich-internet-application-from-flex-to-html5/</link>
		<pubDate>Sun, 15 May 2016 16:31:34 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1482</guid>
		<description></description>
		<content><![CDATA[This paper shows a new approach to migrate a Flex based Rich Internet Application (RIA) that is using the Cairngorm architectural framework to HTML5. The migration has been done rewriting the Cairngorm code, from ActionScript to Javascript and using the result as super classes that have to be implemented by concrete Javascript classes. The similarities between the original ActionScript and Flex code and the resulting Javascript code help the developers in the migration process. To overcome the problems that arise due to the fact that some multimedia features are not yet implemented in any browser -despite the HTML5 specification states that they will be in the future -, we have suggested the use of minimal Flash widgets that communicate with their HTML Wrapper page by means of the ExternalInterface API. Doing so, it will be easy to replace these widgets with HTML5 objects whenever they are implemented by major browsers.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1482</post_id>
		<post_date><![CDATA[2016-05-15 18:31:34]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 16:31:34]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-experience-migrating-a-cairngorm-based-rich-internet-application-from-flex-to-html5]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cairngorm-framework"><![CDATA[Cairngorm framework]]></category>
		<category domain="post_tag" nicename="flash"><![CDATA[Flash]]></category>
		<category domain="post_tag" nicename="flex"><![CDATA[Flex]]></category>
		<category domain="post_tag" nicename="html5"><![CDATA[HTML5]]></category>
		<category domain="post_tag" nicename="migration"><![CDATA[migration]]></category>
		<category domain="post_tag" nicename="ria"><![CDATA[RIA]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1483]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/021]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper shows a new approach to migrate a Flex based Rich Internet Application (RIA) that is using the Cairngorm architectural framework to HTML5. The migration has been done rewriting the Cairngorm code, from ActionScript to Javascript and using the result as super classes that have to be implemented by concrete Javascript classes. The similarities between the original ActionScript and Flex code and the resulting Javascript code help the developers in the migration process. To overcome the problems that arise due to the fact that some multimedia features are not yet implemented in any browser -despite the HTML5 specification states that they will be in the future -, we have suggested the use of minimal Flash widgets that communicate with their HTML Wrapper page by means of the ExternalInterface API. Doing so, it will be easy to replace these widgets with HTML5 objects whenever they are implemented by major browsers.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Cairngorm framework, Flash, Flex, HTML5, migration, RIA]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan A. Pereira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[UPV/EHU, Donostia, SPAIN, ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[juanan.pereira@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Silvia Sanz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[UPV/EHU, Donostia, SPAIN, ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[silvia.sanz@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inko Perurena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[UPV/EHU, Donostia, SPAIN, ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inko.perurena@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Julián Gutiérrez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[UPV/EHU, Donostia, SPAIN, ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[julian.gutierrez@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Imanol Luengo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[UPV/EHU, Donostia, SPAIN, ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[iluengo004@ikasle.ehu.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Verificación de la información extraída por wrappers web usando algoritmos basados en colonias de hormigas</title>
		<link>https://biblioteca.sistedes.es/articulo/verificacion-de-la-informacion-extraida-por-wrappers-web-usando-algoritmos-basados-en-colonias-de-hormigas/</link>
		<pubDate>Sun, 15 May 2016 16:34:19 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1485</guid>
		<description></description>
		<content><![CDATA[ Un wrapper es un sistema automático que permite navegar, extraer, estructurar y verificar información proveniente de la Web. Una de las tareas más importantes dentro de este campo es la verificación automática de la información proveniente de esta fuente de datos semiestructurados. En la literatura existen distintas técnicas que intentan solucionar este problema. En este trabajo, presentamos una nueva propuesta que hace uso de los algoritmos de optimización basados en colonias de hormigas. De los distintos algoritmos de colonias de hormigas existentes, usaremos el denominado Best-Worst Ant System que ya ha sido usado en diversos problemas de optimización alcanzando unos resultados bastante prometedores. Realizaremos un análisis no paramétrico del comportamiento de nuestra propuesta y la compararemos con las técnicas de verificación ya existentes. Para hacer este estudio utilizaremos diversas bases de datos reales. Los resultados obtenidos nos permiten confirmar el buen rendimiento que presenta nuestra propuesta frente a los métodos tradicionales aplicados.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1485</post_id>
		<post_date><![CDATA[2016-05-15 18:34:19]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 16:34:19]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[verificacion-de-la-informacion-extraida-por-wrappers-web-usando-algoritmos-basados-en-colonias-de-hormigas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1486]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/022]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[ Un wrapper es un sistema automático que permite navegar, extraer, estructurar y verificar información proveniente de la Web. Una de las tareas más importantes dentro de este campo es la verificación automática de la información proveniente de esta fuente de datos semiestructurados. En la literatura existen distintas técnicas que intentan solucionar este problema. En este trabajo, presentamos una nueva propuesta que hace uso de los algoritmos de optimización basados en colonias de hormigas. De los distintos algoritmos de colonias de hormigas existentes, usaremos el denominado Best-Worst Ant System que ya ha sido usado en diversos problemas de optimización alcanzando unos resultados bastante prometedores. Realizaremos un análisis no paramétrico del comportamiento de nuestra propuesta y la compararemos con las técnicas de verificación ya existentes. Para hacer este estudio utilizaremos diversas bases de datos reales. Los resultados obtenidos nos permiten confirmar el buen rendimiento que presenta nuestra propuesta frente a los métodos tradicionales aplicados.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Iñaki Fernández de Viana]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Tecnologías de la Información, Universidad de Huelva. 21071 La Rábida (Huelva)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[i.fviana@dti.uhu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pedro J. Abad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Tecnologías de la Información, Universidad de Huelva. 21071 La Rábida (Huelva)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[abadhe@dti.uhu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José Luis Álvarez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Tecnologías de la Información, Universidad de Huelva. 21071 La Rábida (Huelva)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[alvarez@dti.uhu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José Luis Arjona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. Tecnologías de la Información, Universidad de Huelva. 21071 La Rábida (Huelva)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jose.arjona@dti.uhu.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Computer-Aided Relearning Activity Patterns for People with Acquired Brain Injury*</title>
		<link>https://biblioteca.sistedes.es/articulo/computer-aided-relearning-activity-patterns-for-people-with-acquired-brain-injury/</link>
		<pubDate>Sun, 15 May 2016 16:37:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1488</guid>
		<description></description>
		<content><![CDATA[This paper describes the activities carried out in the course of developing a tool, HABITAT, to assist people with Acquired Brain Injury (ABI).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1488</post_id>
		<post_date><![CDATA[2016-05-15 18:37:06]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 16:37:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[computer-aided-relearning-activity-patterns-for-people-with-acquired-brain-injury]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1489]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/023]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper describes the activities carried out in the course of developing a tool, HABITAT, to assist people with Acquired Brain Injury (ABI).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Montero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Computing Systems Department, University of Castilla-La Mancha, Avda. España s/n Albacete 02071]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fmontero@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Víctor López-Jaquero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Computing Systems Department, University of Castilla-La Mancha, Avda. España s/n Albacete 02071]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[victor@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Elena Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Computing Systems Department, University of Castilla-La Mancha, Avda. España s/n Albacete 02071]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[enavarro@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Enriqueta Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Computing Systems Department, University of Castilla-La Mancha, Avda. España s/n Albacete 02071]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[enri@dsi.uclm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Exploring Tabletops as an Effective Tool to Foster Creativity Traits</title>
		<link>https://biblioteca.sistedes.es/articulo/exploring-tabletops-as-an-effective-tool-to-foster-creativity-traits/</link>
		<pubDate>Sun, 15 May 2016 16:42:35 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1491</guid>
		<description></description>
		<content><![CDATA[People are continuously solving problems in their everyday activities. Some of these are "routine" problems that are easy to solve and have obvious and well-known criteria for identifying the solution by applying knowledge directly. Other problems are considered "complex" or "intractable" problems which people are unable to easily come up with a solution even if they are considered to have an adequate level of intelligence. In this case, divergent thinking and eventually creativity can make a difference in devising new solutions.
Creativity is therefore important for learning and future personal development, especially in the case of children and teenagers, and as a consequence it is also relevant for the whole society. How it can be fostered as well as evaluated in Information and Communications Technologies (ICT) settings seems to be a key issue for research. Despite advanced technology is being used to provide ICT systems according to creativity theories they rarely assess creativity itself, what brings up doubts on whether technologies actually provide some benefit in the expected direction. Moreover most of the computer-mediated approaches used to address creativity have been designed to support single-user interactions and so fail to consider other important dimensions of creativity, such as collaboration, reflection and divergent thinking in group face-toface scenarios.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1491</post_id>
		<post_date><![CDATA[2016-05-15 18:42:35]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 16:42:35]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[exploring-tabletops-as-an-effective-tool-to-foster-creativity-traits]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1492]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/024]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[People are continuously solving problems in their everyday activities. Some of these are "routine" problems that are easy to solve and have obvious and well-known criteria for identifying the solution by applying knowledge directly. Other problems are considered "complex" or "intractable" problems which people are unable to easily come up with a solution even if they are considered to have an adequate level of intelligence. In this case, divergent thinking and eventually creativity can make a difference in devising new solutions.
Creativity is therefore important for learning and future personal development, especially in the case of children and teenagers, and as a consequence it is also relevant for the whole society. How it can be fostered as well as evaluated in Information and Communications Technologies (ICT) settings seems to be a key issue for research. Despite advanced technology is being used to provide ICT systems according to creativity theories they rarely assess creativity itself, what brings up doubts on whether technologies actually provide some benefit in the expected direction. Moreover most of the computer-mediated approaches used to address creativity have been designed to support single-user interactions and so fail to consider other important dimensions of creativity, such as collaboration, reflection and divergent thinking in group face-toface scenarios.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alejandro Catala]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ISSI-Departamento de Sistemas Informáticos y Computación Universitat Politècnica de València Camí de Vera s/n, 46022, Valencia Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[acatala@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Jaen]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ISSI-Departamento de Sistemas Informáticos y Computación Universitat Politècnica de València Camí de Vera s/n, 46022, Valencia Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fjaen@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Betsy van Dijk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Human Media Interaction University of Twente Faculty EEMCS PO Box 217 7500 AE Enschede The Netherlands]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[e.m.a.g.vandijk@utwente.nl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Sergi Jordà]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Music Technology Group Universitat Pompeu Fabra Roc Boronat 138, 08018 Barcelona Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sergi.jorda@upf.edu]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Desarrollo Dirigido por Modelos en Ingeniería Web con Webratio y RUX-Tool #</title>
		<link>https://biblioteca.sistedes.es/articulo/desarrollo-dirigido-por-modelos-en-ingenieria-web-con-webratio-y-rux-tool/</link>
		<pubDate>Sun, 15 May 2016 16:46:21 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1494</guid>
		<description></description>
		<content><![CDATA[A lo largo de los últimos años, se han planteado diferentes propuestas para la creación de aplicaciones Web en base a modelos conceptuales. Estos modelos tienen como objetivo principal el desarrollo de Webs basadas en grandes cantidades de datos (conocidas como Data Intensive Web Applications). Este tipo de modelos tiene en cuenta los diferentes elementos de información, organizados generalmente en páginas enlazadas que permiten estructurar los elementos y la navegación de la aplicación. Las modernas técnicas de generación automática de código sobre la base de diseño dirigido por modelos simplifica las fases más costosas del proceso de desarrollo de este tipo de aplicaciones (codificación, revisión y mantenimiento), reduciendo el uso de los recursos técnicos y humanos que se emplean y mejorando en algunos casos la calidad del producto final. En este sentido, la casi totalidad de estos modelos disponen de diferentes representaciones que permiten expresar los conceptos implicados en el diseño y desarrollo de una aplicación Web utilizando la noción de capas encapsuladas que dividen los objetivos en diferentes niveles según la responsabilidad requerida. Mediante esta división, cada una de las capas puede ser especificada de manera independientemente, definiendo en cada una modelos como pueden ser los de datos, navegación, etc.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1494</post_id>
		<post_date><![CDATA[2016-05-15 18:46:21]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 16:46:21]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[desarrollo-dirigido-por-modelos-en-ingenieria-web-con-webratio-y-rux-tool]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="ingenieria-web"><![CDATA[Ingeniería Web]]></category>
		<category domain="post_tag" nicename="rich-internet-applications"><![CDATA[Rich Internet Applications]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1495]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/025]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A lo largo de los últimos años, se han planteado diferentes propuestas para la creación de aplicaciones Web en base a modelos conceptuales. Estos modelos tienen como objetivo principal el desarrollo de Webs basadas en grandes cantidades de datos (conocidas como Data Intensive Web Applications). Este tipo de modelos tiene en cuenta los diferentes elementos de información, organizados generalmente en páginas enlazadas que permiten estructurar los elementos y la navegación de la aplicación. Las modernas técnicas de generación automática de código sobre la base de diseño dirigido por modelos simplifica las fases más costosas del proceso de desarrollo de este tipo de aplicaciones (codificación, revisión y mantenimiento), reduciendo el uso de los recursos técnicos y humanos que se emplean y mejorando en algunos casos la calidad del producto final. En este sentido, la casi totalidad de estos modelos disponen de diferentes representaciones que permiten expresar los conceptos implicados en el diseño y desarrollo de una aplicación Web utilizando la noción de capas encapsuladas que dividen los objetivos en diferentes niveles según la responsabilidad requerida. Mediante esta división, cada una de las capas puede ser especificada de manera independientemente, definiendo en cada una modelos como pueden ser los de datos, navegación, etc.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Ingeniería Web, Rich Internet Applications]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rober Morales-Chaparro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando Sánchez-Figueroa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Carlos Preciado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group. Universidad de Extremadura. Cáceres, 10003]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jcpreciado@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Marino Linaje Trigueros]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Roberto Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[José María Conejero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Pedro Clemente]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SIM4CMM: Decision Making Support in CMMI Based Project Management</title>
		<link>https://biblioteca.sistedes.es/articulo/sim4cmm-decision-making-support-in-cmmi-based-project-management/</link>
		<pubDate>Sun, 15 May 2016 16:50:34 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1500</guid>
		<description></description>
		<content><![CDATA[Estimates of task duration or the amount of resources needed in software projects are often very inaccurate. To avoid this problem, project management must be effective and dynamic, that is, being proactive rather than reactive. Among the tasks needed in this approach, reassigning resources, hiring new personnel or adapting estimates to new situations can be found. We propose a tool to help decision making in project management offering a real time simulation of the project team behavior, the interaction with the project tasks and the project metrics.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1500</post_id>
		<post_date><![CDATA[2016-05-15 18:50:34]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 16:50:34]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[sim4cmm-decision-making-support-in-cmmi-based-project-management]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="multiparadigm-simulation-modeling"><![CDATA[Multiparadigm Simulation Modeling]]></category>
		<category domain="post_tag" nicename="project-planning-cmmi-hybrid-models"><![CDATA[Project Planning; CMMI; Hybrid models]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1501]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/026]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Estimates of task duration or the amount of resources needed in software projects are often very inaccurate. To avoid this problem, project management must be effective and dynamic, that is, being proactive rather than reactive. Among the tasks needed in this approach, reassigning resources, hiring new personnel or adapting estimates to new situations can be found. We propose a tool to help decision making in project management offering a real time simulation of the project team behavior, the interaction with the project tasks and the project metrics.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Multiparadigm Simulation Modeling, Project Planning; CMMI; Hybrid models]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Daniel Crespo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Cadiz, C/ Chile, 1, 11003 - Cadiz, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[dani.crespobernal@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mercedes Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Cadiz, C/ Chile, 1, 11003 - Cadiz, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mercedes.ruz@uca.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SPRINTT: Un Entorno para la Institucionalización de Procesos Software</title>
		<link>https://biblioteca.sistedes.es/articulo/sprintt-un-entorno-para-la-institucionalizacion-de-procesos-software/</link>
		<pubDate>Sun, 15 May 2016 16:53:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1503</guid>
		<description></description>
		<content><![CDATA[La adaptación de procesos es una tarea crucial. Sin embargo, no es sencillo hacer cambios de forma ad-hoc dentro de un proceso y esperar que sea correcto y consistente. Cualquier organización se enfrenta continuamente a este reto cuando lleva a cabo sus proyectos de acuerdo a sus modelos de procesos teniendo en cuenta las características de cada proyecto. Como resultado, se obtienen versiones del modelo de procesos que cada vez es menos manejable ante los múltiples cambios realizados de forma ad-hoc. La solución pasa por dotar a los procesos software de mecanismos adecuados para la adaptación sistemática y además aprovechar el conocimiento obtenido en cada adaptación para mejorar el propio modelo de procesos. Con todo ello en este artículo se presenta el ciclo SPRINTT para la institucionalización de procesos software que promueve la adaptación y estandarización de variantes y el paradigma de Procesos Ricos en Variantes (VRP) en el que se basa. El paradigma integra la variabilidad dentro de los procesos, para adaptarlos según cada proyecto, de manera sencilla y consistente. La propuesta se ha aplicado en un caso de estudio para la definición de procesos adaptables de Desarrollo Global de Software. Finalmente se propone extender este enfoque a nivel de contexto para vincular cambios en la organización y variaciones dentro de un proceso rico en variantes.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1503</post_id>
		<post_date><![CDATA[2016-05-15 18:53:15]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 16:53:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[sprintt-un-entorno-para-la-institucionalizacion-de-procesos-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="adaptacion-de-procesos"><![CDATA[Adaptación de procesos]]></category>
		<category domain="post_tag" nicename="procesos-ricos-en-variantes"><![CDATA[Procesos ricos en variantes]]></category>
		<category domain="post_tag" nicename="rationale-management"><![CDATA[Rationale Management]]></category>
		<category domain="post_tag" nicename="variabilidad"><![CDATA[Variabilidad]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1504]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/027]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La adaptación de procesos es una tarea crucial. Sin embargo, no es sencillo hacer cambios de forma ad-hoc dentro de un proceso y esperar que sea correcto y consistente. Cualquier organización se enfrenta continuamente a este reto cuando lleva a cabo sus proyectos de acuerdo a sus modelos de procesos teniendo en cuenta las características de cada proyecto. Como resultado, se obtienen versiones del modelo de procesos que cada vez es menos manejable ante los múltiples cambios realizados de forma ad-hoc. La solución pasa por dotar a los procesos software de mecanismos adecuados para la adaptación sistemática y además aprovechar el conocimiento obtenido en cada adaptación para mejorar el propio modelo de procesos. Con todo ello en este artículo se presenta el ciclo SPRINTT para la institucionalización de procesos software que promueve la adaptación y estandarización de variantes y el paradigma de Procesos Ricos en Variantes (VRP) en el que se basa. El paradigma integra la variabilidad dentro de los procesos, para adaptarlos según cada proyecto, de manera sencilla y consistente. La propuesta se ha aplicado en un caso de estudio para la definición de procesos adaptables de Desarrollo Global de Software. Finalmente se propone extender este enfoque a nivel de contexto para vincular cambios en la organización y variaciones dentro de un proceso rico en variantes.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Adaptación de procesos, Variabilidad, Procesos ricos en variantes, Rationale Management]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Tomás Martínez-Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información. Universidad de Castilla-La Mancha. Ciudad Real, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[tomas.martinez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Félix García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información. Universidad de Castilla-La Mancha. Ciudad Real, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[felix.garcía@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información. Universidad de Castilla-La Mancha. Ciudad Real, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mario.piattini@uclm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un experimento para validar transformaciones QVT para la generación de modelos de servicios en SoaML desde modelos de procesos de negocio en BPMN2</title>
		<link>https://biblioteca.sistedes.es/articulo/un-experimento-para-validar-transformaciones-qvt-para-la-generacion-de-modelos-de-servicios-en-soaml-desde-modelos-de-procesos-de-negocio-en-bpmn2/</link>
		<pubDate>Sun, 15 May 2016 16:56:18 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1506</guid>
		<description></description>
		<content><![CDATA[La realización de procesos de negocio (PNs) mediante servicios presenta varias ventajas frente a otras opciones tales como desacoplar la definición de los PN de las tecnologías que los implementan, promover la reutilización de los servicios entre distintos PNs, y facilitar el análisis del impacto de los cambios, tanto en la definición de los PNs como en su implementación. En el framework MINERVA se propone un enfoque MDA para la generación automática de servicios en SoaML desde PNs en BPMN2, mediante transformaciones QVT. Hemos validado las transformaciones propuestas por medio de un experimento que se centró en evaluar dos características de calidad: la adecuación de las transformaciones propuestas (en relación con lo que los usuarios esperan modelar por sí mismos a partir del modelo de PN) y la entendibilidad de los modelos de servicios que se generan (por medio del significado de los elementos generados y sus relaciones). Hemos encontrado que el 82% y el 75% de los participantes prefiere y entiende, respectivamente, el diseño que proponemos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1506</post_id>
		<post_date><![CDATA[2016-05-15 18:56:18]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 16:56:18]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-experimento-para-validar-transformaciones-qvt-para-la-generacion-de-modelos-de-servicios-en-soaml-desde-modelos-de-procesos-de-negocio-en-bpmn2]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="experimentacion"><![CDATA[experimentación]]></category>
		<category domain="post_tag" nicename="generacion-automatica"><![CDATA[generación automática]]></category>
		<category domain="post_tag" nicename="modelos-de-pns-y-servicios"><![CDATA[modelos de PNs y servicios]]></category>
		<category domain="post_tag" nicename="soaml-y-bpmn2"><![CDATA[SoaML y BPMN2]]></category>
		<category domain="post_tag" nicename="transformaciones-qvt"><![CDATA[transformaciones QVT]]></category>
		<category domain="post_tag" nicename="validacion-empirica"><![CDATA[validación empírica]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1507]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/028]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La realización de procesos de negocio (PNs) mediante servicios presenta varias ventajas frente a otras opciones tales como desacoplar la definición de los PN de las tecnologías que los implementan, promover la reutilización de los servicios entre distintos PNs, y facilitar el análisis del impacto de los cambios, tanto en la definición de los PNs como en su implementación. En el framework MINERVA se propone un enfoque MDA para la generación automática de servicios en SoaML desde PNs en BPMN2, mediante transformaciones QVT. Hemos validado las transformaciones propuestas por medio de un experimento que se centró en evaluar dos características de calidad: la adecuación de las transformaciones propuestas (en relación con lo que los usuarios esperan modelar por sí mismos a partir del modelo de PN) y la entendibilidad de los modelos de servicios que se generan (por medio del significado de los elementos generados y sus relaciones). Hemos encontrado que el 82% y el 75% de los participantes prefiere y entiende, respectivamente, el diseño que proponemos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[validación empírica, experimentación, generación automática, transformaciones QVT, SoaML y BPMN2, modelos de PNs y servicios]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Andrea Delgado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ Instituto de Computación, Facultad de Ingeniería, Universidad de la República, Julio Herrera y Reissig 565, 11300, Montevideo, Uruguay ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[adelgado@fing.edu.uy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francisco Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla ­ La Mancha, Camino de Moledores s/n, 13051, Ciudad Real, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[francisco.ruizg@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ignacio García-Rodríguez de Guzmán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla ­ La Mancha, Camino de Moledores s/n, 13051, Ciudad Real, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ignacio.grodriguez,@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla ­ La Mancha, Camino de Moledores s/n, 13051, Ciudad Real, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mario.piattini@uclm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evaluación de la eficiencia de métodos de identificación del defecto de diseño GodClass</title>
		<link>https://biblioteca.sistedes.es/articulo/evaluacion-de-la-eficiencia-de-metodos-de-identificacion-del-defecto-de-diseno-godclass/</link>
		<pubDate>Sun, 15 May 2016 16:59:28 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1509</guid>
		<description></description>
		<content><![CDATA[La identificación de defectos de diseño en entidades de código es una de las tareas del proceso de mantenimiento del software que sirve para evaluar la calidad de un sistema. Un defecto de diseño describe una situación que sugiere un problema potencial en la estructura del software. La intencíon de diseño de la entidad, que puede ser expresada como estereotipos de clasificadores estándar de UML, proporciona una fuente de información utilizada en algunas definiciones textuales de defectos. En las entidades de código de un sistema software orientado a objetos la información de estereotipos UML no suele estar disponible explícitamente, aunque los diseñadores y programadores la hayan tenido en cuenta en sus soluciones. En la práctica de la automatización de detección de defectos de diseño, esta informacíon es obviada a pesar de su posible utilidad en el proceso de identificacíon de defectos. Actualmente existen métodos de identificación del defecto de diseño GodClass basados en métricas de código. Incluso existen herramientas que lo automatizan, como InCode y JDeodorant, ambas avaladas con importantes publicaciones de investigación, en las que esta información no se tiene en cuenta. Nosotros proponemos utilizar técnicas de aprendizaje supervisado basado en clasificadores de tipo árbol de decisíon, para modelar el problema de la deteccíon de defectos de diseño como una clasificación de entidades de código "con defecto" o "sin defecto". La clasificacíon inicial en la fase de entrenamiento se puede obtener a partir de los métodos actuales. Este trabajo presenta un caso de estudio para evaluar cómo influye la información relativa a la naturaleza de diseño de la entidad en la deteccíon de defecto GodClass para distintos clasificadores. La evaluación consiste en comparar de medidas de rendimiento del clasificador obtenidas en la fase de entrenamiento (Recuperación, Precisíon y F-Measure). Las resultados avalan la validez de considerar la naturaleza de diseño de la entidad en los métodos de identificacíon de defectos de código.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1509</post_id>
		<post_date><![CDATA[2016-05-15 18:59:28]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 16:59:28]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evaluacion-de-la-eficiencia-de-metodos-de-identificacion-del-defecto-de-diseno-godclass]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="aprendizaje-supervisado"><![CDATA[aprendizaje supervisado]]></category>
		<category domain="post_tag" nicename="defectos-de-diseno-orientados-a-objetos"><![CDATA[defectos de diseño orientados a objetos]]></category>
		<category domain="post_tag" nicename="estereotipo-de-clasificadores-uml"><![CDATA[estereotipo de clasificadores UML]]></category>
		<category domain="post_tag" nicename="experimentacion-en-ingenieria-del-software"><![CDATA[experimentacíon en ingeniería del software]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1510]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/029]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La identificación de defectos de diseño en entidades de código es una de las tareas del proceso de mantenimiento del software que sirve para evaluar la calidad de un sistema. Un defecto de diseño describe una situación que sugiere un problema potencial en la estructura del software. La intencíon de diseño de la entidad, que puede ser expresada como estereotipos de clasificadores estándar de UML, proporciona una fuente de información utilizada en algunas definiciones textuales de defectos. En las entidades de código de un sistema software orientado a objetos la información de estereotipos UML no suele estar disponible explícitamente, aunque los diseñadores y programadores la hayan tenido en cuenta en sus soluciones. En la práctica de la automatización de detección de defectos de diseño, esta informacíon es obviada a pesar de su posible utilidad en el proceso de identificacíon de defectos. Actualmente existen métodos de identificación del defecto de diseño GodClass basados en métricas de código. Incluso existen herramientas que lo automatizan, como InCode y JDeodorant, ambas avaladas con importantes publicaciones de investigación, en las que esta información no se tiene en cuenta. Nosotros proponemos utilizar técnicas de aprendizaje supervisado basado en clasificadores de tipo árbol de decisíon, para modelar el problema de la deteccíon de defectos de diseño como una clasificación de entidades de código "con defecto" o "sin defecto". La clasificacíon inicial en la fase de entrenamiento se puede obtener a partir de los métodos actuales. Este trabajo presenta un caso de estudio para evaluar cómo influye la información relativa a la naturaleza de diseño de la entidad en la deteccíon de defecto GodClass para distintos clasificadores. La evaluación consiste en comparar de medidas de rendimiento del clasificador obtenidas en la fase de entrenamiento (Recuperación, Precisíon y F-Measure). Las resultados avalan la validez de considerar la naturaleza de diseño de la entidad en los métodos de identificacíon de defectos de código.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[defectos de diseño orientados a objetos, experimentacíon en ingeniería del software, estereotipo de clasificadores UML, aprendizaje supervisado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos López]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Burgos, EPS Edificio C, C/Francisco Vitoria s/n, Burgos, España, ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[clopezno@ubu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Esperanza Manso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Valladolid, Campus Miguel Delibes, Valladolid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[manso@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Yania Crespo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Valladolid, Campus Miguel Delibes, Valladolid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[yania@infor.uva.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Alf como lenguaje de especificación de refactorizaciones</title>
		<link>https://biblioteca.sistedes.es/articulo/alf-como-lenguaje-de-especificacion-de-refactorizaciones/</link>
		<pubDate>Sun, 15 May 2016 17:02:26 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1512</guid>
		<description></description>
		<content><![CDATA[Las definiciones más habituales de operaciones de refactorización se centran en un lenguaje particular. Sin embargo, una de las líneas de investigacíon en refactorizacíon en los últimos años aborda la independencia del lenguaje en la definicíon de refactorizaciones, que posteriormente deberá ser implementada para lenguajes particulares. Se han aportado diferentes soluciones para representar el código con cierta independencia del lenguaje, sin embargo la definicíon e implementacíon de refactorizaciones continúa siendo mayoritariamente dependiente del lenguaje. En cuanto a esta definicíon e implementacíon de refactorizaciones, se aprecia un importante salto bien sea desde las definiciones de refactorizaciones en forma de recetas, bien sea desde las definiciones formales utilizando lógica de predicados o reescritura de grafos, a la implementacíon real de la refactorizacíon. En este trabajo, tomando como base un metamodelo UML definido para la representacíon de código de forma independiente del lenguaje, se valida la aplicacíon del lenguaje de acciones Alf como lenguaje para la definicíon de refactorizaciones. El uso de Alf tiene una doble implicacíon. Por una parte se consigue acercar la definicíon de refactorizaciones a su posterior implementacíon, dado que se produce una traduccíon con menor esfuerzo desde el lenguaje de acciones al lenguaje de implementacíon elegido. Por otra parte, el uso de Alf y los parsers asociados, permiten validar que el metamodelo contiene la informacíon suficiente para definir refactorizaciones.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1512</post_id>
		<post_date><![CDATA[2016-05-15 19:02:26]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 17:02:26]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[alf-como-lenguaje-de-especificacion-de-refactorizaciones]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="lenguaje-de-acciones-alf"><![CDATA[lenguaje de acciones Alf]]></category>
		<category domain="post_tag" nicename="lenguaje-de-modelado-uml"><![CDATA[lenguaje de modelado UML]]></category>
		<category domain="post_tag" nicename="metamodelo"><![CDATA[metamodelo]]></category>
		<category domain="post_tag" nicename="refactorizacion"><![CDATA[Refactorización]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1513]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/030]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las definiciones más habituales de operaciones de refactorización se centran en un lenguaje particular. Sin embargo, una de las líneas de investigacíon en refactorizacíon en los últimos años aborda la independencia del lenguaje en la definicíon de refactorizaciones, que posteriormente deberá ser implementada para lenguajes particulares. Se han aportado diferentes soluciones para representar el código con cierta independencia del lenguaje, sin embargo la definicíon e implementacíon de refactorizaciones continúa siendo mayoritariamente dependiente del lenguaje. En cuanto a esta definicíon e implementacíon de refactorizaciones, se aprecia un importante salto bien sea desde las definiciones de refactorizaciones en forma de recetas, bien sea desde las definiciones formales utilizando lógica de predicados o reescritura de grafos, a la implementacíon real de la refactorizacíon. En este trabajo, tomando como base un metamodelo UML definido para la representacíon de código de forma independiente del lenguaje, se valida la aplicacíon del lenguaje de acciones Alf como lenguaje para la definicíon de refactorizaciones. El uso de Alf tiene una doble implicacíon. Por una parte se consigue acercar la definicíon de refactorizaciones a su posterior implementacíon, dado que se produce una traduccíon con menor esfuerzo desde el lenguaje de acciones al lenguaje de implementacíon elegido. Por otra parte, el uso de Alf y los parsers asociados, permiten validar que el metamodelo contiene la informacíon suficiente para definir refactorizaciones.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[refactorización, lenguaje de modelado UML, metamodelo, lenguaje de acciones Alf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Raúl Marticorena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Burgos, EPS Edificio C, C/Francisco Vitoria s/n, Burgos, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rmartico@ubu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Yania Crespo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Valladolid, Campus Miguel Delibes, Valladolid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[yania@infor.uva.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Usability mechanisms extension to ScrumTime</title>
		<link>https://biblioteca.sistedes.es/articulo/usability-mechanisms-extension-to-scrumtime/</link>
		<pubDate>Sun, 15 May 2016 17:06:59 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1516</guid>
		<description></description>
		<content><![CDATA[This contribution presents the extension of the existing ScrumTime tool to support usability mechanisms that has been done. The presented tool is used to manage agile projects. The extension increases the features of ScrumTime to define user stories through usability mechanisms selection, acceptance criteria definition and recommendation about usability tasks, acceptance criteria and usability stories. The tool is available to be tested.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1516</post_id>
		<post_date><![CDATA[2016-05-15 19:06:59]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 17:06:59]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[usability-mechanisms-extension-to-scrumtime]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="agile-development"><![CDATA[Agile development]]></category>
		<category domain="post_tag" nicename="hci"><![CDATA[HCI]]></category>
		<category domain="post_tag" nicename="usability-patterns"><![CDATA[usability patterns]]></category>
		<category domain="post_tag" nicename="user-stories"><![CDATA[user stories]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1517]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/031]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This contribution presents the extension of the existing ScrumTime tool to support usability mechanisms that has been done. The presented tool is used to manage agile projects. The extension increases the features of ScrumTime to define user stories through usability mechanisms selection, acceptance criteria definition and recommendation about usability tasks, acceptance criteria and usability stories. The tool is available to be tested.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Agile development, usability patterns, user stories, HCI]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana M. Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ammoreno@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Agustin Yagüe]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[agustin.yague@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Diego Yucra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[diego.yucra@gmail.com]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Tailoring user stories to deal with usability</title>
		<link>https://biblioteca.sistedes.es/articulo/tailoring-user-stories-to-deal-with-usability/</link>
		<pubDate>Sun, 15 May 2016 17:09:21 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1519</guid>
		<description></description>
		<content><![CDATA[Agile teams have to address usability to properly catch their users experience. But like in traditional software development, this task is not easy to achieve; there exists an interesting debate in the agile and usability communities about how to deal with this integration. In this paper we try to contribute to this debate by discussing the incorporation of particular usability recommendations into one of the most popular artifacts for communicating agile requirements, user stories. We discuss about the changes the incorporation of particular usability issues may introduce in a user story, and describe a tool that helps the agile team to deal with such usability issues during the specification of user stories. Some encouraging results about preliminary validation are also presented in the paper.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1519</post_id>
		<post_date><![CDATA[2016-05-15 19:09:21]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 17:09:21]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[tailoring-user-stories-to-deal-with-usability]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="agile-development"><![CDATA[Agile development]]></category>
		<category domain="post_tag" nicename="hci"><![CDATA[HCI]]></category>
		<category domain="post_tag" nicename="usability-patterns"><![CDATA[usability patterns]]></category>
		<category domain="post_tag" nicename="user-stories"><![CDATA[user stories]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1520]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/032]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Agile teams have to address usability to properly catch their users experience. But like in traditional software development, this task is not easy to achieve; there exists an interesting debate in the agile and usability communities about how to deal with this integration. In this paper we try to contribute to this debate by discussing the incorporation of particular usability recommendations into one of the most popular artifacts for communicating agile requirements, user stories. We discuss about the changes the incorporation of particular usability issues may introduce in a user story, and describe a tool that helps the agile team to deal with such usability issues during the specification of user stories. Some encouraging results about preliminary validation are also presented in the paper.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Agile development, usability patterns, user stories, HCI]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana M. Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ammoreno@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Agustin Yagüe]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[agustin.yague@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Diego Yucra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[diego.yucra@gmail.com]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Assessing the influence of stereotypes on the comprehension of UML sequence diagrams: A family of experiments</title>
		<link>https://biblioteca.sistedes.es/articulo/assessing-the-influence-of-stereotypes-on-the-comprehension-of-uml-sequence-diagrams-a-family-of-experiments/</link>
		<pubDate>Sun, 15 May 2016 17:13:19 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1522</guid>
		<description></description>
		<content><![CDATA[Stereotypes are often used in industrial contexts and their application spans from use cases to class diagrams. Indeed, companies use stereotypes within their development processes to specialize general processes aiming to fit them to a particular technology in use, such as programming languages (e.g. C#, Java), application type (e.g. realtime, Web applications, client-server, standalone), reusable component used (e.g. Microsoft Foundation Class Library, Enterprise Java Beans Library) or simply to give more detailed guidelines to the practitioners involved in the system development processes.
Nevertheless, the influence of stereotypes on the comprehension of requirements models, such as UML sequence diagrams, had not been investigated yet. This fact motivated us to develop the research presented in this work.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1522</post_id>
		<post_date><![CDATA[2016-05-15 19:13:19]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 17:13:19]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[assessing-the-influence-of-stereotypes-on-the-comprehension-of-uml-sequence-diagrams-a-family-of-experiments]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1523]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/033]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Stereotypes are often used in industrial contexts and their application spans from use cases to class diagrams. Indeed, companies use stereotypes within their development processes to specialize general processes aiming to fit them to a particular technology in use, such as programming languages (e.g. C#, Java), application type (e.g. realtime, Web applications, client-server, standalone), reusable component used (e.g. Microsoft Foundation Class Library, Enterprise Java Beans Library) or simply to give more detailed guidelines to the practitioners involved in the system development processes.
Nevertheless, the influence of stereotypes on the comprehension of requirements models, such as UML sequence diagrams, had not been investigated yet. This fact motivated us to develop the research presented in this work.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José A. Cruz-Lemus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Technologies and Information Systems, University of Castilla-La Mancha, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[JoseAntonio.Cruz@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Marcela Genero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Technologies and Information Systems, University of Castilla-La Mancha, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Marcela.Genero@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Danilo Caivano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Informatics, University of Bari, Italy ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[caivano@di.uniba.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Silvia Abrahão]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Information Systems and Computation, Universidad Politécnica de Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sabrahao@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Emilio Insfrán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Department of Information Systems and Computation, Universidad Politécnica de Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[einsfran@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[José A. Carsí]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Department of Information Systems and Computation, Universidad Politécnica de Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[pcarsi@dsic.upv.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Metaheurísticas como soporte a la seleccíon de requisitos del software</title>
		<link>https://biblioteca.sistedes.es/articulo/metaheuristicas-como-soporte-a-la-seleccion-de-requisitos-del-software/</link>
		<pubDate>Sun, 15 May 2016 17:16:35 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1525</guid>
		<description></description>
		<content><![CDATA[Las técnicas de optimización y metaheurísticas han sido aplicadas ampliamente en numerosas áreas, entre ellas la Ingeniería del Software. En este trabajo mostramos la incorporacíon de estas técnicas como soporte a las tareas de selección de un grupo de requisitos de entre aquellos que han sido propuestos por los clientes, validando experimentalmente sus resultados. Los algoritmos metaheurísticos son ejecutados desde una herramienta web que permite la definicíon colaborativa de los requisitos de un proyecto software y ayudan a los desarrolladores durante la ejecución del mismo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1525</post_id>
		<post_date><![CDATA[2016-05-15 19:16:35]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 17:16:35]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[metaheuristicas-como-soporte-a-la-seleccion-de-requisitos-del-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="gestion-de-requisitos"><![CDATA[gestíon de requisitos]]></category>
		<category domain="post_tag" nicename="ingenieria-de-requisitos-asistida-por-computadora"><![CDATA[ingeniería de requisitos asistida por computadora]]></category>
		<category domain="post_tag" nicename="optimizacion-metaheuristica"><![CDATA[optimizacíon metaheurística]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1526]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/034]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las técnicas de optimización y metaheurísticas han sido aplicadas ampliamente en numerosas áreas, entre ellas la Ingeniería del Software. En este trabajo mostramos la incorporacíon de estas técnicas como soporte a las tareas de selección de un grupo de requisitos de entre aquellos que han sido propuestos por los clientes, validando experimentalmente sus resultados. Los algoritmos metaheurísticos son ejecutados desde una herramienta web que permite la definicíon colaborativa de los requisitos de un proyecto software y ayudan a los desarrolladores durante la ejecución del mismo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[gestíon de requisitos, ingeniería de requisitos asistida por computadora, optimizacíon metaheurística]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Isabel M. del Aguila]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Computacíon, Ctra Sacramento s/n, 04120 Universidad de Almería, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[imaguila@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José del Sagrado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Computacíon, Ctra Sacramento s/n, 04120 Universidad de Almería, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jsagrado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco J. Orellana]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Computacíon, Ctra Sacramento s/n, 04120 Universidad de Almería, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fjorella@ual.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Enfoque dirigido por modelos para probar Sistemas de Información con Bases de Datos</title>
		<link>https://biblioteca.sistedes.es/articulo/enfoque-dirigido-por-modelos-para-probar-sistemas-de-informacion-con-bases-de-datos/</link>
		<pubDate>Sun, 15 May 2016 17:21:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1532</guid>
		<description></description>
		<content><![CDATA[La base de datos es un componente esencial de los sistemas de información. En efecto, para una base de datos dada, una organización tendrá, probablemente, múltiples aplicaciones que la gestionen, de acuerdo a los diferentes tipos de usuarios, plataformas, dispositivos, etcétera. Aunque la propia base de datos ya incorporará su propio conjunto de restricciones, la lógica de los programas asociados a ella debe también contemplarlas y manejarlas correctamente. En este artículo proponemos un enfoque de generación de casos de prueba centrado en la base de datos, donde se prueba el comportamiento de las aplicaciones que la gestionan, comprobando si son capaces de manejar las particularidades de las estructuras definidas en forma adecuada para las distintas capas de la arquitectura (lógica, interfaz de usuario, etc.). Esta propuesta representa el modelo de datos usando UML Data Modeling Profile, el cual es extraído automáticamente a partir del esquema relacional de la base de datos mediante técnicas de ingeniería inversa, para luego generar el modelo de pruebas de forma automática usando transformaciones entre modelos. Dicha transformación busca ocurrencias de patrones que, desde el punto de vista del testing, representan situaciones de prueba interesantes, y genera casos de prueba siguiendo el estándar UML Testing Profile. En este artículo se describe el entorno de trabajo y se presentan, a modo de ejemplo, el diseño de las pruebas para las operaciones de creación y eliminación de instancias.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1532</post_id>
		<post_date><![CDATA[2016-05-15 19:21:50]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 17:21:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[enfoque-dirigido-por-modelos-para-probar-sistemas-de-informacion-con-bases-de-datos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="datos-de-prueba"><![CDATA[datos de prueba]]></category>
		<category domain="post_tag" nicename="pruebas-basadas-en-modelos"><![CDATA[Pruebas basadas en modelos]]></category>
		<category domain="post_tag" nicename="pruebas-de-sistemas-de-informacion"><![CDATA[Pruebas de Sistemas de Información]]></category>
		<category domain="post_tag" nicename="pruebas-de-software"><![CDATA[Pruebas de Software]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1533]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/035]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La base de datos es un componente esencial de los sistemas de información. En efecto, para una base de datos dada, una organización tendrá, probablemente, múltiples aplicaciones que la gestionen, de acuerdo a los diferentes tipos de usuarios, plataformas, dispositivos, etcétera. Aunque la propia base de datos ya incorporará su propio conjunto de restricciones, la lógica de los programas asociados a ella debe también contemplarlas y manejarlas correctamente. En este artículo proponemos un enfoque de generación de casos de prueba centrado en la base de datos, donde se prueba el comportamiento de las aplicaciones que la gestionan, comprobando si son capaces de manejar las particularidades de las estructuras definidas en forma adecuada para las distintas capas de la arquitectura (lógica, interfaz de usuario, etc.). Esta propuesta representa el modelo de datos usando UML Data Modeling Profile, el cual es extraído automáticamente a partir del esquema relacional de la base de datos mediante técnicas de ingeniería inversa, para luego generar el modelo de pruebas de forma automática usando transformaciones entre modelos. Dicha transformación busca ocurrencias de patrones que, desde el punto de vista del testing, representan situaciones de prueba interesantes, y genera casos de prueba siguiendo el estándar UML Testing Profile. En este artículo se describe el entorno de trabajo y se presentan, a modo de ejemplo, el diseño de las pruebas para las operaciones de creación y eliminación de instancias.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Pruebas de Software, Pruebas basadas en modelos, Pruebas de Sistemas de Información, Datos de Prueba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Federico Toledo Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Abstracta, Montevideo, Uruguay.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ftoledo@abstracta.com.uy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Beatriz Pérez Lamancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro de Ensayos de Software, Universidad de la República  Montevideo, Uruguay ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[bperez@fing.edu.uy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Macario Polo Usaola]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha, Ciudad Real, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[macario.polo@uclm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evaluación de la cobertura en la interacción usuario-base de datos utilizando un enfoque de caja negra</title>
		<link>https://biblioteca.sistedes.es/articulo/evaluacion-de-la-cobertura-en-la-interaccion-usuario-base-de-datos-utilizando-un-enfoque-de-caja-negra/</link>
		<pubDate>Sun, 15 May 2016 17:24:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1536</guid>
		<description></description>
		<content><![CDATA[Probar una aplicación de bases de datos es una tarea laboriosa debido a que su comportamiento no sólo depende de los valores suministrados por el usuario a través de un interfaz, sino que también depende de la estructura y la información almacenada en la base de datos. Por ello, durante el diseño de los casos de prueba se debe considerar tanto la interacción con el usuario como la interacción con la base de datos. Además, la estructura de la base de datos puede tener una gran complejidad, lo que dificulta el diseño de datos de prueba de calidad. Este trabajo describe un enfoque basado en la especificación (caja negra) que guía el diseño de los datos de prueba (entradas del usuario y base de datos de prueba) para una aplicación de bases de datos y que evalúa automáticamente la cobertura alcanzada por dichos datos de prueba. Para ello se modela de forma conjunta la estructura de la base de datos y del interfaz del usuario, dando lugar a un modelo llamado Modelo Integrado de Datos (IDM), y se expresa la funcionalidad requerida mediante un conjunto de reglas de negocio, escritas en términos del IDM, que forman el Modelo de Reglas Integrado (IRM). Posteriormente se aplica un criterio de suficiencia basado en MCDC sobre el IRM para derivar automáticamente las situaciones de interés a probar (requisitos de prueba). Finalmente, se evalúa automáticamente la cobertura alcanzada por los datos de prueba diseñados. El enfoque ha sido aplicado a dos aplicaciones de bases de datos y los resultados muestran que permiten diseñar casos de prueba capaces de detectar fallos significativos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1536</post_id>
		<post_date><![CDATA[2016-05-15 19:24:02]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 17:24:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evaluacion-de-la-cobertura-en-la-interaccion-usuario-base-de-datos-utilizando-un-enfoque-de-caja-negra]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="datos-de-prueba"><![CDATA[datos de prueba]]></category>
		<category domain="post_tag" nicename="evaluacion-de-la-cobertura"><![CDATA[evaluación de la cobertura]]></category>
		<category domain="post_tag" nicename="mcdc"><![CDATA[MCDC]]></category>
		<category domain="post_tag" nicename="model-based-testing"><![CDATA[model-based testing]]></category>
		<category domain="post_tag" nicename="pruebas-basadas-en-la-especificacion"><![CDATA[pruebas basadas en la especificación]]></category>
		<category domain="post_tag" nicename="pruebas-de-caja-negra"><![CDATA[pruebas de caja negra]]></category>
		<category domain="post_tag" nicename="pruebas-sobre-bases-de-datos"><![CDATA[pruebas sobre bases de datos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1538]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/036]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Probar una aplicación de bases de datos es una tarea laboriosa debido a que su comportamiento no sólo depende de los valores suministrados por el usuario a través de un interfaz, sino que también depende de la estructura y la información almacenada en la base de datos. Por ello, durante el diseño de los casos de prueba se debe considerar tanto la interacción con el usuario como la interacción con la base de datos. Además, la estructura de la base de datos puede tener una gran complejidad, lo que dificulta el diseño de datos de prueba de calidad. Este trabajo describe un enfoque basado en la especificación (caja negra) que guía el diseño de los datos de prueba (entradas del usuario y base de datos de prueba) para una aplicación de bases de datos y que evalúa automáticamente la cobertura alcanzada por dichos datos de prueba. Para ello se modela de forma conjunta la estructura de la base de datos y del interfaz del usuario, dando lugar a un modelo llamado Modelo Integrado de Datos (IDM), y se expresa la funcionalidad requerida mediante un conjunto de reglas de negocio, escritas en términos del IDM, que forman el Modelo de Reglas Integrado (IRM). Posteriormente se aplica un criterio de suficiencia basado en MCDC sobre el IRM para derivar automáticamente las situaciones de interés a probar (requisitos de prueba). Finalmente, se evalúa automáticamente la cobertura alcanzada por los datos de prueba diseñados. El enfoque ha sido aplicado a dos aplicaciones de bases de datos y los resultados muestran que permiten diseñar casos de prueba capaces de detectar fallos significativos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[pruebas sobre bases de datos, pruebas basadas en la especificación, pruebas de caja negra, datos de prueba, evaluación de la cobertura, MCDC, model-based testing]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Raquel Blanco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo Campus de Gijón s/n, 33204 Gijón-Asturias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rblanco@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo Campus de Gijón s/n, 33204 Gijón-Asturias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Rubén V. Seco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo Campus de Gijón s/n, 33204 Gijón-Asturias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[valdesruben@uniovi.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evolutionary Mutation Testing</title>
		<link>https://biblioteca.sistedes.es/articulo/evolutionary-mutation-testing/</link>
		<pubDate>Sun, 15 May 2016 17:31:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1542</guid>
		<description></description>
		<content><![CDATA[Mutation testing is a fault-based testing technique providing a test criterion: the mutation score. This criterion can be used to measure the eectiveness of a test suite in terms of its ability to detect faults. Mutation testing generates mutants from the program under test by applying mutation operators to it.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1542</post_id>
		<post_date><![CDATA[2016-05-15 19:31:09]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 17:31:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evolutionary-mutation-testing]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1543]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/037]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Mutation testing is a fault-based testing technique providing a test criterion: the mutation score. This criterion can be used to measure the eectiveness of a test suite in terms of its ability to detect faults. Mutation testing generates mutants from the program under test by applying mutation operators to it.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan José Domínguez Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Escuela Superior de Ingeniería, C/Chile 1, CP 11002, Cádiz, España,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[juanjose.dominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonia Estero Botaro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Escuela Superior de Ingeniería, C/Chile 1, CP 11002, Cádiz, España,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[antonia.estero@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio García Domínguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Escuela Superior de Ingeniería, C/Chile 1, CP 11002, Cádiz, España,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[antonio.garciadominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Escuela Superior de Ingeniería, C/Chile 1, CP 11002, Cádiz, España,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia una propuesta de priorización de casos de pruebas a partir de NDT</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-una-propuesta-de-priorizacion-de-casos-de-pruebas-a-partir-de-ndt/</link>
		<pubDate>Sun, 15 May 2016 17:34:27 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1545</guid>
		<description></description>
		<content><![CDATA[La importancia de la fase de pruebas ha ido incrementándose de manera exponencial en los últimos tiempos, llegando a considerarse hoy en día como una de las fases más importantes durante el desarrollo de software debido a los riesgos que puede suponer que el hecho de no realizar las pruebas de forma completa o incorrecta. Estos hechos quedan reflejados a la hora de definir la planificación de los proyectos, en los que la planificación se extiende en la fase de pruebas, resultando más costoso el proyecto. Esta situación conlleva la necesidad de estudiar y aplicar nuevas técnicas para ejecutar la fase de pruebas lo más completa posible reduciendo el coste de dicha fase. Entre las técnicas para conseguir este objetivo se encuentra la técnica de priorización de los casos de pruebas. Esta técnica permite generar un conjunto de casos de pruebas idóneo para validar todas las casuísticas del proyecto. En este trabajo de investigación estudiaremos una nueva línea de investigación sobre la priorización de los casos de pruebas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1545</post_id>
		<post_date><![CDATA[2016-05-15 19:34:27]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 17:34:27]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-una-propuesta-de-priorizacion-de-casos-de-pruebas-a-partir-de-ndt]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="casos-de-pruebas"><![CDATA[casos de pruebas]]></category>
		<category domain="post_tag" nicename="ingenieria-guiada-por-modelos"><![CDATA[ingeniería guiada por modelos]]></category>
		<category domain="post_tag" nicename="priorizacion-casos-pruebas"><![CDATA[priorización casos pruebas]]></category>
		<category domain="post_tag" nicename="seleccion-casos-pruebas"><![CDATA[selección casos pruebas]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1546]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/038]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La importancia de la fase de pruebas ha ido incrementándose de manera exponencial en los últimos tiempos, llegando a considerarse hoy en día como una de las fases más importantes durante el desarrollo de software debido a los riesgos que puede suponer que el hecho de no realizar las pruebas de forma completa o incorrecta. Estos hechos quedan reflejados a la hora de definir la planificación de los proyectos, en los que la planificación se extiende en la fase de pruebas, resultando más costoso el proyecto. Esta situación conlleva la necesidad de estudiar y aplicar nuevas técnicas para ejecutar la fase de pruebas lo más completa posible reduciendo el coste de dicha fase. Entre las técnicas para conseguir este objetivo se encuentra la técnica de priorización de los casos de pruebas. Esta técnica permite generar un conjunto de casos de pruebas idóneo para validar todas las casuísticas del proyecto. En este trabajo de investigación estudiaremos una nueva línea de investigación sobre la priorización de los casos de pruebas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[priorización casos pruebas, selección casos pruebas, casos de pruebas, ingeniería guiada por modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carmen R. Cutilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de investigación IWT2, Universidad de Sevilla, Sevilla, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carmen.ruiz@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Julian A. García-García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de investigación IWT2, Universidad de Sevilla, Sevilla, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[julian.garcia@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier J. Gutiérrez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de investigación IWT2, Universidad de Sevilla, Sevilla, España ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[javierj@us.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Model-Based Testing in Early Software Development Phases</title>
		<link>https://biblioteca.sistedes.es/articulo/model-based-testing-in-early-software-development-phases/</link>
		<pubDate>Sun, 15 May 2016 17:38:55 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1548</guid>
		<description></description>
		<content><![CDATA[Despite the clear advantages of using test models, drawing them is not common practice in industry. This is not in the last place because, up to date, no easy to use tool existed that enables the creation of test models and implies less maintenance when requirements change.
In this paper we will discuss a tool that does do these things, yet is very simple, light-weight, easy to learn and does not require experience and or knowledge of difficult formal methods. Basically the tool helps a tester to draw a model, by providing a drawing canvas with a range of shapes and the possibility of connecting them. Secondly, the coverage algorithms underlying the tool, will extract all the combinations of the connections between the elements, and display a minimum set of test cases that can be used for functional or acceptance testing purposes.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1548</post_id>
		<post_date><![CDATA[2016-05-15 19:38:55]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 17:38:55]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[model-based-testing-in-early-software-development-phases]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/039]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Despite the clear advantages of using test models, drawing them is not common practice in industry. This is not in the last place because, up to date, no easy to use tool existed that enables the creation of test models and implies less maintenance when requirements change.
In this paper we will discuss a tool that does do these things, yet is very simple, light-weight, easy to learn and does not require experience and or knowledge of difficult formal methods. Basically the tool helps a tester to draw a model, by providing a drawing canvas with a range of shapes and the possibility of connecting them. Secondly, the coverage algorithms underlying the tool, will extract all the combinations of the connections between the elements, and display a minimum set of test cases that can be used for functional or acceptance testing purposes.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Silvio Cacace]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dialogues Technology]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[silvio.cacace@dialoguestechnology.nl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Tanja E.J. Vos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[tvos@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1549]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Operadores de Mutacíon de Cobertura para WS-BPEL 2.0</title>
		<link>https://biblioteca.sistedes.es/articulo/operadores-de-mutacion-de-cobertura-para-ws-bpel-2-0/</link>
		<pubDate>Sun, 15 May 2016 17:41:29 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1551</guid>
		<description></description>
		<content><![CDATA[Dada la importancia que en los últimos años están cobrando los servicios web en el ámbito de los procesos de negocio, es imprescindible contar con un soporte de casos de prueba lo suficientemente amplio como para detectar fallos y hacer que se apliquen criterios de cobertura sobre estos servicios. En este contexto está enmarcada la prueba de mutaciones, una técnica de prueba basada en fallos que requiere la definicíon de un conjunto de operadores de mutacíon para realizar cambios sintácticos en el programa que se desea probar. En este trabajo se define e implementa, por primera vez, un conjunto de operadores de mutacíon de cobertura para WS-BPEL 2.0, que aplican los criterios de cobertura definidos dentro del contexto de las pruebas de caja blanca. Además se muestran los resultados experimentales obtenidos al aplicar dichos operadores a varias composiciones WS-BPEL, viendo la aportacíon de éstos en el proceso de prueba.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1551</post_id>
		<post_date><![CDATA[2016-05-15 19:41:29]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 17:41:29]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[operadores-de-mutacion-de-cobertura-para-ws-bpel-2-0]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="criterios-de-cobertura"><![CDATA[criterios de cobertura]]></category>
		<category domain="post_tag" nicename="operadores-de-mutacion"><![CDATA[operadores de mutación]]></category>
		<category domain="post_tag" nicename="prueba-de-mutaciones"><![CDATA[prueba de mutaciones]]></category>
		<category domain="post_tag" nicename="servicios-web"><![CDATA[servicios web]]></category>
		<category domain="post_tag" nicename="ws-bpel"><![CDATA[WS-BPEL]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1552]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Dada la importancia que en los últimos años están cobrando los servicios web en el ámbito de los procesos de negocio, es imprescindible contar con un soporte de casos de prueba lo suficientemente amplio como para detectar fallos y hacer que se apliquen criterios de cobertura sobre estos servicios. En este contexto está enmarcada la prueba de mutaciones, una técnica de prueba basada en fallos que requiere la definicíon de un conjunto de operadores de mutacíon para realizar cambios sintácticos en el programa que se desea probar. En este trabajo se define e implementa, por primera vez, un conjunto de operadores de mutacíon de cobertura para WS-BPEL 2.0, que aplican los criterios de cobertura definidos dentro del contexto de las pruebas de caja blanca. Además se muestran los resultados experimentales obtenidos al aplicar dichos operadores a varias composiciones WS-BPEL, viendo la aportacíon de éstos en el proceso de prueba.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[prueba de mutaciones, operadores de mutación, criterios de cobertura, servicios web, WS-BPEL]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonia Estero Botaro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Chile 1, 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[antonia.estero@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Chile 1, 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Valentín Liñeiro Barea]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Chile 1, 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[valentin.lineirobarea@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Chile 1, 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/040]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Prueba de mutaciones sobre consultas de procesamiento de eventos en aplicaciones en tiempo real</title>
		<link>https://biblioteca.sistedes.es/articulo/prueba-de-mutaciones-sobre-consultas-de-procesamiento-de-eventos-en-aplicaciones-en-tiempo-real/</link>
		<pubDate>Sun, 15 May 2016 17:45:25 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1555</guid>
		<description></description>
		<content><![CDATA[La prueba de mutaciones es una técnica de prueba de software que ha sido usada con éxito en la prueba de lenguajes de programación clásicos. Sin embargo, no se ha empleado en la prueba de aplicaciones en tiempo real que procesen un gran número de flujos de eventos y en las que se realicen consultas de procesos de eventos. Un error mientras se está diseñando la consulta para procesar un flujo de eventos, puede ocasionar un comportamiento anómalo del sistema. En este trabajo, proponemos la prueba de mutaciones para controlar las consultas en aplicaciones en tiempo real realizadas en el lenguaje EPL de procesamiento de eventos. Se presentan y definen los operadores de mutación para EPL, comparándolos con los operadores de mutación del lenguaje SQL. Definimos los criterios necesarios para matar mutantes en EPL. Finalmente, se presenta una arquitectura para la generación automática de dichos mutantes.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1555</post_id>
		<post_date><![CDATA[2016-05-15 19:45:25]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 17:45:25]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[prueba-de-mutaciones-sobre-consultas-de-procesamiento-de-eventos-en-aplicaciones-en-tiempo-real]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="aplicaciones-en-tiempo-real"><![CDATA[Aplicaciones en tiempo real]]></category>
		<category domain="post_tag" nicename="casos-de-prueba-adecuados"><![CDATA[Casos de prueba adecuados]]></category>
		<category domain="post_tag" nicename="lenguaje-para-el-procesamiento-de-eventos"><![CDATA[Lenguaje para el Procesamiento de Eventos]]></category>
		<category domain="post_tag" nicename="operadores-de-mutacion-para-epl"><![CDATA[Operadores de mutación para EPL]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1556]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/041]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La prueba de mutaciones es una técnica de prueba de software que ha sido usada con éxito en la prueba de lenguajes de programación clásicos. Sin embargo, no se ha empleado en la prueba de aplicaciones en tiempo real que procesen un gran número de flujos de eventos y en las que se realicen consultas de procesos de eventos. Un error mientras se está diseñando la consulta para procesar un flujo de eventos, puede ocasionar un comportamiento anómalo del sistema. En este trabajo, proponemos la prueba de mutaciones para controlar las consultas en aplicaciones en tiempo real realizadas en el lenguaje EPL de procesamiento de eventos. Se presentan y definen los operadores de mutación para EPL, comparándolos con los operadores de mutación del lenguaje SQL. Definimos los criterios necesarios para matar mutantes en EPL. Finalmente, se presenta una arquitectura para la generación automática de dichos mutantes.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Lenguaje para el Procesamiento de Eventos, Operadores de mutación para EPL, Aplicaciones en tiempo real, Casos de prueba adecuados]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Lorena Gutiérrez Madroña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Sistemas Informáticos Escuela Superior de Ingeniería, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[lorena.gutierrez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan José Domínguez Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Sistemas Informáticos Escuela Superior de Ingeniería, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanjose.dominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Sistemas Informáticos Escuela Superior de Ingeniería, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Testing in Service Oriented Architectures with dynamic binding: A mapping study</title>
		<link>https://biblioteca.sistedes.es/articulo/testing-in-service-oriented-architectures-with-dynamic-binding-a-mapping-study/</link>
		<pubDate>Sun, 15 May 2016 17:47:24 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1559</guid>
		<description></description>
		<content><![CDATA[This article aims at identifying the state of the art in the research on testing Service Oriented Architectures (SOA) with dynamic binding. Testing SOA presents new challenges to researchers because some traditional testing techniques need to be suitably adapted due to the unique features of this new paradigm, for example, the dynamic behavior that allows discovering, selecting and binding a service at runtime. Testing this dynamic binding is one of the most challenging tasks in SOA because the final bound services cannot be known until the moment of the invocations. Hence, there have been a number of recent studies that aim at improving the quality of the dynamic binding using testing approaches.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1559</post_id>
		<post_date><![CDATA[2016-05-15 19:47:24]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 17:47:24]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[testing-in-service-oriented-architectures-with-dynamic-binding-a-mapping-study]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1560]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/042]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This article aims at identifying the state of the art in the research on testing Service Oriented Architectures (SOA) with dynamic binding. Testing SOA presents new challenges to researchers because some traditional testing techniques need to be suitably adapted due to the unique features of this new paradigm, for example, the dynamic behavior that allows discovering, selecting and binding a service at runtime. Testing this dynamic binding is one of the most challenging tasks in SOA because the final bound services cannot be known until the moment of the invocations. Hence, there have been a number of recent studies that aim at improving the quality of the dynamic binding using testing approaches.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Marcos Palacios]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Computing, University of Oviedo Campus Universitario de Gijón. 33204, Asturias, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[palaciosmarcos@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José García-Fanjul]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computing, University of Oviedo Campus Universitario de Gijón. 33204, Asturias, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jgfanjul@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computing, University of Oviedo Campus Universitario de Gijón. 33204, Asturias, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automated Metamorphic Testing on the Analysis of Feature Models</title>
		<link>https://biblioteca.sistedes.es/articulo/automated-metamorphic-testing-on-the-analysis-of-feature-models/</link>
		<pubDate>Sun, 15 May 2016 17:49:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1562</guid>
		<description></description>
		<content><![CDATA[Software Product Line (SPL) engineering is a reuse strategy to develop families of related systems. From common assets, different software products are assembled reducing production costs and time­to­market. Products in SPLs are defined in terms of features. A feature is an increment in product functionality. Feature models are widely used to represent all the valid combinations of features (i.e. products) of an SPL in a single model in terms of features and relations among them. The automated analysis of feature models deals with the computer­aided extraction of information from feature models. Typical operations of analysis allow determining whether a feature model is void (i.e. it represents no products), whether it contains errors (e.g. features that cannot be part of any product) or what is the number of products of the SPL represented by the model. Catalogues with up to 30 analysis operations on feature models and multiple analysis solutions have been reported.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1562</post_id>
		<post_date><![CDATA[2016-05-15 19:49:53]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 17:49:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automated-metamorphic-testing-on-the-analysis-of-feature-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1563]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/043]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Software Product Line (SPL) engineering is a reuse strategy to develop families of related systems. From common assets, different software products are assembled reducing production costs and time­to­market. Products in SPLs are defined in terms of features. A feature is an increment in product functionality. Feature models are widely used to represent all the valid combinations of features (i.e. products) of an SPL in a single model in terms of features and relations among them. The automated analysis of feature models deals with the computer­aided extraction of information from feature models. Typical operations of analysis allow determining whether a feature model is void (i.e. it represents no products), whether it contains errors (e.g. features that cannot be part of any product) or what is the number of products of the SPL represented by the model. Catalogues with up to 30 analysis operations on feature models and multiple analysis solutions have been reported.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville. Av Reina Mercedes S/N, 41012 Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Robert M. Hierons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Brunel University. Uxbridge, Middlesex, UB7 7NU United Kingdom]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[David Benavides]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Brunel University. Uxbridge, Middlesex, UB7 7NU United Kingdom]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Seville. Av Reina Mercedes S/N, 41012 Seville, Spain]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automated testing on the analysis of variability-intensive artifacts: An exploratory study with SAT Solvers</title>
		<link>https://biblioteca.sistedes.es/articulo/automated-testing-on-the-analysis-of-variability-intensive-artifacts-an-exploratory-study-with-sat-solvers/</link>
		<pubDate>Sun, 15 May 2016 17:51:57 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1565</guid>
		<description></description>
		<content><![CDATA[The automated detection of faults on variability analysis tools is a challenging task often infeasible due to the combinatorial complexity of the analyses. In previous works, we successfully automated the generation of test data for feature model analysis tools using metamorphic testing. The positive results obtained have encouraged us to explore the applicability of this technique for the efficient detection of faults in other variability-intensive domains. In this paper, we present an automated test data generator for SAT solvers that enables the generation of random propositional formulas (inputs) and their solutions (expected output). In order to show the feasibility of our approach, we introduced 100 artificial faults (i.e. mutants) in an open source SAT solver and compared the ability of our generator and three related benchmarks to detect them. Our results are promising and encourage us to generalize the technique, which could be potentially applicable to any tool dealing with variability such as Eclipse repositories or Maven dependencies analyzers.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1565</post_id>
		<post_date><![CDATA[2016-05-15 19:51:57]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 17:51:57]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automated-testing-on-the-analysis-of-variability-intensive-artifacts-an-exploratory-study-with-sat-solvers]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1566]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The automated detection of faults on variability analysis tools is a challenging task often infeasible due to the combinatorial complexity of the analyses. In previous works, we successfully automated the generation of test data for feature model analysis tools using metamorphic testing. The positive results obtained have encouraged us to explore the applicability of this technique for the efficient detection of faults in other variability-intensive domains. In this paper, we present an automated test data generator for SAT solvers that enables the generation of random propositional formulas (inputs) and their solutions (expected output). In order to show the feasibility of our approach, we introduced 100 artificial faults (i.e. mutants) in an open source SAT solver and compared the ability of our generator and three related benchmarks to detect them. Our results are promising and encourage us to generalize the technique, which could be potentially applicable to any tool dealing with variability such as Eclipse repositories or Maven dependencies analyzers.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana B. Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Seville, Av Reina Mercedes S/N Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Seville, Av Reina Mercedes S/N Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/044]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>PrMO: An Ontology of Process-reference Models</title>
		<link>https://biblioteca.sistedes.es/articulo/prmo-an-ontology-of-process-reference-models/</link>
		<pubDate>Sun, 15 May 2016 17:56:13 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1568</guid>
		<description></description>
		<content><![CDATA[For a couple of decades, process quality has been considered as one of main factors in the delivery of high quality products. Multiple models and standards have emerged as a solution to this issue, but the harmonization of several models in a company for the fulfillment of its quality requirements is no easy task. The difficulty lies in the lack of specific guidelines and in there not being any homogeneous representation which makes this labor less intense. To address that situation, this paper presents an Ontology of Process-reference Models, called PrMO. It defines a Common Structure of Process Elements (CSPE) as a means to support the harmonization of structural differences of multiple reference models, through homogenization of their process structures. PrMO has been validated through instantiation of the information contained in different models, such as CMMI-(ACQ, DEV), ISO (9001, 27001, 27002, 20000-2), ITIL, Cobit, Risk IT, Val IT, BASEL II, amongst others. Both the common structure and the homogenization method are presented, along with an application example. A WEB tool to support the homogenization of models is also described, along with other uses which illustrate the advantages of PrMO. The proposed ontology could be extremely useful for organizations and other consultants that plan to carry out the harmonization of multiple models. Keywords: Harmonization of multiple models and standards; homogenization; mapping; integration; ontology, processes.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1568</post_id>
		<post_date><![CDATA[2016-05-15 19:56:13]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 17:56:13]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[prmo-an-ontology-of-process-reference-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1569]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/045]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[For a couple of decades, process quality has been considered as one of main factors in the delivery of high quality products. Multiple models and standards have emerged as a solution to this issue, but the harmonization of several models in a company for the fulfillment of its quality requirements is no easy task. The difficulty lies in the lack of specific guidelines and in there not being any homogeneous representation which makes this labor less intense. To address that situation, this paper presents an Ontology of Process-reference Models, called PrMO. It defines a Common Structure of Process Elements (CSPE) as a means to support the harmonization of structural differences of multiple reference models, through homogenization of their process structures. PrMO has been validated through instantiation of the information contained in different models, such as CMMI-(ACQ, DEV), ISO (9001, 27001, 27002, 20000-2), ITIL, Cobit, Risk IT, Val IT, BASEL II, amongst others. Both the common structure and the homogenization method are presented, along with an application example. A WEB tool to support the homogenization of models is also described, along with other uses which illustrate the advantages of PrMO. The proposed ontology could be extremely useful for organizations and other consultants that plan to carry out the harmonization of multiple models. Keywords: Harmonization of multiple models and standards; homogenization; mapping; integration; ontology, processes.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[César Pardo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[IDIS Research Group Electronic and Telecommunications Engineering Faculty University of Cauca, Street 5 # 4 - 70. Kybele Consulting Colombia (Spinoff) Popayán, Cauca, Colombia.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cpardo@unicauca.edu.co]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Félix García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ALARCOS Research Group ITSI, Information Systems and Technologies Department University of Castilla­La Mancha, Paseo de la Universidad 4, Ciudad Real, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Felix.Garcia@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco J. Pino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[IDIS Research Group Electronic and Telecommunications Engineering Faculty University of Cauca, Street 5 # 4 - 70. Kybele Consulting Colombia (Spinoff) Popayán, Cauca, Colombia.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fjpino@unicauca.edu.co]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[ALARCOS Research Group ITSI, Information Systems and Technologies Department University of Castilla­La Mancha, Paseo de la Universidad 4, Ciudad Real, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Mario.Piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[María Teresa Baldassarre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Department of Informatics, University of Bari. SER&Practices, SPINOFF, Via E. Orabona 4, 70126, Bari, Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[baldassarre@di.uniba.it]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Approach to Test-Driven Development of Conceptual Schemas</title>
		<link>https://biblioteca.sistedes.es/articulo/an-approach-to-test-driven-development-of-conceptual-schemas/</link>
		<pubDate>Sun, 15 May 2016 18:01:44 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1571</guid>
		<description></description>
		<content><![CDATA[Conceptual modeling is an essential requirements engineering activity. Its objective is the development of the conceptual schema (CS) of an Information System (IS), which defines the general knowledge that an IS needs to know to perform its functions.
A CS consists of a structural (sub)schema and a behavioral (sub)schema. The structural schema consists of a taxonomy of entity types, a set of relationship types, and the constraints they must satisfy. The behavioral schema consists of a set of event types with their characteristics, constraints and effects.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1571</post_id>
		<post_date><![CDATA[2016-05-15 20:01:44]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 18:01:44]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-approach-to-test-driven-development-of-conceptual-schemas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1572]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/046]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Conceptual modeling is an essential requirements engineering activity. Its objective is the development of the conceptual schema (CS) of an Information System (IS), which defines the general knowledge that an IS needs to know to perform its functions.
A CS consists of a structural (sub)schema and a behavioral (sub)schema. The structural schema consists of a taxonomy of entity types, a set of relationship types, and the constraints they must satisfy. The behavioral schema consists of a set of event types with their characteristics, constraints and effects.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Albert Tort]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Service and Information System Engineering Universitat Politècnica de Catalunya - BarcelonaTech Barcelona, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[atort@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antoni Olivé]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Service and Information System Engineering Universitat Politècnica de Catalunya - BarcelonaTech Barcelona, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[olive@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Maria-Ribera Sancho]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Service and Information System Engineering Universitat Politècnica de Catalunya - BarcelonaTech Barcelona, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ribera@essi.upc.edu]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>GAmeraHOM: una herramienta de generación de mutantes de orden superior para WS-BPEL</title>
		<link>https://biblioteca.sistedes.es/articulo/gamerahom-una-herramienta-de-generacion-de-mutantes-de-orden-superior-para-ws-bpel/</link>
		<pubDate>Sun, 15 May 2016 18:03:04 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1574</guid>
		<description></description>
		<content><![CDATA[El desarrollo de técnicas para que la prueba de mutaciones disminuya el tiempo de cómputo y reduzca los mutantes producidos no han ido en paralelo al desarrollo de herramientas generadoras de mutantes que las implementen. Una de las técnicas de optimización propuestas sugiere utilizar mutantes de orden superior, sin embargo apenas existen herramientas que la implementen. En este trabajo se presenta GAmeraHOM, el primer generador de mutantes de orden superior para WS-BPEL, basado en la mutación evolutiva mediante el empleo de un algoritmo genético. Esto conlleva una reducción del número de mutantes generados y ejecutados, seleccionando principalmente los mutantes difíciles de matar y los potencialmente equivalentes. Este conjunto reducido permitirá mejorar la calidad del conjunto de casos de prueba. La herramienta GAmeraHOM provee una configuración fácilmente parametrizable y además permite adaptar el código del generador a otros lenguajes de forma independiente.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1574</post_id>
		<post_date><![CDATA[2016-05-15 20:03:04]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 18:03:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[gamerahom-una-herramienta-de-generacion-de-mutantes-de-orden-superior-para-ws-bpel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="algoritmo-genetico"><![CDATA[algoritmo genético]]></category>
		<category domain="post_tag" nicename="composiciones-de-servicios"><![CDATA[composiciones de servicios]]></category>
		<category domain="post_tag" nicename="generador-de-mutantes"><![CDATA[generador de mutantes]]></category>
		<category domain="post_tag" nicename="mutantes-de-orden-superior"><![CDATA[mutantes de orden superior]]></category>
		<category domain="post_tag" nicename="prueba-de-mutaciones"><![CDATA[prueba de mutaciones]]></category>
		<category domain="post_tag" nicename="prueba-del-software"><![CDATA[prueba del software]]></category>
		<category domain="post_tag" nicename="ws-bpel-2-0"><![CDATA[WS-BPEL 2.0]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El desarrollo de técnicas para que la prueba de mutaciones disminuya el tiempo de cómputo y reduzca los mutantes producidos no han ido en paralelo al desarrollo de herramientas generadoras de mutantes que las implementen. Una de las técnicas de optimización propuestas sugiere utilizar mutantes de orden superior, sin embargo apenas existen herramientas que la implementen. En este trabajo se presenta GAmeraHOM, el primer generador de mutantes de orden superior para WS-BPEL, basado en la mutación evolutiva mediante el empleo de un algoritmo genético. Esto conlleva una reducción del número de mutantes generados y ejecutados, seleccionando principalmente los mutantes difíciles de matar y los potencialmente equivalentes. Este conjunto reducido permitirá mejorar la calidad del conjunto de casos de prueba. La herramienta GAmeraHOM provee una configuración fácilmente parametrizable y además permite adaptar el código del generador a otros lenguajes de forma independiente.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[prueba de mutaciones, mutantes de orden superior, generador de mutantes, algoritmo genético, WS-BPEL 2.0, composiciones de servicios, prueba del software]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1575]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/047]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Emma Blanco Muñoz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Escuela Superior de Ingeniería C/Chile 1, CP 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ emma.blancomu@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio García Domínguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Escuela Superior de Ingeniería C/Chile 1, CP 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[antonio.garciadominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan José Domínguez Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Escuela Superior de Ingeniería C/Chile 1, CP 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanjose.dominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Escuela Superior de Ingeniería C/Chile 1, CP 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>MuBPEL: una Herramienta de Mutación Firme para WS-BPEL 2.0</title>
		<link>https://biblioteca.sistedes.es/articulo/mubpel-una-herramienta-de-mutacion-firme-para-ws-bpel-2-0/</link>
		<pubDate>Sun, 15 May 2016 18:09:17 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1577</guid>
		<description></description>
		<content><![CDATA[La prueba de mutaciones evalúa la calidad de un conjunto de casos de prueba realizando cambios en el programa y comprobando si las pruebas los detectan. Se ha aplicado con éxito sobre programas FORTRAN, C y Java, entre otros. Dos problemas comunes son la dificultad de detectar cambios que no modifican el significado del programa, y su alto coste computacional. La mutación firme es una variante de la mutación fuerte tradicional que compara estados intermedios. En este trabajo presentamos MuBPEL, una herramienta de código abierto de mutación firme para composiciones de servicios Web escritas en WS-BPEL 2.0. Los operadores de mutación están implementados en XSLT 2.0 y su organización permite añadir nuevos operadores de forma sencilla. MuBPEL integra el motor ActiveBPEL y la biblioteca de pruebas unitarias BPELUnit de forma transparente y permite paralelizar el trabajo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1577</post_id>
		<post_date><![CDATA[2016-05-15 20:09:17]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 18:09:17]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mubpel-una-herramienta-de-mutacion-firme-para-ws-bpel-2-0]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="composiciones-de-servicios"><![CDATA[composiciones de servicios]]></category>
		<category domain="post_tag" nicename="mutacion-firme"><![CDATA[mutación firme]]></category>
		<category domain="post_tag" nicename="prueba-de-mutaciones"><![CDATA[prueba de mutaciones]]></category>
		<category domain="post_tag" nicename="prueba-del-software"><![CDATA[prueba del software]]></category>
		<category domain="post_tag" nicename="ws-bpel-2-0"><![CDATA[WS-BPEL 2.0]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1578]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/048]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La prueba de mutaciones evalúa la calidad de un conjunto de casos de prueba realizando cambios en el programa y comprobando si las pruebas los detectan. Se ha aplicado con éxito sobre programas FORTRAN, C y Java, entre otros. Dos problemas comunes son la dificultad de detectar cambios que no modifican el significado del programa, y su alto coste computacional. La mutación firme es una variante de la mutación fuerte tradicional que compara estados intermedios. En este trabajo presentamos MuBPEL, una herramienta de código abierto de mutación firme para composiciones de servicios Web escritas en WS-BPEL 2.0. Los operadores de mutación están implementados en XSLT 2.0 y su organización permite añadir nuevos operadores de forma sencilla. MuBPEL integra el motor ActiveBPEL y la biblioteca de pruebas unitarias BPELUnit de forma transparente y permite paralelizar el trabajo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[prueba de mutaciones, mutación firme, WS-BPEL 2.0, composiciones de servicios, prueba del software]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio García Domínguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Escuela Superior de Ingeniería, C/Chile 1, CP 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[antonio.garciadominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonia Estero Botaro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Escuela Superior de Ingeniería, C/Chile 1, CP 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[antonia.estero@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan José Domínguez Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Escuela Superior de Ingeniería, C/Chile 1, CP 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanjose.dominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Escuela Superior de Ingeniería, C/Chile 1, CP 11002, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Francisco Palomo Lozano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Escuela Superior de Ingeniería, C/Chile 1, CP 11002, Cádiz, España]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Tutorial de Pruebas de Rendimiento</title>
		<link>https://biblioteca.sistedes.es/articulo/tutorial-de-pruebas-de-rendimiento/</link>
		<pubDate>Sun, 15 May 2016 18:11:30 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1580</guid>
		<description></description>
		<content><![CDATA[Una prueba de desempeño (performance test) se define como una investigación técnica para determinar o validar la velocidad, escalabilidad y/o características de estabilidad de un sistema bajo prueba. Las pruebas de carga (load test) tienen como objetivo simular la realidad a la cual estará sometido el sistema en producción (lo cual se conoce como escenario) para analizar su desempeño ante esa situación. En este tutorial se presenta una metodología que se encuentra en el marco de la Ingeniería de Software más precisamente en el área de Verificación de Software, útil para realizar pruebas de carga, aunque puede ser extendida a otros tipos de pruebas de desempeño como por ejemplo pruebas de estrés o pruebas de picos. Uno de los desafíos de las pruebas de performance es lograr reducir riesgos del negocio y obtener información útil del sistema en tiempos reducidos, tratando de obtener información de valor que permita maximizar la relación costo/beneficio de la prueba. El tutorial se orientaría principalmente a las áreas de desarrollo de sistemas empresariales, pruebas de software, metodologías y procesos. El objetivo del curso es transmitir a los participantes la necesidad de la realización de este tipo de pruebas en forma oportuna, y una metodología clara como para poder llevar a cabo estas tareas, viendo con ejemplos y demostraciones las herramientas necesarias para la simulación de la carga de usuarios concurrentes (en particular OpenSTA), así como la monitorización de sistemas (a nivel de Sistema Operativo y de aplicación), introduciéndonos en el análisis de resultados.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1580</post_id>
		<post_date><![CDATA[2016-05-15 20:11:30]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 18:11:30]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[tutorial-de-pruebas-de-rendimiento]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="aseguramiento-de-la-calidad"><![CDATA[aseguramiento de la calidad]]></category>
		<category domain="post_tag" nicename="metodologia"><![CDATA[Metodología]]></category>
		<category domain="post_tag" nicename="performance-testing"><![CDATA[performance testing]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1581]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/049]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Una prueba de desempeño (performance test) se define como una investigación técnica para determinar o validar la velocidad, escalabilidad y/o características de estabilidad de un sistema bajo prueba. Las pruebas de carga (load test) tienen como objetivo simular la realidad a la cual estará sometido el sistema en producción (lo cual se conoce como escenario) para analizar su desempeño ante esa situación. En este tutorial se presenta una metodología que se encuentra en el marco de la Ingeniería de Software más precisamente en el área de Verificación de Software, útil para realizar pruebas de carga, aunque puede ser extendida a otros tipos de pruebas de desempeño como por ejemplo pruebas de estrés o pruebas de picos. Uno de los desafíos de las pruebas de performance es lograr reducir riesgos del negocio y obtener información útil del sistema en tiempos reducidos, tratando de obtener información de valor que permita maximizar la relación costo/beneficio de la prueba. El tutorial se orientaría principalmente a las áreas de desarrollo de sistemas empresariales, pruebas de software, metodologías y procesos. El objetivo del curso es transmitir a los participantes la necesidad de la realización de este tipo de pruebas en forma oportuna, y una metodología clara como para poder llevar a cabo estas tareas, viendo con ejemplos y demostraciones las herramientas necesarias para la simulación de la carga de usuarios concurrentes (en particular OpenSTA), así como la monitorización de sistemas (a nivel de Sistema Operativo y de aplicación), introduciéndonos en el análisis de resultados.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[performance testing, metodología, aseguramiento de la calidad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Federico Toledo Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Abstracta, Montevideo, Uruguay.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ftoledo@abstracta.com.uy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Beatriz Pérez Lamancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro de Ensayos de Software, Universidad de la República, Montevideo, Uruguay]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[bperez@fing.edu.uy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Macario Polo Usaola]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha, Ciudad Real, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[macario.polo@uclm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Creación Colaborativa de Lenguajes Específicos de Dominio</title>
		<link>https://biblioteca.sistedes.es/articulo/creacion-colaborativa-de-lenguajes-especificos-de-dominio/</link>
		<pubDate>Sun, 15 May 2016 21:44:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1588</guid>
		<description></description>
		<content><![CDATA[El desarrollo de sofware es un proceso donde participan muchos actores, principalmente los desarrolladores y los clientes del producto. En la actualidad, procesos de desarrollo como los basados en metodologías ágiles proponen la participación de forma directa de los usuarios o clientes. La idea clave es definir procesos guiados por la comunidad donde todos los participantes (técnicos y no técnicos) colaboran para que el producto satisfaga los requisitos. Esta aproximación es especialmente interesante en el ámbito del desarrollo de lenguajes específicos de dominio (DSL). Sin embargo, aunque estos lenguajes están destinados a una comunidad de usuarios expertos de un dominio concreto, actualmente dichos usuarios tienen poca (o nula) participación en el desarrollo. Nuestra propuesta consiste en incorporar el aspecto colaborativo en los procesos de desarrollo de DSLs, permitiendo a la comunidad de usuarios del lenguaje participar activamente en su creación y evolución. Para ello proponemos adaptar Collaboro, un lenguaje para representar las actividades de colaboración que surgen durante el desarrollo de DSLs, para ser utilizado a lo largo de todo el proceso.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1588</post_id>
		<post_date><![CDATA[2016-05-15 23:44:50]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 21:44:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[creacion-colaborativa-de-lenguajes-especificos-de-dominio]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1589]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/050]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El desarrollo de sofware es un proceso donde participan muchos actores, principalmente los desarrolladores y los clientes del producto. En la actualidad, procesos de desarrollo como los basados en metodologías ágiles proponen la participación de forma directa de los usuarios o clientes. La idea clave es definir procesos guiados por la comunidad donde todos los participantes (técnicos y no técnicos) colaboran para que el producto satisfaga los requisitos. Esta aproximación es especialmente interesante en el ámbito del desarrollo de lenguajes específicos de dominio (DSL). Sin embargo, aunque estos lenguajes están destinados a una comunidad de usuarios expertos de un dominio concreto, actualmente dichos usuarios tienen poca (o nula) participación en el desarrollo. Nuestra propuesta consiste en incorporar el aspecto colaborativo en los procesos de desarrollo de DSLs, permitiendo a la comunidad de usuarios del lenguaje participar activamente en su creación y evolución. Para ello proponemos adaptar Collaboro, un lenguaje para representar las actividades de colaboración que surgen durante el desarrollo de DSLs, para ser utilizado a lo largo de todo el proceso.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Luis Cánovas Izquierdo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[AtlanMod, é cole des Mines de Nantes ­ INRIA ­ LINA, Nantes, France, ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[javier.canovas@inria.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jordi Cabot]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[AtlanMod, é cole des Mines de Nantes ­ INRIA ­ LINA, Nantes, France, ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jordi.cabot@inria.fr]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>On the Modular Specification of Non-Functional Properties in DSVLs</title>
		<link>https://biblioteca.sistedes.es/articulo/on-the-modular-specification-of-non-functional-properties-in-dsvls/</link>
		<pubDate>Sun, 15 May 2016 21:47:12 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1591</guid>
		<description></description>
		<content><![CDATA[In previous work we have presented an approach to monitor nonfunctional properties of systems modeled in terms of domain specific visual languages using observers. In this work we present an approach to decouple the definition of observers behavior and systems behavior. Having a library with different kinds of observers behavior, and having the behavioral definition of the system, weaving links can be established among them in order to include observers in the system behavioral specification.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1591</post_id>
		<post_date><![CDATA[2016-05-15 23:47:12]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 21:47:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[on-the-modular-specification-of-non-functional-properties-in-dsvls]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="dsvls"><![CDATA[DSVLs]]></category>
		<category domain="post_tag" nicename="observers"><![CDATA[observers]]></category>
		<category domain="post_tag" nicename="weaving-mechanisms"><![CDATA[weaving mechanisms]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1592]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/051]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In previous work we have presented an approach to monitor nonfunctional properties of systems modeled in terms of domain specific visual languages using observers. In this work we present an approach to decouple the definition of observers behavior and systems behavior. Having a library with different kinds of observers behavior, and having the behavioral definition of the system, weaving links can be established among them in order to include observers in the system behavioral specification.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[DSVLs, weaving mechanisms, observers]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Troya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[GISUM/Atenea Research Group. Universidad de Málaga (Spain) ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[javiertc@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Vallecillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[GISUM/Atenea Research Group. Universidad de Málaga (Spain) ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[av@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco Durán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[GISUM/Atenea Research Group. Universidad de Málaga (Spain) ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[duran@lcc.uma.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Secure Bussiness Process Model specification through a UML 2.0 Activity Diagram Profile</title>
		<link>https://biblioteca.sistedes.es/articulo/secure-bussiness-process-model-specification-through-a-uml-2-0-activity-diagram-profile/</link>
		<pubDate>Sun, 15 May 2016 21:48:42 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1594</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1594</post_id>
		<post_date><![CDATA[2016-05-15 23:48:42]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 21:48:42]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[secure-bussiness-process-model-specification-through-a-uml-2-0-activity-diagram-profile]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1595]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/052]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Definición del dominio de las aplicaciones Web basadas en CMS: un Metamodelo Común para CMS</title>
		<link>https://biblioteca.sistedes.es/articulo/definicion-del-dominio-de-las-aplicaciones-web-basadas-en-cms-un-metamodelo-comun-para-cms/</link>
		<pubDate>Sun, 15 May 2016 21:51:34 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1597</guid>
		<description></description>
		<content><![CDATA[En los últimos años, los Sistemas de Gestión de Contenidos (Content Management System, CMS) han aumentado su presencia en organizaciones y empresas gracias a las ventajas que ofrecen para la gestión del contenido digital. En concreto, las empresas han empezado a utilizar CMSs como plataforma de desarrollo para sus aplicaciones Web. Por esta razón, las aplicaciones Web basadas en CMS han ganado popularidad rápidamente. A pesar de ello, los métodos de ingeniería Web que existen en la actualidad no están del todo adaptados al dominio de los CMS. Esto queda reflejado en los lenguajes de modelado que proponen los métodos de ingeniería Web dirigidos por modelos ya que carecen de expresividad para representar y capturar los elementos necesarios para desarrollar este tipo de aplicaciones Web. Para contribuir a la solución de este problema presentamos en este artículo un metamodelo que recoge los principales conceptos para modelar aplicaciones Web basadas en CMS, CMS-CM (CMS Common Metamodel). Este metamodelo podría ser utilizado para extender los lenguajes de modelado ya existentes, además de servir de base a nuevos lenguajes de modelado específicos para el ámbito de los CMS.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1597</post_id>
		<post_date><![CDATA[2016-05-15 23:51:34]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 21:51:34]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[definicion-del-dominio-de-las-aplicaciones-web-basadas-en-cms-un-metamodelo-comun-para-cms]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="desarrollo-dirigido-por-modelos"><![CDATA[Desarrollo dirigido por modelos]]></category>
		<category domain="post_tag" nicename="ingenieria-web"><![CDATA[Ingeniería Web]]></category>
		<category domain="post_tag" nicename="lenguaje-especifico-de-dominio"><![CDATA[Lenguaje Específico de Dominio]]></category>
		<category domain="post_tag" nicename="sistema-de-gestion-de-contenidos"><![CDATA[Sistema de Gestión de Contenidos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1598]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/053]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años, los Sistemas de Gestión de Contenidos (Content Management System, CMS) han aumentado su presencia en organizaciones y empresas gracias a las ventajas que ofrecen para la gestión del contenido digital. En concreto, las empresas han empezado a utilizar CMSs como plataforma de desarrollo para sus aplicaciones Web. Por esta razón, las aplicaciones Web basadas en CMS han ganado popularidad rápidamente. A pesar de ello, los métodos de ingeniería Web que existen en la actualidad no están del todo adaptados al dominio de los CMS. Esto queda reflejado en los lenguajes de modelado que proponen los métodos de ingeniería Web dirigidos por modelos ya que carecen de expresividad para representar y capturar los elementos necesarios para desarrollar este tipo de aplicaciones Web. Para contribuir a la solución de este problema presentamos en este artículo un metamodelo que recoge los principales conceptos para modelar aplicaciones Web basadas en CMS, CMS-CM (CMS Common Metamodel). Este metamodelo podría ser utilizado para extender los lenguajes de modelado ya existentes, además de servir de base a nuevos lenguajes de modelado específicos para el ámbito de los CMS.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Ingeniería Web, Desarrollo Dirigido por Modelos, Lenguaje Específico de Dominio, Sistema de Gestión de Contenidos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Feliu Trias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group Rey Juan Carlos University Tulipán S/N, 28933, Móstoles, Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[feliu.trias@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Valeria de Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group Rey Juan Carlos University Tulipán S/N, 28933, Móstoles, Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[valeria.decastro@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Marcos López-Sanz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group Rey Juan Carlos University Tulipán S/N, 28933, Móstoles, Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[marcos.lopez@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group Rey Juan Carlos University Tulipán S/N, 28933, Móstoles, Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Moskitt4SPL: Tool Support for Developing Self-Adaptive Systems</title>
		<link>https://biblioteca.sistedes.es/articulo/moskitt4spl-tool-support-for-developing-self-adaptive-systems/</link>
		<pubDate>Sun, 15 May 2016 21:54:23 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1600</guid>
		<description></description>
		<content><![CDATA[Increasingly, software needs to dynamically adapt its behavior at runtime in response to changing conditions in the supporting computing, communication infrastructure, and in the surrounding physical environment [6]. Self-adaptive software systems are able to reconfigure at run-time to adapt to changes. The implementation of ad-hoc solutions to cover all possible system configurations and reconfigurations is not feasible. Dynamic Software Product Lines (DSPLs) provide a systematic basis for the engineering of selfadaptive systems [4]. A key characteristic in DSPLs is the intensive use of variability at run-time in order to adapt the system configuration caused by an environment change. Following this approach, a self-adaptive system can be seen as a family of feasible system configurations with a mechanism to move from one configuration to another. The development of self-adaptive systems involves great complexity and becomes a tedious task. We propose Moskitt4SPL (M4SPL) an open-source tool to ease the development of self-adaptive systems. In this tool, we combine model-driven and DSPLs to better cope with the complexities during the construction of self-adaptive systems. M4SPL can be used for modeling systems which make use of variability at run-time in order to adapt the system configuration caused by an environment change. M4SPL provides edition capabilities for Feature Models, Configuration Models and Resolution Models which are part of a self-adaptive system specification. Furthermore, M4SPL incorporates a series of refinements to automatically ensure interesting behavior issues in adaptation specifications. Dealing with those issues before execution is essential for reliable selfadaptive systems that fulfill many of the user's needs. M4SPL can be used standalone as an Eclipse plug-in or integrated in the MDE MOSKitt environment.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1600</post_id>
		<post_date><![CDATA[2016-05-15 23:54:23]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 21:54:23]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[moskitt4spl-tool-support-for-developing-self-adaptive-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1601]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/054]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Increasingly, software needs to dynamically adapt its behavior at runtime in response to changing conditions in the supporting computing, communication infrastructure, and in the surrounding physical environment [6]. Self-adaptive software systems are able to reconfigure at run-time to adapt to changes. The implementation of ad-hoc solutions to cover all possible system configurations and reconfigurations is not feasible. Dynamic Software Product Lines (DSPLs) provide a systematic basis for the engineering of selfadaptive systems [4]. A key characteristic in DSPLs is the intensive use of variability at run-time in order to adapt the system configuration caused by an environment change. Following this approach, a self-adaptive system can be seen as a family of feasible system configurations with a mechanism to move from one configuration to another. The development of self-adaptive systems involves great complexity and becomes a tedious task. We propose Moskitt4SPL (M4SPL) an open-source tool to ease the development of self-adaptive systems. In this tool, we combine model-driven and DSPLs to better cope with the complexities during the construction of self-adaptive systems. M4SPL can be used for modeling systems which make use of variability at run-time in order to adapt the system configuration caused by an environment change. M4SPL provides edition capabilities for Feature Models, Configuration Models and Resolution Models which are part of a self-adaptive system specification. Furthermore, M4SPL incorporates a series of refinements to automatically ensure interesting behavior issues in adaptation specifications. Dealing with those issues before execution is essential for reliable selfadaptive systems that fulfill many of the user's needs. M4SPL can be used standalone as an Eclipse plug-in or integrated in the MDE MOSKitt environment.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Gómez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Métodos de Producción de Software Universitat Politècnica de València Camino de Vera s/n, E-46022, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[magomez@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ignacio Mansanet]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Métodos de Producción de Software Universitat Politècnica de València Camino de Vera s/n, E-46022, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[imansanet@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Joan Fons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Métodos de Producción de Software Universitat Politècnica de València Camino de Vera s/n, E-46022, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jjfons@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Métodos de Producción de Software Universitat Politècnica de València Camino de Vera s/n, E-46022, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[pele@dsic.upv.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Aplicando los principios del DSDM al desarrollo de transformaciones de modelos en ETL</title>
		<link>https://biblioteca.sistedes.es/articulo/aplicando-los-principios-del-dsdm-al-desarrollo-de-transformaciones-de-modelos-en-etl/</link>
		<pubDate>Sun, 15 May 2016 21:57:23 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1603</guid>
		<description></description>
		<content><![CDATA[Las transformaciones de modelos son uno de los principales artefactos en el Desarrollo de Software Dirigido por Modelos. Sin embargo, a pesar de ser otro artefacto software más, existen pocas aproximaciones que apliquen los principios del DSDM a su desarrollo. En este trabajo presentamos una aproximación para el desarrollo de transformaciones de modelos dirigido por modelos para el lenguaje Epsilon Transformation Language (ETL). Para ello, presentamos un metamodelo para el lenguaje ETL, una transformacíon que permite obtener un modelo ETL a partir de un modelo de la transformación de alto nivel y la generacíon del código ETL que implementa la transformación.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1603</post_id>
		<post_date><![CDATA[2016-05-15 23:57:23]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 21:57:23]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[aplicando-los-principios-del-dsdm-al-desarrollo-de-transformaciones-de-modelos-en-etl]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="atl"><![CDATA[ATL]]></category>
		<category domain="post_tag" nicename="desarrollo-dirigido-por-modelos"><![CDATA[Desarrollo dirigido por modelos]]></category>
		<category domain="post_tag" nicename="etl"><![CDATA[ETL]]></category>
		<category domain="post_tag" nicename="modelos-de-transformacion"><![CDATA[Modelos de Transformación]]></category>
		<category domain="post_tag" nicename="transformaciones-de-modelos"><![CDATA[Transformaciones de Modelos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1604]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/055]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las transformaciones de modelos son uno de los principales artefactos en el Desarrollo de Software Dirigido por Modelos. Sin embargo, a pesar de ser otro artefacto software más, existen pocas aproximaciones que apliquen los principios del DSDM a su desarrollo. En este trabajo presentamos una aproximación para el desarrollo de transformaciones de modelos dirigido por modelos para el lenguaje Epsilon Transformation Language (ETL). Para ello, presentamos un metamodelo para el lenguaje ETL, una transformacíon que permite obtener un modelo ETL a partir de un modelo de la transformación de alto nivel y la generacíon del código ETL que implementa la transformación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Desarrollo Dirigido por Modelos, Transformaciones de Modelos, Modelos de Transformación, ETL, ATL]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alvaro Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigacíon Kybele, Universidad Rey Juan Carlos, Madrid (España).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alvaro.jimenez@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Verónica A. Bollati]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigacíon Kybele, Universidad Rey Juan Carlos, Madrid (España).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[veronica.bollati@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan M. Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigacíon Kybele, Universidad Rey Juan Carlos, Madrid (España).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigacíon Kybele, Universidad Rey Juan Carlos, Madrid (España).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un proceso de modernización dirigido por modelos de sistemas web heredados hacia SOAs</title>
		<link>https://biblioteca.sistedes.es/articulo/un-proceso-de-modernizacion-dirigido-por-modelos-de-sistemas-web-heredados-hacia-soas/</link>
		<pubDate>Sun, 15 May 2016 22:00:39 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1606</guid>
		<description></description>
		<content><![CDATA[En estos últimos años, empresas y administraciones públicas
han desarrollado un ecosistema de aplicaciones Web para ofrecer servicios en general, tanto hacia Internet como hacia sus intranets. Sin embargo, tanto empresas como administraciones públicas están descubriendo que sus webs no están alineadas con sus procesos de negocios, ya que éstas se crearon para solventar problemas concretos, en algunos casos duplicando funcionalidades y sin tener en cuenta la naturaleza cambiante de los procesos de negocio.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1606</post_id>
		<post_date><![CDATA[2016-05-16 00:00:39]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 22:00:39]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-proceso-de-modernizacion-dirigido-por-modelos-de-sistemas-web-heredados-hacia-soas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1607]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/056]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En estos últimos años, empresas y administraciones públicas
han desarrollado un ecosistema de aplicaciones Web para ofrecer servicios en general, tanto hacia Internet como hacia sus intranets. Sin embargo, tanto empresas como administraciones públicas están descubriendo que sus webs no están alineadas con sus procesos de negocios, ya que éstas se crearon para solventar problemas concretos, en algunos casos duplicando funcionalidades y sin tener en cuenta la naturaleza cambiante de los procesos de negocio.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Encarna Sosa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Quercuss Software Engineering Group. Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[esosa@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pedro J. Clemente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Quercuss Software Engineering Group. Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pjclemente@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José M. Conejero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Quercuss Software Engineering Group. Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[chemacm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Roberto Rodríguez-Echeverría]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Quercuss Software Engineering Group. Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[rre@unex.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un framework basado en modelos para la modernización de datos</title>
		<link>https://biblioteca.sistedes.es/articulo/un-framework-basado-en-modelos-para-la-modernizacion-de-datos/</link>
		<pubDate>Sun, 15 May 2016 22:02:32 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1609</guid>
		<description></description>
		<content><![CDATA[La modernización de software permite a las empresas mantener el valor estratégico de sus sistemas legacy (legados). La reingeniería de datos es un tipo de modernización que mejora la calidad de los datos de dichos sistemas. En este trabajo presentamos una arquitectura basada en las técnicas de la Ingeniería de Software Dirigida por Modelos que automatiza la tarea de la reingeniería de los datos relacionada con la mejora de la calidad y la migracíon de datos. Además la solución propuesta tambíen proporciona independencia respecto del sistema gestor de base de datos a modernizar.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1609</post_id>
		<post_date><![CDATA[2016-05-16 00:02:32]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 22:02:32]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-framework-basado-en-modelos-para-la-modernizacion-de-datos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="ingenieria-de-software-dirigida-por-modelos"><![CDATA[Ingeniería de Software Dirigida por Modelos]]></category>
		<category domain="post_tag" nicename="modernizacion-de-datos"><![CDATA[Modernizacíon de datos]]></category>
		<category domain="post_tag" nicename="reingenieria-de-datos"><![CDATA[Reingeniería de datos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1610]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/057]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La modernización de software permite a las empresas mantener el valor estratégico de sus sistemas legacy (legados). La reingeniería de datos es un tipo de modernización que mejora la calidad de los datos de dichos sistemas. En este trabajo presentamos una arquitectura basada en las técnicas de la Ingeniería de Software Dirigida por Modelos que automatiza la tarea de la reingeniería de los datos relacionada con la mejora de la calidad y la migracíon de datos. Además la solución propuesta tambíen proporciona independencia respecto del sistema gestor de base de datos a modernizar.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Ingeniería de Software Dirigida por Modelos, Modernizacíon de datos, Reingeniería de datos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Fco. Javier Bermúdez Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia, Murcia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fjavier@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jesús García Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia, Murcia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jmolina@um.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>iTrace: un framework para soportar el análisis de información de trazabilidad en proyectos de Desarrollo Software Dirigidos por Modelos</title>
		<link>https://biblioteca.sistedes.es/articulo/itrace-un-framework-para-soportar-el-analisis-de-informacion-de-trazabilidad-en-proyectos-de-desarrollo-software-dirigidos-por-modelos/</link>
		<pubDate>Sun, 15 May 2016 22:05:25 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1612</guid>
		<description></description>
		<content><![CDATA[El papel clave de los modelos en cualquier proceso de Desarrollo de Software Dirigido por Modelos (DSDM) proporciona un nuevo escenario para manejar la trazabilidad. Hasta ahora, existen una serie de propuestas dedicadas al almacenamiento, visualización, generación semi-automática y gestión de operaciones CRUD con enlaces de traza. No obstante, existe una falta de propuestas que se centren en el análisis de la información proporcionada por tales trazas. Además, las propuestas que llevan a cabo algún tipo de análisis de la información de trazabilidad no tienen en cuenta que esta información es consumida por diferentes tipos de actores, cada uno con sus propias necesidades. Para abordar estas cuestiones en este trabajo se introduce iTrace, un framework para la gestión y el análisis de la información de trazabilidad en proyectos de DSDM. Nuestra propuesta busca mejorar el uso que se hace de la información de trazabilidad disponible en proyectos de DSDM mediante dos tipos diferentes de análisis: análisis orientado a modelos, para modeladores, desarrolladores y el resto de perfiles operativos y análisis orientado a datos, para jefes de proyecto, analistas de negocio y usuarios finales en general.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1612</post_id>
		<post_date><![CDATA[2016-05-16 00:05:25]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 22:05:25]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[itrace-un-framework-para-soportar-el-analisis-de-informacion-de-trazabilidad-en-proyectos-de-desarrollo-software-dirigidos-por-modelos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="analisis-de-informacion-de-trazabilidad"><![CDATA[Análisis de Información de Trazabilidad]]></category>
		<category domain="post_tag" nicename="analisis-orientado-a-datos"><![CDATA[Análisis Orientado a Datos]]></category>
		<category domain="post_tag" nicename="analisis-orientado-a-modelos"><![CDATA[Análisis Orientado a Modelos]]></category>
		<category domain="post_tag" nicename="desarrollo-software-dirigido-por-modelos"><![CDATA[Desarrollo Software Dirigido por Modelos]]></category>
		<category domain="post_tag" nicename="modelos-de-traza"><![CDATA[Modelos de Traza]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1613]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/058]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El papel clave de los modelos en cualquier proceso de Desarrollo de Software Dirigido por Modelos (DSDM) proporciona un nuevo escenario para manejar la trazabilidad. Hasta ahora, existen una serie de propuestas dedicadas al almacenamiento, visualización, generación semi-automática y gestión de operaciones CRUD con enlaces de traza. No obstante, existe una falta de propuestas que se centren en el análisis de la información proporcionada por tales trazas. Además, las propuestas que llevan a cabo algún tipo de análisis de la información de trazabilidad no tienen en cuenta que esta información es consumida por diferentes tipos de actores, cada uno con sus propias necesidades. Para abordar estas cuestiones en este trabajo se introduce iTrace, un framework para la gestión y el análisis de la información de trazabilidad en proyectos de DSDM. Nuestra propuesta busca mejorar el uso que se hace de la información de trazabilidad disponible en proyectos de DSDM mediante dos tipos diferentes de análisis: análisis orientado a modelos, para modeladores, desarrolladores y el resto de perfiles operativos y análisis orientado a datos, para jefes de proyecto, analistas de negocio y usuarios finales en general.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Desarrollo Software Dirigido por Modelos, Análisis de Información de Trazabilidad, Análisis Orientado a Modelos, Análisis Orientado a Datos, Modelos de Traza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Iván Santiago]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Departamento de Lenguajes y Sistemas Informáticos II, Universidad Rey Juan Carlos, Avda. Tulipán S/N, 28933, Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ivan.santiago@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan M. Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Departamento de Lenguajes y Sistemas Informáticos II, Universidad Rey Juan Carlos, Avda. Tulipán S/N, 28933, Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Valeria de Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Departamento de Lenguajes y Sistemas Informáticos II, Universidad Rey Juan Carlos, Avda. Tulipán S/N, 28933, Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[valeria.decastro@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Departamento de Lenguajes y Sistemas Informáticos II, Universidad Rey Juan Carlos, Avda. Tulipán S/N, 28933, Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Diseño de Niveles y uso de Motores en el Desarrollo de Videojuegos dirigido por Modelos</title>
		<link>https://biblioteca.sistedes.es/articulo/diseno-de-niveles-y-uso-de-motores-en-el-desarrollo-de-videojuegos-dirigido-por-modelos/</link>
		<pubDate>Sun, 15 May 2016 22:07:31 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1615</guid>
		<description></description>
		<content><![CDATA[La propuesta del desarrollo de juegos dirigidos por modelos (MDGD) ofrece un multi-modelo para la especificación de videojuegos dividido en varias vistas: jugabilidad, interfaz gráfica y control entre otras. Este concepto de modelado conceptual permite a los diseñadores de juegos especificar juegos a un gran nivel de abstracción independientemente de la plataforma utilizada mediante la aplicación de MDD. En este trabajo se presenta una nueva vista añadida al modelado del gameplay de los videojuegos que permite el diseño de niveles. Ya que es común en el desarrollo de juegos el utilizar motores `estándares' en su construcción, se muestra cómo es posible integrar un motor de tiles 2D en el proceso de desarrollo definiendo un meta-modelo específico de la plataforma (PSM) genérico que permite definir la estructura y el comportamiento del sistema haciendo uso del motor sin entrar en los detalles técnicos de implementación.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1615</post_id>
		<post_date><![CDATA[2016-05-16 00:07:31]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 22:07:31]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[diseno-de-niveles-y-uso-de-motores-en-el-desarrollo-de-videojuegos-dirigido-por-modelos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="desarrollo-de-software-dirigido-por-modelos"><![CDATA[Desarrollo de Software Dirigido por Modelos]]></category>
		<category domain="post_tag" nicename="diseno-de-juegos"><![CDATA[diseño de juegos]]></category>
		<category domain="post_tag" nicename="diseno-de-niveles"><![CDATA[diseño de niveles]]></category>
		<category domain="post_tag" nicename="especificacion-gameplay"><![CDATA[especificación gameplay]]></category>
		<category domain="post_tag" nicename="mda"><![CDATA[MDA]]></category>
		<category domain="post_tag" nicename="mdd"><![CDATA[MDD]]></category>
		<category domain="post_tag" nicename="motor-de-videojuegos-2d"><![CDATA[motor de videojuegos 2D]]></category>
		<category domain="post_tag" nicename="pim"><![CDATA[PIM]]></category>
		<category domain="post_tag" nicename="psm"><![CDATA[PSM]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1616]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/059]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La propuesta del desarrollo de juegos dirigidos por modelos (MDGD) ofrece un multi-modelo para la especificación de videojuegos dividido en varias vistas: jugabilidad, interfaz gráfica y control entre otras. Este concepto de modelado conceptual permite a los diseñadores de juegos especificar juegos a un gran nivel de abstracción independientemente de la plataforma utilizada mediante la aplicación de MDD. En este trabajo se presenta una nueva vista añadida al modelado del gameplay de los videojuegos que permite el diseño de niveles. Ya que es común en el desarrollo de juegos el utilizar motores `estándares' en su construcción, se muestra cómo es posible integrar un motor de tiles 2D en el proceso de desarrollo definiendo un meta-modelo específico de la plataforma (PSM) genérico que permite definir la estructura y el comportamiento del sistema haciendo uso del motor sin entrar en los detalles técnicos de implementación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[desarrollo de software dirigido por modelos, MDA , diseño de niveles, PIM,PSM, motor de videojuegos 2D, MDD, especificación gameplay, diseño de juegos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Víctor M. Bolinches]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Ingeniería del Software y Sistemas de Información, Departamento de Sistema Informáticos y de Computación, Universitat Politècnica de València. Camí de Vera s/n 46022 Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[vicboma@ei.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José A. Carsí]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Ingeniería del Software y Sistemas de Información, Departamento de Sistema Informáticos y de Computación, Universitat Politècnica de València. Camí de Vera s/n 46022 Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pcarsi@dsic.upv.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Introducing Safety Requirements Traceability Support in Model-Driven Development of Robotic Applications</title>
		<link>https://biblioteca.sistedes.es/articulo/introducing-safety-requirements-traceability-support-in-model-driven-development-of-robotic-applications/</link>
		<pubDate>Sun, 15 May 2016 22:09:44 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1618</guid>
		<description></description>
		<content><![CDATA[Teleoperated service robots are used to perform hazardous operations in hostile environments such as nuclear reactors, space missions, warehouses, etc. Since they have to interact with both the environment and human operators, it is essential that they be so designed as to involve no risk to the operators, the environment, or the robot itself. Where it is impossible to eliminate the risk, this at least must be limited.
The work described in this article was developed in the context of the European Union V Framework Programme EFTCoR project (Environmental Friendly and CostEffective Technology for Coating Removal), which addressed the development of a solution to the problem of retrieval and confinement of sub-products from ship maintenance operations. Given the experience of the DSIE research group in both the design of component-based software applications for tele-operated service robots [1], and the combined use of safety standards (like ANSI/RIA 15.06-1999 and European Standard EN 61508:2001) with specific methodologies for safety systems development (like Rapid Object-Oriented Process for Embedded Systems, ROPES) [2], we decided to develop an integrated development framework.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1618</post_id>
		<post_date><![CDATA[2016-05-16 00:09:44]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 22:09:44]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[introducing-safety-requirements-traceability-support-in-model-driven-development-of-robotic-applications]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1619]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/060]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Teleoperated service robots are used to perform hazardous operations in hostile environments such as nuclear reactors, space missions, warehouses, etc. Since they have to interact with both the environment and human operators, it is essential that they be so designed as to involve no risk to the operators, the environment, or the robot itself. Where it is impossible to eliminate the risk, this at least must be limited.
The work described in this article was developed in the context of the European Union V Framework Programme EFTCoR project (Environmental Friendly and CostEffective Technology for Coating Removal), which addressed the development of a solution to the problem of retrieval and confinement of sub-products from ship maintenance operations. Given the experience of the DSIE research group in both the design of component-based software applications for tele-operated service robots [1], and the combined use of safety standards (like ANSI/RIA 15.06-1999 and European Standard EN 61508:2001) with specific methodologies for safety systems development (like Rapid Object-Oriented Process for Embedded Systems, ROPES) [2], we decided to develop an integrated development framework.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[División de Sistemas e Ingeniería Electrónica (DSIE) Universidad Politécnica de Cartagena, 30.202, Cartagena, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pedro.sanchez@upct.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Diego Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[División de Sistemas e Ingeniería Electrónica (DSIE) Universidad Politécnica de Cartagena, 30.202, Cartagena, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[diego.alonso@upct.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisca Rosique]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[División de Sistemas e Ingeniería Electrónica (DSIE) Universidad Politécnica de Cartagena, 30.202, Cartagena, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Bárbara Álvarez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[División de Sistemas e Ingeniería Electrónica (DSIE) Universidad Politécnica de Cartagena, 30.202, Cartagena, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Juan A. Pastor]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[División de Sistemas e Ingeniería Electrónica (DSIE) Universidad Politécnica de Cartagena, 30.202, Cartagena, España]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un repositorio NoSQL para acceso escalable a modelos</title>
		<link>https://biblioteca.sistedes.es/articulo/un-repositorio-nosql-para-acceso-escalable-a-modelos/</link>
		<pubDate>Sun, 15 May 2016 22:14:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1621</guid>
		<description></description>
		<content><![CDATA[La creciente madurez de la Ingeniería Dirigida por Modelos (MDE) está promoviendo su adopcíon por grandes compañías [1][2] que se benefician en términos de productividad, calidad y reuso. Sin embargo, la aplicacíon de MDE en este contexto requiere de herramientas de escala industrial que puedan operar con modelos muy grandes y complejos. Una operacíon básica de dichas herramientas es la persistencia de modelos y su acceso, debiendo satisfacer dos requisitos esenciales: escalabilidad e integracíon.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1621</post_id>
		<post_date><![CDATA[2016-05-16 00:14:05]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 22:14:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-repositorio-nosql-para-acceso-escalable-a-modelos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1622]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/061]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La creciente madurez de la Ingeniería Dirigida por Modelos (MDE) está promoviendo su adopcíon por grandes compañías [1][2] que se benefician en términos de productividad, calidad y reuso. Sin embargo, la aplicacíon de MDE en este contexto requiere de herramientas de escala industrial que puedan operar con modelos muy grandes y complejos. Una operacíon básica de dichas herramientas es la persistencia de modelos y su acceso, debiendo satisfacer dos requisitos esenciales: escalabilidad e integracíon.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Espinazo Pagán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jespinazo@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jesús Sánchez Cuadrado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Autónoma de Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jesus.sanchez.cuadrado@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesús García Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jmolina@um.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Family of Case Studies on Business Process Mining</title>
		<link>https://biblioteca.sistedes.es/articulo/a-family-of-case-studies-on-business-process-mining/</link>
		<pubDate>Sun, 15 May 2016 22:17:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1624</guid>
		<description></description>
		<content><![CDATA[Business processes, most of which are automated by information systems, have become a key asset in organizations. Unfortunately, uncontrolled maintenance implies that information systems age over time until they need to be modernized. During software modernization, ageing systems cannot be entirely discarded because they gradually embed meaningful business knowledge, which is not present in any other artifact. This paper presents a technique for recovering business processes from legacy systems in order to preserve that knowledge. The technique statically analyzes source code and generates a code model, which is later transformed by pattern matching into a business process model. This technique has been validated over a two year period in several industrial modernization projects. This paper reports the results of a family of case studies that were performed to empirically validate the technique using analysis and meta-analysis techniques. The study demonstrates the effectiveness and efficiency of the technique.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1624</post_id>
		<post_date><![CDATA[2016-05-16 00:17:09]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 22:17:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-family-of-case-studies-on-business-process-mining]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="business-process"><![CDATA[Business process]]></category>
		<category domain="post_tag" nicename="case-study"><![CDATA[Case Study]]></category>
		<category domain="post_tag" nicename="meta-analysis"><![CDATA[Meta-analysis]]></category>
		<category domain="post_tag" nicename="static-analysis"><![CDATA[Static Analysis]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1625]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/062]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Business processes, most of which are automated by information systems, have become a key asset in organizations. Unfortunately, uncontrolled maintenance implies that information systems age over time until they need to be modernized. During software modernization, ageing systems cannot be entirely discarded because they gradually embed meaningful business knowledge, which is not present in any other artifact. This paper presents a technique for recovering business processes from legacy systems in order to preserve that knowledge. The technique statically analyzes source code and generates a code model, which is later transformed by pattern matching into a business process model. This technique has been validated over a two year period in several industrial modernization projects. This paper reports the results of a family of case studies that were performed to empirically validate the technique using analysis and meta-analysis techniques. The study demonstrates the effectiveness and efficiency of the technique.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Business Process, Static Analysis, Case Study, Meta-Analysis]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ricardo Pérez-Castillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Alarcos Research Group, University of Castilla-La Mancha Paseo de la Universidad, nº4 13071 ­ Ciudad Real (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ricardo.pdelcastillo@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José A. Cruz-Lemus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Alarcos Research Group, University of Castilla-La Mancha Paseo de la Universidad, nº4 13071 ­ Ciudad Real (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[joseantonio.cruz@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ignacio García-Rodríguez de Guzmán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Alarcos Research Group, University of Castilla-La Mancha Paseo de la Universidad, nº4 13071 ­ Ciudad Real (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ignacio.grodriguez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Alarcos Research Group, University of Castilla-La Mancha Paseo de la Universidad, nº4 13071 ­ Ciudad Real (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mario.piattini@uclm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evolución de Sistemas Auto-Adaptables mediante Modelos en Tiempo de Ejecución</title>
		<link>https://biblioteca.sistedes.es/articulo/evolucion-de-sistemas-auto-adaptables-mediante-modelos-en-tiempo-de-ejecucion/</link>
		<pubDate>Sun, 15 May 2016 22:19:42 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1627</guid>
		<description></description>
		<content><![CDATA[La auto-adaptación se está convirtiendo en un requisito indispensable en los sistemas software. Los sistemas auto-adaptables son capaces de adaptar dinámicamente su comportamiento y estructura en ejecución en respuesta a variaciones en el sistema y el entorno. Los enfoques actuales de auto-adaptación tienden a asumir un mundo cerrado, en el que todos los fenómenos de interés son previstos en tiempo de diseño. Sin embargo, algunos comportamientos adaptativos no se pueden prever a priori. En este ámbito, se requieren técnicas que den soporte a la evolución en tiempo de ejecución de sistemas auto-adaptables. Este artículo propone una aproximación dirigida por modelos para desarrollar y evolucionar de forma sistemática sistemas auto-adaptables mientras están en ejecución. Específicamente, la aproximación utiliza Modelos en Tiempo de Ejecución para incorporar nuevas capacidades que no fueron previstas en el diseño inicial del sistema.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1627</post_id>
		<post_date><![CDATA[2016-05-16 00:19:42]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 22:19:42]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evolucion-de-sistemas-auto-adaptables-mediante-modelos-en-tiempo-de-ejecucion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="adaptacion-dinamica"><![CDATA[Adaptación Dinámica]]></category>
		<category domain="post_tag" nicename="evolucion"><![CDATA[evolución]]></category>
		<category domain="post_tag" nicename="modelos-en-tiempo-de-ejecucion"><![CDATA[Modelos en Tiempo de Ejecución]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1628]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/063]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La auto-adaptación se está convirtiendo en un requisito indispensable en los sistemas software. Los sistemas auto-adaptables son capaces de adaptar dinámicamente su comportamiento y estructura en ejecución en respuesta a variaciones en el sistema y el entorno. Los enfoques actuales de auto-adaptación tienden a asumir un mundo cerrado, en el que todos los fenómenos de interés son previstos en tiempo de diseño. Sin embargo, algunos comportamientos adaptativos no se pueden prever a priori. En este ámbito, se requieren técnicas que den soporte a la evolución en tiempo de ejecución de sistemas auto-adaptables. Este artículo propone una aproximación dirigida por modelos para desarrollar y evolucionar de forma sistemática sistemas auto-adaptables mientras están en ejecución. Específicamente, la aproximación utiliza Modelos en Tiempo de Ejecución para incorporar nuevas capacidades que no fueron previstas en el diseño inicial del sistema.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Modelos en Tiempo de Ejecución, Evolución, Adaptación Dinámica]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Gómez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Métodos de Producción de Software Universitat Politècnica de València Camino de Vera s/n, E-46022, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[magomez@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Joan Fons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Métodos de Producción de Software Universitat Politècnica de València Camino de Vera s/n, E-46022, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jjfons@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Métodos de Producción de Software Universitat Politècnica de València Camino de Vera s/n, E-46022, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pele@dsic.upv.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Parametrización de las transformaciones horizontales en el modelo de herradura</title>
		<link>https://biblioteca.sistedes.es/articulo/parametrizacion-de-las-transformaciones-horizontales-en-el-modelo-de-herradura/</link>
		<pubDate>Sun, 15 May 2016 22:22:38 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1630</guid>
		<description></description>
		<content><![CDATA[En los procesos de modernizacíon o reingeniería de software se aplica generalmente el denominado modelo de herradura. En este modelo hay transformaciones verticales entre artefactos software de diferente nivel de abstracción y transformaciones horizontales en el mismo nivel de abstracción. A pesar de ser un modelo conocido y usado en numerosos trabajos todavía no se ha explorado completamente cómo automatizarlo. En este artículo se discuten los problemas existentes para su automatización, y se motiva la problemática con un caso real de modernizacíon. Se describe una aproximacíon basada en la parametrizacíon de transformaciones horizontales con informacíon descubierta en las transformaciones verticales y los cambios realizados en los modelos de niveles superiores.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1630</post_id>
		<post_date><![CDATA[2016-05-16 00:22:38]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 22:22:38]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[parametrizacion-de-las-transformaciones-horizontales-en-el-modelo-de-herradura]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1631]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/064]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los procesos de modernizacíon o reingeniería de software se aplica generalmente el denominado modelo de herradura. En este modelo hay transformaciones verticales entre artefactos software de diferente nivel de abstracción y transformaciones horizontales en el mismo nivel de abstracción. A pesar de ser un modelo conocido y usado en numerosos trabajos todavía no se ha explorado completamente cómo automatizarlo. En este artículo se discuten los problemas existentes para su automatización, y se motiva la problemática con un caso real de modernizacíon. Se describe una aproximacíon basada en la parametrizacíon de transformaciones horizontales con informacíon descubierta en las transformaciones verticales y los cambios realizados en los modelos de niveles superiores.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús Sánchez Cuadrado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Autónoma de Madrid ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jesus.sanchez.cuadrado@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Orlando Avila García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Open Canarias, S.L.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[orlando@opencanarias.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Luis Cánovas Izquierdo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[AtlandMod, école des Mines de Nantes ­ INRIA ­ LINA, Francia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[javier.canovas@inria.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Adolfo Sánchez-Barbudo Herrera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Open Canarias, S.L. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[adolfosbh@opencanarias.com]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Transformacíon de modelos con Eclectic</title>
		<link>https://biblioteca.sistedes.es/articulo/transformacion-de-modelos-con-eclectic/</link>
		<pubDate>Sun, 15 May 2016 22:24:26 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1633</guid>
		<description></description>
		<content><![CDATA[Las transformaciones de modelos son un elemento clave del Desarrollo de Software Dirigido por Modelos. En los últimos años se han propuesto varios lenguajes de transformación de diferente naturaleza, siendo cada uno de ellos adecuado para un determinado tipo de tarea de transformación. Sin embargo, una transformacíon compleja normalmente implica abordar una serie de sub-problemas que corresponden a diferentes estilos de transformacíon, y por tanto no toda la transformacíon puede desarrollarse de forma natural en el lenguaje elegido. En esta demostracíon se presentará el entorno de transformación de modelos Eclectic, que trata de abordar el desarrollo de transformaciones de modelos ofreciendo una familia de lenguajes de transformación. Cada lenguaje tiene como objetivo abordar un determinado tipo de transformaciones, y está específicamente diseñado para ello. La demostracíon se ilustrará con un ejemplo de aplicacíon que utiliza diferentes lenguajes, se mostrará el entorno de desarrollo y se comentarán características de la aproximación tales como interoperabilidad entre lenguajes e integracíon con programas Java.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1633</post_id>
		<post_date><![CDATA[2016-05-16 00:24:26]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 22:24:26]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[transformacion-de-modelos-con-eclectic]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1634]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/065]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las transformaciones de modelos son un elemento clave del Desarrollo de Software Dirigido por Modelos. En los últimos años se han propuesto varios lenguajes de transformación de diferente naturaleza, siendo cada uno de ellos adecuado para un determinado tipo de tarea de transformación. Sin embargo, una transformacíon compleja normalmente implica abordar una serie de sub-problemas que corresponden a diferentes estilos de transformacíon, y por tanto no toda la transformacíon puede desarrollarse de forma natural en el lenguaje elegido. En esta demostracíon se presentará el entorno de transformación de modelos Eclectic, que trata de abordar el desarrollo de transformaciones de modelos ofreciendo una familia de lenguajes de transformación. Cada lenguaje tiene como objetivo abordar un determinado tipo de transformaciones, y está específicamente diseñado para ello. La demostracíon se ilustrará con un ejemplo de aplicacíon que utiliza diferentes lenguajes, se mostrará el entorno de desarrollo y se comentarán características de la aproximación tales como interoperabilidad entre lenguajes e integracíon con programas Java.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús Sánchez Cuadrado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Autónoma de Madrid (Spain) ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jesus.sanchez.cuadrado@um.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Prueba de Transformaciones de Modelos con TractsTool</title>
		<link>https://biblioteca.sistedes.es/articulo/prueba-de-transformaciones-de-modelos-con-tractstool/</link>
		<pubDate>Sun, 15 May 2016 22:30:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1636</guid>
		<description></description>
		<content><![CDATA[Las tranformaciones de modelos son un elemento esencial en la Ingeniería Dirigida por Modelos (Model-driven Engineering, MDE) y por ello una tarea que está cobrando relevancia es probar su corrección. Los Tracts ofrecen un enfoque modular y extensible para la especificación y verificación de transformaciones de modelos. Este trabajo presenta TractsTool, una herramienta desarrollada en Eclipse que implementa los mecanismos que proporcionan los Tracts.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1636</post_id>
		<post_date><![CDATA[2016-05-16 00:30:53]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 22:30:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[prueba-de-transformaciones-de-modelos-con-tractstool]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="tracts"><![CDATA[Tracts]]></category>
		<category domain="post_tag" nicename="transformaciones-de-modelos"><![CDATA[Transformaciones de Modelos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1637]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/066]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las tranformaciones de modelos son un elemento esencial en la Ingeniería Dirigida por Modelos (Model-driven Engineering, MDE) y por ello una tarea que está cobrando relevancia es probar su corrección. Los Tracts ofrecen un enfoque modular y extensible para la especificación y verificación de transformaciones de modelos. Este trabajo presenta TractsTool, una herramienta desarrollada en Eclipse que implementa los mecanismos que proporcionan los Tracts.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[MDE, Transformaciones de Modelos, Tracts]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel Wimmer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[GISUM/Grupo de investigación Atenea. Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mw@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Loli Burgueño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[GISUM/Grupo de investigación Atenea. Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[av@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Vallecillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[GISUM/Grupo de investigación Atenea. Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[av@lcc.uma.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Desarrollo dirigido por modelos de visualización de datos para la Web</title>
		<link>https://biblioteca.sistedes.es/articulo/desarrollo-dirigido-por-modelos-de-visualizacion-de-datos-para-la-web/</link>
		<pubDate>Sun, 15 May 2016 22:52:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1639</guid>
		<description></description>
		<content><![CDATA[La visualización de datos juega un papel clave al presentar informes empresariales. Una adecuada visualización sirve de soporte para fundamentar mejor la toma de decisiones. Sin embargo, una visualización desacertada puede inducir a tomar una decisión incorrecta. Habitualmente, la elección de diferentes representaciones visuales para un mismo conjunto de datos se prefija por los desarrolladores de la misma. En este contexto, el usuario final no tiene ocasión de ajustar o cambiar las visualizaciones en tiempo de ejecución y no todos los usuarios tienen por qué tener los mismos intereses cuando visualizan los mismos datos. En este trabajo presentamos un lenguaje específico de dominio que permite definir semiautomáticamente patrones de visualización reutilizables de manera que el usuario final pueda elegir el que más se adapte a sus intereses.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1639</post_id>
		<post_date><![CDATA[2016-05-16 00:52:50]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 22:52:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[desarrollo-dirigido-por-modelos-de-visualizacion-de-datos-para-la-web]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="desarrollo-de-software-dirigido-por-modelos"><![CDATA[Desarrollo de Software Dirigido por Modelos]]></category>
		<category domain="post_tag" nicename="ingenieria-web"><![CDATA[Ingeniería Web]]></category>
		<category domain="post_tag" nicename="lenguajes-especificos-del-dominio"><![CDATA[Lenguajes específicos del dominio]]></category>
		<category domain="post_tag" nicename="visualizacion-de-datos"><![CDATA[Visualización de Datos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1640]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/067]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La visualización de datos juega un papel clave al presentar informes empresariales. Una adecuada visualización sirve de soporte para fundamentar mejor la toma de decisiones. Sin embargo, una visualización desacertada puede inducir a tomar una decisión incorrecta. Habitualmente, la elección de diferentes representaciones visuales para un mismo conjunto de datos se prefija por los desarrolladores de la misma. En este contexto, el usuario final no tiene ocasión de ajustar o cambiar las visualizaciones en tiempo de ejecución y no todos los usuarios tienen por qué tener los mismos intereses cuando visualizan los mismos datos. En este trabajo presentamos un lenguaje específico de dominio que permite definir semiautomáticamente patrones de visualización reutilizables de manera que el usuario final pueda elegir el que más se adapte a sus intereses.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Visualización de datos, Desarrollo de software dirigido por modelos, Lenguajes específicos del dominio, Ingeniería Web]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rober Morales-Chaparro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[robermorales@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Carlos Preciado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jcpreciado@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Fernando Sánchez-Figueroa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fernando@unex.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Managing crosscutting concerns in component based systems using a model driven development approach</title>
		<link>https://biblioteca.sistedes.es/articulo/managing-crosscutting-concerns-in-component-based-systems-using-a-model-driven-development-approach/</link>
		<pubDate>Sun, 15 May 2016 22:59:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1642</guid>
		<description></description>
		<content><![CDATA[In general, one may consider that the ultimate goal of these proposals is to be able to reduce development costs and eort, while improving the modularity, exibility, adaptability, and reliability of software systems. An analysis of each of these technologies shows them all to include the principle of the separation of concerns and their further integration as key factors to obtaining high-quality and evolvable large software systems. Each identies dierent concerns and deals with them separately in order to specify, design, and build applications, and at the same time provides mechanisms for the correct and appropriate integration of these concerns in the nal application.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1642</post_id>
		<post_date><![CDATA[2016-05-16 00:59:49]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 22:59:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[managing-crosscutting-concerns-in-component-based-systems-using-a-model-driven-development-approach]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1643]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/068]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In general, one may consider that the ultimate goal of these proposals is to be able to reduce development costs and eort, while improving the modularity, exibility, adaptability, and reliability of software systems. An analysis of each of these technologies shows them all to include the principle of the separation of concerns and their further integration as key factors to obtaining high-quality and evolvable large software systems. Each identies dierent concerns and deals with them separately in order to specify, design, and build applications, and at the same time provides mechanisms for the correct and appropriate integration of these concerns in the nal application.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro J. Clemente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group. University of Extremadura (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pjclemente@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group. University of Extremadura (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanher@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José M. Conejero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group. University of Extremadura (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[chemacm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group. University of Extremadura (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[gobellot@unex.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Diseño de Servidores de Adquisicíon y Publicacíon de Datos de Sensores</title>
		<link>https://biblioteca.sistedes.es/articulo/diseno-de-servidores-de-adquisicion-y-publicacion-de-datos-de-sensores/</link>
		<pubDate>Sun, 15 May 2016 23:11:43 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1647</guid>
		<description></description>
		<content><![CDATA[ En este artículo proponemos el diseño e implementación de un framework para el desarrollo de servidores de adquisición y publicacíon de datos llamado DADIS. La estructura de DADIS está dividida en tres capas: i) una capa inferior de adquisicíon de datos que se encarga de la comunicacíon con los diferentes sensores, ii) una capa intermedia que constituye el núcleo del sistema y se encarga de proporcionar funcionalidad de propósito general, y iii) una capa superior de comunicacíon con aplicaciones de usuario. El uso extensivo del patrón de diseño Adapter (Wrapper) convierte a DADIS en una herramienta de propósito general extremadamente flexible en la incorporación tanto de nuevos canales síncronos y asíncronos de adquisicíon de datos como de nuevos servicios de publicacíon. Además, el uso del patrón Observer en la capa de comunicacíon con las aplicaciones de usuario permite que los servicios de publicacíon que se quieran incorporar puedan implementar tanto el modelo cliente/servidor como el modelo publicador/suscriptor.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1647</post_id>
		<post_date><![CDATA[2016-05-16 01:11:43]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 23:11:43]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[diseno-de-servidores-de-adquisicion-y-publicacion-de-datos-de-sensores]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="adquisicion-de-datos"><![CDATA[Adquisicíon de Datos]]></category>
		<category domain="post_tag" nicename="almacenamiento-de-datos"><![CDATA[Almacenamiento de Datos]]></category>
		<category domain="post_tag" nicename="arquitectura-de-sistemas"><![CDATA[Arquitectura de Sistemas]]></category>
		<category domain="post_tag" nicename="control-distribuido"><![CDATA[Control Distribuido]]></category>
		<category domain="post_tag" nicename="monitorizacion"><![CDATA[Monitorización]]></category>
		<category domain="post_tag" nicename="scada"><![CDATA[SCADA]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1648]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/069]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[ En este artículo proponemos el diseño e implementación de un framework para el desarrollo de servidores de adquisición y publicacíon de datos llamado DADIS. La estructura de DADIS está dividida en tres capas: i) una capa inferior de adquisicíon de datos que se encarga de la comunicacíon con los diferentes sensores, ii) una capa intermedia que constituye el núcleo del sistema y se encarga de proporcionar funcionalidad de propósito general, y iii) una capa superior de comunicacíon con aplicaciones de usuario. El uso extensivo del patrón de diseño Adapter (Wrapper) convierte a DADIS en una herramienta de propósito general extremadamente flexible en la incorporación tanto de nuevos canales síncronos y asíncronos de adquisicíon de datos como de nuevos servicios de publicacíon. Además, el uso del patrón Observer en la capa de comunicacíon con las aplicaciones de usuario permite que los servicios de publicacíon que se quieran incorporar puedan implementar tanto el modelo cliente/servidor como el modelo publicador/suscriptor.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Adquisicíon de Datos, Almacenamiento de Datos, Monitorización, SCADA, Control Distribuido, Arquitectura de Sistemas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Sebastían Villarroya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Gráficos por Ordenador e Ingeniería de Datos (COGRADE), Departamento de Electrónica y Computacíon, Universidad de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[sebastian.villarroya@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David Mera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Gráficos por Ordenador e Ingeniería de Datos (COGRADE), Departamento de Electrónica y Computacíon, Universidad de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[david.mera@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel A. Regueiro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Gráficos por Ordenador e Ingeniería de Datos (COGRADE), Departamento de Electrónica y Computacíon, Universidad de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuelantonio.regueiro@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José M. Cotos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Gráficos por Ordenador e Ingeniería de Datos (COGRADE), Departamento de Electrónica y Computacíon, Universidad de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manel.cotos@usc.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automating the deployment of componentized systems</title>
		<link>https://biblioteca.sistedes.es/articulo/automating-the-deployment-of-componentized-systems/</link>
		<pubDate>Sun, 15 May 2016 23:13:30 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1650</guid>
		<description></description>
		<content><![CDATA[Embedded and self-adaptive systems demand continuous adaptation and reconfiguration activities based on changing quality conditions and context information. As a consequence, systems have to be (re)deployed several times and software components need to be mapped onto new or existing hardware pieces. Today, the way to determine an optimal deployment in complex systems, often performed at runtime, constitutes a well-known challenge. In this paper we highlight the major problems of automatic deployment and present a research plan to reach for an UML-based solution for the deployment of componentized systems. As a first step towards a solution, we use the UML superstructure to suggest a way to redeploy UML component diagrams based on the inputs and outputs required to enact an automatic deployment process.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1650</post_id>
		<post_date><![CDATA[2016-05-16 01:13:30]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 23:13:30]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automating-the-deployment-of-componentized-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1651]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/070]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Embedded and self-adaptive systems demand continuous adaptation and reconfiguration activities based on changing quality conditions and context information. As a consequence, systems have to be (re)deployed several times and software components need to be mapped onto new or existing hardware pieces. Today, the way to determine an optimal deployment in complex systems, often performed at runtime, constitutes a well-known challenge. In this paper we highlight the major problems of automatic deployment and present a research plan to reach for an UML-based solution for the deployment of componentized systems. As a first step towards a solution, we use the UML superstructure to suggest a way to redeploy UML component diagrams based on the inputs and outputs required to enact an automatic deployment process.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús García-Galán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Trinidad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Rafael Capilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards Run-time Resilience Evaluation in Self-Adaptive Systems</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-run-time-resilience-evaluation-in-self-adaptive-systems/</link>
		<pubDate>Sun, 15 May 2016 23:15:58 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1653</guid>
		<description></description>
		<content><![CDATA[The provision of assurances for self-adaptive systems presents its challenges, since uncertainties associated with their operating environments often hamper the provision of absolute guarantees that system properties can be satisfied. In previous work, we defined a development-time approach for the evaluation of self-adaptive systems that relies on stimulation and probabilistic modelchecking to provide levels of confidence regarding service delivery. However, development-time evaluation has limitations due to the dynamic nature of selfadaptive systems, whose behavior depends on run-time conditions that continuously change. In this paper, we discuss the challenges and issues posed by the shift of resilience evaluation from development-time to run-time.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1653</post_id>
		<post_date><![CDATA[2016-05-16 01:15:58]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 23:15:58]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-run-time-resilience-evaluation-in-self-adaptive-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="resilience-evaluation"><![CDATA[resilience evaluation]]></category>
		<category domain="post_tag" nicename="self-adaptation-assurances-architecture-model"><![CDATA[self-adaptation; assurances; architecture model]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1654]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/071]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The provision of assurances for self-adaptive systems presents its challenges, since uncertainties associated with their operating environments often hamper the provision of absolute guarantees that system properties can be satisfied. In previous work, we defined a development-time approach for the evaluation of self-adaptive systems that relies on stimulation and probabilistic modelchecking to provide levels of confidence regarding service delivery. However, development-time evaluation has limitations due to the dynamic nature of selfadaptive systems, whose behavior depends on run-time conditions that continuously change. In this paper, we discuss the challenges and issues posed by the shift of resilience evaluation from development-time to run-time.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[resilience evaluation, self-adaptation; assurances; architecture model]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Cámara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Coimbra, Portugal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jcmoreno@dei.uc.pt]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Rogério de Lemos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Kent, UK]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[r.delemos@kent.ac.uk]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Prototyping Component-Based Self-Adaptive Systems with Maude</title>
		<link>https://biblioteca.sistedes.es/articulo/prototyping-component-based-self-adaptive-systems-with-maude/</link>
		<pubDate>Sun, 15 May 2016 23:18:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1656</guid>
		<description></description>
		<content><![CDATA[Software adaptation is becoming increasingly important as more and more applications need to dynamically adapt their structure and behavior to cope with changing contexts, available resources and user requirements. Maude is a high-performance reflective language and system, supporting both equational and rewriting logic specification and programming for a wide range of applications. In this paper we describe our experience in using Maude for prototyping component-based self-adaptive systems so that they can be formally simulated and analyzed. In order to illustrate the benefits of using Maude in this context, a case study in the robotics domain is presented.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1656</post_id>
		<post_date><![CDATA[2016-05-16 01:18:50]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 23:18:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[prototyping-component-based-self-adaptive-systems-with-maude]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="component-based-architecture"><![CDATA[component-based architecture]]></category>
		<category domain="post_tag" nicename="maude"><![CDATA[Maude]]></category>
		<category domain="post_tag" nicename="prototyping"><![CDATA[prototyping]]></category>
		<category domain="post_tag" nicename="self-adaptation"><![CDATA[Self-Adaptation]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1657]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/072]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Software adaptation is becoming increasingly important as more and more applications need to dynamically adapt their structure and behavior to cope with changing contexts, available resources and user requirements. Maude is a high-performance reflective language and system, supporting both equational and rewriting logic specification and programming for a wide range of applications. In this paper we describe our experience in using Maude for prototyping component-based self-adaptive systems so that they can be formally simulated and analyzed. In order to illustrate the benefits of using Maude in this context, a case study in the robotics domain is presented.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Self-adaptation, component-based architecture, prototyping, Maude]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan F. Inglés-Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Tecnologías de la Información y Comunicaciones, E.T.S.I. de Telecomunicación, Universidad Politécnica de Cartagena, Edificio Antigones, 30202 Cartagena, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[juanfran.ingles@upct.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Cristina Vicente-Chicote]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Tecnologías de la Información y Comunicaciones, E.T.S.I. de Telecomunicación, Universidad Politécnica de Cartagena, Edificio Antigones, 30202 Cartagena, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cristina.vicente@upct.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Troya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[GISUM/Atenea Research Group. Universidad de Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[javiertc@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Vallecillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[GISUM/Atenea Research Group. Universidad de Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[av@lcc.uma.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>MinFrEditor: Entorno de desarrollo de aplicaciones para un framework de componentes</title>
		<link>https://biblioteca.sistedes.es/articulo/minfreditor-entorno-de-desarrollo-de-aplicaciones-para-un-framework-de-componentes/</link>
		<pubDate>Sun, 15 May 2016 23:20:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1659</guid>
		<description></description>
		<content><![CDATA[El entorno de modelado MinFrEditor integra un conjunto de herramientas diseadas para facilitar el desarrollo de aplicaciones basadas en componentes utilizando el framework MinFr. Este entorno de desarrollo permite a los usuarios de MinFr: (1) Modelar aplicaciones basadas en componentes utilizando un leguaje textual, (2) hacer el despliegue de las aplicaciones y (3) generar modelos de entrada para herramientas de análisis de tiempo real.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1659</post_id>
		<post_date><![CDATA[2016-05-16 01:20:51]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 23:20:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[minfreditor-entorno-de-desarrollo-de-aplicaciones-para-un-framework-de-componentes]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="desarrollo-de-software-basado-en-componentes"><![CDATA[desarrollo de software basado en componentes]]></category>
		<category domain="post_tag" nicename="desarrollo-de-software-dirigido-por-modelos"><![CDATA[Desarrollo de Software Dirigido por Modelos]]></category>
		<category domain="post_tag" nicename="editor"><![CDATA[Editor]]></category>
		<category domain="post_tag" nicename="framework"><![CDATA[framework]]></category>
		<category domain="post_tag" nicename="herramienta-de-desarrollo"><![CDATA[herramienta de desarrollo]]></category>
		<category domain="post_tag" nicename="ingenieria-de-software"><![CDATA[ingeniería de software]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1660]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/073]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El entorno de modelado MinFrEditor integra un conjunto de herramientas diseadas para facilitar el desarrollo de aplicaciones basadas en componentes utilizando el framework MinFr. Este entorno de desarrollo permite a los usuarios de MinFr: (1) Modelar aplicaciones basadas en componentes utilizando un leguaje textual, (2) hacer el despliegue de las aplicaciones y (3) generar modelos de entrada para herramientas de análisis de tiempo real.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ingeniería de software, desarrollo de software basado en componentes, desarrollo de software dirigido por modelos, framework, editor, herramienta de desarrollo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Sánchez-Ledesma]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ivisíon de Sistemas e Ingeniería Electrónica (DSIE), Universidad Politécnica de Cartagena, Campus Muralla del Mar, E-30202, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[francisco.sanchez@upct.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Pastor]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ivisíon de Sistemas e Ingeniería Electrónica (DSIE), Universidad Politécnica de Cartagena, Campus Muralla del Mar, E-30202, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Diego Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ivisíon de Sistemas e Ingeniería Electrónica (DSIE), Universidad Politécnica de Cartagena, Campus Muralla del Mar, E-30202, Spain]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Agile Product Line Engineering--A Systematic Literature Review</title>
		<link>https://biblioteca.sistedes.es/articulo/agile-product-line-engineering-a-systematic-literature-review/</link>
		<pubDate>Sun, 15 May 2016 23:23:33 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1662</guid>
		<description></description>
		<content><![CDATA[Software Product Line Engineering (SPLE)[1] demands upfront long-term investment in (i) designing a common set of core-assets and (ii) managing variability across the products from the same family. When anticipated changes in these coreassets have been predicted with certain accuracy, SPLE has proved significant improvements. However, when large/complex product-line projects have to deal with changing market conditions, alternatives to supplement SPLE are required.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1662</post_id>
		<post_date><![CDATA[2016-05-16 01:23:33]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 23:23:33]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[agile-product-line-engineering-a-systematic-literature-review]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1663]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/074]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Software Product Line Engineering (SPLE)[1] demands upfront long-term investment in (i) designing a common set of core-assets and (ii) managing variability across the products from the same family. When anticipated changes in these coreassets have been predicted with certain accuracy, SPLE has proved significant improvements. However, when large/complex product-line projects have to deal with changing market conditions, alternatives to supplement SPLE are required.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jessica Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Technical University of Madrid (UPM) - Universidad Politécnica de Madrid E.U. Informática Ctra. Valencia Km. 7 E-28031 Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[yesica.diaz@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jennifer Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Technical University of Madrid (UPM) - Universidad Politécnica de Madrid E.U. Informática Ctra. Valencia Km. 7 E-28031 Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jenifer.perez@eui.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pedro P. Alarcón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Technical University of Madrid (UPM) - Universidad Politécnica de Madrid E.U. Informática Ctra. Valencia Km. 7 E-28031 Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pedrop.alarcon@eui.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Garbajosa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Technical University of Madrid (UPM) - Universidad Politécnica de Madrid E.U. Informática Ctra. Valencia Km. 7 E-28031 Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jgs@eui.upm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación de Documentos con Contenido Variable en DPLfw</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-de-documentos-con-contenido-variable-en-dplfw/</link>
		<pubDate>Sun, 15 May 2016 23:25:57 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1665</guid>
		<description></description>
		<content><![CDATA[Actualmente existen soluciones tecnológicas para la generación de documentos personalizados en cuanto a sus contenidos y apariencia. Sin embargo, todas ellas requieren de amplios conocimientos en lenguajes especializados (XML, XSLT o XPATH entre otros) y no contemplan tareas relacionadas específicamente con el dominio, como es la identificación de la variabilidad en el contenido de los documentos. En este trabajo presentamos DPLfw, un entorno de trabajo basado en modelos para la generación de documentos con contenido variable. DPLfw es una implementación de la propuesta de Líneas de Producto de Documentos, donde la variabilidad en el contenido se representa mediante características, y la generación de documentos se soporta sobre un proceso basado en Líneas de Productos. Este artículo describe la arquitectura de DPLfw, a la vez que muestra su uso en la generación de documentación de usuario.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1665</post_id>
		<post_date><![CDATA[2016-05-16 01:25:57]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 23:25:57]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-de-documentos-con-contenido-variable-en-dplfw]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="dita"><![CDATA[DITA]]></category>
		<category domain="post_tag" nicename="impresion-de-datos-variables"><![CDATA[Impresión de Datos Variables]]></category>
		<category domain="post_tag" nicename="ingenieria-dirigida-por-modelos"><![CDATA[Ingeniería Dirigida por Modelos]]></category>
		<category domain="post_tag" nicename="lineas-de-productos-de-documentos"><![CDATA[Líneas de Productos de Documentos]]></category>
		<category domain="post_tag" nicename="modelado-de-caracteristicas"><![CDATA[Modelado de Características]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1666]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/075]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Actualmente existen soluciones tecnológicas para la generación de documentos personalizados en cuanto a sus contenidos y apariencia. Sin embargo, todas ellas requieren de amplios conocimientos en lenguajes especializados (XML, XSLT o XPATH entre otros) y no contemplan tareas relacionadas específicamente con el dominio, como es la identificación de la variabilidad en el contenido de los documentos. En este trabajo presentamos DPLfw, un entorno de trabajo basado en modelos para la generación de documentos con contenido variable. DPLfw es una implementación de la propuesta de Líneas de Producto de Documentos, donde la variabilidad en el contenido se representa mediante características, y la generación de documentos se soporta sobre un proceso basado en Líneas de Productos. Este artículo describe la arquitectura de DPLfw, a la vez que muestra su uso en la generación de documentación de usuario.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Impresión de Datos Variables, Líneas de Productos de Documentos, Modelado de Características, Ingeniería Dirigida por Modelos, DITA]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Abel Gómez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ISSI ­ DSIC, Universitat Politècnica de València. Cno. de Vera, s/n. 46022 Valencia. Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[agomez@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ma Carmen Penadés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ISSI ­ DSIC, Universitat Politècnica de València. Cno. de Vera, s/n. 46022 Valencia. Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mpenades@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José H. Canós]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ISSI ­ DSIC, Universitat Politècnica de València. Cno. de Vera, s/n. 46022 Valencia. Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jhcanos@dsic.upv.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>BeTTy: Un Framework de Pruebas para el Análisis Automático de Modelos de Características</title>
		<link>https://biblioteca.sistedes.es/articulo/betty-un-framework-de-pruebas-para-el-analisis-automatico-de-modelos-de-caracteristicas/</link>
		<pubDate>Sun, 15 May 2016 23:29:16 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1668</guid>
		<description></description>
		<content><![CDATA[El análisis automático de modelos de características es un área de investigación activo que ha llamado la atencíon de numerosos investigadores durante las dos últimas décadas. Durante este tiempo, el número de herramientas y técnicas para el análisis de modelos de características se ha multiplicado y con ellas su complejidad. En este escenario, la falta de mecanismos específicos para validar y evaluar la funcionalidad y el rendimiento de las herramientas de análisis se ha convertido en un gran obstáculo dificultando el desarrollo de herramientas y afectando negativamente a su calidad y fiabilidad. En este artículo, presentamos BeTTy, un framework para la automatizacíon de pruebas en el análisis de modelos de características. Entre otras funcionalidades, BeTTy permite la deteccíon automática de errores en herramientas de análisis de modelos de características. Además, BeTTy permite generar modelos de características tanto aleatorios como computacionalmente duros, útiles para evaluar el rendimiento de las herramientas de análisis. Parte de la funcionalidad del framework es ofrecida a través de una aplicacíon Web que facilita en gran medida su uso.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1668</post_id>
		<post_date><![CDATA[2016-05-16 01:29:16]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 23:29:16]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[betty-un-framework-de-pruebas-para-el-analisis-automatico-de-modelos-de-caracteristicas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1669]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/076]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El análisis automático de modelos de características es un área de investigación activo que ha llamado la atencíon de numerosos investigadores durante las dos últimas décadas. Durante este tiempo, el número de herramientas y técnicas para el análisis de modelos de características se ha multiplicado y con ellas su complejidad. En este escenario, la falta de mecanismos específicos para validar y evaluar la funcionalidad y el rendimiento de las herramientas de análisis se ha convertido en un gran obstáculo dificultando el desarrollo de herramientas y afectando negativamente a su calidad y fiabilidad. En este artículo, presentamos BeTTy, un framework para la automatizacíon de pruebas en el análisis de modelos de características. Entre otras funcionalidades, BeTTy permite la deteccíon automática de errores en herramientas de análisis de modelos de características. Además, BeTTy permite generar modelos de características tanto aleatorios como computacionalmente duros, útiles para evaluar el rendimiento de las herramientas de análisis. Parte de la funcionalidad del framework es ofrecida a través de una aplicacíon Web que facilita en gran medida su uso.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos. Universidad de Sevilla. Av Reina Mercedes S/N, 41012 Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José A. Galindo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos. Universidad de Sevilla. Av Reina Mercedes S/N, 41012 Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[David Benavides]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos. Universidad de Sevilla. Av Reina Mercedes S/N, 41012 Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José A. Parejo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos. Universidad de Sevilla. Av Reina Mercedes S/N, 41012 Sevilla, España]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Systematic Review of Quality Attributes and Measures for Software Product Lines</title>
		<link>https://biblioteca.sistedes.es/articulo/a-systematic-review-of-quality-attributes-and-measures-for-software-product-lines/</link>
		<pubDate>Sun, 15 May 2016 23:31:47 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1671</guid>
		<description></description>
		<content><![CDATA[While quality is an important factor in the construction of single software products, it becomes crucial in Software Product Lines (SPL) since the quality of all products that can be derived from the product line must be ensured. Software measures provide an appropriate mechanism for understanding, controlling, and predicting the quality of software development projects.
A great number of software measures for assessing the quality of Software Product Lines (SPL) have been proposed over the last few years. However, no studies summarizing the current knowledge about them exist. This paper presents a systematic literature review with the aim of identifying and analyzing the existing quality attributes and measures proposed by researchers from 1996 to 2010 to evaluate the quality of software product lines.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1671</post_id>
		<post_date><![CDATA[2016-05-16 01:31:47]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 23:31:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-systematic-review-of-quality-attributes-and-measures-for-software-product-lines]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1673]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/077]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[While quality is an important factor in the construction of single software products, it becomes crucial in Software Product Lines (SPL) since the quality of all products that can be derived from the product line must be ensured. Software measures provide an appropriate mechanism for understanding, controlling, and predicting the quality of software development projects.
A great number of software measures for assessing the quality of Software Product Lines (SPL) have been proposed over the last few years. However, no studies summarizing the current knowledge about them exist. This paper presents a systematic literature review with the aim of identifying and analyzing the existing quality attributes and measures proposed by researchers from 1996 to 2010 to evaluate the quality of software product lines.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Silvia Abrahão]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo ISSI, Departamento de Sistemas Informáticos y Computación Universitat Politècnica de València Camino de Vera s/n, 46022, Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[sabrahao@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sonia Montagud]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo ISSI, Departamento de Sistemas Informáticos y Computación Universitat Politècnica de València Camino de Vera s/n, 46022, Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[smontagud@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Emilio Insfran]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo ISSI, Departamento de Sistemas Informáticos y Computación Universitat Politècnica de València Camino de Vera s/n, 46022, Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[einsfran@dsic.upv.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Diferencias entre las Actividades de Mantenimiento en los Procesos de Desarrollo Tradicional y Open Source</title>
		<link>https://biblioteca.sistedes.es/articulo/diferencias-entre-las-actividades-de-mantenimiento-en-los-procesos-de-desarrollo-tradicional-y-open-source/</link>
		<pubDate>Sun, 15 May 2016 23:36:27 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1677</guid>
		<description></description>
		<content><![CDATA[ Antecedentes. La creciente importancia del Open Source Software (OSS) ha llevado a los investigadores a estudiar cómo los procesos OSS difieren de los procesos de la ingeniería del software tradicional. Objetivo. Determinar las diferencias y similitudes entre las actividades del proceso de mantenimiento seguido por la comunidad OSS y el establecido por el estándar IEEE 1074:2006. Método. Para conocer las actividades que conforman el proceso de desarrollo OSS realizamos un Systematic Mapping Study. Posteriormente, realizamos un emparejamiento entre las actividades del estándar IEEE 1074:2006 con las actividades del proceso OSS. Resultados. Encontramos un total de 22 estudios primarios. De estos estudios, el 73% contaban con actividades relacionadas con el proceso de mantenimiento. Conclusiones. El proceso de mantenimiento tradicional del software no encaja con lo que ocurre en la comunidad OSS. En su lugar, puede ser mejor caracterizar la dinámica general de la evolución OSS como reinvención. Esta reinvención emerge continuamente de la adaptación, aprendizaje, y mejora de las funcionalidades y calidad del OSS. Los proyectos OSS evolucionan a través de mejoras menores donde participan tanto usuarios como desarrolladores.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1677</post_id>
		<post_date><![CDATA[2016-05-16 01:36:27]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 23:36:27]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[diferencias-entre-las-actividades-de-mantenimiento-en-los-procesos-de-desarrollo-tradicional-y-open-source]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="open-source-software"><![CDATA[Open Source Software]]></category>
		<category domain="post_tag" nicename="proceso-de-mantenimiento"><![CDATA[Proceso de Mantenimiento]]></category>
		<category domain="post_tag" nicename="systematic-mapping-study"><![CDATA[Systematic Mapping Study]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1678]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/078]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[ Antecedentes. La creciente importancia del Open Source Software (OSS) ha llevado a los investigadores a estudiar cómo los procesos OSS difieren de los procesos de la ingeniería del software tradicional. Objetivo. Determinar las diferencias y similitudes entre las actividades del proceso de mantenimiento seguido por la comunidad OSS y el establecido por el estándar IEEE 1074:2006. Método. Para conocer las actividades que conforman el proceso de desarrollo OSS realizamos un Systematic Mapping Study. Posteriormente, realizamos un emparejamiento entre las actividades del estándar IEEE 1074:2006 con las actividades del proceso OSS. Resultados. Encontramos un total de 22 estudios primarios. De estos estudios, el 73% contaban con actividades relacionadas con el proceso de mantenimiento. Conclusiones. El proceso de mantenimiento tradicional del software no encaja con lo que ocurre en la comunidad OSS. En su lugar, puede ser mejor caracterizar la dinámica general de la evolución OSS como reinvención. Esta reinvención emerge continuamente de la adaptación, aprendizaje, y mejora de las funcionalidades y calidad del OSS. Los proyectos OSS evolucionan a través de mejoras menores donde participan tanto usuarios como desarrolladores.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Systematic Mapping Study, Proceso de Mantenimiento, Open Source Software]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[John W. Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad Autónoma de Madrid Calle Francisco Tomás y Valiente 11, 28049 Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[john.castro@estudiante.uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Silvia T. Acuña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad Autónoma de Madrid Calle Francisco Tomás y Valiente 11, 28049 Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[silvia.acunna@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Oscar Dieste]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática, Universidad Politécnica de Madrid Campus de Montegancedo s/n, 28660 Boadilla del Monte, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[odieste@fi.upm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Refactorización selectiva de Procesos de Negocio</title>
		<link>https://biblioteca.sistedes.es/articulo/refactorizacion-selectiva-de-procesos-de-negocio/</link>
		<pubDate>Sun, 15 May 2016 23:38:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1680</guid>
		<description></description>
		<content><![CDATA[Los modelos de procesos de negocio se han convertido en uno de los activos más importantes para las organizaciones. Las organizaciones intentan disponer de representaciones precisas de sus procesos de negocio, por lo que deben enfrentarse, durante el ciclo de vida de los procesos de negocio, a defectos en la calidad en dichas representaciones como, por ejemplo, la falta de entendibilidad y modificabilidad. Estos defectos se acentúan cuando los modelos de procesos de negocio han sido extraídos mediante ingeniería inversa (por ejemplo desde los sistemas de información que los soportan parcialmente). En este caso, la refactorización puede ser usada para modificar la representación de los procesos de negocio preservando su comportamiento externo. Este trabajo propone una técnica para seleccionar el conjunto de operadores de refactorización más apropiado en cada caso a fin de maximizar la mejora de entendibilidad y modificabilidad de los modelos de procesos de negocio. La técnica considera un conjunto de medidas presentes en la literatura para evaluar entendibilidad y modificabilidad, y define un conjunto de indicadores para dichas medidas para priorizar la aplicación de cada uno de los operadores de refactorización.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1680</post_id>
		<post_date><![CDATA[2016-05-16 01:38:54]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 23:38:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[refactorizacion-selectiva-de-procesos-de-negocio]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="entendibilidad"><![CDATA[Entendibilidad]]></category>
		<category domain="post_tag" nicename="modelos-de-procesos-de-negocio"><![CDATA[Modelos de procesos de negocio]]></category>
		<category domain="post_tag" nicename="modificabilidad"><![CDATA[Modificabilidad]]></category>
		<category domain="post_tag" nicename="refactorizacion"><![CDATA[Refactorización]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1681]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/079]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los modelos de procesos de negocio se han convertido en uno de los activos más importantes para las organizaciones. Las organizaciones intentan disponer de representaciones precisas de sus procesos de negocio, por lo que deben enfrentarse, durante el ciclo de vida de los procesos de negocio, a defectos en la calidad en dichas representaciones como, por ejemplo, la falta de entendibilidad y modificabilidad. Estos defectos se acentúan cuando los modelos de procesos de negocio han sido extraídos mediante ingeniería inversa (por ejemplo desde los sistemas de información que los soportan parcialmente). En este caso, la refactorización puede ser usada para modificar la representación de los procesos de negocio preservando su comportamiento externo. Este trabajo propone una técnica para seleccionar el conjunto de operadores de refactorización más apropiado en cada caso a fin de maximizar la mejora de entendibilidad y modificabilidad de los modelos de procesos de negocio. La técnica considera un conjunto de medidas presentes en la literatura para evaluar entendibilidad y modificabilidad, y define un conjunto de indicadores para dichas medidas para priorizar la aplicación de cada uno de los operadores de refactorización.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Modelos de Procesos de Negocio, Refactorización, Entendibilidad, Modificabilidad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Fernández-Ropero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Castilla-La Mancha, Paseo de la Universidad 4 13071, Ciudad Real, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[MariaS.Fernandez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ricardo Pérez-Castillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Castilla-La Mancha, Paseo de la Universidad 4 13071, Ciudad Real, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Ricardo.PdelCastillo@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Castilla-La Mancha, Paseo de la Universidad 4 13071, Ciudad Real, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Mario.Piattini@uclm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Accessibility and Internationalization in Requirements Engineering Tools</title>
		<link>https://biblioteca.sistedes.es/articulo/accessibility-and-internationalization-in-requirements-engineering-tools/</link>
		<pubDate>Sun, 15 May 2016 23:43:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1683</guid>
		<description></description>
		<content><![CDATA[In recent years, there has been a significant increase in software development in collaborative and globally distributed settings. Thus, there is a growing interest on accessibility and internationalization issues in Requirements Engineering (RE) tools. The main contribution of this paper is to shed light on RE tools' accessibility and internationalization, which are key capabilities concerning Global Software Development (GSD). To the best of our knowledge, this is the first manuscript on this subject. A 147-item checklist based principally on the features covered by the standard ISO/IEC 9241-171 was used to assess 13 RE tools. Then, a descriptive statistical study was carried out to provide comparability. Bivariate correlation tests were also applied to measure the association between different variables. A major margin for amelioration was found by current RE tools, mainly with regard to the input, output and internationalization features. The outcome of this research shows that there is a lack of adequacy to the accessibility and internationalization needs. In future work, the scope of the study will be extended to cover other capabilities on RE tools and address the multi-cultural challenges in the GSD.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1683</post_id>
		<post_date><![CDATA[2016-05-16 01:43:01]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 23:43:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[accessibility-and-internationalization-in-requirements-engineering-tools]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="accessibility"><![CDATA[Accessibility]]></category>
		<category domain="post_tag" nicename="internationalization"><![CDATA[Internationalization]]></category>
		<category domain="post_tag" nicename="requirements-engineering-tools"><![CDATA[Requirements Engineering Tools]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1684]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/080]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In recent years, there has been a significant increase in software development in collaborative and globally distributed settings. Thus, there is a growing interest on accessibility and internationalization issues in Requirements Engineering (RE) tools. The main contribution of this paper is to shed light on RE tools' accessibility and internationalization, which are key capabilities concerning Global Software Development (GSD). To the best of our knowledge, this is the first manuscript on this subject. A 147-item checklist based principally on the features covered by the standard ISO/IEC 9241-171 was used to assess 13 RE tools. Then, a descriptive statistical study was carried out to provide comparability. Bivariate correlation tests were also applied to measure the association between different variables. A major margin for amelioration was found by current RE tools, mainly with regard to the input, output and internationalization features. The outcome of this research shows that there is a lack of adequacy to the accessibility and internationalization needs. In future work, the scope of the study will be extended to cover other capabilities on RE tools and address the multi-cultural challenges in the GSD.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ Requirements Engineering Tools, Accessibility, Internationalization]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Luis Fernández-Alemán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Faculty of Computer Science, Regional Campus of International Excellence "Campus Mare Nostrum", University of Murcia, Murcia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aleman@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan M. Carrillo De Gea]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Faculty of Computer Science, Regional Campus of International Excellence "Campus Mare Nostrum", University of Murcia, Murcia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jmcdg1@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Joaqúin Nicolás]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Faculty of Computer Science, Regional Campus of International Excellence "Campus Mare Nostrum", University of Murcia, Murcia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jnr@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ambrosio Toval]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Faculty of Computer Science, Regional Campus of International Excellence "Campus Mare Nostrum", University of Murcia, Murcia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[atoval@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Diego Alcón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Faculty of Computer Science, Regional Campus of International Excellence "Campus Mare Nostrum", University of Murcia, Murcia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[d.alconcazorla@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Sofia Ouhbi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Faculty of Computer Science, Regional Campus of International Excellence "Campus Mare Nostrum", University of Murcia, Murcia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[sofia.ouhbi@um.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Using Small Affordable Robots for Hybrid Simulation of Wireless Data Access Systems</title>
		<link>https://biblioteca.sistedes.es/articulo/using-small-affordable-robots-for-hybrid-simulation-of-wireless-data-access-systems/</link>
		<pubDate>Sun, 15 May 2016 23:45:13 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1686</guid>
		<description></description>
		<content><![CDATA[During the last years, research on data processing in wireless environments has increased due to the emergence of mobile devices that are able to obtain real environmental sensory information (e.g., smartphones). Testing the different approaches in a real environment is not always possible due to high costs of deployment of hardware and users in many cases. However, the real world complexity can be simplified according to our needs as information systems always deal with simplified abstractions of real objects. For example, a system considering the location of a real car could simplify it as a certain entity with the same movement path. This can be achieved by using software simulations, which obtain approximated results reducing the costs. Nevertheless, it is difficult to develop an accurate real-world model to simulate the environmental conditions (e.g. uneven tracks, dynamic wireless network coverage, etc.). We introduce in this paper a hybrid simulation platform that is able to recreate real-world scenarios more accurately than software simulations. For that, it uses small affordable robots equipped with sensors in controlled real environments as counterparts of real moving objects and the scenario where they are involved. This enables testing the system considering real communication delays, real sensor readings, etc., instead of having to simulate such events. Finally, we present the experimental evaluation of the system using LEGO Mindstorms robots to simulate a real rowing race at the San Sebastian bay.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1686</post_id>
		<post_date><![CDATA[2016-05-16 01:45:13]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 23:45:13]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[using-small-affordable-robots-for-hybrid-simulation-of-wireless-data-access-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="hybrid-simulation"><![CDATA[Hybrid Simulation]]></category>
		<category domain="post_tag" nicename="lego-mindstorms"><![CDATA[LEGO Mindstorms]]></category>
		<category domain="post_tag" nicename="wireless-data-access"><![CDATA[Wireless Data Access]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1687]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/081]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[During the last years, research on data processing in wireless environments has increased due to the emergence of mobile devices that are able to obtain real environmental sensory information (e.g., smartphones). Testing the different approaches in a real environment is not always possible due to high costs of deployment of hardware and users in many cases. However, the real world complexity can be simplified according to our needs as information systems always deal with simplified abstractions of real objects. For example, a system considering the location of a real car could simplify it as a certain entity with the same movement path. This can be achieved by using software simulations, which obtain approximated results reducing the costs. Nevertheless, it is difficult to develop an accurate real-world model to simulate the environmental conditions (e.g. uneven tracks, dynamic wireless network coverage, etc.). We introduce in this paper a hybrid simulation platform that is able to recreate real-world scenarios more accurately than software simulations. For that, it uses small affordable robots equipped with sensors in controlled real environments as counterparts of real moving objects and the scenario where they are involved. This enables testing the system considering real communication delays, real sensor readings, etc., instead of having to simulate such events. Finally, we present the experimental evaluation of the system using LEGO Mindstorms robots to simulate a real rowing race at the San Sebastian bay.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Hybrid Simulation, Wireless Data Access, LEGO Mindstorms]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Gorka Guerrero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[IIS Department, University of Zaragoza María de Luna 1, 50018, Zaragoza, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[524080@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Roberto Yus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[IIS Department, University of Zaragoza María de Luna 1, 50018, Zaragoza, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ryus@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Eduardo Mena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[IIS Department, University of Zaragoza María de Luna 1, 50018, Zaragoza, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[emena@unizar.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Agile Moodle: Una plataforma para el Aprendizaje Ágil en Ingeniería del Software</title>
		<link>https://biblioteca.sistedes.es/articulo/agile-moodle-una-plataforma-para-el-aprendizaje-agil-en-ingenieria-del-software/</link>
		<pubDate>Sun, 15 May 2016 23:47:42 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1689</guid>
		<description></description>
		<content><![CDATA[En la actualidad, la universidad española todavía tiene retos pendientes de superar para adaptarse al marco del Espacio Europeo de Educación Superior (EEES). Uno de los más importantes es el de proporcionar mecanismos para fomentar y evaluar la adquisición de competencias generales o transversales: capacidades, habilidades y/o aptitudes que el alumno debe desarrollar para aplicarlas a lo largo de su carrera profesional.Por otro lado, en la última década, las metodologías ágiles [1] han adquirido una gran relevancia en el área de la industria software, debido a que su adopción en las empresas está revirtiendo en un aumento de la calidad y competitividad en el mercado [2]. Esto hace indispensable que los contenidos necesarios para el aprendizaje de las metodologías ágiles se impartan en asignaturas pertenecientes a la rama de ingeniería del software, así como su práctica durante el ciclo formativo del ingeniero de software. Asimismo, las metodologías ágiles, y especialmente SCRUM [3], se centran en la gestión de proyectos basados en equipos auto-organizados donde se potencia a sus individuos. En este sentido, las metodologías ágiles se presentan como un marco perfecto para la adquisición de competencias generales de forma flexible y sencilla.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1689</post_id>
		<post_date><![CDATA[2016-05-16 01:47:42]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 23:47:42]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[agile-moodle-una-plataforma-para-el-aprendizaje-agil-en-ingenieria-del-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1690]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/082]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En la actualidad, la universidad española todavía tiene retos pendientes de superar para adaptarse al marco del Espacio Europeo de Educación Superior (EEES). Uno de los más importantes es el de proporcionar mecanismos para fomentar y evaluar la adquisición de competencias generales o transversales: capacidades, habilidades y/o aptitudes que el alumno debe desarrollar para aplicarlas a lo largo de su carrera profesional.Por otro lado, en la última década, las metodologías ágiles [1] han adquirido una gran relevancia en el área de la industria software, debido a que su adopción en las empresas está revirtiendo en un aumento de la calidad y competitividad en el mercado [2]. Esto hace indispensable que los contenidos necesarios para el aprendizaje de las metodologías ágiles se impartan en asignaturas pertenecientes a la rama de ingeniería del software, así como su práctica durante el ciclo formativo del ingeniero de software. Asimismo, las metodologías ágiles, y especialmente SCRUM [3], se centran en la gestión de proyectos basados en equipos auto-organizados donde se potencia a sus individuos. En este sentido, las metodologías ágiles se presentan como un marco perfecto para la adquisición de competencias generales de forma flexible y sencilla.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Ortíz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid E.U. Informática Ctra. Valencia Km. 7 E-28031 Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[portiz@syst.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jennifer Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid E.U. Informática Ctra. Valencia Km. 7 E-28031 Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jenifer.perez@eui.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Santiago Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid E.U. Informática Ctra. Valencia Km. 7 E-28031 Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[salonso@eui.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José Luis Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid E.U. Informática Ctra. Valencia Km. 7 E-28031 Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jlsanchez@eui.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Javier Gil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid E.U. Informática Ctra. Valencia Km. 7 E-28031 Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[jgil@eui.upm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Auditoría de procesos de negocio en la nube: persistencia mediante almacenes no relacionales</title>
		<link>https://biblioteca.sistedes.es/articulo/auditoria-de-procesos-de-negocio-en-la-nube-persistencia-mediante-almacenes-no-relacionales/</link>
		<pubDate>Sun, 15 May 2016 23:49:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1692</guid>
		<description></description>
		<content><![CDATA[Cada día crece el número de aplicaciones y servicios basados en la nube ofertados por proveedores tales como Amazon, Google o Sun entre otros. Además de ofrecerse el software como servicio (SaaS, Software as a Service), destacan los sistemas de procesos de negocio que se ofrecen a los clientes como servicio, denominados PRaaS (Process as a Service).
Uno de los problemas que conlleva la computación en la nube (cloud computing) es la pérdida de control sobre los datos y procesos que hace necesario la realización de auditorías que permitan además verificar el grado de cumplimiento de los procedimientos y regulaciones establecidas por la organización. Como resultado de este proceso de auditoría, es habitual que el volumen de datos se incremente considerablemente en poco tiempo por lo que la escalabilidad será uno de los requisitos a exigir al sistema de almacenamiento subyacente.
En este trabajo se plantea una posible línea de investigación basada en el uso de sistemas de bases de datos no relacionales para dotar de persistencia a los sistemas PRaaS persiguiendo el principal objetivo de mejorar la escalabilidad de los mismos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1692</post_id>
		<post_date><![CDATA[2016-05-16 01:49:54]]></post_date>
		<post_date_gmt><![CDATA[2016-05-15 23:49:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[auditoria-de-procesos-de-negocio-en-la-nube-persistencia-mediante-almacenes-no-relacionales]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="bases-de-datos-no-relacionales"><![CDATA[bases de datos no relacionales]]></category>
		<category domain="post_tag" nicename="cloud-computing"><![CDATA[Cloud Computing]]></category>
		<category domain="post_tag" nicename="compliance-management"><![CDATA[compliance management]]></category>
		<category domain="post_tag" nicename="escalabilidad"><![CDATA[escalabilidad]]></category>
		<category domain="post_tag" nicename="praas"><![CDATA[PRaaS]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2012/083]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Cada día crece el número de aplicaciones y servicios basados en la nube ofertados por proveedores tales como Amazon, Google o Sun entre otros. Además de ofrecerse el software como servicio (SaaS, Software as a Service), destacan los sistemas de procesos de negocio que se ofrecen a los clientes como servicio, denominados PRaaS (Process as a Service).
Uno de los problemas que conlleva la computación en la nube (cloud computing) es la pérdida de control sobre los datos y procesos que hace necesario la realización de auditorías que permitan además verificar el grado de cumplimiento de los procedimientos y regulaciones establecidas por la organización. Como resultado de este proceso de auditoría, es habitual que el volumen de datos se incremente considerablemente en poco tiempo por lo que la escalabilidad será uno de los requisitos a exigir al sistema de almacenamiento subyacente.
En este trabajo se plantea una posible línea de investigación basada en el uso de sistemas de bases de datos no relacionales para dotar de persistencia a los sistemas PRaaS persiguiendo el principal objetivo de mejorar la escalabilidad de los mismos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[PRaaS, bases de datos no relacionales, cloud computing, compliance management, escalabilidad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[M. Cruz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cruz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[B. Bernárdez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[beat@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[M. Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[A. Durán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[amador@us.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Desarrollando una fachada de servicios REST/SOA para aplicaciones SOFEA aplicando una aproximación MDE</title>
		<link>https://biblioteca.sistedes.es/articulo/desarrollando-una-fachada-de-servicios-restsoa-para-aplicaciones-sofea-aplicando-una-aproximacion-mde/</link>
		<pubDate>Thu, 18 Aug 2016 12:53:20 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1799</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1799</post_id>
		<post_date><![CDATA[2016-08-18 14:53:20]]></post_date>
		<post_date_gmt><![CDATA[2016-08-18 12:53:20]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[desarrollando-una-fachada-de-servicios-restsoa-para-aplicaciones-sofea-aplicando-una-aproximacion-mde]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1805]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años, el desarrollo web ha introducido un cambio drástico a nivel arquitectónico con la aparición de las arquitecturas de presentación basadas en servicios (SOFEA), motivado en gran medida por la aparición de los dispositivos móviles. Este estilo propone una clara separación entre la parte cliente, ejecutada completamente en el navegador, y una parte servidora que devuelve únicamente datos mediante una fachada REST o SOA.

Una de las características más importantes de SOFEA es la de minimizar el número de llamadas remotas debido a su elevado coste temporal. Para ello es necesario definir una fachada que ofrezca un número reducido de operaciones, y ensamblar en un solo objeto datos complejos. Sin embargo, se requieren de grandes cantidades de clases ensambladoras que realicen las transformaciones entre las entidades de negocio y los objetos ensamblados, dificultando la mantenibilidad del código de la fachada.

Para resolver este problema, este trabajo presenta un modelo de servicios basado en la propuesta OOH4RIA. Este modelo de servicios, mediante una notación textual,  permite modelar una fachada REST ofertando un conjunto de operaciones del modelo de dominio. Además, introduce aspectos de seguridad y una estructuración de los datos basada en el patrón Transfer Object Assembler.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Web Services, SOFEA, REST, MDE, OOH4RIA]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Arias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[antonio.arias@ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jesús M.	Hermida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Italy	European Commission, Joint Research Centre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jesus.hermida@jrc.ec.europa.eu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Santiago Meliá]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[santi@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/047]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Involucrando al humano en el bucle de control de sistemas auto-adaptativos</title>
		<link>https://biblioteca.sistedes.es/articulo/involucrando-al-humano-en-el-bucle-de-control-de-sistemas-auto-adaptativos/</link>
		<pubDate>Thu, 18 Aug 2016 14:47:08 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1802</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1802</post_id>
		<post_date><![CDATA[2016-08-18 16:47:08]]></post_date>
		<post_date_gmt><![CDATA[2016-08-18 14:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[involucrando-al-humano-en-el-bucle-de-control-de-sistemas-auto-adaptativos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1803]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La auto-adaptación juega un papel clave en los sistemas software del futuro, los cuales están formados por complejos ecosistemas heterogéneos teniendo que ser capaces de adaptarse continua y autónomamente, en tiempo de ejecución, a su contexto (nuevas condiciones del entorno, situaciones impredecibles, necesidades cambiantes de los usuarios, nuevos recursos, etc.). Aunque estas adaptaciones deben gestionarse de forma autónoma, la experiencia demuestra que los humanos no pueden excluirse completamente del bucle de adaptación, ya sea para solucionar conflictos difíciles de resolver autónomamente o para mejorar las estrategias de adaptación con su realimentación. En este artículo se abre una línea de trabajo para involucrar al humano en el bucle de control de los sistemas auto-adaptativos ("human in the loop") y que éstos puedan participar en la toma de decisiones de adaptación, siempre intentando maximizar la autonomía y evitar sistemas intrusivos y molestos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Auto-adaptación, Computación Autónoma, "Human in the Loop", Interacción Persona-Ordenador, Experiencia de Usuario]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miriam	Gil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mgil@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pele@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Joan	Fons 	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jjfons@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manoli Albert	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[malbert@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/048]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Uso de Juegos Serios para la Formación en los Procesos del Ciclo de Vida y Mejora del Software</title>
		<link>https://biblioteca.sistedes.es/articulo/uso-de-juegos-serios-para-la-formacion-en-los-procesos-del-ciclo-de-vida-y-mejora-del-software/</link>
		<pubDate>Thu, 18 Aug 2016 15:11:12 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1806</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1806</post_id>
		<post_date><![CDATA[2016-08-18 17:11:12]]></post_date>
		<post_date_gmt><![CDATA[2016-08-18 15:11:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[uso-de-juegos-serios-para-la-formacion-en-los-procesos-del-ciclo-de-vida-y-mejora-del-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1807]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La formación en proceso software es un tema de gran relevancia a tener en cuenta por los profesionales de la industria de la ingeniería del software en el camino hacia el desarrollo de software de calidad con éxito. Sin embargo, los estudios realizados muestran como dicha formación es altamente teórica y en la mayoría de los casos suele impartirse de forma separada a la formación en las actividades del desarrollo del software, en un entorno donde los futuros profesionales apenas adquieren experiencia práctica en la aplicación de los procesos del ciclo de vida y mejora del software. En este artículo, analizamos el uso de los juegos serios para la formación en proceso software, y los grupos de procesos del ciclo de vida del software definidos por el estándar ISO/IEC 12207. Además, proponemos un juego serio basado en simulación para formar en dirección y gestión de proyectos software, y lo relacionamos con los procesos del estándar ISO/IEC 12207. Por último, presentamos los resultados de la evaluación realizada por expertos (n=10) sobre el uso del juego serio propuesto para la formación en proceso software, concluyendo que su uso durante el curso ayuda a los alumnos en la adquisición de los conocimientos del proceso software de forma práctica.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Proceso Software, ISO/IEC 12207, Juegos Serios, Formación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alejandro Calderón Sánchez	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alejandro.calderonsanchez@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mercedes Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mercedes.ruiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/050]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>AgileRoadmap: Un modelo y estrategia para implantación de prácticas ágiles</title>
		<link>https://biblioteca.sistedes.es/articulo/agileroadmap-un-modelo-y-estrategia-para-implantacion-de-practicas-agiles/</link>
		<pubDate>Thu, 18 Aug 2016 15:18:27 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1809</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1809</post_id>
		<post_date><![CDATA[2016-08-18 17:18:27]]></post_date>
		<post_date_gmt><![CDATA[2016-08-18 15:18:27]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[agileroadmap-un-modelo-y-estrategia-para-implantacion-de-practicas-agiles]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1810]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La comunidad que trabaja con métodos ágiles no cuenta con un cuerpo de conocimiento consensuado. Si bien esto ha permitido que los métodos ágiles se hayan difundido rápidamente, sin la regulación centralizada de alguna institución, como contrapartida la aplicación de métodos ágiles en muchos casos carece de rigor o su valoración resulta demasiado subjetiva. Claramente existen unos métodos ágiles más populares; Scrum, Kanban, Lean Development y Extreme Programming, cada uno de ellos tiene sus propias fuentes de información y en general, se ha fomentado su aplicación de forma exclusiva. Sin embargo, las prácticas ágiles detrás de dichos métodos son complementarias, e incluso muchas de ellas son comunes a varios métodos. A través de implantaciones reales de métodos ágiles en diferentes empresas hemos ido refinando un enfoque para implantación de agilismo que hemos denominado AgileRoadmap. Nuestra propuesta incluye un modelo y una estrategia para la implantación del agilismo, integrando las prácticas ágiles de dichos métodos más populares y centrándose en la aplicación de prácticas, no en la aplicación de un método en concreto. AgileRoadmap incluye un catálogo de prácticas ágiles y una serie de criterios que ayudan en la selección de prácticas ágiles para un cierto contexto de trabajo. Así, AgileRoadmap puede ayudar a elaborar una hoja de ruta para la implantación del agilismo en equipos de trabajo. En este artículo se presenta AgileRoadmap y una herramienta de apoyo que hemos desarrollado para facilitar su aplicación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Métodos ágiles, Scrum, Kanban, Lean Development, Extreme Programming]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Patricio Letelier	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[letelier@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mª Carmen Penadés		]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mpenades@dsic.upv.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/051]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Categorización de Actividades de Seguridad en el Desarrollo de Software</title>
		<link>https://biblioteca.sistedes.es/articulo/categorizacion-de-actividades-de-seguridad-en-el-desarrollo-de-software/</link>
		<pubDate>Thu, 18 Aug 2016 15:25:08 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1812</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1812</post_id>
		<post_date><![CDATA[2016-08-18 17:25:08]]></post_date>
		<post_date_gmt><![CDATA[2016-08-18 15:25:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[categorizacion-de-actividades-de-seguridad-en-el-desarrollo-de-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1813]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resulta evidente la necesidad de considerar la seguridad en todas las tareas del ciclo de vida del software. Su inclusión desde las fases más tempranas de desarrollo evitará futuros sobrecostes en las fases finales, que suelen ser las más complejas. La detección de fallos de seguridad o vulnerabilidades en las fases iniciales de desarrollo garantizan la reducción de posibles ataques maliciosos, además de contribuir a la reputación corporativa de las empresas que desarrollan software. En el camino hacia particularizar un modelo de desarrollo de software seguro por defecto, y tras analizar diferentes marcos de trabajo, se han identificado una serie de prácticas de seguridad recurrentes en todos ellos, y, por ello, fundamentales. Las carencias detectadas en los modelos estudiados se subsanan añadiendo nuevas actividades de seguridad, propuestas por los autores. Este trabajo realiza una categorización de las actividades de seguridad del ciclo de vida del software, de manera que se encuentren correctamente planificadas y se implementen de forma sistemática, garantizando una mayor seguridad del software desarrollado.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Modelo de Seguridad, Software Seguro, Ciclo de Vida, Desarrollo Seguro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Carlos Sancho Núñez		]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Viewnext S.A.	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jcsanchon@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Andrés Caro Lindo			]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[andresc@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pablo García Rodríguez		]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pablogr@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/052]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación automática de eventos de prueba para sistemas de IoT</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-automatica-de-eventos-de-prueba-para-sistemas-de-iot/</link>
		<pubDate>Tue, 30 Aug 2016 12:03:48 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1817</guid>
		<description></description>
		<content><![CDATA[CEDI_2016_paper_78]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1817</post_id>
		<post_date><![CDATA[2016-08-30 14:03:48]]></post_date>
		<post_date_gmt><![CDATA[2016-08-30 12:03:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-automatica-de-eventos-de-prueba-para-sistemas-de-iot]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1818]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La aplicación en diversas áreas de Internet de las Cosas (IoT) ha ido en aumento en los últimos años. Uno de los principales inconvenientes que tienen los sistemas IoT es la cantidad de información que tienen que manejar. Esta información llega en forma de eventos, cuyo receptor ha de tomar las decisiones correctas, en tiempo real, según los datos recibidos. Viendo la relevancia que tiene el procesado de esta información, resulta fundamental analizar y probar los sistemas IoT que van a trabajar con ella. Para probar las distintas funcionalidades de los sistemas IoT, se necesita una gran cantidad de eventos con estructuras y valores específicos. Conseguir estos eventos de forma manual puede ser una tarea muy costosa y propensa a errores. En este trabajo se presenta un método para la generación automática de eventos de prueba para sistemas de IoT. Los resultados obtenidos en los casos de prueba utilizados muestran su viabilidad.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Generador de eventos, Pruebas, Definición de tipo de evento, Internet de las Cosas, Procesado de Eventos Complejos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Lorena Gutiérrez-Madroñal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[lorena.gutierrez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo		]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan José	Domínguez Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanjose.dominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/007]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Software Engineering Experiments to value MDE in testing. Learning Lessons</title>
		<link>https://biblioteca.sistedes.es/articulo/a-software-engineering-experiments-to-value-mde-in-testing-learning-lessons/</link>
		<pubDate>Tue, 30 Aug 2016 12:15:23 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1820</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1820</post_id>
		<post_date><![CDATA[2016-08-30 14:15:23]]></post_date>
		<post_date_gmt><![CDATA[2016-08-30 12:15:23]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-software-engineering-experiments-to-value-mde-in-testing-learning-lessons]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1821]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Controlled experiments are commonly used to evaluate Software Engineer-ing methods, processes and tools. Validating results of Software Engineering research in industrial settings is a direct way to obtain feedback about its value. However, few software engineering experiments are running in indus-try. The lack of communication between companies and research teams does not make the necessary cooperation among them possible. This paper pre-sents our experiences when running an experiment dealing with Early Test-ing at the University of Seville. It also introduces the strategy we followed to obtain the participation of 97 practitioners from 32 different software com-panies. Such strategy is pointed out as a set of guidelines to successfully in-volve this large number of companies and practitioners.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Software experiments in enterprise, early testing experiences, enterprise experiences]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María José Escalona		]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mjescalona@us.es	Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Guillermo Lopez Nicolás]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto Tecnológico de Aragón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[glopez@itainnova.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sira	Vegas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[svegas@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Laura García-Borgoñón	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Instituto Tecnológico de Aragón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[laurag@itainnova.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Julián Alberto	García García	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[julian.garcia@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Natalia Juristo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[natalia@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/008]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia un entorno extensible basado en ADM para la refactorización de sistemas heredados</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-un-entorno-extensible-basado-en-adm-para-la-refactorizacion-de-sistemas-heredados/</link>
		<pubDate>Tue, 30 Aug 2016 12:24:54 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1824</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1824</post_id>
		<post_date><![CDATA[2016-08-30 14:24:54]]></post_date>
		<post_date_gmt><![CDATA[2016-08-30 12:24:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-un-entorno-extensible-basado-en-adm-para-la-refactorizacion-de-sistemas-heredados]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1826]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Hoy en día siguen activos muchos sistemas heredados que presentan problemas que afectan a las distintas características la calidad del software. Para mejorar estos problemas, existen herramientas de refactorización, cuyo objetivo es mejorar aspectos de calidad concretos sin afectar al comportamiento del sistema heredado. ADM (Modernización Dirigida por la Arquitectura), se presenta como el paradigma que basa el entendimiento y evolución de los sistemas software en MDA. Existen multitud de entornos que implementan estrategias de refactorización clásicas para mejorar la calidad de los sistemas, pero estas herramientas ofrecen un catálogo fijo de refactorizaciones. La propuesta que se presenta en este artículo consiste en un entorno flexible basado en ADM que permite la definición de “bad-smells” (clásicos y nuevos), aplicables a contextos concretos y su identificación en sistemas heredados, teniendo así una herramienta totalmente flexible y extensible.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Refactorización, ADM, Flexible, Extensible, Calidad, Sistemas Heredados]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Abel	Lorente Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información (ITSI), Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[abel.lorente@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ignacio García-Rodríguez de Guzmán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información (ITSI), Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Ignacio.GRodriguez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información (ITSI), Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Mario.Piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/014]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Pruebas sobre aplicaciones de bases de datos orientadas a grafos: un enfoque basado en modelos</title>
		<link>https://biblioteca.sistedes.es/articulo/pruebas-sobre-aplicaciones-de-bases-de-datos-orientadas-a-grafos-un-enfoque-basado-en-modelos/</link>
		<pubDate>Tue, 30 Aug 2016 12:30:17 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1828</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1828</post_id>
		<post_date><![CDATA[2016-08-30 14:30:17]]></post_date>
		<post_date_gmt><![CDATA[2016-08-30 12:30:17]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[pruebas-sobre-aplicaciones-de-bases-de-datos-orientadas-a-grafos-un-enfoque-basado-en-modelos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1829]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las bases de datos NoSQL plantean nuevos desafíos a la hora de probar las aplicaciones que las utilizan, debido a que sus modelos de datos y sus modos de acceso difieren de las bases de datos relacionales. La prueba de aplicaciones que acceden a bases de datos relacionales ha atraído el interés de muchos investigadores, mientras que la prueba de aplicaciones que acceden a bases de datos NoSQL es un área que aún no ha sido prácticamente explorada. Este trabajo describe un enfoque que permite crear modelos que definen objetivos de prueba para aplicaciones que utilizan bases de datos orientadas a grafo, a partir de la especificación del sistema y del modelo de datos conceptual. Estos modelos son empleados posteriormente para derivar los requisitos de prueba que guían la generación de los casos de prueba. El enfoque ha sido aplicado a una aplicación que representa un problema del mundo real y los resultados muestran que permite diseñar casos de prueba capaces de detectar fallos que pueden aparecer tanto en la especificación del sistema como en la implementación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Pruebas sobre bases de datos orientadas a grafos, Pruebas basadas en la especificación, Base de datos de prueba, Model-based testing]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Raquel Blanco	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rblanco@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Tuya	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/009]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación y Ejecución de Escenarios de Prueba para Aplicaciones MapReduce</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-y-ejecucion-de-escenarios-de-prueba-para-aplicaciones-mapreduce/</link>
		<pubDate>Tue, 30 Aug 2016 12:35:30 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1831</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1831</post_id>
		<post_date><![CDATA[2016-08-30 14:35:30]]></post_date>
		<post_date_gmt><![CDATA[2016-08-30 12:35:30]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-y-ejecucion-de-escenarios-de-prueba-para-aplicaciones-mapreduce]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1832]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los programas que procesan grandes cantidades de datos se suelen ejecutar sobre una infraestructura distribuida, como es el caso de las aplicaciones implementadas bajo el modelo de procesamiento MapReduce. Estos modelos permiten al desarrollador centrarse en la funcionalidad de la aplicación y abstraer aspectos relacionados con la infraestructura en la que se ejecutará. Sin embargo, su configuración y estado pueden causar que ciertos defectos sean difíciles de detectar debido a que las pruebas se suelen ejecutar en un entorno controlado, con bajo nivel de paralelismo y con pocos datos de entrada. En este artículo se elabora una técnica de prueba que partiendo de unos datos de entrada, genera y reproduce diferentes configuraciones de la infraestructura con el objetivo de detectar aquellas que revelen defectos funcionales en la aplicación. Esta técnica se automatiza en un motor de ejecución de pruebas y se aplica a un caso de estudio que actualmente se encuentra en producción. Como resultado, partiendo de un caso de prueba de tamaño reducido, se han identificado automáticamente varias configuraciones de la infraestructura que ocasionarían fallos de la aplicación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Pruebas del software, MapReduce, Big Data engineering]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús Morán		]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[moranjesus@lsi.uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Claudio de la Riva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[claudio@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/010]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Sobre el grado de acuerdo entre evaluadores en la detección de Design Smells</title>
		<link>https://biblioteca.sistedes.es/articulo/sobre-el-grado-de-acuerdo-entre-evaluadores-en-la-deteccion-de-design-smells/</link>
		<pubDate>Tue, 30 Aug 2016 12:42:34 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1834</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1834</post_id>
		<post_date><![CDATA[2016-08-30 14:42:34]]></post_date>
		<post_date_gmt><![CDATA[2016-08-30 12:42:34]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[sobre-el-grado-de-acuerdo-entre-evaluadores-en-la-deteccion-de-design-smells]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1835]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La detección de Design Smells ha ido experimentado un auge en resultados de investigación publicados. La primera definición de Design Smells data del año 2000. La primera herramienta se reporta en 2002. A partir de 2004 comienza un crecimiento continuado, proliferando la aparición de nuevas herramientas para la detección automática de Design Smells. Particularmente a partir de 2009-2010 se produce un incremento notable en la actividad en este ámbito. La detección automática de Design Smells ha evolucionado a la par que las herramientas automáticas de refactoring. Sin embargo se constata que no ha sido comparable su adopción por parte de los desarrolladores en la producción y mantenimiento del software, con la forma en la que se han adoptado las herramientas de refactoring. En este trabajo partimos de la suposición de que la diferencia reside en la objetividad y pragmatismo de una operación de refactoring comparada con el grado de subjetividad que suponemos en la definición e identificación de Design Smells. Para estudiar este problema se diseñó una encuesta difundida vía correo electrónico en la que se obtuvieron 92 respuestas de personas tanto de la academia como de la industria acerca de la presencia de Design Smells en 5 clases de un proyecto de código abierto. El estudio se ha realizado centrándose en la detección de dos tipos de Design Smells: God Class y Feature Envy. La selección se basa en que son dos de los Design Smells más populares en la literatura y en que además se trata de Design Smells de diferente naturaleza en cuanto al ámbito y al efecto en el software. Se ha realizado un estudio en el que se valora el grado de acuerdo en la identificación de Design Smells entre los encuestados. En el trabajo se analizan la interrelación entre diferentes factores como la experiencia del evaluador, su contexto de trabajo, etc. Los resultados obtenidos muestran que no existe acuerdo en general y que es muy pobre en los casos en los que sí existe algún acuerdo. A partir de los resultados obtenidos se concluye con recomendaciones a tener en cuenta en las nuevas tendencias para la detección automática de Design Smells que pueden influir positivamente en la adopción por la industria de técnicas y herramientas para la detección de Design Smells.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Detección de Design Smells, encuesta, acuerdo entre evaluadores, Kappa-Fleiss, calidad, evolución, mantenimiento]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Khalid Alkharabsheh	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnologías de la Información Universidad de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[khalid.alkharabsheh@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Yania Crespo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Informática, Universidad de Valladolid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[yania@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Esperanza Manso	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Informática, Universidad de Valladolid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manso@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jose Angel Taboada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnologías de la Información Universidad de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Joseangel.taboada@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/011]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Comparación de herramientas de Detección de Design Smells</title>
		<link>https://biblioteca.sistedes.es/articulo/comparacion-de-herramientas-de-deteccion-de-design-smells/</link>
		<pubDate>Tue, 30 Aug 2016 15:12:04 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1837</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1837</post_id>
		<post_date><![CDATA[2016-08-30 17:12:04]]></post_date>
		<post_date_gmt><![CDATA[2016-08-30 15:12:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[comparacion-de-herramientas-de-deteccion-de-design-smells]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1838]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La detección de Design Smells ha experimentado un auge en actividad entre los años 2010 y 2014.
Proliferan las herramientas de detección automática pero se percibe un problema de falta de acuerdo en la identificación de Design Smells. En este trabajo se presentan dos experimentos. El primero es un experimento diseñado como estudio preliminar en el que se comparan una selección de 6 herramientas (inCode, inFusion, iPlasma, Together, JDeodorant y JSmellSensor) usándolas para detectar Design Smells en un proyecto software de código abierto. Del proyecto seleccionado se eligieron 100 clases aleatoriamente para este primer estudio exploratorio. El análisis consistió en valorar el grado de acuerdo en la identificación de Design Smells en el grupo de herramientas. En este primer experimento el estudio se realizó centrándose en la detección de dos tipos de Design Smells: God Class y Feature Envy. De este primer estudio se detectó un grupo de tres herramientas (inCode, inFusion, iPlasma) con un grado de acuerdo muy bueno. Se analizó que esto es así debido a que las tres fueron desarrolladas en el mismo grupo de investigación. Entre el resto de herramientas el acuerdo es inexistente (peor que al azar) o débil. El acuerdo débil se detectó entre el grupo de tres herramientas antes mencionadas y la herramienta JSmellSensor. JSmellSensor es una herramienta experimental desarrollada en nuestro grupo de investigación que parte de conocimiento aportado por iPlasma. Debido a estas circunstancias y para profundizar en el problema se diseñó una réplica. En esta réplica se comparan 5 herramientas (iPlasma, PMD, JDeodorant, DECOR, Together). Del grupo de tres herramientas identificado en el primer experimento se eligió como representante iPlasma. Se decidió que JSmellSensor no participase en esta réplica. En este segundo experimento se analizaron 12588 clases fruto de la preparación de un dataset con todas las clases de 24 proyectos de código abierto obtenidos de SourceForge. Este segundo experimento se centró únicamente en el estudio del acuerdo en la identificación de God Clss. Los resultados obtenidos en este segundo experimento muestran que tanto el acuerdo entre las herramientas tomadas conjuntamente como analizadas dos a dos es muy pobre.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Detección de Design Smells, Kappa-Fleiss, FCA, calidad, evolución, mantenimiento]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Khalid Alkharabsheh	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnologías de la Información Universidad de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[khalidkh1980@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Yania Crespo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Informática, Universidad de Valladolid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[yania@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Esperanza Manso	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Informática, Universidad de Valladolid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manso@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jose Angel Taboada	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnologías de la Información Universidad de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Joseangel.taboada@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/012]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Calidad Ágil: Patrones de Diseño en un contexto de Desarrollo Dirigido por Pruebas</title>
		<link>https://biblioteca.sistedes.es/articulo/calidad-agil-patrones-de-diseno-en-un-contexto-de-desarrollo-dirigido-por-pruebas/</link>
		<pubDate>Wed, 31 Aug 2016 12:33:22 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1840</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1840</post_id>
		<post_date><![CDATA[2016-08-31 14:33:22]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 12:33:22]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[calidad-agil-patrones-de-diseno-en-un-contexto-de-desarrollo-dirigido-por-pruebas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1841]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En esta investigación se propone un conjunto inicial de patrones de diseño que pueden ser utilizados en un contexto de TDD. Se analizan las características de calidad de software de cada uno de los patrones del conjunto seleccionado según el estándar de calidad de software vigente ISO/IEC 25010:2011~cite{ISO/IEC}.

Para cada patrón y característica ISO, se discute si las propiedades esperadas del código resultan aumentadas o inhibidas con la incorporación del patrón.

Se realiza un análisis crítico de cada patrón seleccionado según tres dimensiones: (1)capacidad de prueba (testability), (2)características de calidad propiciadas y (3)características de calidad inhibidas. Esto deriva en un resumen para cada patrón seleccionado, incluyendo una breve descripción de cada patrón, componentes, y su impacto (beneficios y desventajas ) en la calidad del código de pruebas desarrollado a través de su utilización.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[TDD design patterns, Analysis patterns, Quality Assessment, Java unit tests, ISO/IEC 25010 quality attributes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel I. Capel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[manuelcapel@ugr.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Anna C. Grimán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Procesos y Sistemas, Universidad Simón Bolívar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[agriman@usb.ve]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Eladio Garví]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[egarvi@ugr.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/013]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Static analysis of textual models</title>
		<link>https://biblioteca.sistedes.es/articulo/static-analysis-of-textual-models/</link>
		<pubDate>Wed, 31 Aug 2016 14:10:45 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1845</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1845</post_id>
		<post_date><![CDATA[2016-08-31 16:10:45]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 14:10:45]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[static-analysis-of-textual-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1846]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Domain specific languages (DSLs) based on textual notations are useful to describe the semantics of a given problem. Software frameworks, such as Xtext, enable to easily design and develop textual DSLs. The use of interactive quality platforms for analysing source code such as SonarQube is increasing. For evaluating the quality of a program written with an Xtext-designed DSL, all the artifacts required by SonarQube to parse and query the source code must be developed, which becomes time-consuming and error-prone. A transformation tool and its application to a DSL are presented to bridge the gap between Xtext and SonarQube grammar formats by following a model-driven interoperability strategy.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[DSL, Xtext, SonarQube, Model-driven Interoperability]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Iván	Ruiz-Rube	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ivan.ruiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Tatiana Person]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[tatiana.personmontero@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Dodero	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanma.dodero@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/020]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evaluating Embedded Relational Databases for Large Model Persistence and Query</title>
		<link>https://biblioteca.sistedes.es/articulo/evaluating-embedded-relational-databases-for-large-model-persistence-and-query/</link>
		<pubDate>Wed, 31 Aug 2016 14:20:33 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1848</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1848</post_id>
		<post_date><![CDATA[2016-08-31 16:20:33]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 14:20:33]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evaluating-embedded-relational-databases-for-large-model-persistence-and-query]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1849]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Large models are increasingly used in Model Driven Development. Different studies have proved that XMI (default persistence in Eclipse Modelling Framework) has some limitations when operating with large models. To overcome them, recent approaches have used databases for persistence of models. EDBM (Embedded DataBase for Models) is an approach for persisting models in an embedded relational database, which provides scalable querying mechanism by runtime translation of model-level queries to SQL. In this paper, we present an evaluation of EDBM in terms of scalability with existing approaches. GraBaTs 2009 case study (models from 8.8MB to 646MB) is used for evaluation. EDBM is 70% faster than compared approaches to persist XMI GraBats models into databases and executes the GraBats query faster, as well as having a low memory usage. These results indicate that embedded relational database, combined with a scalable query mechanism provide a promising alternative for persisting and querying large models.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Model-Driven Development, Large-Scale Models, Persistence, Query, Runtime Translation, Evaluation]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Xabier De Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[IK4-Ikerlan Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[xdecarlos@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Goiuria Sagardui]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Mondragon Unibertsitatea]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gsagardui@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Salvador Trujillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[IK4-Ikerlan Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[strujillo@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Alain Perkaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[IK4-Ikerlan Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aperkaz@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Mikel Cañizo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[IK4-Ikerlan Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[mcanizo@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Aitziber Iglesias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[IK4-Ikerlan Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[aiglesias@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/015]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Performance Analysis of Persistence Technologies for Cloud Repositories of Models</title>
		<link>https://biblioteca.sistedes.es/articulo/performance-analysis-of-persistence-technologies-for-cloud-repositories-of-models/</link>
		<pubDate>Wed, 31 Aug 2016 14:27:12 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1851</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1851</post_id>
		<post_date><![CDATA[2016-08-31 16:27:12]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 14:27:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[performance-analysis-of-persistence-technologies-for-cloud-repositories-of-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1852]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The growing adoption of Model Driven Development (MDD) in companies during last decade arises some model interchange problems. Companies need support to interchange models and reuse parts of them for developing new projects. Traditional tools for model edition and model interchange have different performance issues related to the models storage. There are mainly two styles to organize the persistence of models into repositories: a complex and large model or a large amount of small models. This last approach is common in companies that generate software from models. In this paper, we analyse performance properties of different persistence technologies to store small/medium-scale models, the analysis results should be considered in the design of model repositories in the cloud. With this aim, we have designed and developed a generic architecture to evaluate each persistence technology under similar situations.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[model repository, persistence technology, performance analysis]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan-Pablo Salazar-Álvarez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Center for Open Middleware, Universidad Politécnica de Madrid (UPM)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jpsalalv@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Elena Gómez-Martínez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Center for Open Middleware, Universidad Politécnica de Madrid (UPM)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[elena.gomez@centeropenmiddleware.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Miguel de Miguel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DIT, Universidad Politécnica de Madrid (UPM)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mmiguel@dit.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/016]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una Propuesta de Editor Gráfico para el Modelado y la Generación de Código de Patrones de Eventos sobre Drones</title>
		<link>https://biblioteca.sistedes.es/articulo/una-propuesta-de-editor-grafico-para-el-modelado-y-la-generacion-de-codigo-de-patrones-de-eventos-sobre-drones/</link>
		<pubDate>Wed, 31 Aug 2016 14:35:03 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1854</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1854</post_id>
		<post_date><![CDATA[2016-08-31 16:35:03]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 14:35:03]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-propuesta-de-editor-grafico-para-el-modelado-y-la-generacion-de-codigo-de-patrones-de-eventos-sobre-drones]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1855]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los lenguajes de procesamiento de eventos (EPL) permiten declarar e implementar patrones de eventos que son procesados posteriormente por motores de procesamiento de eventos complejos (CEP) y así poder detectar situaciones de interés del usuario en tiempo real. Para llevar a cabo esta tarea, el usuario debe tener un alto grado de experiencia en estos lenguajes. Sin embargo, y en el ámbito de los drones, los usuarios suelen tener un vasto conocimiento en el dominio para el que se necesitan definir ciertos patrones de eventos (motores, dispositivos de navegación, pilotos automáticos, etc.), pero que son inexpertos tanto en EPLs como en el lenguaje requerido para implementar las acciones a llevar a cabo en el dron tras la detección de los eventos. En este artículo presentamos un editor de modelado de patrones con el propósito de facilitar a los usuarios finales un entorno amigable e intuitivo con el que poder definir gráficamente las situaciones críticas y relevantes que se requieran detectar en los drones, y sin necesidad de conocer ningún lenguaje de programación en particular. Además, este editor transforma estos modelos gráficos de patrones al código que los implementa.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Procesamiento de Eventos Complejos, Lenguaje de Procesamiento de Eventos, Desarrollo de Software Dirigido por Modelos, Editor de Modelado Gráfico, Dron]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanher@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Enrique Moguel	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[enrique@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Carlos Preciado	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jcpreciado@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Fernando Sánchez-Figueroa	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[fernando@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/021]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards Distributed Model Transformations with LinTra</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-distributed-model-transformations-with-lintra/</link>
		<pubDate>Wed, 31 Aug 2016 14:40:39 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1857</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1857</post_id>
		<post_date><![CDATA[2016-08-31 16:40:39]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 14:40:39]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-distributed-model-transformations-with-lintra]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1858]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Performance and scalability of model transformations are becoming prominent topics in Model-Driven Engineering. In previous work, we introduced LinTra, a platform for executing model transformations in parallel. LinTra is based on the Linda model of a coordination language and is intended to be used as a middleware where high-level model transformation languages are compiled. In this paper we present an approach to achieve scalable out-place model-to-model transformation executions in LinTra by distributing the models involved in the transformation over a set of machines.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Model Transformation, Distribution, LinTra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Loli Burgueño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[loli@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Wimmer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Business Informatics Group, Vienna University of Technology]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[wimmer@big.tuwien.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Vallecillo	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[av@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/022]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards the Automation of Metamorphic Testing in Model Transformations</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-the-automation-of-metamorphic-testing-in-model-transformations/</link>
		<pubDate>Wed, 31 Aug 2016 14:49:32 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1860</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1860</post_id>
		<post_date><![CDATA[2016-08-31 16:49:32]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 14:49:32]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-the-automation-of-metamorphic-testing-in-model-transformations]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1861]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Model transformations are the cornerstone of Model-Driven Engineering, and provide the essential mechanisms for manipulating and transforming models. Checking whether the output of a model transformation is correct is a manual and error-prone task, this is refereed to as the oracle problem in the software testing literature. The correctness of the model transformation program is crucial for the proper generation of its output, so they should be tested. Metamorphic testing is a testing technique to alleviate the oracle problem consisting on exploiting the relations between different inputs and outputs of the program under test, so-called metamorphic relations. In this paper we give an insight into our approach to generically define metamorphic relations for model transformations, which can be automatically instantiated given any specific model transformation.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Metamorphic Testing, Model Transformation, Automation, Generic]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Troya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jtroya@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/023]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Lenguaje específico para el modelado de flujos de trabajo aplicados a ciencia de datos</title>
		<link>https://biblioteca.sistedes.es/articulo/lenguaje-especifico-para-el-modelado-de-flujos-de-trabajo-aplicados-a-ciencia-de-datos/</link>
		<pubDate>Wed, 31 Aug 2016 14:59:40 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1863</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1863</post_id>
		<post_date><![CDATA[2016-08-31 16:59:40]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 14:59:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[lenguaje-especifico-para-el-modelado-de-flujos-de-trabajo-aplicados-a-ciencia-de-datos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1864]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La ciencia de datos permite la extracción de conocimiento utilizando fuentes no heterogéneas con grandes volúmenes de datos. Este campo es actualmente una de las áreas de mayor crecimiento debido al aumento exponencial de datos disponibles, con aplicación en un amplio rango de dominios. De hecho, es frecuente que los usuarios no posean conocimientos específicos en computación. Para ellos los flujos de trabajo son un mecanismo adecuado de representación y modelización de su proceso de trabajo, ya que permiten definir a alto nivel la secuencia de acciones que permitiría capturar la información y transformarla en conocimiento. Los sistemas de gestión de flujos de trabajo son los encargados de ejecutarlos de forma transparente. En este trabajo se presenta, formalizando su sintaxis abstracta, un lenguaje para la definición de flujos de trabajo a distintos niveles de abstracción. El desarrollo de este lenguaje, por su independencia de la notación concreta, se hace necesario para alcanzar un mayor nivel de interoperabilidad entre las aplicaciones ya desarrolladas para este fin.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[lenguaje específico del dominio, flujos de trabajo, ciencia de datos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rubén Salado-Cid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico, Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rsalado@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Raúl	Romero	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico, Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/017]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>MDDE: Una concepción genérica para diseño de entornos de desarrollo de software basados en MDSE</title>
		<link>https://biblioteca.sistedes.es/articulo/mdde-una-concepcion-generica-para-diseno-de-entornos-de-desarrollo-de-software-basados-en-mdse/</link>
		<pubDate>Wed, 31 Aug 2016 15:03:57 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1866</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1866</post_id>
		<post_date><![CDATA[2016-08-31 17:03:57]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 15:03:57]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mdde-una-concepcion-generica-para-diseno-de-entornos-de-desarrollo-de-software-basados-en-mdse]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1867]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Se presenta MDDE (Model-Driven Development Environment), una concepción genérica para diseño de entornos de desarrollo de software basados en MDSE. Su objetivo es facilitar el uso de esta disciplina a los ingenieros software que di-señan e implementan entornos de soporte a las metodologías que proponen y que necesitan incluir en ellos nuevos modelos de información, herramientas y proce-sos de desarrollo. El componente principal de la concepción propuesta es un mo-delo de referencia que define las capacidades básicas, tanto funcionales como de interacción, que son comunes a cualquier entorno. En ella, la especificación e im-plementación de entornos, el soporte a los procesos que determinan su funciona-lidad y la definición de las opciones de interacción, supervisión y control por par-te de los operadores, se realizan íntegramente mediante la formulación de mode-los. Para dar soporte a esta capacidad, el modelo de referencia incluye un meta-modelo que formaliza tales modelos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[MDSE, meta-modelado, entorno de desarrollo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[César Cuevas		]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Ingeniería Software y Tiempo Real, Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cuevasce@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Patricia López Martínez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Ingeniería Software y Tiempo Real, Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[lopezpa@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose M. Drake]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Ingeniería Software y Tiempo Real, Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[drakej@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/018]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Desarrollo Eficiente de Lenguajes Específicos de Dominio para la Ejecución de Procesos de Minería de Datos</title>
		<link>https://biblioteca.sistedes.es/articulo/desarrollo-eficiente-de-lenguajes-especificos-de-dominio-para-la-ejecucion-de-procesos-de-mineria-de-datos/</link>
		<pubDate>Wed, 31 Aug 2016 15:09:08 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1869</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1869</post_id>
		<post_date><![CDATA[2016-08-31 17:09:08]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 15:09:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[desarrollo-eficiente-de-lenguajes-especificos-de-dominio-para-la-ejecucion-de-procesos-de-mineria-de-datos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1870]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Aunque las técnicas de minería de datos están consiguiendo cada día una mayor popularidad, su complejidad impide que sean aún utilizables por personas sin un sólido conocimiento en las mismas. Una posible solución, ya explorada por los autores de este artículo, es la construcción de Lenguajes Específicos de Dominio que proporcionen una serie de primitivas de alto nivel para la ejecución de procesos de minería de datos. Dichas primitivas sólo hacen referencia a terminología propia del dominio analizado, enmascarando detalles técnicos de bajo nivel. No obstante, la construcción de un lenguaje específico de dominio puede ser un proceso costoso. Este artículo muestra como reducir los tiempos de desarrollo de estos lenguajes de análisis mediante la reutilización de partes comunes de estos DSLs.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Lenguajes Específicos de Dominio, Desarrollo de Software Dirigido por Modelos, Minería de Datos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alfonso de La Vega	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería Informática y Electrónica Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alfonso.delavega@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Diego García-Saiz	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería Informática y Electrónica Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[diego.garciasuc@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Marta Zorrilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería Informática y Electrónica Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[marta.zorrilla@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Pablo Sánchez	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería Informática y Electrónica Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[p.sanchez@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/019]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Bringing together existing Business Modeling flavors</title>
		<link>https://biblioteca.sistedes.es/articulo/bringing-together-existing-business-modeling-flavors/</link>
		<pubDate>Wed, 31 Aug 2016 15:15:10 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1872</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1872</post_id>
		<post_date><![CDATA[2016-08-31 17:15:10]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 15:15:10]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[bringing-together-existing-business-modeling-flavors]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1873]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[There are currently several techniques or notations for business modeling that allow the idea of business to be explored in greater or less detail, while simultaneously helping to understand, conceptualize and represent the services that add value to an organization. All of these techniques have similarities and differences, but are in many cases complementary. However, there is no integrated environment that makes it possible to work with several models simultaneously, and much less that provides support as regards identifying, registering and managing the relationships among them. This work is a first step towards attempting to fill this lack by constructing a technological environment that will integrate tools in order to support different business modeling techniques and to register and manage the relationships among different models.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Business Modeling, Toolkit, Model Engineering]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan M. Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Valeria De Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[valeria.decastro@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[David Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[david.granada@urjc.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[ Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/024]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una herramienta para evaluar el rendimiento de aplicaciones intensivas en datos</title>
		<link>https://biblioteca.sistedes.es/articulo/una-herramienta-para-evaluar-el-rendimiento-de-aplicaciones-intensivas-en-datos/</link>
		<pubDate>Wed, 31 Aug 2016 15:19:45 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1875</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1875</post_id>
		<post_date><![CDATA[2016-08-31 17:19:45]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 15:19:45]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-herramienta-para-evaluar-el-rendimiento-de-aplicaciones-intensivas-en-datos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1876]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las aplicaciones intensivas en datos (AID) que usan tecnologías de Big Data se están convirtiendo en una parte importante del mercado de desarrollo de software. Sin embargo, las técnicas --y su automatización-- para el asesoramiento de la calidad para este tipo de aplicaciones es claramente insuficiente. El proyecto DICE H2020 tiene como objetivo definir metodologías y crear herramientas para desarrollar y monitorizar AID mediante técnicas de ingeniería dirigida por modelos. En este artículo presentamos un componente clave del proyecto DICE: su herramienta de simulación. Esta herramienta es capaz de evaluar el rendimiento de AID simulando su comportamiento mediante modelos de redes de Petri. Como complemento, existe a disposición un vídeo mostrando la herramienta en http://tiny.cc/z1qzay. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Aplicaciones Intensivas en Datos, Lenguaje de Modelado Unificado (UML), Redes de Petri, Herramientas de simulación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Abel Gómez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[abel.gomez@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José	Merseguer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jmerse@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/026]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Análisis de transformaciones de modelos ATL con AnATLyzer</title>
		<link>https://biblioteca.sistedes.es/articulo/analisis-de-transformaciones-de-modelos-atl-con-anatlyzer/</link>
		<pubDate>Wed, 31 Aug 2016 15:29:57 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1878</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1878</post_id>
		<post_date><![CDATA[2016-08-31 17:29:57]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 15:29:57]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analisis-de-transformaciones-de-modelos-atl-con-anatlyzer]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1879]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las transformaciones de modelos son un elemento clave del Desarrollo de Software Dirigido por Modelos puesto que permiten automatizar muchas tareas de manipulación de modelos. Por tanto, disponer de métodos que permitan detectar errores no triviales resulta esencial. Sin embargo no existen herramientas prácticas de análisis de transformaciones que sean capaces de tratar con transformaciones complejas.

En esta demostración se presentará anATLyzer un analizador estático para transformaciones ATL que hace uso de "constraint solving" para mejorar la precisión del análisis. AnATLyzer no se limita a un subconjunto de ATL sino que intenta cubrir ATL completamente. Se integra con el editor de ATL en Eclipse, y ofrece servicios adicionales como visualización y quick fixes, así como una API para ser utilizado de manera programática.

La demostración se ilustrará con un ejemplo sobre el que se mostrarán algunos de los tipos de errores que hemos encontrado analizando transformaciones del Zoo de ATL, con el objetivo de motivar la necesidad de este tipo de herramientas y mostrar sus características principales.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Transformaciones de modelos, ATL, AnATLyzer, Análisis estático, Constraint solving]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús Sánchez Cuadrado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de investigación Miso, Universidad Autónoma de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jesus.sanchez.cuadrado@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Esther Guerra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de investigación Miso, Universidad Autónoma de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[esther.guerra@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan de Lara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de investigación Miso, Universidad Autónoma de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juan.delara@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/025]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Auditorías de Green in IT: Un Mapeo Sistemático</title>
		<link>https://biblioteca.sistedes.es/articulo/auditorias-de-green-in-it-un-mapeo-sistematico/</link>
		<pubDate>Wed, 31 Aug 2016 22:01:19 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1881</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1881</post_id>
		<post_date><![CDATA[2016-09-01 00:01:19]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 22:01:19]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[auditorias-de-green-in-it-un-mapeo-sistematico]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2191]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años el mundo ha ido experimentando una serie de cambios ambientales que han hecho que en la sociedad surja una fuerte convicción en pos de proteger el medioambiente. Las Tecnologías de la Información (TI) y, de manera especial, las tecnologías software, pueden contribuir a la ecosostenibilidad de dos maneras: “Green By IT”, en el sentido de que las TI pueden proporcionar herramientas que permitan llevar a cabo tareas de una manera adecuada para el medioambiente, y “Green In IT”, cuando las propias TI tienen impacto en el medioambiente, debido a su consumo energético. Sin embargo, las técnicas de Green in IT son relativamente jóvenes y no existe ningún estándar o marco que permita controlar su correcta implementación y/o funcionamiento. Por ello, el objetivo del presente mapeo sistemático es recopilar el conocimiento actual en relación a las auditorías de Green in IT, con el fin de poder determinar cuáles son las características más importantes a la hora de desarrollar un marco de auditoría de Green in IT. Los resultados obtenidos demuestran la novedad de esta área y la casi nula existencia de estudios relacionados con ésta, y, por ello, la necesidad de elaborar un marco de auditoría de Green in IT.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Auditoría, Green in IT, Mapeo sistemático]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[J. David Patón-Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Alarcos, Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[JDavid.Paton@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Alarcos, Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Mario.Piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/053]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>¿Qué desafíos presenta el desarrollo global del software? Aprende jugando</title>
		<link>https://biblioteca.sistedes.es/articulo/que-desafios-presenta-el-desarrollo-global-del-software-aprende-jugando/</link>
		<pubDate>Wed, 31 Aug 2016 22:06:22 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1885</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1885</post_id>
		<post_date><![CDATA[2016-09-01 00:06:22]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 22:06:22]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[que-desafios-presenta-el-desarrollo-global-del-software-aprende-jugando]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las empresas de desarrollo de software intentan unirse al mercado global con el fin de poder contratar mano de obra en otros países, buscando reducir los costes, aumentar la productividad y así obtener ventajas competitivas. Esto es lo que se conoce como Desarrollo Global del Software (DGS o GSD, por sus siglas en inglés: Global Software Development). Para realizar esta práctica las empresas requieren desarrolladores que posean conocimientos y habilidades para solventar los problemas que surgen a causa de la distancia geográfica, temporal y cultural. Es aquí donde los juegos serios pueden jugar un papel importante, ya que se trata de juegos educativos que permiten adquirir conocimientos y habilidades con un bajo coste. En este artículo se describe un juego con el cual se puedan adquirir algunas de las competencias necesarias en el DGS. El juego simula escenarios que suelen presentarse durante el desarrollo global de un proyecto software, de manera que el usuario pueda tomar conciencia de los problemas referentes al DGS y adquirir una cierta experiencia a la hora de solventar estos problemas. Además, se describe una evaluación preliminar del mismo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Desarrollo Global del Software, Juegos Serios, Desarrollo Distribuido del Software]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aurora Vizcaíno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Alarcos, Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aurora.vizcaino@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Alarcos, Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[david.valencia1@alu.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Pablo Soto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Alarcos, Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jpsoto@mat.uson.mx]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Lilia García-Mundo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Alarcos, Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[liliacarmen.garcia@alu.uclm.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Alarcos, Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[mario.piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2190]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/055]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia el uso de sistemas de recomendación en sistemas de alta variabilidad</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-el-uso-de-sistemas-de-recomendacion-en-sistemas-de-alta-variabilidad/</link>
		<pubDate>Wed, 31 Aug 2016 22:21:13 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1888</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1888</post_id>
		<post_date><![CDATA[2016-09-01 00:21:13]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 22:21:13]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-el-uso-de-sistemas-de-recomendacion-en-sistemas-de-alta-variabilidad]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1889]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los sistemas de alta variabilidad son sistemas software cuyo comportamiento puede ser personalizado de acuerdo con las necesidades de un contexto particular. De hecho, existen sistemas de alta variabilidad que representan miles de productos. Por otra parte, en la industria encontramos los sistemas de recomendación, los cuales, permiten recomendar la serie de productos que mejor se adapten a un usuario o un contexto de uso particular. En este artículo de prospección exploramos el uso de sistemas de recomendación en el contexto de los sistemas de alta variabilidad. Asimismo, identificamos algunas tareas donde podrían ayudar a la gestión de los sistemas de variabilidad.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[feature models, recommender systems, variability-intensive systems, software product lines]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jorge L. Rodas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Milagro, Ecuador]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jrodass@unemi.edu.ec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Olivares]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Inria - Rennes, France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[javier.olivares@inria.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José A. Galindo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Inria - Rennes, France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jagalindog@inria.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[David Benavides]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[benavides@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Aplicando Scaffolding en el desarrollo de Líneas de Producto Software</title>
		<link>https://biblioteca.sistedes.es/articulo/aplicando-scaffolding-en-el-desarrollo-de-lineas-de-producto-software/</link>
		<pubDate>Wed, 31 Aug 2016 22:35:36 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1893</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1893</post_id>
		<post_date><![CDATA[2016-09-01 00:35:36]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 22:35:36]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[aplicando-scaffolding-en-el-desarrollo-de-lineas-de-producto-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1894]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las Líneas de Producto Software (LPS) constituyen una tecnología madura para producir software que ha sido objeto de una gran cantidad de investigación, por lo que existen numerosas técnicas, metodologías y herramientas para crearlas. Sin embargo, es complicado utilizar algunas de estas herramientas en la industria debido a factores como la rápida evolución que han tenido los entornos de desarrollo, lo que provoca que estas herramientas estén obsoletas, la falta de soporte para proyectos que utilizan diferentes lenguajes de desarrollo, o la dificultad en el mantenimiento del código de los productos generados por la LPS. Por otra parte, la popularidad de la técnica de scaffolding no ha parado de aumentar entre los desarrolladores de software desde que apareció hace unos años, a pesar de recurrir a alternativas poco valoradas en la academia tales como el uso de preprocesadores.

En este trabajo proponemos la utilización de la técnica de scaffolding para implementar una LPS, lo que nos permite superar algunas de las limitaciones clásicas de otras herramientas LPS.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ingeniería de líneas de producto software, scaffolding, arquitectura software de propósito general, gestión de la variabilidad, desarrollo de software orientado a características]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Nieves R. Brisaboa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de Datos, Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[brisaboa@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alejandro Cortiñas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de Datos, Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[alejandro.cortinas@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Miguel R. Luaces]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de Datos, Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[luaces@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[ Oscar Pedreira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de Datos, Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[opedreira@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/001]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Herramienta de Soporte a la Evaluación y Mejora de la Gestión de Planes de Emergencia</title>
		<link>https://biblioteca.sistedes.es/articulo/herramienta-de-soporte-a-la-evaluacion-y-mejora-de-la-gestion-de-planes-de-emergencia/</link>
		<pubDate>Thu, 01 Sep 2016 14:08:12 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1900</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1900</post_id>
		<post_date><![CDATA[2016-09-01 16:08:12]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 14:08:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[herramienta-de-soporte-a-la-evaluacion-y-mejora-de-la-gestion-de-planes-de-emergencia]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1901]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La gestión de planes de emergencia es un tema que compete a todas las organizaciones y a la comunidad en general. La falta de propuestas para evaluar un plan de emergencia, más allá de una simple auditoría, hace que los planificadores construyan planes de emergencia basándose en su propia formación y experiencia. A pesar de las regulaciones legales existentes sobre formato y contenido de los mismos, pensamos que la definición de un marco de referencia para evaluar su gestión, aumentará la capacidad de los planificadores de construir cada vez mejores planes. QuEP define un modelo de evaluación y mejora basado en niveles de madurez, respecto a la gestión que una organización hace de su plan de emergencia; cada nivel identifica principios, prácticas, cuestiones y técnicas. Una vez realizada la evaluación de la organización, se le sugieren las técnicas a seguir para mejorar el ciclo de vida de su plan de emergencia, aumentando así la calidad del mismo, y por tanto, mejorando la gestión de emergencias en la organización. En este artículo se presenta el desarrollo iterativo de una herramienta web de soporte al marco QuEP para la evaluación de la gestión de planes de emergencia, generando la estrategia de mejora a seguir como un conjunto de buenas prácticas organizadas por niveles y por actores.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Modelo de evaluación y mejora, Gestión de Planes de Emergencia, Marco QuEP, Herramienta de soporte]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana Gabriela Núñez Ávila]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[anunez@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mª Carmen Penadés Gramage	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mpenades@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José H. Canós Cerda	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jhcanos@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/054]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Smart Spaces: sistema de tecnoinclusión inteligente</title>
		<link>https://biblioteca.sistedes.es/articulo/smart-spaces-sistema-de-tecnoinclusion-inteligente/</link>
		<pubDate>Thu, 01 Sep 2016 14:12:49 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1903</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1903</post_id>
		<post_date><![CDATA[2016-09-01 16:12:49]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 14:12:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[smart-spaces-sistema-de-tecnoinclusion-inteligente]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El mundo se está transformando y la sociedad está cambiando gracias al uso de las nuevas tecnologías. En los últimos años las ciudades están evolucionando mejorando sus infraestructuras, su manera de gestionar los recursos, etc., y por consiguiente, facilitando y mejorando la vida de sus ciudadanos. Pero existe un sector de la sociedad que no está siendo muy considerado en esta evolución de las ciudades: las personas con diversidad funcional. Smart Spaces es una propuesta estratégica para la integración de personas con discapacidad en el área de movilidad mediante la combinación fundamentos tecnológicos de entornos inteligentes y el soporte a los servicios de voluntariado para la atención a la diversidad funcional en la Universidad de Extremadura. El objetivo principal de este proyecto es facilitar el acceso a la información que nos rodea a las personas con discapacidad mediante una plataforma Web y aplicación para dispositivos móviles con la que se pretende ayudar a las personas con discapacidad, mostrándoles la información que ellos requieren y en el formato apropiado. Haciendo uso de una estrategia colaborativa para la adquisición de puntos de interés y mostrando dichos puntos a través de una capa de Realidad Aumentada. Las personas con movilidad reducida podrán conocer si el establecimiento o punto de destino tiene plazas de aparcamiento adaptadas, podrán consultar su estado, podrán conocer la localización de las rampas de acceso, lavabos adaptados, ascensores, etc.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Smart Cities, Accesibilidad, Movilidad Reducida, Puntos de Interés, Realidad Aumentada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Enrique Moguel	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group. Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[enrique@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Carlos Preciado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group. Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jcpreciado@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Fernando Sánchez-Figueroa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group. Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fernando@unex.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group. Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juanher@unex.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1947]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/056]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Estudio del Soporte a la Variabilidad en la Nube en un entorno con Multitenencia: Plataforma GPaaS</title>
		<link>https://biblioteca.sistedes.es/articulo/estudio-del-soporte-a-la-variabilidad-en-la-nube-en-un-entorno-con-multitenencia-plataforma-gpaas/</link>
		<pubDate>Thu, 01 Sep 2016 14:37:11 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1906</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1906</post_id>
		<post_date><![CDATA[2016-09-01 16:37:11]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 14:37:11]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[estudio-del-soporte-a-la-variabilidad-en-la-nube-en-un-entorno-con-multitenencia-plataforma-gpaas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1907]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los requisitos de la sociedad actual y la nueva era de Internet de las Cosas (IoT), entre otros múltiples factores, explican el auge del “Software as a Service” (SaaS) y el paradigma de computación en la nube (Cloud Computing). La tendencia en el desarrollo software apunta hacia la producción de software cada vez más flexible, dinámico y personalizado, que a su vez, es accesible a través de Internet (off-premises), sin necesidad de ser instalado y gestionado localmente (on-premises). Una de las propiedades clave de Cloud Computing es la multitenancia: la instan-ciación de varias ocurrencias software a partir de una aplicación base o recursos compartidos. En este artículo se presenta: (i) un estudio de la multitenancia y el soporte a la variabilidad en la nube; y (ii) una experiencia de desarrollo SaaS cuyo objetivo es analizar la capacidad de la multitenancia para soportar la flexibilidad, adaptabilidad y variabilidad del software en la nube, así como sus limitaciones, con el fin identificar líneas de investigación futuras. En particular, el análisis se ha realizado utilizando la plataforma Cloud de Minsait (Indra) sobre Microsoft Azu-re en el laboratorio iSSF de la UPM.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Cloud Computing, Multitenancia, Variabilidad, Flexibilidad, Personalización Masiva, Adaptabilidad, Reconfiguración Dinámica]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Héctor Humanes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[CITSEM, Universidad Politecnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[h.humanes@alumnos.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Iván Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[CITSEM, Universidad Politecnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ivan.htemprano@alumnos.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jessica Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[CITSEM, Universidad Politecnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[yesica.diaz@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[ Jennifer Perez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[CITSEM, Universidad Politecnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jenifer.perez@eui.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Alfonso Ríos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Minsait, Indra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[ariosa@minsait.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[ Javier Gonzalez- Rodriguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Minsait, Indra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[jvgonzalez@minsait.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[ Jordi Paraire]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[jjparaire@minsait.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Minsait, Indra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/002]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evolución arquitectónica de servicios basada en modelos CVL con cardinalidad</title>
		<link>https://biblioteca.sistedes.es/articulo/evolucion-arquitectonica-de-servicios-basada-en-modelos-cvl-con-cardinalidad/</link>
		<pubDate>Thu, 01 Sep 2016 14:42:15 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1909</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1909</post_id>
		<post_date><![CDATA[2016-09-01 16:42:15]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 14:42:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evolucion-arquitectonica-de-servicios-basada-en-modelos-cvl-con-cardinalidad]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1910]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La computación en la nube se está convirtiendo en un mecanismo predominante para desplegar fácilmente aplicaciones con requisitos especiales, tales como el almacenamiento masivo compartido, o el equilibrado de carga. Esta funcionalidad se proporciona normalmente como servicios por las plataformas en la nube.
Un desarrollador puede mejorar tanto el despliegue de sus aplicaciones como la productividad siguiendo un enfoque multi-tenancy, donde diferentes variantes de la misma aplicación pueden adaptarse rápidamente a las necesidades de cada usuario (tenant). Sin embargo, gestionar la variabilidad inherente a las aplicaciones multi-tenant, con cientos de usuarios y miles de configuraciones arquitectónicas diferentes, puede llegar a ser una tarea intratable de abordar manualmente. En este artículo, se propone un enfoque de línea de producto software en el cual: (1) usamos modelos de variabilidad con cardinalidad para modelar cada tenant como una característica clonable, (2) automatizamos el proceso de evolución de las arquitecturas de aplicaciones multi-tenant, y (3) demostramos que la implementación de los procesos de evolución es correcta y eficiente para un número elevado de tenants en un tiempo razonable.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Cardinalidad, Evolución, Línea de Producto Arquitectónica, Variabilidad CVL]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Miguel Horcas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Andalucía Tech, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[horcas@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mónica Pinto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Andalucía Tech, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pinto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Andalucía Tech, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/003]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Measuring the quality of transformation alternatives in software architectures evolution</title>
		<link>https://biblioteca.sistedes.es/articulo/measuring-the-quality-of-transformation-alternatives-in-software-architectures-evolution/</link>
		<pubDate>Thu, 01 Sep 2016 14:48:57 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1912</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1912</post_id>
		<post_date><![CDATA[2016-09-01 16:48:57]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 14:48:57]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[measuring-the-quality-of-transformation-alternatives-in-software-architectures-evolution]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1913]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Many today's software systems need to be self-adapted at run-time. Model transformation is a good approach to adapt the component-based architecture of such software systems. However, existing model transformation processes focus on the functionalities of systems, giving less importance to the quality attributes. The goal of this study is to improve model transformation processes by also considering quality attributes in the generation and adaptation of component-based architectures (i.e., driving the selection among many alternative model transformations by software architecture metrics). Such metrics evaluate the qualities of an architecture, such as flexibility and modifiability. This paper provides some measures of quality for different transformation alternatives and an example in the ENIA software.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[component-based software architecture, conguration, architecture metrics, quality-driven transformation, model transformation]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Criado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[javi.criado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Silverio Martínez-Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[GESSI Research Group, Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[smartinez@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[David Ameller]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[GESSI Research Group, Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[dameller@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Luis Iribarne]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[luis.iribarne@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>El uso de modelos de características con atributos para pruebas en sistemas de alta variabilidad: primeros pasos</title>
		<link>https://biblioteca.sistedes.es/articulo/el-uso-de-modelos-de-caracteristicas-con-atributos-para-pruebas-en-sistemas-de-alta-variabilidad-primeros-pasos/</link>
		<pubDate>Thu, 01 Sep 2016 14:55:55 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1915</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1915</post_id>
		<post_date><![CDATA[2016-09-01 16:55:55]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 14:55:55]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[el-uso-de-modelos-de-caracteristicas-con-atributos-para-pruebas-en-sistemas-de-alta-variabilidad-primeros-pasos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los modelos de características con atributos representan todos los productos de una línea de productos junto con información adicional. En la literatura encontramos modelos representando miles de productos distintos. La selección de estos productos para hacer pruebas es un reto que se está estudiando en la literatura, en algunas de estas propuestas utilizan modelos de características con atributos para seleccionar este subconjunto de productos. Sin embargo no existe una guía de como utilizar los atributos para selección de casos de pruebas en distintos escenarios, con el objetivo de alimentar esa guía, nos proponemos buscar en la literatura la manera de caracterizar los modelos usados por otros investigadores con el objetivo de ayudar a modelar atributos en modelos de características para realizar las pruebas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Modelo de características, Atributos, Pruebas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Mariuxi Vinueza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad of Milagro, Ecuador]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mvinuezam@unemi.edu.ec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Jorge L. Rodas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad of Milagro, Ecuador]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrodass@unemi.edu.ec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José A. Galindo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[INRIA - Rennes, France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jagalindo@inria.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[David Benavides]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[benavides@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/006]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una herramienta de programación para usuarios finales de aplicaciones móviles basadas en datos abiertos</title>
		<link>https://biblioteca.sistedes.es/articulo/una-herramienta-de-programacion-para-usuarios-finales-de-aplicaciones-moviles-basadas-en-datos-abiertos/</link>
		<pubDate>Thu, 01 Sep 2016 15:08:27 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1919</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1919</post_id>
		<post_date><![CDATA[2016-09-01 17:08:27]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 15:08:27]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-herramienta-de-programacion-para-usuarios-finales-de-aplicaciones-moviles-basadas-en-datos-abiertos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1920]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Durante los últimos años los teléfonos inteligentes (smartphones) han experimentado un rápido crecimiento. De manera que, actualmente, los dispositivos móviles constituyen la opción más frecuente de acceso a internet. De hecho, casi se puede decir que existe una aplicación móvil para cada aspecto de nuestra vida tanto profesional como personal. Por otro lado, últimamente, impulsado por las políticas internacionales de transparencia, se han puesto a disposición pública un gran número de recursos de datos abiertos. Datos abiertos de turismo, de meteorología y geográficos, por citar algunos, se han puesto disponibles para su reutilización por parte de instituciones públicas de todos los niveles. Sin embargo, a pesar de las acciones realizadas para la generación de aplicaciones que exploten estas nuevas fuentes de datos, la gran mayoría está enfocada en datos de un solo dominio y, normalmente, en datos de un solo conjunto de datos. Por lo tanto, los usuarios finales se ven forzados a utilizar varias aplicaciones al mismo tiempo para poder satisfacer sus necesidades particulares. En este trabajo, proponemos una herramienta de desarrollo de aplicaciones por parte de usuarios finales para la creación de aplicaciones basadas en datos abiertos personalizadas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[End-User Development, Mobile Application Development, Open Data]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Roberto Rodríguez-Echeverría]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rre@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Eneas Macías]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[enmaciasm@alumnos.unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José M. Conejero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[chemacm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/049]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un Repositorio RDF para la Integración de Flujos de Datos de Analítica Web y Comercio Electrónico</title>
		<link>https://biblioteca.sistedes.es/articulo/un-repositorio-rdf-para-la-integracion-de-flujos-de-datos-de-analitica-web-y-comercio-electronico/</link>
		<pubDate>Thu, 01 Sep 2016 15:15:54 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1922</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1922</post_id>
		<post_date><![CDATA[2016-09-01 17:15:54]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 15:15:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-repositorio-rdf-para-la-integracion-de-flujos-de-datos-de-analitica-web-y-comercio-electronico]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1923]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La Analítica Web supone hoy en día una tarea ineludible para las empresas de comercio electrónico, ya que les permite analizar el comportamiento de sus clientes. El proyecto Europeo SME-Ecompass tiene como objetivo desarrollar herramientas avanzadas de análitica web accesibles para las PYMES. Con esta motivación, proponemos servicio de integración de datos basado en ontologías para recopilar, integrar y almacenar información de traza web procedente de distintas fuentes. Estas se consolidan en un Repositorio RDF diseñado para proporcionar
semántica común a los datos de análisis y dar servicio homogéneo a algoritmos de Minería de Datos. El servicio propuesto se ha validado mediante traza digital real (Google Analitics y Piwik) de 15 tiendas virtuales de diferentes sectores y países europeos (UK, España, Grecia y
Alemania) durante varios meses de actividad. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Integraciónn de datos, RDF, Ontologías, Análisis Web, Google Analytics]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Maria del Mar Roldán-García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mmar@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose García-Nieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jnieto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[ Jose F. Aldana-Montes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jfam@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/027]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>v-RDFCSA: Compresión e Indexación de Colecciones de Versiones RDF</title>
		<link>https://biblioteca.sistedes.es/articulo/v-rdfcsa-compresion-e-indexacion-de-colecciones-de-versiones-rdf/</link>
		<pubDate>Thu, 01 Sep 2016 15:29:43 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1926</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1926</post_id>
		<post_date><![CDATA[2016-09-01 17:29:43]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 15:29:43]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[v-rdfcsa-compresion-e-indexacion-de-colecciones-de-versiones-rdf]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1927]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento – NoComercial – CompartirIgual (by-nc-sa)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La compresión, la indexación y la consulta de colecciones RDF son tópicos emergentes en la conocida como Web de Datos. Sin embargo, las técnicas más relevantes en el estado del arte no van más allá de la visión estática de los datos y obvian el cómo estos archivos RDF evolucionan a lo largo del tiempo, generando múltiples versiones de la colección que precisan ser preservadas para su explotación en diferentes tipos de aplicaciones.

En este artículo presentamos una nueva solución para la compresión de archivos RDF. Nuestra propuesta, referida como v-RDFCSA, extiende el auto-índice RDFCSA con estructuras de bits que implementan la codificación de la información de versionado. De esta manera, conseguimos preservar los triples RDF en espacio comprimido y, sobre ellos, resolver tanto patrones SPARQL como operaciones temporales de consulta basadas en dichos patrones. Los experimentos realizados, sobre el benchmark BEAR, muestran que v-RDFCSA reduce los requisitos de almacenamiento entre 35 y 60 veces respecto al estado del arte y consigue más de un orden magnitud de ventaja en la resolución de consultas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Archivos RDF, Compresión, Consultas de versiones, RDFCSA]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana Cerdeira-Pena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de Datos, Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[acerdeira@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Antonio Fariña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de Datos, Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fari@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier D. Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Vienna University of Economics and Business (WU)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jfernand@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Miguel A. Martínez-Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[DataWeb Research, Universidad de Valladolid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[migumar2@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/028]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Compresión de Big Semantic Data basada en HDT y MapReduce</title>
		<link>https://biblioteca.sistedes.es/articulo/compresion-de-big-semantic-data-basada-en-hdt-y-mapreduce/</link>
		<pubDate>Thu, 01 Sep 2016 16:00:40 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1931</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1931</post_id>
		<post_date><![CDATA[2016-09-01 18:00:40]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 16:00:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[compresion-de-big-semantic-data-basada-en-hdt-y-mapreduce]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1932]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[HDT es un formato binario diseñado para la serialización de grandes colecciones RDF que surgió con el objetivo de reducir los requisitos de almacenamiento que presentaban otros formatos RDF. Además de su capacidad para la compresión, la estructura interna de los ficheros HDT permite acceder a los datos comprimidos y, con ello, resolver algunas consultas interés en el ámbito de la Web Semántica. Existen diferentes aplicaciones basadas en HDT, como la exitosa Linked Data Fragments, que sacan provecha de sus particularidades para propósitos de publicación intercambio y consumo de colecciones RDF. Sin embargo, la obtención de estas representaciones está gravada por un proceso de compresión que resulta muy exigente en el consumo de memoria principal. Este hecho, limita la adopción de HDT en aplicaciones basadas en la explotación de Big Semantic Data.  En este artículo presentamos HDT-MR, una revisión del algoritmo de construcción de HDT basada en tecnología MapReduce. Esta nueva propuesta plantea configuraciones optimizadas de jobs MapReduce que permiten i) identificar los vocabularios de URIs y literales, necesarios para la construcción del diccionario HDT y ii) codificar los triples utilizando los diccionarios ya comprimidos. Nuestra experimentación muestra que el rendimiento de HDT-MR es lineal con el volumen de los datos de la entrada y que el despliegue actual, realizado sobre un cluster Hadoop, es capaz de serializar colecciones RDF que contienen miles de millones de triples.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Web Semántica, Compresión, RDF, HDT, MapReduce, Hadoop]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José M. Giménez-García	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Univ Lyon, UJM-Saint-Etienne, CNRS, Laboratoire Hubert Curien, France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jose.gimenez.garcia@univ-st-etienne.fr	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier D.	Fernández	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Institute for Information Business Vienna University of Economics and Business (WU), Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jfernand@wu.ac.at	 ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Miguel A.	Martinez-Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DataWeb Research, Department of Computer Science, University of Valladolid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[migumar2@infor.uva.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/029]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Arquitectura software basada en tecnologías Smart para agricultura de precisión</title>
		<link>https://biblioteca.sistedes.es/articulo/arquitectura-software-basada-en-tecnologias-smart-para-agricultura-de-precision/</link>
		<pubDate>Thu, 01 Sep 2016 16:12:36 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1934</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1934</post_id>
		<post_date><![CDATA[2016-09-01 18:12:36]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 16:12:36]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[arquitectura-software-basada-en-tecnologias-smart-para-agricultura-de-precision]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1935]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo describe la arquitectura de un sistema de información en el contexto de la agricultura de precisión. Una red de sensores instalados sobre las zonas de cultivo se encarga de monitorizar las variables que finalmente alimentan el modelo de riego y fertilización implementado. Las mediciones obtenidas se almacenan de manera autónoma y continua sobre una base de datos MongoDB, cuyo diseño prevé la variabilidad espacio-temporal de los diversos componentes de la aplicación (zonas, cultivos, sectores de irrigación, etc.). Datos obtenidos de otras fuentes, tales como servicios meteorológicos o análisis de suelo completan el modelo, cuyo objetivo final es el de mejorar la eficiencia en la gestión de la explotación agraria. Los procesos que combinan toda esta información y ponen en marcha el modelo se implantan mediante el uso del framework de edición de flujos Node-RED, con el desarrollo de flujos de datos para establecer la conexión con la red de sensores y servicios meteorológicos y proveer de datos al sistema, consiguiendo al integrar estas tecnologías una infraestructura digital para la explotación rentable de recursos agrarios.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Agricultura de Precisión, Modelo de riego, Flujo de Datos, MongoDB]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mscabrera@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Manuel Barrena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[barrena@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pablo Bustos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Tecnología de Computadores y de las Comunicaciones, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pbustos@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Carlos Campillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Centro de Investigaciones Científicas y Tecnológicas de Extremadura (CICYTEX)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[carlos.campillo@gobex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Pablo García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[pablogr@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/030]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>TINTIN: comprobación incremental de aserciones SQL</title>
		<link>https://biblioteca.sistedes.es/articulo/tintin-comprobacion-incremental-de-aserciones-sql/</link>
		<pubDate>Thu, 01 Sep 2016 16:17:11 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1937</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1937</post_id>
		<post_date><![CDATA[2016-09-01 18:17:11]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 16:17:11]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[tintin-comprobacion-incremental-de-aserciones-sql]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1938]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Ninguno de los SGBD más populares del momento implementa aserciones SQL, obligando así a implementar manualmente su comprobación. Por ello, presentamos TINTIN: una aplicación que genera automáticamente el código SQL para comprobar aserciones. Dicho código captura las tuplas insertadas/borradas en una transacción, comprueba que ninguna de ellas viole ninguna aserción mediante consultas SQL, y materializa los cambios en caso que sean satisfechas. La eficiencia del código se basa en la comprobación incremental de las aserciones.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[aserción, restricción de integridad, comprobación incremental, SQL]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Xavier Oriol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[xoriol@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ernest Teniente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ernest.teniente@upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Guillem Rull]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[grull@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/036]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>RecSim: Hacia la Evaluación de Sistemas de Recomendación Utilizando un Simulador</title>
		<link>https://biblioteca.sistedes.es/articulo/recsim-hacia-la-evaluacion-de-sistemas-de-recomendacion-utilizando-un-simulador/</link>
		<pubDate>Thu, 01 Sep 2016 16:22:57 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1940</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1940</post_id>
		<post_date><![CDATA[2016-09-01 18:22:57]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 16:22:57]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[recsim-hacia-la-evaluacion-de-sistemas-de-recomendacion-utilizando-un-simulador]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1941]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los sistemas de recomendación ofrecen recomendaciones personalizadas a usuarios acerca de ítems de distinto tipo (películas, libros, restaurantes, hoteles, lugares a visitar, etc.), aliviando así la sobrecarga de datos que estos experimentan cuando tienen que tomar decisiones al elegir entre diversas alternativas. Debido a su interés tanto para usuarios finales como para empresas, este tipo de sistemas han atraído una intensa actividad investigadora. En concreto, en los últimos años ha crecido el interés por los sistemas de recomendación dependientes del contexto y por su aplicación en escenarios de computación móvil.

Sin embargo, existen dificultades para evaluar las propuestas existentes debido a la carencia de conjuntos de datos apropiados para evaluación. En este artículo motivamos el interés de evaluar sistemas de recomendación mediante la realización de simulaciones para recoger datos y opiniones de usuarios reales. Asimismo, describimos las ideas principales detrás de la herramienta RecSim que hemos desarrollado.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Sistemas de recomendación, Simulación, Computación Móvil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Sergio Ilarri	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[silarri@unizar.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Slavcho Ivanov]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[619885@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/032]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>WikInfoboxer: A Tool to Create Wikipedia Infoboxes Using DBpedia</title>
		<link>https://biblioteca.sistedes.es/articulo/wikinfoboxer-a-tool-to-create-wikipedia-infoboxes-using-dbpedia/</link>
		<pubDate>Thu, 01 Sep 2016 16:27:38 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1943</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1943</post_id>
		<post_date><![CDATA[2016-09-01 18:27:38]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 16:27:38]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[wikinfoboxer-a-tool-to-create-wikipedia-infoboxes-using-dbpedia]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1944]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Wikipedia infoboxes present a summary, in a semistructured format, of the articles they are associated to. Therefore, they have become the main information source used by projects to leverage the knowledge in Wikipedia, such as DBpedia. However, creating quality infoboxes is complicated as current mechanisms are based on simple templates which, for example, do not check whether the information provided is semantically correct.

In this paper, we present WikInfoboxer, a tool to help Wikipedia editors to create rich and accurate infoboxes. WikInfoboxer computes attributes that might be interesting for an article and suggests possible values for them after analyzing similar articles from DBpedia. To make the process easier for editors, WikInfoboxer presents this information in a friendly user interface.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Infobox, Wikipedia, DBpedia, Semantic Web]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ismael Rodríguez-Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ismaro.394@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Raquel Trillo-Lado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[raqueltl@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Roberto Yus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ryus@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/037]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Aproximación a la búsqueda basada en términos sobre conjuntos de datos medioambientales</title>
		<link>https://biblioteca.sistedes.es/articulo/aproximacion-a-la-busqueda-basada-en-terminos-sobre-conjuntos-de-datos-medioambientales/</link>
		<pubDate>Mon, 05 Sep 2016 15:19:11 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1973</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1973</post_id>
		<post_date><![CDATA[2016-09-05 17:19:11]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 15:19:11]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[aproximacion-a-la-busqueda-basada-en-terminos-sobre-conjuntos-de-datos-medioambientales]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1974]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este artículo se discuten los trabajos, actualmente en curso, de diseño e implementación de un sistema de búsqueda por términos sobre fuentes de datos medioambientales, entre las que se incluyen fuentes de entidades geográficas y arrays que almacenan la variación espacio-temporal de distintas variables geo-físicas. Este tipo de sistemas facilitan el descubrimiento y el acceso a fuentes de datos de naturaleza científica a usuarios no expertos, que pueden utilizarlas en aplicaciones de muy diverso tipo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Búsqueda basada en términos, Datos Medioambientales, Recuperación de Información]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Álvarez-Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[david.alvarez.castro@rai.usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José R.R. Viqueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrr.viqueira@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alberto Bugarín]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[alberto.bugarin.diz@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/033]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Federated Approach for Array and Entity Environmental Linked Data</title>
		<link>https://biblioteca.sistedes.es/articulo/a-federated-approach-for-array-and-entity-environmental-linked-data/</link>
		<pubDate>Mon, 05 Sep 2016 15:24:54 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1976</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1976</post_id>
		<post_date><![CDATA[2016-09-05 17:24:54]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 15:24:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-federated-approach-for-array-and-entity-environmental-linked-data]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1977]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Available environmental and spatial data is increasing in size and every time new application domains take advantage of this fact. The need for accessing them through linked data paradigm is also increased, due to the interest of their combination with already available linked data repositories. Entity based environmental data fits perfectly to the graph data model of RDF, however, much environmental data are array-based, and such data are clearly not efficiently represented with RDF. In fact, transforming array environmental data to RDF triples in some datasets will generate huge RDF datasets. Querying these datasets through SPARQL will lead to low performance solutions. In this paper, we propose a federated architecture that integrates entity and array-based repositories into a single SPARQL-based framework, where SPARQL queries are translated into SQL and array-based queries. New operations will be added to SPARQL algebra in order to embed those relational and array-based queries into SPARQL query plans. This will make SPARQL able to access two different database paradigms (entity and array) in one query to answer questions like “What is the predicted average of temperature of each municipality of Spain for the next week?”]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Linked Data, Geospatial and environmental data, GeoSPARQL, SPARQL Query Processing]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Shahed Bassam Almobydeen]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CITIUS). Universidade de Santiago de Compostela ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[shahed.almobydeen@rai.usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José R.R. Viqueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CITIUS). Universidade de Santiago de Compostela ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrr.viqueira@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Lama Penín]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CITIUS). Universidade de Santiago de Compostela ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuel.lama@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/034]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Procesamiento paralelo de datos medioambientales con Apache Spark</title>
		<link>https://biblioteca.sistedes.es/articulo/procesamiento-paralelo-de-datos-medioambientales-con-apache-spark/</link>
		<pubDate>Mon, 05 Sep 2016 15:30:10 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1979</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1979</post_id>
		<post_date><![CDATA[2016-09-05 17:30:10]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 15:30:10]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[procesamiento-paralelo-de-datos-medioambientales-con-apache-spark]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En la actualidad existen enormes volúmenes de datos de tipo medioambiental que son resultado o bien de campañas de recolección de datos de campo en las que se involucran muchos expertos o bien del procesamiento de datos generados por dispositivos de sensorización. En general, los primeros se modelan y gestionan con tecnologías de bases de datos, mientras que los segundos pueden requerir de formatos de array de tipo científico más específicos. El procesamiento declarativo de cualquiera de los tipos de datos está resuelto, con tecnologías de almacenes de datos tradicionales o con bases de datos de arrays. Sin embargo el procesamiento declarativo integrado de ambos tipos de dato todavía demanda soluciones ad-hoc. En este artículo se proporciona una descripción breve de los primeros pasos hacia la implementación de un sistema de procesamiento paralelo integrado de datos relacionales y de arrrays.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Big Data, Environmental Data, OLAP, Spark]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Diego Ferrón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnoloxías da Información (CITIUS). Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[diego.ferron@rai.usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sebastián Villarroya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnoloxías da Información (CITIUS). Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sebastian.villarroya@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José R.R. Viqueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnoloxías da Información (CITIUS). Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jrr.viqueira@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Tomás F. Pena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnoloxías da Información (CITIUS). Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[tf.pena@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/035]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Distance Range Queries in SpatialHadoop</title>
		<link>https://biblioteca.sistedes.es/articulo/distance-range-queries-in-spatialhadoop/</link>
		<pubDate>Mon, 05 Sep 2016 16:24:51 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1982</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1982</post_id>
		<post_date><![CDATA[2016-09-05 18:24:51]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 16:24:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[distance-range-queries-in-spatialhadoop]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1983]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Efficient processing of Distance Range Queries (DRQs) is of great importance in spatial databases due to the wide area of applications. This type of spatial query is characterized by a distance range over one or two datasets. The most representative and known DRQs are the eDistance Range Query (eDRQ) and the eDistance Range Join Query (eDRJQ). Given the increasing volume of spatial data, it is difficult to perform a DRQ on a centralized machine efficiently. Moreover, the eDRJQ is an expensive spatial operation, since it can be considered a combination of the eDR and the spatial join queries. For this reason, this paper addresses the problem of computing DRQs on big spatial datasets in SpatialHadoop, an extension of Hadoop that supports spatial operations efficiently, and proposes new algorithms in SpatialHadoop to perform efficient parallel DRQs on large-scale spatial datasets. We have evaluated the performance of the proposed algorithms in several situations with big synthetic and real-world datasets. The experiments have demonstrated the efficiency (in terms of total execution time and number of distance computations) and scalability (in terms of epsilon values, sizes of datasets and number of computing nodes) of our proposal.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Distance Range Queries, Distance Join, Spatial Data, Processing SpatialHadoop, MapReduce]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Corral	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dept. of Informatics, University of Almeria, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[acorral@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francisco	 García-García		]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dept. of Informatics, University of Almeria, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[paco.garcia@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Luis	Iribarne	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dept. of Informatics, University of Almeria, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[liribarn@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Michael Vassilakopoulos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dept. of Electrical and Computer Engineering, University of Thessaly, Volos, Greece]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mvasilako@uth.gr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/031]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Providing Support for the Optimized Management of Declarative Processes</title>
		<link>https://biblioteca.sistedes.es/articulo/providing-support-for-the-optimized-management-of-declarative-processes/</link>
		<pubDate>Mon, 05 Sep 2016 16:49:08 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1985</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1985</post_id>
		<post_date><![CDATA[2016-09-05 18:49:08]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 16:49:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[providing-support-for-the-optimized-management-of-declarative-processes]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1986]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Declarative process models are becoming increasingly popular due to the high flexibility they offer to process participants. Based on a declarative process model, there exist numerous possible enactment plans, each one with specific values for relevant objective functions (e.g., overall completion time). How to actually execute such a model is quite challenging due to several reasons: (1) proper objective functions must be considered to find optimized enactment plans, (2) users often do not have an understanding of the overall process, (3) the presence of a variety of temporal constraints to be met during process enactment, and (4) the need to coordinate multiple instances of a process concurrently exe- cuted (which compete for shared resources). This is further complicated by the fact that the enactment of new process instances may continuously start over time and many organizations do not exactly know their future demands. In such con- text, to properly support users in enacting declarative process models, this paper suggests generating optimized enactment plans from declarative process models. The generated enactment plans may be used for different purposes, e.g., to pro- vide personal schedules to users. Moreover, they may be dynamically adapted if required. To evaluate the applicability of our approach in practical settings we apply it to a real process scenario from the healthcare domain. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Process flexibility, declarative process model, temporal constraints, constraint programming, scheduling, healthcare processes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Irene Barba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[irenebr@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Andreas Lanz ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Institute of Databases and Information Systems, Ulm University, Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[andreas.lanz@uni-ulm.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Andrés Jiménez Ramírez	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ajramirez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Barbara Weber]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science, University of Innsbruck, Austria, Technical University of Denmark, Denmark]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[bweb@dtu.dk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Manfred	Reichert]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Institute of Databases and Information Systems, Ulm University, Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[manfred.reichert@uni-ulm.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Carmelo Del Valle	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[carmelo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/044]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Prueba de Mutación Evolutiva Aplicada a Sistemas Orientados a Objetos</title>
		<link>https://biblioteca.sistedes.es/articulo/prueba-de-mutacion-evolutiva-aplicada-a-sistemas-orientados-a-objetos/</link>
		<pubDate>Mon, 05 Sep 2016 17:00:06 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1988</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1988</post_id>
		<post_date><![CDATA[2016-09-05 19:00:06]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 17:00:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[prueba-de-mutacion-evolutiva-aplicada-a-sistemas-orientados-a-objetos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1989]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A pesar del beneficio que puede reportar la prueba de mutaciones en el proceso de prueba de software, el coste que supone su aplicación siempre ha sido visto como un obstáculo para una mayor acogida por parte de la industria. Por esta razón se han desarrollado diversas técnicas que tratan de paliar el problema, principalmente mediante la reducción del número de mutantes que son generados. Entre ellas se encuentra la Prueba de Mutación Evolutiva, que propone el empleo de algoritmos evolutivos para encontrar un subconjunto de mutantes que presenta mayor posibilidad de ayudar a refinar el conjunto de casos de prueba empleado. La técnica solo había sido probada con éxito en operadores para el lenguaje de programación WS-BPEL. En este artículo se presentan los experimentos llevados a cabo aplicando la Prueba de Mutación Evolutiva con mutantes generados por operadores de mutación para C++ relacionados con la orientación a objetos. Los resultados obtenidos, usando los parámetros considerados como más apropiados para la configuración del algoritmo, revelan que la técnica también es más efectiva que una estrategia aleatoria con operadores de clase para sistemas en C++.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Prueba de software, Prueba de mutaciones, Algoritmos evolutivos, C++, Orientación a objetos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Delgado-Pérez	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pedro.delgado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sergio Segura	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Garcia-Dominguez	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science, University of York, United Kingdom]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[antonio.garcia-dominguez@york.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Juan José	Domínguez-Jiménez	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[juanjose.dominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/038]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Flujo de trabajo para la experimentación colaborativa en Ingeniería del Software guiada por búsqueda</title>
		<link>https://biblioteca.sistedes.es/articulo/flujo-de-trabajo-para-la-experimentacion-colaborativa-en-ingenieria-del-software-guiada-por-busqueda/</link>
		<pubDate>Mon, 05 Sep 2016 17:59:21 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1991</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1991</post_id>
		<post_date><![CDATA[2016-09-05 19:59:21]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 17:59:21]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[flujo-de-trabajo-para-la-experimentacion-colaborativa-en-ingenieria-del-software-guiada-por-busqueda]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Isabel María del Águila]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad of Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[imaguila@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José del Sagrado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad of Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jsagrado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alfonso Bosch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad of Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[abosch@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/039]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2330]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La Ingeniería del Software Guiada por Búsqueda persigue reformular problemas de Ingeniería del Software que a menudo comprenden objetivos en conﬂicto, como problemas de optimización. Así, las técnicas que se aplican en esta disciplina buscan una o un conjunto de soluciones casi-óptimas en un espacio de soluciones candidatas con la ayuda de una función de aptitud que les permita distinguir las mejores soluciones. La naturaleza estocástica de los algoritmos de optimización requiere de la repetición de las búsquedas para mitigar los efectos de la aleatoriedad. A la hora de comparar algoritmos, el investigador comparará los resultados con mejor calidad (mejores valores en la función de aptitud, en indicadores de calidad y rendimiento) devueltos en las búsquedas, lo que conlleva un trabajo adicional por parte del investigador. La sobrecarga que implica esta actividad puede aminorarse si la experimentación se enfoca de manera colaborativa. Este artículo propone un ﬂujo de trabajo para la experimentación colaborativa basado en resultados e indicadores de calidad y rendimiento.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[metaheurísticas, experimentación cooperativa, indicadores de calidad]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Configuración guiada por búsqueda de aplicaciones basadas en micro-servicios</title>
		<link>https://biblioteca.sistedes.es/articulo/configuracion-guiada-por-busqueda-de-aplicaciones-basadas-en-micro-servicios/</link>
		<pubDate>Mon, 05 Sep 2016 18:14:49 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1993</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1993</post_id>
		<post_date><![CDATA[2016-09-05 20:14:49]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 18:14:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[configuracion-guiada-por-busqueda-de-aplicaciones-basadas-en-micro-servicios]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1994]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Organizaciones como Netflix, Google o Amazon hacen uso de arquitecturas basadas en micro-servicios, lo que ha disparado el interés de la comunidad en ingeniería del software por este estilo arquitectónico, en el que los distintos módulos de la aplicación se implementan como servicios web RESTful independientes. De esta forma, se alcanza un nivel de modularidad que facilita el control del re-despliegue en únicamente aquellas partes que soportan mayor carga de trabajo y, consecuentemente, evitan el uso indiscriminado de la infraestructura. Todos estos servicios, además, se coordinan e invocan orquestando las interacciones necesarias para satisfacer los requisitos del sistema. No obstante, el buen uso de este estilo arquitectónico supone nuevos retos, como determinar qué instancias de servicios se despliegan o establecer la mejor configuración de la nube que los aloja, conforme a la carga esperada y para cumplir los Acuerdos de Nivel de Servicio. Se trata de un problema de optimización en el que deben considerarse simultáneamente múltiples propiedades, a menudo en conflicto entre sí. Por ello, tras formular este caso como un problema de búsqueda, se discutirá cómo el uso de técnicas multi-objetivo puede mejorar las soluciones actuales, permitiéndonos escoger los proveedores y configuraciones apropiadas para dismuir los costes de explotación, asegurar la disponibilidad de los servicios críticos, sin empobrecer la latencia y el tiempo de respuesta.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[micro-services, optimización multi-objetivo, cloud computing, Acuerdos de Nivel de Servicio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Antonio Parejo Maestre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[japarejo@us.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Aurora Ramírez	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico, Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[aramirez@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José Raúl	Romero	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico, Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Sergio Segura	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/045]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Minimización de conjuntos de casos de prueba en la prueba de mutaciones de composiciones BPEL</title>
		<link>https://biblioteca.sistedes.es/articulo/minimizacion-de-conjuntos-de-casos-de-prueba-en-la-prueba-de-mutaciones-de-composiciones-bpel/</link>
		<pubDate>Mon, 05 Sep 2016 18:19:03 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1996</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1996</post_id>
		<post_date><![CDATA[2016-09-05 20:19:03]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 18:19:03]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[minimizacion-de-conjuntos-de-casos-de-prueba-en-la-prueba-de-mutaciones-de-composiciones-bpel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1997]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Tanto en la aplicación de prueba de mutaciones a composiciones BPEL como en la realización de estudios experimentales sobre diversas métricas de calidad, surge la necesidad de minimizar conjuntos de casos de prueba manteniendo la máxima cobertura de mutación. La prueba de este tipo de software presenta algunas peculiaridades. Normalmente, las composiciones son relativamente pequeñas cuando se comparan con aplicaciones desarrolladas en lenguajes
tradicionales, pues se encargan exclusivamente de la orquestación de los servicios, y no se dispone de un gran número de casos de prueba para ellas. No obstante, su ejecución puede resultar muy costosa, y debe realizarse para un número de mutantes que, normalmente, supera ampliamente al de casos de prueba. Proponemos aquí como técnica de minimización una reducción a programación lineal entera y evaluamos su rendimiento para distintas
composiciones.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Minimización de conjuntos de casos de prueba, Programación lineal entera, Prueba de mutaciones, Composiciones BPEL]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco	Palomo-Lozano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[francisco.palomo@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonia Estero-Botaro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[antonia.estero@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/046]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un algoritmo híbrido para el problema NRP con interdependencias</title>
		<link>https://biblioteca.sistedes.es/articulo/un-algoritmo-hibrido-para-el-problema-nrp-con-interdependencias/</link>
		<pubDate>Mon, 05 Sep 2016 18:23:31 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1999</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1999</post_id>
		<post_date><![CDATA[2016-09-05 20:23:31]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 18:23:31]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-algoritmo-hibrido-para-el-problema-nrp-con-interdependencias]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2000]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este artículo presentamos un algoritmo híbrido para una variante del problema de la siguiente versión (NRP). En esta variante existe un conjunto de requisitos para los que se dispone de una estimación del esfuerzo necesario para su implementación y de la satisfacción
percibida por los potenciales clientes con la inclusión de dichos requisitos. Entre estos requisitos existen relaciones de interdependencia, que establecen a ciertos requisitos como prerequisitos de otros, o que obligan a implementar determinados requisitos simultáneamente en caso
de incluirse alguno de ellos en la siguiente versión del producto a desarrollar. Dado un límite superior de esfuerzo prefijado, el objetivo es seleccionar un subconjunto de requisitos que cumpla todas las restricciones y maximice la satisfacción global de los clientes. La propuesta combina heurísticas con técnicas exactas para una versión simplificada del problema. El rendimiento del algoritmo resultante en distintos escenarios realistas se compara con el de otras técnicas metaheurísticas previamente empleadas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Técnicas metaheurísticas, Ingeniería de requisitos, Problema de la siguiente versión, Interdependencias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco	 Palomo-Lozano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[francisco.palomo@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Isabel María del Águila]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[imaguila@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/040]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Dos estrategias de búsqueda anytime basadas en programación lineal entera para resolver el problema de selección de requisitos</title>
		<link>https://biblioteca.sistedes.es/articulo/dos-estrategias-de-busqueda-anytime-basadas-en-programacion-lineal-entera-para-resolver-el-problema-de-seleccion-de-requisitos/</link>
		<pubDate>Mon, 05 Sep 2016 18:29:40 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2002</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2002</post_id>
		<post_date><![CDATA[2016-09-05 20:29:40]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 18:29:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[dos-estrategias-de-busqueda-anytime-basadas-en-programacion-lineal-entera-para-resolver-el-problema-de-seleccion-de-requisitos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2003]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El problema de selección de requisitos (o Next Release Problem, NRP) consiste en seleccionar el subconjunto de requisitos que se va a desarrollar en la siguiente versión de una aplicación software. Esta selección se debe hacer de tal forma que maximice la satisfacción de las partes interesadas a la vez que se minimiza el esfuerzo empleado en el desarrollo y se cumplen un conjunto de restricciones. Trabajos recientes han abordado la formulación bi-objetivo de este problema usando técnicas exactas basadas en resolutores SAT y resolutores de programación lineal entera. Ambos se enfrentan a dificultades cuando las instancias tienen un gran tamaño, sin embargo la programación lineal entera (ILP) parece ser más efectiva que los resolutores SAT. En la práctica, no es necesario calcular todas las soluciones del frente de Pareto (que pueden llegar a ser muchas) y basta con obtener un buen número de soluciones eficientes bien distribuidas en el espacio objetivo. Las estrategias de búsqueda basadas en ILP que se han utilizado en el pasado para encontrar un frente bien distribuido en cualquier instante de tiempo solo buscan soluciones soportadas. En este trabajo proponemos dos estrategias basadas en ILP que son capaces de encontrar el frente completo con suficiente tiempo y que, además, tienen la propiedad de aportar un conjunto de soluciones bien distribuido en el frente objetivo en cualquier momento de la búsqueda.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[problema de selección de requisitos, programación lineal entera, optimización multi-objetivo, optimización combinatoria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco  Chicano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Andalucía Tech]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[chicano@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miguel Ángel	Domínguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Andalucía Tech]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[miguel.angel.dominguez.rios@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Isabel María del Águila	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[imaguila@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José	Del Sagrado	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jsagrado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Enrique Alba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Andalucía Tech]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[eat@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/041]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Aplicando programación lineal entera a la búsqueda de conjuntos de productos de prueba priorizados para líneas de productos software</title>
		<link>https://biblioteca.sistedes.es/articulo/aplicando-programacion-lineal-entera-a-la-busqueda-de-conjuntos-de-productos-de-prueba-priorizados-para-lineas-de-productos-software/</link>
		<pubDate>Mon, 05 Sep 2016 18:34:37 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2005</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2005</post_id>
		<post_date><![CDATA[2016-09-05 20:34:37]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 18:34:37]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[aplicando-programacion-lineal-entera-a-la-busqueda-de-conjuntos-de-productos-de-prueba-priorizados-para-lineas-de-productos-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2006]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las líneas de productos software son familias de productos que están íntimamente relacionados entre sí, normalmente formados por combinaciones de un conjunto de características software. Generalmente no es factible testar todos los productos de la familia, ya que el número de productos es muy elevado debido a la explosión combinatoria de características. Por este motivo, se han propuesto criterios de cobertura que pretenden probar al menos todas las interacciones entre características sin necesidad de probar todos los productos, por ejemplo todos los pares de características (emph{pairwise coverage}). Además, es deseable testar primero los productos compuestos por un conjunto de características prioritarias. Este problema es conocido como emph{Prioritized Pairwise Test Data Generation}. En este trabajo proponemos una técnica basada en programación lineal entera para generar este conjunto de pruebas priorizado. Nuestro estudio revela que la propuesta basada en programación lineal entera consigue mejores resultados estadísticamente tanto en calidad como en tiempo de computación con respecto a las técnicas existentes para este problema.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Líneas de productos software, Pruebas de software, Programación lineal entera, Optimización multi-objetivo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Ferrer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ferrer@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francisco	 Chicano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[chicano@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Roberto Erick Lopez-Herrejon]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Systems Engineering and Automation, Johannes Kepler University, Linz, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[roberto.lopezherrejon@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Enrique Alba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[eat@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/042]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Estudio de mecanismos de hibridación para el descubrimiento evolutivo de arquitecturas</title>
		<link>https://biblioteca.sistedes.es/articulo/estudio-de-mecanismos-de-hibridacion-para-el-descubrimiento-evolutivo-de-arquitecturas/</link>
		<pubDate>Mon, 05 Sep 2016 18:41:27 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2008</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2008</post_id>
		<post_date><![CDATA[2016-09-05 20:41:27]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 18:41:27]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[estudio-de-mecanismos-de-hibridacion-para-el-descubrimiento-evolutivo-de-arquitecturas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2009]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las decisiones que los ingenieros software toman durante el análisis arquitectónico pueden verse influenciadas por aspectos como la naturaleza del sistema bajo estudio o los criterios de calidad que deben guiar su desarrollo, generalmente expresados en términos de métricas software. A la hora de abordar tareas de diseño arquitectónico como problemas de optimización, factores como los anteriores también deben ser tenidos en cuenta, ya que podrían afectar al funcionamiento de cualquier algoritmo de búsqueda. Incluir técnicas de búsqueda local en un algoritmo evolutivo constituye un mecanismo habitual para intentar mejorar su rendimiento, si bien diseñar un modelo híbrido añade nuevas variables a ser estudiadas. En este trabajo se analiza la idoneidad de este tipo de enfoque para la resolución del problema del descubrimiento de arquitecturas software. El estudio experimental realizado muestra que las características del problema pueden influir tanto en la eficiencia de la búsqueda local como en la calidad de las soluciones obtenidas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Ingeniería del software basada en búsqueda, Arquitecturas software, Algoritmos evolutivos, Búsqueda local]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aurora Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico. Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aramirez@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Antonio Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico. Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[i12momej@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José Raúl	Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico. Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Sebastián Ventura	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico. Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sventura@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/043]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>BPMS-Game: Herramienta para la Gamificación de Procesos de Negocio</title>
		<link>https://biblioteca.sistedes.es/articulo/bpms-game-herramienta-para-la-gamificacion-de-procesos-de-negocio/</link>
		<pubDate>Tue, 06 Sep 2016 11:58:39 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2015</guid>
		<description></description>
		<content><![CDATA[En los últimos años, el paradigma BPM está teniendo una repercusión significativa en las organizaciones a la hora de dar soporte a la mejora continua de sus procesos de negocio. Uno de los aspectos que puede promover un mejor desempeño de dichos procesos es el factor humano, por lo que es de gran importancia mejorar la motivación de los usuarios para la realización de las tareas que tienen encomendadas. En este contexto, resulta de interés el área de “Gamificación”, que está muy presente en muchos aspectos la sociedad actual, con el objetivo de mejorar la participación y el compromiso de un usuario para la realización de sus tareas aplicando mecanismos de juegos. La gamificación puede ser por tanto un mecanismo adecuado para su aplicación en los procesos de las organizaciones para mejorar la motivación y el rendimiento de los usuarios involucrados. Por todo ello, en el presente artículo se describe la herramienta BPMS-Game, que da soporte a la aplicación de gamificación en sistemas BPMS. La utilidad potencial de la herramienta se ilustra con un caso de ejemplo.]]></content>
		<excerpt><![CDATA[Procesos de Negocio, Gamificación, BPMS]]></excerpt>
		<post_id>2015</post_id>
		<post_date><![CDATA[2016-09-06 13:58:39]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 11:58:39]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[bpms-game-herramienta-para-la-gamificacion-de-procesos-de-negocio]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="bpms"><![CDATA[BPMS]]></category>
		<category domain="post_tag" nicename="gamificacion"><![CDATA[gamificación]]></category>
		<category domain="post_tag" nicename="procesos-de-negocio"><![CDATA[Procesos de Negocio]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2025]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años, el paradigma BPM está teniendo una repercusión significativa en las organizaciones a la hora de dar soporte a la mejora continua de sus procesos de negocio. Uno de los aspectos que puede promover un mejor desempeño de dichos procesos es el factor humano, por lo que es de gran importancia mejorar la motivación de los usuarios para la realización de las tareas que tienen encomendadas. En este contexto, resulta de interés el área de “Gamificación”, que está muy presente en muchos aspectos la sociedad actual, con el objetivo de mejorar la participación y el compromiso de un usuario para la realización de sus tareas aplicando mecanismos de juegos. La gamificación puede ser por tanto un mecanismo adecuado para su aplicación en los procesos de las organizaciones para mejorar la motivación y el rendimiento de los usuarios involucrados. Por todo ello, en el presente artículo se describe la herramienta BPMS-Game, que da soporte a la aplicación de gamificación en sistemas BPMS. La utilidad potencial de la herramienta se ilustra con un caso de ejemplo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Procesos de Negocio, Gamificación, BPMS]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Mancebo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla la Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[javier.mancbo@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Félix García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla la Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[felix.garcia@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/027]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Servitización: Un estudio de Técnicas de Modelado de Negocio</title>
		<link>https://biblioteca.sistedes.es/articulo/servitizacion-un-estudio-de-tecnicas-de-modelado-de-negocio/</link>
		<pubDate>Tue, 06 Sep 2016 12:12:12 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2048</guid>
		<description></description>
		<content><![CDATA[El concepto de servitización se puede resumir en la idea de ofrecer servicios en combinación con productos con el objetivo de mejorar la oferta de valor al cliente. Para afrontar exitosamente un proceso de servitización, las empresas necesitan rediseñar su modelo de negocio. Definir el modelo de negocio implica un proceso de innovación y la conceptualización de la idea de negocio de una organización. El objetivo de este trabajo es analizar brevemente el proceso de servitización en la literatura y presentar un estudio sobre las técnicas y metodologías para el modelado de negocio que pueden ayudar en este proceso.]]></content>
		<excerpt><![CDATA[Servitización, Servicios, Modelo de Negocio]]></excerpt>
		<post_id>2048</post_id>
		<post_date><![CDATA[2016-09-06 14:12:12]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 12:12:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[servitizacion-un-estudio-de-tecnicas-de-modelado-de-negocio]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="modelo-de-negocio"><![CDATA[Modelo de Negocio]]></category>
		<category domain="post_tag" nicename="servicios"><![CDATA[Servicios]]></category>
		<category domain="post_tag" nicename="servitizacion"><![CDATA[Servitización]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El concepto de servitización se puede resumir en la idea de ofrecer servicios en combinación con productos con el objetivo de mejorar la oferta de valor al cliente. Para afrontar exitosamente un proceso de servitización, las empresas necesitan rediseñar su modelo de negocio. Definir el modelo de negocio implica un proceso de innovación y la conceptualización de la idea de negocio de una organización. El objetivo de este trabajo es analizar brevemente el proceso de servitización en la literatura y presentar un estudio sobre las técnicas y metodologías para el modelado de negocio que pueden ayudar en este proceso.
]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Servitización, Servicios, Modelo de Negocio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Valeria de Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[valeria.decastro@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan M. Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Eloísa Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[eloisa.diaz@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[María Luz Martín]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[luz.martin@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2055]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/002]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automatización de la etapa de análisis para la aplicación de la técnica de prueba metamórfica a composiciones de servicios WS-BPEL</title>
		<link>https://biblioteca.sistedes.es/articulo/automatizacion-de-la-etapa-de-analisis-para-la-aplicacion-de-la-tecnica-de-prueba-metamorfica-a-composiciones-de-servicios-ws-bpel/</link>
		<pubDate>Tue, 06 Sep 2016 12:39:31 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2057</guid>
		<description></description>
		<content><![CDATA[La importancia de los servicios web en el mundo actual está en auge, y el impacto social que están teniendo gracias a las nuevas tecnologías desarrolladas, hace necesario el diseño de mejores técnicas de prueba para el software específico de composición de estos servicios web. Una de las técnicas propuestas para las composiciones WS-BPEL es la técnica de prueba metamórfica. En trabajos anteriores se ha presentado una arquitectura para su aplicación y se han aportado algunas ideas para la automatización de la etapa inicial de la misma, que se corresponde con el análisis y obtención de propiedades, pero no se llegaron a desarrollar ni implementar. En este trabajo se presenta el diseño de una solución para automatizar ciertos aspectos de la etapa de análisis y obtención de propiedades, la cual ha sido probada en diferentes casos de prueba obteniéndose buenos resultados.]]></content>
		<excerpt><![CDATA[pruebas metamórficas, relaciones metamórficas, WS-BPEL, composiciones de servicios web, solución, análisis]]></excerpt>
		<post_id>2057</post_id>
		<post_date><![CDATA[2016-09-06 14:39:31]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 12:39:31]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automatizacion-de-la-etapa-de-analisis-para-la-aplicacion-de-la-tecnica-de-prueba-metamorfica-a-composiciones-de-servicios-ws-bpel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="analisis"><![CDATA[análisis]]></category>
		<category domain="post_tag" nicename="composiciones-de-servicios-web"><![CDATA[composiciones de servicios web]]></category>
		<category domain="post_tag" nicename="pruebas-metamorficas"><![CDATA[pruebas metamórficas]]></category>
		<category domain="post_tag" nicename="relaciones-metamorficas"><![CDATA[relaciones metamórficas]]></category>
		<category domain="post_tag" nicename="solucion"><![CDATA[solución]]></category>
		<category domain="post_tag" nicename="ws-bpel"><![CDATA[WS-BPEL]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2058]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La importancia de los servicios web en el mundo actual está en auge, y el impacto social que están teniendo gracias a las nuevas tecnologías desarrolladas, hace necesario el diseño de mejores técnicas de prueba para el software específico de composición de estos servicios web. Una de las técnicas propuestas para las composiciones WS-BPEL es la técnica de prueba metamórfica. En trabajos anteriores se ha presentado una arquitectura para su aplicación y se han aportado algunas ideas para la automatización de la etapa inicial de la misma, que se corresponde con el análisis y obtención de propiedades, pero no se llegaron a desarrollar ni implementar. En este trabajo se presenta el diseño de una solución para automatizar ciertos aspectos de la etapa de análisis y obtención de propiedades, la cual ha sido probada en diferentes casos de prueba obteniéndose buenos resultados.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[pruebas metamórficas, relaciones metamórficas, WS-BPEL, composiciones de servicios web, solución, análisis]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[M Carmen de Castro-Cabrera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[maricarmen.decastro@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Kevin J Valle-Gómez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[kevin.vallegomez@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/008]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Defining PPIs for Process Variants based on Change Patterns</title>
		<link>https://biblioteca.sistedes.es/articulo/defining-ppis-for-process-variants-based-on-change-patterns/</link>
		<pubDate>Tue, 06 Sep 2016 12:46:30 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2060</guid>
		<description></description>
		<content><![CDATA[Business Process (BP) families are made up of BP variants that share commonalities but also show differences to accommodate the specific necessities of different application contexts (i.e., country regulations, industrial domain, etc.). Even though there are modelling techniques to represent these families (e.g., C-EPC, Provop), there is no work aimed at the performance measurement of the different BP variants that conform the family. Process Performance Indicators (PPI) are commonly used to study and analyse the performance of business processes. However, the application of such indicators in BP families increases the modelling and management complexity of the whole family. To deal with this complexity, this work introduces a modelling solution for managing PPI variability based on the concepts of change patterns for process families (CP4PF). The proposed solution includes a set of patterns aimed at 1) reducing the number of operations required to specify PPIs and 2) ensuring PPI family correctness.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2060</post_id>
		<post_date><![CDATA[2016-09-06 14:46:30]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 12:46:30]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[defining-ppis-for-process-variants-based-on-change-patterns]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2061]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Bedilia Estrada-Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Victoria Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Métodos de Producción de Software, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Adela del-Río-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Métodos de Producción de Software, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Business Process (BP) families are made up of BP variants that share commonalities but also show differences to accommodate the specific necessities of different application contexts (i.e., country regulations, industrial domain, etc.). Even though there are modelling techniques to represent these families (e.g., C-EPC, Provop), there is no work aimed at the performance measurement of the different BP variants that conform the family. Process Performance Indicators (PPI) are commonly used to study and analyse the performance of business processes. However, the application of such indicators in BP families increases the modelling and management complexity of the whole family. To deal with this complexity, this work introduces a modelling solution for managing PPI variability based on the concepts of change patterns for process families (CP4PF). The proposed solution includes a set of patterns aimed at 1) reducing the number of operations required to specify PPIs and 2) ensuring PPI family correctness.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/018]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Incertidumbre de Datos en el Modelado de Procesos de Negocio</title>
		<link>https://biblioteca.sistedes.es/articulo/incertidumbre-de-datos-en-el-modelado-de-procesos-de-negocio/</link>
		<pubDate>Tue, 06 Sep 2016 12:55:32 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2066</guid>
		<description></description>
		<content><![CDATA[Este artículo describe nuestro trabajo en curso sobre el modelado de procesos de negocio teniendo en cuenta la incertidumbre de los datos. Esto es un aspecto esencial para modelar con mayor precisión y fidelidad procesos industriales en donde ciertos parámetros –como la duración de las tareas o el coste de algunos recursos– no pueden determinarse con exactitud, pero son necesarios tenerlos en cuenta a la hora de analizar los sistemas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2066</post_id>
		<post_date><![CDATA[2016-09-06 14:55:32]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 12:55:32]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[incertidumbre-de-datos-en-el-modelado-de-procesos-de-negocio]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2067]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo describe nuestro trabajo en curso sobre el modelado de procesos de negocio teniendo en cuenta la incertidumbre de los datos. Esto es un aspecto esencial para modelar con mayor precisión y fidelidad procesos industriales en donde ciertos parámetros –como la duración de las tareas o el coste de algunos recursos– no pueden determinarse con exactitud, pero son necesarios tenerlos en cuenta a la hora de analizar los sistemas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Priscill Orue]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[priscill.orue@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carmen Morcillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[aixela@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Vallecillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[av@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/019]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automatic Generation of Purchasing Plans for Cloud Services</title>
		<link>https://biblioteca.sistedes.es/articulo/automatic-generation-of-purchasing-plans-for-cloud-services/</link>
		<pubDate>Tue, 06 Sep 2016 13:06:51 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2069</guid>
		<description></description>
		<content><![CDATA[The myriad of cloud service providers, as well as their overwhelming variety of configuration and purchasing options, result in a highly complex purchasing scenario. Furthermore, users may specify their needs for cloud services provisioning with a certain scheduling restrictions. There is a need for an automatic support for obtaining an appropriate purchasing plan, which takes into account both service configurations and scheduling needs, while allowing the comparison among different providers and their various offerings. In this work, we present an automatic purchasing plan generator, which analyzes cloud service offerings from several providers to obtain an optimized purchasing plan according to user needs. From the obtained purchasing plan, our solution can provide the corresponding charge plan, possibly including discounts, which serves the purpose of comparing offerings to get the best option.]]></content>
		<excerpt><![CDATA[Cloud Services, Purchasing Plan, Discounts]]></excerpt>
		<post_id>2069</post_id>
		<post_date><![CDATA[2016-09-06 15:06:51]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 13:06:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automatic-generation-of-purchasing-plans-for-cloud-services]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="cloud-services"><![CDATA[Cloud Services]]></category>
		<category domain="post_tag" nicename="discounts"><![CDATA[Discounts]]></category>
		<category domain="post_tag" nicename="purchasing-plan"><![CDATA[Purchasing Plan]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2070]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The myriad of cloud service providers, as well as their overwhelming variety of configuration and purchasing options, result in a highly complex purchasing scenario. Furthermore, users may specify their needs for cloud services provisioning with a certain scheduling restrictions. There is a need for an automatic support for obtaining an appropriate purchasing plan, which takes into account both service configurations and scheduling needs, while allowing the comparison among different providers and their various offerings. In this work, we present an automatic purchasing plan generator, which analyzes cloud service offerings from several providers to obtain an optimized purchasing plan according to user needs. From the obtained purchasing plan, our solution can provide the corresponding charge plan, possibly including discounts, which serves the purpose of comparing offerings to get the best option.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Cloud Services, Purchasing Plan, Discounts]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Octavio Martín-Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática – Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[omartindiaz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José María García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática – Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[josemgarcia@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática – Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática – Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/015]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SOA 2.0 para el Control y Alerta de Riesgos para la Salud Derivados de la Calidad del Aire</title>
		<link>https://biblioteca.sistedes.es/articulo/soa-2-0-para-el-control-y-alerta-de-riesgos-para-la-salud-derivados-de-la-calidad-del-aire/</link>
		<pubDate>Tue, 06 Sep 2016 16:13:01 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2091</guid>
		<description></description>
		<content><![CDATA[La calidad del aire es un factor al que se la ha dado gran relevancia en los últimos años dado que puede afectar seriamente a la salud y a la calidad de vida de las personas. En la actualidad carecemos de medios que nos proporcionen información sobre la calidad del aire en tiempo real y de fácil acceso para los ciudadanos; y en especial no hay medios que se puedan particularizar para las condiciones específicas de cada individuo. En este artículo mostramos nuestros avances en la propuesta, implementación y prueba de una arquitectura orientada a servicios y dirigida por eventos que nos permite detectar en tiempo real los cambios en la calidad del aire y ponerlos al alcance de los ciudadanos enviándoles notificaciones y alertas personalizadas en función de sus características personales, previniendo así mayores riesgos para la salud.]]></content>
		<excerpt><![CDATA[Arquitecturas Orientadas a Servicios, Arquitecturas Dirigidas por Eventos, Procesamiento de Eventos Complejos, Bus de Servicios Empresariales, Calidad del Aire]]></excerpt>
		<post_id>2091</post_id>
		<post_date><![CDATA[2016-09-06 18:13:01]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 16:13:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[soa-2-0-para-el-control-y-alerta-de-riesgos-para-la-salud-derivados-de-la-calidad-del-aire]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="arquitecturas-dirigidas-por-eventos"><![CDATA[Arquitecturas Dirigidas por Eventos]]></category>
		<category domain="post_tag" nicename="arquitecturas-orientadas-a-servicios"><![CDATA[arquitecturas orientadas a servicios]]></category>
		<category domain="post_tag" nicename="bus-de-servicios-empresariales"><![CDATA[Bus de Servicios Empresariales]]></category>
		<category domain="post_tag" nicename="calidad-del-aire"><![CDATA[calidad del aire]]></category>
		<category domain="post_tag" nicename="procesamiento-de-eventos-complejos"><![CDATA[procesamiento de eventos complejos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2092]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La calidad del aire es un factor al que se la ha dado gran relevancia en los últimos años dado que puede afectar seriamente a la salud y a la calidad de vida de las personas. En la actualidad carecemos de medios que nos proporcionen información sobre la calidad del aire en tiempo real y de fácil acceso para los ciudadanos; y en especial no hay medios que se puedan particularizar para las condiciones específicas de cada individuo. En este artículo mostramos nuestros avances en la propuesta, implementación y prueba de una arquitectura orientada a servicios y dirigida por eventos que nos permite detectar en tiempo real los cambios en la calidad del aire y ponerlos al alcance de los ciudadanos enviándoles notificaciones y alertas personalizadas en función de sus características personales, previniendo así mayores riesgos para la salud.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Arquitecturas Orientadas a Servicios, Arquitecturas Dirigidas por Eventos, Procesamiento de Eventos Complejos, Bus de Servicios Empresariales, Calidad del Aire]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alfonso García de Prado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software Escuela Superior de Ingeniería, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alfonso.garciadeprado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software Escuela Superior de Ingeniería, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software Escuela Superior de Ingeniería, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Adolfo R. de Soto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingenierías Mecánica, Informática y Aeroespacial, Universidad de León]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[adolfo.rdesoto@unileon.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/025]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Recompilación de procesos de educación a partir de registros de eventos (resumen)</title>
		<link>https://biblioteca.sistedes.es/articulo/recompilacion-de-procesos-de-educacion-a-partir-de-registros-de-eventos/</link>
		<pubDate>Tue, 06 Sep 2016 16:24:06 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2095</guid>
		<description></description>
		<content><![CDATA[Resumen de artículo publicado como:

Vidal, J.C., Vázquez-Barreiros, B., Lama, M., Mucientes, M.: Recompiling learning processes from event logs.Knowledge-Based Systems 100 (2016) 160-174.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2095</post_id>
		<post_date><![CDATA[2016-09-06 18:24:06]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 16:24:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[recompilacion-de-procesos-de-educacion-a-partir-de-registros-de-eventos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2098]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen de artículo publicado como:

Vidal, J.C., Vázquez-Barreiros, B., Lama, M., Mucientes, M.: Recompiling learning processes from event logs.Knowledge-Based Systems 100 (2016) 160-174.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan C. Vidal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Informacióon (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[juan.vidal@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Borja Vázquez-Barreiros]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Informacióon (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[borja.vazquez@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Lama]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Informacióon (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuel.lama@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel Mucientes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Informacióon (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manuel.mucientes@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/026]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Supporting Compensations with WS-Agreement</title>
		<link>https://biblioteca.sistedes.es/articulo/supporting-compensations-with-ws-agreement/</link>
		<pubDate>Tue, 06 Sep 2016 16:32:48 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2101</guid>
		<description></description>
		<content><![CDATA[During the last years the use of service level agreements (SLA) is rising uncontrollably to describe the rights and obligations of parties involved in service provisioning (typically the service consumer and the service provider); amongst other information, SLA could define guarantees associated with the idea of service level objectives (SLOs) that normally represent key performance indicators of either the consumer or the provider. In case the guarantee is under or over fulfilled SLAs could also define some compensations (i.e. penalties or rewards). In such a context, there have been important steps towards the automation of the analysis of SLAs. One of these steps is a characterization model of SLAs with compensations proposed by the authors in a previous work; and another step is the standardisation effort in the SLAs notation made by WS-Agreement. However, real-world SLAs includes complex concepts that must be considered, namely: (i) SLA terms that specify compensations without an explicit SLO; and (ii) a limit for the compensations. In this paper we extend our prior characterization model considering these complex concepts. Specifically, (i) we provide up to five real-world scenarios whose SLAs incorporate aforementioned new concepts; (ii) we extend our model for compensable guarantees considering terms without an explicit SLO; and (iii) we provide a novel WS-Agreement-based syntax to model SLAs with compensations considering these concepts. These contributions aim to establish a foundation to elaborate tools that could provide an automated support to the modelling and analysis of SLAs with compensations.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2101</post_id>
		<post_date><![CDATA[2016-09-06 18:32:48]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 16:32:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[supporting-compensations-with-ws-agreement]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2102]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[During the last years the use of service level agreements (SLA) is rising uncontrollably to describe the rights and obligations of parties involved in service provisioning (typically the service consumer and the service provider); amongst other information, SLA could define guarantees associated with the idea of service level objectives (SLOs) that normally represent key performance indicators of either the consumer or the provider. In case the guarantee is under or over fulfilled SLAs could also define some compensations (i.e. penalties or rewards). In such a context, there have been important steps towards the automation of the analysis of SLAs. One of these steps is a characterization model of SLAs with compensations proposed by the authors in a previous work; and another step is the standardisation effort in the SLAs notation made by WS-Agreement. However, real-world SLAs includes complex concepts that must be considered, namely: (i) SLA terms that specify compensations without an explicit SLO; and (ii) a limit for the compensations. In this paper we extend our prior characterization model considering these complex concepts. Specifically, (i) we provide up to five real-world scenarios whose SLAs incorporate aforementioned new concepts; (ii) we extend our model for compensable guarantees considering terms without an explicit SLO; and (iii) we provide a novel WS-Agreement-based syntax to model SLAs with compensations considering these concepts. These contributions aim to establish a foundation to elaborate tools that could provide an automated support to the modelling and analysis of SLAs with compensations.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Müller]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Octavio Martín-Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio M. Gutierrez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/023]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Reparación de alineamientos en modelos de proceso similares</title>
		<link>https://biblioteca.sistedes.es/articulo/reparacion-de-alineamientos-en-modelos-de-proceso-similares/</link>
		<pubDate>Tue, 06 Sep 2016 16:41:18 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2104</guid>
		<description></description>
		<content><![CDATA[Una de las ramas más importantes de la minería de procesos es el análisis de conformidad, es decir, analizar hasta qué punto un proceso de negocio se ajusta a los datos de ejecución de los procesos de negocio observados. Los alineamientos son el instrumento estándar de facto dentro de las analíticas de conformidad. Los alineamientos relacionan elementos de un registro de eventos con las actividades presentes en un modelo de proceso. Sin embargo, calcularlos es un problema combinatorio y, por lo tanto, extremadamente costoso. En este artículo mostramos como es posible reparar un alineamiento para un proceso dado, utilizando como punto de partida un modelo y un alineamiento previo. De este modo, demostramos cómo es posible obtener un nuevo alineamiento, en un tiempo significativamente mejor, reparando aquellas partes que ya no se ajustan al comportamiento del nuevo modelo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2104</post_id>
		<post_date><![CDATA[2016-09-06 18:41:18]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 16:41:18]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[reparacion-de-alineamientos-en-modelos-de-proceso-similares]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2105]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Una de las ramas más importantes de la minería de procesos es el análisis de conformidad, es decir, analizar hasta qué punto un proceso de negocio se ajusta a los datos de ejecución de los procesos de negocio observados. Los alineamientos son el instrumento estándar de facto dentro de las analíticas de conformidad. Los alineamientos relacionan elementos de un registro de eventos con las actividades presentes en un modelo de proceso. Sin embargo, calcularlos es un problema combinatorio y, por lo tanto, extremadamente costoso. En este artículo mostramos cómo es posible reparar un alineamiento para un proceso dado, utilizando como punto de partida un modelo y un alineamiento previo. De este modo, demostramos cómo es posible obtener un nuevo alineamiento, en un tiempo significativamente mejor, reparando aquellas partes que ya no se ajustan al comportamiento del nuevo modelo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[B. Vázquez-Barreiros]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[borja.vazquez@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[S.J. van Zelst]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Mathematics and Computer Science, Eindhoven University of Technology]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[s.j.v.zelst@tue.nl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[J.C.A.M. Buijs]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Mathematics and Computer Science Eindhoven, University of Technology]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[j.c.a.m.buijs@tue.nl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[M. Lama]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manuel.lamausc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[M. Mucientes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[manuel.mucientesg@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/017]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>RALph: A Graphical Notation for Resource Assignments in Business Processes (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/ralph-a-graphical-notation-for-resource-assignments-in-business-processes-abstract/</link>
		<pubDate>Tue, 06 Sep 2016 16:50:02 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2108</guid>
		<description></description>
		<content><![CDATA[Resumen de artículo publicado como:

Cristina Cabanillas, David Knuplesch, Manuel Resinas, Manfred Reichert, Jan Mendling, Antonio Ruiz-Cortés: RALph: A Graphical Notation for Resource Assignments in Business Processes. International Conference on Advanced Information Systems Engineering (CAiSE) 2015: 53-68. DOI: 10.1007/978-3-319-19069-3_4.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2108</post_id>
		<post_date><![CDATA[2016-09-06 18:50:02]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 16:50:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[ralph-a-graphical-notation-for-resource-assignments-in-business-processes-abstract]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2109]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen de artículo publicado en:

Cristina Cabanillas, David Knuplesch, Manuel Resinas, Manfred Reichert, Jan Mendling, Antonio Ruiz-Cortés: RALph: A Graphical Notation for Resource Assignments in Business Processes. International Conference on Advanced Information Systems Engineering (CAiSE) 2015: 53-68. DOI: 10.1007/978-3-319-19069-3_4.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cristina Cabanillas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Vienna University of Economics and Business]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cristina.cabanillas@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David Knuplesch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Ulm University]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[david.knuplesch@uni-ulm.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manfred Reichert]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Ulm University]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manfred.reichert@uni-ulm.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Jan Mendling]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Vienna University of Economics and Business]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[jan.mendling@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/029]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Opening up Context-aware Services Compositions to End-Users</title>
		<link>https://biblioteca.sistedes.es/articulo/opening-up-context-aware-services-compositions-to-end-users/</link>
		<pubDate>Tue, 06 Sep 2016 17:01:11 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2111</guid>
		<description></description>
		<content><![CDATA[The interconnected world in which we live opens many possibilities to create, consume, and share knowledge and services. Even though end-users are more than ever prepared in terms of technology (e.g., by using smartphones), their specific context (i.e., personal interests, geographical location, etc.) is not yet properly considered in existing solutions to explore these possibilites. Therefore, we need to provide end-users with tools that allow them to create, consume, and share added value services by using the proper knowledge and services according to their context. In this sense this paper discusses how existing solutions could be integrated to achieve this goal. In particular we explore the possibility of extending EUCalipTool, an end-user mobile tool for service compositions, with the context-aware notification capabilities offered by nimBees.]]></content>
		<excerpt><![CDATA[Service Discovery, Context-aware discovery, End-user Development]]></excerpt>
		<post_id>2111</post_id>
		<post_date><![CDATA[2016-09-06 19:01:11]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 17:01:11]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[opening-up-context-aware-services-compositions-to-end-users]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="context-aware-discovery"><![CDATA[Context-aware discovery]]></category>
		<category domain="post_tag" nicename="end-user-development"><![CDATA[End-user Development]]></category>
		<category domain="post_tag" nicename="service-discovery"><![CDATA[Service Discovery]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2112]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The interconnected world in which we live opens many possibilities to create, consume, and share knowledge and services. Even though end-users are more than ever prepared in terms of technology (e.g., by using smartphones), their specific context (i.e., personal interests, geographical location, etc.) is not yet properly considered in existing solutions to explore these possibilites. Therefore, we need to provide end-users with tools that allow them to create, consume, and share added value services by using the proper knowledge and services according to their context. In this sense this paper discusses how existing solutions could be integrated to achieve this goal. In particular we explore the possibility of extending EUCalipTool, an end-user mobile tool for service compositions, with the context-aware notification capabilities offered by nimBees.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Service Discovery, Context-aware discovery, End-user Development]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ignacio Mansanet]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València, Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[imansanet@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Victoria Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València, Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[vtorres@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pedro Valderas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València, Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pvalderas@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[José Manuel García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/009]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Construyendo Perfiles Virtuales Mediante el Procesamiento de Eventos Complejos</title>
		<link>https://biblioteca.sistedes.es/articulo/construyendo-perfiles-virtuales-mediante-el-procesamiento-de-eventos-complejos/</link>
		<pubDate>Tue, 06 Sep 2016 17:13:14 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2115</guid>
		<description></description>
		<content><![CDATA[A medida que se incrementa el número de dispositivos inteligentes, el esfuerzo requerido para adaptarlos a las necesidades de cada usuario también crece. Asimismo, el proceso de adaptación de un dispositivo al contexto de un usuario es todavía un proceso muy manual. A pesar de que en los últimos años han surgido algunas propuestas centradas en obtener la informacióon contextual de los usuarios para crear sus perfiles virtuales, se necesitan soluciones novedosas que permitan crear perfiles más completos, que sean utilizados por los dispositivos inteligentes para adaptarse automáticamente a las necesidades de sus usuarios, redundando en una mayor exactitud de la adaptación. En este artículo se propone la integración del modelo computacional People as a Service (PeaaS) con el procesamiento de eventos complejos (CEP) para la creación en tiempo real de perfiles virtuales complejos desde el propio dispositivo móvil y la compartición de estos como servicios para el resto de sistemas y dispositivos. Además, se evalúa esta integración en un caso de estudio sobre Alzheimer. Los resultados confirman que el uso de la tecnología CEP para la identificación de información contextual compleja es posible.]]></content>
		<excerpt><![CDATA[Información Contextual, CEP, PeaaS, Asper, MDD]]></excerpt>
		<post_id>2115</post_id>
		<post_date><![CDATA[2016-09-06 19:13:14]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 17:13:14]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[construyendo-perfiles-virtuales-mediante-el-procesamiento-de-eventos-complejos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="asper"><![CDATA[Asper]]></category>
		<category domain="post_tag" nicename="cep"><![CDATA[CEP]]></category>
		<category domain="post_tag" nicename="informacion-contextual"><![CDATA[Información Contextual]]></category>
		<category domain="post_tag" nicename="mdd"><![CDATA[MDD]]></category>
		<category domain="post_tag" nicename="peaas"><![CDATA[PeaaS]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2116]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A medida que se incrementa el número de dispositivos inteligentes, el esfuerzo requerido para adaptarlos a las necesidades de cada usuario también crece. Asimismo, el proceso de adaptación de un dispositivo al contexto de un usuario es todavía un proceso muy manual. A pesar de que en los últimos años han surgido algunas propuestas centradas en obtener la informacióon contextual de los usuarios para crear sus perfiles virtuales, se necesitan soluciones novedosas que permitan crear perfiles más completos, que sean utilizados por los dispositivos inteligentes para adaptarse automáticamente a las necesidades de sus usuarios, redundando en una mayor exactitud de la adaptación. En este artículo se propone la integración del modelo computacional People as a Service (PeaaS) con el procesamiento de eventos complejos (CEP) para la creación en tiempo real de perfiles virtuales complejos desde el propio dispositivo móvil y la compartición de estos como servicios para el resto de sistemas y dispositivos. Además, se evalúa esta integración en un caso de estudio sobre Alzheimer. Los resultados confirman que el uso de la tecnología CEP para la identificación de información contextual compleja es posible.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Información Contextual, CEP, PeaaS, Asper, MDD]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jose Garcia-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Juan M. Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/010]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>La Web de las Cosas se nos viene encima</title>
		<link>https://biblioteca.sistedes.es/articulo/la-web-de-las-cosas-se-nos-viene-encima/</link>
		<pubDate>Tue, 06 Sep 2016 17:18:01 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2118</guid>
		<description></description>
		<content><![CDATA[A medida que crece el interés por la denominada Web de las Cosas (WoT), deberíamos hacer disminuir las barreras de entrada para el uso de las tecnologías asociadas. Hoy en día somos capaces de desarrollar aplicaciones que adaptan su comportamiento de acuerdo a condiciones definidas de antemano, así como a las preferencias personales de sus usuarios, facilitando así su utilización. El software para la Web de las Cosas que desarrollemos en el futuro inmediato debería ser capaz de ajustar de forma automática su comportamiento también de acuerdo a situaciones no predefinidas y al contexto en el que se mueven sus usuarios. En este artículo de reflexión, discutimos el estado actual del arte y la necesidad de nuevos modelos y herramientas capaces de hacer frente a estos retos, de forma que podamos predecir el comportamiento esperado de un sistema WoT y la interacción necesaria entre los dispositivos que lo integran, con el objetivo de lograr una mejor respuesta del sistema a información contextual variable.]]></content>
		<excerpt><![CDATA[Internet de las Cosas, Web de las Cosas, Sensibilidad al contexto]]></excerpt>
		<post_id>2118</post_id>
		<post_date><![CDATA[2016-09-06 19:18:01]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 17:18:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[la-web-de-las-cosas-se-nos-viene-encima]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="internet-de-las-cosas"><![CDATA[Internet de las Cosas]]></category>
		<category domain="post_tag" nicename="sensibilidad-al-contexto"><![CDATA[Sensibilidad al contexto]]></category>
		<category domain="post_tag" nicename="web-de-las-cosas"><![CDATA[Web de las Cosas]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2119]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A medida que crece el interés por la denominada Web de las Cosas (WoT), deberíamos hacer disminuir las barreras de entrada para el uso de las tecnologías asociadas. Hoy en día somos capaces de desarrollar aplicaciones que adaptan su comportamiento de acuerdo a condiciones definidas de antemano, así como a las preferencias personales de sus usuarios, facilitando así su utilización. El software para la Web de las Cosas que desarrollemos en el futuro inmediato debería ser capaz de ajustar de forma automática su comportamiento también de acuerdo a situaciones no predefinidas y al contexto en el que se mueven sus usuarios. En este artículo de reflexión, discutimos el estado actual del arte y la necesidad de nuevos modelos y herramientas capaces de hacer frente a estos retos, de forma que podamos predecir el comportamiento esperado de un sistema WoT y la interacción necesaria entre los dispositivos que lo integran, con el objetivo de lograr una mejor respuesta del sistema a información contextual variable.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Internet de las Cosas, Web de las Cosas, Sensibilidad al contexto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/011]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Análisis inteligente de flujos de trabajo sociales</title>
		<link>https://biblioteca.sistedes.es/articulo/analisis-inteligente-de-flujos-de-trabajo-sociales/</link>
		<pubDate>Tue, 06 Sep 2016 17:30:08 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2121</guid>
		<description></description>
		<content><![CDATA[Los flujos de trabajo sociales (SOW) coordinan las actividades realizadas por un conjunto de usuarios que bien de forma individual o en cooperación tratan de alcanzar un determinado objetivo. Los SOW son flujos no estructurados en los que participan un gran número de usuarios que llevan a cabo actividades de muy diversa naturaleza que se extienden a lo largo del tiempo y que típicamente consumen pocos recursos de computación. Un ejemplo de procesos que se modelan a través de este tipo de flujos de trabajo son las campañas de marketing que tienen como objetivo motivar a los potenciales clientes en el consumo de un determinado producto o servicio. En este trabajo, se presenta el proyecto Inteligencia (Artificial) de Negocio para Flujos de Trabajo Sociales, en el que se combinan técnicas de minería de procesos, estrategias de paralelización de algoritmos, y técnicas de localización y seguimiento de usuarios, con el fin de extraer información relevante sobre SOW, como los que modelan, entre otros, el comportamiento de los usuarios en campañas de marketing desarrolladas en escenarios abiertos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2121</post_id>
		<post_date><![CDATA[2016-09-06 19:30:08]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 17:30:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analisis-inteligente-de-flujos-de-trabajo-sociales]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[11]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2122]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los flujos de trabajo sociales (SOW) coordinan las actividades realizadas por un conjunto de usuarios que bien de forma individual o en cooperación tratan de alcanzar un determinado objetivo. Los SOW son flujos no estructurados en los que participan un gran número de usuarios que llevan a cabo actividades de muy diversa naturaleza que se extienden a lo largo del tiempo y que típicamente consumen pocos recursos de computación. Un ejemplo de procesos que se modelan a través de este tipo de flujos de trabajo son las campañas de marketing que tienen como objetivo motivar a los potenciales clientes en el consumo de un determinado producto o servicio. En este trabajo, se presenta el proyecto Inteligencia (Artificial) de Negocio para Flujos de Trabajo Sociales, en el que se combinan técnicas de minería de procesos, estrategias de paralelización de algoritmos, y técnicas de localización y seguimiento de usuarios, con el fin de extraer información relevante sobre SOW, como los que modelan, entre otros, el comportamiento de los usuarios en campañas de marketing desarrolladas en escenarios abiertos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel Lama]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[manuel.lama@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pedro Álvarez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Ingenería de Aragón (I3A) Depto. de Informática e Ingenería de Sistemas, Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[alvaper@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Ocaña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Depto. de Electrónica, Escuela Politécnica Superior. Universidad de Alcalá de Henares]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mocana@depeca.uah.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel Mucientes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manuel.mucientes@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Joaquín Ezpeleta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Ingenería de Aragón (I3A) Depto. de Informática e Ingeneríaa de Sistemas, Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[ezpeleta@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Miguel Ángel Garrido]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Depto. de Electrónica, Escuela Politécnica Superior. Universidad de Alcalá de Henares]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[garrido@depeca.uah.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Alberto Bugarín]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[alberto.bugarin.diz@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/028]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Depto. de Electrónica, Escuela Politécnica Superior. Universidad de Alcalá de Henares]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>MigraSOA: Migrando aplicaciones web legadas hacia arquitecturas orientadas a servicios (SOA)</title>
		<link>https://biblioteca.sistedes.es/articulo/migrasoa-migrando-aplicaciones-web-legadas-hacia-arquitecturas-orientadas-a-servicios-soa/</link>
		<pubDate>Tue, 06 Sep 2016 17:37:58 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2125</guid>
		<description></description>
		<content><![CDATA[La migración de aplicaciones legadas hacia arquitecturas orientadas a servicios (SOA) es un proceso relativamente habitual en la actualidad, ya que las características de flexibilidad arquitectónica que ofrece SOA permiten adaptar fácilmente las aplicaciones a los nuevos requisitos marcados por las empresas. Sin embargo, el desarrollo de esta migración hacia estas nuevas arquitecturas software se lleva a cabo normalmente de forma manual, siendo este un mecanismo tedioso y propenso a errores. MigraSOA es una propuesta de migración de aplicaciones web legadas (LWA) hacia SOA que utiliza técnicas de Desarrollo de Software Dirigido por Modelos (MDD) para abordar la complejidad de las tecnologías subyacentes (servicios web, definición de procesos de negocio o plataformas para procesos de negocio ejecutables). En este trabajo, además de presentar MigraSOA de una forma global, nos centraremos en los aspectos de alineación de los procesos de negocio definidos por la empresa con los servicios web subyacentes en la aplicación legada y en cómo extender los modelos BPMN para conseguir la sincronización entre ellos y los servicios disponibles.]]></content>
		<excerpt><![CDATA[migración de aplicaciones web, servicios web, procesos de negocio, arquitecturas orientadas a servicios]]></excerpt>
		<post_id>2125</post_id>
		<post_date><![CDATA[2016-09-06 19:37:58]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 17:37:58]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[migrasoa-migrando-aplicaciones-web-legadas-hacia-arquitecturas-orientadas-a-servicios-soa]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="arquitecturas-orientadas-a-servicios"><![CDATA[arquitecturas orientadas a servicios]]></category>
		<category domain="post_tag" nicename="migracion-de-aplicaciones-web"><![CDATA[migración de aplicaciones web]]></category>
		<category domain="post_tag" nicename="procesos-de-negocio"><![CDATA[Procesos de Negocio]]></category>
		<category domain="post_tag" nicename="servicios-web"><![CDATA[servicios web]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2126]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La migración de aplicaciones legadas hacia arquitecturas orientadas a servicios (SOA) es un proceso relativamente habitual en la actualidad, ya que las características de flexibilidad arquitectónica que ofrece SOA permiten adaptar fácilmente las aplicaciones a los nuevos requisitos marcados por las empresas. Sin embargo, el desarrollo de esta migración hacia estas nuevas arquitecturas software se lleva a cabo normalmente de forma manual, siendo este un mecanismo tedioso y propenso a errores. MigraSOA es una propuesta de migración de aplicaciones web legadas (LWA) hacia SOA que utiliza técnicas de Desarrollo de Software Dirigido por Modelos (MDD) para abordar la complejidad de las tecnologías subyacentes (servicios web, definición de procesos de negocio o plataformas para procesos de negocio ejecutables). En este trabajo, además de presentar MigraSOA de una forma global, nos centraremos en los aspectos de alineación de los procesos de negocio definidos por la empresa con los servicios web subyacentes en la aplicación legada y en cómo extender los modelos BPMN para conseguir la sincronización entre ellos y los servicios disponibles.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[migración de aplicaciones web, servicios web, procesos de negocio, arquitecturas orientadas a servicios]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Encarna Sosa-Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura. Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[esosa@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pedro J. Clemente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura. Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pjclemente@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alvaro Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura. Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aeprieto@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José M. Conejero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura. Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[chemacm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Roberto Rodríguez-Echeverría]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura. Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[rre@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/024]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una aproximación DevOps para el Desarrollo Dirigido por Modelos de Servicios Cloud</title>
		<link>https://biblioteca.sistedes.es/articulo/una-aproximacion-devops-para-el-desarrollo-dirigido-por-modelos-de-servicios-cloud/</link>
		<pubDate>Tue, 06 Sep 2016 19:07:45 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2132</guid>
		<description></description>
		<content><![CDATA[El desarrollo de software ágil promueve la entrega continua e incremental de software. Con cada incremento surge la necesidad de realizar una integración del nuevo código fuente con el existente para obtener una nueva versión del software. La nueva versión debe superar un conjunto de pruebas para ser desplegada en el entorno de operaciones. El tiempo que transcurre desde que el nuevo incremento pasa del entorno de desarrollo al entorno de operaciones debe ser minimizado para reducir costes económicos a las organizaciones. DevOps es un conjunto de principios y prácticas que optimizan el tiempo de entrega de un producto software, gestionan la infraestructura como código y mejoran la experiencia del usuario en base a la retroalimentación de sus comentarios. En trabajos anteriores hemos presentado DIARy como un método dirigido por modelos que soporta la reconfiguración dinámica de arquitecturas de servicios cloud producida por la integración incremental de nuevos servicios. En este trabajo presentamos una extensión del método DIARy con el fin de adoptar DevOps con una estrategia dirigida por modelos.]]></content>
		<excerpt><![CDATA[DevOps, Servicios Cloud, Integración y Reconfiguración de Servicios, Desarrollo Ágil, Desarrollo Dirigido por Modelos]]></excerpt>
		<post_id>2132</post_id>
		<post_date><![CDATA[2016-09-06 21:07:45]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:07:45]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-aproximacion-devops-para-el-desarrollo-dirigido-por-modelos-de-servicios-cloud]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="desarrollo-agil"><![CDATA[Desarrollo Ágil]]></category>
		<category domain="post_tag" nicename="desarrollo-dirigido-por-modelos"><![CDATA[Desarrollo dirigido por modelos]]></category>
		<category domain="post_tag" nicename="devops"><![CDATA[DevOps]]></category>
		<category domain="post_tag" nicename="integracion-y-reconfiguracion-de-servicios"><![CDATA[Integración y Reconfiguración de Servicios]]></category>
		<category domain="post_tag" nicename="servicios-cloud"><![CDATA[Servicios Cloud]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2133]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El desarrollo de software ágil promueve la entrega continua e incremental de software. Con cada incremento surge la necesidad de realizar una integración del nuevo código fuente con el existente para obtener una nueva versión del software. La nueva versión debe superar un conjunto de pruebas para ser desplegada en el entorno de operaciones. El tiempo que transcurre desde que el nuevo incremento pasa del entorno de desarrollo al entorno de operaciones debe ser minimizado para reducir costes económicos a las organizaciones. DevOps es un conjunto de principios y prácticas que optimizan el tiempo de entrega de un producto software, gestionan la infraestructura como código y mejoran la experiencia del usuario en base a la retroalimentación de sus comentarios. En trabajos anteriores hemos presentado DIARy como un método dirigido por modelos que soporta la reconfiguración dinámica de arquitecturas de servicios cloud producida por la integración incremental de nuevos servicios. En este trabajo presentamos una extensión del método DIARy con el fin de adoptar DevOps con una estrategia dirigida por modelos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[DevOps, Servicios Cloud, Integración y Reconfiguración de Servicios, Desarrollo Ágil, Desarrollo Dirigido por Modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julio Sandobalín-Guamán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València y Departamento de Informática y Ciencias de la Computación, Escuela Politécnica Nacional (Ecuador)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jsandobalin@disc.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miguel Zúñiga-Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València y Departamento de Ciencias de la Computación, Universidad de Cuenca (Ecuador)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mzuniga@disc.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Emilio Insfran]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[einsfran@disc.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Silvia Abrahão]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sabrahao@disc.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Carlos Cano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[carcage@disc.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/014]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards a general architecture for predictive monitoring of business processes</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-a-general-architecture-for-predictive-monitoring-of-business-processes/</link>
		<pubDate>Tue, 06 Sep 2016 19:15:49 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2135</guid>
		<description></description>
		<content><![CDATA[Process mining allows the extraction of useful information from event logs and historical data of business processes. This information will improve the performance of these processes and is generally obtained after they have finished. Therefore, predictive monitoring of business process running instances is needed, in order to provide proactive and corrective actions to improve the process performance and mitigate the possible risks in real time. This monitoring allows the prediction of evaluation metrics for a runtime process. In this context, this work describes a general methodology for a business process monitoring system for the prediction of process performance indicators and their stages, such as, the processing and encoding of log events, the calculation of aggregated attributes or the application of a data mining algorithm.]]></content>
		<excerpt><![CDATA[business process, process mining, predictive monitoring, business process indicator prediction]]></excerpt>
		<post_id>2135</post_id>
		<post_date><![CDATA[2016-09-06 21:15:49]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:15:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-a-general-architecture-for-predictive-monitoring-of-business-processes]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="business-process"><![CDATA[Business process]]></category>
		<category domain="post_tag" nicename="business-process-indicator-prediction"><![CDATA[business process indicator prediction]]></category>
		<category domain="post_tag" nicename="predictive-monitoring"><![CDATA[predictive monitoring]]></category>
		<category domain="post_tag" nicename="process-mining"><![CDATA[Process Mining]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2136]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Process mining allows the extraction of useful information from event logs and historical data of business processes. This information will improve the performance of these processes and is generally obtained after they have finished. Therefore, predictive monitoring of business process running instances is needed, in order to provide proactive and corrective actions to improve the process performance and mitigate the possible risks in real time. This monitoring allows the prediction of evaluation metrics for a runtime process. In this context, this work describes a general methodology for a business process monitoring system for the prediction of process performance indicators and their stages, such as, the processing and encoding of log events, the calculation of aggregated attributes or the application of a data mining algorithm.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[business process, process mining, predictive monitoring, business process indicator prediction]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alfonso E. Márquez-Chamorro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[amarquez6@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/003]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automating Correctness Verification of Artifact-Centric Business Process Models (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/automating-correctness-verification-of-artifact-centric-business-process-models-abstract/</link>
		<pubDate>Tue, 06 Sep 2016 19:20:44 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2138</guid>
		<description></description>
		<content><![CDATA[Resumen de artículo publicado como:

Automating Correctness Verification of Artifact-Centric Business Process Models. Published in Journal of Information and Software Technology. Vol. 62, Issue C, Pages 187-197, June 2015. DOI:10.1016/j.infsof.2015.02.010.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2138</post_id>
		<post_date><![CDATA[2016-09-06 21:20:44]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:20:44]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automating-correctness-verification-of-artifact-centric-business-process-models-abstract]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2139]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen de artículo publicado en:

Automating Correctness Verification of Artifact-Centric Business Process Models. Published in Journal of Information and Software Technology. Vol. 62, Issue C, Pages 187-197, June 2015. DOI:10.1016/j.infsof.2015.02.010.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Diana Borrego]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[dianabn@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Rafael M. Gasca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gasca@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[María Teresa Gómez-López]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[maytegomez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modelling Service Level Agreements for Business Process Outsourcing Services (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/modelling-service-level-agreements-for-business-process-outsourcing-services-abstract/</link>
		<pubDate>Tue, 06 Sep 2016 19:25:12 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2141</guid>
		<description></description>
		<content><![CDATA[Resumen del artículo publicado como:

A. del Río-Ortega et al.: Modelling Service Level Agreements for Business Process Outsourcing Services. In: CAiSE 2015: 485-500.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2141</post_id>
		<post_date><![CDATA[2016-09-06 21:25:12]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:25:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modelling-service-level-agreements-for-business-process-outsourcing-services-abstract]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen del artículo publicado en:

A. del Río-Ortega et al.: Modelling Service Level Agreements for Business Process Outsourcing Services. In: CAiSE 2015: 485-500.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Adela del-Río-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Manuel Gutiérrez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Amador Durán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2142]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/022]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Verification and Validation of UML Artifact-centric Business Process Models (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/verification-and-validation-of-uml-artifact-centric-business-process-models-abstract/</link>
		<pubDate>Tue, 06 Sep 2016 19:29:40 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2145</guid>
		<description></description>
		<content><![CDATA[Resumen del artículo publicado en:

27th Int. Conf. on Advanced Information Systems Engineering (CAiSE 2015).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2145</post_id>
		<post_date><![CDATA[2016-09-06 21:29:40]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:29:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[verification-and-validation-of-uml-artifact-centric-business-process-models-abstract]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2146]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen del artículo publicado en:

27th Int. Conf. on Advanced Information Systems Engineering (CAiSE 2015).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Montserrat Estañol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[estanyol@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Maria-Ribera Sancho]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya y Barcelona Supercomputing Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ribera@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ernest Teniente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[teniente@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Reconfiguration of Service Failures in DAMASCo using Dynamic Software Product Lines (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/reconfiguration-of-service-failures-in-damasco-using-dynamic-software-product-lines-abstract/</link>
		<pubDate>Tue, 06 Sep 2016 19:33:36 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2148</guid>
		<description></description>
		<content><![CDATA[<div data-canvas-width="47.34519999999999">Building service-based applications requires providing the ability to handle, maintain or upgrade the services that compose these applications. As same services may be used by a wide variability of applications, the management of the heterogeneity at runtime is required. This is crucial to reconfigure applications in case of service failures. The DAMASCo framework reduces the complexity of modeling services focusing on the discovery, composition and adaptation of context-aware services. But currently, it does not support the dynamic reconfiguration of service-based applications. In this work, we follow a Dynamic Software Product Line approach to extend DAMASCo for providing reconfiguration to support specific situations of fails at runtime. We propose a novel approach of grouping services in families facilitating the selection and usage of similar services in case of fails. We apply our approach to an intelligent transportation system case study where DAMASCo composes and reconfigure the necessary services to provide a dynamic route for a driver’srequest.</div>
&nbsp;

Resumen del artículo publicado en:

12th IEEE International Conference on Services Computing (SCC 2015).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2148</post_id>
		<post_date><![CDATA[2016-09-06 21:33:36]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:33:36]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[reconfiguration-of-service-failures-in-damasco-using-dynamic-software-product-lines-abstract]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="dsp"><![CDATA[DSP]]></category>
		<category domain="post_tag" nicename="heterogeneity"><![CDATA[Heterogeneity]]></category>
		<category domain="post_tag" nicename="service-reconfiguration"><![CDATA[Service Reconfiguration]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2149]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Building service-based applications requires providing the ability to handle, maintain or upgrade the services that compose these applications. As same services may be used by a wide variability of applications, the management of the heterogeneity at runtime is required. This is crucial to reconfigure applications in case of service failures. The DAMASCo framework reduces the complexity of modeling services focusing on the discovery, composition and adaptation of context-aware services. But currently, it does not support the dynamic reconfiguration of service-based applications. In this work, we follow a Dynamic Software Product Line approach to extend DAMASCo for providing reconfiguration to support specific situations of fails at runtime. We propose a novel approach of grouping services in families facilitating the selection and usage of similar services in case of fails. We apply our approach to an intelligent transportation system case study where DAMASCo composes and reconfigure the necessary services to provide a dynamic route for a driver’srequest.

Resumen del artículo publicado en:

12th IEEE International Conference on Services Computing (SCC 2015).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Cubo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cubo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Nadia Gamez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[nadia@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ernesto Pimentel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ernesto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Service Reconfiguration, Heterogeneity, DSP]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/007]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Reconfigurando Aplicaciones Multi-Cloud con Líneas de Producto Software Dinámicas</title>
		<link>https://biblioteca.sistedes.es/articulo/reconfigurando-aplicaciones-multi-cloud-con-lineas-de-producto-software-dinamicas/</link>
		<pubDate>Tue, 06 Sep 2016 19:39:04 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2151</guid>
		<description></description>
		<content><![CDATA[La reconfiguración dinámica de aplicaciones multi-cloud es un reto complejo aún no suficientemente explorado. En estos entornos las aplicaciones o sus módulos pueden estar desplegados en diferentes proveedores. Por lo tanto, reconfigurar en tiempo de ejecución estas aplicaciones puede requerir la modificación de la distribución en múltiples y heterogéneos proveedores. Obtener la nueva distribución para que sigan funcionando correctamente las aplicaciones no es una tarea sencilla, pues tanto los requisitos de las aplicaciones como las propiedades de los proveedores son muy diversos y variables. Además, la migración de las aplicaciones o sus módulos en tiempo real de un proveedor a otro puede conllevar problemas de compatibilidad y/o dependencias entre los módulos. Por lo tanto, el manejo de la variabilidad dinámica de las aplicaciones y proveedores, así como el de las dependencias existentes es deseable que se haga a un alto nivel de abstracción. Las Líneas de Producto Software Dinámicas (DSLP) utilizan modelos de variabilidad en tiempo de ejecución para obtener los cambios que han de llevarse a cabo durante la reconfiguración. En este trabajo, exploramos el uso del enfoque de DSPL, para que cuando ocurran problemas en los proveedores o se violen requisitos de las aplicaciones multi-cloud, las apps puedan ser reconfiguradas y seguir proporcionando los servicios adecuadamente a los usuarios.]]></content>
		<excerpt><![CDATA[Reconfiguración, Aplicaciones Cloud, Multi-Cloud, DSPL, Variabilidad]]></excerpt>
		<post_id>2151</post_id>
		<post_date><![CDATA[2016-09-06 21:39:04]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:39:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[reconfigurando-aplicaciones-multi-cloud-con-lineas-de-producto-software-dinamicas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="aplicaciones-cloud"><![CDATA[Aplicaciones Cloud]]></category>
		<category domain="post_tag" nicename="dspl"><![CDATA[DSPL]]></category>
		<category domain="post_tag" nicename="multi-cloud"><![CDATA[Multi-Cloud]]></category>
		<category domain="post_tag" nicename="reconfiguracion"><![CDATA[Reconfiguración]]></category>
		<category domain="post_tag" nicename="variabilidad"><![CDATA[Variabilidad]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2152]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La reconfiguración dinámica de aplicaciones multi-cloud es un reto complejo aún no suficientemente explorado. En estos entornos las aplicaciones o sus módulos pueden estar desplegados en diferentes proveedores. Por lo tanto, reconfigurar en tiempo de ejecución estas aplicaciones puede requerir la modificación de la distribución en múltiples y heterogéneos proveedores. Obtener la nueva distribución para que sigan funcionando correctamente las aplicaciones no es una tarea sencilla, pues tanto los requisitos de las aplicaciones como las propiedades de los proveedores son muy diversos y variables. Además, la migración de las aplicaciones o sus módulos en tiempo real de un proveedor a otro puede conllevar problemas de compatibilidad y/o dependencias entre los módulos. Por lo tanto, el manejo de la variabilidad dinámica de las aplicaciones y proveedores, así como el de las dependencias existentes es deseable que se haga a un alto nivel de abstracción. Las Líneas de Producto Software Dinámicas (DSLP) utilizan modelos de variabilidad en tiempo de ejecución para obtener los cambios que han de llevarse a cabo durante la reconfiguración. En este trabajo, exploramos el uso del enfoque de DSPL, para que cuando ocurran problemas en los proveedores o se violen requisitos de las aplicaciones multi-cloud, las apps puedan ser reconfiguradas y seguir proporcionando los servicios adecuadamente a los usuarios. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Reconfiguración, Aplicaciones Cloud, Multi-Cloud, DSPL, Variabilidad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Cubo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cubo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Nadia Gámez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[nadia@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ernesto Pimentel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ernesto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/013]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Bidimensional Cross-Cloud Application Management with TOSCA and Brooklyn (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/bidimensional-cross-cloud-application-management-with-tosca-and-brooklyn-abstract/</link>
		<pubDate>Tue, 06 Sep 2016 19:47:45 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2154</guid>
		<description></description>
		<content><![CDATA[The diversity in the way different cloud providers offer their services, give their SLAs, present their QoS, support different technologies, etc., complicates the portability and interoperability of cloud applications, and favors vendor lock-in. Standards like TOSCA, and tools supporting them, have come to help in the provider-independent description of cloud applications. After the variety of proposed cross-cloud application management tools, we propose going one step further in the unification of cloud services with a deployment tool in which IaaS and PaaS services are integrated into a unified interface. We provide support for applications whose components are to be deployed on different providers, indistinctly using IaaS and PaaS services. The TOSCA standard is used to define a portable model describing the topology of the cloud applications and the required resources in an agnostic, and providers- and resources-independent way. We include in this paper some highlights on our implementation on Apache Brooklyn and present a non-trivial example that illustrates our approach.

Resumen del artículo publicado en:

Jose Carrasco, Javier Cubo, Francisco Durán, Ernesto Pimentel. Bidimensional Cross-Cloud Application Management with TOSCA and Brooklyn, 9th IEEE International Conference on Cloud Computing (CLOUD 2016), San Francisco, (EEUU). IEEE Computer Society, 2016.]]></content>
		<excerpt><![CDATA[Cloud applications, multi-deployment, cross-cloud, standards, TOSCA, Brooklyn, IaaS, PaaS]]></excerpt>
		<post_id>2154</post_id>
		<post_date><![CDATA[2016-09-06 21:47:45]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:47:45]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[bidimensional-cross-cloud-application-management-with-tosca-and-brooklyn-abstract]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="brooklyn"><![CDATA[Brooklyn]]></category>
		<category domain="post_tag" nicename="cloud-applications"><![CDATA[Cloud applications]]></category>
		<category domain="post_tag" nicename="cross-cloud"><![CDATA[cross-cloud]]></category>
		<category domain="post_tag" nicename="iaas"><![CDATA[IaaS]]></category>
		<category domain="post_tag" nicename="multi-deployment"><![CDATA[multi-deployment]]></category>
		<category domain="post_tag" nicename="paas"><![CDATA[PaaS]]></category>
		<category domain="post_tag" nicename="standards"><![CDATA[standards]]></category>
		<category domain="post_tag" nicename="tosca"><![CDATA[TOSCA]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2155]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The diversity in the way different cloud providers offer their services, give their SLAs, present their QoS, support different technologies, etc., complicates the portability and interoperability of cloud applications, and favors vendor lock-in. Standards like TOSCA, and tools supporting them, have come to help in the provider-independent description of cloud applications. After the variety of proposed cross-cloud application management tools, we propose going one step further in the unification of cloud services with a deployment tool in which IaaS and PaaS services are integrated into a unified interface. We provide support for applications whose components are to be deployed on different providers, indistinctly using IaaS and PaaS services. The TOSCA standard is used to define a portable model describing the topology of the cloud applications and the required resources in an agnostic, and providers- and resources-independent way. We include in this paper some highlights on our implementation on Apache Brooklyn and present a non-trivial example that illustrates our approach.

Resumen del artículo publicado en:

Jose Carrasco, Javier Cubo, Francisco Durán, Ernesto Pimentel. Bidimensional Cross-Cloud Application Management with TOSCA and Brooklyn, 9th IEEE International Conference on Cloud Computing (CLOUD 2016), San Francisco, (EEUU). IEEE Computer Society, 2016.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Cloud applications, multi-deployment, cross-cloud, standards, TOSCA, Brooklyn, IaaS, PaaS]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jose Carrasco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[josec@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Cubo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cubo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco Durán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[duran@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ernesto Pimentel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[ernesto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/012]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Recommender System for Process Discovery (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-recommender-system-for-process-discovery-abstract/</link>
		<pubDate>Tue, 06 Sep 2016 19:54:43 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2157</guid>
		<description></description>
		<content><![CDATA[Resumen del artículo publicado como:

Joel Ribeiro, Josep Carmona, Mustafa Misir, Michle Sebag: A Recommender System for Process Discovery. 12th International Conference on Business Process Management, BPM 2014, Haifa, Israel, September 7-11, 67-83. Lecture Notes in Computer Science 8659, Springer 2014, ISBN 978-3-319-10171-2.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2157</post_id>
		<post_date><![CDATA[2016-09-06 21:54:43]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:54:43]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-recommender-system-for-process-discovery-abstract]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2158]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen del artículo publicado como:

Joel Ribeiro, Josep Carmona, Mustafa Misir, Michle Sebag: A Recommender System for Process Discovery. 12th International Conference on Business Process Management, BPM 2014, Haifa, Israel, September 7-11, 67-83. Lecture Notes in Computer Science 8659, Springer 2014, ISBN 978-3-319-10171-2.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Joel Ribeiro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jribeiro@lsi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Josep Carmona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jcarmona@lsi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Mustafa Misir]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[TAO, INRIA Saclay - CNRS - LRI, Université Paris Sud XI (France)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mustafa.misir@lri.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Michele Sebag]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[TAO, INRIA Saclay - CNRS - LRI, Université Paris Sud XI (France)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[michele.sebag@lri.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/001]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Process Mining: Past, Present and (Likely) Future</title>
		<link>https://biblioteca.sistedes.es/articulo/process-mining-past-present-and-likely-future/</link>
		<pubDate>Tue, 06 Sep 2016 19:57:45 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2160</guid>
		<description></description>
		<content><![CDATA[The process mining field came here to stay. This is demonstrated by the growing interest in the last decade, both in academia and industry. Being at the intersection of many disciplines, process mining techniques transform structured information into valuable models, which provide a fresh and formal insight into the real execution of processes within an organization. Still, there is way more to do than what has been accomplished: process discovery techniques may suffer from noisy, incomplete event logs and may fail to choose the right representational bias; conformance checking suffers from the inherent complexity of working at the state-space level, and in case of large inputs this fact prevents from enhancing process models with additional perspectives. In this paper I will provide an historical overview of the field, describe its current challenges, and vaticinate its long-term future.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2160</post_id>
		<post_date><![CDATA[2016-09-06 21:57:45]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:57:45]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[process-mining-past-present-and-likely-future]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2161]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The process mining field came here to stay. This is demonstrated by the growing interest in the last decade, both in academia and industry. Being at the intersection of many disciplines, process mining techniques transform structured information into valuable models, which provide a fresh and formal insight into the real execution of processes within an organization. Still, there is way more to do than what has been accomplished: process discovery techniques may suffer from noisy, incomplete event logs and may fail to choose the right representational bias; conformance checking suffers from the inherent complexity of working at the state-space level, and in case of large inputs this fact prevents from enhancing process models with additional perspectives. In this paper I will provide an historical overview of the field, describe its current challenges, and vaticinate its long-term future.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Josep Carmona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jcarmona@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/006]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>VIVACE: A framework for the systematic evaluation of variability support in process-aware information systems (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/vivace-a-framework-for-the-systematic-evaluation-of-variability-support-in-process-aware-information-systems-summary/</link>
		<pubDate>Tue, 06 Sep 2016 20:10:47 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2163</guid>
		<description></description>
		<content><![CDATA[Resumen del artículo publicado como:

Clara Ayora, Victoria Torres, Barbara Weber, Manfred Reichert, and Vicente Pelechano. VIVACE: A framework for the systematic evaluation of variability support in process-aware information systems, Information and Software Technology, Volume 57, January 2015, Pages 248–276, Elsevier, 2015.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2163</post_id>
		<post_date><![CDATA[2016-09-06 22:10:47]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 20:10:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[vivace-a-framework-for-the-systematic-evaluation-of-variability-support-in-process-aware-information-systems-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2165]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen del artículo publicado como:

Clara Ayora, Victoria Torres, Barbara Weber, Manfred Reichert, and Vicente Pelechano. VIVACE: A framework for the systematic evaluation of variability support in process-aware information systems, Information and Software Technology, Volume 57, January 2015, Pages 248–276, Elsevier, 2015.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Clara Ayora]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València y Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cayora@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Victoria Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València y Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[vtorres@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Barbara Weber]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Innsbruck (Austria)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[barbara.weber@uibk.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manfred Reichert]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Ulm (Germany)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manfred.reichert@uni-ulm.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València y Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[pele@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/016]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Monitoring the service-based system lifecycle with SALMon (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/monitoring-the-service-based-system-lifecycle-with-salmon-summary/</link>
		<pubDate>Tue, 06 Sep 2016 20:15:11 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2167</guid>
		<description></description>
		<content><![CDATA[Resumen del artículo publicado como:

Marc Oriol, Xavier Franch, Jordi Marco. Monitoring the service-based system lifecycle with SALMon, Expert Systems with Applications, 42(19), 2015.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2167</post_id>
		<post_date><![CDATA[2016-09-06 22:15:11]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 20:15:11]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[monitoring-the-service-based-system-lifecycle-with-salmon-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2168]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen del artículo publicado como:

Marc Oriol, Xavier Franch, Jordi Marco. Monitoring the service-based system lifecycle with SALMon, Expert Systems with Applications, 42(19), 2015.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Marc Oriol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya, y GESSI research group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[moriol@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Xavier Franch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya, y GESSI research group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[franch@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jordi Marco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya, y GESSI research group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jmarco@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/021]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Governing the service-chain: Challenges ahead</title>
		<link>https://biblioteca.sistedes.es/articulo/governing-the-service-chain-challenges-ahead/</link>
		<pubDate>Tue, 06 Sep 2016 20:18:08 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2170</guid>
		<description></description>
		<content><![CDATA[As Information Systems are evolving into an ecosystem of services, organizations face the persistent challenge of IT governance. In such a context, Cloud Computing shift has supported a growing service chain that has transformed the business model from industry. In this position paper we outline the dimensions of this service chain reality and the role of Service Level Agreement as a foundation to support its governance challenges.

&nbsp;]]></content>
		<excerpt><![CDATA[service-chain, governance, sla]]></excerpt>
		<post_id>2170</post_id>
		<post_date><![CDATA[2016-09-06 22:18:08]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 20:18:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[governing-the-service-chain-challenges-ahead]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="governance"><![CDATA[governance]]></category>
		<category domain="post_tag" nicename="service-chain"><![CDATA[service-chain]]></category>
		<category domain="post_tag" nicename="sla"><![CDATA[SLA]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2171]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[As Information Systems are evolving into an ecosystem of services, organizations face the persistent challenge of IT governance. In such a context, Cloud Computing shift has supported a growing service chain that has transformed the business model from industry. In this position paper we outline the dimensions of this service chain reality and the role of Service Level Agreement as a foundation to support its governance challenges.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[service-chain, governance, sla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/030]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Programming Elasticity and Commitment in Dynamic Processes (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/programming-elasticity-and-commitment-in-dynamic-processes-summary/</link>
		<pubDate>Tue, 06 Sep 2016 20:23:39 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2173</guid>
		<description></description>
		<content><![CDATA[In the past, elasticity and commitment in business processes were under-explored. But as businesses increasingly exploit pay-per-use resources in the cloud for on-demand needs, elasticity and commitment have become important issues. Here, the authors discuss the value of using elastic resources and commitments to create more dynamic organizations that can easily balance the need to be adaptable and flexible, while also retaining a high level of manageability.

Resumen del artículo publicado como:

Pablo Fernandez, Hong-Linh Truong, Schahram Dustdar, and Antonio Ruiz-Cortes. Programming Elasticity and Commitment in Dynamic Processes, IEEE Internet Computing, Vol 19, 2 , 68-74, 2015.]]></content>
		<excerpt><![CDATA[elasticity, commitments, process management]]></excerpt>
		<post_id>2173</post_id>
		<post_date><![CDATA[2016-09-06 22:23:39]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 20:23:39]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[programming-elasticity-and-commitment-in-dynamic-processes-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="commitments"><![CDATA[commitments]]></category>
		<category domain="post_tag" nicename="elasticity"><![CDATA[elasticity]]></category>
		<category domain="post_tag" nicename="process-management"><![CDATA[process management]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2174]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In the past, elasticity and commitment in business processes were under-explored. But as businesses increasingly exploit pay-per-use resources in the cloud for on-demand needs, elasticity and commitment have become important issues. Here, the authors discuss the value of using elastic resources and commitments to create more dynamic organizations that can easily balance the need to be adaptable and flexible, while also retaining a high level of manageability.

Resumen del artículo publicado como:

Pablo Fernandez, Hong-Linh Truong, Schahram Dustdar, and Antonio Ruiz-Cortes. Programming Elasticity and Commitment in Dynamic Processes, IEEE Internet Computing, Vol 19, 2 , 68-74, 2015.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[elasticity, commitments, process management]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Hong-Linh Truong]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Technical University of Vienna (Austria)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Schahram Dustdar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Technical University of Vienna (Austria)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/020]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Constraint-Based Testing: An Emerging Trend in Software Testing</title>
		<link>https://biblioteca.sistedes.es/articulo/constraint-based-testing-an-emerging-trend-in-software-testing/</link>
		<pubDate>Thu, 08 Sep 2016 09:25:39 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2194</guid>
		<description></description>
		<content><![CDATA[Software Testing involves the development of smart techniques to automatically find test inputs which uncover faults in programs. An emerging trend in this area, called “Constraint-Based Testing”, aims at exploiting constraint solving techniques for this goal. My talk will review different techniques including dynamic symbolic execution, path-based exploration and constraint-based exploration and will emphasize the usage of advanced Constraint Programming tools.Software Testing involves the development of smart techniques to automatically find test inputs which uncover faults in programs. An emerging trend in this area, called “Constraint-Based Testing”, aims at exploiting constraint solving techniques for this goal. My talk will review different techniques including dynamic symbolic execution, path-based exploration and constraint-based exploration and will emphasize the usage of advanced Constraint Programming tools.]]></content>
		<excerpt><![CDATA[Software Testing involves the development of smart techniques to automatically find test inputs which uncover faults in programs. An emerging trend in this area, called “Constraint-Based Testing”, aims at exploiting constraint solving techniques for this goal. My talk will review different techniques including dynamic symbolic execution, path-based exploration and constraint-based exploration and will emphasize the usage of advanced Constraint Programming tools.Software Testing involves the development of smart techniques to automatically find test inputs which uncover faults in programs. An emerging trend in this area, called “Constraint-Based Testing”, aims at exploiting constraint solving techniques for this goal. My talk will review different techniques including dynamic symbolic execution, path-based exploration and constraint-based exploration and will emphasize the usage of advanced Constraint Programming tools.]]></excerpt>
		<post_id>2194</post_id>
		<post_date><![CDATA[2016-09-08 11:25:39]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 09:25:39]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[constraint-based-testing-an-emerging-trend-in-software-testing]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[10]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2195]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Software Testing involves the development of smart techniques to automatically find test inputs which uncover faults in programs. An emerging trend in this area, called “Constraint-Based Testing”, aims at exploiting constraint solving techniques for this goal. My talk will review different techniques including dynamic symbolic execution, path-based exploration and constraint-based exploration and will emphasize the usage of advanced Constraint Programming tools.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Arnaud Gotlieb]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Simula Research Laboratory. Norway]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[arnaud@simula.no]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards Automatic Learning of Heuristics for Mechanical Transformations of Procedural Code</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-automatic-learning-of-heuristics-for-mechanical-transformations-of-procedural-code/</link>
		<pubDate>Thu, 08 Sep 2016 09:39:12 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2199</guid>
		<description></description>
		<content><![CDATA[The current trends in next-generation exascale systems go towards integrating a wide range of specialized (co-)processors into traditional supercomputers. Due to the efficiency of heterogeneous systems in terms of Watts and FLOPS per surface unit, opening the access of heterogeneous platforms to a range of users as wide as possible is an important problem to be tackled. However, the integration of heterogeneous, specialized devices increases programming complexity, restricting it to a few experts, and makes porting applications onto different computational infrastructures extremely costly. In order to bridge the gap between the programming needs of heterogeneous systems and the expertise of programmers, program transformation has been proposed elsewhere as a means to ease program generation and adaptation. This brings about several issues such as how to plan a transformation strategy which eventually generates code with increased performance. In this paper we propose a machine learning-based approach to learn heuristics for defining transformation strategies of a program transformation system. Our approach proposes a novel combination of reinforcement learning and classification methods to efficiently tackle the problems inherent to this type of systems. Preliminary results demonstrate the suitability of this approach.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2199</post_id>
		<post_date><![CDATA[2016-09-08 11:39:12]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 09:39:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-automatic-learning-of-heuristics-for-mechanical-transformations-of-procedural-code]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2200]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The current trends in next-generation exascale systems go towards integrating a wide range of specialized (co-)processors into traditional supercomputers. Due to the efficiency of heterogeneous systems in terms of Watts and FLOPS per surface unit, opening the access of heterogeneous platforms to a range of users as wide as possible is an important problem to be tackled. However, the integration of heterogeneous, specialized devices increases programming complexity, restricting it to a few experts, and makes porting applications onto different computational infrastructures extremely costly. In order to bridge the gap between the programming needs of heterogeneous systems and the expertise of programmers, program transformation has been proposed elsewhere as a means to ease program generation and adaptation. This brings about several issues such as how to plan a transformation strategy which eventually generates code with increased performance. In this paper we propose a machine learning-based approach to learn heuristics for defining transformation strategies of a program transformation system. Our approach proposes a novel combination of reinforcement learning and classification methods to efficiently tackle the problems inherent to this type of systems. Preliminary results demonstrate the suitability of this approach.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Program Transformation, Machine Learning, Heterogeneous Systems]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Guillermo Vigueras  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[guillermo.vigueras@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Manuel Carro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[manuel.carro@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Salvador Tamarit  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[salvador.tamarit@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Julio Mariño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[julio.marino@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/015]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards a Semantics-Aware Code Transformation Toolchain for Heterogeneous Systems</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-a-semantics-aware-code-transformation-toolchain-for-heterogeneous-systems/</link>
		<pubDate>Thu, 08 Sep 2016 09:49:31 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2203</guid>
		<description></description>
		<content><![CDATA[Obtaining good performance when programming heterogeneous computing platforms poses significant challenges. We present a program transformation environment, implemented in Haskell, where architecture-agnostic scientific C code with semantic annotations is transformed into functionally equivalent code better suited for a given platform. The transformation steps are represented as rules which can be fired when certain syntactic and semantic conditions are fulfilled. These rules are not hard-wired into the rewriting engine: they are written in a C-like language and are automatically processed and incorporated by the rewriting engine. That makes it possible for end-users to add their own rules or to provide sets of rules which are adapted to certain specific domains or purposes.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2203</post_id>
		<post_date><![CDATA[2016-09-08 11:49:31]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 09:49:31]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-a-semantics-aware-code-transformation-toolchain-for-heterogeneous-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2204]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Obtaining good performance when programming heterogeneous computing platforms poses significant challenges. We present a program transformation environment, implemented in Haskell, where architecture-agnostic scientific C code with semantic annotations is transformed into functionally equivalent code better suited for a given platform. The transformation steps are represented as rules which can be fired when certain syntactic and semantic conditions are fulfilled. These rules are not hard-wired into the rewriting engine: they are written in a C-like language and are automatically processed and incorporated by the rewriting engine. That makes it possible for end-users to add their own rules or to provide sets of rules which are adapted to certain specific domains or purposes.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Rule-based program transformation, Semantics-aware program transformation, High-performance, Heterogeneous platforms, Scientific computing, Domain-specific language, Haskell, C]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Tamarit  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[salvador.tamarit@upm.es, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Julio Mariño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[julio.marino@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Guillermo Vigueras  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[guillermo.vigueras@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel Carro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manuel.carro@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/014]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Metapredicate Optimization for Datalog Queries through Program Analysis</title>
		<link>https://biblioteca.sistedes.es/articulo/metapredicate-optimization-for-datalog-queries-through-program-analysis/</link>
		<pubDate>Thu, 08 Sep 2016 10:59:07 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2237</guid>
		<description></description>
		<content><![CDATA[Some systems extend Datalog in order to allow the use of constructions in which several queries are composed to produce the set of resulting tuples. These constructions include outer joins, aggregate and grouping predicates, as well as, to some extent, negation. Typically, the result of such
constructions depends on the subset of the tuples in the sets initially computed. In order to optimize for efficiency these compound queries, it would be interesting to determine in advance the subsets involved in the compound construct. Static analysis can be used at compile-time to infer
an over-approximation of such subsets. Very precise abstract interpretation-based static analyzers have been developed for logic languages, and in particular the use of type domains allow to infer descriptive types for the arguments of a given predicate. Using the extensional description of the
types inferred, the Datalog program can then be transformed to use the inferred subsets instead of the original queries. Here, we propose a source-to-source transformation of Datalog programs based on static analysis for optimizing queries involving outer join, negation, aggregate and grouping predicates. This approach has been tested in the DES system, using CiaoPP (a language preprocessor for Prolog) for inferring descriptive types. Some preliminary experiments show promising results.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2237</post_id>
		<post_date><![CDATA[2016-09-08 12:59:07]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 10:59:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[metapredicate-optimization-for-datalog-queries-through-program-analysis]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2238]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Some systems extend Datalog in order to allow the use of constructions in which several queries are composed to produce the set of resulting tuples. These constructions include outer joins, aggregate and grouping predicates, as well as, to some extent, negation. Typically, the result of such
constructions depends on the subset of the tuples in the sets initially computed. In order to optimize for efficiency these compound queries, it would be interesting to determine in advance the subsets involved in the compound construct. Static analysis can be used at compile-time to infer
an over-approximation of such subsets. Very precise abstract interpretation-based static analyzers have been developed for logic languages, and in particular the use of type domains allow to infer descriptive types for the arguments of a given predicate. Using the extensional description of the
types inferred, the Datalog program can then be transformed to use the inferred subsets instead of the original queries. Here, we propose a source-to-source transformation of Datalog programs based on static analysis for optimizing queries involving outer join, negation, aggregate and grouping predicates. This approach has been tested in the DES system, using CiaoPP (a language preprocessor for Prolog) for inferring descriptive types. Some preliminary experiments show promising results.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Bueno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DIA, Polytechnic University of Madrid (UPM)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[bueno@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jesús Correas  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[DSIC, Madrid, Spain Complutense University of Madrid (UCM)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jcorreas@fdi.ucm.es  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[ Fernando Sáenz-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DISIA, Madrid, Spain Complutense University of Madrid (UCM)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ fernan@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/002]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Proving termination properties of conditional rewrite systems</title>
		<link>https://biblioteca.sistedes.es/articulo/proving-termination-properties-of-conditional-rewrite-systems/</link>
		<pubDate>Thu, 08 Sep 2016 11:03:28 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2240</guid>
		<description></description>
		<content><![CDATA[Conditional Term Rewriting Systems (CTRSs) extend Term Rewriting Systems (TRSs) conditional part c to each rewrite rule l → r, thus obtaining a conditional rewrite rule l → r ⇐ c. The addition of such conditional parts c substantially increases the expressiveness of programming languages that use them and often clarifies the purpose of the rules to make programs more readable and self-explanatory. Computations with CTRSs are defined by means of an Inference System where each rewriting step s →R t requires a proof. This proof-theoretical definition of the operational semantics suggests a natural definition of the termination behavior of R as the absence of infinite proof trees. The notion of operational termination captures this idea, meaning that, given an initial goal, an interpreter will either succeed in finite time in producing a closed proof tree, or will fail in finite time, not being able to close or extend further any of the possible proof trees, after exhaustively searching all such proof trees. Besides implying termination in the usual ‘horizontal’ sense (i.e., as the absence of infinite sequences of rewrite steps), operational termination also captures a ‘vertical’ dimension of the termination behavior which is missing in the usual “without infinite reduction sequences” definition of termination. In [1] we define the notion of V-termination, which captures such a vertical dimension of the termination behavior of CTRSs. We provide a uniform definition of termination and V-termination of CTRSs as the absence of specific kinds of infinite proof trees. We prove that operational termination is just the conjunction of termination and V-termination. We use these results to develop a methodology to prove or disprove termination, V-termination, and operational termination of CTRSs by extending the Dependency Pair (DP) approach for TRSs and generalize the DP approach to all aforementioned termination properties of CTRSs.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2240</post_id>
		<post_date><![CDATA[2016-09-08 13:03:28]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 11:03:28]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[proving-termination-properties-of-conditional-rewrite-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2241]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Conditional Term Rewriting Systems (CTRSs) extend Term Rewriting Systems (TRSs) conditional part c to each rewrite rule l → r, thus obtaining a conditional rewrite rule l → r ⇐ c. The addition of such conditional parts c substantially increases the expressiveness of programming languages that use them and often clarifies the purpose of the rules to make programs more readable and self-explanatory. Computations with CTRSs are defined by means of an Inference System where each rewriting step s →R t requires a proof. This proof-theoretical definition of the operational semantics suggests a natural definition of the termination behavior of R as the absence of infinite proof trees. The notion of operational termination captures this idea, meaning that, given an initial goal, an interpreter will either succeed in finite time in producing a closed proof tree, or will fail in finite time, not being able to close or extend further any of the possible proof trees, after exhaustively searching all such proof trees. Besides implying termination in the usual ‘horizontal’ sense (i.e., as the absence of infinite sequences of rewrite steps), operational termination also captures a ‘vertical’ dimension of the termination behavior which is missing in the usual “without infinite reduction sequences” definition of termination. In [1] we define the notion of V-termination, which captures such a vertical dimension of the termination behavior of CTRSs. We provide a uniform definition of termination and V-termination of CTRSs as the absence of specific kinds of infinite proof trees. We prove that operational termination is just the conjunction of termination and V-termination. We use these results to develop a methodology to prove or disprove termination, V-termination, and operational termination of CTRSs by extending the Dependency Pair (DP) approach for TRSs and generalize the DP approach to all aforementioned termination properties of CTRSs.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Lucas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politecnica de Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Meseguer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[CS Dept. at the University of Illinois at Urbana-Champaign]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/020]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Abstract analysis of universal properties for tccp</title>
		<link>https://biblioteca.sistedes.es/articulo/abstract-analysis-of-universal-properties-for-tccp/</link>
		<pubDate>Thu, 08 Sep 2016 11:07:47 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2243</guid>
		<description></description>
		<content><![CDATA[The Timed Concurrent Constraint Language (tccp) is a time extension of the concurrent constraint paradigm of Saraswat. tccp was defined to model reactive systems, where infinite behaviors arise naturally. It is well-known that modeling and analyzing concurrent systems by hand can be an extremely hard task. Thus, the development of automatic formal methods is essential. The particular characteristics of ccp languages make such task even harder, since we have to deal with technical issues due to the infinite computations (natural to reactive systems), use of negative information (particular for ccp languages) and non-determinism.
One well established technique to develop semantic-based program analysis is abstract interpretation, which relies on the definition of a specific approximated abstract semantics that captures the information needed to perform the analysis. Typically, one defines an over-approximation of the concrete semantics that includes all possible traces of the system, possibly introducing inexistent ones. This allows one to develop (correct) analysis of universal properties. It does not allow to analyze existential properties, for instance to verify that there exists a suspension trace.
This paper (originally published in [1]) defines a framework of over-approximated abstract semantics parametric w.r.t. an abstract constraint system.
Since we need to preserve the notion of time—to be able to express properties of interest like safety or time-depending properties—the abstract semantics domains are not Noetherian (even if we use finite abstract constraint systems). Thus, in order to have an effective approach we use a widening to ensure finiteness of the analysis.
The abstract semantics is correct and can be represented as a finite graph where each node represents
a hypothetical computational step of the program containing approximated information for the variables.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2243</post_id>
		<post_date><![CDATA[2016-09-08 13:07:47]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 11:07:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[abstract-analysis-of-universal-properties-for-tccp]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2244]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The Timed Concurrent Constraint Language (tccp) is a time extension of the concurrent constraint paradigm of Saraswat. tccp was defined to model reactive systems, where infinite behaviors arise naturally. It is well-known that modeling and analyzing concurrent systems by hand can be an extremely hard task. Thus, the development of automatic formal methods is essential. The particular characteristics of ccp languages make such task even harder, since we have to deal with technical issues due to the infinite computations (natural to reactive systems), use of negative information (particular for ccp languages) and non-determinism.
One well established technique to develop semantic-based program analysis is abstract interpretation, which relies on the definition of a specific approximated abstract semantics that captures the information needed to perform the analysis. Typically, one defines an over-approximation of the concrete semantics that includes all possible traces of the system, possibly introducing inexistent ones. This allows one to develop (correct) analysis of universal properties. It does not allow to analyze existential properties, for instance to verify that there exists a suspension trace.
This paper (originally published in [1]) defines a framework of over-approximated abstract semantics parametric w.r.t. an abstract constraint system.
Since we need to preserve the notion of time—to be able to express properties of interest like safety or time-depending properties—the abstract semantics domains are not Noetherian (even if we use finite abstract constraint systems). Thus, in order to have an effective approach we use a widening to ensure finiteness of the analysis.
The abstract semantics is correct and can be represented as a finite graph where each node represents
a hypothetical computational step of the program containing approximated information for the variables.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Marco Comini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DIMI, Università degli Studi di Udine  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[marco.comini@uniud.it  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ María del Mar Gallardo  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[LCC, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gallardo@lcc.uma.es  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[ Laura Titolo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[LCC, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ laura.titolo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Alicia Villanueva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[villanue@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/017]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>River basin management with SPIN</title>
		<link>https://biblioteca.sistedes.es/articulo/river-basin-management-with-spin/</link>
		<pubDate>Thu, 08 Sep 2016 12:09:56 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2246</guid>
		<description></description>
		<content><![CDATA[This paper presents the use of the SPIN model checker as the core engine to build Decision Support Systems (DSSs) to control complex river basins during flood situations. Current DSSs in this domain are mostly based on simulators to predict the rainfall and the water flow along the river basin.
In this paper, we propose a scheme that integrates simulators in the water domain with additional logic in P ROMELA to represent basin elements, such as dams, their management rules, the evolution of dam parameters (e.g. level or discharge capacity), and user defined constraints in the whole basin over time. Then, we use the exploration capabilities of SPIN to find out which sequences of operations over the dams produce a global behaviour that mitigates the effect of floods according to user defined constraints along the river basin. Although the method is general for any river basin with dams, it has been evaluated in a real basin in the south of Spain.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2246</post_id>
		<post_date><![CDATA[2016-09-08 14:09:56]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:09:56]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[river-basin-management-with-spin]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2247]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper presents the use of the SPIN model checker as the core engine to build Decision Support Systems (DSSs) to control complex river basins during flood situations. Current DSSs in this domain are mostly based on simulators to predict the rainfall and the water flow along the river basin.
In this paper, we propose a scheme that integrates simulators in the water domain with additional logic in P ROMELA to represent basin elements, such as dams, their management rules, the evolution of dam parameters (e.g. level or discharge capacity), and user defined constraints in the whole basin over time. Then, we use the exploration capabilities of SPIN to find out which sequences of operations over the dams produce a global behaviour that mitigates the effect of floods according to user defined constraints along the river basin. Although the method is general for any river basin with dams, it has been evaluated in a real basin in the south of Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María del Mar Gallardo  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Andalucía Tech, Dept. de Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[gallardo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pedro Merino  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Andalucía Tech, Dept. de Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pedro@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Laura Panizo  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Andalucía Tech, Dept. de Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[laurapanizo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[ Alberto Salmerón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Andalucía Tech, Dept. de Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[salmeron@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/007]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automatic Grading of Programming Exercises using Property-Based Testing</title>
		<link>https://biblioteca.sistedes.es/articulo/automatic-grading-of-programming-exercises-using-property-based-testing/</link>
		<pubDate>Thu, 08 Sep 2016 12:13:04 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2249</guid>
		<description></description>
		<content><![CDATA[We present a framework for automatic grading of programming exercises using property-based testing, a form of model-based black-box testing. Models are developed to assess both the functional behaviour of programs and their algorithmic complexity. From the functional correctness model a
large number of test cases are derived automatically. Executing them on the body of exercises gives rise to a (partial) ranking of programs, so that a program A is ranked higher than program B if it fails a strict subset of the test cases failed by B. The model for algorithmic complexity is used to compute worst-case complexity bounds. The framework moreover considers code structural metrics, such as McCabe’s cyclomatic complexity, giving rise to a composite program grade that includes both functional, non-functional, and code structural aspects. The framework is evaluated in a course teaching algorithms and data structures using Java.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2249</post_id>
		<post_date><![CDATA[2016-09-08 14:13:04]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:13:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automatic-grading-of-programming-exercises-using-property-based-testing]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2250]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We present a framework for automatic grading of programming exercises using property-based testing, a form of model-based black-box testing. Models are developed to assess both the functional behaviour of programs and their algorithmic complexity. From the functional correctness model a
large number of test cases are derived automatically. Executing them on the body of exercises gives rise to a (partial) ranking of programs, so that a program A is ranked higher than program B if it fails a strict subset of the test cases failed by B. The model for algorithmic complexity is used to compute worst-case complexity bounds. The framework moreover considers code structural metrics, such as McCabe’s cyclomatic complexity, giving rise to a composite program grade that includes both functional, non-functional, and code structural aspects. The framework is evaluated in a course teaching algorithms and data structures using Java.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Clara Benac Earle  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid, Spain  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cbenac@fi.upm.es  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Lars-Ake Fredlund]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid, Spain  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[lfredlund@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[John Hughes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Chalmers University of Technology and Quviq AB, Göteborg, Sweden]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[rjmh@chalmers.se]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/023]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Fuzzy Thresholded Fixpoint Semantics</title>
		<link>https://biblioteca.sistedes.es/articulo/fuzzy-thresholded-fixpoint-semantics/</link>
		<pubDate>Thu, 08 Sep 2016 12:18:11 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2253</guid>
		<description></description>
		<content><![CDATA[This work proposes an immediate consequences operator that allows us to give a fixpoint characterization of the least Herbrand model for a powerful class of fuzzy logic programs coping with implicit/explicit truth degree annotations, a great variety of connectives and unification by similarity. The so-called FASILL language (acronym of “Fuzzy Aggregators and Similarity Into a Logic Language”) has been recently designed and implemented in our research group and it enjoys the capability for managing filters or thresholds in a natural way in order to relax some computational and
declarative aspects as revealed in the proposed fixpoint semantics.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2253</post_id>
		<post_date><![CDATA[2016-09-08 14:18:11]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:18:11]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[fuzzy-thresholded-fixpoint-semantics]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2254]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This work proposes an immediate consequences operator that allows us to give a fixpoint characterization of the least Herbrand model for a powerful class of fuzzy logic programs coping with implicit/explicit truth degree annotations, a great variety of connectives and unification by similarity. The so-called FASILL language (acronym of “Fuzzy Aggregators and Similarity Into a Logic Language”) has been recently designed and implemented in our research group and it enjoys the capability for managing filters or thresholds in a natural way in order to relax some computational and
declarative aspects as revealed in the proposed fixpoint semantics.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ Fuzzy Logic Programming, Similarity Relation, Herbrand Model, Immediate Consequences Operator, Fixpoint Semantics]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pascual Julián-Iranzo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dep. of Technologies and Information Systems. U. of Castilla-La Mancha, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Pascual.Julian@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ginés Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dep. of Computing Systems. U. of Castilla-La Mancha, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Gines.Moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jaime Penabad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dep. of Mathematics. U. of Castilla-La Mancha, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Jaime.Penabad@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Formal Relational Languages in a Deductive Setting</title>
		<link>https://biblioteca.sistedes.es/articulo/formal-relational-languages-in-a-deductive-setting/</link>
		<pubDate>Thu, 08 Sep 2016 12:19:56 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2256</guid>
		<description></description>
		<content><![CDATA[The relational data model coincides with the deductive one and, thus, formal relational query languages can be mapped to a deductive setting. These languages include, on the one hand, Tuple Relational Calculus (TRC) and Domain Relational Calculus (DRC). It can be argued that TRC can be
seen as the formal basis of SQL, while DRC does the same for the semantic web language SPARQL and even the graphical relational language Query-by-Example (QBE). On the other hand, Relational Algebra (RA) is also used as a target language for intermediate compilations from SQL to executable query plans. As commonly acknowledged, RA allows a more formal setting for query optimizations than SQL. In this work, we describe the new support of TRC and DRC in the deductive system DES (which included already SQL and RA) with the aim to have an integrated system for learning database query (formal) languages based on logic.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2256</post_id>
		<post_date><![CDATA[2016-09-08 14:19:56]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:19:56]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[formal-relational-languages-in-a-deductive-setting]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2257]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The relational data model coincides with the deductive one and, thus, formal relational query languages can be mapped to a deductive setting. These languages include, on the one hand, Tuple Relational Calculus (TRC) and Domain Relational Calculus (DRC). It can be argued that TRC can be
seen as the formal basis of SQL, while DRC does the same for the semantic web language SPARQL and even the graphical relational language Query-by-Example (QBE). On the other hand, Relational Algebra (RA) is also used as a target language for intermediate compilations from SQL to executable query plans. As commonly acknowledged, RA allows a more formal setting for query optimizations than SQL. In this work, we describe the new support of TRC and DRC in the deductive system DES (which included already SQL and RA) with the aim to have an integrated system for learning database query (formal) languages based on logic.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Fernando Sáenz-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid (UCM), Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fernan@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/003]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Logic of Graph Conditions Extended with Paths</title>
		<link>https://biblioteca.sistedes.es/articulo/a-logic-of-graph-conditions-extended-with-paths/</link>
		<pubDate>Thu, 08 Sep 2016 12:22:55 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2259</guid>
		<description></description>
		<content><![CDATA[In this paper we tackle the problem of extending the logic of nested graph conditions with paths. This means, for instance, that we may state properties about the existence of paths between some given nodes. As a main contribution, a sound and complete tableau method is defined for reasoning about this kind of properties.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2259</post_id>
		<post_date><![CDATA[2016-09-08 14:22:55]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:22:55]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-logic-of-graph-conditions-extended-with-paths]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2260]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento – NoComercial (by-nc)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper we tackle the problem of extending the logic of nested graph conditions with paths. This means, for instance, that we may state properties about the existence of paths between some given nodes. As a main contribution, a sound and complete tableau method is defined for reasoning about this kind of properties.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Marisa Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad del País Vasco (UPV/EHU), Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[marisa.navarro@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando Orejas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[orejas@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Elvira Pino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pino@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Leen Lambers]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Hasso Plattner Institut. University of Potsdam, Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Leen.Lambers@hpi.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/009]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Polymorphic Types in Erlang Function Specifications</title>
		<link>https://biblioteca.sistedes.es/articulo/polymorphic-types-in-erlang-function-specifications/</link>
		<pubDate>Thu, 08 Sep 2016 12:26:02 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2262</guid>
		<description></description>
		<content><![CDATA[Erlang is a concurrent functional programming language developed by Ericsson, well suited for implementing distributed systems. Although Erlang is dynamically typed, the Dialyzer static analysis tool can be used to extract implicit type information from the programs, both for documentation
purposes and for finding errors that will definitively arise at program execution. Dialyzer is based on the notion of success types, that correspond to safe over-approximations for the semantics of expressions. Erlang also supports user given function specifications (or just specs), that are contracts
providing more information about the semantics of functions. Function specs are useful not only as documentation, but also can be employed by Dialyzer to improve the precision of the analysis. Even though specs can have a polymorphic shape, in practice Dialyzer is not able to exploit all their potential. One reason for that is that extending the notion of success type to a polymorphic setting is not trivial, and several interpretations are possible. In this work [1] we propose a precise formulation for a novel interpretation of function specs as polymorphic success types, and a program transformation that allows us to apply this new interpretation on the call sites of functions with a declared spec. This results on a significant improvement in the number of definite errors that Dialyzer is able to detect.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2262</post_id>
		<post_date><![CDATA[2016-09-08 14:26:02]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:26:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[polymorphic-types-in-erlang-function-specifications]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2263]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Erlang is a concurrent functional programming language developed by Ericsson, well suited for implementing distributed systems. Although Erlang is dynamically typed, the Dialyzer static analysis tool can be used to extract implicit type information from the programs, both for documentation
purposes and for finding errors that will definitively arise at program execution. Dialyzer is based on the notion of success types, that correspond to safe over-approximations for the semantics of expressions. Erlang also supports user given function specifications (or just specs), that are contracts
providing more information about the semantics of functions. Function specs are useful not only as documentation, but also can be employed by Dialyzer to improve the precision of the analysis. Even though specs can have a polymorphic shape, in practice Dialyzer is not able to exploit all their potential. One reason for that is that extending the notion of success type to a polymorphic setting is not trivial, and several interpretations are possible. In this work [1] we propose a precise formulation for a novel interpretation of function specs as polymorphic success types, and a program transformation that allows us to apply this new interpretation on the call sites of functions with a declared spec. This results on a significant improvement in the number of definite errors that Dialyzer is able to detect.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Javier López-Fraguas,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de sistemas Informáticos y Computación. Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fraguas@sip.ucm.es,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Montenegro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de sistemas Informáticos y Computación. Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[montenegro@fdi.ucm.es,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Rodríguez-Hortalá]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de sistemas Informáticos y Computación. Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanrh@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Que Ningún Término Resoluble de Lambda-Valor Se Quede Atrás (resumen)</title>
		<link>https://biblioteca.sistedes.es/articulo/que-ningun-termino-resoluble-de-lambda-valor-se-quede-atras-resumen/</link>
		<pubDate>Thu, 08 Sep 2016 12:29:39 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2265</guid>
		<description></description>
		<content><![CDATA[Este es el resumen de la ponencia en Castellano sobre el artículo titulado "No solvable lambda-value term left behind" publicado por los autores en la revista Logical Methods in Computer Science Vol. 2(2:12) 2016, págs.1–43. La ponencia forma parte del programa de las XVI Jornadas sobre Programación y Lenguajes dentro del V Congreso Español de Informática que tuvo lugar del 13 al 16 de septiembre de 2016 en Salamanca.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2265</post_id>
		<post_date><![CDATA[2016-09-08 14:29:39]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:29:39]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[que-ningun-termino-resoluble-de-lambda-valor-se-quede-atras-resumen]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2266]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este es el resumen de la ponencia en Castellano sobre el artículo titulado "No solvable lambda-value term left behind" publicado por los autores en la revista Logical Methods in Computer Science Vol. 2(2:12) 2016, págs.1–43. La ponencia forma parte del programa de las XVI Jornadas sobre Programación y Lenguajes dentro del V Congreso Español de Informática que tuvo lugar del 13 al 16 de septiembre de 2016 en Salamanca.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Álvaro García-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Reykjavík University, Islandia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alvarog@ru.is]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Nogueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto IMDEA Software Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pablo.nogueira@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/006]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Combining Runtime Checking and Slicing to improve Maude Error Diagnosis</title>
		<link>https://biblioteca.sistedes.es/articulo/combining-runtime-checking-and-slicing-to-improve-maude-error-diagnosis/</link>
		<pubDate>Thu, 08 Sep 2016 12:32:33 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2268</guid>
		<description></description>
		<content><![CDATA[This paper introduces the idea of using assertion checking for enhancing the dynamic slicing of Maude computation traces. Since trace slicing can greatly simplify the size and complexity of the analyzed traces, our methodology can be useful for improving the diagnosis of erroneous Maude
programs. The proposed methodology is based on (i) a logical notation for specifying two types of user-defined assertions that are imposed on execution runs: functional assertions and system assertions; (ii) a runtime checking technique that dynamically tests the assertions and is provably safe in the sense that all errors flagged are definite violations of the specifications; and (iii) a mechanism based on equational least general generalization that automatically derives accurate criteria for slicing from falsified assertions.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2268</post_id>
		<post_date><![CDATA[2016-09-08 14:32:33]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:32:33]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[combining-runtime-checking-and-slicing-to-improve-maude-error-diagnosis]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2269]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper introduces the idea of using assertion checking for enhancing the dynamic slicing of Maude computation traces. Since trace slicing can greatly simplify the size and complexity of the analyzed traces, our methodology can be useful for improving the diagnosis of erroneous Maude
programs. The proposed methodology is based on (i) a logical notation for specifying two types of user-defined assertions that are imposed on execution runs: functional assertions and system assertions; (ii) a runtime checking technique that dynamically tests the assertions and is provably safe in the sense that all errors flagged are definite violations of the specifications; and (iii) a mechanism based on equational least general generalization that automatically derives accurate criteria for slicing from falsified assertions.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Alpuente  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DSIC-ELP, Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alpuente@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Francisco Frechina  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[DSIC-ELP, Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ffrechina@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Julia Sapiña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DSIC-ELP, Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jsapina@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Demis Ballis]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[DIMI, University of Udine, Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[demis.ballis@uniud.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/001]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Reversible Term Rewriting</title>
		<link>https://biblioteca.sistedes.es/articulo/reversible-term-rewriting/</link>
		<pubDate>Thu, 08 Sep 2016 12:35:37 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2271</guid>
		<description></description>
		<content><![CDATA[Essentially, in a reversible programming language, for each forward computation step from state S to state S', there exists a constructive and deterministic method to go backwards from state S' to state S. Besides its theoretical interest, reversible computation is a fundamental concept which is relevant in many different areas like cellular automata, bidirectional program transformation, or quantum computing, to name a few. In this paper, we focus on term rewriting, a computation model that underlies most rule-based programming languages. In general, term rewriting is not reversible, even for injective functions; namely, given a rewrite step t1 → t2 , we do not always have a decidable and deterministic method to get t1 from t2 . Here, we introduce a conservative extension of term rewriting that becomes reversible. Furthermore, we also define a transformation to make a rewrite system reversible using standard term rewriting.
This paper has been published in Naoki Nishida, Adrián Palacios, Germán Vidal. Reversible Term Rewriting. In Delia Kesner and Brigitte Pientka, editors, Proceedings of the First International Conference on Formal Structures for Computation and Deduction, FSCD 2016, June 22-26, 2016,
Porto, Portugal. LIPIcs 52, 28:1–28:18, Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2016.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2271</post_id>
		<post_date><![CDATA[2016-09-08 14:35:37]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:35:37]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[reversible-term-rewriting]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2272]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Essentially, in a reversible programming language, for each forward computation step from state S to state S', there exists a constructive and deterministic method to go backwards from state S' to state S. Besides its theoretical interest, reversible computation is a fundamental concept which is relevant in many different areas like cellular automata, bidirectional program transformation, or quantum computing, to name a few. In this paper, we focus on term rewriting, a computation model that underlies most rule-based programming languages. In general, term rewriting is not reversible, even for injective functions; namely, given a rewrite step t1 → t2 , we do not always have a decidable and deterministic method to get t1 from t2 . Here, we introduce a conservative extension of term rewriting that becomes reversible. Furthermore, we also define a transformation to make a rewrite system reversible using standard term rewriting.
This paper has been published in Naoki Nishida, Adrián Palacios, Germán Vidal. Reversible Term Rewriting. In Delia Kesner and Brigitte Pientka, editors, Proceedings of the First International Conference on Formal Structures for Computation and Deduction, FSCD 2016, June 22-26, 2016,
Porto, Portugal. LIPIcs 52, 28:1–28:18, Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2016.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Naoki Nishida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Graduate School of Information Science, Nagoya University, Japan]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[nishida@is.nagoya-u.ac.jp]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Adrián Palacios  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[MiST, DSIC, Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[apalacios@dsic.upv.es  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Germán Vidal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[MiST, DSIC, Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gvidal@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/011]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Page-Level Webpage Menu Detection</title>
		<link>https://biblioteca.sistedes.es/articulo/page-level-webpage-menu-detection/</link>
		<pubDate>Thu, 08 Sep 2016 12:38:51 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2274</guid>
		<description></description>
		<content><![CDATA[One of the key elements of a website are Web menus, which provide fundamental information about the structure of the own website. For humans, identifying the main menu of a website is a relatively easy task. However, for computer tools identifying the menu is not trivial at all and, in fact, it is still a challenging unsolved problem. From the point of view of crawlers and indexers, menu detection is a valuable technique, because processing the menu allows these tools to immediately find out the structure of the website. Identifying the menu is also essential for website mapping tasks. With the information of the menu, it is possible to build a sitemap that includes the main pages without having to follow all the links. In this work, we propose a novel method for automatic Web menu detection that works at the level of DOM. Our implementation and experiments demonstrate the usefulness of the technique.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2274</post_id>
		<post_date><![CDATA[2016-09-08 14:38:51]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:38:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[page-level-webpage-menu-detection]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2275]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[One of the key elements of a website are Web menus, which provide fundamental information about the structure of the own website. For humans, identifying the main menu of a website is a relatively easy task. However, for computer tools identifying the menu is not trivial at all and, in fact, it is still a challenging unsolved problem. From the point of view of crawlers and indexers, menu detection is a valuable technique, because processing the menu allows these tools to immediately find out the structure of the website. Identifying the menu is also essential for website mapping tasks. With the information of the menu, it is possible to build a sitemap that includes the main pages without having to follow all the links. In this work, we propose a novel method for automatic Web menu detection that works at the level of DOM. Our implementation and experiments demonstrate the usefulness of the technique.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julián Alarte]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación. Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalarte@dsic.upv.es  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ David Insa  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación. Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ dinsa@dsic.upv.es  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[ Josep Silva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación. Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ jsilva@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/022]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Tutorial on Using Dafny to Construct Verified Software</title>
		<link>https://biblioteca.sistedes.es/articulo/a-tutorial-on-using-dafny-to-construct-verified-software/</link>
		<pubDate>Thu, 08 Sep 2016 12:40:33 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2277</guid>
		<description></description>
		<content><![CDATA[This paper is a tutorial for newcomers to the field of automated verification tools, though we assume the reader to be relatively familiar with Hoare-style verification. In this paper, besides introducing the most basic features of the language and verifier Dafny, we place special emphasis on how to use Dafny as an assistant in the development of verified programs. Our main aim is to encourage the software engineering community to make the move towards using formal verification tools.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2277</post_id>
		<post_date><![CDATA[2016-09-08 14:40:33]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:40:33]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-tutorial-on-using-dafny-to-construct-verified-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2278]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper is a tutorial for newcomers to the field of automated verification tools, though we assume the reader to be relatively familiar with Hoare-style verification. In this paper, besides introducing the most basic features of the language and verifier Dafny, we place special emphasis on how to use Dafny as an assistant in the development of verified programs. Our main aim is to encourage the software engineering community to make the move towards using formal verification tools.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Paqui Lucio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[The University of the Basque Country (UPV/EHU)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[paqui.lucio@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/010]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Introduction to Liquid Haskell</title>
		<link>https://biblioteca.sistedes.es/articulo/an-introduction-to-liquid-haskell/</link>
		<pubDate>Thu, 08 Sep 2016 12:42:13 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2280</guid>
		<description></description>
		<content><![CDATA[This paper is a tutorial introducing the underlying technology and the use of the tool Liquid Haskell, a type-checker for the functional language Haskell that can help programmers to verify non-trivial properties of their programs with a low effort.
The first sections introduce the technology of Liquid Types by explaining its principles and summarizing how its type inference algorithm manages to prove properties. The remaining sections present a selection of Haskell examples and show the kind of properties that can be proved with the
system.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2280</post_id>
		<post_date><![CDATA[2016-09-08 14:42:13]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:42:13]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-introduction-to-liquid-haskell]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2281]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper is a tutorial introducing the underlying technology and the use of the tool Liquid Haskell, a type-checker for the functional language Haskell that can help programmers to verify non-trivial properties of their programs with a low effort.
The first sections introduce the technology of Liquid Types by explaining its principles and summarizing how its type inference algorithm manages to prove properties. The remaining sections present a selection of Haskell examples and show the kind of properties that can be proved with the
system.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ricardo Peña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Complutense University of Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ricardo@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/016]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Comparing MapReduce and Pipeline implementations for Counting Triangles</title>
		<link>https://biblioteca.sistedes.es/articulo/comparing-mapreduce-and-pipeline-implementations-for-counting-triangles/</link>
		<pubDate>Thu, 08 Sep 2016 12:45:55 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2283</guid>
		<description></description>
		<content><![CDATA[A common method to define a parallel solution for a computational problem consists in finding a way to use the Divide &amp; Conquer paradigm in order to have processors acting on its own data and scheduled in a parallel fashion. MapReduce is a programming model that follows this paradigm,
and allows for the definition of efficient solutions by both decomposing a problem into steps on subsets of the input data and combining the results of each step to produce final results. Albeit used for the implementation of a wide variety of computational problems, MapReduce performance
can be negatively affected whenever the replication factor grows or the size of the input is larger than the resources available at each processor. In this paper we show an alternative approach to implement the Divide &amp; Conquer paradigm, named dynamic pipeline. The main features of pipeline
are illustrated on a parallel implementation of the well-known problem of counting triangles in a graph. This problem is especially interesting either when the input graph does not fit in memory or is dynamically generated. To evaluate the properties of pipeline, a dynamic pipeline of processes and
an ad-hoc version of MapReduce are implemented in the language Go, exploiting its ability to deal with channels and spawned processes. An empirical evaluation is conducted on graphs of different topologies, sizes, and densities. Observed results suggest that pipeline allows for the implementation of an efficient solution of the problem of counting triangles in a graph, particularly, in dense and large graphs, drastically reducing the execution time with respect to the MapReduce implementation.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2283</post_id>
		<post_date><![CDATA[2016-09-08 14:45:55]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:45:55]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[comparing-mapreduce-and-pipeline-implementations-for-counting-triangles]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[10]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2284]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A common method to define a parallel solution for a computational problem consists in finding a way to use the Divide & Conquer paradigm in order to have processors acting on its own data and scheduled in a parallel fashion. MapReduce is a programming model that follows this paradigm,
and allows for the definition of efficient solutions by both decomposing a problem into steps on subsets of the input data and combining the results of each step to produce final results. Albeit used for the implementation of a wide variety of computational problems, MapReduce performance
can be negatively affected whenever the replication factor grows or the size of the input is larger than the resources available at each processor. In this paper we show an alternative approach to implement the Divide & Conquer paradigm, named dynamic pipeline. The main features of pipeline
are illustrated on a parallel implementation of the well-known problem of counting triangles in a graph. This problem is especially interesting either when the input graph does not fit in memory or is dynamically generated. To evaluate the properties of pipeline, a dynamic pipeline of processes and
an ad-hoc version of MapReduce are implemented in the language Go, exploiting its ability to deal with channels and spawned processes. An empirical evaluation is conducted on graphs of different topologies, sizes, and densities. Observed results suggest that pipeline allows for the implementation of an efficient solution of the problem of counting triangles in a graph, particularly, in dense and large graphs, drastically reducing the execution time with respect to the MapReduce implementation.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Edelmira Pasarella]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Computer Science Department. Universitat Politècnica de Catalunya, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[edelmira@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Maria-Esther Vidal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Bonn & Fraunhofer IAIS, Germany / Universidad Simón Bolívar, Venezuela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[vidal@cs.uni-bonn.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Cristina Zoltan]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Computer Science Department. Universitat Politècnica de Catalunya, Spain / Universidad Internacional de Ciencia y Tecnología, Panamá]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[zoltan@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/013]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Synthesizing Invariants for Arrays (Work in Progress)</title>
		<link>https://biblioteca.sistedes.es/articulo/synthesizing-invariants-for-arrays-work-in-progress/</link>
		<pubDate>Thu, 08 Sep 2016 12:48:52 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2286</guid>
		<description></description>
		<content><![CDATA[Liquid types can be seen as as a computer assisted verification system. Ordinary Hindley-Milner types are qualified by predicates expressing properties. In this way, the programmer may specify the preconditions and postconditions of functions. More importantly, the system infers the types of all the intermediate variables and checks that the verification conditions proving correctness hold. The predicates are currently expressed in a quantifier free decidable logic.
Here, we extend Liquid types with quantified predicates of a decidable logic for arrays, propose a concept of an array refinement type, and provide an inference algorithm for this extension. By applying this ideas to several imperative algorithms dealing with arrays, we have been able to infer
complex invariants.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2286</post_id>
		<post_date><![CDATA[2016-09-08 14:48:52]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:48:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[synthesizing-invariants-for-arrays-work-in-progress]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2287]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Liquid types can be seen as as a computer assisted verification system. Ordinary Hindley-Milner types are qualified by predicates expressing properties. In this way, the programmer may specify the preconditions and postconditions of functions. More importantly, the system infers the types of all the intermediate variables and checks that the verification conditions proving correctness hold. The predicates are currently expressed in a quantifier free decidable logic.
Here, we extend Liquid types with quantified predicates of a decidable logic for arrays, propose a concept of an array refinement type, and provide an inference algorithm for this extension. By applying this ideas to several imperative algorithms dealing with arrays, we have been able to infer
complex invariants.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel Montenegro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Complutense University of Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[montenegro@fdi.ucm.es,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Susana Nieva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Complutense University of Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[nieva@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ricardo Peña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Complutense University of Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ricardo@sip.ucm.es,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Clara Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Complutense University of Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[csegura@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/024]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Processing an Intermediate Representation Written in Lisp</title>
		<link>https://biblioteca.sistedes.es/articulo/processing-an-intermediate-representation-written-in-lisp/</link>
		<pubDate>Thu, 08 Sep 2016 12:51:15 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2289</guid>
		<description></description>
		<content><![CDATA[In the context of designing the verification platform CAVI-ART, we arrived to the need of deciding a textual format for our intermediate representation of programs. After considering several options, we finally decided to use S-expressions for that textual representation, and Common Lisp for processing it in order to obtain the verification conditions. In this paper, we discuss the benefits of this decision. S-expressions are homoiconic, i.e. they can be both considered as data and as code. We exploit this duality, and extensively use the facilities of the Common Lisp environment to make different processing with these textual representations. In particular, using a common compilation scheme we
show that program execution, and verification condition generation, can be seen as two instantiations of the same generic process.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2289</post_id>
		<post_date><![CDATA[2016-09-08 14:51:15]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:51:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[processing-an-intermediate-representation-written-in-lisp]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2290]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In the context of designing the verification platform CAVI-ART, we arrived to the need of deciding a textual format for our intermediate representation of programs. After considering several options, we finally decided to use S-expressions for that textual representation, and Common Lisp for processing it in order to obtain the verification conditions. In this paper, we discuss the benefits of this decision. S-expressions are homoiconic, i.e. they can be both considered as data and as code. We exploit this duality, and extensively use the facilities of the Common Lisp environment to make different processing with these textual representations. In particular, using a common compilation scheme we
show that program execution, and verification condition generation, can be seen as two instantiations of the same generic process.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ricardo Peña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Complutense University of Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ricardo@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Santiago Saavedra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Complutense University of Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[s.saavedra@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[ Jaime Sánchez-Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Complutense University of Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jaime@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/019]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A tool for the automatic generation of logical models of order-sorted first-order theories</title>
		<link>https://biblioteca.sistedes.es/articulo/a-tool-for-the-automatic-generation-of-logical-models-of-order-sorted-first-order-theories/</link>
		<pubDate>Thu, 08 Sep 2016 12:53:40 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2292</guid>
		<description></description>
		<content><![CDATA[Semantics-based program analysis guarantees that the obtained knowledge about focused program features matches the real behaviour of the program. Automation of the analyses requires abstraction mechanisms to approximate the (usually undecidable) program semantics and targeted properties. In this setting, the logical notions of interpretation of a logic language and model of a theory provide an appropriate framework for abstraction in the sense that the corresponding analyses will be sound and, when relying on some decidable theory, amenable for automation. We describe a new tool, AGES, which is able to automatically generate models for order-sorted first-order theories. Such theories are very helpful in the semantic description of most programming languages. The current version of the tool systematically exploits (and relies on) the recently introduced convex domains which are well-suited for representing domains for different sorts; we use them to interpret the ranked symbols of order-sorted signatures and also the (also ranked) predicate symbols in the language by means of appropriately adapted convex matrix interpretations. The system is available as a web application and can be used to give support to users interested in checking properties of software modules provided
that they are able to describe the property as an order-sorted first-order theory whose satisfiability guarantees the property. Examples of such properties are partial correctness, program termination, etc. The paper illustrates the use of the tool by means of simple case studies.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2292</post_id>
		<post_date><![CDATA[2016-09-08 14:53:40]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:53:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-tool-for-the-automatic-generation-of-logical-models-of-order-sorted-first-order-theories]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<category domain="post_tag" nicename="abstraction"><![CDATA[Abstraction]]></category>
		<category domain="post_tag" nicename="logical-models"><![CDATA[Logical models]]></category>
		<category domain="post_tag" nicename="order-sorted-first-order-logic"><![CDATA[Order-sorted first-order logic]]></category>
		<category domain="post_tag" nicename="program-analysis"><![CDATA[Program analysis]]></category>
		<category domain="post_tag" nicename="termination"><![CDATA[termination]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2293]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Semantics-based program analysis guarantees that the obtained knowledge about focused program features matches the real behaviour of the program. Automation of the analyses requires abstraction mechanisms to approximate the (usually undecidable) program semantics and targeted properties. In this setting, the logical notions of interpretation of a logic language and model of a theory provide an appropriate framework for abstraction in the sense that the corresponding analyses will be sound and, when relying on some decidable theory, amenable for automation. We describe a new tool, AGES, which is able to automatically generate models for order-sorted first-order theories. Such theories are very helpful in the semantic description of most programming languages. The current version of the tool systematically exploits (and relies on) the recently introduced convex domains which are well-suited for representing domains for different sorts; we use them to interpret the ranked symbols of order-sorted signatures and also the (also ranked) predicate symbols in the language by means of appropriately adapted convex matrix interpretations. The system is available as a web application and can be used to give support to users interested in checking properties of software modules provided
that they are able to describe the property as an order-sorted first-order theory whose satisfiability guarantees the property. Examples of such properties are partial correctness, program termination, etc. The paper illustrates the use of the tool by means of simple case studies.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Raúl Gutiérrez  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Salvador Lucas  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Patricio Reinoso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/018]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Abstraction, Logical models, Order-sorted first-order logic, Program analysis, Termination]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>How to construct a suite of program slices</title>
		<link>https://biblioteca.sistedes.es/articulo/how-to-construct-a-suite-of-program-slices/</link>
		<pubDate>Thu, 08 Sep 2016 12:55:48 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2295</guid>
		<description></description>
		<content><![CDATA[Program slicing is a technique to extract the part of a program (the slice) that influences or is influenced by a set of variables at a given point. Computing minimal slices is undecidable in the general case. Obtaining the minimal slice of a given program is computationally prohibitive even for very small programs. Hence, no matter what program slicer we use, in general, we cannot be sure that our slices are minimal. This is probably the fundamental reason why no benchmark collection of minimal program slices exists, even though this would be of great interest. In this work, we present the first suite of quasi-minimal slices (i.e., we cannot prove that they are minimal, but we provide technological evidences, based on different techniques, that they probably are). We explain the process of constructing the suite, the methodology and tools that were used, and the obtained results. The suite comes with a collection of Erlang benchmarks together with different slicing criteria and the associated quasi-minimal slices. This suite can be used to evaluate and compare program slicers, but it is particularly useful to develop slicers, because it contains scripts that allow for automatically validating a slicer against the whole suite. Concretely, these scripts produce reports about the impact on recall and precision of any change done during the development of the slicer.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2295</post_id>
		<post_date><![CDATA[2016-09-08 14:55:48]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:55:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[how-to-construct-a-suite-of-program-slices]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2296]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Program slicing is a technique to extract the part of a program (the slice) that influences or is influenced by a set of variables at a given point. Computing minimal slices is undecidable in the general case. Obtaining the minimal slice of a given program is computationally prohibitive even for very small programs. Hence, no matter what program slicer we use, in general, we cannot be sure that our slices are minimal. This is probably the fundamental reason why no benchmark collection of minimal program slices exists, even though this would be of great interest. In this work, we present the first suite of quasi-minimal slices (i.e., we cannot prove that they are minimal, but we provide technological evidences, based on different techniques, that they probably are). We explain the process of constructing the suite, the methodology and tools that were used, and the obtained results. The suite comes with a collection of Erlang benchmarks together with different slicing criteria and the associated quasi-minimal slices. This suite can be used to evaluate and compare program slicers, but it is particularly useful to develop slicers, because it contains scripts that allow for automatically validating a slicer against the whole suite. Concretely, these scripts produce reports about the impact on recall and precision of any change done during the development of the slicer.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Insa  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación. Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[dinsa@dsic.upv.es  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Sergio Pérez  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación. Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ serperu@dsic.upv.es  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[ Josep Silva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación. Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ jsilva@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/021]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Testing of ATL programs from Randomly Generated Ecore Test Models</title>
		<link>https://biblioteca.sistedes.es/articulo/testing-of-atl-programs-from-randomly-generated-ecore-test-models/</link>
		<pubDate>Thu, 08 Sep 2016 12:58:10 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2298</guid>
		<description></description>
		<content><![CDATA[Model transformation testing is crucial to detect incorrect transformations. Buggy transformations can lead to incorrect target models, either violating target meta-model requirements or more complex target model properties. In this paper we present a tool for testing ATL transformations. This tool is an extension of a previously developed tool for testing XML-based languages. With this aim an Ecore to XML Schema transformation is defined which makes to automatically generate random Ecore models possible. These randomly generated Ecore models are used to test ATL transformations. Properties to be tested are specified by OCL constraints, describing input and output conditions on source and target models, respectively.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2298</post_id>
		<post_date><![CDATA[2016-09-08 14:58:10]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:58:10]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[testing-of-atl-programs-from-randomly-generated-ecore-test-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2299]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Model transformation testing is crucial to detect incorrect transformations. Buggy transformations can lead to incorrect target models, either violating target meta-model requirements or more complex target model properties. In this paper we present a tool for testing ATL transformations. This tool is an extension of a previously developed tool for testing XML-based languages. With this aim an Ecore to XML Schema transformation is defined which makes to automatically generate random Ecore models possible. These randomly generated Ecore models are used to test ATL transformations. Properties to be tested are specified by OCL constraints, describing input and output conditions on source and target models, respectively.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús M. Almendros-Jiménez ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dept. of Informatics. University of Almería, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalmen@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Antonio Becerra-Terón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[￼ Dept. of Informatics. University of Almería, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[abecerra@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/012]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Partial Evaluation of Order-sorted Equational Programs modulo Axioms (Trabajo de alto nivel)</title>
		<link>https://biblioteca.sistedes.es/articulo/partial-evaluation-of-order-sorted-equational-programs-modulo-axioms-trabajo-de-alto-nivel/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/partial-evaluation-of-order-sorted-equational-programs-modulo-axioms-trabajo-de-alto-nivel/</guid>
		<description></description>
		<content><![CDATA[Partial evaluation (PE) is a powerful and general program optimization
technique with many successful applications. However, it has never been investigated
in the context of expressive rule-based languages like Maude, CafeOBJ,
OBJ, ASF+SDF, and ELAN, which support: rich type structures with sorts, subsorts
and overloading; and equational rewriting modulo axioms such as commutativity,
associativity–commutativity, and associativity–commutativity–identity. In
this paper, we illustrate the key concepts by showing how they apply to partial
evaluation of expressive rule-based programs written in Maude. Our partial evaluation
scheme is based on an automatic unfolding algorithm that computes term
variants and relies on equational least general generalization for ensuring global
termination. We demonstrate the use of the resulting partial evaluator for program
optimization on several examples where it shows significant speed-ups.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2454</post_id>
		<post_date><![CDATA[2017-06-30 02:55:48]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[partial-evaluation-of-order-sorted-equational-programs-modulo-axioms-trabajo-de-alto-nivel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="equational-rewriting-modulo-axioms"><![CDATA[Equational Rewriting modulo Axioms]]></category>
		<category domain="post_tag" nicename="maude"><![CDATA[Maude]]></category>
		<category domain="post_tag" nicename="partial-evaluation"><![CDATA[Partial Evaluation]]></category>
		<category domain="post_tag" nicename="rewriting-logic"><![CDATA[Rewriting Logic]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Partial evaluation (PE) is a powerful and general program optimization
technique with many successful applications. However, it has never been investigated
in the context of expressive rule-based languages like Maude, CafeOBJ,
OBJ, ASF+SDF, and ELAN, which support: rich type structures with sorts, subsorts
and overloading; and equational rewriting modulo axioms such as commutativity,
associativity–commutativity, and associativity–commutativity–identity. In
this paper, we illustrate the key concepts by showing how they apply to partial
evaluation of expressive rule-based programs written in Maude. Our partial evaluation
scheme is based on an automatic unfolding algorithm that computes term
variants and relies on equational least general generalization for ensuring global
termination. We demonstrate the use of the resulting partial evaluator for program
optimization on several examples where it shows significant speed-ups.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/007]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2856]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498591532.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Alpuente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alpuente@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Angel Cuenca-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[acuenca@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Universidad de Guayaquil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Santiago	Escobar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sescobar@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José Meseguer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[meseguer@cs.uiuc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Illinois at Urbana-Champaign]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Built-in Variant Generation and Unification, and Their Applications in Maude 2.7 (Tutorial)</title>
		<link>https://biblioteca.sistedes.es/articulo/built-in-variant-generation-and-unification-and-their-applications-in-maude-2-7-tutorial/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/built-in-variant-generation-and-unification-and-their-applications-in-maude-2-7-tutorial/</guid>
		<description></description>
		<content><![CDATA[This paper introduces some novel features of Maude 2.7. We have added support for: (i) built-in order-sorted unification modulo associativity, commutativity, and identity, (ii) built-in variant generation, (iii) built-in order-sorted unification modulo a finite variant theory, and (iv) symbolic reachability modulo a finite variant theory.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2455</post_id>
		<post_date><![CDATA[2017-06-30 02:55:49]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[built-in-variant-generation-and-unification-and-their-applications-in-maude-2-7-tutorial]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="associativity-commutativity-and-identity"><![CDATA[associativity commutativity and identity]]></category>
		<category domain="post_tag" nicename="maude"><![CDATA[Maude]]></category>
		<category domain="post_tag" nicename="narrowing"><![CDATA[narrowing]]></category>
		<category domain="post_tag" nicename="order-sorted"><![CDATA[Order-sorted]]></category>
		<category domain="post_tag" nicename="unification"><![CDATA[unification]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper introduces some novel features of Maude 2.7. We have added support for: (i) built-in order-sorted unification modulo associativity, commutativity, and identity, (ii) built-in variant generation, (iii) built-in order-sorted unification modulo a finite variant theory, and (iv) symbolic reachability modulo a finite variant theory.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/010]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2857]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498592286.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Durán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[duran@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Steven Eker]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[eker@csl.sri.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[SRI International]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Santiago	Escobar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sescobar@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Narciso Martí-Oliet]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[narciso@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[José Meseguer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[meseguer@cs.uiuc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Illinois at Urbana-Champaign]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Carolyn Talcott]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[clt@cs.stanford.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[SRI International]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Description and Evaluation of a Generic Design to Integrate CLP and Tabled Execution (Trabajo de alto nivel)</title>
		<link>https://biblioteca.sistedes.es/articulo/description-and-evaluation-of-a-generic-design-to-integrate-clp-and-tabled-execution-trabajo-de-alto-nivel/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/description-and-evaluation-of-a-generic-design-to-integrate-clp-and-tabled-execution-trabajo-de-alto-nivel/</guid>
		<description></description>
		<content><![CDATA[Logic programming systems with tabling and constraints (TCLP, tabled constraint logic
programming) have been shown to be more expressive and in some cases more efficient
than those featuring only either tabling or constraints. Previous implementations of TCLP
systems which use entailment to determine call / answer subsumption did not provide a
simple, uniform, and well-documented interface to facilitate the integration of additional
constraint solvers in existing tabling systems, which would increase the application range of
TCLP. We present the design and an experimental evaluation of Mod TCLP, a framework
which eases this integration. Mod TCLP views the constraints solver as a client of the tabling
system. The tabling system is generic w.r.t. the constraint solver and only requires a clear,
small interface from the latter. We validate our design by integrating four constraint solvers:
a re-engineered version of a previously existing constraint solver for difference constraints,
written in C; the standard versions of Holzbauer’s CLP(Q) and CLP(R), written in Prolog;
and a new constraint solver for equations over finite lattices. We evaluate the performance
of our framework in several benchmarks using the aforementioned constraint solvers. All
the development work and evaluation was done in Ciao Prolog.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2456</post_id>
		<post_date><![CDATA[2017-06-30 02:55:50]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[description-and-evaluation-of-a-generic-design-to-integrate-clp-and-tabled-execution-trabajo-de-alto-nivel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="constraints"><![CDATA[constraints]]></category>
		<category domain="post_tag" nicename="implementation"><![CDATA[Implementation]]></category>
		<category domain="post_tag" nicename="interface"><![CDATA[Interface]]></category>
		<category domain="post_tag" nicename="prolog"><![CDATA[Prolog]]></category>
		<category domain="post_tag" nicename="tabling"><![CDATA[Tabling]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Logic programming systems with tabling and constraints (TCLP, tabled constraint logic
programming) have been shown to be more expressive and in some cases more efficient
than those featuring only either tabling or constraints. Previous implementations of TCLP
systems which use entailment to determine call / answer subsumption did not provide a
simple, uniform, and well-documented interface to facilitate the integration of additional
constraint solvers in existing tabling systems, which would increase the application range of
TCLP. We present the design and an experimental evaluation of Mod TCLP, a framework
which eases this integration. Mod TCLP views the constraints solver as a client of the tabling
system. The tabling system is generic w.r.t. the constraint solver and only requires a clear,
small interface from the latter. We validate our design by integrating four constraint solvers:
a re-engineered version of a previously existing constraint solver for difference constraints,
written in C; the standard versions of Holzbauer’s CLP(Q) and CLP(R), written in Prolog;
and a new constraint solver for equations over finite lattices. We evaluate the performance
of our framework in several benchmarks using the aforementioned constraint solvers. All
the development work and evaluation was done in Ciao Prolog.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/016]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498592587.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498592587.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Joaquín Arias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[joaquin.arias@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid e IMDEA Software]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Carro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mcarro@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid e IMDEA Software]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>FuzzyDES: Fuzzifying DES (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/fuzzydes-fuzzifying-des-trabajo-en-progreso/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/fuzzydes-fuzzifying-des-trabajo-en-progreso/</guid>
		<description></description>
		<content><![CDATA[This paper describes a system implementation of a fuzzy deductive database. Concepts supporting the fuzzy logic programming system BPL are translated into the deductive database system DES. We develop a version of fuzzy Datalog as its query language, where programs and queries are compiled to the DES core Datalog language. Weak unification and weak SLD resolution are adapted to this setting, and extended to allow rules with truth degree annotations. We provide a public implementation in Prolog which is open-source, multiplatform, portable, and in-memory. A database example for a recommender system is used to illustrate some of the features of the system.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2457</post_id>
		<post_date><![CDATA[2017-06-30 02:55:50]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[fuzzydes-fuzzifying-des-trabajo-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="bousiprolog"><![CDATA[Bousi~Prolog]]></category>
		<category domain="post_tag" nicename="datalog-educational-system"><![CDATA[Datalog Educational System]]></category>
		<category domain="post_tag" nicename="fuzzy-datalog"><![CDATA[Fuzzy Datalog]]></category>
		<category domain="post_tag" nicename="fuzzy-logic-programming"><![CDATA[Fuzzy Logic Programming]]></category>
		<category domain="post_tag" nicename="fuzzydes"><![CDATA[FuzzyDES]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper describes a system implementation of a fuzzy deductive database. Concepts supporting the fuzzy logic programming system BPL are translated into the deductive database system DES. We develop a version of fuzzy Datalog as its query language, where programs and queries are compiled to the DES core Datalog language. Weak unification and weak SLD resolution are adapted to this setting, and extended to allow rules with truth degree annotations. We provide a public implementation in Prolog which is open-source, multiplatform, portable, and in-memory. A database example for a recommender system is used to illustrate some of the features of the system.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/004]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498603725.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498603725.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pascual Julián-Iranzo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Pascual.Julian@uclm.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando	Sáenz-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fernan@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Tuning Fuzzy Logic Programs with Symbolic Execution (Trabajo de alto nivel)</title>
		<link>https://biblioteca.sistedes.es/articulo/tuning-fuzzy-logic-programs-with-symbolic-execution-trabajo-de-alto-nivel/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/tuning-fuzzy-logic-programs-with-symbolic-execution-trabajo-de-alto-nivel/</guid>
		<description></description>
		<content><![CDATA[Fuzzy logic programming is a growing declarative paradigm aiming to integrate fuzzy logic into logic programming. One of the most difficult tasks when specifying a fuzzy logic program is determining the right weights for each rule, as well as the most appropriate fuzzy connectives and operators. In this paper, we introduce a symbolic extension of fuzzy logic programs in which some of these parameters can be left unknown, so that the user can easily see the impact of their possible values. Furthermore, given a number of test cases, the most appropriate values for these parameters can be automatically computed.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2458</post_id>
		<post_date><![CDATA[2017-06-30 02:55:50]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[tuning-fuzzy-logic-programs-with-symbolic-execution-trabajo-de-alto-nivel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="fuzzy-logic-programming"><![CDATA[Fuzzy Logic Programming]]></category>
		<category domain="post_tag" nicename="symbolic-execution"><![CDATA[symbolic execution]]></category>
		<category domain="post_tag" nicename="tuning"><![CDATA[tuning]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Fuzzy logic programming is a growing declarative paradigm aiming to integrate fuzzy logic into logic programming. One of the most difficult tasks when specifying a fuzzy logic program is determining the right weights for each rule, as well as the most appropriate fuzzy connectives and operators. In this paper, we introduce a symbolic extension of fuzzy logic programs in which some of these parameters can be left unknown, so that the user can easily see the impact of their possible values. Furthermore, given a number of test cases, the most appropriate values for these parameters can be automatically computed.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/005]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498593173.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498593173.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ginés Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[gines.moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jaime Penabab]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Jaime.Penabab@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Germán Vidal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gvidal@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politecnica de Valencia	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Simulation Tool for tccp Programs (Trabajo de alto nivel)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-simulation-tool-for-tccp-programs-trabajo-de-alto-nivel/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-simulation-tool-for-tccp-programs-trabajo-de-alto-nivel/</guid>
		<description></description>
		<content><![CDATA[The Timed Concurrent Constraint Language tccp is a declarative synchronous concurrent language, particularly suitable for modelling reactive systems. In tccp, agents communicate and synchronise through a global constraint store. It supports a notion of discrete time that allows all non-blocked agents to proceed with their execution simultaneously.
In this paper, we present a modular architecture for the simulation of tccp programs. The tool comprises three main components. First, a set of basic abstract instructions able to model the tccp agent behaviour, the memory model needed to manage the active agents and the state of the store during the execution. Second, the agent interpreter that executes the instructions of the current agent iteratively and calculates the new agents to be executed at the next time instant. Finally, the constraint solver components which are the modules that deal with constraints.
In this paper, we describe the implementation of these components and present an example of a real system modelled in tccp.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2459</post_id>
		<post_date><![CDATA[2017-06-30 02:55:50]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-simulation-tool-for-tccp-programs-trabajo-de-alto-nivel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="abstract-tccp-instructions"><![CDATA[Abstract tccp instructions]]></category>
		<category domain="post_tag" nicename="simulation-tool"><![CDATA[Simulation tool]]></category>
		<category domain="post_tag" nicename="timed-concurrent-constraint-language-tccp"><![CDATA[Timed Concurrent Constraint Language (tccp)]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The Timed Concurrent Constraint Language tccp is a declarative synchronous concurrent language, particularly suitable for modelling reactive systems. In tccp, agents communicate and synchronise through a global constraint store. It supports a notion of discrete time that allows all non-blocked agents to proceed with their execution simultaneously.
In this paper, we present a modular architecture for the simulation of tccp programs. The tool comprises three main components. First, a set of basic abstract instructions able to model the tccp agent behaviour, the memory model needed to manage the active agents and the state of the store during the execution. Second, the agent interpreter that executes the instructions of the current agent iteratively and calculates the new agents to be executed at the next time instant. Finally, the constraint solver components which are the modules that deal with constraints.
In this paper, we describe the implementation of these components and present an example of a real system modelled in tccp.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/009]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498593348.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498593348.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María del Mar Gallardo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[gallardo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Leticia Lavado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[leticialavmu@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Laura Panizo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[laurapanizo@lcc.uma.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Tool for Black-Box Testing in a Multilanguage Verification Platform (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-tool-for-black-box-testing-in-a-multilanguage-verification-platform-trabajo-en-progreso/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-tool-for-black-box-testing-in-a-multilanguage-verification-platform-trabajo-en-progreso/</guid>
		<description></description>
		<content><![CDATA[In the context of the multilanguage verification platform CAVI-ART, we have defined an Intermediate Representation (IR) to which all the source languages are translated. This IR contains both the code and the assertions given by the programmer. Its primary purpose was automatically generating and proving, in a source language independent way, the verification conditions ensuring the program correctness. The logical formulas are sent by the platform to an SMT solver which checks their validity.

In this paper we present a new use of the IR: we transform it into an executable language (that it turns out to be Haskell) and also transform the assertions into executable (Haskell) code. Thanks to that, tests can be run on the transformed program, and bugs can be detected either in the specification assertions or in the code. Moreover, we use the assertions to generate black-box test-cases from them, and also as test oracles. In this way, given the IR of a program, all the process ---namely, test-case generation, test running, and test correctness checking--- is completely automatic. So, thousands of tests can be run with little or none effort. The only burden for the programmer is providing the precondition and the postcondition of the code under test, which anyway should have been provided in advance, since the primary goal was to verify the program.

We discuss the problems we have encountered while implementing this idea, and how we have solved them. In particular, we report on the use of Haskell resources such as GADTs, efficient data structures, and specialized libraries.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2460</post_id>
		<post_date><![CDATA[2017-06-30 02:55:50]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-tool-for-black-box-testing-in-a-multilanguage-verification-platform-trabajo-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="black-box"><![CDATA[black box]]></category>
		<category domain="post_tag" nicename="executable-assertions"><![CDATA[executable assertions]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<category domain="post_tag" nicename="verification-platform"><![CDATA[verification platform]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In the context of the multilanguage verification platform CAVI-ART, we have defined an Intermediate Representation (IR) to which all the source languages are translated. This IR contains both the code and the assertions given by the programmer. Its primary purpose was automatically generating and proving, in a source language independent way, the verification conditions ensuring the program correctness. The logical formulas are sent by the platform to an SMT solver which checks their validity.

In this paper we present a new use of the IR: we transform it into an executable language (that it turns out to be Haskell) and also transform the assertions into executable (Haskell) code. Thanks to that, tests can be run on the transformed program, and bugs can be detected either in the specification assertions or in the code. Moreover, we use the assertions to generate black-box test-cases from them, and also as test oracles. In this way, given the IR of a program, all the process ---namely, test-case generation, test running, and test correctness checking--- is completely automatic. So, thousands of tests can be run with little or none effort. The only burden for the programmer is providing the precondition and the postcondition of the code under test, which anyway should have been provided in advance, since the primary goal was to verify the program.

We discuss the problems we have encountered while implementing this idea, and how we have solved them. In particular, we report on the use of Haskell resources such as GADTs, efficient data structures, and specialized libraries.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/001]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Marta Aracil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[maracil@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pedro García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pegarc03@ucm.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ricardo Peña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ricardo@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Termination Analysis in a Multi-language Verification Platform (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/termination-analysis-in-a-multi-language-verification-platform-trabajo-en-progreso/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/termination-analysis-in-a-multi-language-verification-platform-trabajo-en-progreso/</guid>
		<description></description>
		<content><![CDATA[One aim of the verification platform CAVI-ART is to provide as much assistance as possible to programmers in order to alleviate their verification effort. One of these aids is automatically proving termination of programs, whenever this is possible. Since CAVI-ART is a multi-language platform, the analysis is performed at the level of the platform Intermediate Representation language (IR), to which all source languages are first translated.

We have selected one of the the most successful termination tools, called RANK, and transform our IR-programs to an appropriate input for RANK. There is a fundamental mismatch between the functional, stateless, recursive flavour of our IR, and the automaton-based input of RANK, which is a tool developed for imperative, mutable-state programs. In this paper we show how we have circumvented this problem, and present an algorithm transforming the IR to an automaton. We give some examples of recursive programs that we have successfully proved terminating.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2461</post_id>
		<post_date><![CDATA[2017-06-30 02:55:50]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[termination-analysis-in-a-multi-language-verification-platform-trabajo-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="integer-automata"><![CDATA[integer automata]]></category>
		<category domain="post_tag" nicename="termination-analysis"><![CDATA[Termination analysis]]></category>
		<category domain="post_tag" nicename="verification-platform"><![CDATA[verification platform]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[One aim of the verification platform CAVI-ART is to provide as much assistance as possible to programmers in order to alleviate their verification effort. One of these aids is automatically proving termination of programs, whenever this is possible. Since CAVI-ART is a multi-language platform, the analysis is performed at the level of the platform Intermediate Representation language (IR), to which all source languages are first translated.

We have selected one of the the most successful termination tools, called RANK, and transform our IR-programs to an appropriate input for RANK. There is a fundamental mismatch between the functional, stateless, recursive flavour of our IR, and the automaton-based input of RANK, which is a tool developed for imperative, mutable-state programs. In this paper we show how we have circumvented this problem, and present an algorithm transforming the IR to an automaton. We give some examples of recursive programs that we have successfully proved terminating.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/014]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499160980.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jakub Holubanský]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jakubhol@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Álvaro Mínguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[alvaming@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ricardo Peña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ricardo@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Type Checking and Testing of SPARQL Queries (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/type-checking-and-testing-of-sparql-queries-trabajo-en-progreso/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/type-checking-and-testing-of-sparql-queries-trabajo-en-progreso/</guid>
		<description></description>
		<content><![CDATA[In this paper we describe a property-based testing tool for SPARQL. The tool randomly generates test cases in the form of instances of an ontology. The tool checks the well typed-ness of the SPARQL query as well as the consistency of the test cases with the ontology axioms. With this aim, a type system has been defined for SPARQL. Test cases are after used to execute queries. The output of the queries are tested with a Boolean property which is defined in terms of membership of ontology individuals to classes. The testing tool reports counterexamples when the Boolean property is not satisfied.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2462</post_id>
		<post_date><![CDATA[2017-06-30 02:55:50]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[type-checking-and-testing-of-sparql-queries-trabajo-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="semantic-web"><![CDATA[Semantic Web]]></category>
		<category domain="post_tag" nicename="sparql"><![CDATA[SPARQL]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<category domain="post_tag" nicename="type-systems"><![CDATA[Type Systems]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper we describe a property-based testing tool for SPARQL. The tool randomly generates test cases in the form of instances of an ontology. The tool checks the well typed-ness of the SPARQL query as well as the consistency of the test cases with the ontology axioms. With this aim, a type system has been defined for SPARQL. Test cases are after used to execute queries. The output of the queries are tested with a Boolean property which is defined in terms of membership of ontology individuals to classes. The testing tool reports counterexamples when the Boolean property is not satisfied.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/002]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498593875.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498593875.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús M. Almendros-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalmen@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Becerra-Terón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[abecerra@ual.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>FSA-SPARQL: Fuzzy Queries in SPARQL (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/fsa-sparql-fuzzy-queries-in-sparql-trabajo-en-progreso/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/fsa-sparql-fuzzy-queries-in-sparql-trabajo-en-progreso/</guid>
		<description></description>
		<content><![CDATA[SPARQL has been adopted as query language for the Semantic Web. RDF and OWL have been also established as vocabularies to describe ontologies in this setting. While RDF/OWL/SPARQL have been designed for querying crisp information, some contexts require to manage uncertainty, vagueness and imprecise knowledge. In this paper we propose a SPARQL extension, called FSA-SPARQL (Fuzzy Sets and Aggregators based SPARQL) in which queries can involve different fuzzy connectives and (aggregation) operators. The language has been implemented as an extension of the ARQ Jena SPARQL engine and it is equipped with a Web tool from which queries can be executed on-line.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2463</post_id>
		<post_date><![CDATA[2017-06-30 02:55:51]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[fsa-sparql-fuzzy-queries-in-sparql-trabajo-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="fuzzy-logic"><![CDATA[Fuzzy Logic]]></category>
		<category domain="post_tag" nicename="semantic-web"><![CDATA[Semantic Web]]></category>
		<category domain="post_tag" nicename="sparql"><![CDATA[SPARQL]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[SPARQL has been adopted as query language for the Semantic Web. RDF and OWL have been also established as vocabularies to describe ontologies in this setting. While RDF/OWL/SPARQL have been designed for querying crisp information, some contexts require to manage uncertainty, vagueness and imprecise knowledge. In this paper we propose a SPARQL extension, called FSA-SPARQL (Fuzzy Sets and Aggregators based SPARQL) in which queries can involve different fuzzy connectives and (aggregation) operators. The language has been implemented as an extension of the ARQ Jena SPARQL engine and it is equipped with a Web tool from which queries can be executed on-line.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/006]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498601637.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498601637.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús M. Almendros-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalmen@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Becerra-Terón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[abecerra@ual.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ginés Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gines.moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Use of logical models for proving operational termination in general logics (Tutorial)</title>
		<link>https://biblioteca.sistedes.es/articulo/use-of-logical-models-for-proving-operational-termination-in-general-logics-tutorial/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/use-of-logical-models-for-proving-operational-termination-in-general-logics-tutorial/</guid>
		<description></description>
		<content><![CDATA[A declarative programming language is based on some logic L and its operational semantics is given by a proof calculus which is often presented in a natural deduction style by means of inference rules. Declarative programs are theories S of L and executing a program is proving goals G in the inference system I(S) associated to S as a particularization of the inference system of the logic. The usual soundness assumption for L implies that every model M of S also satisfies G. In this setting, the operational termination of a declarative program is quite naturally defined as the absence of infinite proof trees in the inference system I(S). Proving operational termination of declarative programs often involves two main ingredients: (i) the generation of logical models M to abstract the program execution (i.e., the provability of specific goals in I(S)), and (ii) the use of well-founded relations to guarantee the absence of infinite branches in proof trees and hence of infinite proof trees, possibly taking into account the information about provability encoded by M. In this paper we show how to deal with (i) and (ii) in a uniform way. The main point is the synthesis of logical models where well-foundedness is a side requirement for some specific predicate symbols.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2464</post_id>
		<post_date><![CDATA[2017-06-30 02:55:51]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[use-of-logical-models-for-proving-operational-termination-in-general-logics-tutorial]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="abstraction"><![CDATA[Abstraction]]></category>
		<category domain="post_tag" nicename="logical-models"><![CDATA[Logical models]]></category>
		<category domain="post_tag" nicename="operational-termination"><![CDATA[Operational Termination]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A declarative programming language is based on some logic L and its operational semantics is given by a proof calculus which is often presented in a natural deduction style by means of inference rules. Declarative programs are theories S of L and executing a program is proving goals G in the inference system I(S) associated to S as a particularization of the inference system of the logic. The usual soundness assumption for L implies that every model M of S also satisfies G. In this setting, the operational termination of a declarative program is quite naturally defined as the absence of infinite proof trees in the inference system I(S). Proving operational termination of declarative programs often involves two main ingredients: (i) the generation of logical models M to abstract the program execution (i.e., the provability of specific goals in I(S)), and (ii) the use of well-founded relations to guarantee the absence of infinite branches in proof trees and hence of infinite proof trees, possibly taking into account the information about provability encoded by M. In this paper we show how to deal with (i) and (ii) in a uniform way. The main point is the synthesis of logical models where well-foundedness is a side requirement for some specific predicate symbols.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/015]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498601913.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498601913.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Lucas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[slucas@dsic.upv.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Some applications of context-sensitive rewriting (Tutorial)</title>
		<link>https://biblioteca.sistedes.es/articulo/some-applications-of-context-sensitive-rewriting-tutorial/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/some-applications-of-context-sensitive-rewriting-tutorial/</guid>
		<description></description>
		<content><![CDATA[The appropriate selection of the arguments of functions that can be evaluated in function calls improves the evaluation of such calls in a number of different ways: efficiency, speed, termination behavior, etc. This is essential in the conditional if-then-else operator. Other operators like sequencing (;) or choice (+) that are used in concurrent and/or imperative languages require a similar treatment. The (lazy) list constructor 'cons' of functional languages is another well-known example. At the syntactic level we can specify this by just associating a set mu(f) of indices of evaluable arguments to each function symbol 'f' by means of a mapping mu which we call a replacement map. For instance, we let mu(if-then-else)={1} to specify that only the boolean argument 'b' of a conditional expression (if b then e else e') is necessarily evaluated. We can write mu(;)={1} to avoid computations on S2 in a sequence S1;S2, and mu(+)={} to say that processes should not be executed as part of a choice expression. In the realm of term rewriting, context-sensitive rewriting is the restriction of rewriting that arises when these syntactic replacement restrictions are taken into account. It has been used to improve the termination behavior of reduction-based computation systems and programs. It has been shown useful as an operational notion to model or simulate the executions of various formalisms and calculi. Some computational properties of context-sensitive rewriting (remarkably termination) have been used to characterize or verify computational properties of important rewriting strategies like innermost, outermost, demand-driven, and lazy rewriting. Context-sensitive rewriting has also been shown useful to develop verification techniques and tools for variants of rewriting like order-sorted or conditional rewriting. Consequently, it is also useful for analyzing computational properties of programs written in sophisticated rewriting-based programming languages such as OBJ*, CafeOBJ, Maude, Elan, etc., where related language constructions are used. This paper provides an overview of the theory of context-sensitive rewriting and some of its applications.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2465</post_id>
		<post_date><![CDATA[2017-06-30 02:55:51]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[some-applications-of-context-sensitive-rewriting-tutorial]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="context-sensitive-rewriting"><![CDATA[context-sensitive rewriting]]></category>
		<category domain="post_tag" nicename="infinitary-normalization"><![CDATA[infinitary normalization]]></category>
		<category domain="post_tag" nicename="normalization"><![CDATA[normalization]]></category>
		<category domain="post_tag" nicename="replacement-restrictions"><![CDATA[replacement restrictions]]></category>
		<category domain="post_tag" nicename="rewriting-semantics"><![CDATA[rewriting semantics]]></category>
		<category domain="post_tag" nicename="termination"><![CDATA[termination]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The appropriate selection of the arguments of functions that can be evaluated in function calls improves the evaluation of such calls in a number of different ways: efficiency, speed, termination behavior, etc. This is essential in the conditional if-then-else operator. Other operators like sequencing (;) or choice (+) that are used in concurrent and/or imperative languages require a similar treatment. The (lazy) list constructor 'cons' of functional languages is another well-known example. At the syntactic level we can specify this by just associating a set mu(f) of indices of evaluable arguments to each function symbol 'f' by means of a mapping mu which we call a replacement map. For instance, we let mu(if-then-else)={1} to specify that only the boolean argument 'b' of a conditional expression (if b then e else e') is necessarily evaluated. We can write mu(;)={1} to avoid computations on S2 in a sequence S1;S2, and mu(+)={} to say that processes should not be executed as part of a choice expression. In the realm of term rewriting, context-sensitive rewriting is the restriction of rewriting that arises when these syntactic replacement restrictions are taken into account. It has been used to improve the termination behavior of reduction-based computation systems and programs. It has been shown useful as an operational notion to model or simulate the executions of various formalisms and calculi. Some computational properties of context-sensitive rewriting (remarkably termination) have been used to characterize or verify computational properties of important rewriting strategies like innermost, outermost, demand-driven, and lazy rewriting. Context-sensitive rewriting has also been shown useful to develop verification techniques and tools for variants of rewriting like order-sorted or conditional rewriting. Consequently, it is also useful for analyzing computational properties of programs written in sophisticated rewriting-based programming languages such as OBJ*, CafeOBJ, Maude, Elan, etc., where related language constructions are used. This paper provides an overview of the theory of context-sensitive rewriting and some of its applications.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/008]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498602104.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498602104.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Lucas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[slucas@dsic.upv.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards a formal framework for analyzing stream processing systems in Maude (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-a-formal-framework-for-analyzing-stream-processing-systems-in-maude-trabajo-en-progreso/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-a-formal-framework-for-analyzing-stream-processing-systems-in-maude-trabajo-en-progreso/</guid>
		<description></description>
		<content><![CDATA[With the rise of Big Data technologies, distributed stream processing systems (SPS) have gained popularity in the last years. Among these systems Spark Streaming stands out as a particularly attractive option, with a growing adoption in the industry, so we will consider in particular some features of SPS in Spark Streaming. Maude is a high-performance logical framework where other systems can be easily specified and executed. In this paper we show how a Maude specification of Spark Streaming would allow developers to analyze and prove properties on their programs.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2466</post_id>
		<post_date><![CDATA[2017-06-30 02:55:51]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-a-formal-framework-for-analyzing-stream-processing-systems-in-maude-trabajo-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="maude"><![CDATA[Maude]]></category>
		<category domain="post_tag" nicename="model-checking"><![CDATA[Model checking]]></category>
		<category domain="post_tag" nicename="stream-processing-systems"><![CDATA[Stream processing systems]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[With the rise of Big Data technologies, distributed stream processing systems (SPS) have gained popularity in the last years. Among these systems Spark Streaming stands out as a particularly attractive option, with a growing adoption in the industry, so we will consider in particular some features of SPS in Spark Streaming. Maude is a high-performance logical framework where other systems can be easily specified and executed. In this paper we show how a Maude specification of Spark Streaming would allow developers to analyze and prove properties on their programs.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/003]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498602286.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498602286.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Adrián Riesco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ariesco@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miguel Palomino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[miguelpt@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Narciso Martí-Oliet]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[narciso@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A type derivation system for Erlang (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-type-derivation-system-for-erlang-trabajo-en-progreso/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-type-derivation-system-for-erlang-trabajo-en-progreso/</guid>
		<description></description>
		<content><![CDATA[Erlang is a dynamically typed concurrent functional language of increasing interest in industry and academy. Official Erlang distributions come equipped with Dialyzer, a useful static analysis tool able to anticipate runtime errors by inferring so-called success types, which are overapproximations to the real semantics of expressions. However, Dialyzer exhibits two main weaknesses: on the practical side, its ability to deal with functions that are typically polymorphic is rather poor; and on the theoretical side, a fully developed theory for its underlying type system –comparable to, say, Hindley-Milner system– does not seem to exist, something that we consider a regrettable circumstance. This work in progress is the starting point of a medium-term project aiming at improving both aspects, so that at its end we should have proposed a full type system able to infer polymorphic success types for Erlang programs, accompanied by solid theoretical foundations including adequateness results for the type system. In this first step we only provide a derivation system of monomorphic success types for Erlang, along with correctness results with respect to a suitable semantics for the language.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2467</post_id>
		<post_date><![CDATA[2017-06-30 02:55:51]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-type-derivation-system-for-erlang-trabajo-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="dialyzer"><![CDATA[Dialyzer]]></category>
		<category domain="post_tag" nicename="erlang"><![CDATA[Erlang]]></category>
		<category domain="post_tag" nicename="program-semantics"><![CDATA[program semantics]]></category>
		<category domain="post_tag" nicename="success-types"><![CDATA[Success types]]></category>
		<category domain="post_tag" nicename="type-systems"><![CDATA[Type Systems]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Erlang is a dynamically typed concurrent functional language of increasing interest in industry and academy. Official Erlang distributions come equipped with Dialyzer a useful static analysis tool able to anticipate runtime errors by inferring so-called success types, which are overapproximations to the real semantics of expressions. However, Dialyzer exhibits two main weaknesses: on the practical side, its ability to deal with functions that are typically polymorphic is rather poor; and on the theoretical side, a fully developed theory for its underlying type system –comparable to, say, Hindley-Milner system– does not seem to exist, something that we consider a regrettable circumstance. This work in progress is the starting point of a medium-term project aiming at improving both aspects, so that at its end we should have proposed a full type system able to infer polymorphic success types for Erlang programs, accompanied by solid theoretical foundations including adequateness results for the type system. In this first step we only provide a derivation system of monomorphic success types for Erlang, along with correctness results with respect to a suitable semantics for the language.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/018]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498602481.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498602481.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Javier López-Fraguas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fraguas@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Montenegro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[montenegro@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Gorka Suárez-García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gorka.suarez@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evaluación de Requisitos de Seguridad con MBASafe conforme a la norma EN 50128 (Trabajo de alto nivel)</title>
		<link>https://biblioteca.sistedes.es/articulo/evaluacion-de-requisitos-de-seguridad-con-mbasafe-conforme-a-la-norma-en-50128-trabajo-de-alto-nivel/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/evaluacion-de-requisitos-de-seguridad-con-mbasafe-conforme-a-la-norma-en-50128-trabajo-de-alto-nivel/</guid>
		<description></description>
		<content><![CDATA[According to EN 50129, manufacturers of rail vehicles shall justify via a safety case that their vehicles are adequately safe for their intended applications. MBASafe is a recently proposed and potentially innovative design and verification process. In the presence of compelling arguments concerning its adequacy as process evidence, MBASafe could support the safety claims within the required safety cases.
In this paper, we contribute to partially justify the adequacy of MBASafe to act as process evidence. To do that, we first manually check if MBASafe includes EN 50128-compliant process elements, then we model MBASafe in compliance with Software Process Engineering Meta-model 2.0, then, we derive process-based arguments from the MBASafe process model by using MDSafeCer, the recently introduced Model Driven Safety Certification method. By doing so, we provide a twofold contribution: we further validate MDSafeCer in the rail domain and we strengthen MBASafe.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2468</post_id>
		<post_date><![CDATA[2017-06-30 02:55:51]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evaluacion-de-requisitos-de-seguridad-con-mbasafe-conforme-a-la-norma-en-50128-trabajo-de-alto-nivel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="en-5012x"><![CDATA[EN 5012x]]></category>
		<category domain="post_tag" nicename="model-driven-safety-certication"><![CDATA[model-driven safety certication]]></category>
		<category domain="post_tag" nicename="process-assessment"><![CDATA[process assessment]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[According to EN 50129, manufacturers of rail vehicles shall justify via a safety case that their vehicles are adequately safe for their intended applications. MBASafe is a recently proposed and potentially innovative design and verification process. In the presence of compelling arguments concerning its adequacy as process evidence, MBASafe could support the safety claims within the required safety cases.
In this paper, we contribute to partially justify the adequacy of MBASafe to act as process evidence. To do that, we first manually check if MBASafe includes EN 50128-compliant process elements, then we model MBASafe in compliance with Software Process Engineering Meta-model 2.0, then, we derive process-based arguments from the MBASafe process model by using MDSafeCer, the recently introduced Model Driven Safety Certification method. By doing so, we provide a twofold contribution: we further validate MDSafeCer in the rail domain and we strengthen MBASafe. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/013]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498603878.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498603878.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Barbara Gallina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[barbara.gallina@mdh.se]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Malardalen University]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Elena Gómez-Martínez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[egomez@babel.ls.fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Clara Benac Earle]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[cbenac@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards the model-based predictive performance analysis of Cloud adaptive systems with e-Motions (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-the-model-based-predictive-performance-analysis-of-cloud-adaptive-systems-with-e-motions-trabajo-en-progreso/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-the-model-based-predictive-performance-analysis-of-cloud-adaptive-systems-with-e-motions-trabajo-en-progreso/</guid>
		<description></description>
		<content><![CDATA[We use graph transformation to define an adaptive component model, what allows us to carry on predictive analyses on dynamic architectures through simulations. Specifically, we build on the e-Motions definition of the Palladio component model, and then specify adaptation mechanisms as generic adaptation rules. We illustrate our approach with rules modelling the increase in the number of CPU replicas used by a component, and the distribution of works between processors, reacting, respectively, to saturated queues or response time constraints violations. We evaluate alternative scenarios by analysing their performance, and discuss on its consequences in practice.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2469</post_id>
		<post_date><![CDATA[2017-06-30 02:55:51]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-the-model-based-predictive-performance-analysis-of-cloud-adaptive-systems-with-e-motions-trabajo-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="domain-specific-languages"><![CDATA[Domain Specific Languages]]></category>
		<category domain="post_tag" nicename="e-motions"><![CDATA[e-Motions]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<category domain="post_tag" nicename="performance-analysis"><![CDATA[performance analysis]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We use graph transformation to define an adaptive component model, what allows us to carry on predictive analyses on dynamic architectures through simulations. Specifically, we build on the e-Motions definition of the Palladio component model, and then specify adaptation mechanisms as generic adaptation rules. We illustrate our approach with rules modelling the increase in the number of CPU replicas used by a component, and the distribution of works between processors, reacting, respectively, to saturated queues or response time constraints violations. We evaluate alternative scenarios by analysing their performance, and discuss on its consequences in practice.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/012]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498602918.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498602918.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Patricia de Oliveira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[patricia@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francisco Durán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[duran@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ernesto Pimentel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ernesto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards the Automatic Verification of QCSP tractability results (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-the-automatic-verication-of-qcsp-tractability-results-trabajo-en-progreso/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-the-automatic-verication-of-qcsp-tractability-results-trabajo-en-progreso/</guid>
		<description></description>
		<content><![CDATA[We deal with the quantied constraint satisfaction problem (QCSP) which consists in deciding, given an structure and a first-order sentence built from atoms, with conjunction and quantication, whether or not the sentence is true on the structure. We study a known proof system which has been used to derive QCSP tractability results. Our contribution is to formalize this proof system into an automatically veried theory, so that it can be used (in a near future) as a basis for automatically verify tractability results.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2470</post_id>
		<post_date><![CDATA[2017-06-30 02:55:51]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-the-automatic-verication-of-qcsp-tractability-results-trabajo-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="automatic-verification"><![CDATA[Automatic verification]]></category>
		<category domain="post_tag" nicename="dafny"><![CDATA[Dafny]]></category>
		<category domain="post_tag" nicename="inductive-predicate"><![CDATA[inductive predicate]]></category>
		<category domain="post_tag" nicename="proof-system"><![CDATA[proof system]]></category>
		<category domain="post_tag" nicename="tractability-results"><![CDATA[tractability results]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We deal with the quantied constraint satisfaction problem (QCSP) which consists in deciding, given an structure and a rst-order sentence built from atoms, with conjunction and quantication, whether or not the sentence is true on the structure. We study a known proof system which has been used to derive QCSP tractability results. Our contribution is to formalize this proof system into an automatically veried theory, so that it can be used (in a near future) as a basis for automatically verify tractability results.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/017]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498603120.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498603120.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alex Abuin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aabuin@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Ik4-Ikerlan Research Center	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Hubie Chen]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[hubie.chen@ehu.eus	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad del País Vasco and IKERBASQUE Basque Foundation for Science]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Montserrat Hermo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[montserrat.hermo@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad del País Vasco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Paqui Lucio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[paqui.lucio@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad del País Vasco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A characterisation of reliability tools for Software Defined Networks (Trabajo original)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-characterisation-of-reliability-tools-for-software-defined-networks-trabajo-original/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-characterisation-of-reliability-tools-for-software-defined-networks-trabajo-original/</guid>
		<description></description>
		<content><![CDATA[Software Defined Network (SDN) is a new paradigm in networking that introduces great flexibility, allowing the dynamic configuration of parts of the network through centralised programming. SDN has been successfully applied in field networks, and is now being applied to wireless and mobile networks, generating Software Defined Mobile/Wireless networks (SDWNs). SDN can be also combined with Network Function Virtualization (NFV) producing a software network in which the specific hardware is replaced by general purpose computing equipment running SDN and NFV software solutions. This highly programmable and flexible network introduces many challenges from the point of view of reliability (or robustness), and operators need to ensure the same level of confidence as in previous, less flexible deployments. This paper provides a first study of the current tools used to analyse the reliability of SDNs before deployment and/or during the exploitation of the network. Most of these tools offer some kind of automatic verification, supported by algorithms based on formal methods, but they do not differentiate between fixed and mobile/wireless networks. In the paper we provide a number of classifications of the tools to make this selection easier for potential users, and we also identify promising research areas where more effort needs to be made.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2471</post_id>
		<post_date><![CDATA[2017-06-30 02:55:51]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-characterisation-of-reliability-tools-for-software-defined-networks-trabajo-original]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="communication-networks"><![CDATA[Communication Networks]]></category>
		<category domain="post_tag" nicename="model-checking"><![CDATA[Model checking]]></category>
		<category domain="post_tag" nicename="reliability"><![CDATA[Reliability]]></category>
		<category domain="post_tag" nicename="runtime"><![CDATA[Runtime]]></category>
		<category domain="post_tag" nicename="software-defined-network"><![CDATA[Software Defined Network]]></category>
		<category domain="post_tag" nicename="verification"><![CDATA[Verification]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Software Defined Network (SDN) is a new paradigm in networking that introduces great flexibility, allowing the dynamic configuration of parts of the network through centralised programming. SDN has been successfully applied in field networks, and is now being applied to wireless and mobile networks, generating Software Defined Mobile/Wireless networks (SDWNs). SDN can be also combined with Network Function Virtualization (NFV) producing a software network in which the specific hardware is replaced by general purpose computing equipment running SDN and NFV software solutions. This highly programmable and flexible network introduces many challenges from the point of view of reliability (or robustness), and operators need to ensure the same level of confidence as in previous, less flexible deployments. This paper provides a first study of the current tools used to analyse the reliability of SDNs before deployment and/or during the exploitation of the network. Most of these tools offer some kind of automatic verification, supported by algorithms based on formal methods, but they do not differentiate between fixed and mobile/wireless networks. In the paper we provide a number of classifications of the tools to make this selection easier for potential users, and we also identify promising research areas where more effort needs to be made.
]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/011]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498603312.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498603312.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Leticia Lavado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[leticialavmu@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Laura Panizo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[laurapanizo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[María del Mar Gallardo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gallardo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Pedro Merino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[pedro@lcc.uma.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards a Social End-user Composition of Services</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-a-social-end-user-composition-of-services/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:00 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-a-social-end-user-composition-of-services/</guid>
		<description></description>
		<content><![CDATA[Nowadays, end-users’ environment is plenty of services that support their life style, and involving them in the process of service creation can allows them to benefit from a cheaper, faster, and better service provisioning. There are already tools targeted to the authoring and
consumption of services. However these tools consider end-users as isolated individuals, missing the potential that their social environment can bring to them. In this paper, we investigate how social networks can be used to improve the authoring and consumption of services by end-users. We propose a social network of service compositions as a valuable
mechanism to share knowledge among end-users in order to improve their skills in composing new services. In addition, we analyse the underlying relationships created among service compositions in order to provide end-users with an intuitive way of browsing them.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2472</post_id>
		<post_date><![CDATA[2017-06-30 02:56:00]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:00]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-a-social-end-user-composition-of-services]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Nowadays, end-users’ environment is plenty of services that support their life style, and involving them in the process of service creation can allows them to benefit from a cheaper, faster, and better service provisioning. There are already tools targeted to the authoring and
consumption of services. However these tools consider end-users as isolated individuals, missing the potential that their social environment can bring to them. In this paper, we investigate how social networks can be used to improve the authoring and consumption of services by end-users. We propose a social network of service compositions as a valuable
mechanism to share knowledge among end-users in order to improve their skills in composing new services. In addition, we analyse the underlying relationships created among service compositions in order to provide end-users with an intuitive way of browsing them.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/001]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496868434.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496868434.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Valderas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pvalderas@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Victoria Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[vtorres@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pele@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Kopernik: Modeling Business Processes for Digital Customers</title>
		<link>https://biblioteca.sistedes.es/articulo/kopernik-modeling-business-processes-for-digital-customers/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:00 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/kopernik-modeling-business-processes-for-digital-customers/</guid>
		<description></description>
		<content><![CDATA[This paper presents the Kopernik approach for modeling business processes for digital customers. These processes require a high degree of flexibility in the execution of their tasks or actions. We achieve this by using an artifact-centric approach to process modeling and the
use of condition-action rules. The processes modeled following Kopernik can then be implemented in an existing commercial tool, Balandra.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2473</post_id>
		<post_date><![CDATA[2017-06-30 02:56:00]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:00]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[kopernik-modeling-business-processes-for-digital-customers]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>1</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper presents the Kopernik approach for modeling business processes for digital customers. These processes require a high degree of flexibility in the execution of their tasks or actions. We achieve this by using an artifact-centric approach to process modeling and the
use of condition-action rules. The processes modeled following Kopernik can then be implemented in an existing commercial tool, Balandra.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/002]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496924157.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496924157.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Montserrat Estañol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[estanyol@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya, Barcelona - SIRIS Lab, Research Division of SIRIS Academic, Barcelona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[manuel.castro@leelo.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Léelo - Process as a service, Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Silvia Díaz-Montenegro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sylvia.diazm@leelo.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Léelo - Process as a service, Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ernest Teniente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[teniente@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya, Barcelona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>M-eRoDes: una plataforma de servicios para la creación y evaluación automática de actividades de aprendizaje colaborativo</title>
		<link>https://biblioteca.sistedes.es/articulo/m-erodes-una-plataforma-de-servicios-para-la-creacion-y-evaluacion-automatica-de-actividades-de-aprendizaje-colaborativo/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:00 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/m-erodes-una-plataforma-de-servicios-para-la-creacion-y-evaluacion-automatica-de-actividades-de-aprendizaje-colaborativo/</guid>
		<description></description>
		<content><![CDATA[En este trabajo se presenta una plataforma de servicios de e-learning, llamada M-eRoDes, que ofrece funcionalidad para crear y evaluar automáticamente actividades de enseñanza-aprendizaje basadas en metodologías activas. La plataforma facilita que los estudiantes
aprendan creando sus propios recursos (audiovisuales) de aprendizaje y a su vez enseñen con estos mismos recursos a sus compañeros. Además, M-eRoDes integra un novedoso sistema de evaluación basado en modelos de conocimiento y semántica.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2474</post_id>
		<post_date><![CDATA[2017-06-30 02:56:00]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:00]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[m-erodes-una-plataforma-de-servicios-para-la-creacion-y-evaluacion-automatica-de-actividades-de-aprendizaje-colaborativo]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>2</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="aprendizaje-online"><![CDATA[aprendizaje online]]></category>
		<category domain="post_tag" nicename="metodologias-activas"><![CDATA[metodologías activas]]></category>
		<category domain="post_tag" nicename="representacion-del-conocimiento"><![CDATA[representación del conocimiento]]></category>
		<category domain="post_tag" nicename="serviciosaplicaciones-web"><![CDATA[Servicios/aplicaciones Web]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este trabajo se presenta una plataforma de servicios de e-learning, llamada M-eRoDes, que ofrece funcionalidad para crear y evaluar automáticamente actividades de enseñanza-aprendizaje basadas en metodologías activas. La plataforma facilita que los estudiantes
aprendan creando sus propios recursos (audiovisuales) de aprendizaje y a su vez ense~nen con estos mismos recursos a sus compa~neros. Además, M-eRoDes integra un novedoso sistema de evaluación basado en modelos de conocimiento y semántica.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/003]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496924527.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496924527.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Álvarez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alvaper@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sandra Baldassarri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sandra@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza, Españaa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Predicciones en Procesos de Negocio Declarativos</title>
		<link>https://biblioteca.sistedes.es/articulo/predicciones-en-procesos-de-negocio-declarativos/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/predicciones-en-procesos-de-negocio-declarativos/</guid>
		<description></description>
		<content><![CDATA[La generación de predicciones sobre instancias de procesos de negocio permite anticipar problemas, evitar el incumplimiento de restricciones de una manera proactiva, y tomar decisiones sobre prioridades y restricciones al enfrentarse a eventos inesperados, e.g., retrasos. Sin embargo, elaborar una predicción es una tarea compleja en la mayoría de los casos ya que se deben tener en cuenta múltiples instancias y recursos, es necesario adaptar dichas predicciones a circunstancias cambiantes, y hay que tener en cuenta distintas dimensiones, no sólo el tiempo. En este contexto, el presente trabajo propone una propuesta novedosa para generar predicciones sobre un conjunto de instancias en ejecución relacionadas con un modelo declarativo de un proceso de negocio. Dicha propuesta consiste en generar un plan de ejecución optimizado a partir del modelo declarativo y del estado de las instancias en ejecución. Tras ello, la predicción se genera evaluando la función que se desea predecir sobre el plan de ejecución generado. La presente propuesta ha sido evaluada utilizando un modelo de proceso de un escenario real que incluye restricciones temporales, de datos, de recursos y de control-flow que lo dotan de una alta complejidad. Los prometedores resultados obtenidos alientan a continuar los trabajos en escenarios con características diferentes que permitan extender la validez de la propuesta.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2475</post_id>
		<post_date><![CDATA[2017-06-30 02:56:01]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[predicciones-en-procesos-de-negocio-declarativos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>1</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="constraint-programming"><![CDATA[Constraint programming]]></category>
		<category domain="post_tag" nicename="constraint-based-process-models"><![CDATA[Constraint-based process models]]></category>
		<category domain="post_tag" nicename="flexible-process-aware-information-systems"><![CDATA[Flexible process-aware information systems]]></category>
		<category domain="post_tag" nicename="planning-and-scheduling"><![CDATA[Planning and scheduling]]></category>
		<category domain="post_tag" nicename="time-prediction"><![CDATA[Time prediction]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La generación de predicciones sobre instancias de procesos de negocio permite anticipar problemas, evitar el incumplimiento de restricciones de una manera proactiva, y tomar decisiones sobre prioridades y restricciones al enfrentarse a eventos inesperados, e.g., retrasos. Sin embargo, elaborar una predicción es una tarea compleja en la mayoría de los casos ya que se deben tener en cuenta múltiples instancias y recursos, es necesario adaptar dichas predicciones a circunstancias cambiantes, y hay que tener en cuenta distintas dimensiones, no sólo el tiempo. En este contexto, el presente trabajo propone una propuesta novedosa para generar predicciones sobre un conjunto de instancias en ejecución relacionadas con un modelo declarativo de un proceso de negocio. Dicha propuesta consiste en generar un plan de ejecución optimizado a partir del modelo declarativo y del estado de las instancias en ejecución. Tras ello, la predicción se genera evaluando la función que se desea predecir sobre el plan de ejecución generado. La presente propuesta ha sido evaluada utilizando un modelo de proceso de un escenario real que incluye restricciones temporales, de datos, de recursos y de control-flow que lo dotan de una alta complejidad. Los prometedores resultados obtenidos alientan a continuar los trabajos en escenarios con características diferentes que permitan extender la validez de la propuesta. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/005]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496924921.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496924921.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Andrés Jiménez-Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ajramirez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Irene Barba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[irenebr@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Fernández-Olivares]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[faro@decsai.ugr.esg]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Granada, Granada, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Carmelo del Valle]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[carmelo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Barbara Weber]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[bweber@dtu.dk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Technical University of Denmark, Kongens Lyngby, Denmark]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards the Extraction of Frequent Patterns in Complex Process Models</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-the-extraction-of-frequent-patterns-in-complex-process-models/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-the-extraction-of-frequent-patterns-in-complex-process-models/</guid>
		<description></description>
		<content><![CDATA[In this paper, we present WoMine, an algorithm to retrieve frequent behavioural patterns from the model. Our approach searches in process models extracting structures with sequences, selections, parallels and loops, which are frequently executed in the logs. This proposal has been validated with a set of process models, and compared with the state of the art techniques. Experiments have validated that WoMine can find all types of patterns, extracting information that cannot be mined with the state of the art techniques.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2476</post_id>
		<post_date><![CDATA[2017-06-30 02:56:01]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-the-extraction-of-frequent-patterns-in-complex-process-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>2</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="frequent-pattern-mining"><![CDATA[frequent pattern mining]]></category>
		<category domain="post_tag" nicename="process-discovery"><![CDATA[process discovery]]></category>
		<category domain="post_tag" nicename="process-mining"><![CDATA[Process Mining]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper, we present WoMine, an algorithm to retrieve frequent behavioural patterns from the model. Our approach searches in process models extracting structures with sequences, selections, parallels and loops, which are frequently executed in the logs. This proposal has been validated with a set of process models, and compared with the state of the art techniques. Experiments have validated that WoMine can find all types of patterns, extracting information that cannot be mined with the state of the art techniques.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/006]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496925629.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496925629.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Chapela-Campa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[david.chapela@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Mucientes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[manuel.mucientes@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Lama]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuel.lama@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Monitorización predictiva de procesos de negocio basada en modelos de predicción actualizables</title>
		<link>https://biblioteca.sistedes.es/articulo/monitorizacion-predictiva-de-procesos-de-negocio-basada-en-modelos-de-prediccion-actualizables/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/monitorizacion-predictiva-de-procesos-de-negocio-basada-en-modelos-de-prediccion-actualizables/</guid>
		<description></description>
		<content><![CDATA[La monitorización predictiva de instancias de procesos de negocio en ejecución propociona acciones proactivas y correctivas para mejorar el rendimiento de los procesos y mitigar los posibles riesgos en tiempo real. Dicha monitorización permite la predicción de métricas de evaluación o indicadores del rendimiento de un proceso en ejecución. En este contexto, este trabajo define una arquitectura para el proceso de predicción de indicadores que, asimismo, contempla la posibilidad de la actualización del modelo predictivo a lo largo del tiempo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2477</post_id>
		<post_date><![CDATA[2017-06-30 02:56:01]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[monitorizacion-predictiva-de-procesos-de-negocio-basada-en-modelos-de-prediccion-actualizables]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>3</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mineria-de-procesos"><![CDATA[minería de procesos]]></category>
		<category domain="post_tag" nicename="monitorizacion-predictiva"><![CDATA[monitorización predictiva]]></category>
		<category domain="post_tag" nicename="prediccion-de-indicadores"><![CDATA[predicción de indicadores.]]></category>
		<category domain="post_tag" nicename="procesos-de-negocio"><![CDATA[Procesos de Negocio]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La monitorización predictiva de instancias de procesos de negocio en ejecución propociona acciones proactivas y correctivas para mejorar el rendimiento de los procesos y mitigar los posibles riesgos en tiempo real. Dicha monitorización permite la predicción de métricas de evaluación o indicadores del rendimiento de un proceso en ejecución. En este contexto, este trabajo define una arquitectura para el proceso de predicción de indicadores que, asimismo, contempla la posibilidad de la actualización del modelo predictivo a lo largo del tiempo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/007]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alfonso E. Márquez-Chamorro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[amarquez6@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Analyzer4BPEL: Una herramienta de análisis de composiciones WS-BPEL para su aplicación en la etapa de prueba del software</title>
		<link>https://biblioteca.sistedes.es/articulo/analyzer4bpel-una-herramienta-de-analisis-de-composiciones-ws-bpel-para-su-aplicacion-en-la-etapa-de-prueba-del-software/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/analyzer4bpel-una-herramienta-de-analisis-de-composiciones-ws-bpel-para-su-aplicacion-en-la-etapa-de-prueba-del-software/</guid>
		<description></description>
		<content><![CDATA[Toda herramienta de prueba de software requiere en algún momento de su proceso realizar un análisis, o bien como primer paso, para extraer la información necesaria para aplicar una determinada técnica, o bien, una vez procesado el software para estudiar los resultados y evaluarlos. Existen en la actualidad herramientas capaces de analizar la mayoría de los lenguajes de programación. Sin embargo, no abundan los analizadores de lenguajes para composiciones de servicios. En este trabajo se presenta una aplicación que realiza un análisis de composiciones en lenguaje WS-BPEL y de sus casos de prueba para extraer información útil para diversos objetivos. Así mismo, se describe su utilización particular, en una de las etapas de la aplicación de una técnica de prueba de software: la prueba metamórfica.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2478</post_id>
		<post_date><![CDATA[2017-06-30 02:56:01]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analyzer4bpel-una-herramienta-de-analisis-de-composiciones-ws-bpel-para-su-aplicacion-en-la-etapa-de-prueba-del-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>1</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="analisis"><![CDATA[análisis]]></category>
		<category domain="post_tag" nicename="bpts"><![CDATA[BPTS]]></category>
		<category domain="post_tag" nicename="casos-de-prueba"><![CDATA[casos de prueba]]></category>
		<category domain="post_tag" nicename="prueba-del-software"><![CDATA[prueba del software]]></category>
		<category domain="post_tag" nicename="prueba-metamorfica"><![CDATA[prueba metamórfica]]></category>
		<category domain="post_tag" nicename="relaciones-metamorfircas"><![CDATA[relaciones metamórfircas]]></category>
		<category domain="post_tag" nicename="servicios-web"><![CDATA[servicios web]]></category>
		<category domain="post_tag" nicename="ws-bpel"><![CDATA[WS-BPEL]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Toda herramienta de prueba de software requiere en algún momento de su proceso realizar un análisis, o bien como primer paso, para extraer la información necesaria para aplicar una determinada técnica, o bien, una vez procesado el software para estudiar los resultados y evaluarlos. Existen en la actualidad herramientas capaces de analizar la mayoría de los lenguajes de programación. Sin embargo, no abundan los analizadores de lenguajes para composiciones de servicios. En este trabajo se presenta una aplicación que realiza un análisis de composiciones en lenguaje WS-BPEL y de sus casos de prueba para extraer información útil para diversos objetivos. Así mismo, se describe su utilización particular, en una de las etapas de la aplicación de una técnica de prueba de software: la prueba metamórfica.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/009]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496926419.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496926419.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Kevin J. Valle-Gómez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[kevin.vallegomez@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[M. Carmen de Castro-Cabrera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[maricarmen.decastro@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards SLA modeling for RESTful APIs</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-sla-modeling-for-restful-apis/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-sla-modeling-for-restful-apis/</guid>
		<description></description>
		<content><![CDATA[The term of API Economy is becoming increasingly used to describe the change of vision in how APIs can add value to the organizations. Furthermore, a greater automation of RESTful APIs management can suppose a competitive advantage for the company. New proposals are emerging in order to automatize some API governance tasks and increase the ease of use (e.g. generation of code and documentation). Despite that, the non-functional aspects are often addressed in a highly specific manner or even there not exists any solution for an automatic governance. Nevertheless, these properties are already defined in natural language at the Service Level Agreement (SLA) that both customer and provided have established. In this paper, we carry out a study on the *aaS industry and analyze the current both API modeling and SLA modeling proposals in order to identify the open challenges for an automatic RESTful API governance.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2479</post_id>
		<post_date><![CDATA[2017-06-30 02:56:01]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-sla-modeling-for-restful-apis]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>2</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The term of API Economy is becoming increasingly used to describe the change of vision in how APIs can add value to the organizations. Furthermore, a greater automation of RESTful APIs management can suppose a competitive advantage for the company. New proposals are emerging in order to automatize some API governance tasks and increase the ease of use (e.g. generation of code and documentation). Despite that, the non-functional aspects are often addressed in a highly specific manner or even there not exists any solution for an automatic governance. Nevertheless, these properties are already defined in natural language at the Service Level Agreement (SLA) that both customer and provided have established. In this paper, we carry out a study on the *aaS industry and analyze the current both API modeling and SLA modeling proposals in order to identify the open challenges for an automatic RESTful API governance.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/010]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2783]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Gámez-Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[agamez2@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modelling Citizen Letters for Public Services automation</title>
		<link>https://biblioteca.sistedes.es/articulo/modelling-citizen-letters-for-public-services-automation/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/modelling-citizen-letters-for-public-services-automation/</guid>
		<description></description>
		<content><![CDATA[The publication and, when it is possible, automation of public services on Internet provides advantages for citizens and governance. The former because promotes the transparency and control over governance actions and avoids unneeded presencial inquiries and the latter because information systems help to decrease human resources costs. A number of efforts have been performed by public administrations to provide precise service information online. As this service information is incrementally published, manual interaction to navigate and query these services becomes a difficult task that automated mechanisms could support based on service catalogs. In this paper we introduce an ongoing work proposing the use of ontologies to enable the automated processing -i.e. search and validation- of these service catalogs.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2480</post_id>
		<post_date><![CDATA[2017-06-30 02:56:01]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modelling-citizen-letters-for-public-services-automation]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>3</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The publication and, when it is possible, automation of public services on Internet provides advantages for citizens and governance. The former because promotes the transparency and control over governance actions and avoids unneeded presencial inquiries and the latter because information systems help to decrease human resources costs. A number of efforts have been performed by public administrations to provide precise service information online. As this service information is incrementally published, manual interaction to navigate and query these services becomes a difficult task that automated mechanisms could support based on service catalogs. In this paper we introduce an ongoing work proposing the use of ontologies to enable the automated processing -i.e. search and validation- of these service catalogs.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/011]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496926934.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496926934.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Manuel Gutiérrez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[amgutierrez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernanda Massena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fmmassena@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidade Federal do Estado do Rio de Janeiro, Brazil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Claudia Cappelli]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[claudia.cappelli@uniriotec.br]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidade Federal do Estado do Rio de Janeiro, Brazil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Flavia Santoro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[flavia.santoro@uniriotec.br]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidade Federal do Estado do Rio de Janeiro, Brazil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Detección de Abandono de una Zona Segura mediante la Integración de CEP y SOA 2.0</title>
		<link>https://biblioteca.sistedes.es/articulo/deteccion-de-abandono-de-una-zona-segura-mediante-la-integracion-de-cep-y-soa-2-0/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/deteccion-de-abandono-de-una-zona-segura-mediante-la-integracion-de-cep-y-soa-2-0/</guid>
		<description></description>
		<content><![CDATA[Existe una gran problemática alrededor de personas enfermas de Alzheimer. Estas personas viven en el pasado y no son conscientes de la reali-dad en la que viven. Gran parte de ellas llegan a perderse provocando un gran dolor en familia y amigos. Por consiguiente, el ser informado en el instante jus-to que dicha persona abandona su hogar, la residencia o lugar de recreo evitaría muchas situaciones trágicas para estas familias. En este artículo desarrollamos un sistema que integra SOA 2.0 con un motor de procesamiento de eventos complejos y un sensor GPS con el fin de avisar a los familiares en el momento en que el enfermo salga de una zona determinada. Los resultados obtenidos de-muestran que el procesamiento de eventos complejos es la tecnología acertada para detectar en tiempo real cuándo una persona abandona una zona establecida y ser informados de su posición, pudiendo emprender su búsqueda inmediata-mente y evitar la fatal pérdida.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2481</post_id>
		<post_date><![CDATA[2017-06-30 02:56:01]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[deteccion-de-abandono-de-una-zona-segura-mediante-la-integracion-de-cep-y-soa-2-0]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="arquitectura-dirigida-por-eventos"><![CDATA[Arquitectura Dirigida por Eventos]]></category>
		<category domain="post_tag" nicename="arquitectura-orientada-a-servicios"><![CDATA[Arquitectura Orientada a Servicios]]></category>
		<category domain="post_tag" nicename="bus-de-servicios-empresaria-les"><![CDATA[Bus de Servicios Empresaria-les]]></category>
		<category domain="post_tag" nicename="gps"><![CDATA[GPS.]]></category>
		<category domain="post_tag" nicename="procesamiento-de-eventos-complejos"><![CDATA[procesamiento de eventos complejos]]></category>
		<category domain="post_tag" nicename="rest"><![CDATA[REST]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Existe una gran problemática alrededor de personas enfermas de Alzheimer. Estas personas viven en el pasado y no son conscientes de la reali-dad en la que viven. Gran parte de ellas llegan a perderse provocando un gran dolor en familia y amigos. Por consiguiente, el ser informado en el instante jus-to que dicha persona abandona su hogar, la residencia o lugar de recreo evitaría muchas situaciones trágicas para estas familias. En este artículo desarrollamos un sistema que integra SOA 2.0 con un motor de procesamiento de eventos complejos y un sensor GPS con el fin de avisar a los familiares en el momento en que el enfermo salga de una zona determinada. Los resultados obtenidos de-muestran que el procesamiento de eventos complejos es la tecnología acertada para detectar en tiempo real cuándo una persona abandona una zona establecida y ser informados de su posición, pudiendo emprender su búsqueda inmediata-mente y evitar la fatal pérdida.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/012]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2787]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496929227.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carmen Marchena-Tinoco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carmen.marchenatinoco@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Escuela Superior de Ingeniería, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carmen Moreno-Muñoz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[carmen.morenomunoz@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Escuela Superior de Ingeniería, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>QSS: una experiencia en la industria 4.0 en seguridad y prevención de riesgos</title>
		<link>https://biblioteca.sistedes.es/articulo/qss-una-experiencia-en-la-industria-4-0-en-seguridad-y-prevencion-de-riesgos/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/qss-una-experiencia-en-la-industria-4-0-en-seguridad-y-prevencion-de-riesgos/</guid>
		<description></description>
		<content><![CDATA[En los últimos años, la Industria 4.0 se está convirtiendo en una gran apuesta de los gobiernos industrializados y donde las fábricas renuevan sus procesos industriales interconectándolos entre sí. Los principales desafíos a los que ha de hacer frente esta Industria 4.0 se encuentran en el desarrollo de software donde, entre otros, la ciberseguridad y el control de riesgos son aspectos claves en la innovación hacia esta industria 4.0. Este artículo presenta nuestra experiencia práctica en el desarrollo e implantación de una arquitectura SOA 2.0 para la monitorización en tiempo real de escenarios de trabajo de alta peligrosidad que, haciendo uso de los principios de la industria 4.0, permiten realizar una rápida toma de decisiones orientadas a la seguridad y prevención de riesgos de los trabajadores de una empresa de explosivos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2482</post_id>
		<post_date><![CDATA[2017-06-30 02:56:01]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[qss-una-experiencia-en-la-industria-4-0-en-seguridad-y-prevencion-de-riesgos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>1</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="entornos-de-alta-peligrosidad"><![CDATA[Entornos de alta peligrosidad]]></category>
		<category domain="post_tag" nicename="industria-4-0"><![CDATA[Industria 4.0]]></category>
		<category domain="post_tag" nicename="soa-2-0"><![CDATA[SOA 2.0]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años, la Industria 4.0 se está convirtiendo en una gran apuesta de los gobiernos industrializados y donde las fábricas renuevan sus procesos industriales interconectándolos entre sí. Los principales desafíos a los que ha de hacer frente esta Industria 4.0 se encuentran en el desarrollo de software donde, entre otros, la ciberseguridad y el control de riesgos son aspectos claves en la innovación hacia esta industria 4.0. Este artículo presenta nuestra experiencia práctica en el desarrollo e implantación de una arquitectura SOA 2.0 para la monitorización en tiempo real de escenarios de trabajo de alta peligrosidad que, haciendo uso de los principios de la industria 4.0, permiten realizar una rápida toma de decisiones orientadas a la seguridad y prevención de riesgos de los trabajadores de una empresa de explosivos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/013]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2782]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JCIS_2017_paper_8.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Guillermo Barco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanher@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[QSEG, Escuela Politécnica de Cáceres, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Enrique Moguel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[enrique@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[QSEG, Escuela Politécnica de Cáceres, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jorge Perianez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Industria 4.0, SOA 2.0, Entornos de alta peligrosidad]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>El papel de los ciudadanos en las ciudades inteligentes: un escenario de movilidad urbana</title>
		<link>https://biblioteca.sistedes.es/articulo/el-papel-de-los-ciudadanos-en-las-ciudades-inteligentes-un-escenario-de-movilidad-urbana/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/el-papel-de-los-ciudadanos-en-las-ciudades-inteligentes-un-escenario-de-movilidad-urbana/</guid>
		<description></description>
		<content><![CDATA[Gran parte de los esfuerzos dedicados al desarrollo de las llamadas ciudades inteligentes se centran en el campo del Internet of Things (IoT). Las instituciones ofrecen habitualmente
la información recolectada mediante IoT en forma de datos abiertos y estadísticas, a partir de las cuales se pueden realizar análisis y obtener conclusiones que ayuden a mejorar la gestión de las ciudades, haciéndolas más eficientes y habitables. No obstante, sin el concurso de los ciudadanos en la generación y recogida de información, no es posible ofrecer una imagen completa de las ciudades. El análisis de la información recopilada no tendrá en
cuenta el contexto de las personas, ni podrá adaptarse a las necesidades de las mismas. Para resolver este problema, proponemos el uso de un nuevo modelo capaz de convivir con el de IoT actual y que cubra estas necesidades respecto a los ciudadanos. Se trata de Internet of People (IoP), un modelo de computación social y móvil que permite recopilar información a partir de los smartphones y del uso que hacen de ellos sus propietarios. Mediante
un motor de inferencia, dicha información se transforma en conocimiento de los hábitos del usuario del teléfono, conocimiento que puede ser ofrecido a su vez como un servicio. La
combinación de los datos recogidos por ambas partes, IoT e IoP, procurará realmente el adjetivo inteligente a la ciudad, permitiendo que los servicios que el IoT ofrece puedan adaptarse a cada persona, y convirtiendo a estas últimas en el objetivo central
de la ciudad inteligente.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2483</post_id>
		<post_date><![CDATA[2017-06-30 02:56:02]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[el-papel-de-los-ciudadanos-en-las-ciudades-inteligentes-un-escenario-de-movilidad-urbana]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>2</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Gran parte de los esfuerzos dedicados al desarrollo de las llamadas ciudades inteligentes se centran en el campo del Internet of Things (IoT). Las instituciones ofrecen habitualmente
la información recolectada mediante IoT en forma de datos abiertos y estadísticas, a partir de las cuales se pueden realizar análisis y obtener conclusiones que ayuden a mejorar la gestión de las ciudades, haciéndolas más eficientes y habitables. No obstante, sin el concurso de los ciudadanos en la generación y recogida de información, no es posible ofrecer una imagen completa de las ciudades. El análisis de la información recopilada no tendrá en
cuenta el contexto de las personas, ni podrá adaptarse a las necesidades de las mismas. Para resolver este problema, proponemos el uso de un nuevo modelo capaz de convivir con el de IoT actual y que cubra estas necesidades respecto a los ciudadanos. Se trata de Internet of People (IoP), un modelo de computación social y móvil que permite recopilar información a partir de los smartphones y del uso que hacen de ellos sus propietarios. Mediante
un motor de inferencia, dicha información se transforma en conocimiento de los hábitos del usuario del teléfono, conocimiento que puede ser ofrecido a su vez como un servicio. La
combinación de los datos recogidos por ambas partes, IoT e IoP, procurará realmente el adjetivo inteligente a la ciudad, permitiendo que los servicios que el IoT ofrece puedan adaptarse a cada persona, y convirtiendo a estas últimas en el objetivo central
de la ciudad inteligente.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/014]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496930266.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496930266.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alejandro Pérez-Vereda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[apvereda@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José Garcia-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Juan M. Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia la mejora de las mediciones topográficas de campo a través de una arquitectura orientada a servicios dirigida por eventos</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-la-mejora-de-las-mediciones-topograficas-de-campo-a-traves-de-una-arquitectura-orientada-a-servicios-dirigida-por-eventos/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/hacia-la-mejora-de-las-mediciones-topograficas-de-campo-a-traves-de-una-arquitectura-orientada-a-servicios-dirigida-por-eventos/</guid>
		<description></description>
		<content><![CDATA[Las tecnologías para las mediciones topográficas y el software para calcular y representar la elevación del terreno han evolucionado considerablemente en los últimos años. Sin embargo, las empresas de topografía, especialmente las pymes, aún sufren grandes costes por datos erróneos o incompletos en las mediciones realizadas por los operarios. En este artículo se esboza una propuesta para la reducción de dichos costes –en tiempo y en dinero– a través de una arquitectura orientada a servicios y dirigida por eventos que emita la recepción
instantánea de los datos tomados por los operarios, la detección de mediciones erróneas o incompletas y la inmediata notificación a los operarios para solventar la incidencia.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2484</post_id>
		<post_date><![CDATA[2017-06-30 02:56:02]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-la-mejora-de-las-mediciones-topograficas-de-campo-a-traves-de-una-arquitectura-orientada-a-servicios-dirigida-por-eventos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>3</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="arquitecturas-dirigidas-por-eventos"><![CDATA[Arquitecturas Dirigidas por Eventos]]></category>
		<category domain="post_tag" nicename="arquitecturas-orientadas-a-servicios"><![CDATA[arquitecturas orientadas a servicios]]></category>
		<category domain="post_tag" nicename="bus-de-servicios-empresariales"><![CDATA[Bus de Servicios Empresariales]]></category>
		<category domain="post_tag" nicename="procesamiento-de-eventos-complejos"><![CDATA[procesamiento de eventos complejos]]></category>
		<category domain="post_tag" nicename="topografia"><![CDATA[Topografía]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las tecnologías para las mediciones topográficas y el software para calcular y representar la elevación del terreno han evolucionado considerablemente en los últimos años. Sin embargo, las empresas de topografía, especialmente las pymes, aún sufren grandes costes por datos erróneos o incompletos en las mediciones realizadas por los operarios. En este artículo se esboza una propuesta para la reducción de dichos costes –en tiempo y en dinero– a través de una arquitectura orientada a servicios y dirigida por eventos que emita la recepción
instantánea de los datos tomados por los operarios, la detección de mediciones erróneas o incompletas y la inmediata notificación a los operarios para solventar la incidencia.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/015]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2788]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496930401.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alfonso García de Prado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alfonso.garciadeprado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francisco Gámez Lázaro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[francisco@georamasc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Georama S.C.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Coordinating heterogeneous IoT devices by means of the centralized vision of the SDN controller</title>
		<link>https://biblioteca.sistedes.es/articulo/coordinating-heterogeneous-iot-devices-by-means-of-the-centralized-vision-of-the-sdn-controller/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/coordinating-heterogeneous-iot-devices-by-means-of-the-centralized-vision-of-the-sdn-controller/</guid>
		<description></description>
		<content><![CDATA[The IoT (Internet of Things) has become a reality during recent years. The desire of having everything connected to the Internet results in clearly identified benefits that will impact on socio economic development. However, the exponential growth in the number of IoT devices and their heterogeneity open new challenges that must be carefully studied. Coordination among devices to adapt them to their users' context usually requires high volumes of data to be exchanged with the cloud. In order to reduce unnecessary communications and network overhead, this paper proposes a novel network architecture based on the Software-Defined Networking paradigm that allows IoT devices coordinate and adapt them within the scope of a particular context.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2485</post_id>
		<post_date><![CDATA[2017-06-30 02:56:02]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[coordinating-heterogeneous-iot-devices-by-means-of-the-centralized-vision-of-the-sdn-controller]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="internet-of-things"><![CDATA[Internet of Things]]></category>
		<category domain="post_tag" nicename="situational-context"><![CDATA[Situational-Context]]></category>
		<category domain="post_tag" nicename="software-defined-networking"><![CDATA[Software-Defined Networking]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The IoT (Internet of Things) has become a reality during recent years. The desire of having everything connected to the Internet results in clearly identified benefits that will impact on socio economic development. However, the exponential growth in the number of IoT devices and their heterogeneity open new challenges that must be carefully studied. Coordination among devices to adapt them to their users' context usually requires high volumes of data to be exchanged with the cloud. In order to reduce unnecessary communications and network overhead, this paper proposes a novel network architecture based on the Software-Defined Networking paradigm that allows IoT devices coordinate and adapt them within the scope of a particular context.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/016]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496950553.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496950553.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jaime Galán-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jaime@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose Garcia-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Juan M. Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automatización del Aprovisionamiento de Infraestructura en la Nube</title>
		<link>https://biblioteca.sistedes.es/articulo/automatizacion-del-aprovisionamiento-de-infraestructura-en-la-nube/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/automatizacion-del-aprovisionamiento-de-infraestructura-en-la-nube/</guid>
		<description></description>
		<content><![CDATA[DevOps es un paradigma que aporta prácticas y herramientas que optimizan el tiempo de entrega del software. En particular, la Infraestructura como Código es la capacidad principal de DevOps para automatizar la gestión de la infraestructura basada en actividades de desarrollo de software. Existe una gran variedad de herramientas que gestionan el aprovisionamiento de infraestructura y utilizan scripts para definir el estado final del hardware. Sin embargo, aún existen retos técnicos para gestionar las herramientas en actividades como la integración, despliegue y entrega continua de aplicaciones. Para abordar este problema, en trabajos previos, presentamos una extensión de un método de reconfiguración dinámica de arquitecturas de servicios en la nube (DIARy) con el fin de adoptar las prácticas de DevOps. En este trabajo presentamos una herramienta para modelar el aprovisionamiento de infraestructura en la nube basado en el concepto de Infraestructura como Código.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2486</post_id>
		<post_date><![CDATA[2017-06-30 02:56:02]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automatizacion-del-aprovisionamiento-de-infraestructura-en-la-nube]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>2</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="aprovisionamiento-de-infraestructura"><![CDATA[Aprovisionamiento de Infraestructura]]></category>
		<category domain="post_tag" nicename="desarrollo-dirigido-por-modelos"><![CDATA[Desarrollo dirigido por modelos]]></category>
		<category domain="post_tag" nicename="devops"><![CDATA[DevOps]]></category>
		<category domain="post_tag" nicename="infraestructura-como-codigo"><![CDATA[Infraestructura como Código]]></category>
		<category domain="post_tag" nicename="servicios-en-la-nube"><![CDATA[Servicios en la Nube]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[DevOps es un paradigma que aporta prácticas y herramientas que optimizan el tiempo de entrega del software. En particular, la Infraestructura como Código es la capacidad principal de DevOps para automatizar la gestión de la infraestructura basada en actividades de desarrollo de software. Existe una gran variedad de herramientas que gestionan el aprovisionamiento de infraestructura y utilizan scripts para definir el estado final del hardware. Sin embargo, aún existen retos técnicos para gestionar las herramientas en actividades como la integración, despliegue y entrega continua de aplicaciones. Para abordar este problema, en trabajos previos, presentamos una extensión de un método de reconfiguración dinámica de arquitecturas de servicios en la nube (DIARy) con el fin de adoptar las prácticas de DevOps. En este trabajo presentamos una herramienta para modelar el aprovisionamiento de infraestructura en la nube basado en el concepto de Infraestructura como Código.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/018]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496952434.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496952434.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julio Sandobalín]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[julio.sandobalin@epn.edu.ec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática y Ciencias de la Computación, Escuela Politécnica Nacional de Ecuador]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Emilio Insfran]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[einsfran@disc.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Silvia Abrahão]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sabrahao@disc.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Mejorando la arquitectura de la infraestructura de datos y metadatos estadísticos de Canarias (eDatos)</title>
		<link>https://biblioteca.sistedes.es/articulo/mejorando-la-arquitectura-de-la-infraestructura-de-datos-y-metadatos-estadisticos-de-canarias-edatos/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/mejorando-la-arquitectura-de-la-infraestructura-de-datos-y-metadatos-estadisticos-de-canarias-edatos/</guid>
		<description></description>
		<content><![CDATA[La integración de datos entre distintos sistemas es un problema típico al que se enfrentan los responsables de las organizaciones. En este artículo se detalla la solución propuesta a un caso real del Instituto Canario de Estadística (ISTAC) haciendo uso de una aproximación orientada a servicios, basada en eventos (EDSOA) y utilizando como software base Apache Kafka.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2487</post_id>
		<post_date><![CDATA[2017-06-30 02:56:02]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mejorando-la-arquitectura-de-la-infraestructura-de-datos-y-metadatos-estadisticos-de-canarias-edatos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>3</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La integración de datos entre distintos sistemas es un problema típico al que se enfrentan los responsables de las organizaciones. En este artículo se detalla la solución propuesta a un caso real del Instituto Canario de Estadística (ISTAC) haciendo uso de una aproximación orientada a servicios, basada en eventos (EDSOA) y utilizando como software base Apache Kafka.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/019]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496952572.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496952572.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Peña Dorta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carlos@arte-consultores.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Arte Consultores Tecnológicos, S.L., Canarias, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Rita Díaz Adán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[rdiaada@arte-consultores.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Arte Consultores Tecnológicos, S.L., Canarias, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alberto González Yanes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jgonyanp@gobiernodecanarias.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto Canario de Estadísticas, Canarias, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Optimización de indicadores técnicos utilizando un conjunto de Algoritmos Evolutivos Multiobjetivo</title>
		<link>https://biblioteca.sistedes.es/articulo/optimizacion-de-indicadores-tecnicos-utilizando-un-conjunto-de-algoritmos-evolutivos-multiobjetivo-2/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/optimizacion-de-indicadores-tecnicos-utilizando-un-conjunto-de-algoritmos-evolutivos-multiobjetivo-2/</guid>
		<description></description>
		<content><![CDATA[Los indicadores técnicos, mediante la aplicación de un conjunto de fórmulas matemáticas, representan de forma gráfica la serie de precios de un activo. Estas fórmulas comprenden un conjunto de reglas y parámetros cuyos valores son desconocidos y dependen de factores, como el mercado en el que opera, o el tamaño de la ventana de tiempo. Este trabajo se centra en la realización de una aplicación software que optimiza, en tiempo real, el valor de los parámetros para dichos indicadores técnicos mediante el uso de algoritmos evolutivos multiobjetivos (AEMOs). A diferencia de otros enfoques, en este documento se aplica un conjunto de AEMOs diferentes que compiten entre sí, con el fin de lograr mejores rendimientos con un riesgo mínimo. El proceso de optimización es continuo y tiene lugar al final de cada intervalo de tiempo. Esta técnica permite aplicar soluciones no dominadas, obtenidas con diferentes AEMOs y puede mejorar considerablemente los resultados de la estrategia Buy &amp; Hold, incluso operando diariamente. Esta afirmación se demostrará comparando los resultados con los presentados previamente en la literatura. Para realizar esta operativa se ha empleado una arquitectura basada en servicios, donde las distintas partes del software han sido implementadas como servicios.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2489</post_id>
		<post_date><![CDATA[2017-06-30 02:56:02]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[optimizacion-de-indicadores-tecnicos-utilizando-un-conjunto-de-algoritmos-evolutivos-multiobjetivo-2]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="algoritmos-evolutivos"><![CDATA[algoritmos evolutivos]]></category>
		<category domain="post_tag" nicename="indicadores-tecnicos"><![CDATA[Indicadores Técnicos]]></category>
		<category domain="post_tag" nicename="optimizacion-multiobjetivo"><![CDATA[Optimización Multiobjetivo]]></category>
		<category domain="post_tag" nicename="servicios"><![CDATA[Servicios]]></category>
		<category domain="post_tag" nicename="trading-automatizado"><![CDATA[Trading automatizado]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los indicadores técnicos, mediante la aplicación de un conjunto de fórmulas matemáticas, representan de forma gráfica la serie de precios de un activo. Estas fórmulas comprenden un conjunto de reglas y parámetros cuyos valores son desconocidos y dependen de factores, como el mercado en el que opera, o el tamaño de la ventana de tiempo. Este trabajo se centra en la realización de una aplicación software que optimiza, en tiempo real, el valor de los parámetros para dichos indicadores técnicos mediante el uso de algoritmos evolutivos multiobjetivos (AEMOs). A diferencia de otros enfoques, en este documento se aplica un conjunto de AEMOs diferentes que compiten entre sí, con el fin de lograr mejores rendimientos con un riesgo mínimo. El proceso de optimización es continuo y tiene lugar al final de cada intervalo de tiempo. Esta técnica permite aplicar soluciones no dominadas, obtenidas con diferentes AEMOs y puede mejorar considerablemente los resultados de la estrategia Buy & Hold, incluso operando diariamente. Esta afirmación se demostrará comparando los resultados con los presentados previamente en la literatura. Para realizar esta operativa se ha empleado una arquitectura basada en servicios, donde las distintas partes del software han sido implementadas como servicios.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/020]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Soltero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[franciscojose.soltero@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[david.granada@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Marcos López]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[marcos.lopez@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Juan M. Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>On the feasibility of measuring performance using PPINOT in CMMN</title>
		<link>https://biblioteca.sistedes.es/articulo/on-the-feasibility-of-measuring-performance-using-ppinot-in-cmmn/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/on-the-feasibility-of-measuring-performance-using-ppinot-in-cmmn/</guid>
		<description></description>
		<content><![CDATA[Monitoring and measuring the performance of business processes are valuable tasks that facilitate the identification of possible improvement areas within the organisation according to the fulfillment of its strategic and business goals. A large number of techniques and tools have been developed with the aim of measuring process performance, but most of those processes are structured processes, usually defined using BPMN. The object of this paper is to identify and to analyse the feasibility of using an existing mechanism for the definition and modelling of process performance indicators (PPINOT) in a different context to structured BPMN processes; such as Cases, usually modelled using CMMN. This analysis is based on the similarities between CMMN and BPMN, and on characteristics and attributes used by PPINOT to get values from the process.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2490</post_id>
		<post_date><![CDATA[2017-06-30 02:56:02]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[on-the-feasibility-of-measuring-performance-using-ppinot-in-cmmn]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>1</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="business-processes"><![CDATA[business processes]]></category>
		<category domain="post_tag" nicename="cmmn"><![CDATA[CMMN]]></category>
		<category domain="post_tag" nicename="performance-indicators"><![CDATA[performance indicators]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Monitoring and measuring the performance of business processes are valuable tasks that facilitate the identification of possible improvement areas within the organisation according to the fulfillment of its strategic and business goals. A large number of techniques and tools have been developed with the aim of measuring process performance, but most of those processes are structured processes, usually defined using BPMN. The object of this paper is to identify and to analyse the feasibility of using an existing mechanism for the definition and modelling of process performance indicators (PPINOT) in a different context to structured BPMN processes; such as Cases, usually modelled using CMMN. This analysis is based on the similarities between CMMN and BPMN, and on characteristics and attributes used by PPINOT to get values from the process.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/021]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496953559.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496953559.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Bedilia Estrada-Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[iestrada@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Adela del-Río-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[adeladelrio@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Depto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Depto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Devising an SLA-Aware Methodology to Improve Process Performance</title>
		<link>https://biblioteca.sistedes.es/articulo/devising-an-sla-aware-methodology-to-improve-process-performance/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/devising-an-sla-aware-methodology-to-improve-process-performance/</guid>
		<description></description>
		<content><![CDATA[Aiming to be as competitive as possible, organisations are always pursuing to improve their business processes applying corrective actions when needed. However, the actual analysis and decision making for those actions is typically a challenging task relying on extensive human-in-the-loop expertise. Specifically, this improvement process usually involves: (i) to analyse evidences to understand the current behavior; (ii) to decide the actual objectives (usually defined in Service Level Agreements -SLAs- based on intuition) and (iii) to establish the improvement plan. In this ongoing work, we aim to propose a data-driven and intuition-free methodology to define an SLA as a governance element that specifies the service level objectives in an explicit way. Such a methodology considers process performance indicators that are analysed by means of inference, optimization, and simulation techniques. In order to motivate and exemplify our work we address a Healthcare scenario.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2491</post_id>
		<post_date><![CDATA[2017-06-30 02:56:02]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[devising-an-sla-aware-methodology-to-improve-process-performance]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>3</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Aiming to be as competitive as possible, organisations are always pursuing to improve their business processes applying corrective actions when needed. However, the actual analysis and decision making for those actions is typically a challenging task relying on extensive human-in-the-loop expertise. Specifically, this improvement process usually involves: (i) to analyse evidences to understand the current behavior; (ii) to decide the actual objectives (usually defined in Service Level Agreements -SLAs- based on intuition) and (iii) to establish the improvement plan. In this ongoing work, we aim to propose a data-driven and intuition-free methodology to define an SLA as a governance element that specifies the service level objectives in an explicit way. Such a methodology considers process performance indicators that are analysed by means of inference, optimization, and simulation techniques. In order to motivate and exemplify our work we address a Healthcare scenario.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/023]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496954008.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496954008.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Müller]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Minsu Cho]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Pohang University of Science and Technology, Pohang, Korea.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Minseok Song]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Pohang University of Science and Technology, Pohang, Kore]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Seville, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Seville, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Actualización reactiva de bases de datos usando cadenas de procesadores de flujo de datos</title>
		<link>https://biblioteca.sistedes.es/articulo/actualizacion-reactiva-de-bases-de-datos-usando-cadenas-de-procesadores-de-flujo-de-datos/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:03 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/actualizacion-reactiva-de-bases-de-datos-usando-cadenas-de-procesadores-de-flujo-de-datos/</guid>
		<description></description>
		<content><![CDATA[Este trabajo en curso explora el uso de cadenas de procesadores de flujos de datos como medio para proporcionar a aplicaciones con requisitos de tiempo real (TR) un acceso a la información del entorno bajo una perspectiva de base de datos (consultas continuas consistentes). En este trabajo se formulan las características que han de ofrecer las cadenas de procesadores de flujos de datos para este caso de uso, se define la arquitectura de procesado a utilizar y se asig-nan responsabilidades a cada uno de los elementos de la arquitectura.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2550</post_id>
		<post_date><![CDATA[2017-07-02 04:47:03]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:03]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[actualizacion-reactiva-de-bases-de-datos-usando-cadenas-de-procesadores-de-flujo-de-datos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="base-de-datos-en-memoria"><![CDATA[Base de datos en memoria]]></category>
		<category domain="post_tag" nicename="consultas-sobre-flujos-de-datos"><![CDATA[Consultas sobre flujos de datos]]></category>
		<category domain="post_tag" nicename="flujos-de-datos"><![CDATA[Flujos de datos]]></category>
		<category domain="post_tag" nicename="tiempo-real"><![CDATA[Tiempo real]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este trabajo en curso explora el uso de cadenas de procesadores de flujos de datos como medio para proporcionar a aplicaciones con requisitos de tiempo real (TR) un acceso a la información del entorno bajo una perspectiva de base de datos (consultas continuas consistentes). En este trabajo se formulan las características que han de ofrecer las cadenas de procesadores de flujos de datos para este caso de uso, se define la arquitectura de procesado a utilizar y se asig-nan responsabilidades a cada uno de los elementos de la arquitectura.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/011]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_2.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_2.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel Algorri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[miguel.algorri@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José María Drake]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jose.drake@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Marta Zorrilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[marta.zorrilla@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Linda-based Platform for the Parallel Execution of Out-place Model Transformations</title>
		<link>https://biblioteca.sistedes.es/articulo/a-linda-based-platform-for-the-parallel-execution-of-out-place-model-transformations/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:04 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-linda-based-platform-for-the-parallel-execution-of-out-place-model-transformations/</guid>
		<description></description>
		<content><![CDATA[Context: The performance and scalability of model transformations is gaining interest as industry is progressively adopting model-driven techniques and multicore computers are becoming commonplace. However, existing model transformation engines are mostly based on sequential and in-memory execution strategies, and thus their capabilities to transform large models in parallel and distributed environments are limited. Objective: This paper presents a solution that provides concurrency and distribution to model transformations. Method: Inspired by the concepts and principles of the Linda coordination language, and the use of data parallelism to achieve parallelization, a novel Java-based execution platform is introduced. It offers a set of core features for the parallel execution of out-place transformations that can be used as a target for high-level transformation language compilers. Results: Significant gains in performance and scalability of this platform are reported with regard to existing model transformation solutions. These results are demonstrated by running a model transformation test suite, and by its comparison against several state-of-the-art model transformation engines. Conclusion: Our Linda-based approach to the concurrent execution of model transformations can serve as a platform for their scalable and efficient implementation in parallel and distributed environments.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2551</post_id>
		<post_date><![CDATA[2017-07-02 04:47:04]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-linda-based-platform-for-the-parallel-execution-of-out-place-model-transformations]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="model-transformation"><![CDATA[Model Transformation]]></category>
		<category domain="post_tag" nicename="parallelization"><![CDATA[Parallelization]]></category>
		<category domain="post_tag" nicename="performance"><![CDATA[Performance]]></category>
		<category domain="post_tag" nicename="scalability"><![CDATA[Scalability]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Context: The performance and scalability of model transformations is gaining interest as industry is progressively adopting model-driven techniques and multicore computers are becoming commonplace. However, existing model transformation engines are mostly based on sequential and in-memory execution strategies, and thus their capabilities to transform large models in parallel and distributed environments are limited.  Objective: This paper presents a solution that provides concurrency and distribution to model transformations.  Method: Inspired by the concepts and principles of the Linda coordination language, and the use of data parallelism to achieve parallelization, a novel Java-based execution platform is introduced. It offers a set of core features for the parallel execution of out-place transformations that can be used as a target for high-level transformation language compilers.  Results: Significant gains in performance and scalability of this platform are reported with regard to existing model transformation solutions. These results are demonstrated by running a model transformation test suite, and by its comparison against several state-of-the-art model transformation engines.  Conclusion: Our Linda-based approach to the concurrent execution of model transformations can serve as a platform for their scalable and efficient implementation in parallel and distributed environments.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/075]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_3.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_3.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Loli Burgueño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[loli@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Málaga,  GISUM/Atenea Research Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Wimmer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[wimmer@big.tuwien.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Christian Doppler Laboratory for Model-Integrated Smart Production,  TU Wien]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Vallecillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[av@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga,  GISUM/Atenea Research Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Requirement-driven Evolution in Software Product Lines: A Systematic Mapping Study</title>
		<link>https://biblioteca.sistedes.es/articulo/requirement-driven-evolution-in-software-product-lines-a-systematic-mapping-study/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:04 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/requirement-driven-evolution-in-software-product-lines-a-systematic-mapping-study/</guid>
		<description></description>
		<content><![CDATA[Artículo relevante. Leticia Montalvillo, Oscar Díaz: Requirement-driven evolution in software product lines: A systematic mapping study. Journal of Systems and Software Volume 122, December 2016, Pages 110-143, COMPUTER SCIENCE, SOFTWARE ENGINEERING, IF: 1,424, Posición: (24/106), Cuartil: Q1. DOI http://dx.doi.org/10.1016/j.jss.2016.08.053]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2552</post_id>
		<post_date><![CDATA[2017-07-02 04:47:04]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[requirement-driven-evolution-in-software-product-lines-a-systematic-mapping-study]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="evolution"><![CDATA[Evolution]]></category>
		<category domain="post_tag" nicename="software-product-lines"><![CDATA[software product lines]]></category>
		<category domain="post_tag" nicename="systematic-mapping-study"><![CDATA[Systematic Mapping Study]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Artículo relevante.  Leticia Montalvillo, Oscar Díaz: Requirement-driven evolution in software product lines: A systematic mapping study. Journal of Systems and Software Volume 122, December 2016, Pages 110-143, COMPUTER SCIENCE, SOFTWARE ENGINEERING, IF: 1,424, Posición: (24/106), Cuartil: Q1. DOI http://dx.doi.org/10.1016/j.jss.2016.08.053]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/007]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_4.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_4.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Leticia Montalvillo Mendizabal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[leticia.montalvillo@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of The Basque Country (UPV/EHU)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Oscar Diaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[oscar.diaz@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Survey on Metamorphic Testing</title>
		<link>https://biblioteca.sistedes.es/articulo/a-survey-on-metamorphic-testing/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:04 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-survey-on-metamorphic-testing/</guid>
		<description></description>
		<content><![CDATA[S. Segura, G. Fraser, A. B. Sanchez and A. Ruiz-Cortés, A Survey on Metamorphic Testing, in IEEE Transactions on Software Engineering, vol. 42, no. 9, pp. 805-824, Sept. 1 2016. https://doi.org/10.1109/TSE.2016.2532875 Indicadores de calidad: - Revista de referencia en el área de Ingeniería del Software (CS-SE: 20/106). - Ha recibido 9 citas desde su publicación en febrero de 2016 (más otras 5-7 citas por aparecer en las actas del segundo workshop internacional de pruebas metamórficas [1]). - Hemos sido invitados a presentar el trabajo en ICSE17 como parte de la iniciativa journal-first (ver programa de la conferencia [2]). - Colaboración internacional con el profesor Gordon Fraser. [1] https://www.cs.montana.edu/met17/ [2] http://icse2017.gatech.edu/?q=technical-research-accepted]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2553</post_id>
		<post_date><![CDATA[2017-07-02 04:47:04]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-survey-on-metamorphic-testing]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="metamorphic-testing"><![CDATA[metamorphic testing]]></category>
		<category domain="post_tag" nicename="oracle-problem"><![CDATA[oracle problem]]></category>
		<category domain="post_tag" nicename="survey"><![CDATA[survey]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[S. Segura, G. Fraser, A. B. Sanchez and A. Ruiz-Cortés, A Survey on Metamorphic Testing, in IEEE Transactions on Software Engineering, vol. 42, no. 9, pp. 805-824, Sept. 1 2016. https://doi.org/10.1109/TSE.2016.2532875  Indicadores de calidad:  - Revista de referencia en el área de Ingeniería del Software (CS-SE: 20/106).  - Ha recibido 9 citas desde su publicación en febrero de 2016 (más otras 5-7 citas por aparecer en las actas del segundo workshop internacional de pruebas metamórficas [1]).  - Hemos sido invitados a presentar el trabajo en ICSE17 como parte de la iniciativa journal-first (ver programa de la conferencia [2]).  - Colaboración internacional con el profesor Gordon Fraser.  [1] https://www.cs.montana.edu/met17/ [2] http://icse2017.gatech.edu/?q=technical-research-accepted ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/066]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_6.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_6.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Gordon Fraser]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gordon.fraser@sheffield.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Sheffield]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ana B. Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[anabsanchez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Assessment of class mutation operators for C++ with the MuCPP mutation system</title>
		<link>https://biblioteca.sistedes.es/articulo/assessment-of-class-mutation-operators-for-c-with-the-mucpp-mutation-system/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:04 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/assessment-of-class-mutation-operators-for-c-with-the-mucpp-mutation-system/</guid>
		<description></description>
		<content><![CDATA[Context: Mutation testing has been mainly analyzed regarding traditional mutation operators involving structured programming constructs common in mainstream languages, but mutations at the class level have not been assessed to the same extent. This fact is noteworthy in the case of C++ , despite being one of the most relevant languages including object-oriented features. Objective: This paper provides a complete evaluation of class operators for the C++ programming language. MuCPP, a new system devoted to the application of mutation testing to this language, was developed to this end. This mutation system implements class mutation operators in a robust way, dealing with the inherent complexity of the language. Method: MuCPP generates the mutants by traversing the abstract syntax tree of each translation unit with the Clang API, and stores mutants as branches in the Git version control system. The tool is able to detect duplicate mutants, avoid system headers, and drive the compilation process. Then, MuCPP is used to conduct experiments with several open-source C++ programs. Results: The improvement rules listed in this paper to reduce unproductive class mutants have a significant impact in the computational cost of the technique. We also calculate the quantity and distribution of mutants generated with class operators, which generate far fewer mutants than their traditional counterparts. Conclusions: We show that the tests accompanying these programs cannot detect faults related to particular object-oriented features of C++ . In order to increase the mutation score, we create new test scenarios to kill the surviving class mutants for all the applications. The results confirm that, while traditional mutation operators are still needed, class operators can complement them and help testers further improve the test suite. Autores: Pedro Delgado-Pérez, Inmaculada Medina-Bulo, Francisco Palomo-Lozano, Antonio García-Domínguez, Juan José Domínguez-Jiménez Revista: Information and Software Technology, Volume 81, January 2017, Pages 169-184, http://dx.doi.org/10.1016/j.infsof.2016.07.002 Factor de impacto: 1.569 - Q1 (listado JCR 2015)]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2554</post_id>
		<post_date><![CDATA[2017-07-02 04:47:04]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[assessment-of-class-mutation-operators-for-c-with-the-mucpp-mutation-system]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="c"><![CDATA[C++]]></category>
		<category domain="post_tag" nicename="class-mutation-operators"><![CDATA[Class mutation operators]]></category>
		<category domain="post_tag" nicename="mutation-system"><![CDATA[Mutation system]]></category>
		<category domain="post_tag" nicename="mutation-testing"><![CDATA[Mutation testing]]></category>
		<category domain="post_tag" nicename="object-oriented-programming"><![CDATA[Object-oriented programming]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Context: Mutation testing has been mainly analyzed regarding traditional mutation operators involving structured programming constructs common in mainstream languages, but mutations at the class level have not been assessed to the same extent. This fact is noteworthy in the case of C++ , despite being one of the most relevant languages including object-oriented features. Objective: This paper provides a complete evaluation of class operators for the C++ programming language. MuCPP, a new system devoted to the application of mutation testing to this language, was developed to this end. This mutation system implements class mutation operators in a robust way, dealing with the inherent complexity of the language. Method: MuCPP generates the mutants by traversing the abstract syntax tree of each translation unit with the Clang API, and stores mutants as branches in the Git version control system. The tool is able to detect duplicate mutants, avoid system headers, and drive the compilation process. Then, MuCPP is used to conduct experiments with several open-source C++ programs. Results: The improvement rules listed in this paper to reduce unproductive class mutants have a significant impact in the computational cost of the technique. We also calculate the quantity and distribution of mutants generated with class operators, which generate far fewer mutants than their traditional counterparts. Conclusions: We show that the tests accompanying these programs cannot detect faults related to particular object-oriented features of C++ . In order to increase the mutation score, we create new test scenarios to kill the surviving class mutants for all the applications. The results confirm that, while traditional mutation operators are still needed, class operators can complement them and help testers further improve the test suite.   Autores: Pedro Delgado-Pérez, Inmaculada Medina-Bulo, Francisco Palomo-Lozano, Antonio García-Domínguez, Juan José Domínguez-Jiménez  Revista: Information and Software Technology, Volume 81, January 2017, Pages 169-184, http://dx.doi.org/10.1016/j.infsof.2016.07.002  Factor de impacto: 1.569 - Q1 (listado JCR 2015)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/067]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_7.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_7.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Delgado-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pedro.delgado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco Palomo-Lozano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[francisco.palomo@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Garcia-Dominguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[a.garcia-dominguez@aston.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science,  Aston University]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Juan José Domínguez-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[juanjose.dominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>tESA: using semantics of scientific articles to approximate semantic relatedness</title>
		<link>https://biblioteca.sistedes.es/articulo/tesa-using-semantics-of-scientific-articles-to-approximate-semantic-relatedness/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/tesa-using-semantics-of-scientific-articles-to-approximate-semantic-relatedness/</guid>
		<description></description>
		<content><![CDATA[Short abstract Semantic relatedness is a measure that quantifies the strength of a semantic link between two concepts. Often, it can be efficiently approximated with methods that operate on words, which represent these concepts. Approximating semantic relatedness between texts is an important part of many text and knowledge processing tasks of crucial importance in the ever growing domain of biomedical informatics. In this paper we present tESA, an extension to a well known Explicit Semantic Relatedness (ESA) method, which leverages the semantics of a corpus of scientific documents to improve the quality of the relatedness approximation for biomedical domain. In our extension we use two separate sets of vectors, corresponding to different sections of the articles from the underlying corpus of documents, as opposed to the original method, which only uses a single vector space. Our findings suggest that extending the original ESA methodology with the use of title vectors of the documents of scientific corpora may be used to enhance the performance of a distributional semantic relatedness measures. Background Semantic relatedness is a measure that quantifies the strength of a semantic link between two concepts. Often, it can be efficiently approximated with methods that operate on words, which represent these concepts. Approximating semantic relatedness between texts and concepts represented by these texts is an important part of many text and knowledge processing tasks of crucial importance in the ever growing domain of biomedical informatics. The problem of most state-of-the-art methods for calculating semantic relatedness is their dependence on highly specialized, structured knowledge resources, which makes these methods poorly adaptable for many usage scenarios. On the other hand, the domain knowledge in the Life Sciences has become more and more accessible, but mostly in its unstructured form - as texts in large document collections, which makes its use more challenging for automated processing. In this paper we present tESA, an extension to a well known Explicit Semantic Relatedness (ESA) method. Results In our extension we use two separate sets of vectors, corresponding to different sections of the articles from the underlying corpus of documents, as opposed to the original method, which only uses a single vector space. We present an evaluation of Life Sciences domain-focused applicability of both tESA and domain-adapted Explicit Semantic Analysis. The methods are tested against a set of standard benchmarks established for the evaluation of biomedical semantic relatedness quality. Our experiments show that the propsed method achieves results comparable with or superior to the current state-of-the-art methods. Additionally, a comparative discussion of the results obtained with tESA and ESA is presented, together with a study of the adaptability of the methods to different corpora and their performance with different input parameters. Conclusions Our findings suggest that combined use of the semantics from different sections (i.e. extending the original ESA methodology with the use of title vectors) of the documents of scientific corpora may be used to enhance the performance of a distributional semantic relatedness measures, which can be observed in the largest reference datasets. We also present the impact of the proposed extension on the size of distributional representations. Publication details The original paper tESA: a distributional measure for calculating semantic relatedness (DOI: 10.1186/s13326-016-0109-6), authored by Maciej Rybinski and José Francisco Aldana-Montes, was published online in the Journal of Biomedical Semantics on 28th of December 2016. The Journal of Biomedical Semantics currently holds (according to the latest JCR for 2015) an impact factor of 1.62, with a five-year impact factor of 2.511. The main impact factor places the Journal in the second cuartile (Q2) of its JCR-SCI category MATHEMATICAL &amp; COMPUTATIONAL BIOLOGY. Acknowledgments Work presented here was partially supported by grants TIN2014-58304-R (Ministerio de Ciencia e Innovación), P11-TIC-7529 and P12-TIC-1519 (Plan Andaluz de Investigación, Desarrollo e Innovación) and EU FP7-KBBE-289126 (the EU 7th Framework Programme, BIOLEDGE).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2555</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[tesa-using-semantics-of-scientific-articles-to-approximate-semantic-relatedness]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="bioinformatics"><![CDATA[Bioinformatics]]></category>
		<category domain="post_tag" nicename="biomedical-semantics"><![CDATA[Biomedical semantics]]></category>
		<category domain="post_tag" nicename="distributional-linguistics"><![CDATA[Distributional linguistics]]></category>
		<category domain="post_tag" nicename="explicit-semantic-analysis"><![CDATA[Explicit semantic analysis]]></category>
		<category domain="post_tag" nicename="knowledge-extraction"><![CDATA[Knowledge extraction]]></category>
		<category domain="post_tag" nicename="semantic-relatedness"><![CDATA[Semantic relatedness]]></category>
		<category domain="post_tag" nicename="semantic-similarity"><![CDATA[Semantic similarity]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Short abstract  Semantic relatedness is a measure that quantifies the strength of a semantic link between two concepts. Often, it can be efficiently approximated with methods that operate on words, which represent these concepts. Approximating semantic relatedness between texts is an important part of many text and knowledge processing tasks of crucial importance in the ever growing domain of biomedical informatics.   In this paper we present tESA, an extension to a well known Explicit Semantic Relatedness (ESA) method, which leverages the semantics of a corpus of scientific documents to improve the quality of the relatedness approximation for biomedical domain. In our extension we use two separate sets of vectors, corresponding to different sections of the articles from the underlying corpus of documents, as opposed to the original method, which only uses a single vector space.  Our findings suggest that extending the original ESA methodology with the use of title vectors of the documents of scientific corpora may be used to enhance the performance of a distributional semantic relatedness measures.  Background  Semantic relatedness is a measure that quantifies the strength of a semantic link between two concepts. Often, it can be efficiently approximated with methods that operate on words, which represent these concepts. Approximating semantic relatedness between texts and concepts represented by these texts is an important part of many text and knowledge processing tasks of crucial importance in the ever growing domain of biomedical informatics. The problem of most state-of-the-art methods for calculating semantic relatedness is their dependence on highly specialized, structured knowledge resources, which makes these methods poorly adaptable for many usage scenarios. On the other hand, the domain knowledge in the Life Sciences has become more and more accessible, but mostly in its unstructured form - as texts in large document collections, which makes its use more challenging for automated processing. In this paper we present tESA, an extension to a well known Explicit Semantic Relatedness (ESA) method.   Results  In our extension we use two separate sets of vectors, corresponding to different sections of the articles from the underlying corpus of documents, as opposed to the original method, which only uses a single vector space. We present an evaluation of Life Sciences domain-focused applicability of both tESA and domain-adapted Explicit Semantic Analysis. The methods are tested against a set of standard benchmarks established for the evaluation of biomedical semantic relatedness quality. Our experiments show that the propsed method achieves results comparable with or superior to the current state-of-the-art methods. Additionally, a comparative discussion of the results obtained with tESA and ESA is presented, together with a study of the adaptability of the methods to different corpora and their performance with different input parameters.   Conclusions  Our findings suggest that combined use of the semantics from different sections (i.e. extending the original ESA methodology with the use of title vectors) of the documents of scientific corpora may be used to enhance the performance of a distributional semantic relatedness measures, which can be observed in the largest reference datasets. We also present the impact of the proposed extension on the size of distributional representations.  Publication details  The original paper tESA: a distributional measure for calculating semantic relatedness (DOI: 10.1186/s13326-016-0109-6), authored by Maciej Rybinski and José Francisco Aldana-Montes, was published online in the Journal of Biomedical Semantics on 28th of December 2016. The Journal of Biomedical Semantics currently holds (according to the latest JCR for 2015) an impact factor of 1.62, with a five-year impact factor of 2.511. The main impact factor places the Journal in the second cuartile (Q2) of its JCR-SCI category MATHEMATICAL & COMPUTATIONAL BIOLOGY.   Acknowledgments  Work presented here was partially supported by grants TIN2014-58304-R (Ministerio de Ciencia e Innovación), P11-TIC-7529 and P12-TIC-1519 (Plan Andaluz de Investigación, Desarrollo e Innovación) and EU FP7-KBBE-289126 (the EU 7th Framework Programme, BIOLEDGE).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/022]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_8.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_8.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Maciej Rybinski]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[maciek.rybinski@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Malaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose F Aldana Montes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jfam@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Malaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Rich contextual information for monitoring the elderly in an early stage of cognitive impairment</title>
		<link>https://biblioteca.sistedes.es/articulo/rich-contextual-information-for-monitoring-the-elderly-in-an-early-stage-of-cognitive-impairment/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/rich-contextual-information-for-monitoring-the-elderly-in-an-early-stage-of-cognitive-impairment/</guid>
		<description></description>
		<content><![CDATA[Artículo relevante ya publicado. Revista de publicación: Pervasive and Mobile Computing Available online : 24 May 2016 Numero: 34 Páginas: 106 - 125 DOI: http://dx.doi.org/10.1016/j.pmcj.2016.05.001 Factor de impacto: JCR 2.079, SJR 0.872, IPP 2.289, SNIP 2.051 Abstract: With the increase in the elderly population, there is a concomitant growth in the number of cases of cognitive impairment. The early stages of these disorders can cause the elderly difficulties in performing their daily activities. To improve their independence while keeping their caregivers informed, this paper presents a monitoring system that focuses on the use of rich contextual information to detect a wide variety of a cognitively impaired persons routines and deviations from those routines. A detailed architecture of the system is presented together with an in-depth description of the algorithms for the identification of routines and deviations. In an experimental test with students, the algorithms identified some 91% of the routines and some 96% of the deviations.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2556</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[rich-contextual-information-for-monitoring-the-elderly-in-an-early-stage-of-cognitive-impairment]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="contextual-information"><![CDATA[Contextual information]]></category>
		<category domain="post_tag" nicename="eldercare"><![CDATA[Eldercare]]></category>
		<category domain="post_tag" nicename="identification-of-routines"><![CDATA[Identification of routines]]></category>
		<category domain="post_tag" nicename="sociological-profiles"><![CDATA[Sociological Profiles]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Artículo relevante ya publicado. Revista de publicación: Pervasive and Mobile Computing Available online : 24 May 2016 Numero: 34 Páginas: 106 - 125 DOI: http://dx.doi.org/10.1016/j.pmcj.2016.05.001 Factor de impacto: JCR 2.079, SJR 0.872, IPP 2.289, SNIP 2.051  Abstract:  With the increase in the elderly population, there is a concomitant growth in the number of cases of cognitive impairment. The early stages of these disorders can cause the elderly difficulties in performing their daily activities. To improve their independence while keeping their caregivers informed, this paper presents a monitoring system that focuses on the use of rich contextual information to detect a wide variety of a cognitively impaired persons routines and deviations from those routines. A detailed architecture of the system is presented together with an in-depth description of the algorithms for the identification of routines and deviations. In an experimental test with students, the algorithms identified some 91% of the routines and some 96% of the deviations.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/064]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_9.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_9.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose García-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Murillo Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards Mutation Testing of Configurable Simulink Models: a Product Line Engineering Perspective</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-mutation-testing-of-configurable-simulink-models-a-product-line-engineering-perspective/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-mutation-testing-of-configurable-simulink-models-a-product-line-engineering-perspective/</guid>
		<description></description>
		<content><![CDATA[Mutation testing has been found to be an efficient technique in order to assess the quality of a test suite. The use of Simulink models is increasing in both industry and academia to model and simulate complex systems such as Cyber-Physical Systems (CPSs). An advantage of Simulink is its ease to integrate software and control algorithms with complex mathematical models that typically represent continuous dynamic behaviors. In addition to that, the increasing trend of industry in adopting product line engineering methods to efficiently support the variability that their products demand is resulting in configurable Simulink models. Consequently, many configurations can be employed to test the configurable system. Each of these configurations will have a set of mutants, which will be in accordance with the configuration characteristics (i.e., features). However, manually generating and configuring mutants for each of the configurations is a time-consuming and non-systematic process. To deal with this problem, we propose a methodology supported by a tool that automatically generates mutants for configurable Simulink models.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2557</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-mutation-testing-of-configurable-simulink-models-a-product-line-engineering-perspective]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cyber-physical-systems"><![CDATA[Cyber-Physical Systems]]></category>
		<category domain="post_tag" nicename="feature-modeling"><![CDATA[Feature Modeling]]></category>
		<category domain="post_tag" nicename="matlabsimulink"><![CDATA[MATLAB/Simulink]]></category>
		<category domain="post_tag" nicename="mutation-testing"><![CDATA[Mutation testing]]></category>
		<category domain="post_tag" nicename="product-line-engineering"><![CDATA[Product Line Engineering]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Mutation testing has been found to be an efficient technique in order to assess the quality of a test suite. The use of Simulink models is increasing in both industry and academia to model and simulate complex systems such as Cyber-Physical Systems (CPSs). An advantage of Simulink is its ease to integrate software and control algorithms with complex mathematical models that typically represent continuous dynamic behaviors. In addition to that, the increasing trend of industry in adopting product line engineering methods to efficiently support the variability that their products demand is resulting in configurable Simulink models. Consequently, many configurations can be employed to test the configurable system. Each of these configurations will have a set of mutants, which will be in accordance with the configuration characteristics (i.e., features). However, manually generating and configuring mutants for each of the configurations is a time-consuming and non-systematic process. To deal with this problem, we propose a methodology supported by a tool that automatically generates mutants for configurable Simulink models.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/008]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_11.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_11.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aitor Arrieta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aarrieta@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Urtzi Markiegi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[umarkiegi@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Leire Etxeberria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[letxeberria@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Test Case Prioritization of Configurable Cyber-Physical Systems with Weight-Based Search Algorithms</title>
		<link>https://biblioteca.sistedes.es/articulo/test-case-prioritization-of-configurable-cyber-physical-systems-with-weight-based-search-algorithms/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/test-case-prioritization-of-configurable-cyber-physical-systems-with-weight-based-search-algorithms/</guid>
		<description></description>
		<content><![CDATA[El paper fue publicado en julio de 2016 en la conferencia GECCO (The Genetic and Evolutionary Computation Conference), que es un congreso de clase 2 del ranking SCIE de congresos relevantes. Hasta la fecha, según google scholar, ha recibido un total de dos citas. Cyber-Physical Systems (CPSs) can be found in many sectors (e.g., automotive and aerospace). These systems are usually configurable to give solutions based on different needs. The variability of these systems is large, which implies they can be set into millions of configurations. As a result, different testing processes are needed to efficiently test these systems: the appropriate configurations must be selected and relevant test cases for each configuration must be chosen as well as prioritized. Prioritizing the order in which the test cases are executed reduces the time for detecting faults in these kinds of systems. However, the test suite size is often large and exploring all the possible test case orders is infeasible. Search algorithms can help find optimal solutions from a large solution space. This paper presents an approach based on weight-based search algorithms for prioritizing the test cases for configurable CPSs. We empirically evaluate the performance of the following algorithms with two case studies: Weight-Based Genetic Algorithms, Random Weighted Genetic Algorithms, Greedy, Alternating Variable Method and Random Search (RS). Our results suggest that all the search algorithms outperform RS, which is taken as a baseline. Local search algorithms have shown better performance than global search algorithms.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2558</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[test-case-prioritization-of-configurable-cyber-physical-systems-with-weight-based-search-algorithms]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="configurable-cyber-physical-systems"><![CDATA[Configurable Cyber-Physical Systems]]></category>
		<category domain="post_tag" nicename="search-algorithms"><![CDATA[Search Algorithms]]></category>
		<category domain="post_tag" nicename="test-case-prioritization"><![CDATA[Test Case Prioritization]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El paper fue publicado en julio de 2016 en la conferencia GECCO (The Genetic and Evolutionary Computation Conference), que es un congreso de clase 2 del ranking SCIE de congresos relevantes.  Hasta la fecha, según google scholar, ha recibido un total de dos citas.    Cyber-Physical Systems (CPSs) can be found in many sectors (e.g., automotive and aerospace). These systems are usually configurable to give solutions based on different needs. The variability of these systems is large, which implies they can be set into millions of configurations. As a result, different testing processes are needed to efficiently test these systems: the appropriate configurations must be selected and relevant test cases for each configuration must be chosen as well as prioritized. Prioritizing the order in which the test cases are executed reduces the time for detecting faults in these kinds of systems. However, the test suite size is often large and exploring all the possible test case orders is infeasible. Search algorithms can help find optimal solutions from a large solution space. This paper presents an approach based on weight-based search algorithms for prioritizing the test cases for configurable CPSs. We empirically evaluate the performance of the following algorithms with two case studies: Weight-Based Genetic Algorithms, Random Weighted Genetic Algorithms, Greedy, Alternating Variable Method and Random Search (RS). Our results suggest that all the search algorithms outperform RS, which is taken as a baseline. Local search algorithms have shown better performance than global search algorithms.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/043]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_12.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_12.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aitor Arrieta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aarrieta@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Shuai Wang]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[shuai@simula.no]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Simula Research Laboratory]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Goiuria Sagardui]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gsagardui@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Mondragon]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Leire Etxeberria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[letxeberria@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Compact and queryable representation of raster datasets</title>
		<link>https://biblioteca.sistedes.es/articulo/compact-and-queryable-representation-of-raster-datasets/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/compact-and-queryable-representation-of-raster-datasets/</guid>
		<description></description>
		<content><![CDATA[Titulo: Compact and queryable representation of raster datasets Autores: Susana Ladra, José R. Paramá, Fernando Silva-Coira Congreso: INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATA BASE MANAGEMENT (SSDBM) 2016 Clasificación Ranking SCIE. Clase 2 (A-) Clasidicación CORE: A Citas: 2 DOI: http://dx.doi.org/10.1145/2949689.2949710]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2559</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[compact-and-queryable-representation-of-raster-datasets]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="compresion-de-datos"><![CDATA[Compresión de datos]]></category>
		<category domain="post_tag" nicename="raster"><![CDATA[Ráster]]></category>
		<category domain="post_tag" nicename="sistemas-de-informacion-geografica"><![CDATA[Sistemas de Informacíon Geográfica]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Titulo: Compact and queryable representation of raster datasets Autores: Susana Ladra, José R. Paramá, Fernando Silva-Coira  Congreso: INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATA BASE MANAGEMENT (SSDBM) 2016  Clasificación Ranking SCIE. Clase 2 (A-) Clasidicación CORE: A  Citas: 2  DOI: http://dx.doi.org/10.1145/2949689.2949710]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/012]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_13.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_13.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Susana Ladra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[susana.ladra@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José R. Paramá]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jose.parama@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Fernando Silva-Coira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fernando.silva@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Multi-Objective Test Case Prioritization in Highly Configurable Systems: A Case Study</title>
		<link>https://biblioteca.sistedes.es/articulo/multi-objective-test-case-prioritization-in-highly-configurable-systems-a-case-study/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/multi-objective-test-case-prioritization-in-highly-configurable-systems-a-case-study/</guid>
		<description></description>
		<content><![CDATA[Test case prioritization schedules test cases for execution in an order that attempts to accelerate the detection of faults. The order of test cases is determined by prioritization objectives such as covering code or critical components as rapidly as possible. The importance of this technique has been recognized in the context of Highly-Configurable Systems (HCSs), where the potentially huge number of configurations makes testing extremely challenging. However, current approaches for test case prioritization in HCSs suffer from two main limitations. First, the prioritization is usually driven by a single objective which neglects the potential benefits of combining multiple criteria to guide the detection of faults. Second, instead of using industry-strength case studies, evaluations are conducted using synthetic data, which provides no information about the effectiveness of different prioritization objectives. In this paper, we address both limitations by studying 63 combinations of up to three prioritization objectives in accelerating the detection of faults in the Drupal framework. Results show that non-functional properties such as the number of changes in the features are more effective than functional metrics extracted from the configuration model. Results also suggest that multi-objective prioritization typically results in faster fault detection than mono-objective prioritization. Indicios de calidad de la revista: Journal of Systems and Software (Elsevier) ISSN: 0164-1212 Factor de impacto 2015: 1,424 Factor de impacto a 5 años: 1,767 Indexada en dos categorías: Computer Science / Theory &amp; Methods: 31/105 (Q2) Computer Science / Software Engineering: 24/106 (Q1) Otros datos: CiteScore: 2.93 Source Normalized Impact per Paper (SNIP): 2.415 SCImago Journal Rank (SJR): 0.897 Indicios de calidad del propio paper: Número de Citas según Google Scholar: 3 Número de lecturas según Research Gate: 73]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2560</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[multi-objective-test-case-prioritization-in-highly-configurable-systems-a-case-study]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="optimizacion-multi-objetivo"><![CDATA[optimización multi-objetivo]]></category>
		<category domain="post_tag" nicename="priorizacion-de-pruebas"><![CDATA[priorización de pruebas]]></category>
		<category domain="post_tag" nicename="sistemas-altamente-configurables"><![CDATA[sistemas altamente configurables]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Test case prioritization schedules test cases for execution in an order that attempts to accelerate the detection of faults. The order of test cases is determined by prioritization objectives such as covering code or critical components as rapidly as possible. The importance of this technique has been recognized in the context of Highly-Configurable Systems (HCSs), where the potentially huge number of configurations makes testing extremely challenging. However, current approaches for test case prioritization in HCSs suffer from two main limitations. First, the prioritization is usually driven by a single objective which neglects the potential benefits of combining multiple criteria to guide the detection of faults. Second, instead of using industry-strength case studies, evaluations are conducted using synthetic data, which provides no information about the effectiveness of different prioritization objectives. In this paper, we address both limitations by studying 63 combinations of up to three prioritization objectives in accelerating the detection of faults in the Drupal framework. Results show that non-functional properties such as the number of changes in the features are more effective than functional metrics extracted from the configuration model. Results also suggest that multi-objective prioritization typically results in faster fault detection than mono-objective prioritization.  Indicios de calidad de la revista: Journal of Systems and Software (Elsevier) ISSN: 0164-1212  Factor de impacto 2015: 1,424  Factor de impacto a 5 años: 1,767  Indexada en dos categorías:  Computer Science / Theory & Methods: 31/105 (Q2)  Computer Science / Software Engineering: 24/106 (Q1)  Otros datos:  CiteScore: 2.93  Source Normalized Impact per Paper (SNIP): 2.415  SCImago Journal Rank (SJR): 0.897  Indicios de calidad del propio paper: Número de Citas según Google Scholar: 3 Número de lecturas según Research Gate: 73]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/040]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_14.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_14.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Antonio Parejo Maestre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[japarejo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ana Belén Sánchez Jerez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[anabsanchez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Roberto Erick Lopez-Herrejón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[Roberto.Lopez@etsmtl.ca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Department of Software Engineering and Information Technology of the École de Technologie Supérieure of the University of Quebec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Alexander Egyed]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[alexander.egyed@jku.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Institute for Software Systems Engineering,  Johannes Kepler University]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evaluación de la Mejora de Conjuntos de Casos de Prueba mediante la Prueba de Mutación Evolutiva</title>
		<link>https://biblioteca.sistedes.es/articulo/evaluacion-de-la-mejora-de-conjuntos-de-casos-de-prueba-mediante-la-prueba-de-mutacion-evolutiva/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/evaluacion-de-la-mejora-de-conjuntos-de-casos-de-prueba-mediante-la-prueba-de-mutacion-evolutiva/</guid>
		<description></description>
		<content><![CDATA[La Prueba de Mutación Evolutiva (PME) es una técnica surgida recientemente para reducir el número de mutantes a generar en la prueba de mutaciones y, por consiguiente, su alto coste computacional. Esto se logra a través de un algoritmo genético, el cual trata de localizar la mayor cantidad posible de los mutantes con potencial para guiar a la mejora del conjunto de casos de prueba (denominados mutantes fuertes) en ese subconjunto de mutantes generado. La técnica ha sido evaluada precisamente respecto a esa capacidad de encontrar mutantes fuertes, pero tal análisis omite el hecho de que parte de esos mutantes fuertes puede no aportar a la mejora de las pruebas ya que son mutantes equivalentes. Por esa razón, en este artículo se propone una nueva metodología para la evaluación de la PME. Esta realiza una estimación del refinamiento conseguido del conjunto de pruebas a través de los mutantes seleccionados por el algoritmo genético. Esta metodología se emplea sobre cuatro programas en C++ que aplican orientación a objetos, mostrando que la PME es capaz de aumentar el conjunto de pruebas generando un porcentaje menor de mutantes que la selección aleatoria.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2561</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evaluacion-de-la-mejora-de-conjuntos-de-casos-de-prueba-mediante-la-prueba-de-mutacion-evolutiva]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="algoritmos-geneticos"><![CDATA[Algoritmos genéticos]]></category>
		<category domain="post_tag" nicename="prueba-de-mutaciones"><![CDATA[prueba de mutaciones]]></category>
		<category domain="post_tag" nicename="prueba-de-software"><![CDATA[Prueba de software]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La Prueba de Mutación Evolutiva (PME) es una técnica surgida recientemente para reducir el número de mutantes a generar en la prueba de mutaciones y, por consiguiente, su alto coste computacional. Esto se logra a través de un algoritmo genético, el cual trata de localizar la mayor cantidad posible de los mutantes con potencial para guiar a la mejora del conjunto de casos de prueba (denominados mutantes fuertes) en ese subconjunto de mutantes generado. La técnica ha sido evaluada precisamente respecto a esa capacidad de encontrar mutantes fuertes, pero tal análisis omite el hecho de que parte de esos mutantes fuertes puede no aportar a la mejora de las pruebas ya que son mutantes equivalentes. Por esa razón, en este artículo se propone una nueva metodología para la evaluación de la PME. Esta realiza una estimación del refinamiento conseguido del conjunto de pruebas a través de los mutantes seleccionados por el algoritmo genético. Esta metodología se emplea sobre cuatro programas en C++ que aplican orientación a objetos, mostrando que la PME es capaz de aumentar el conjunto de pruebas generando un porcentaje menor de mutantes que la selección aleatoria.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/036]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_15.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_15.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Delgado-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pedro.delgado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Mejora del Rendimiento de la Prueba de Mutación Evolutiva mediante la Reducción de Mutantes Equivalentes</title>
		<link>https://biblioteca.sistedes.es/articulo/mejora-del-rendimiento-de-la-prueba-de-mutacion-evolutiva-mediante-la-reduccion-de-mutantes-equivalentes/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/mejora-del-rendimiento-de-la-prueba-de-mutacion-evolutiva-mediante-la-reduccion-de-mutantes-equivalentes/</guid>
		<description></description>
		<content><![CDATA[La Prueba de Mutación Evolutiva (PME) busca la generación de un subconjunto de mutantes mediante un algoritmo genético con el objetivo de mejorar el conjunto de casos de prueba a un menor coste. A pesar de los resultados positivos obtenidos hasta el momento empleando esta técnica, otros avances paralelos en la prueba de mutaciones pueden aumentar la eficiencia de la PME. En este artículo se propone la incorporación en herramientas que aplican la PME de nuevas técnicas para ayudar a detectar mutantes que son equivalentes al programa original, exponiendo los beneficios de esta fusión.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2562</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mejora-del-rendimiento-de-la-prueba-de-mutacion-evolutiva-mediante-la-reduccion-de-mutantes-equivalentes]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="algoritmos-geneticos"><![CDATA[Algoritmos genéticos]]></category>
		<category domain="post_tag" nicename="prueba-de-mutaciones"><![CDATA[prueba de mutaciones]]></category>
		<category domain="post_tag" nicename="prueba-de-software"><![CDATA[Prueba de software]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La Prueba de Mutación Evolutiva (PME) busca la generación de un subconjunto de mutantes mediante un algoritmo genético con el objetivo de mejorar el conjunto de casos de prueba a un menor coste. A pesar de los resultados positivos obtenidos hasta el momento empleando esta técnica, otros avances paralelos en la prueba de mutaciones pueden aumentar la eficiencia de la PME. En este artículo se propone la incorporación en herramientas que aplican la PME de nuevas técnicas para ayudar a detectar mutantes que son equivalentes al programa original, exponiendo los beneficios de esta fusión.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/039]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_16.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_16.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Delgado-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pedro.delgado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Requirements reuse and requirement patterns: a state of the practice survey</title>
		<link>https://biblioteca.sistedes.es/articulo/requirements-reuse-and-requirement-patterns-a-state-of-the-practice-survey/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/requirements-reuse-and-requirement-patterns-a-state-of-the-practice-survey/</guid>
		<description></description>
		<content><![CDATA[Autores: Cristina Palomares, Carme Quer, Xavier Franch Revista: Empirical Software Engineering (Springer), in press DOI: http://dx.doi.org/10.1007/s10664-016-9485-x JCR IF 2015: 1.393 (27/106 de la categoría de ingeniería del software)]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2563</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[requirements-reuse-and-requirement-patterns-a-state-of-the-practice-survey]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="exploratory-survey"><![CDATA[exploratory survey]]></category>
		<category domain="post_tag" nicename="online-questionnaire"><![CDATA[online questionnaire]]></category>
		<category domain="post_tag" nicename="requirements-engineering"><![CDATA[requirements engineering]]></category>
		<category domain="post_tag" nicename="software-rerquirement-patterns"><![CDATA[software rerquirement patterns]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Autores: Cristina Palomares, Carme Quer, Xavier Franch  Revista: Empirical Software Engineering (Springer), in press  DOI: http://dx.doi.org/10.1007/s10664-016-9485-x  JCR IF 2015: 1.393 (27/106 de la categoría de ingeniería del software) ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/051]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_17.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_17.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cristina Palomares]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cpalomares@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carme Quer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cquer@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Xavier Franch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[franch@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>On the use of developers context for automatic refactoring of software anti-patterns</title>
		<link>https://biblioteca.sistedes.es/articulo/on-the-use-of-developers-context-for-automatic-refactoring-of-software-anti-patterns/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/on-the-use-of-developers-context-for-automatic-refactoring-of-software-anti-patterns/</guid>
		<description></description>
		<content><![CDATA[Publication: Journal of Systems and Software Number: Available On-line Month and Year: May 2016 DOI: 10.1016/j.jss.2016.05.042 Quality indicators of the journal: ISI JCR IF=1.424 (Q1 in CS/SE, Q2 in CS/TM), 5-year IF=1.767, SNIP=2.415, SJR=0.897, CiteScore=2.93 Citations (according to Google Scholar): 4]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2564</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[on-the-use-of-developers-context-for-automatic-refactoring-of-software-anti-patterns]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="anti-patterns"><![CDATA[Anti-patterns]]></category>
		<category domain="post_tag" nicename="automatic-refactoring"><![CDATA[Automatic refactoring]]></category>
		<category domain="post_tag" nicename="interaction-traces"><![CDATA[Interaction traces]]></category>
		<category domain="post_tag" nicename="metaheuristics"><![CDATA[Metaheuristics]]></category>
		<category domain="post_tag" nicename="software-maintenance"><![CDATA[Software maintenance]]></category>
		<category domain="post_tag" nicename="task-context"><![CDATA[Task context]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Publication: Journal of Systems and Software Number: Available On-line Month and Year: May 2016 DOI: 10.1016/j.jss.2016.05.042 Quality indicators of the journal: ISI JCR IF=1.424 (Q1 in CS/SE, Q2 in CS/TM), 5-year IF=1.767, SNIP=2.415, SJR=0.897, CiteScore=2.93 Citations (according to Google Scholar): 4]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/041]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_19.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_19.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rodrigo Morales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rodrigo.morales@polymtl.ca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Polytechnique Montréal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Zéphyrin Soh]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[zephyrin.soh@polymtl.ca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Polytechnique Montréal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Foutse Khomh]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[foutse.khomh@polymtl.ca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Polytechnique Montréal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Giuliano Antoniol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[giuliano.antoniol@polymtl.ca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Polytechnique Montréal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Francisco Chicano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[chicano@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Configuración Eco-Eficiente de Atributos de Calidad Funcionales</title>
		<link>https://biblioteca.sistedes.es/articulo/configuracion-eco-eficiente-de-atributos-de-calidad-funcionales/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/configuracion-eco-eficiente-de-atributos-de-calidad-funcionales/</guid>
		<description></description>
		<content><![CDATA[Los atributos de calidad funcionales (FQAs) son aquellos que para satisfacerlos se necesita incorporar funcionalidad adicional a la arquitectura de las aplicación (e.g., seguridad). La nueva funcionalidad incorporada por estos FQAs (e.g., encriptación) afecta a otro atributo de calidad como es el consumo de energía de la aplicación. Hasta el momento no se han explorado suficientemente las interdependencias entre, por ejemplo diferentes niveles de seguridad y su incidencia en el consumo de energía. En este artículo se propone una solución para ayudar al arquitecto software a generar la configuración de los FQAs que optimiza la eficiencia energética de la aplicación. Para ello se define un modelo de uso para cada FQA, teniendo en cuenta las variables que influyen en el consumo de energía y como el valor de estas variables cambia en función del punto de la aplicación donde se requiere ese FQA. Se extiende una Línea de Productos Software que modela una familia de FQAs para incorporar la variabilidad del modelo de uso y los frameworks existentes que implementan los FQAs. Generamos la configuración más eco-eficiente seleccionando el framework y las características más adecuadas para cada FQA y configurándolo según los requisitos de la aplicación.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2565</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[configuracion-eco-eficiente-de-atributos-de-calidad-funcionales]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="atributos-de-calidad"><![CDATA[Atributos de Calidad]]></category>
		<category domain="post_tag" nicename="eco-eficiente"><![CDATA[Eco-Eficiente]]></category>
		<category domain="post_tag" nicename="energia"><![CDATA[Energía]]></category>
		<category domain="post_tag" nicename="fqa"><![CDATA[FQA]]></category>
		<category domain="post_tag" nicename="linea-de-productos-software"><![CDATA[Línea de Productos Software]]></category>
		<category domain="post_tag" nicename="variabilidad"><![CDATA[Variabilidad]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los atributos de calidad funcionales (FQAs) son aquellos que para satisfacerlos se necesita incorporar funcionalidad adicional a la arquitectura de las aplicación (e.g., seguridad). La nueva funcionalidad incorporada por estos FQAs (e.g., encriptación) afecta a otro atributo de calidad como es el consumo de energía de la aplicación. Hasta el momento no se han explorado suficientemente las interdependencias entre, por ejemplo diferentes niveles de seguridad y su incidencia en el consumo de energía. En este artículo se propone una solución para ayudar al arquitecto software a generar la configuración de los FQAs que optimiza la eficiencia energética de la aplicación. Para ello se define un modelo de uso para cada FQA, teniendo en cuenta las variables que influyen en el consumo de energía y como el valor de estas variables cambia en función del punto de la aplicación donde se requiere ese FQA. Se extiende una Línea de Productos Software que modela una familia de FQAs para incorporar la variabilidad del modelo de uso y los frameworks existentes que implementan los FQAs. Generamos la configuración más eco-eficiente seleccionando el framework y las características más adecuadas para cada FQA y configurándolo según los requisitos de la aplicación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/003]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_22.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_22.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Miguel Horcas Aguilera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[horcas@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mónica Pinto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pinto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Universal indexes for highly repetitive document collections</title>
		<link>https://biblioteca.sistedes.es/articulo/universal-indexes-for-highly-repetitive-document-collections/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/universal-indexes-for-highly-repetitive-document-collections/</guid>
		<description></description>
		<content><![CDATA[Abstract ======== Indexing highly repetitive collections has become a relevant problem with the emergence of large repositories of versioned documents, among other applications. These collections may reach huge sizes, but are formed mostly of documents that are near-copies of others. Traditional techniques for indexing these collections fail to properly exploit their regularities in order to reduce space. We introduce new techniques for compressing inverted indexes that exploit this near-copy regularity. They are based on run-length, Lempel-Ziv, or grammar compression of the differential inverted lists, instead of the usual practice of gap-encoding them. We show that, in this highly repetitive setting, our compression methods significantly reduce the space obtained with classical techniques, at the price of moderate slowdowns. Moreover, our best methods are universal, that is, they do not need to know the versioning structure of the collection, nor that a clear versioning structure even exists. We also introduce compressed self-indexes in the comparison. These are designed for general strings (not only natural language texts) and represent the text collection plus the index structure (not an inverted index) in integrated form. We show that these techniques can compress much further, using a small fraction of the space required by our new inverted indexes. Yet, they are orders of magnitude slower. Publication Details =================== Francisco Claude, Antonio Fariña, Miguel A. Martínez-Prieto, Gonzalo Navarro. Universal indexes for highly repetitive document collections Information Systems, 61, pp. 1-23, 2016, DOI: http://dx.doi.org/10.1016/j.is.2016.04.002 Citations Google Scholar: 3 (2 self-citations)]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2566</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[universal-indexes-for-highly-repetitive-document-collections]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="inverted-index"><![CDATA[Inverted index]]></category>
		<category domain="post_tag" nicename="repetitive-collections"><![CDATA[Repetitive collections]]></category>
		<category domain="post_tag" nicename="self-index"><![CDATA[Self-index]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Abstract ======== Indexing highly repetitive collections has become a relevant problem with the emergence of large repositories of versioned documents, among other applications. These collections may reach huge sizes, but are formed mostly of documents that are near-copies of others. Traditional techniques for indexing these collections fail to properly exploit their regularities in order to reduce space.  We introduce new techniques for compressing inverted indexes that exploit this near-copy regularity. They are based on run-length, Lempel-Ziv, or grammar compression of the differential inverted lists, instead of the usual practice of gap-encoding them. We show that, in this highly repetitive setting, our compression methods significantly reduce the space obtained with classical techniques, at the price of moderate slowdowns. Moreover, our best methods are universal, that is, they do not need to know the versioning structure of the collection, nor that a clear versioning structure even exists.  We also introduce compressed self-indexes in the comparison. These are designed for general strings (not only natural language texts) and represent the text collection plus the index structure (not an inverted index) in integrated form. We show that these techniques can compress much further, using a small fraction of the space required by our new inverted indexes. Yet, they are orders of magnitude slower.  Publication Details =================== Francisco Claude, Antonio Fariña, Miguel A. Martínez-Prieto, Gonzalo Navarro. Universal indexes for highly repetitive document collections Information Systems, 61, pp. 1-23, 2016,  DOI: http://dx.doi.org/10.1016/j.is.2016.04.002  Citations Google Scholar: 3 (2 self-citations)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/024]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_24.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_24.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Claude]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fclaude@recoded.cl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Diego Portales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Fariña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fari@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of A Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Miguel A. Martinez-Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[migumar2@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DataWeb Research,  Department of Computer Science,  University of Valladolid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Gonzalo Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[gnavarro@dcc.uchile.cl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Chile]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Interactive Fuzzy Inference System for Teletherapy of Older People</title>
		<link>https://biblioteca.sistedes.es/articulo/an-interactive-fuzzy-inference-system-for-teletherapy-of-older-people/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-interactive-fuzzy-inference-system-for-teletherapy-of-older-people/</guid>
		<description></description>
		<content><![CDATA[The progressive aging of the population in developed countries is becoming a problem for healthcare systems, which must invest ever higher sums in caring for their older citizens. One of the most important issues in this area involves the physical and cognitive problems associated with growing old. In order to reduce the effect of these problems, gerontechnology has emerged as one of the most promising alternatives, especially in the field of the telerehabilitation systems developed to date. However, most of these systems do not offer therapists the facilities to design therapies adapted to individual patients. This paper proposes a novel system that supplies this need and enables therapists to create bespoke motor therapies as state diagrams and manage them efficiently in a collaborative setting. The proposed system is equipped with a fuzzy-based decision-making component that therapists can use to control transitioning between states according to variables such as fatigue and performance. Therefore, the system makes it feasible to provide older patients with the treatment they need in their own homes while its effectiveness is controlled by a Fuzzy Inference System. Cogn Comput (2016) 8:318-335 DOI 10.1007/s12559-015-9356-6 Ã?ndice de calidad: ------------------------ índice de impacto: 1.993 Posición relativa: 41/130]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2567</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-interactive-fuzzy-inference-system-for-teletherapy-of-older-people]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="bespoke-therapy-editor"><![CDATA[Bespoke therapy editor]]></category>
		<category domain="post_tag" nicename="fuzzy-inference-system"><![CDATA[Fuzzy Inference System]]></category>
		<category domain="post_tag" nicename="gerontechnology"><![CDATA[Gerontechnology]]></category>
		<category domain="post_tag" nicename="telerehabilitation"><![CDATA[Telerehabilitation]]></category>
		<category domain="post_tag" nicename="teletherapy"><![CDATA[Teletherapy]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The progressive aging of the population in developed countries is becoming a problem for healthcare systems, which must invest ever higher sums in caring for their older citizens. One of the most important issues in this area involves the physical and cognitive problems associated with growing old. In order to reduce the effect of these problems, gerontechnology has emerged as one of the most promising alternatives, especially in the field of the telerehabilitation systems developed to date. However, most of these systems do not offer therapists the facilities to design therapies adapted to individual patients. This paper proposes a novel system that supplies this need and enables therapists to create bespoke motor therapies as state diagrams and manage them efficiently in a collaborative setting. The proposed system is equipped with a fuzzy-based decision-making component that therapists can use to control transitioning between states according to variables such as fatigue and performance. Therefore, the system makes it feasible to provide older patients with the treatment they need in their own homes while its effectiveness is controlled by a Fuzzy Inference System.  Cogn Comput (2016) 8:318-335 DOI 10.1007/s12559-015-9356-6  Ã?ndice de calidad:  ------------------------ índice de impacto: 1.993 Posición relativa: 41/130]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/060]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_26.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_26.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel A. Teruel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[miguel@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Elena Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[elena.navarro@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pascual Gonzalez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pgonzalez@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Víctor López-Jaquero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[victor@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Francisco Montero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[fmontero@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An ACO-based personalized learning technique in support of people with acquired brain injury</title>
		<link>https://biblioteca.sistedes.es/articulo/an-aco-based-personalized-learning-technique-in-support-of-people-with-acquired-brain-injury/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-aco-based-personalized-learning-technique-in-support-of-people-with-acquired-brain-injury/</guid>
		<description></description>
		<content><![CDATA[The ever-increasing cases of acquired brain injury (ABI), especially among young people, have prompted a rapid progress in research involving neurological disorders. One important path is the concept of relearning, which attempts to help people regain basic motor and cognitive skills lost due to illness or accident. The goals of relearning are twofold. First, there must exist a way to properly assess the necessities of an affected person, leading to a diagnosis, followed by a recommendation regarding the exercises, tests and tasks to perform, and second, there must be a way to confirm the results obtained from these recommendations in order to fine-tune and personalize the relearning process. This presents a challenge, as there is a deeply-rooted duality between the personalized and the generalized approach. In this work we propose a personalization algorithm based on the ant colony optimization (ACO), which is a bio-inspired meta-heuristic. As we show, the stochastic nature of ants has certain similarities to the human learning process. Applied Soft Computing 47 (2016) 316-331 http://dx.doi.org/10.1016/j.asoc.2016.04.039 21/130 (Q1) We combine the adaptive and exploratory capabilities of ACO systems to respond to rapidly changing environments and the ubiquitous human factor. Finally, we test the proposed solution extensively in various scenarios, achieving high quality results.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2568</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-aco-based-personalized-learning-technique-in-support-of-people-with-acquired-brain-injury]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="abi"><![CDATA[ABI]]></category>
		<category domain="post_tag" nicename="aco"><![CDATA[ACO]]></category>
		<category domain="post_tag" nicename="acquired-brain-injury"><![CDATA[Acquired brain injury]]></category>
		<category domain="post_tag" nicename="recommendation-system"><![CDATA[Recommendation system]]></category>
		<category domain="post_tag" nicename="relearning-process"><![CDATA[Relearning process]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The ever-increasing cases of acquired brain injury (ABI), especially among young people, have prompted a rapid progress in research involving neurological disorders. One important path is the concept of relearning, which attempts to help people regain basic motor and cognitive skills lost due to illness or accident. The goals of relearning are twofold. First, there must exist a way to properly assess the necessities of an affected person, leading to a diagnosis, followed by a recommendation regarding the exercises, tests and tasks to perform, and second, there must be a way to confirm the results obtained from these recommendations in order to fine-tune and personalize the relearning process.  This presents a challenge, as there is a deeply-rooted duality between the personalized and the generalized approach. In this work we propose a personalization algorithm based on the ant colony optimization (ACO), which is a bio-inspired meta-heuristic. As we show, the stochastic nature of ants has certain similarities to the human learning process.  Applied Soft Computing 47 (2016) 316-331 http://dx.doi.org/10.1016/j.asoc.2016.04.039  21/130 (Q1)    We combine the adaptive and exploratory capabilities of ACO systems to respond to rapidly changing environments and the ubiquitous human factor. Finally, we test the proposed solution extensively in various scenarios, achieving high quality results.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/059]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_27.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_27.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Kamil Krynicki]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[kkrynicki@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Jaen]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fjaen@upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Elena Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Elena.Navarro@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Applying thematic analysis to define an awareness interpretation for collaborative computer games</title>
		<link>https://biblioteca.sistedes.es/articulo/applying-thematic-analysis-to-define-an-awareness-interpretation-for-collaborative-computer-games/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/applying-thematic-analysis-to-define-an-awareness-interpretation-for-collaborative-computer-games/</guid>
		<description></description>
		<content><![CDATA[Indices de calidad: Índice de impacto: 1.569, Q1 Posición que ocupa la revista en la categoría: 16/106 Número de citas: 3 Context Collaborative computer games have evolved from single-player to massively multiplayer awareness-demanding games, usually involving collaboration to achieve team goals. As a consequence of such evolution, these players should be provided with awareness information that enables them to perform collaborative tasks with other team members. Objective The objective of this work is the analysis of current awareness interpretations in order to develop an awareness interpretation that collects the awareness needs of such games. Method This analysis has been conducted by means of a step-by-step Thematic Analysis of current interpretations that led us to extract the most relevant awareness elements defined in existing interpretations. The developed awareness interpretation was empirically evaluated by means of several surveys aimed at assessing whether the implementation of the interpretation elements in a game would improve the players enjoyment. Results The Thematic Synthesis Analysis concluded that none of the current awareness interpretations can deal properly with collaborative computer games, specifically due to collaboration and social &amp; group dynamics. This Thematic Synthesis Analysis led us to coin Gamespace Awareness, a new awareness interpretation based on a combination of the previously analyzed awareness interpretations, which is suitable for collaborative computer games. The interpretation was positively evaluated for two games, namely a first person shooter and a real-time strategy game. Conclusions Gamespace Awareness combines the potential awareness elements needed for collaborative computer games, making it possible to identify the awareness requirements of these games from the very beginning.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2569</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[applying-thematic-analysis-to-define-an-awareness-interpretation-for-collaborative-computer-games]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="awareness"><![CDATA[Awareness]]></category>
		<category domain="post_tag" nicename="collaborative-computer-games"><![CDATA[Collaborative computer games]]></category>
		<category domain="post_tag" nicename="empirical-evaluation"><![CDATA[Empirical evaluation]]></category>
		<category domain="post_tag" nicename="game-development"><![CDATA[Game development]]></category>
		<category domain="post_tag" nicename="gamespace-awareness"><![CDATA[Gamespace awareness]]></category>
		<category domain="post_tag" nicename="thematic-synthesis"><![CDATA[Thematic synthesis]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Indices de calidad: Ã?ndice de impacto: 1.569, Q1 Posición que ocupa la revista en la categoría: 16/106 Número de citas: 3   Context Collaborative computer games have evolved from single-player to massively multiplayer awareness-demanding games, usually involving collaboration to achieve team goals. As a consequence of such evolution, these players should be provided with awareness information that enables them to perform collaborative tasks with other team members.  Objective  The objective of this work is the analysis of current awareness interpretations in order to develop an awareness interpretation that collects the awareness needs of such games.  Method  This analysis has been conducted by means of a step-by-step Thematic Analysis of current interpretations that led us to extract the most relevant awareness elements defined in existing interpretations. The developed awareness interpretation was empirically evaluated by means of several surveys aimed at assessing whether the implementation of the interpretation elements in a game would improve the players enjoyment.  Results  The Thematic Synthesis Analysis concluded that none of the current awareness interpretations can deal properly with collaborative computer games, specifically due to collaboration and social & group dynamics. This Thematic Synthesis Analysis led us to coin Gamespace Awareness, a new awareness interpretation based on a combination of the previously analyzed awareness interpretations, which is suitable for collaborative computer games. The interpretation was positively evaluated for two games, namely a first person shooter and a real-time strategy game.  Conclusions  Gamespace Awareness combines the potential awareness elements needed for collaborative computer games, making it possible to identify the awareness requirements of these games from the very beginning.   ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/046]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_28.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_28.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel A. Teruel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[miguel@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Elena Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Elena.Navarro@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pascual Gonzalez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pgonzalez@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Víctor López-Jaquero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[victor@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Francisco Montero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[fmontero@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>DScaffolding: una Herramienta de Apoyo en el Aprendizaje y la Ejecución de Investigación Científica Basada en Diseño</title>
		<link>https://biblioteca.sistedes.es/articulo/dscaffolding-una-herramienta-de-apoyo-en-el-aprendizaje-y-la-ejecucion-de-investigacion-cientifica-basada-en-diseno/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/dscaffolding-una-herramienta-de-apoyo-en-el-aprendizaje-y-la-ejecucion-de-investigacion-cientifica-basada-en-diseno/</guid>
		<description></description>
		<content><![CDATA[El aprendizaje y la práctica de Investigación Científica Basada en Diseño (ICBD) son tareas complejas para las que no existe asistencia más allá de publicaciones. Estas dos tareas abarcan numerosas actividades que deben ser dominadas y coordinadas. Este artículo describe una nueva herramienta, DScaffolding, desarrollada con el fin de asistir a los investigadores principiantes en la ejecución de proyectos de ICBD. Las actividades de ICBD se integran dentro un popular editor de mapas mentales (MindMeister). Se ha realizado una evaluación formativa sobre una versión inicial de DScaffolding. El prototipo está disponible en forma de extensión en la tienda web de Google Chrome.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2570</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[dscaffolding-una-herramienta-de-apoyo-en-el-aprendizaje-y-la-ejecucion-de-investigacion-cientifica-basada-en-diseno]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="analisis-de-causa-raiz"><![CDATA[Análisis de Causa Raíz]]></category>
		<category domain="post_tag" nicename="investigacion-cientifica-basada-en-diseno"><![CDATA[Investigación Científica Basada en Diseño]]></category>
		<category domain="post_tag" nicename="mapas-mentales"><![CDATA[Mapas Mentales]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El aprendizaje y la práctica de Investigación Científica Basada en Diseño (ICBD) son tareas complejas para las que no existe asistencia más allá de publicaciones. Estas dos tareas abarcan numerosas actividades que deben ser dominadas y coordinadas. Este artículo describe una nueva herramienta, DScaffolding, desarrollada con el fin de asistir a los investigadores principiantes en la ejecución de proyectos de ICBD. Las actividades de ICBD se integran dentro un popular editor de mapas mentales (MindMeister). Se ha realizado una evaluación formativa sobre una versión inicial de DScaffolding. El prototipo está disponible en forma de extensión en la tienda web de Google Chrome.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/048]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_29.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_29.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Oscar Diaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[oscar.diaz@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad del País Vasco (UPV/EHU), San Sebastián, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jeremías P. Contell]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jeremias.perez@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad del País Vasco (UPV/EHU), San Sebastián, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[John Venable]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[j.venable@curtin.edu.au]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[School of Information Systems, Curtin University of Technology, Perth, Western Australia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Incremental Consolidation of Data-Intensive Multi-Flows</title>
		<link>https://biblioteca.sistedes.es/articulo/incremental-consolidation-of-data-intensive-multi-flows/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/incremental-consolidation-of-data-intensive-multi-flows/</guid>
		<description></description>
		<content><![CDATA[En Transactions on Knowledge and Data Engineering, 28(5). IEEE Press, May 2016. Páginas 1203-1216. ISSN: 1041-4347. DOI: 10.1109/TKDE.2016.2515609 Ã?ndice de impacto: JCR-Science Edition 2015, 2.476 Quartil i área: Q1, COMPUTER SCIENCE, INFORMATION SYSTEMS, 17/143 Business intelligence (BI) systems depend on efficient integration of disparate and often heterogeneous data. The integration of data is governed by data-intensive flows and is driven by a set of information requirements. Designing such flows is in general a complex process, which due to the complexity of business environments is hard to be done manually. In this paper, we deal with the challenge of efficient design and maintenance of data-intensive flows and propose an incremental approach, namely CoAl , for semi-automatically consolidating data-intensive flows satisfying a given set of information requirements. CoAl works at the logical level and consolidates data flows from either high-level information requirements or platform-specific programs. As CoAl integrates a new data flow, it opts for maximal reuse of existing flows and applies a customizable cost model tuned for minimizing the overall cost of a unified solution. We demonstrate the efficiency and effectiveness of our approach through an experimental evaluation using our implemented prototype.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2571</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[incremental-consolidation-of-data-intensive-multi-flows]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="business-intelligence"><![CDATA[Business Intelligence]]></category>
		<category domain="post_tag" nicename="data-warehousing"><![CDATA[Data warehousing]]></category>
		<category domain="post_tag" nicename="data-intensive-flows"><![CDATA[Data-intensive flows]]></category>
		<category domain="post_tag" nicename="workflow-management"><![CDATA[Workflow management]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En Transactions on Knowledge and Data Engineering, 28(5). IEEE Press, May 2016. Páginas 1203-1216.  ISSN: 1041-4347.  DOI: 10.1109/TKDE.2016.2515609 Ã?ndice de impacto: JCR-Science Edition 2015, 2.476 Quartil i área: Q1, COMPUTER SCIENCE, INFORMATION SYSTEMS, 17/143  Business intelligence (BI) systems depend on efficient integration of disparate and often heterogeneous data. The integration of data is governed by data-intensive flows and is driven by a set of information requirements. Designing such flows is in general a complex process, which due to the complexity of business environments is hard to be done manually. In this paper, we deal with the challenge of efficient design and maintenance of data-intensive flows and propose an incremental approach, namely CoAl , for semi-automatically consolidating data-intensive flows satisfying a given set of information requirements. CoAl works at the logical level and consolidates data flows from either high-level information requirements or platform-specific programs. As CoAl integrates a new data flow, it opts for maximal reuse of existing flows and applies a customizable cost model tuned for minimizing the overall cost of a unified solution. We demonstrate the efficiency and effectiveness of our approach through an experimental evaluation using our implemented prototype.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/019]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_30.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_30.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Petar Jovanovic]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[petar@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica De Catalunya - Barcelona Tech]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Oscar Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[oromero@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alkis Simitsis]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[alkis@hpe.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[HP Labs]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Alberto Abello]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aabello@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Mejorando el Conocimiento de los Estudiantes sobre Desarrollo Global del Software mediante un Juego Serio</title>
		<link>https://biblioteca.sistedes.es/articulo/mejorando-el-conocimiento-de-los-estudiantes-sobre-desarrollo-global-del-software-mediante-un-juego-serio/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/mejorando-el-conocimiento-de-los-estudiantes-sobre-desarrollo-global-del-software-mediante-un-juego-serio/</guid>
		<description></description>
		<content><![CDATA[La globalización ha llevado a muchas empresas a realizar el desarrollo de sus productos de una manera distribuida, llevándose a cabo por diferentes equipos e incluso desde diferentes países. Este nuevo paradigma de desarrollo se conoce como Desarrollo Global del Software - DGS. Para realizar esta práctica las empresas requieren desarrolladores que posean conocimientos y habilidades para solventar los problemas que surgen a causa de la distancia geográfica, temporal y cultural. Por eso, es muy importante que las asignaturas de Ingeniería del Software traten el DGS para que los alumnos conozcan este paradigma y sean conscientes de los desafíos que implica. Lo ideal sería que los alumnos pudieran trabajar en proyectos globales, pero somos conscientes de que esta actividad no siempre es posible. Por ello, en este artículo se evalúa la eficiencia de utilizar, como alternativa, un juego serio diseñado para que los alumnos descubran los problemas que conlleva el DGS.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2572</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mejorando-el-conocimiento-de-los-estudiantes-sobre-desarrollo-global-del-software-mediante-un-juego-serio]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="desarrollo-global-de-software"><![CDATA[Desarrollo Global de Software]]></category>
		<category domain="post_tag" nicename="experimento"><![CDATA[Experimento]]></category>
		<category domain="post_tag" nicename="juego-serio"><![CDATA[Juego serio]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La globalización ha llevado a muchas empresas a realizar el desarrollo de sus productos de una manera distribuida, llevándose a cabo por diferentes equipos e incluso desde diferentes países. Este nuevo paradigma de desarrollo se conoce como Desarrollo Global del Software - DGS. Para realizar esta práctica las empresas requieren desarrolladores que posean conocimientos y habilidades para solventar los problemas que surgen a causa de la distancia geográfica, temporal y cultural. Por eso, es muy importante que las asignaturas de Ingeniería del Software traten el DGS para que los alumnos conozcan este paradigma y sean conscientes de los desafíos que implica. Lo ideal sería que los alumnos pudieran trabajar en proyectos globales, pero somos conscientes de que esta actividad no siempre es posible. Por ello, en este artículo se evalúa la eficiencia de utilizar, como alternativa, un juego serio diseñado para que los alumnos descubran los problemas que conlleva el DGS. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/057]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_31.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_31.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aurora Vizcaíno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Aurora.Vizcaino@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Félix García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[felix.garcia@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[David Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[david.valencia@avanttic.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[avanticc Consultorí­a Tecnológica,  S.L.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ignacio García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Ignacio.GRodriguez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Ma ángeles Moraga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[Mariangeles.Moraga@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Approach for Debugging Model Transformations Applying Spectrum-Based Fault Localization</title>
		<link>https://biblioteca.sistedes.es/articulo/an-approach-for-debugging-model-transformations-applying-spectrum-based-fault-localization/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-approach-for-debugging-model-transformations-applying-spectrum-based-fault-localization/</guid>
		<description></description>
		<content><![CDATA[Model transformations play a cornerstone role in Model-Driven Engineering as they provide the essential mechanisms for manipulating and transforming models. The use of assertions for checking their correctness has been proposed in several works. However, it is still challenging and error prone to locate the faulty rules, and the situation gets more critical as the size and complexity of model transformations grow, where manual debugging is no longer possible. Spectrum-Based Fault Localization (SBFL) is a technique for software debugging that uses the results of test cases and their corresponding code coverage information to estimate the likelihood of each program component (e.g., statements) of being faulty. This paper describes a proposal for applying SBFL for locating the faulty rules in ATL model transformations. The approach aims at automatically detecting the transformation rule that makes an assertion fail.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2573</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-approach-for-debugging-model-transformations-applying-spectrum-based-fault-localization]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="debugging"><![CDATA[Debugging]]></category>
		<category domain="post_tag" nicename="fault-localization"><![CDATA[Fault Localization]]></category>
		<category domain="post_tag" nicename="model-transformation"><![CDATA[Model Transformation]]></category>
		<category domain="post_tag" nicename="spectrum"><![CDATA[Spectrum]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Model transformations play a cornerstone role in Model-Driven Engineering as they provide the essential mechanisms for manipulating and transforming models. The use of assertions for checking their correctness has been proposed in several works. However, it is still challenging and error prone to locate the faulty rules, and the situation gets more critical as the size and complexity of model transformations grow, where manual debugging is no longer possible. Spectrum-Based Fault Localization (SBFL) is a technique for software debugging that uses the results of test cases and their corresponding code coverage information to estimate the likelihood of each program component (e.g., statements) of being faulty. This paper describes a proposal for applying SBFL for locating the faulty rules in ATL model transformations. The approach aims at automatically detecting the transformation rule that makes an assertion fail.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/026]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_32.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_32.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Troya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jtroya@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José Antonio Parejo Maestre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[japarejo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Creating datasets for data analysis through a cloud microservice-based architecture</title>
		<link>https://biblioteca.sistedes.es/articulo/creating-datasets-for-data-analysis-through-a-cloud-microservice-based-architecture/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/creating-datasets-for-data-analysis-through-a-cloud-microservice-based-architecture/</guid>
		<description></description>
		<content><![CDATA[Data analysis is a trending technique due to the tendency of analyzing patterns or generating knowledge in different domains. However, it is difficult to know at design time what raw data should be collected, how it is going to be analyzed or which analysis techniques will be applied to data. Service-oriented architectures can be applied to solve these problems by providing flexible and reliable architectures. In this paper, we present a microservice-based software architecture in the cloud with the aim of generating datasets to carry out data analysis. This architecture facilitates acquiring data, which may be located in a data center, distributed, or even on different devices (ubiquitous computing) due to the rise of the IoT. It provides an infrastructure over which multiple developer' groups can work in parallel on the microservices. These microservices also provide a reliable and affordable adaptability to the lack of specific requirements in some functionalities and the fast evolution and variability of them, due to the fast changing of client needs.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2574</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[creating-datasets-for-data-analysis-through-a-cloud-microservice-based-architecture]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="architectures"><![CDATA[architectures]]></category>
		<category domain="post_tag" nicename="datasets"><![CDATA[datasets]]></category>
		<category domain="post_tag" nicename="microservices"><![CDATA[microservices]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Data analysis is a trending technique due to the tendency of analyzing patterns or generating knowledge in different domains. However, it is difficult to know at design time what raw data should be collected, how it is going to be analyzed or which analysis techniques will be applied to data. Service-oriented architectures can be applied to solve these problems by providing flexible and reliable architectures. In this paper, we present a microservice-based software architecture in the cloud with the aim of generating datasets to carry out data analysis. This architecture facilitates acquiring data, which may be located in a data center, distributed, or even on different devices (ubiquitous computing) due to the rise of the IoT. It provides an infrastructure over which multiple developer' groups can work in parallel on the microservices. These microservices also provide a reliable and affordable adaptability to the lack of specific requirements in some functionalities and the fast evolution and variability of them, due to the fast changing of client needs.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/004]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_33.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_33.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Jesús Fernández-García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ajfernandez@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Almeria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Criado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[javi.criado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Almerí­a]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Corral]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[acorral@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Almeria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Luis Iribarne]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[luis.iribarne@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Almerí­a]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia un Marco de Desarrollo para Apps Móviles</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-un-marco-de-desarrollo-para-apps-moviles/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/hacia-un-marco-de-desarrollo-para-apps-moviles/</guid>
		<description></description>
		<content><![CDATA[En los últimos años el desarrollo de aplicaciones móviles ha ido ganando adeptos a gran velocidad debido a la popularidad que han adquirido los dispositivos móviles. El establecimiento de un marco de procesos adecuado para desarrollar este tipo de aplicaciones resulta vital a la hora de garantizar que los productos se desarrollan y se validan siguiendo un método sistemático y coherente. En este artículo se presenta una iniciativa de diseño y validación de un marco de procesos específico para el desarrollo de aplicaciones móviles. El marco propuesto ha sido diseñado en base a los fundamentos básicos de ingeniería del software y considerando modelos de desarrollo existentes que han sido adaptados a las características particulares del contexto. La propuesta ha sido validada en un proyecto real obteniendo unos resultados que nos han servido como punto de partida para iniciar una mejora del proceso de desarrollo que seguimos en nuestro grupo de investigación.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2575</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-un-marco-de-desarrollo-para-apps-moviles]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="aplicaciones-moviles"><![CDATA[aplicaciones móviles]]></category>
		<category domain="post_tag" nicename="apps"><![CDATA[apps]]></category>
		<category domain="post_tag" nicename="desarrollo-de-softare"><![CDATA[desarrollo de softare]]></category>
		<category domain="post_tag" nicename="marco-de-desarrollo"><![CDATA[marco de desarrollo]]></category>
		<category domain="post_tag" nicename="proceso-software"><![CDATA[Proceso Software]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años el desarrollo de aplicaciones móviles ha ido ganando adeptos a gran velocidad debido a la popularidad que han adquirido los dispositivos móviles. El establecimiento de un marco de procesos adecuado para desarrollar este tipo de aplicaciones resulta vital a la hora de garantizar que los productos se desarrollan y se validan siguiendo un método sistemático y coherente. En este artículo se presenta una iniciativa de diseño y validación de un marco de procesos específico para el desarrollo de aplicaciones móviles. El marco propuesto ha sido diseñado en base a los fundamentos básicos de ingeniería del software y considerando modelos de desarrollo existentes que han sido adaptados a las características particulares del contexto. La propuesta ha sido validada en un proyecto real obteniendo unos resultados que nos han servido como punto de partida para iniciar una mejora del proceso de desarrollo que seguimos en nuestro grupo de investigación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/055]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_34.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_34.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Esperança Amengual]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[eamengual@uib.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat de les Illes Balears]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antoni Bibiloni Coll]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[antoni.bibiloni@uib.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat de les Illes Balears]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Miguel Mascaró]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mascport@uib.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat de les Illes Balears]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Pere Palmer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[pere.palmer@uib.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat de les Illes Balears]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>iHDT++: un Autoíndice Semántico para la Resolución de Patrones de Consulta SPARQL</title>
		<link>https://biblioteca.sistedes.es/articulo/ihdt-un-autoindice-semantico-para-la-resolucion-de-patrones-de-consulta-sparql/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/ihdt-un-autoindice-semantico-para-la-resolucion-de-patrones-de-consulta-sparql/</guid>
		<description></description>
		<content><![CDATA[La publicación de colecciones RDF, y el volumen de las mismas, ha crecido exponencialmente en los últimos años, abriendo nuevos retos de investigación relacionados con el almacenamiento, el procesamiento y la consulta de Big Semantic Data. Los auto-índices RDF son una de las soluciones más innovadoras en este escenario, ya que no sólo comprimen las colecciones, sino que además proveen acceso eficiente a los datos sin descomprimirlos previamente. En este escenario, HDT es una de las soluciones de referencia y su uso ha sido validado por diferentes herramientas semánticas. Sin embargo, la efectividad de HDT está limitada por la sencillez de su diseño y sus ratios de compresión han sido recientemente mejorados por HDT++. Sin embargo, HDT++ no soporta directamente la resolución de consultas SPARQL. En este artículo extendemos HDT++ para dar soporte a la resolución de todos los triple patterns SPARQL. Esta nueva propuesta (iHDT++) mejora los resultados de compresión obtenidos por HDT y garantiza un rendimiento comparable para la resolución de consultas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2576</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[ihdt-un-autoindice-semantico-para-la-resolucion-de-patrones-de-consulta-sparql]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="compresion"><![CDATA[Compresión]]></category>
		<category domain="post_tag" nicename="hdt"><![CDATA[HDT]]></category>
		<category domain="post_tag" nicename="rdf"><![CDATA[RDF]]></category>
		<category domain="post_tag" nicename="sparql"><![CDATA[SPARQL]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La publicación de colecciones RDF, y el volumen de las mismas, ha crecido exponencialmente en los últimos años, abriendo nuevos retos de investigación relacionados con el almacenamiento, el procesamiento y la consulta de Big Semantic Data. Los auto-índices RDF son una de las soluciones más innovadoras en este escenario, ya que no sólo comprimen las colecciones, sino que además proveen acceso eficiente a los datos sin descomprimirlos previamente. En este escenario, HDT es una de las soluciones de referencia y su uso ha sido validado por diferentes herramientas semánticas. Sin embargo, la efectividad de HDT está limitada por la sencillez de su diseño y sus ratios de compresión han sido recientemente mejorados por HDT++. Sin embargo, HDT++ no soporta directamente la resolución de consultas SPARQL. En este artículo extendemos HDT++ para dar soporte a la resolución de todos los triple patterns SPARQL. Esta nueva propuesta (iHDT++) mejora los resultados de compresión obtenidos por HDT y garantiza un rendimiento comparable para la resolución de consultas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/018]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_35.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_35.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Hernández Illera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[antonio.hi@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DataWeb Research,  Department of Computer Science,  University of Valladolid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miguel A. Martinez-Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[migumar2@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[DataWeb Research,  Department of Computer Science,  University of Valladolid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier D. Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jfernand@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Computer Science Department. University of Valladolid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Impacto de las métricas CK en la refactorización</title>
		<link>https://biblioteca.sistedes.es/articulo/impacto-de-las-metricas-ck-en-la-refactorizacion/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/impacto-de-las-metricas-ck-en-la-refactorizacion/</guid>
		<description></description>
		<content><![CDATA[Las métricas CK son las que alcanzan un mayor consenso, a nivel de diseño orientado a objetos, sobre la idenficación de la necesidad de una refactorización. Para estimar el impacto de estas métricas de calidad en la refactorización en este trabajo nos basamos en la reducción de la entropía. Para medir este impacto empleamos datos validados de refactorizaciones y métricas de código de varios proyectos open source. Las valoraciones obtenidas se combinan para ordenar las métricas y proponemos un método para medir su influencia incluso en aquellas situaciones en las que no todas las métricas puedan ser valoradas o cuando esta valoración no alcance unos tasas suficientemente representativas. Los resultados obtenidos con el enfoque aplicado están en la misma línea de trabajos previos de otros autores.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2577</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[impacto-de-las-metricas-ck-en-la-refactorizacion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="evolucion-del-software"><![CDATA[evolución del software]]></category>
		<category domain="post_tag" nicename="metricas-de-codigo"><![CDATA[métricas de código]]></category>
		<category domain="post_tag" nicename="refactorizacion"><![CDATA[Refactorización]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las métricas CK son las que alcanzan un mayor consenso, a nivel de diseño orientado a objetos, sobre la idenficación de la necesidad de una refactorización. Para estimar el impacto de estas métricas de calidad en la refactorización en este trabajo nos basamos en la reducción de la entropía. Para medir este impacto empleamos datos validados de refactorizaciones y métricas de código de varios proyectos open source. Las valoraciones obtenidas se combinan para ordenar las métricas y proponemos un método para medir su influencia incluso en aquellas situaciones en las que no todas las métricas puedan ser  valoradas o cuando esta valoración no alcance unos tasas suficientemente representativas. Los resultados obtenidos con el enfoque aplicado están en la misma línea de trabajos previos de otros autores.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/038]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_37.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_37.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Del Sagrado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jsagrado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Informatics,  University of Almerí­a]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Isabel María Del águila]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[imaguila@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alfonso J. Bosch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[abosch@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Almerí­a]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Francisco Chicano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[chicano@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Propuesta de Marco para el Gobierno de la Seguridad en Entornos Big Data</title>
		<link>https://biblioteca.sistedes.es/articulo/propuesta-de-marco-para-el-gobierno-de-la-seguridad-en-entornos-big-data/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/propuesta-de-marco-para-el-gobierno-de-la-seguridad-en-entornos-big-data/</guid>
		<description></description>
		<content><![CDATA[Big Data ya es una realidad en el día a día de muchas compañías. Cuando se implanta un entorno Big Data en una organización, este se debe adaptar a las características de la misma. Para poder alcanzar una garantía de seguridad mientras se respetan las características inherentes de la organización se re-quiere una adecuada función de gobierno. Para lograr este objetivo hemos creado una propuesta de marco para el gobierno de la seguridad en entornos Big Data denominada marco GSB. Este marco de gobierno toma como base los estándares internacionales relacionados con el gobierno de las TI, como por ejemplo COBIT, y lo adapta a las necesidades específicas de un entorno de Big Data. El objetivo final del marco GSB es cubrir todo su ciclo de vida de forma segura.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2578</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[propuesta-de-marco-para-el-gobierno-de-la-seguridad-en-entornos-big-data]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="gobierno-de-las-ti"><![CDATA[Gobierno de las TI]]></category>
		<category domain="post_tag" nicename="seguridad-de-la-informacion"><![CDATA[Seguridad de la información]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Big Data ya es una realidad en el día a día de muchas compañías. Cuando se implanta un entorno Big Data en una organización, este se debe adaptar a las características de la misma. Para poder alcanzar una garantía de seguridad mientras se respetan las características inherentes de la organización se re-quiere una adecuada función de gobierno. Para lograr este objetivo hemos creado una propuesta de marco para el gobierno de la seguridad en entornos Big Data denominada marco GSB. Este marco de gobierno toma como base los estándares internacionales relacionados con el gobierno de las TI, como por ejemplo COBIT, y lo adapta a las necesidades específicas de un entorno de Big Data. El objetivo final del marco GSB es cubrir todo su ciclo de vida de forma segura.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/020]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_38.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_38.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julio Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[julio.moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ALARCOS Research Group. UCLM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Serrano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Manuel.Serrano@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ALARCOS Research Group. UCLM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Eduardo Fernandez-Medina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[eduardo.fdezmedina@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ALARCOS Research Group. UCLM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modelos de Madurez de Usabilidad: Evolución y Situación Actual</title>
		<link>https://biblioteca.sistedes.es/articulo/modelos-de-madurez-de-usabilidad-evolucion-y-situacion-actual/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/modelos-de-madurez-de-usabilidad-evolucion-y-situacion-actual/</guid>
		<description></description>
		<content><![CDATA[Los beneficios de incorporar la usabilidad en el desarrollo del software han sido ampliamente documentados tanto desde el punto de vista del usuario como para la propia organización de desarrollo. Los modelos de madurez de usabilidad (MMUs) se usan para evaluar cómo una organización integra buenas prácticas de usabilidad en su proceso de desarrollo de software, por lo tanto, los MMUs son, así mismo, un vehículo eficaz para promover dicha integración. El objetivo de este trabajo es proporcionar información actualizada y detallada sobre los MMUs utilizados en la última década. Para ello hemos realizado un mapeo siste-mático de los MMUs objeto de publicación en los últimos 10 años. Como resul-tado, hemos identificado once modelos desde 2006. Para cada uno de ellos se han analizado en detalle distintas características de diseño y aplicación. El análisis ex-haustivo de dichos modelos, confirma la falta de evidencia empírica y de docu-mentación de soporte para su aplicación objetiva, carencias ya predichas por tra-bajos anteriores. Nuestro estudio identifica además otras carencias como son el grado de prescriptividad o mutabilidad de dichos modelos. Este estudio justifica así la necesidad de seguir trabajando en mejorar la madurez de los MMUs para potenciar su eficacia en la integración de prácticas de usabilidad en el desarrollo de software.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2579</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modelos-de-madurez-de-usabilidad-evolucion-y-situacion-actual]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mapeo-sistematico"><![CDATA[mapeo sistemático]]></category>
		<category domain="post_tag" nicename="modelos-de-madurez"><![CDATA[modelos de madurez]]></category>
		<category domain="post_tag" nicename="modelos-de-madurez-de-usabilidad"><![CDATA[Modelos de madurez de usabilidad]]></category>
		<category domain="post_tag" nicename="usabilidad"><![CDATA[usabilidad]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los beneficios de incorporar la usabilidad en el desarrollo del software han sido ampliamente documentados tanto desde el punto de vista del usuario como para la propia organización de desarrollo. Los modelos de madurez de usabilidad (MMUs) se  usan para evaluar cómo una organización integra buenas prácticas de usabilidad en su proceso de desarrollo de software, por lo tanto, los MMUs son, así mismo, un vehículo eficaz para promover dicha integración. El objetivo de este trabajo es proporcionar información actualizada y detallada sobre los MMUs utilizados en la última década. Para ello hemos realizado un mapeo siste-mático de los MMUs objeto de publicación en los últimos 10 años. Como resul-tado, hemos identificado once modelos desde 2006. Para cada uno de ellos se han analizado en detalle distintas características de diseño y aplicación. El análisis ex-haustivo de dichos modelos, confirma la falta de evidencia empírica y de docu-mentación de soporte para su aplicación objetiva, carencias ya predichas por tra-bajos anteriores. Nuestro estudio identifica además otras carencias como son el grado de prescriptividad o mutabilidad de dichos modelos. Este estudio justifica así la necesidad de seguir trabajando en mejorar la madurez de los MMUs para potenciar su eficacia en la integración de prácticas de usabilidad en el desarrollo de software.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/058]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_39.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_39.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carmen L. Carvajal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carmen.carvajal07@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ana M. Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ammoreno@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Coverage-Aware Test Database Reduction</title>
		<link>https://biblioteca.sistedes.es/articulo/coverage-aware-test-database-reduction/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/coverage-aware-test-database-reduction/</guid>
		<description></description>
		<content><![CDATA[Functional testing of applications that process the information stored in databases often requires a careful design of the test database. The larger the test database, the more difficult it is to develop and maintain tests as well as to load and reset the test data. This paper presents an approach to reduce a database with respect to a set of SQL queries and a coverage criterion. The reduction procedures search the rows in the initial database that contribute to the coverage in order to find a representative subset that satisfies the same coverage as the initial database. The approach is automated and efficiently executed against large databases and complex queries. The evaluation is carried out over two real life applications and a well-known database benchmark. The results show a very large degree of reduction as well as scalability in relation to the size of the initial database and the time needed to perform the reduction. --- Datos del artículo --- Autores: Javier Tuya, Claudio de la Riva, María José Suárez-Cabal, Raquel Blanco Revista: IEEE Transactions on Software Engineering Year: 2016, Volume: 42, Issue: 10 Pages: 941 - 959, DOI: 10.1109/TSE.2016.2519032 Factor de impacto (JCR 2005): 1,516, Q1 in Computer Science, Software engineering --- Nota --- Artículo para track Requisitos, Calidad y Pruebas, enviado a otros por conflicto de interés]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2580</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[coverage-aware-test-database-reduction]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="test-coverage-of-code"><![CDATA[Test coverage of code]]></category>
		<category domain="post_tag" nicename="test-database-reduction"><![CDATA[Test database reduction]]></category>
		<category domain="post_tag" nicename="test-design"><![CDATA[Test design]]></category>
		<category domain="post_tag" nicename="testing-tools"><![CDATA[Testing tools]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Functional testing of applications that process the information stored in databases often requires a careful design of the test database. The larger the test database, the more difficult it is to develop and maintain tests as well as to load and reset the test data. This paper presents an approach to reduce a database with respect to a set of SQL queries and a coverage criterion. The reduction procedures search the rows in the initial database that contribute to the coverage in order to find a representative subset that satisfies the same coverage as the initial database. The approach is automated and efficiently executed against large databases and complex queries. The evaluation is carried out over two real life applications and a well-known database benchmark. The results show a very large degree of reduction as well as scalability in relation to the size of the initial database and the time needed to perform the reduction.  --- Datos del artículo --- Autores: Javier Tuya, Claudio de la Riva, María José Suárez-Cabal, Raquel Blanco Revista: IEEE Transactions on Software Engineering Year: 2016, Volume: 42, Issue: 10  Pages: 941 - 959,  DOI: 10.1109/TSE.2016.2519032  Factor de impacto (JCR 2005): 1,516, Q1 in Computer Science, Software engineering  --- Nota --- Artículo para track Requisitos, Calidad y Pruebas, enviado a otros por conflicto de interés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/068]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_40.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_40.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Claudio de La Riva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[claudio@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de  Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[María José Suárez-Cabal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[cabal@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Raquel Blanco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[rblanco@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modeling Systems Variability with Delta Rhapsody</title>
		<link>https://biblioteca.sistedes.es/articulo/modeling-systems-variability-with-delta-rhapsody/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/modeling-systems-variability-with-delta-rhapsody/</guid>
		<description></description>
		<content><![CDATA[Variability modeling is demanded by industrial companies to support customization of their products. However, not all the software tools include variability modeling mechanisms. IBM Rhapsody is one of the leading environments for modeling complex industrial systems. In this paper we present Delta Rhapsody, a tool for modeling variability in IBM Rhapsody models employing the delta modeling paradigm.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2581</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modeling-systems-variability-with-delta-rhapsody]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="delta-modelling"><![CDATA[Delta Modelling]]></category>
		<category domain="post_tag" nicename="rhapsody"><![CDATA[Rhapsody]]></category>
		<category domain="post_tag" nicename="variability"><![CDATA[Variability]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Variability modeling is demanded by industrial companies to support customization of their products. However, not all the software tools include variability modeling mechanisms. IBM Rhapsody is one of the leading environments for modeling complex industrial systems. In this paper we present Delta Rhapsody, a tool for modeling variability in IBM Rhapsody models employing the delta modeling paradigm.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/006]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_41.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_41.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Xabier Perez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[xabier.perezb@alumni.mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Mondragon Unibertsitatea]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Oskar Berreteaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[oberreteaga@ulmaembedded.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ULMA Embedded Solutions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Leire Etxeberria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[letxeberria@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Aitor Arrieta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aarrieta@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Urtzi Markiegi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[umarkiegi@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Soportando el modelado de procesos  de negocio con Process Chain Network</title>
		<link>https://biblioteca.sistedes.es/articulo/soportando-el-modelado-de-procesos-de-negocio-con-process-chain-network/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/soportando-el-modelado-de-procesos-de-negocio-con-process-chain-network/</guid>
		<description></description>
		<content><![CDATA[En la actualidad, los modelos de negocio se han convertido en un activo fundamental para cualquier tipo de organización. De hecho, son varias las notaciones que gozan de cierto nivel de aceptación para la representación de modelos de negocio. Sin embargo, no existe a día de hoy un entorno que permita gestionar eficazmente modelos de negocio elaborados con diferentes notaciones, debiendo recurrir a diferentes herramientas o incluso en algunos casos, a simples editores de imágenes o diagramadores genéricos. Este último es el caso de Process Chain Network (PCN), una técnica para la representación visual de procesos de negocio, utilizada habitualmente en el área de operaciones de servicio. Por todo ello, en este trabajo se presenta un DSL gráfico que soporta la notación PCN y se integra en un entorno de modelado para el diseño de servicios, con la intención de soportar a medio plazo la gestión integrada de modelos de negocio elaborados con diferentes notaciones.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2582</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[soportando-el-modelado-de-procesos-de-negocio-con-process-chain-network]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="bpmn"><![CDATA[BPMN]]></category>
		<category domain="post_tag" nicename="modelo-de-negocio"><![CDATA[Modelo de Negocio]]></category>
		<category domain="post_tag" nicename="proceso-de-negocio"><![CDATA[Proceso de Negocio]]></category>
		<category domain="post_tag" nicename="process-chain-network"><![CDATA[Process Chain Network]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En la actualidad, los modelos de negocio se han convertido en un activo fundamental para cualquier tipo de organización. De hecho, son varias las notaciones que gozan de cierto nivel de aceptación para la representación de modelos de negocio. Sin embargo, no existe a día de hoy un entorno que permita gestionar eficazmente modelos de negocio elaborados con diferentes notaciones, debiendo recurrir a diferentes herramientas o incluso en algunos casos, a simples editores de imágenes o diagramadores genéricos. Este último es el caso de Process Chain Network (PCN), una técnica para la representación visual de procesos de negocio, utilizada habitualmente en el área de operaciones de servicio. Por todo ello, en este trabajo se presenta un DSL gráfico que soporta la notación PCN y se integra en un entorno de modelado para el diseño de servicios, con la intención de soportar a medio plazo la gestión integrada de modelos de negocio elaborados con diferentes notaciones. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/030]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_42.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_42.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Javier Pérez Blanco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[francisco.perez@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group,  University Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[María Valeria De Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[valeria.decastro@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group. University Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[David Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[david.granada@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Cómo gestionan la variabilidad las empresas que no conocen de líneas de producto software: hacia una evaluación real</title>
		<link>https://biblioteca.sistedes.es/articulo/como-gestionan-la-variabilidad-las-empresas-que-no-conocen-de-lineas-de-producto-software-hacia-una-evaluacion-real/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/como-gestionan-la-variabilidad-las-empresas-que-no-conocen-de-lineas-de-producto-software-hacia-una-evaluacion-real/</guid>
		<description></description>
		<content><![CDATA[Las líneas de producto software tienen como prioridad alcanzar la reutilización sistemática dentro de una organización permitiendo la reducción de coste, esfuerzo, tiempo de desarrollo, y numero promedio de defectos por producto. Sin embargo, existen desafíos al ejecutar un proyecto de emph{líneas de producto software (SPLs)} y pocas veces estos han sido reportados, reduciendo la posibilidad de comprobación entre la teoría y la praxis. Esto implica dificultades para el fortalecimiento o elaboración de ajustes o mejoras a los frameworks de SPL. Asimismo, hay nuevos conceptos novedosos como los ecosistemas software software ecosystems'', que hacen necesario revisar el concepto de SPL y adaptarlo a los tiempos actuales. En este artículo, presentamos el diseño de un emph{estudio de caso} para la reducir esta brecha, permitiendo conocer el contexto de dos medianas empresas que no saben de líneas de producto software emph{gestionan la variabilidad}. También, nos permitirá identificar oportunidades y debilidades descubiertas en los frameworks de adopción de SPL con el objetivo de mejorarlos. Además de presentar un fragmento metodológico que indique el camino a seguir para que una empresa pueda transicionar hacia el paradigma de SPLs.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2583</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[como-gestionan-la-variabilidad-las-empresas-que-no-conocen-de-lineas-de-producto-software-hacia-una-evaluacion-real]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="estudio-de-casos"><![CDATA[estudio de casos]]></category>
		<category domain="post_tag" nicename="gestion-de-variabilidad"><![CDATA[gestión de variabilidad]]></category>
		<category domain="post_tag" nicename="lineas-de-producto-software"><![CDATA[Líneas de Producto Software]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las líneas de producto software tienen como prioridad alcanzar la reutilización sistemática dentro de una organización permitiendo la reducción de coste, esfuerzo, tiempo de desarrollo, y numero promedio de defectos por producto. Sin embargo, existen desafíos al ejecutar un proyecto de emph{líneas de producto software (SPLs)} y pocas veces estos han sido reportados, reduciendo la posibilidad de comprobación entre la teoría y la praxis. Esto implica dificultades para el fortalecimiento o elaboración de ajustes o mejoras a los frameworks de SPL. Asimismo, hay nuevos conceptos novedosos como los ecosistemas software software ecosystems'', que hacen necesario revisar el concepto de SPL y adaptarlo a los tiempos actuales. En este artículo, presentamos el diseño de un emph{estudio de caso} para la reducir esta brecha, permitiendo conocer el contexto de dos medianas empresas que no saben de líneas de producto software emph{gestionan la variabilidad}. También, nos permitirá identificar oportunidades y debilidades descubiertas en los frameworks de adopción de SPL con el objetivo de mejorarlos. Además de presentar un fragmento metodológico que indique el camino a seguir para que una empresa pueda transicionar hacia el paradigma de SPLs.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/002]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_43.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_43.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana E. Chacón-Luna]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[achaconl1@unemi.edu.ec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad estatal de Milagro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José A. Galindo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jagalindo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[David Benavides]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[benavides@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Localización de defectos en aplicaciones MapReduce</title>
		<link>https://biblioteca.sistedes.es/articulo/localizacion-de-defectos-en-aplicaciones-mapreduce/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/localizacion-de-defectos-en-aplicaciones-mapreduce/</guid>
		<description></description>
		<content><![CDATA[Los programas que analizan grandes cantidades de datos suelen ejecutarse en entornos distribuidos, tal y como ocurre con las aplicaciones MapReduce. Estos programas se desarrollan independientemente de la infraestructura sobre que la que se ejecutan, ya que un framework gestiona automáticamente la asignación de recursos y gestión de fallos, entre otros. Detectar y localizar defectos en estos programas suele ser una tarea compleja ya que diversas funciones se ejecutan simultáneamente en una infraestructura distribuida, difícil de controlar y que cambia continuamente. En este artículo se describe una técnica que, a partir de un fallo detectado en las pruebas, localiza defectos de diseño analizando dinámicamente los parámetros que lo causan.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2584</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[localizacion-de-defectos-en-aplicaciones-mapreduce]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="big-data-engineering"><![CDATA[Big Data Engineering]]></category>
		<category domain="post_tag" nicename="localizacion-de-defectos"><![CDATA[Localización de defectos]]></category>
		<category domain="post_tag" nicename="mapreduce"><![CDATA[MapReduce]]></category>
		<category domain="post_tag" nicename="pruebas-del-software"><![CDATA[Pruebas del software]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los programas que analizan grandes cantidades de datos suelen ejecutarse en entornos distribuidos, tal y como ocurre con las aplicaciones MapReduce. Estos programas se desarrollan independientemente de la infraestructura sobre que la que se ejecutan, ya que un framework gestiona automáticamente la asignación de recursos y gestión de fallos, entre otros. Detectar y localizar defectos en estos programas suele ser una tarea compleja ya que diversas funciones se ejecutan simultáneamente en una infraestructura distribuida, difícil de controlar y que cambia continuamente. En este artículo se describe una técnica que, a partir de un fallo detectado en las pruebas, localiza defectos de diseño analizando dinámicamente los parámetros que lo causan.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/070]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_44.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_44.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús Morán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[moranjesus@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Claudio De La Riva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[claudio@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Bibiano Rivas García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Bibiano.Rivas@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Mantenimiento de la Consistencia Lógica en Cassandra</title>
		<link>https://biblioteca.sistedes.es/articulo/mantenimiento-de-la-consistencia-logica-en-cassandra/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/mantenimiento-de-la-consistencia-logica-en-cassandra/</guid>
		<description></description>
		<content><![CDATA[A diferencia de las bases de datos relacionales, en bases de datos NoSQL como Cassandra es muy común que exista duplicidad de los datos en diferentes tablas. Esto es debido a que, normalmente, las tablas son diseñadas en base a las consul-tas y a la ausencia de relaciones entre ellas para primar el rendimiento en las con-sultas. Por tanto, si los datos no se actualizan convenientemente, se pueden pro-ducir inconsistencias en la información almacenada. Es relativamente fácil intro-ducir defectos que originan inconsistencia de datos en Cassandra, sobre todo du-rante la evolución de un sistema en el que se crean nuevas tablas, y éstos son difí-ciles de detectar utilizando técnicas convencionales de pruebas dinámicas. El desarrollador es quien debe preocuparse de mantener esta consistencia incluyendo y actualizando los procedimientos adecuados. Este trabajo propone un enfoque preventivo a estos problemas, estableciendo los procesos necesarios para asegu-rar la calidad de los datos desde el punto de vista de su consistencia, facilitando así las tareas del desarrollador. Estos procesos incluyen: (1) un análisis estático considerando el modelo conceptual, las consultas y el modelo lógico de la aplica-ción, para identificar qué elementos (tablas o columnas) de la base de datos se ven afectados por un cambio, y (2) la determinación y ejecución de las operaciones que aseguren la consistencia de la información.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2585</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mantenimiento-de-la-consistencia-logica-en-cassandra]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="apache-cassandra"><![CDATA[Apache Cassandra]]></category>
		<category domain="post_tag" nicename="consistencia-logica"><![CDATA[Consistencia Lógica]]></category>
		<category domain="post_tag" nicename="pruebas-estaticas"><![CDATA[Pruebas Estáticas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A diferencia de las bases de datos relacionales, en bases de datos NoSQL como Cassandra es muy común que exista duplicidad de los datos en diferentes tablas. Esto es debido a que, normalmente, las tablas son diseñadas en base a las consul-tas y a la ausencia de relaciones entre ellas para primar el rendimiento en las con-sultas. Por tanto, si los datos no se actualizan convenientemente, se pueden pro-ducir inconsistencias en la información almacenada. Es relativamente fácil intro-ducir defectos que originan inconsistencia de datos en Cassandra, sobre todo du-rante la evolución de un sistema en el que se crean nuevas tablas, y éstos son difí-ciles de detectar utilizando técnicas convencionales de pruebas dinámicas. El desarrollador es quien debe preocuparse de mantener esta consistencia incluyendo y actualizando los procedimientos adecuados. Este trabajo propone un enfoque preventivo a estos problemas, estableciendo los procesos necesarios para asegu-rar la calidad de los datos desde el punto de vista de su consistencia, facilitando así las tareas del desarrollador. Estos procesos incluyen: (1) un análisis estático considerando el modelo conceptual, las consultas y el modelo lógico de la aplica-ción, para identificar qué elementos (tablas o columnas) de la base de datos se ven afectados por un cambio, y (2) la determinación y ejecución de las operaciones que aseguren la consistencia de la información.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/071]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_45.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_45.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Suárez-Otero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[suarezgpablo@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Gutierrez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[javierj@lsi.us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de  Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Claudio de La Riva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[claudio@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An exploratory study in communication in Agile Global Software Development</title>
		<link>https://biblioteca.sistedes.es/articulo/an-exploratory-study-in-communication-in-agile-global-software-development/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-exploratory-study-in-communication-in-agile-global-software-development/</guid>
		<description></description>
		<content><![CDATA[Global software development (GSD) is gaining ever more relevance. Although communication is key in the exchange of information between team members, multi-site software development has introduced additional obstacles (different time-zones and cultures, IT infrastructure, etc.) and delays into the act of communication, which is already problematic. Communication is even more critical in the case of Agile Global Software Development (AGSD) in which communication plays a primary role. This paper reports an exploratory study of the effects of tools supporting communication in AGSD. More precisely, this paper analyses the perception of team members about communication infrastructures in AGSD. The research question to which this study responds concerns how development teams perceive the communication infrastructure while developing products using agile methodologies. Most previous studies have dealt with communication support from a highly technological media tool perspective. In this research work, instead, observations were obtained from three perspectives: communication among team members, communication of the status of the development process, and communication of the status of the progress of the product under development. It has been possible to show that team members perceive advantages to using media tools that make them feel in practice that teams are co-located, such as smartboards supported by efficient video-tools, and combining media tools with centralized repository tools, with information from the process development and product characteristics, that allow distributed teams to effectively share information about the status of the project/process/product during the development process in order to overcome some of the still existing problems in communication in AGSD. COMPUTER STANDARDS &amp; INTERFACES Volumen: 48 Páginas: 184-197 Número especial: SI DOI: 10.1016/j.csi.2016.06.002 Impacto de la revista 2015 Computer Science: 171/393 Q2 2015 Computer Svience/Software Engineering 35/106 Q2]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2586</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-exploratory-study-in-communication-in-agile-global-software-development]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="agile"><![CDATA[Agile]]></category>
		<category domain="post_tag" nicename="development-project"><![CDATA[Development project]]></category>
		<category domain="post_tag" nicename="exploratory-research"><![CDATA[Exploratory research]]></category>
		<category domain="post_tag" nicename="global-distributed-software-development"><![CDATA[Global Distributed Software Development]]></category>
		<category domain="post_tag" nicename="infrastructure"><![CDATA[Infrastructure]]></category>
		<category domain="post_tag" nicename="mangement"><![CDATA[Mangement]]></category>
		<category domain="post_tag" nicename="teams"><![CDATA[Teams]]></category>
		<category domain="post_tag" nicename="tools-and-technologies"><![CDATA[Tools and technologies]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Global software development (GSD) is gaining ever more relevance. Although communication is key in the exchange of information between team members, multi-site software development has introduced additional obstacles (different time-zones and cultures, IT infrastructure, etc.) and delays into the act of communication, which is already problematic. Communication is even more critical in the case of Agile Global Software Development (AGSD) in which communication plays a primary role. This paper reports an exploratory study of the effects of tools supporting communication in AGSD. More precisely, this paper analyses the perception of team members about communication infrastructures in AGSD. The research question to which this study responds concerns how development teams perceive the communication infrastructure while developing products using agile methodologies. Most previous studies have dealt with communication support from a highly technological media tool perspective. In this research work, instead, observations were obtained from three perspectives: communication among team members, communication of the status of the development process, and communication of the status of the progress of the product under development. It has been possible to show that team members perceive advantages to using media tools that make them feel in practice that teams are co-located, such as smartboards supported by efficient video-tools, and combining media tools with centralized repository tools, with information from the process development and product characteristics, that allow distributed teams to effectively share information about the status of the project/process/product during the development process in order to overcome some of the still existing problems in communication in AGSD.   COMPUTER STANDARDS & INTERFACES  Volumen: 48  Páginas: 184-197  Número especial: SI  DOI: 10.1016/j.csi.2016.06.002   Impacto de la revista  2015 Computer Science: 171/393 Q2 2015 Computer Svience/Software Engineering 35/106 Q2 ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/045]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_46.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_46.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Agustin Yague]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[agustin.yague@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Garbajosa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jgs@etsisi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jessica Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[idiaz@etsisi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Eloy Gonzalez Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[egonzalezort@indra.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Indra Software Labs]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A model-based proposal for integrating the measures lifecycle within the process lifecycle</title>
		<link>https://biblioteca.sistedes.es/articulo/a-model-based-proposal-for-integrating-the-measures-lifecycle-within-the-process-lifecycle/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-model-based-proposal-for-integrating-the-measures-lifecycle-within-the-process-lifecycle/</guid>
		<description></description>
		<content><![CDATA[Software development process (SDP) is a complex and long endeavor, the quality and management of this process affect the quality of its results. Measuring the SDP is essential to gain insight on its performance and to discover improvements. This work proposes to use Model-Driven Engineering (MDE) paradigm to integrate the measures lifecycle within the process lifecycle in order to explicitly and operationally model measures during the process modeling. Also defines transformation rules to derive executable code to run these measures into enterprise tools in order to support the measures lifecycle.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2587</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-model-based-proposal-for-integrating-the-measures-lifecycle-within-the-process-lifecycle]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="measurement"><![CDATA[Measurement.]]></category>
		<category domain="post_tag" nicename="modeling"><![CDATA[Modeling.]]></category>
		<category domain="post_tag" nicename="software-development-process"><![CDATA[Software development process.]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Software development process (SDP) is a complex and long endeavor, the quality and management of this process affect the quality of its results. Measuring the SDP is essential to gain insight on its performance and to discover improvements. This work proposes to use Model-Driven Engineering (MDE) paradigm to integrate the measures lifecycle within the process lifecycle in order to explicitly and operationally model measures during the process modeling. Also defines transformation rules to derive executable code to run these measures into enterprise tools in order to support the measures lifecycle.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/053]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_47.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_47.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ayman Meidan]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ayman.meidan@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Julian Alberto García García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[julian.garcia@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Isabel Ramos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[iramos@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Maria Jose Escalona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mjescalona@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Carlos Arevalo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[carlosarevalo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia una propuesta de estimación de costes de producción desde etapas tempranas del desarrollo Web</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-una-propuesta-de-estimacion-de-costes-de-produccion-desde-etapas-tempranas-del-desarrollo-web/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/hacia-una-propuesta-de-estimacion-de-costes-de-produccion-desde-etapas-tempranas-del-desarrollo-web/</guid>
		<description></description>
		<content><![CDATA[Actualmente, el coste de producción de aplicaciones en infraestructuras cloud se calcula prácticamente en las fases finales de despliegue y produccion. Por otro lado, la creciente consolidación de la Ingeniería Web Dirigida por Modelos ofrece ventajas como la generación de código a partir de la etapa de diseño. Con ambas ideas en mente, en este trabajo presentamos los primeros pasos encaminados a disponer de una propuesta de estimación de los costes de producción en un entorno cloud a partir de la etapa de diseño, anticipando así la toma de decisiones al respecto.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2588</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-una-propuesta-de-estimacion-de-costes-de-produccion-desde-etapas-tempranas-del-desarrollo-web]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="crud"><![CDATA[CRUD.]]></category>
		<category domain="post_tag" nicename="diseno"><![CDATA[Diseño.]]></category>
		<category domain="post_tag" nicename="ingenieria-web"><![CDATA[Ingeniería Web]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Actualmente, el coste de producción de aplicaciones en infraestructuras cloud se calcula prácticamente en las fases nales de despliegue y produccion. Por otro lado, la creciente consolidación de la Ingeniería Web Dirigida por Modelos ofrece ventajas como la generación de código a partir de la etapa de dise~no. Con ambas ideas en mente, en este trabajo presentamos los primeros pasos encaminados a disponer de una propuesta de estimación de los costes de producción en un entorno cloud a partir de la etapa de diseño, anticipando así la toma de decisiones al respecto.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/063]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_48.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_48.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rubén Martín]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rubenms@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Carlos Preciado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jcpreciado@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose Maria Conejero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[chemacm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Roberto Rodriguez-Echeverria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[rre@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Fernando Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[fernando@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Diseñando la Participación del Humano en los Sistemas Autónomos</title>
		<link>https://biblioteca.sistedes.es/articulo/disenando-la-participacion-del-humano-en-los-sistemas-autonomos/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/disenando-la-participacion-del-humano-en-los-sistemas-autonomos/</guid>
		<description></description>
		<content><![CDATA[Estamos entrando gradualmente en la era de los sistemas que pretenden dotar de capacidades de computación autónoma a servicios cotidianos. La búsqueda de la autonomía completa es un reto que se está persiguiendo en diversos ámbitos de aplicación y sectores industriales. Sin embargo, la realidad es que la variedad de sistemas, dominios, entornos y contextos de ejecución, restricciones legales y sociales, hace vislumbrar un mundo donde esta autonomía completa será una utopía a corto y medio plazo. En los escenarios en que el sistema autónomo no pueda automatizar completamente sus tareas, se requerirá pues de la participación humana. Desde un punto de vista ingenieril la colaboración entre el humano y estos sistemas (Human in the Loop) introduce un considerable número de retos y problemas a resolver. En este trabajo se identifican los retos tecnológicos que introduce esta colaboración humano-sistema, y se define un marco conceptual que identifica los aspectos a considerar desde un punto de vista abstracto e ingenieril.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2589</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[disenando-la-participacion-del-humano-en-los-sistemas-autonomos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="human-in-the-loop"><![CDATA[Human in the Loop]]></category>
		<category domain="post_tag" nicename="interaccion-hombre-maquina"><![CDATA[Interacción Hombre-Máquina]]></category>
		<category domain="post_tag" nicename="marco-conceptual"><![CDATA[Marco Conceptual]]></category>
		<category domain="post_tag" nicename="sensibilidad-al-contexto"><![CDATA[Sensibilidad al contexto]]></category>
		<category domain="post_tag" nicename="sistemas-autonomos"><![CDATA[Sistemas Autónomos]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Estamos entrando gradualmente en la era de los sistemas que pretenden dotar de capacidades de computación autónoma a servicios cotidianos. La búsqueda de la autonomía completa es un reto que se está persiguiendo en diversos ámbitos de aplicación y sectores industriales. Sin embargo, la realidad es que la variedad de sistemas, dominios, entornos y contextos de ejecución, restricciones legales y sociales, hace vislumbrar un mundo donde esta autonomía completa será una utopía a corto y medio plazo. En los escenarios en que el sistema autónomo no pueda automatizar completamente sus tareas, se requerirá pues de la participación humana. Desde un punto de vista ingenieril la colaboración entre el humano y estos sistemas (Human in the Loop) introduce un considerable número de retos y problemas a resolver. En este trabajo se identifican los retos tecnológicos que introduce esta colaboración humano-sistema, y se define un marco conceptual que identifica los aspectos a considerar desde un punto de vista abstracto e ingenieril. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/062]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_49.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_49.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pele@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miriam Gil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mgil@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Joan Fons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jjfons@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manoli Albert]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[malbert@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Definiendo un Caso de Estudio para Recomendaciones Dinámicas Móviles</title>
		<link>https://biblioteca.sistedes.es/articulo/definiendo-un-caso-de-estudio-para-recomendaciones-dinamicas-moviles/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/definiendo-un-caso-de-estudio-para-recomendaciones-dinamicas-moviles/</guid>
		<description></description>
		<content><![CDATA[Los denominados sistemas de recomendación permiten aliviar la sobrecarga de información de los usuarios, al ofrecer sugerencias específicas acerca de ítems concretos (películas, libros, actividades, puntos de interés, etc.) que pueden resultar de interés para el usuario. En los últimos años se está realizando una intensa investigación en el desarrollo de sistemas de recomendación sensibles al contexto, ya que tener en cuenta el contexto del usuario (posición geográfica, tiempo atmosférico, estado de ánimo, etc.) permite ofrecer recomendaciones más apropiadas. En entornos de computación móvil uno de los elementos clave del contexto del usuario es su localización, siendo relevante ofrecer sugerencias al usuario de forma proactiva (sin peticiones expresas por parte del usuario) y teniendo en cuenta su trayectoria. En este artículo, describimos nuestro trabajo en progreso relacionado con las recomendaciones dinámicas sensibles al contexto en entornos móviles. Debido a la dificultad de evaluación de estos sistemas de recomendación en el mundo real, nos centramos en el desarrollo de un caso de estudio que simulará un escenario para recomendaciones dinámicas para los visitantes de un museo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2590</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[definiendo-un-caso-de-estudio-para-recomendaciones-dinamicas-moviles]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="computacion-movil"><![CDATA[computación móvil]]></category>
		<category domain="post_tag" nicename="contexto"><![CDATA[Contexto]]></category>
		<category domain="post_tag" nicename="recomendaciones-dinamicas"><![CDATA[recomendaciones dinámicas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los denominados sistemas de recomendación permiten aliviar la sobrecarga de información de los usuarios, al ofrecer sugerencias específicas acerca de ítems concretos (películas, libros, actividades, puntos de interés, etc.) que pueden resultar de interés para el usuario. En los últimos años se está realizando una intensa investigación en el desarrollo de sistemas de recomendación sensibles al contexto, ya que tener en cuenta el contexto del usuario (posición geográfica, tiempo atmosférico, estado de ánimo, etc.) permite ofrecer recomendaciones más apropiadas.  En entornos de computación móvil uno de los elementos clave del contexto del usuario es su localización, siendo relevante ofrecer sugerencias al usuario de forma proactiva (sin peticiones expresas por parte del usuario) y teniendo en cuenta su trayectoria. En este artículo, describimos nuestro trabajo en progreso relacionado con las recomendaciones dinámicas sensibles al contexto en entornos móviles. Debido a la dificultad de evaluación de estos sistemas de recomendación en el mundo real, nos centramos en el desarrollo de un caso de estudio que simulará un escenario para recomendaciones dinámicas para los visitantes de un museo. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/013]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_50.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_50.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Del Carmen Rodríguez-Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[692383@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Ilarri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[silarri@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ramon Hermoso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[rhermoso@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Raquel Trillo-Lado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[raqueltl@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una Aproximación MDA para la Construcción de Componentes COTSgets en Aplicaciones Web</title>
		<link>https://biblioteca.sistedes.es/articulo/una-aproximacion-mda-para-la-construccion-de-componentes-cotsgets-en-aplicaciones-web/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/una-aproximacion-mda-para-la-construccion-de-componentes-cotsgets-en-aplicaciones-web/</guid>
		<description></description>
		<content><![CDATA[Actualmente, existe una tendencia al desarrollo de aplicaciones web. Muchas de estas aplicaciones se construyen en base a componentes reutilizables, lo que influye considerablemente en el tiempo de desarrollo. En este contexto se enmarca nuestra propuesta. El artículo presenta una solución basada en la ingeniería dirigida por modelos (MDE) para agilizar y facilitar a los desarrolladores la implementación de un tipo de componentes web (llamados COTSgets). Nuestra propuesta consiste en la generación automática de la implementación de estos componentes, en lo que a su estructura y funcionalidad básica se refiere, a partir de un modelo que describe su especificación y mediante la utilización de una transformación modelo-a-texto (M2T). Para dicha implementación se ha seleccionado la incipiente tecnología Polymer.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2591</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-aproximacion-mda-para-la-construccion-de-componentes-cotsgets-en-aplicaciones-web]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="componentes-cotsgets"><![CDATA[Componentes COTSgets]]></category>
		<category domain="post_tag" nicename="coscore"><![CDATA[COScore]]></category>
		<category domain="post_tag" nicename="ingenieria-dirigida-por-modelos-mde"><![CDATA[Ingeniería Dirigida por Modelos (MDE)]]></category>
		<category domain="post_tag" nicename="polymer"><![CDATA[Polymer]]></category>
		<category domain="post_tag" nicename="transformacion-de-modelo-a-texto-m2t"><![CDATA[Transformación de Modelo a Texto (M2T)]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Actualmente, existe una tendencia al desarrollo de aplicaciones web. Muchas de estas aplicaciones se construyen en base a componentes reutilizables, lo que influye considerablemente en el tiempo de desarrollo. En este contexto se enmarca nuestra propuesta. El artículo presenta una solución basada en la ingeniería dirigida por modelos (MDE) para agilizar y facilitar a los desarrolladores la implementación de un tipo de componentes web (llamados COTSgets). Nuestra propuesta consiste en la generación automática de la implementación de estos componentes, en lo que a su estructura y funcionalidad básica se refiere, a partir de un modelo que describe su especificación y mediante la utilización de una transformación modelo-a-texto (M2T). Para dicha implementación se ha seleccionado la incipiente tecnología Polymer.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/032]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_53.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_53.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jose A. Asensio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jacortes@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group. University of Almerí­a]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Nicolás Padilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[npadilla@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group. University of Almerí­a]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Criado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[javi.criado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Almerí­a]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Luis Iribarne]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[luis.iribarne@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Almerí­a]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Does the level of detail of UML diagrams affect the maintainability of source code?: a family of experiments</title>
		<link>https://biblioteca.sistedes.es/articulo/does-the-level-of-detail-of-uml-diagrams-affect-the-maintainability-of-source-code-a-family-of-experiments/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/does-the-level-of-detail-of-uml-diagrams-affect-the-maintainability-of-source-code-a-family-of-experiments/</guid>
		<description></description>
		<content><![CDATA[Although the UML is considered to be the de facto standard notation with which to model software, there is still resistance to model-based development. UML modeling is perceived to be expensive and not necessarily cost-effective. It is therefore important to collect empirical evidence concerning the conditions under which the use of UML makes a practical difference. The focus of this paper is to investigate whether and how the Level of Detail (LoD) of UML diagrams impacts on the performance of maintenance tasks in a model-centric approach. A family of experiments consisting of one controlled experiment and three replications has therefore been carried out with 81 students with different abilities and levels of experience from 3 countries (The Netherlands, Spain, and Italy). The analysis of the results of the experiments indicates that there isno strong statistical evidence as to the influence of different LoDs. The analysis suggests a slight tendency toward better results when using low LoD UML diagrams, especially if used for the modification of the source code, while a high LoD would appear to be helpful in understanding the system. The participants in our study also favored low LoD diagrams because they were perceived as easier to read. Although the participants expressed a preference for low LoD diagrams, no statistically significant conclusions can be drawn from the set of experiments. One important finding attained from this family of experiments was that the participants minimized or avoided the use of UML diagrams, regardless of their LoD. This effect was probably the result of using small software systems from well-known domains as experimental materials.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2592</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[does-the-level-of-detail-of-uml-diagrams-affect-the-maintainability-of-source-code-a-family-of-experiments]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="controlled-experiment"><![CDATA[Controlled Experiment]]></category>
		<category domain="post_tag" nicename="family-of-experiments"><![CDATA[Family of experiments]]></category>
		<category domain="post_tag" nicename="level-of-detail"><![CDATA[Level of detail]]></category>
		<category domain="post_tag" nicename="replication"><![CDATA[Replication]]></category>
		<category domain="post_tag" nicename="software-maintenance"><![CDATA[Software maintenance]]></category>
		<category domain="post_tag" nicename="uml-diagrams"><![CDATA[UML diagrams]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Although the UML is considered to be the de facto standard notation with which to model software, there is still resistance to model-based development. UML modeling is perceived to be expensive and not necessarily cost-effective. It is therefore important to collect empirical evidence concerning the conditions under which the use of UML makes a practical difference. The focus of this paper is to investigate whether and how the Level of Detail (LoD) of UML diagrams impacts on the performance of maintenance tasks in a model-centric approach. A family of experiments consisting of one controlled experiment and three replications has therefore been carried out with 81 students with different abilities and levels of experience from 3 countries (The Netherlands, Spain, and Italy). The analysis of the results of the experiments indicates that there isno strong statistical evidence as to the influence of different LoDs. The analysis suggests a slight tendency toward better results when using low LoD UML diagrams, especially if used for the modification of the source code, while a high LoD would appear to be helpful in understanding the system. The participants in our study also favored low LoD diagrams because they were perceived as easier to read. Although the participants expressed a preference for low LoD diagrams, no statistically significant conclusions can be drawn from the set of experiments. One important finding attained from this family of experiments was that the participants minimized or avoided the use of UML diagrams, regardless of their LoD. This effect was probably the result of using small software systems from well-known domains as experimental materials.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/047]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_54.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_54.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana Maria Fernández-Sáez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ana.fernandez@alarcosqualitycenter.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha/ Leiden University]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Marcela Genero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[marcela.genero@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Danilo Caivano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[danilo.caivano@searandp.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Bari]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Michel Chaudron]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[chaudron@chalmers.se]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Chalmers]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A workflow management system to feed digital libraries: proposal and case study</title>
		<link>https://biblioteca.sistedes.es/articulo/a-workflow-management-system-to-feed-digital-libraries-proposal-and-case-study/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-workflow-management-system-to-feed-digital-libraries-proposal-and-case-study/</guid>
		<description></description>
		<content><![CDATA[Articulo publicado en: Multimedia Tools and Applications, 75(7), Springer US, Estados Unidos, 2016, pp. 3843-3877. DOI: 10.1007/s11042-014-2155-3 Multimedia Tools and Applications tiene factor de impacto 1.331, y está clasificada como Q2 en COMPUTER SCIENCE, INFORMATION SYSTEMS]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2593</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-workflow-management-system-to-feed-digital-libraries-proposal-and-case-study]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="digital-libraries"><![CDATA[Digital libraries]]></category>
		<category domain="post_tag" nicename="text-retrieval"><![CDATA[Text retrieval]]></category>
		<category domain="post_tag" nicename="workflow-management-system"><![CDATA[Workflow management system]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Articulo publicado en:  Multimedia Tools and Applications, 75(7), Springer US, Estados Unidos, 2016, pp. 3843-3877.  DOI: 10.1007/s11042-014-2155-3  Multimedia Tools and Applications tiene factor de impacto 1.331, y está clasificada como Q2 en COMPUTER SCIENCE, INFORMATION SYSTEMS]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/010]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_57.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_57.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ángeles S. Places]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[asplaces@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Fariña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fari@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of A Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Miguel R. Luaces]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[luaces@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of A Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Oscar Pedreira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[opedreira@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruna]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Diego Seco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[dseco@udec.cl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Concepción]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Trayectorias semánticas en aplicaciones de Mobile Workforce Management</title>
		<link>https://biblioteca.sistedes.es/articulo/trayectorias-semanticas-en-aplicaciones-de-mobile-workforce-management/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/trayectorias-semanticas-en-aplicaciones-de-mobile-workforce-management/</guid>
		<description></description>
		<content><![CDATA[Los smartphones actuales presentan continuamente mejoras en sus características y en la actualidad incluyen diversos sensores que capturan información de muy diversos tipos (localización, aceleración lineal, etc.). Un proceso industrial que podría beneficiarse mucho de esta información es el de Mobile Workforce Management (MWM). Sin embargo, existen varios problemas que lo impiden: i) hoy en día el nivel de abstracción de las actividades que son identificadas es demasiado bajo (por ejemplo, moviéndose en vez de realizando una inspección en un cliente, o parado en vez de cargando un camión en la instalación de un cliente), ii) los trabajos de investigación se centran en el uso de algoritmos que contrastan la información geográfica con los datos del GPS, o en algoritmos de aprendizaje aplicados a los datos de los sensores, pero existen pocos resultados de investigación que combinen ambos tipos de datos, y iii) la información contextual procedente de los repositorios de información geográfica o del software MWM es raramente usada. En este artículo se presenta una nueva metodología que convierte los datos crudos capturados por los sensores de los dispositivos móviles en trayectorias anotadas con actividades semánticas en un alto nivel de abstracción. La metodología está basada en la definición de taxonomías de actividades que pueden ser adaptadas fácilmente a las necesidades de cualquier empresa. Estas taxonomías describen los valores esperados para cada una de las variables que son recogidas en el sistema usando predicados definidos mediante un lenguaje de especificación de patrones.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2594</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[trayectorias-semanticas-en-aplicaciones-de-mobile-workforce-management]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="datos-de-sensores"><![CDATA[datos de sensores]]></category>
		<category domain="post_tag" nicename="mobile-workforce-management"><![CDATA[mobile workforce management]]></category>
		<category domain="post_tag" nicename="sistemas-de-informacion-geografica"><![CDATA[Sistemas de Informacíon Geográfica]]></category>
		<category domain="post_tag" nicename="trayectorias-semanticas"><![CDATA[trayectorias semánticas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los smartphones actuales presentan continuamente mejoras en sus características y en la actualidad incluyen diversos sensores que capturan información de muy diversos tipos (localización, aceleración lineal, etc.). Un proceso industrial que podría beneficiarse mucho de esta información es el de Mobile Workforce Management (MWM). Sin embargo, existen varios problemas que lo impiden: i) hoy en día el nivel de abstracción de las actividades que son identificadas es demasiado bajo (por ejemplo, moviéndose en vez de realizando una inspección en un cliente, o parado en vez de cargando un camión en la instalación de un cliente), ii) los trabajos de investigación se centran en el uso de algoritmos que contrastan la información geográfica con los datos del GPS, o en algoritmos de aprendizaje aplicados a los datos de los sensores, pero existen pocos resultados de investigación que combinen ambos tipos de datos, y iii) la información contextual procedente de los repositorios de información geográfica o del software MWM es raramente usada.  En este artículo se presenta una nueva metodología que convierte los datos crudos capturados por los sensores de los dispositivos móviles en trayectorias anotadas con actividades semánticas en un alto nivel de abstracción. La metodología está basada en la definición de taxonomías de actividades que pueden ser adaptadas fácilmente a las necesidades de cualquier empresa. Estas taxonomías describen los valores esperados para cada una de las variables que son recogidas en el sistema usando predicados definidos mediante un lenguaje de especificación de patrones. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/023]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_58.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_58.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Nieves R. Brisaboa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[brisaboa@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miguel R. Luaces]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[luaces@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of A Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Cristina Martínez Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[cristina.martinez@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ángeles S. Places]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[asplaces@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una aplicación práctica del método Delphi para la validación de una propuesta de Ingeniería Web</title>
		<link>https://biblioteca.sistedes.es/articulo/una-aplicacion-practica-del-metodo-delphi-para-la-validacion-de-una-propuesta-de-ingenieria-web/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/una-aplicacion-practica-del-metodo-delphi-para-la-validacion-de-una-propuesta-de-ingenieria-web/</guid>
		<description></description>
		<content><![CDATA[Las organizaciones que trabajan en el desarrollo de Sistemas de Información son reacias muchas veces a implantar nuevas metodologías de trabajo sin disponer previamente de ciertas garantías de éxito. Esta reacción es comprensible, ya que el éxito o el fracaso de ciertos proyectos puede suponer graves pérdidas económicas o reputacionales para las misma. En este trabajo vamos a presentar una aplicación práctica del uso de una técnica de juicio de expertos, el método Delphi, para la validación de una propuesta metodológica en el ámbito de la Ingeniería Web. El uso de las técnicas basadas en juicios de expertos puede suponer un buen compromiso en términos de inversión requerida y rápido retorno de la misma, obteniendo un juicio objetivo sobre una determinada propuesta sin tener que realizar una elevada inversión económica o arriesgar determinados proyectos que pueden ser clave para las organizaciones.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2595</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-aplicacion-practica-del-metodo-delphi-para-la-validacion-de-una-propuesta-de-ingenieria-web]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="delphi"><![CDATA[Delphi]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software"><![CDATA[Ingeniería del Software]]></category>
		<category domain="post_tag" nicename="ingenieria-web"><![CDATA[Ingeniería Web]]></category>
		<category domain="post_tag" nicename="juicio-de-expertos"><![CDATA[juicio de expertos]]></category>
		<category domain="post_tag" nicename="metodologias-agiles"><![CDATA[Metodologías Ágiles]]></category>
		<category domain="post_tag" nicename="scrum"><![CDATA[Scrum]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las organizaciones que trabajan en el desarrollo de Sistemas de Información son reacias muchas veces a implantar nuevas metodologías de trabajo sin disponer previamente de ciertas garantías de éxito. Esta reacción es comprensible, ya que el éxito o el fracaso de ciertos proyectos puede suponer graves pérdidas económicas o reputacionales para las misma. En este trabajo vamos a presentar una aplicación práctica del uso de una técnica de juicio de expertos, el método Delphi, para la validación de una propuesta metodológica en el ámbito de la Ingeniería Web. El uso de las técnicas basadas en juicios de expertos puede suponer un buen compromiso en términos de inversión requerida y rápido retorno de la misma, obteniendo un juicio objetivo sobre una determinada propuesta sin tener que realizar una elevada inversión económica o arriesgar determinados proyectos que pueden ser clave para las organizaciones. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/052]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_59.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_59.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Torrecilla-Salinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carlos.torrecilla@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Olga De Troyer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Olga.DeTroyer@vub.ac.be]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science. Vrije Universiteit Brussel (VUB). Belgium]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[M.J. Escalona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mjescalona@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel Mejías]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[risoto@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evaluación de un Método de Monitorización de Calidad de Servicios Cloud: Una Replicación Interna</title>
		<link>https://biblioteca.sistedes.es/articulo/evaluacion-de-un-metodo-de-monitorizacion-de-calidad-de-servicios-cloud-una-replicacion-interna/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/evaluacion-de-un-metodo-de-monitorizacion-de-calidad-de-servicios-cloud-una-replicacion-interna/</guid>
		<description></description>
		<content><![CDATA[Contexto: El modelo de negocio que ofrece la computación en la nube tiene un gran número de ventajas tanto para proveedores como para consumidores. Sin embargo, es imprescindible controlar la calidad de los servicios provistos, lo que se puede alcanzar a través de soluciones de monitorización. Sin embargo, se ha prestado poca atención a las percepciones de los usuarios que las utilizan. En un trabajo previo, hemos realizado un cuasi-experimento para evaluar las percepciones de un grupo de estudiantes en el uso un método de monitorización (Cloud MoS@RT) de calidad de servicios cloud en tiempo de ejecución. Objetivo: Proporcionar mayor evidencia sobre la facilidad de uso percibida, utilidad percibida e intención de uso de un grupo de profesionales utilizando el método Cloud MoS@RT. Método: Hemos ejecutado una replicación interna del cuasi-experimento base con un grupo de profesionales. La tarea experimental consistió en utilizar Cloud MoS@RT para configurar la monitorización de la calidad de un servicio en la plataforma Microsoft Azure. Los participantes también rellenaron un cuestionario que nos ha permitido evaluar su percepción sobre la utilidad del método. Resultados: Los resultados indican que los participantes han percibido el método como fácil de usar y útil, y han manifestado su intención de uso futuro. Conclusiones: Los resultados están alineados con el cuasi-experimento base y confirman que Cloud MoS@RT puede ser utilizado de manera efectiva tanto por estudiantes como profesionales sin la necesidad de un extensivo entrena-miento y conocimiento de la plataforma cloud.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2596</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evaluacion-de-un-metodo-de-monitorizacion-de-calidad-de-servicios-cloud-una-replicacion-interna]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="calidad-de-servicios"><![CDATA[Calidad de Servicios]]></category>
		<category domain="post_tag" nicename="cloud-computing"><![CDATA[Cloud Computing]]></category>
		<category domain="post_tag" nicename="cuasi-experimento"><![CDATA[Cuasi-Experimento]]></category>
		<category domain="post_tag" nicename="monitorizacion"><![CDATA[Monitorización]]></category>
		<category domain="post_tag" nicename="replicacion"><![CDATA[Replicación]]></category>
		<category domain="post_tag" nicename="software-as-a-service"><![CDATA[Software as a Service]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Contexto: El modelo de negocio que ofrece la computación en la nube tiene un gran número de ventajas tanto para proveedores como para consumidores. Sin embargo, es imprescindible controlar la calidad de los servicios provistos, lo que se puede alcanzar a través de soluciones de monitorización. Sin embargo, se ha prestado poca atención a las percepciones de los usuarios que las utilizan. En un trabajo previo, hemos realizado un cuasi-experimento para evaluar las percepciones de un grupo de estudiantes en el uso un método de monitorización (Cloud MoS@RT) de calidad de servicios cloud en tiempo de ejecución. Objetivo: Proporcionar mayor evidencia sobre la facilidad de uso percibida, utilidad percibida e intención de uso de un grupo de profesionales utilizando el método Cloud MoS@RT.  Método: Hemos ejecutado una replicación interna del cuasi-experimento base con un grupo de profesionales. La tarea experimental consistió en utilizar Cloud MoS@RT para configurar la monitorización de la calidad de un servicio en la plataforma Microsoft Azure. Los participantes también rellenaron un cuestionario que nos ha permitido evaluar su percepción sobre la utilidad del método. Resultados: Los resultados indican que los participantes han percibido el método como fácil de usar y útil, y han manifestado su intención de uso futuro. Conclusiones: Los resultados están alineados con el cuasi-experimento base y confirman que Cloud MoS@RT puede ser utilizado de manera efectiva tanto por estudiantes como profesionales sin la necesidad de un extensivo entrena-miento y conocimiento de la plataforma cloud.  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/050]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_60.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_60.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Priscila Cedillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[icedillo@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Emilio Insfran]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[einsfran@disc.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Silvia Abrahao]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sabrahao@disc.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un Editor Textual para el Modelado y la Generación de Código de Patrones de Eventos</title>
		<link>https://biblioteca.sistedes.es/articulo/un-editor-textual-para-el-modelado-y-la-generacion-de-codigo-de-patrones-de-eventos/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/un-editor-textual-para-el-modelado-y-la-generacion-de-codigo-de-patrones-de-eventos/</guid>
		<description></description>
		<content><![CDATA[El procesamiento de eventos complejos (CEP) es una tecnología que permite analizar y correlacionar grandes cantidades de datos con el propósito de detectar situaciones de interés en tiempo real. Para ello se requiere implementar patrones de eventos, especificando las condiciones que deben cumplirse para detectar dichas situaciones, con los lenguajes de procesamiento de eventos (EPL). A pesar de que los usuarios suelen tener un vasto conocimiento en el dominio para el que se necesitan definir ciertos patrones de eventos, suelen ser inexpertos tanto en EPL como en el lenguaje requerido para implementar las acciones a llevar a cabo tras la detección de los patrones. En este artículo presentamos un editor textual para el modelado y la generación de código de los patrones de eventos que se necesiten detectar en un dominio de aplicación. Gracias a este editor, el usuario solo tendrá que conocer un lenguaje textual para definir patrones de eventos, que podrán ser posteriormente transformados automáticamente al EPL soportado por el motor CEP en cuestión. Este editor complementa a MEdit4CEP, un editor que permite la definición gráfica e intuitiva de patrones sin necesidad de conocer ningún lenguaje de programación en particular.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2597</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-editor-textual-para-el-modelado-y-la-generacion-de-codigo-de-patrones-de-eventos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cep"><![CDATA[CEP]]></category>
		<category domain="post_tag" nicename="editor-de-modelado-textual"><![CDATA[Editor de Modelado Textual]]></category>
		<category domain="post_tag" nicename="epl"><![CDATA[EPL]]></category>
		<category domain="post_tag" nicename="mdd"><![CDATA[MDD]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El procesamiento de eventos complejos (CEP) es una tecnología que permite analizar y correlacionar grandes cantidades de datos con el propósito de detectar situaciones de interés en tiempo real. Para ello se requiere implementar patrones de eventos, especificando las condiciones que deben cumplirse para detectar dichas situaciones, con los lenguajes de procesamiento de eventos (EPL). A pesar de que los usuarios suelen tener un vasto conocimiento en el dominio para el que se necesitan definir ciertos patrones de eventos, suelen ser inexpertos tanto en EPL como en el lenguaje requerido para implementar las acciones a llevar a cabo tras la detección de los patrones. En este artículo presentamos un editor textual para el modelado y la generación de código de los patrones de eventos que se necesiten detectar en un dominio de aplicación. Gracias a este editor, el usuario solo tendrá que conocer un lenguaje textual para definir patrones de eventos, que podrán ser posteriormente transformados automáticamente al EPL soportado por el motor CEP en cuestión. Este editor complementa a MEdit4CEP, un editor que permite la definición gráfica e intuitiva de patrones sin necesidad de conocer ningún lenguaje de programación en particular.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/031]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_61.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_61.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ramón Ramírez-González]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[rrgonzalez1992@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Escuela Superior de Ingeniería. Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Design Patterns for Software Evolution Requirements</title>
		<link>https://biblioteca.sistedes.es/articulo/design-patterns-for-software-evolution-requirements/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/design-patterns-for-software-evolution-requirements/</guid>
		<description></description>
		<content><![CDATA[The software Engineering term known as Software Evolution can be understood in two senses. First, as the changes that software experiences over its develop-ment cycle, second, as changes that software goes through in its lifetime. In both cases, software architectures should lead, support and ease any software modifications, reconfiguration or adaptation to a changing environment. At moment, it is widely acknowledged that design and architectural patterns must be used for carrying out any software development focused on quality. We present here the analysis of several design and architectural patterns for sustaining software systems evolution according to two complementary perspectives, one connected with maintainability and the other with dynamicity of any software design.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2598</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[design-patterns-for-software-evolution-requirements]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="architectural-patterns"><![CDATA[Architectural Patterns]]></category>
		<category domain="post_tag" nicename="design-patterns"><![CDATA[Design Patterns]]></category>
		<category domain="post_tag" nicename="software-architecture"><![CDATA[Software Architecture]]></category>
		<category domain="post_tag" nicename="software-quality-factors"><![CDATA[Software Quality Factors]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The software Engineering term known as Software Evolution can be understood in two senses. First, as the changes that software experiences over its develop-ment cycle, second, as changes that software goes through in its lifetime. In both cases, software architectures should lead, support and ease any software modifications, reconfiguration or adaptation to a changing environment. At moment, it is widely acknowledged that design and architectural patterns must be used for carrying out any software development focused on quality. We present here the analysis of several design and architectural patterns for sustaining software systems evolution according to two complementary perspectives, one connected with maintainability and the other with dynamicity of any software design.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/069]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_63.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_63.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel I. Capel Tuñón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[manuelcapel@ugr.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Anna C. Gramán Padua]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[acgriman@usb.ve]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Simón Bolí­var]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Eladio Garví García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[egarvi@ugr.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>HADAS: Asistente de eco-eficiencia con repositorio de consumo energético</title>
		<link>https://biblioteca.sistedes.es/articulo/hadas-asistente-de-eco-eficiencia-con-repositorio-de-consumo-energetico/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/hadas-asistente-de-eco-eficiencia-con-repositorio-de-consumo-energetico/</guid>
		<description></description>
		<content><![CDATA[El interés por la Ingeniería del Software verde, o sea, sensible al consumo de energía, es relativamente reciente. Su objetivo es concienciar a los desarrolladores de software de la influencia que tienen sus decisiones de diseño e implementación en el gasto energético del producto final. Hasta el momento se han publicado muchos resultados experimentales que comparan el consumo de energía de varias soluciones alternativas, y que demuestran que se puede reducir dicho consumo hasta en un 70 %. Aunque estos resultados sean de libre disposición, no es sencillo que un desarrollador aplique este conocimiento a sus aplicaciones. En consecuencia, en este artículo presentamos el eco-asistente HADAS cuya utilidad es: (i) los investigadores almacenarán sus resultados en un repositorio de libre disposición, (ii) los desarrolladores podrán razonar y obtener las configuraciones que menos energía consuman y que satisfaga sus requisitos. Nos centraremos en mostrar los elementos principales de nuestra propuesta y cómo se aplica a casos de estudio reales.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2599</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hadas-asistente-de-eco-eficiencia-con-repositorio-de-consumo-energetico]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cvl"><![CDATA[CVL]]></category>
		<category domain="post_tag" nicename="energia"><![CDATA[Energía]]></category>
		<category domain="post_tag" nicename="java"><![CDATA[Java]]></category>
		<category domain="post_tag" nicename="linea-de-productos-software"><![CDATA[Línea de Productos Software]]></category>
		<category domain="post_tag" nicename="servidor"><![CDATA[Servidor]]></category>
		<category domain="post_tag" nicename="variabilidad"><![CDATA[Variabilidad]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El interés por la Ingeniería del Software verde, o sea, sensible al consumo de energía, es relativamente reciente. Su objetivo es concienciar a los desarrolladores de software de la influencia que tienen sus decisiones de diseño e implementación en el gasto energético del producto final. Hasta el momento se han publicado muchos resultados experimentales que comparan el consumo de energía de varias soluciones alternativas, y que demuestran que se puede reducir dicho consumo hasta en un 70 %. Aunque estos resultados sean de libre disposición, no es sencillo que un desarrollador aplique este conocimiento a sus aplicaciones. En consecuencia, en este artículo presentamos el eco-asistente HADAS cuya utilidad es: (i) los investigadores almacenarán sus resultados en un repositorio de libre disposición, (ii) los desarrolladores podrán razonar y obtener las configuraciones que menos energía consuman y que satisfaga sus requisitos. Nos centraremos en mostrar los elementos principales de nuestra propuesta y cómo se aplica a casos de estudio reales.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/005]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_64.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_64.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Daniel Jesus Munoz Guerra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[danimg@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Malaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Monica Pinto Alarcon]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pinto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Malaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Malaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Impacto de las notaciones en la productividad de creación de modelos de dominio: Un estudio empírico</title>
		<link>https://biblioteca.sistedes.es/articulo/impacto-de-las-notaciones-en-la-productividad-de-creacion-de-modelos-de-dominio-un-estudio-empirico/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/impacto-de-las-notaciones-en-la-productividad-de-creacion-de-modelos-de-dominio-un-estudio-empirico/</guid>
		<description></description>
		<content><![CDATA[El uso intensivo de modelos en el paradigma MDE es una de las piedras angulares para la consecución de mejoras de productividad en el desarrollo software. Sin embargo, con el fin de maximizar dicha mejora, es importante realizar una selección adecuada de las notaciones. Desafortunadamente, la comunidad de MDE todavía adolece de una falta de datos empíricos que soporten dicha selección. El objetivo del estudio empírico presentado en este artículo ha sido comparar dos notaciones, una gráfica y otra textual, con respecto a la eficiencia y eficacia mostrada por desarrolladores software noveles a la hora de desarrollar modelos de dominio de dos aplicaciones distintas. Para ello, se ha diseñado un quasi-experimento con 127 alumnos del grado de Ingeniería Informática de la Universidad de Alicante. Los sujetos se clasificaron de manera aleatoria en cuatro grupos, y a cada grupo se le asignó una combinación de Notación y Sistema. Los datos recogidos muestran que, mientras que el sistema desarrollado no influye de manera significativa en las medidas analizadas, la notación sí lo hace de manera significativa en todas ellas, siendo la notación gráfica la que mejores resultados arroja tanto en cuanto a eficiencia como eficacia. Con el fin de generalizar estos resultados, se hace necesario realizar nuevas réplicas con distintos perfiles de sujetos, distintas notaciones y distintos tipos de aplicación.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2600</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[impacto-de-las-notaciones-en-la-productividad-de-creacion-de-modelos-de-dominio-un-estudio-empirico]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="domain-model"><![CDATA[Domain Model]]></category>
		<category domain="post_tag" nicename="empirical-software-engineering"><![CDATA[Empírical Software Engineering]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="notation"><![CDATA[Notation]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El uso intensivo de modelos en el paradigma MDE es una de las piedras angulares para la consecución de mejoras de productividad en el desarrollo software. Sin embargo, con el fin de maximizar dicha mejora, es importante realizar una selección adecuada de las notaciones. Desafortunadamente, la comunidad de MDE todavía adolece de una falta de datos empíricos que soporten dicha selección. El objetivo del estudio empírico presentado en este artículo ha sido comparar dos notaciones, una gráfica y otra textual, con respecto a la eficiencia y eficacia mostrada por desarrolladores software noveles a la hora de desarrollar modelos de dominio de dos aplicaciones distintas. Para ello, se ha diseñado un quasi-experimento con 127 alumnos del grado de Ingeniería Informática de la Universidad de Alicante. Los sujetos se clasificaron de manera aleatoria en cuatro grupos, y a cada grupo se le asignó una combinación de Notación y Sistema. Los datos recogidos muestran que, mientras que el sistema desarrollado no influye de manera significativa en las medidas analizadas, la notación sí lo hace de manera significativa en todas ellas, siendo la notación gráfica la que mejores resultados arroja tanto en cuanto a eficiencia como eficacia. Con el fin de generalizar estos resultados, se hace necesario realizar nuevas réplicas con distintos perfiles de sujetos, distintas notaciones y distintos tipos de aplicación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/028]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_65.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_65.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cristina Cachero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ccachero@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Santiago Meliá]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[santi@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesús María Hermida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jesus.hermida@jrc.ec.europa.eu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[European Comission Joint Research Centre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Identificadores Persistentes para Objetos Espaciales</title>
		<link>https://biblioteca.sistedes.es/articulo/identificadores-persistentes-para-objetos-espaciales/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/identificadores-persistentes-para-objetos-espaciales/</guid>
		<description></description>
		<content><![CDATA[Resumen. Un gran volumen de la información almacenada en los sistemas de información está georreferenciada mediante direcciones, códigos y conjuntos de coordenadas. Un mecanismo para garantizar un uso consistente es asignar identificadores persistentes y resolubles a la información espacial. Dada la explosión en el volumen de la información espacial es necesario que exista una arquitectura que provea y resuelva dichos identificadores persistentes de la forma más automática posible. Este artículo propone una arquitectura para la recolección, registro, resolución, catalogación y difusión de identificadores persistentes de datos espaciales. También propone un algoritmo para facilitar la recolección de identificadores persistentes mediante la automatización de la extracción de datos espaciales publicados en servicios geoespaciales estándar con recursos limitados. Esta arquitectura ha sido llevada a la práctica para dar soporte a la implementación de la Directiva Europea INSPIRE.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2601</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[identificadores-persistentes-para-objetos-espaciales]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="informacion-geografica"><![CDATA[Información Geográfica]]></category>
		<category domain="post_tag" nicename="inspire"><![CDATA[INSPIRE]]></category>
		<category domain="post_tag" nicename="pid"><![CDATA[PID]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen. Un gran volumen de la información almacenada en los sistemas de información está georreferenciada mediante direcciones, códigos y conjuntos de coordenadas. Un mecanismo para garantizar un uso consistente es asignar identificadores persistentes y resolubles a la información espacial. Dada la explosión en el volumen de la información espacial es necesario que exista una arquitectura que provea y resuelva dichos identificadores persistentes de la forma más automática posible. Este artículo propone una arquitectura para la recolección, registro, resolución, catalogación y difusión de identificadores persistentes de datos espaciales. También propone un algoritmo para facilitar la recolección de identificadores persistentes mediante la automatización de la extracción de datos espaciales publicados en servicios geoespaciales estándar con recursos limitados. Esta arquitectura ha sido llevada a la práctica para dar soporte a la implementación de la Directiva Europea INSPIRE.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/017]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_67.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_67.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco J. Lopez-Pellicer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fjlopez@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Rubén Béjar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[rbejar@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Miguel Á. Latre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[latre@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Javier Nogueras-Iso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jnog@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[F.Javier Zarazaga-Soria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[javy@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Descubrimiento de patrones de diseño basado en buenas prácticas: modelo y discusión</title>
		<link>https://biblioteca.sistedes.es/articulo/descubrimiento-de-patrones-de-diseno-basado-en-buenas-practicas-modelo-y-discusion/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/descubrimiento-de-patrones-de-diseno-basado-en-buenas-practicas-modelo-y-discusion/</guid>
		<description></description>
		<content><![CDATA[La complejidad de los sistemas actuales obliga a los ingenieros software a aprender de las buenas prácticas empleadas en proyectos previos como, por ejemplo, el uso de patrones de diseño. Dichos patrones tienen una gran importancia durante la fase de diseño y su posterior implementación genera varias ventajas. En este contexto, se propone el uso de técnicas de minería de datos que ayuden a comprender como otros ingenieros software han implementado dichos patrones. Con la representación adecuada, este conocimiento se podrá utilizar para identificar fragmentos de código susceptibles de ser convertidos en un determinado patrón. Además del modelo, se discuten ventajas y retos asociados.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2602</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[descubrimiento-de-patrones-de-diseno-basado-en-buenas-practicas-modelo-y-discusion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="buenas-practicas"><![CDATA[buenas prácticas]]></category>
		<category domain="post_tag" nicename="mineria-de-repositorios-software"><![CDATA[Minería de repositorios software]]></category>
		<category domain="post_tag" nicename="patrones-de-diseno"><![CDATA[patrones de diseño]]></category>
		<category domain="post_tag" nicename="programacion-genetica-gramatical"><![CDATA[programación genética gramatical]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La complejidad de los sistemas actuales obliga a los ingenieros software a aprender de las buenas prácticas empleadas en proyectos previos como, por ejemplo, el uso de patrones de diseño. Dichos patrones tienen una gran importancia durante la fase de diseño y su posterior implementación genera varias ventajas. En este contexto, se propone el uso de técnicas de minería de datos que ayuden a comprender como otros ingenieros software han implementado dichos patrones. Con la representación adecuada, este conocimiento se podrá utilizar para identificar fragmentos de código susceptibles de ser convertidos en un determinado patrón. Además del modelo, se discuten ventajas y retos asociados.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/035]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_68.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_68.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rafael Barbudo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rbarbudo@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Aurora Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[aramirez@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José Raúl Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Sebastián Ventura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sventura@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Búsqueda coevolutiva interactiva aplicada al diseño de software</title>
		<link>https://biblioteca.sistedes.es/articulo/busqueda-coevolutiva-interactiva-aplicada-al-diseno-de-software/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/busqueda-coevolutiva-interactiva-aplicada-al-diseno-de-software/</guid>
		<description></description>
		<content><![CDATA[La resolución de tareas de diseño software mediante técnicas de búsqueda plantea dificultades como la exploración efectiva de un gran conjunto de alternativas, cuya calidad no puede ser evaluada sólo en base a medidas software. Con el fin de solventarlas, es necesario considerar técnicas más avanzadas que se aproximen más a cómo los ingenieros diseñan en la realidad. Los modelos coevolutivos permiten descomponer el problema original en varias partes diferenciadas que se resuelven simultáneamente, mientras que la optimización interactiva permite incorporar el conocimiento del ingeniero. Este trabajo propone un modelo que combina ambas técnicas y plantea los retos que conlleva su desarrollo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2603</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[busqueda-coevolutiva-interactiva-aplicada-al-diseno-de-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="algoritmos-coevolutivos"><![CDATA[algoritmos coevolutivos]]></category>
		<category domain="post_tag" nicename="diseno-software"><![CDATA[diseño software]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software-basada-en-busqueda"><![CDATA[ingeniería del software basada en búsqueda]]></category>
		<category domain="post_tag" nicename="optimizacion-interactiva"><![CDATA[optimización interactiva]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La resolución de tareas de diseño software mediante técnicas de búsqueda plantea dificultades como la exploración efectiva de un gran conjunto de alternativas, cuya calidad no puede ser evaluada sólo en base a medidas software. Con el fin de solventarlas, es necesario considerar técnicas más avanzadas que se aproximen más a cómo los ingenieros diseñan en la realidad. Los modelos coevolutivos permiten descomponer el problema original en varias partes diferenciadas que se resuelven simultáneamente, mientras que la optimización interactiva permite incorporar el conocimiento del ingeniero. Este trabajo propone un modelo que combina ambas técnicas y plantea los retos que conlleva su desarrollo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/034]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_69.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_69.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aurora Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aramirez@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Raúl Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sebastián Ventura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sventura@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Visualización de Esquemas en Bases de Datos NoSQL basadas en documentos</title>
		<link>https://biblioteca.sistedes.es/articulo/visualizacion-de-esquemas-en-bases-de-datos-nosql-basadas-en-documentos/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/visualizacion-de-esquemas-en-bases-de-datos-nosql-basadas-en-documentos/</guid>
		<description></description>
		<content><![CDATA[La ausencia de esquema (schemaless) es una de las características más atractivas de las bases de datos NoSQL debido a la flexibilidad que ofrece. Por ejemplo, datos no uniformes pueden ser almacenados y se facilita la evolución. Sin embargo, los desarrolladores siempre tienen en mente un esquema cuando escriben código para bases de datos NoSQL y muchas utilidades de bases de datos también requieren el conocimiento del esquema para implementar su funcionalidad. Por esta razón, recientemente se han propuesto diferentes enfoques para inferir el esquema ímplicito en los datos NoSQL almacenados. En este trabajo se presenta una herramienta para la visualización de esquemas NoSQL representados como modelos que son obtenidos por medio de un proceso de ingeniería inversa definido por los autores en un trabajo previo. Estos modelos conforman a un metamodelo Ecore que representa esquemas versionados NoSQL. La herramienta es capaz de mostrar diferentes vistas o diagramas de los esquemas que han sido ideados para favorecer la comprensión de algún aspecto del esquema, por ejemplo mostrar un esquema global con todas las versiones de entidades y las relaciones entre ellas. Se trata de una de las primeras soluciones de visualización de esquemas NoSQL.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2604</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[visualizacion-de-esquemas-en-bases-de-datos-nosql-basadas-en-documentos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="nosql-databases"><![CDATA[NoSQL Databases]]></category>
		<category domain="post_tag" nicename="nosql-schema"><![CDATA[NoSQL schema]]></category>
		<category domain="post_tag" nicename="schema-visualization"><![CDATA[Schema Visualization]]></category>
		<category domain="post_tag" nicename="sirius"><![CDATA[Sirius]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La ausencia de esquema (schemaless) es una de las características  más atractivas de las bases de datos NoSQL debido a la flexibilidad que ofrece. Por ejemplo, datos no uniformes pueden ser almacenados y se facilita la evolución. Sin embargo, los desarrolladores siempre tienen en mente un esquema cuando escriben código para bases de datos NoSQL y muchas utilidades de bases de datos también requieren el conocimiento del esquema para implementar su funcionalidad. Por esta razón,  recientemente se han propuesto diferentes enfoques para inferir el esquema ímplicito en los datos NoSQL almacenados. En este trabajo se presenta una herramienta para la visualización de esquemas NoSQL representados como modelos que son obtenidos por medio de un proceso de ingeniería inversa definido por los autores en un trabajo previo. Estos modelos conforman a un metamodelo Ecore que representa esquemas versionados NoSQL. La herramienta es capaz de mostrar diferentes vistas o diagramas de los esquemas que han sido ideados para favorecer la comprensión de algún aspecto del esquema, por ejemplo mostrar un esquema global con todas las versiones de entidades y las relaciones entre ellas. Se trata de una de las primeras soluciones de visualización de esquemas NoSQL.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/025]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_71.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_71.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alberto Hernández Chillón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alberto.hernandez1@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Cátedra SAES - Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Severino Feliciano Morales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[severino.feliciano@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesus Garcia-Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jmolina@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Diego Sevilla Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[dsevilla@ditec.um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una experiencia en la implementación del método AFP</title>
		<link>https://biblioteca.sistedes.es/articulo/una-experiencia-en-la-implementacion-del-metodo-afp/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/una-experiencia-en-la-implementacion-del-metodo-afp/</guid>
		<description></description>
		<content><![CDATA[OMG lanzó en 2014 la propuesta Automated Function Point (AFP) para automatizar el conteo de puntos de función de una aplicación legacy en procesos de modernización a partir de modelos KDM. En el contexto de una colaboración entre el grupo Modelum (Universidad de Murcia) y la empresa Open Canarias se ha desarrollado una implementación de AFP que se está evaluando para código Oracle Forms. En este trabajo se describe la experiencia de implementación: motivación, arquitectura y desafíos para completarla.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2605</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-experiencia-en-la-implementacion-del-metodo-afp]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="automated-function-points"><![CDATA[Automated Function Points]]></category>
		<category domain="post_tag" nicename="kdm"><![CDATA[KDM]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="oracle-forms"><![CDATA[Oracle Forms]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[OMG lanzó en 2014 la propuesta Automated Function Point (AFP) para automatizar el conteo de puntos de función de una aplicación legacy en procesos de modernización a partir de modelos KDM. En el contexto de una colaboración entre el grupo Modelum (Universidad de Murcia) y la empresa Open Canarias se ha desarrollado una implementación de AFP que se está evaluando para código Oracle Forms. En este trabajo se describe la experiencia de implementación: motivación, arquitectura y desafíos para completarla.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/033]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_72.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_72.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos J. Fernández Candel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carlosjavier.fernandez1@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose Ramon Hoyos Barceló]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jose.hoyos@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesus Garcia-Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jmolina@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Francisco Javier Bermúdez Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[fjavier@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Benito J. Cuesta Viera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[bcuesta@opencanarias.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Open Canarias S.L.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Predicción de módulos defectuosos como un problema de optimización multiobjetivo</title>
		<link>https://biblioteca.sistedes.es/articulo/prediccion-de-modulos-defectuosos-como-un-problema-de-optimizacion-multiobjetivo/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/prediccion-de-modulos-defectuosos-como-un-problema-de-optimizacion-multiobjetivo/</guid>
		<description></description>
		<content><![CDATA[<div class="page" title="Page 1">
<div class="layoutArea">
<div class="column">

La dificultad de aplicar técnicas de análisis de datos al problema de la calidad del software radica principalmente en dos razones: la ausencia de datos generalistas y de herramientas específicas. En este trabajo exponemos los primeros pasos de una iniciativa para paliar estos inconvenientes. Con respecto al primero, hemos trabajado con dos conjuntos de datos públicos que han sido tratados de forma conjunta para poder lograr modelos más generales. Para el segundo propósito se ha aplicado un algoritmo multiobjetivo que mediante reglas cuantitativas establezca cuáles son los íımites empíricos de los atributos que miden la complejidad a partir de los cuales la probabilidad de error aumenta significativamente e incluso la posibilidad de medir ese aumento.

</div>
</div>
</div>]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2606</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[prediccion-de-modulos-defectuosos-como-un-problema-de-optimizacion-multiobjetivo]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="multiobjetivo"><![CDATA[Multiobjetivo]]></category>
		<category domain="post_tag" nicename="prediccion-defectos-software"><![CDATA[Predicción defectos software]]></category>
		<category domain="post_tag" nicename="reglas"><![CDATA[Reglas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La dificultad de aplicar técnicas de análisis de datos al problema de la calidad del software radica principalmente en dos razones: la ausencia de datos generalistas y de herramientas específicas. En este trabajo exponemos los primeros pasos de una iniciativa para paliar estos inconvenientes. Con respecto al primero, hemos trabajado con dos conjuntos de datos públicos que han sido tratados de forma conjunta para poder lograr modelos más generales. Para el segundo propósito se ha aplicado un algoritmo multiobjetivo que mediante reglas cuantitativas establezca cuáles son los íımites empíricos de los atributos que miden la complejidad a partir de los cuales la probabilidad de error aumenta significativamente e incluso la posibilidad de medir ese aumento.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/042]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_74.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_74.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Martínez Ballesteros]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mariamartinez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José C. Riquelme Santos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[riquelme@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Roberto Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[robertoruiz@upo.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Pablo de Olavide]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Daniel Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[daniel.rodriguez@uah.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Alcalá]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia un Algoritmo Exacto para Resolver el Problema de Agrupamiento de Módulos Software</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-un-algoritmo-exacto-para-resolver-el-problema-de-agrupamiento-de-modulos-software/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/hacia-un-algoritmo-exacto-para-resolver-el-problema-de-agrupamiento-de-modulos-software/</guid>
		<description></description>
		<content><![CDATA[El problema de agrupamiento de módulos software consiste en encontrar una partición del conjunto de módulos de un determinado software de tal forma que se maximice la cohesión entre módulos pertenecientes al mismo componente de la partición a la vez que se minimiza el acoplamiento entre módulos pertenecientes a distintos componentes. El objetivo es estructurar el software de una manera que mejore el desarrollo y la mantenibilidad del sistema. Este problema, conocido como emph{Software Module Clustering}, ha sido abordado en el pasado usando principalmente algoritmos heurísticos y metaheurísticas. En este trabajo describimos un algoritmo exacto basado en ramificación y poda.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2607</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-un-algoritmo-exacto-para-resolver-el-problema-de-agrupamiento-de-modulos-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="agrupamiento-de-modulos-software"><![CDATA[Agrupamiento de módulos software]]></category>
		<category domain="post_tag" nicename="algoritmos-exactos"><![CDATA[Algoritmos exactos]]></category>
		<category domain="post_tag" nicename="ramificacion-y-poda"><![CDATA[Ramificación y poda]]></category>
		<category domain="post_tag" nicename="search-based-software-engineering"><![CDATA[Search-Based Software Engineering]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El problema de agrupamiento de módulos software consiste en encontrar una partición del conjunto de módulos de un determinado software de tal forma que se maximice la cohesión entre módulos pertenecientes al mismo componente de la partición a la vez que se minimiza el acoplamiento entre módulos pertenecientes a distintos componentes. El objetivo es estructurar el software de una manera que mejore el desarrollo y la mantenibilidad del sistema. Este problema, conocido como emph{Software Module Clustering}, ha sido abordado en el pasado usando principalmente algoritmos heurísticos y metaheurísticas. En este trabajo describimos un algoritmo exacto basado en ramificación y poda.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/037]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_75.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_75.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel Ángel Domínguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[miguel.angel.dominguez.rios@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francisco Chicano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[chicano@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Enrique Alba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[eat@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Desarrollando una arquitectura de microservicios mediante MDE</title>
		<link>https://biblioteca.sistedes.es/articulo/desarrollando-una-arquitectura-de-microservicios-mediante-mde/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/desarrollando-una-arquitectura-de-microservicios-mediante-mde/</guid>
		<description></description>
		<content><![CDATA[En los últimos años, la industria del software ha apostado por la migración hacia las aplicaciones basadas en servicios y su despliegue en la nube por su promesa de obtener alta disponibilidad y escalabilidad. Tanto las aplicaciones Web como las móviles utilizan partes servidoras basadas en fachadas REST o SOA que en muchas ocasiones crecen tanto a nivel de servicios como de datos lo que complica su mantenibilidad. En este sentido, ha aparecido recientemente un estilo arquitectónico denominado microservicios que propone la división horizontal de la funcionalidad de una aplicación en una colección de servicios que gestionan separadamente su propia lógica y sus datos. Esta división permite explotar la escalabilidad de la nube a nivel de servicio y abordar los cambios más rápidamente. A pesar de sus beneficios, este estilo arquitectónico presenta algunas desventajas como la dificultad de agregar datos de diferentes microservicios y el mantenimiento de la consistencia entre las diferentes orígenes de datos. Para abordar estos dos retos, este trabajo presenta una solución MDE basada en una evolución del modelo de servicios de OOH4RIA. Este modelo permite tanto acelerar la creación de microservicios como facilitar el mantenimiento en la comunicación y la composición de datos de diferentes orígenes.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2608</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[desarrollando-una-arquitectura-de-microservicios-mediante-mde]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="microservices"><![CDATA[microservices]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<category domain="post_tag" nicename="rest"><![CDATA[REST]]></category>
		<category domain="post_tag" nicename="soa"><![CDATA[SOA]]></category>
		<category domain="post_tag" nicename="web-services"><![CDATA[web services]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años, la industria del software ha apostado por la migración hacia las aplicaciones basadas en servicios y su despliegue en la nube por su promesa de obtener alta disponibilidad y escalabilidad. Tanto las aplicaciones Web como las móviles utilizan partes servidoras basadas en fachadas REST o SOA que en muchas ocasiones crecen tanto a nivel de servicios como de datos lo que complica su mantenibilidad. En este sentido, ha aparecido recientemente un estilo arquitectónico denominado microservicios que propone la división horizontal de la funcionalidad de una aplicación en una colección de servicios que gestionan separadamente su propia lógica y sus datos. Esta división permite explotar la escalabilidad de la nube a nivel de servicio y abordar los cambios más rápidamente. A pesar de sus beneficios, este estilo arquitectónico presenta algunas desventajas como la dificultad de agregar datos de diferentes microservicios y el mantenimiento de la consistencia entre las diferentes orígenes de datos. Para abordar estos dos retos, este trabajo presenta una solución MDE basada en una evolución del modelo de servicios de OOH4RIA. Este modelo permite tanto acelerar la creación de microservicios como facilitar el mantenimiento en la comunicación y la composición de datos de diferentes orígenes.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/061]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_76.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_76.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Santiago Meliá]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[santi@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jesús M. Hermida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jesus.hermida@ec.europa.eu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[European Commission Joint Research Centre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Cristina Cachero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ccachero@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jaume Aragonés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jaume@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SmartPoliTech: un experimento en inmótica social</title>
		<link>https://biblioteca.sistedes.es/articulo/smartpolitech-un-experimento-en-inmotica-social/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/smartpolitech-un-experimento-en-inmotica-social/</guid>
		<description></description>
		<content><![CDATA[La optimización energética en edificios públicos terciarios en España es un reto insoslayable. La realidad actual de despilfarro energético, falta de confort, infrautilización de los espacios o deficiente disposición de los mismos respecto a los usos sobre los que fueron proyectados, es un hecho que repercute directamente en la eficiencia de las actividades realizadas en ellos, así como en las emisiones de $CO_{2}$ que se generan actualmente y que suponen una seria amenaza para la sostenibilidad de estos edificios. La inmótica, como disciplina que apunta a la automatización de los procesos y actividades que se generan en el edificio, surge como elemento capaz de proporcionar soluciones a este grave problema de optimización energética. En este artículo se describen las generalidades del proyecto SmartPolitech, una iniciativa experimental de bajo coste que utiliza la inmótica como medio para abordar una problemática generalizada de ineficiencia energética en la inmensa mayoría de edificios públicos españoles.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2609</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[smartpolitech-un-experimento-en-inmotica-social]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="inmotica"><![CDATA[Inmótica]]></category>
		<category domain="post_tag" nicename="internet-de-las-cosas"><![CDATA[Internet de las Cosas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La optimización energética en edificios públicos terciarios en España es un reto insoslayable. La realidad actual de despilfarro energético, falta de confort, infrautilización de los espacios o deficiente disposición de los mismos respecto a los usos sobre los que fueron proyectados, es un hecho que repercute directamente en la eficiencia de las actividades realizadas en ellos, así como en las emisiones de $CO_{2}$ que se generan actualmente y que suponen una seria amenaza para la sostenibilidad de estos edificios. La inmótica, como disciplina que apunta a la automatización de los procesos y actividades que se generan en el edificio, surge como elemento capaz de proporcionar soluciones a este grave problema de optimización energética. En este artículo se describen las generalidades del proyecto SmartPolitech, una iniciativa experimental de bajo coste que utiliza la inmótica como medio para abordar una problemática generalizada de ineficiencia energética en la inmensa mayoría de edificios públicos españoles.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/021]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_79.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_79.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Agustín Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[agustin.robolab@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Barrena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[barrena@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pablo García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pablogr@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Beatriz Montalbán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[bmpozas@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Pablo Bustos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[pbustos@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Visual CPS: Sistemas Ciber-Físicos en la Nube con Soporte a la Variabilidad y Multitenencia</title>
		<link>https://biblioteca.sistedes.es/articulo/visual-cps-sistemas-ciber-fisicos-en-la-nube-con-soporte-a-la-variabilidad-y-multitenencia/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/visual-cps-sistemas-ciber-fisicos-en-la-nube-con-soporte-a-la-variabilidad-y-multitenencia/</guid>
		<description></description>
		<content><![CDATA[En los últimos años, nuestra sociedad está cambiando a gran velocidad. Cada vez son más los dispositivos que interactúan con nosotros y el entorno para ofrecernos servicios ampliados respecto a los servicios de información tradicionales. Esta nueva era de Internet de las Cosas (Internet of Things - IoT) y de servicios al ciudadano a través de internet, con la nueva concepción de los sistemas inteligentes (smart buildings, grids, cities y spaces), necesitan cada vez de más recursos computacionales y software. En este sentido, Cloud Computing ofrece una serie de características en cuanto escalabilidad y flexibilidad, acceso a recursos a través de Internet (off-premises) sin necesidad de ser instalados y gestionados localmente (on-premises) [1] que son fundamentales para soportar tales sistemas. Los servicios proporcionados por la nube son infraestructura (IaaS), plataforma de desarrollo (PaaS) y software (SaaS). Una de las características más significativas de SaaS (Software as a Service) es la multitenencia, la cual promueve las economías de escala mediante la compartición de una serie de recursos entre múltiples usuarios o grupos de usuarios denominados tenants. Cada tenant podría personalizar ciertas partes del software para satisfacer requisitos individuales. Este concepto no es nuevo, y ha sido abordado ampliamente por la ingeniería de líneas de producto [8] y la gestión de la variabilidad. La variabilidad de un producto software se puede definir como la capacidad de este para cambiar y ser utilizado en múltiples contextos. Resulta de gran importancia el dotar al software de mecanismos para soportar distintos grados de variabilidad para poder ofrecer una personalización ajustada a las necesidades específicas de los usuarios. En este artículo se presenta una herramienta para la creación y gestión de sistemas ciber-físicos en la nube con soporte a múltiples tenants y variabilidad entre los tenants llamada Visual CPS. Un sistema ciber-físico es aquel sistema en el que se embebe o integra capacidad de cómputo con el objetivo de interactuar el software con el mundo físico, obteniendo una comunicación bidireccional entre estos dos. Para soportar dichas características la herramienta se basa en el concepto de multitenencia de la plataforma de nube GPaaS [7] y en el diseño arquitectónico basado en el estilo de microservicios [2] que se define como una aplicación compuesta por componentes independientes, ligeros y muy especializados orquestados para proporcionar la funcionalidad de la aplicación global.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2610</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[visual-cps-sistemas-ciber-fisicos-en-la-nube-con-soporte-a-la-variabilidad-y-multitenencia]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="ciber-physical-system"><![CDATA[Ciber physical system]]></category>
		<category domain="post_tag" nicename="cloud-computing"><![CDATA[Cloud Computing]]></category>
		<category domain="post_tag" nicename="microservices"><![CDATA[microservices]]></category>
		<category domain="post_tag" nicename="multitenancy"><![CDATA[Multitenancy]]></category>
		<category domain="post_tag" nicename="variability"><![CDATA[Variability]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años, nuestra sociedad está cambiando a gran velocidad. Cada vez son más los dispositivos que interactúan con nosotros y el entorno para ofrecernos servicios ampliados respecto a los servicios de información tradicionales. Esta nueva era de Internet de las Cosas (Internet of Things - IoT) y de servicios al ciudadano a través de internet, con la nueva concepción de los sistemas inteligentes (smart buildings, grids, cities y spaces), necesitan cada vez de más recursos computacionales y software. En este sentido, Cloud Computing ofrece una serie de características en cuanto escalabilidad y flexibilidad, acceso a recursos a través de Internet (off-premises) sin necesidad de ser instalados y gestionados localmente (on-premises) [1] que son fundamentales para soportar tales sistemas. Los servicios proporcionados por la nube son infraestructura (IaaS), plataforma de desarrollo (PaaS) y software (SaaS).    Una de las características más significativas de SaaS (Software as a Service) es la multitenencia, la cual promueve las economías de escala mediante la compartición de una serie de recursos entre múltiples usuarios o grupos de usuarios denominados tenants. Cada tenant podría personalizar ciertas partes del software para satisfacer requisitos individuales. Este concepto no es nuevo, y ha sido abordado ampliamente por la ingeniería de líneas de producto [8] y la gestión de la variabilidad. La variabilidad de un producto software se puede definir como la capacidad de este para cambiar y ser utilizado en múltiples contextos. Resulta de gran importancia el dotar al software de mecanismos para soportar distintos grados de variabilidad para poder ofrecer una personalización ajustada a las necesidades específicas de los usuarios.  En este artículo se presenta una herramienta para la creación y gestión de sistemas ciber-físicos en la nube con soporte a múltiples tenants y variabilidad entre los tenants llamada Visual CPS. Un sistema ciber-físico es aquel sistema en el que se embebe o integra capacidad de cómputo con el objetivo de interactuar el software con el mundo físico, obteniendo una comunicación bidireccional entre estos dos. Para soportar dichas características la herramienta se basa en el concepto de multitenencia de la plataforma de nube GPaaS [7] y en el diseño arquitectónico basado en  el estilo de microservicios [2] que se define como una aplicación compuesta por componentes independientes, ligeros y muy especializados orquestados para proporcionar la funcionalidad de la aplicación global.  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/009]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_80.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_80.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Héctor Humanes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[h.humanes@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[SYST Research Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jessica Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[yesica.diaz@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[SYST Research Group ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Carlos Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[carlos.fernandez@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[SYST Research Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Agustín Yagüe]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[agustin.yague@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[SYST Research Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Mapas de navegación para la automatización de pruebas de aceptación en aplicaciones móviles</title>
		<link>https://biblioteca.sistedes.es/articulo/mapas-de-navegacion-para-la-automatizacion-de-pruebas-de-aceptacion-en-aplicaciones-moviles/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/mapas-de-navegacion-para-la-automatizacion-de-pruebas-de-aceptacion-en-aplicaciones-moviles/</guid>
		<description></description>
		<content><![CDATA[Para que el proceso de pruebas del software resulte eficaz es habitual que tanto la parte proveedora como la parte aceptante colaboren. Esto es especialmente cierto en el nivel de las pruebas de aceptación, donde la responsabilidad principal recae en la parte aceptante. Aunque se ha avanzado mucho en herramientas que facilitan de forma automática la generación de casos de prueba y la ejecución de los mismos, estas están normalmente pensadas para desarrolladores con avanzados conocimientos en programación. Este trabajo presenta un componente, denominado Graph2Test, que pretende facilitar la comunicación entre la parte aceptante y la parte desarrolladora en base a la representación mediante un diagrama de estados de los mapas de navegación de la aplicación objeto de las pruebas. A partir de este mapa de navegación se generan casos de prueba en texto plano (lenguaje Gherkin), que posteriormente se transforman en scripts de prueba utilizando la tecnología Cucumber. El componente está especializado en la prueba de aplicaciones móviles Android y autocompleta parcialmente estos scripts de prueba con instrucciones del entorno de automatización Espresso.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2611</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mapas-de-navegacion-para-la-automatizacion-de-pruebas-de-aceptacion-en-aplicaciones-moviles]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="android"><![CDATA[Android]]></category>
		<category domain="post_tag" nicename="automatizacion-de-pruebas"><![CDATA[Automatización de pruebas]]></category>
		<category domain="post_tag" nicename="cucumber"><![CDATA[Cucumber]]></category>
		<category domain="post_tag" nicename="espresso"><![CDATA[Espresso]]></category>
		<category domain="post_tag" nicename="pruebas-de-aceptacion"><![CDATA[Pruebas de aceptación]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Para que el proceso de pruebas del software resulte eficaz es habitual que tanto la parte proveedora como la parte aceptante colaboren. Esto es especialmente cierto en el nivel de las pruebas de aceptación, donde la responsabilidad principal recae en la parte aceptante. Aunque se ha avanzado mucho en herramientas que facilitan de forma automática la generación de casos de prueba y la ejecución de los mismos, estas están normalmente pensadas para desarrolladores con avanzados conocimientos en programación. Este trabajo presenta un componente, denominado Graph2Test, que pretende facilitar la comunicación entre la parte aceptante y la parte desarrolladora en base a la representación mediante un diagrama de estados de los mapas de navegación de la aplicación objeto de las pruebas. A partir de este mapa de navegación se generan casos de prueba en texto plano (lenguaje Gherkin), que posteriormente se transforman en scripts de prueba utilizando la tecnología Cucumber. El componente está especializado en la prueba de aplicaciones móviles Android y autocompleta parcialmente estos scripts de prueba con instrucciones del entorno de automatización Espresso.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/072]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_81.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_81.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ginger Janet Valencia-Vásconez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[neyitagin@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miguel Ángel Latre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[latre@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco Javier López-Pellicer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fjlopez@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Javier Nogueras-Iso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jnog@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación, almacenamiento y consulta de datos espaciales masivos</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-almacenamiento-y-consulta-de-datos-espaciales-masivos/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/generacion-almacenamiento-y-consulta-de-datos-espaciales-masivos/</guid>
		<description></description>
		<content><![CDATA[En este artículo presentamos resultados preliminares para dos problemas que surgen en el ámbito del almacenamiento, consulta y visualización de conjuntos masivos de objetos móviles: una herramienta para la generación de conjuntos de datos masivos de objetos móviles en una red de carreteras y su posterior almacenamiento en diferentes sistemas de almacenamiento, y una serie de experimentos de visualización de 40 millones de datos geolocalizados en los que enfrentamos una solución tradicional con una alternativa Big Data actual.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2612</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-almacenamiento-y-consulta-de-datos-espaciales-masivos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="big-data-geografico"><![CDATA[big data geográfico]]></category>
		<category domain="post_tag" nicename="generacion-de-datos"><![CDATA[generación de datos]]></category>
		<category domain="post_tag" nicename="sistemas-de-informacion-geografica"><![CDATA[Sistemas de Informacíon Geográfica]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este artículo presentamos resultados preliminares para dos problemas que surgen en el ámbito del almacenamiento, consulta y visualización de conjuntos masivos de objetos móviles: una herramienta para la generación de conjuntos de datos masivos de objetos móviles en una red de carreteras y su posterior almacenamiento en diferentes sistemas de almacenamiento, y una serie de experimentos de visualización de 40 millones de datos geolocalizados en los que enfrentamos una solución tradicional con una alternativa Big Data actual.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/016]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_82.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_82.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alejandro Cortiñas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alejandro.cortinas@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miguel R. Luaces]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[luaces@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of A Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Ecological Debt: outlining a measure to evaluate software greenability</title>
		<link>https://biblioteca.sistedes.es/articulo/ecological-debt-outlining-a-measure-to-evaluate-software-greenability/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/ecological-debt-outlining-a-measure-to-evaluate-software-greenability/</guid>
		<description></description>
		<content><![CDATA[Developing low quality software (with design flaws, poor quality code, etc) lead to a product with an inner cost that could be measured by using technical debt, that could be consider as the economical effort to solve all the existing design problems of a given software. As time goes on, software quality is acquiring new dimensions, and one of the most important one in the recent years (required by our society) is Software Sustainability, that could be understood as the degree of environmental-friendliness of a soft-ware system. So, following the idea of technical debt, we propose the concept of Ecological Debt which purpose is to measure the economical effort to develop a sustainable software following the Green-in principles.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2613</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[ecological-debt-outlining-a-measure-to-evaluate-software-greenability]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="ecological-debt"><![CDATA[ecological debt]]></category>
		<category domain="post_tag" nicename="greenability"><![CDATA[greenability]]></category>
		<category domain="post_tag" nicename="software-sustainability"><![CDATA[software sustainability]]></category>
		<category domain="post_tag" nicename="technical-debt"><![CDATA[technical debt]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Developing low quality software (with design flaws, poor quality code, etc) lead to a product with an inner cost that could be measured by using technical debt, that could be consider as the economical effort to solve all the existing design problems of a given software. As time goes on, software quality is acquiring new dimensions, and one of the most important one in the recent years (required by our society) is Software Sustainability, that could be understood as the degree of environmental-friendliness of a soft-ware system. So, following the idea of technical debt, we propose the concept of Ecological Debt which purpose is to measure the economical effort to develop a sustainable software following the Green-in principles.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/054]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_83.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_83.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ignacio García-Rodríguez de Guzmán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ignacio.rodriguez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universida de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Felix Oscar García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[felix.garcia@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[María Ángeles Moraga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mariangeles.moraga@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mario.piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SemHabitApp: Diseño de un Entorno de Observación Biológica para Pacientes Pediátricos Basado en Interacción Tangible y Repositorios Semánticos</title>
		<link>https://biblioteca.sistedes.es/articulo/semhabitapp-diseno-de-un-entorno-de-observacion-biologica-para-pacientes-pediatricos-basado-en-interaccion-tangible-y-repositorios-semanticos/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/semhabitapp-diseno-de-un-entorno-de-observacion-biologica-para-pacientes-pediatricos-basado-en-interaccion-tangible-y-repositorios-semanticos/</guid>
		<description></description>
		<content><![CDATA[Los pacientes pediátricos están sometidos a altas cargas de estrés emocional que repercuten en su bienestar psicológico y social. Estudios previos muestran la efectividad de mezclar terapias tecnológicas de observación de especies animales, aun no contando con la presencia física de éstas en el hospital. En este trabajo se presenta una herramienta de observación de ecosistemas biológicos y un meca-nismo de consultas basado en elementos tangibles que permita a usuarios en edad infantil hospitalizados realizar tareas de exploración biológica de forma autónoma. El mecanismo de consulta desarrollado está basado en definiciones ontológicas utilizando el lenguaje de modelado OWL y en el uso de razonadores semánticos que permiten la inferencia de información no explícita. Por otro lado, el uso de elementos de interacción tangible y de lenguajes icónicos pretende reducir el es-fuerzo cognitivo requerido a usuarios en edad infantil durante el proceso de defi-nición de consultas sobre los repositorios semánticos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2614</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[semhabitapp-diseno-de-un-entorno-de-observacion-biologica-para-pacientes-pediatricos-basado-en-interaccion-tangible-y-repositorios-semanticos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="bases-de-datos-ontologicas"><![CDATA[Bases de datos ontológicas]]></category>
		<category domain="post_tag" nicename="hospitalizacion"><![CDATA[Hospitalización]]></category>
		<category domain="post_tag" nicename="interfaces-tangibles-de-usuario-tui"><![CDATA[Interfaces Tangibles de Usuario (TUI)]]></category>
		<category domain="post_tag" nicename="marcadores-fiduciales"><![CDATA[Marcadores fiduciales]]></category>
		<category domain="post_tag" nicename="owl"><![CDATA[OWL]]></category>
		<category domain="post_tag" nicename="rfid"><![CDATA[RFID]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los pacientes pediátricos están sometidos a altas cargas de estrés emocional que repercuten en su bienestar psicológico y social. Estudios previos muestran la efectividad de mezclar terapias tecnológicas de observación de especies animales, aun no contando con la presencia física de éstas en el hospital. En este trabajo se presenta una herramienta de observación de ecosistemas biológicos y un meca-nismo de consultas basado en elementos tangibles que permita a usuarios en edad infantil hospitalizados realizar tareas de exploración biológica de forma autónoma. El mecanismo de consulta desarrollado está basado en definiciones ontológicas utilizando el lenguaje de modelado OWL y en el uso de razonadores semánticos que permiten la inferencia de información no explícita. Por otro lado, el uso de elementos de interacción tangible y de lenguajes icónicos pretende reducir el es-fuerzo cognitivo requerido a usuarios en edad infantil durante el proceso de defi-nición de consultas sobre los repositorios semánticos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/065]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_84.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_84.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana Seguí]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ansegil@upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando Garcia-Sanjuan]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fegarcia@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Jaen]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fjaen@upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>FABIOLA: Arquitectura para la Optimización de Problemas en entornos de Big Data</title>
		<link>https://biblioteca.sistedes.es/articulo/fabiola-arquitectura-para-la-optimizacion-de-problemas-en-entornos-de-big-data/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/fabiola-arquitectura-para-la-optimizacion-de-problemas-en-entornos-de-big-data/</guid>
		<description></description>
		<content><![CDATA[Dentro de las organizaciones, los problemas de optimización pueden encontrarse en numerosos ejemplos, tales como minimizar los costes de producción, los errores producidos, o maximizar la fidelidad de los clientes. La resolución de estos problemas es un reto que conlleva un esfuerzo extra. Hoy en día, los problemas de Big Data se suman a estos problems de optimización en dichas empresas. Desafortunadamente, afrontar estos problemas en la pequeña y mediana empresa es extremadamente difícil o incluso imposible. En este artículo, proponemos la arquitectura llamada Fabiola, que permite describir los datos distribuidos y estructurados en problemas de optimización que pueden ser paralelizados. Además, Fabiola aplica las técnicas de Programación con Restricciones para poder devolver la solución a dichos problemas de optimización.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2615</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[fabiola-arquitectura-para-la-optimizacion-de-problemas-en-entornos-de-big-data]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="estructura-de-datos"><![CDATA[Estructura de Datos]]></category>
		<category domain="post_tag" nicename="problemas-de-optimizacion"><![CDATA[Problemas de Optimización]]></category>
		<category domain="post_tag" nicename="programacion-con-restricciones"><![CDATA[Programación con Restricciones]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Dentro de las organizaciones, los problemas de optimización pueden encontrarse en numerosos ejemplos, tales como minimizar los costes de producción, los errores producidos, o maximizar la fidelidad de los clientes. La resolución de estos problemas es un reto que conlleva un esfuerzo extra. Hoy en día, los problemas de Big Data se suman a estos problems de optimización en dichas empresas. Desafortunadamente, afrontar estos problemas en la pequeña y mediana empresa es extremadamente difícil o incluso imposible. En este artículo, proponemos la arquitectura llamada Fabiola, que permite describir los datos distribuidos y estructurados en problemas de optimización que pueden ser paralelizados. Además, Fabiola aplica las técnicas de Programación con Restricciones para poder devolver la solución a dichos problemas de optimización.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/014]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_85.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_85.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Luisa Parody]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[lparody@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Angel Jesus Varela Vaca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ajvarela@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Rafael M. Gasca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gasca@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems,  University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Framework for modelling and implementing secure NoSQL document databases</title>
		<link>https://biblioteca.sistedes.es/articulo/framework-for-modelling-and-implementing-secure-nosql-document-databases/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/framework-for-modelling-and-implementing-secure-nosql-document-databases/</guid>
		<description></description>
		<content><![CDATA[The great amount of data managed by Big Data technologies have to be correctly assured in order to protect critical enterprise and personal information. Nevertheless, current security solutions for Big Data technologies such as NoSQL databases do not take into account the special characteristics of these technologies. In this paper, we focus on assuring NoSQL document databases proposing a framework composed of three stages: (1) the source data set is analysed by using Natural Language Processing techniques and ontological resources in order to detect sensitive data. (2) we define a metamodel for document NoSQL databases that allows designer to specify both structural and security aspects. (3) this model is implemented into a specific document database tool, MongoDB. Finally, we apply the framework proposed to a case study with a dataset of medical domain.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2616</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[framework-for-modelling-and-implementing-secure-nosql-document-databases]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="model"><![CDATA[model]]></category>
		<category domain="post_tag" nicename="natural-language-processing"><![CDATA[Natural Language Processing]]></category>
		<category domain="post_tag" nicename="no-sql"><![CDATA[No SQL]]></category>
		<category domain="post_tag" nicename="security"><![CDATA[security]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The great amount of data managed by Big Data technologies have to be correctly assured in order to protect critical enterprise and personal information. Nevertheless, current security solutions for Big Data technologies such as NoSQL databases do not take into account the special characteristics of these technologies.  In this paper, we focus on assuring NoSQL document databases proposing a framework composed of three stages: (1) the source data set is analysed by using Natural Language Processing techniques and ontological resources in order to detect sensitive data. (2) we define a metamodel for document NoSQL databases that allows designer to specify both structural and security aspects. (3) this model is implemented into a specific document database tool, MongoDB. Finally, we apply the framework proposed to a case study with a dataset of medical domain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/015]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_87.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_87.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Blanco Bueno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carlos.blanco@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jesus Peral]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jperal@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Trujillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jtrujillo@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Eduardo Fernandez-Medina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[eduardo.fdezmedina@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[ALARCOS Research Group. UCLM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Ingeniería inversa basada en modelos de código PL/SQL en aplicaciones Oracle Forms</title>
		<link>https://biblioteca.sistedes.es/articulo/ingenieria-inversa-basada-en-modelos-de-codigo-plsql-en-aplicaciones-oracle-forms/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/ingenieria-inversa-basada-en-modelos-de-codigo-plsql-en-aplicaciones-oracle-forms/</guid>
		<description></description>
		<content><![CDATA[El alto coste de mantenimiento de las aplicaciones legacy promueve en las empresas iniciativas de modernización a nuevas plataformas y tecnologías. La modernización de software, en especial la ingeniería inversa, es uno de los escenarios de aplicación de las técnicas de la In- geniería del Software Dirigida por Modelos (MDE), con el fin de automatizar las tareas manuales y reducir costes. En este trabajo se presenta una solución MDE para la extracción de modelos del código PL/SQL de aplicaciones Oracle Forms. En concreto, se ha implementado un enfoque propuesto en un trabajo previo del grupo Modelum dentro de una colaboración con la empresa Open Canarias en el marco de un proyecto CDTI destinado a la automatización de aplicaciones Oracle Forms a Java. Los principales retos que se han debido afrontar han sido el uso extensivo del metamodelo KDM, la implementación de transformaciones modelo a modelo complicadas y la validación de estas transformaciones que gen- eran modelos grandes y complejos. A lo largo del trabajo se discutirá sobre estas cuestiones.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2617</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[ingenieria-inversa-basada-en-modelos-de-codigo-plsql-en-aplicaciones-oracle-forms]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software-dirigida-por-modelos"><![CDATA[Ingeniería del Software Dirigida por Modelos]]></category>
		<category domain="post_tag" nicename="ingenieria-inversa"><![CDATA[Ingeniería Inversa]]></category>
		<category domain="post_tag" nicename="kdm"><![CDATA[KDM]]></category>
		<category domain="post_tag" nicename="modernizacion-de-software"><![CDATA[Modernizacion de software]]></category>
		<category domain="post_tag" nicename="oracle-forms"><![CDATA[Oracle Forms]]></category>
		<category domain="post_tag" nicename="plsql"><![CDATA[PL/SQL]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El alto coste de mantenimiento de las aplicaciones legacy promueve en las empresas iniciativas de modernización a nuevas plataformas y tecnologías. La modernización de software, en especial la ingeniería inversa, es uno de los escenarios de aplicación de las técnicas de la In- geniería del Software Dirigida por Modelos (MDE), con el fin de automatizar las tareas manuales y reducir costes. En este trabajo se presenta una solución MDE para la extracción de modelos del código PL/SQL de aplicaciones Oracle Forms. En concreto, se ha implementado un enfoque propuesto en un trabajo previo del grupo Modelum dentro de  una colaboración con la empresa Open Canarias en el marco de un proyecto CDTI destinado a la automatización de aplicaciones Oracle Forms a Java. Los principales retos que se han debido afrontar han sido el uso extensivo del metamodelo KDM, la implementación de transformaciones modelo a modelo complicadas y la validación de estas transformaciones que gen- eran modelos grandes y complejos. A lo largo del trabajo se discutirá sobre estas cuestiones.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/029]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_89.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_89.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Javier Fernández Candel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carlosjavier.fernandez1@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francisco Javier Bermúdez Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fjavier@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesus Garcia-Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jmolina@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jose Ramon Hoyos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jose.hoyos@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Diego Sevilla Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[dsevilla@ditec.um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Benito J. Cuesta Viera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[bcuesta@opencanarias.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Open Canarias S.L.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Adaptación Dinámica de Calidades de Servicio en Middleware DDS: Un Enfoque Dirigido por Modelos</title>
		<link>https://biblioteca.sistedes.es/articulo/adaptacion-dinamica-de-calidades-de-servicio-en-middleware-dds-un-enfoque-dirigido-por-modelos/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/adaptacion-dinamica-de-calidades-de-servicio-en-middleware-dds-un-enfoque-dirigido-por-modelos/</guid>
		<description></description>
		<content><![CDATA[Los sistemas distribuidos, en particular los utilizados en aplicaciones críticas, deben garantizar determinados requisitos de seguridad y rendimiento en tiempo de ejecución. En este sentido, los middleware basados en el estándar DDS permiten el desarrollo de aplicaciones distribuidas en las que es posible configurar una amplia variedad de parámetros relacionados con la calidad de servicio (QoS). Sin embargo, la configuración de estos parámetros en aplica-ciones cuyo contexto de ejecución es altamente dinámico e impredecible supone un gran reto, ya que los recursos disponibles y la carga de trabajo de estos sistemas pueden fluctuar sensiblemente a lo largo de la ejecución. En este artículo proponemos un enfoque dirigido por modelos para la adaptación automática, segura, transparente y en tiempo de ejecución de los atributos de QoS en middleware basado en DDS, que permite optimizar el rendimiento del sistema en función de los recursos disponibles en cada momento.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2618</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[adaptacion-dinamica-de-calidades-de-servicio-en-middleware-dds-un-enfoque-dirigido-por-modelos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="calidad-de-servicio"><![CDATA[Calidad de Servicio]]></category>
		<category domain="post_tag" nicename="dds"><![CDATA[DDS]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="middleware"><![CDATA[Middleware]]></category>
		<category domain="post_tag" nicename="software-adaptativo"><![CDATA[Software Adaptativo]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los sistemas distribuidos, en particular los utilizados en aplicaciones críticas, deben garantizar determinados requisitos de seguridad y rendimiento en tiempo de ejecución. En este sentido, los middleware basados en el estándar DDS permiten el desarrollo de aplicaciones distribuidas en las que es posible configurar una amplia variedad de parámetros relacionados con la calidad de servicio (QoS). Sin embargo, la configuración de estos parámetros en aplica-ciones cuyo contexto de ejecución es altamente dinámico e impredecible supone un gran reto, ya que los recursos disponibles y la carga de trabajo de estos sistemas pueden fluctuar sensiblemente a lo largo de la ejecución. En este artículo proponemos un enfoque dirigido por modelos para la adaptación automática, segura, transparente y en tiempo de ejecución de los atributos de QoS en middleware basado en DDS, que permite optimizar el rendimiento del sistema en función de los recursos disponibles en cada momento.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/001]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_91.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_91.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan F. Ingles-Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[juanfran.ingles@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Cartagena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Adrián Romero-Garcés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[adrigtl@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Cristina Vicente-Chicote]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[cristinav@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jesús Martínez Cruz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jmcruz@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Integrating risk management in IT settings from ISO standards and management systems perspectives</title>
		<link>https://biblioteca.sistedes.es/articulo/integrating-risk-management-in-it-settings-from-iso-standards-and-management-systems-perspectives/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/integrating-risk-management-in-it-settings-from-iso-standards-and-management-systems-perspectives/</guid>
		<description></description>
		<content><![CDATA[Este artículo analiza las actividades de gestión de riesgos recogidas en varios estándares ISO para así proporcionar una base para mejorar, coordinar e interoperar las actividades de gestión de riesgos en entornos de TI. Tomando como base el estándar internacional ISO 31000 para la gestión de riesgos, se realiza un análisis comparativo de las siguientes normas con el objetivo de identificar las actividades relacionadas con la gestión de riesgos: ISO high level structure for management system standards, ISO 9001 Requisitos de un sistema de gestión de la calidad, ISO 21500 Guía para la gestión de proyectos, ISO/IEC 20000-1 Requisitos de un sistema de gestión de servicios de TI e ISO/IEC 27001 Sistema de gestión de la seguridad de la información de TI. Estas normas facilitan la integración de todas las actividades basadas en procesos, así como la implementación de mecanismos para alinear a todas las entidades de la organización, con el objetivo de hacer frente a los desafíos relacionados con la gestión de riesgos. Se presentan diferentes perspectivas de integración como pueden ser la comprensión de la organización y su contexto, el pensamiento basado en el riesgo, el liderazgo y el compromiso, el enfoque basado en procesos y la estructura PDCA. Indicios de calidad: Publicación: Computer Standards &amp; Interfaces Q2 (35/106) COMPUTER SCIENCE, SOFTWARE ENGINEERING Fecha de publicación: Available online 30 November 2016 DOI: http://dx.doi.org/10.1016/j.csi.2016.11.010]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2619</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[integrating-risk-management-in-it-settings-from-iso-standards-and-management-systems-perspectives]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="entornos-de-ti"><![CDATA[Entornos de TI]]></category>
		<category domain="post_tag" nicename="estandares-iso"><![CDATA[Estándares ISO]]></category>
		<category domain="post_tag" nicename="gestion-integrada-de-riesgos"><![CDATA[Gestión integrada de riesgos]]></category>
		<category domain="post_tag" nicename="sistema-de-gestion-integrado"><![CDATA[Sistema de gestión integrado]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo analiza las actividades de gestión de riesgos recogidas en varios estándares ISO para así proporcionar una base para mejorar, coordinar e interoperar las actividades de gestión de riesgos en entornos de TI. Tomando como base el estándar internacional ISO 31000 para la gestión de riesgos, se realiza un análisis comparativo de las siguientes normas con el objetivo de identificar las actividades relacionadas con la gestión de riesgos: ISO high level structure for management system standards, ISO 9001 Requisitos de un sistema de gestión de la calidad, ISO 21500 Guía para la gestión de proyectos, ISO/IEC 20000-1 Requisitos de un sistema de gestión de servicios de TI e ISO/IEC 27001 Sistema de gestión de la seguridad de la información de TI. Estas normas facilitan la integración de todas las actividades basadas en procesos, así como la implementación de mecanismos para alinear a todas las entidades de la organización, con el objetivo de hacer frente a los desafíos relacionados con la gestión de riesgos. Se presentan diferentes perspectivas de integración como pueden ser la comprensión de la organización y su contexto, el pensamiento basado en el riesgo, el liderazgo y el compromiso, el enfoque basado en procesos y la estructura PDCA.   Indicios de calidad:  Publicación: Computer Standards & Interfaces  Q2 (35/106) COMPUTER SCIENCE, SOFTWARE ENGINEERING  Fecha de publicación: Available online 30 November 2016 DOI: http://dx.doi.org/10.1016/j.csi.2016.11.010]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/056]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_94.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_94.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Beátrix Barafort]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[beatrix.barafort@list.lu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Luxembourg Institute of Science and Technology]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antoni Lluís Mesquida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[antoni.mesquida@uib.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat de les Illes Balears]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonia Mas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[antonia.mas@uib.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat de les Illes Balears]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Docencia sobre Desarrollo de Software dirigido por Modelos en títulos de Grado: fortalezas y debilidades</title>
		<link>https://biblioteca.sistedes.es/articulo/docencia-sobre-desarrollo-de-software-dirigido-por-modelos-en-titulos-de-grado-fortalezas-y-debilidades/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/docencia-sobre-desarrollo-de-software-dirigido-por-modelos-en-titulos-de-grado-fortalezas-y-debilidades/</guid>
		<description></description>
		<content><![CDATA[El Desarrollo de Software Dirigido por Modelos (DSDM) es un área de la Ingeniería del software prometedora, la cual permite el desarrollo de software a partir de artefactos conocidos como modelos, los cuales se definen a partir de los conceptos y relaciones de cada dominio. Posteriormente, y mediante transformaciones bien a otros modelos o bien a texto, es capaz de manejar la complejidad de las actuales tecnologías de desarrollo de software (frameworks, patrones de diseño, versiones de una misma tecnología, integración de múltiples tecnologías, etc.). La inclusión de contenidos sobre DSDM en los títulos de Grado y Máster de Ingeniería Informática es en la actualidad una asignatura pendiente en muchas de estas titulaciones. Probablemente la novedad de la materia y la complejidad de diseñar los nuevos títulos dejo a esta disciplina fuera de los mismos. No obstante, existen algunas universidades donde se han incorporado estos conocimientos y habilidades en Grados (por ejemplo, UPV, UCA o UEx), Másteres (por ejemplo, UMA, UPC, UOC, UAM, U. de Murcia, U. de Oviedo o U. de Almera entre otras). Así, durante el diseño del título de Grado en Ingeniería Informática en Ingeniería del Software de la Universidad de Extremadaura se incluyó una asignatura denominada Diseñoo y Modelado de Sistemas Software (DMSS) que aborda los conceptos esenciales sobre DSDM. En este trabajo se comparte la experiencia docente en esta asignatura durante los ultimos años, justificando la inclusión de los contenidos de DSDM y revisando tanto los aspectos positivos como las principales debilidades.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2620</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[docencia-sobre-desarrollo-de-software-dirigido-por-modelos-en-titulos-de-grado-fortalezas-y-debilidades]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="desarrollo-de-software-dirigido-por-modelos"><![CDATA[Desarrollo de Software Dirigido por Modelos]]></category>
		<category domain="post_tag" nicename="docencia"><![CDATA[Docencia]]></category>
		<category domain="post_tag" nicename="titulos-de-ingenieria-informatica"><![CDATA[Títulos de ingeniería informática]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El Desarrollo de Software Dirigido por Modelos (DSDM) es un área de la Ingeniería del software prometedora, la cual permite el desarrollo de software a partir de artefactos conocidos como modelos, los cuales se definen a partir de los conceptos y relaciones de cada dominio. Posteriormente, y mediante transformaciones bien a otros modelos o bien a texto, es capaz de manejar la complejidad de las actuales tecnologías de desarrollo de software (frameworks, patrones de diseño, versiones de una misma tecnología, integración de múltiples tecnologías, etc.). La inclusión de contenidos sobre DSDM en los títulos de Grado y Máster de Ingeniería Informática es en la actualidad una asignatura pendiente en muchas de estas titulaciones. Probablemente la novedad de la materia y la complejidad de diseñar los nuevos títulos dejo a esta disciplina fuera de los mismos. No obstante, existen algunas universidades donde se han incorporado estos conocimientos y habilidades en Grados (por ejemplo, UPV, UCA o UEx), Másteres (por ejemplo, UMA, UPC, UOC, UAM, U. de Murcia, U. de Oviedo o U. de Almera entre otras). Así, durante el diseño del título de Grado en Ingeniería Informática en Ingeniería del Software de la Universidad de Extremadaura se incluyó una asignatura denominada Diseñoo y Modelado de Sistemas Software (DMSS) que aborda los conceptos esenciales sobre DSDM. En este trabajo se comparte la experiencia docente en esta asignatura durante los ultimos años, justificando la inclusión de los contenidos de DSDM y revisando tanto los aspectos positivos como las principales debilidades.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/027]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_95.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_95.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro J. Clemente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pjclemente@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Effect of Domain Knowledge on Elicitation Effectiveness: An Internally Replicated Controlled Experiment</title>
		<link>https://biblioteca.sistedes.es/articulo/effect-of-domain-knowledge-on-elicitation-effectiveness-an-internally-replicated-controlled-experiment/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/effect-of-domain-knowledge-on-elicitation-effectiveness-an-internally-replicated-controlled-experiment/</guid>
		<description></description>
		<content><![CDATA[IEEE TRANSACTIONS ON SOFTWARE ENGINEERING, VOL. 42, NO. 5, MAY 2016 DOI: https://doi.org/10.1109/TSE.2015.2494588 Factor de impacto: 1.516 Posición: 20/106 (Software Engineering) - Q1]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2621</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[effect-of-domain-knowledge-on-elicitation-effectiveness-an-internally-replicated-controlled-experiment]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="controlled-experiment"><![CDATA[Controlled Experiment]]></category>
		<category domain="post_tag" nicename="domain-knowledge"><![CDATA[domain knowledge]]></category>
		<category domain="post_tag" nicename="internal-replication"><![CDATA[internal replication]]></category>
		<category domain="post_tag" nicename="requirements-elicitation"><![CDATA[requirements elicitation]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[IEEE TRANSACTIONS ON SOFTWARE ENGINEERING, VOL. 42, NO. 5, MAY 2016  DOI: https://doi.org/10.1109/TSE.2015.2494588 Factor de impacto: 1.516 Posición: 20/106 (Software Engineering) - Q1  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/049]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_96.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_96.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alejandrina M. Aranda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alearanda@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Oscar Dieste]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[odieste@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Natalia Juristo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[natalia@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad PolitíƒÂ©cnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An experimental replication on the effect of the practice of mindfulness in conceptual modeling performance</title>
		<link>https://biblioteca.sistedes.es/articulo/an-experimental-replication-on-the-effect-of-the-practice-of-mindfulness-in-conceptual-modeling-performance/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-experimental-replication-on-the-effect-of-the-practice-of-mindfulness-in-conceptual-modeling-performance/</guid>
		<description></description>
		<content><![CDATA[Beatriz Bernárdez, Amador Durán , JoséA. Parejo , Antonio Ruiz-Cortés The Journal of Systems and Software 0 0 0 (2016) 1-20, In Press (Available online 30 June 2016) Indicios de Calidad: Journal of Systems and Software (Elsevier) ISSN: 0164-1212 Factor de impacto 2015: 1,424 Factor de impacto a 5 años: 1,767 Está indexada en dos categorías: Computer Science / Theory &amp; Methods: 31/105 (Q2) Computer Science / Software Engineering: 24/106 (Q1) Otros datos (sacados de la web de la revista): CiteScore: 2.93 Source Normalized Impact per Paper (SNIP): 2.415 SCImago Journal Rank (SJR): 0.897]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2622</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-experimental-replication-on-the-effect-of-the-practice-of-mindfulness-in-conceptual-modeling-performance]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="conceptual-modeling"><![CDATA[Conceptual modeling]]></category>
		<category domain="post_tag" nicename="mindfulness"><![CDATA[Mindfulness]]></category>
		<category domain="post_tag" nicename="replication"><![CDATA[Replication]]></category>
		<category domain="post_tag" nicename="software-psychology"><![CDATA[Software psychology]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Beatriz Bernárdez, Amador Durán , JoséA. Parejo , Antonio Ruiz-Cortés The Journal of Systems and Software 0 0 0 (2016) 1-20, In Press (Available online 30 June 2016)  Indicios de Calidad:  Journal of Systems and Software (Elsevier) ISSN: 0164-1212 Factor de impacto 2015: 1,424 Factor de impacto a 5 años: 1,767   Está indexada en dos categorías:   Computer Science / Theory & Methods: 31/105 (Q2)  Computer Science / Software Engineering: 24/106 (Q1)   Otros datos (sacados de la web de la revista): CiteScore: 2.93 Source Normalized Impact per Paper (SNIP): 2.415 SCImago Journal Rank (SJR): 0.897 ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/044]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_97.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_97.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Beatriz Bernárdez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[beat@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Amador Durán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[amador@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José A. Parejo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[japarejo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Early analysis of resource consumption patterns in mobile applications (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/early-analysis-of-resource-consumption-patterns-in-mobile-applications-summary/</link>
		<pubDate>Sat, 08 Jul 2017 02:35:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/early-analysis-of-resource-consumption-patterns-in-mobile-applications-summary/</guid>
		<description></description>
		<content><![CDATA[The success or failure of a mobile application largely depends on the resources it consumes. A resource-intensive application will quickly be rejected by its users. One of the most important aspects that determines this consumption is the software architecture applied in its development. However, which architecture is the most efficient depends on the application's behaviour.

With the aim of providing mobile developers information on what architectural style consumes fewer resources for each application, in this work we analysed the resources consumed by two applications, each of them built with two different architectures (a server-centric architecture and a mobile-centric architecture) in order to identify under which situation each architecture is more efficient. We observed that, for these cases, as the number of interactions with external entities grows, the more efficient becomes a server-centric architecture. Instead, a mobile-centric architecture is more efficient if the data to be shared has to be updated frequently or if there are few external entities involved.

In addition, by generalizing the analysis of the two applications, a conceptual framework was created with which to analyse the consumption pattern of any applications in their early development phases. This framework can be used to estimate a particular application's consumption with different architectures, or to predict its consumption under future evolution of the app.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2710</post_id>
		<post_date><![CDATA[2017-07-08 04:35:15]]></post_date>
		<post_date_gmt><![CDATA[2017-07-08 02:35:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[early-analysis-of-resource-consumption-patterns-in-mobile-applications-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>2</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The success or failure of a mobile application largely depends on the resources it consumes. A resource-intensive application will quickly be rejected by its users. One of the most important aspects that determines this consumption is the software architecture applied in its development. However, which architecture is the most efficient depends on the application's behaviour.

With the aim of providing mobile developers information on what architectural style consumes fewer resources for each application, in this work we analysed the resources consumed by two applications, each of them built with two different architectures (a server-centric architecture and a mobile-centric architecture) in order to identify under which situation each architecture is more efficient. We observed that, for these cases, as the number of interactions with external entities grows, the more efficient becomes a server-centric architecture. Instead, a mobile-centric architecture is more efficient if the data to be shared has to be updated frequently or if there are few external entities involved.

In addition, by generalizing the analysis of the two applications, a conceptual framework was created with which to analyse the consumption pattern of any applications in their early development phases. This framework can be used to estimate a particular application's consumption with different architectures, or to predict its consumption under future evolution of the app.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/031]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499279592.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499279592.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose Garcia-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Cristina Vicente-Chicote]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[cristinav@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juanher@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Tommi Mikkonen]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[tjm@cs.tut.fi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Tampere University of Technology, Finland]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Juan M. Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Framework for Efficiently Mining the Organisational Perspective of Business Processes (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-framework-for-efficiently-mining-the-organisational-perspective-of-business-processes-summary/</link>
		<pubDate>Sat, 08 Jul 2017 02:35:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-framework-for-efficiently-mining-the-organisational-perspective-of-business-processes-summary/</guid>
		<description></description>
		<content><![CDATA[Actual process executions may constitute a valuable input for improving process design. Process mining provides methods for automatic process analysis, among others for discovering processes by extracting knowledge from event logs in the form of a process model. Various algorithms are available to discover models capturing the control flow of a process, related to the behavioural perspective of the process.For perspectives like the organisational perspective, which manages the involvement of human resources in processes, only partial solutions for mining had been developed despite the importance of resource information not only for performance but also for compliance analysis.

Prior work on mining resource information focused on discovering specific aspects of the organisational perspective such as role models, separation of duty or social networks. However, comprehensive and integrated support for the wellestablished workflow resource patterns, and specifically in this context for the socalled creation patterns, was missing. Furthermore, the close interplay between the organisational and the behavioural perspectives (cross-perspective patterns) was disregarded.

The research reported in this paper presented an efficient and effective framework for mining the organisational perspective of business processes that is divided into an event log pre-processing phase, a phase for integrated resource mining including cross-perspective patterns, and a model post-processing phase. We evaluated our approach with an implementation of the three phases, with simulation experiments for measuring performance, and with the application of the approach on a real-life event log for checking its effectiveness.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2711</post_id>
		<post_date><![CDATA[2017-07-08 04:35:15]]></post_date>
		<post_date_gmt><![CDATA[2017-07-08 02:35:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-framework-for-efficiently-mining-the-organisational-perspective-of-business-processes-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Actual process executions may constitute a valuable input for improving process design. Process mining provides methods for automatic process analysis, among others for discovering processes by extracting knowledge from event logs in the form of a process model. Various algorithms are available to discover models capturing the control flow of a process, related to the behavioural perspective of the process.For perspectives like the organisational perspective, which manages the involvement of human resources in processes, only partial solutions for mining had been developed despite the importance of resource information not only for performance but also for compliance analysis.

Prior work on mining resource information focused on discovering specific aspects of the organisational perspective such as role models, separation of duty or social networks. However, comprehensive and integrated support for the wellestablished workflow resource patterns, and specifically in this context for the socalled creation patterns, was missing. Furthermore, the close interplay between the organisational and the behavioural perspectives (cross-perspective patterns) was disregarded.

The research reported in this paper presented an efficient and effective framework for mining the organisational perspective of business processes that is divided into an event log pre-processing phase, a phase for integrated resource mining including cross-perspective patterns, and a model post-processing phase. We evaluated our approach with an implementation of the three phases, with simulation experiments for measuring performance, and with the application of the approach on a real-life event log for checking its effectiveness.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/029]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499280233.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499280233.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Stefan Schönig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[stefan.schoenig@uni-bayreuth.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Bayreuth, Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Cristina Cabanillas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cristina.cabanillas@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Vienna University of Economics and Business, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Stefan Jablonski]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[stefan.jablonski@uni-bayreuth.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Bayreuth, Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jan Mendling]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jan.mendling@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Vienna University of Economics and Business, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Narrowing the Business-IT Gap in Process Performance Measurement (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/narrowing-the-business-it-gap-in-process-performance-measurement-summary/</link>
		<pubDate>Sat, 08 Jul 2017 02:35:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/narrowing-the-business-it-gap-in-process-performance-measurement-summary/</guid>
		<description></description>
		<content><![CDATA[Process Performance indicators (PPIs) play an important role in monitoring the performance of operational procedures. Both defining and measuring suitable PPIs are key tasks for aligning strategic business objectives with the operational implementation of a process. A major challenge in this regard is that perspectives on the same real-world phenomenon differ among the stakeholders that are involved in these tasks. Since the formulation of PPIs is typically a managerial concern, there is a risk that these do not match with the exact operational and technical characteristics of business processes. To bridge this gap, the concepts described in PPIs must first be linked to their corresponding process elements. Establishing these links is paramount for the monitoring of process performance.
Without them, the values of PPIs cannot be computed automatically. However, the necessary links must currently be established manually. A task which is tedious and error-prone, due to the aforementioned incoherence between the different perspectives. The goal of our work is to overcome the efforts involved in the manual creation of links by automating this step. To achieve this, we developed an approach that automatically aligns textual PPI descriptions to the relevant parts of a process model. The approach takes a textual PPI description and a process model to which the PPI relates as input. Given this input, the approach generates an alignment in three steps. (1) Type classification: We make use of a decision tree classifier to identify the type of a given PPI, which is important because it affects the number and kinds of process model elements that should be aligned to a PPI. (2) PPI parsing: We parse the textual PPI description to extract those phrases that relate to specific parts of a process, making use of natural language processing techniques. (3) Alignment to process model: Finally, given the identified measure type and the extracted phrases, we compute an alignment between the phrases and the process model. A quantitative evaluation with a set of 173 PPIs obtained from industry and reference frameworks, demonstrates that our automated approach produces satisfying results.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2712</post_id>
		<post_date><![CDATA[2017-07-08 04:35:15]]></post_date>
		<post_date_gmt><![CDATA[2017-07-08 02:35:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[narrowing-the-business-it-gap-in-process-performance-measurement-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Process Performance indicators (PPIs) play an important role in monitoring the performance of operational procedures. Both defining and measuring suitable PPIs are key tasks for aligning strategic business objectives with the operational implementation of a process. A major challenge in this regard is that perspectives on the same real-world phenomenon differ among the stakeholders that are involved in these tasks. Since the formulation of PPIs is typically a managerial concern, there is a risk that these do not match with the exact operational and technical characteristics of business processes. To bridge this gap, the concepts described in PPIs must first be linked to their corresponding process elements. Establishing these links is paramount for the monitoring of process performance. Without them, the values of PPIs cannot be computed automatically. However, the necessary links must currently be established manually. A task which is tedious and error-prone, due to the aforementioned incoherence between the different perspectives. The goal of our work is to overcome the efforts involved in the manual creation of links by automating this step. To achieve this, we developed an approach that automatically aligns textual PPI descriptions to the relevant parts of a process model. The approach takes a textual PPI description and a process model to which the PPI relates as input. Given this input, the approach generates an alignment in three steps. (1) Type classification: We make use of a decision tree classifier to identify the type of a given PPI, which is important because it affects the number and kinds of process model elements that should be aligned to a PPI. (2) PPI parsing: We parse the textual PPI description to extract those phrases that relate to specific parts of a process, making use of natural language processing techniques. (3) Alignment to process model: Finally, given the identified measure type and the extracted phrases, we compute an alignment between the phrases and the process model. A quantitative evaluation with a set of 173 PPIs obtained from industry and reference frameworks, demonstrates that our automated approach produces satisfying results.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/028]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499280822.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499280822.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Han van der Aa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[j.h.vander.aa@vu.nl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[VU University Amsterdam, The Netherlands]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Adela del-Río-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[adeladelrio@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Henrik Leopold]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[h.leopold@vu.nl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[VU University Amsterdam, The Netherlands]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Jan Mendling]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[jan.mendling@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Vienna University of Economics and Business, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Hajo Reijers]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[a.reijers@vu.nl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[VU University Amsterdam, The Netherlands & Eindhoven University of Technology, The Netherlands]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Complex Event Processing Modeling by Prioritized Colored Petri Nets (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/complex-event-processing-modeling-by-prioritized-colored-petri-nets-summary/</link>
		<pubDate>Sat, 08 Jul 2017 02:35:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/complex-event-processing-modeling-by-prioritized-colored-petri-nets-summary/</guid>
		<description></description>
		<content><![CDATA[Complex Event Processing (CEP) is a technology that allows us to process and correlate large volumes of data by using event patterns, aiming at promptly detecting specific situations that could require special treatment. The event types and event patterns for a particular application domain are implemented by using an Event Processing Language (EPL). Although some current model-driven tools allow end users to easily define these patterns, which are then transformed automatically into a particular EPL, the generated code is syntactically but not semantically validated. To deal with this problem, a Prioritized Colored Petri Net model (PCPN) for CEP is proposed and conducted in this paper.

Thus, we have not only an event pattern graphical representation, but also the capability to perform formal analysis, and therefore semantic analysis, by means of the PCPN model obtained and the CPN Tools. This formal analysis is twofold. On the one hand, users can interact with the model itself by performing a step by step debugging, since the tool allows to simulate the model. With this in mind, users can specify a concrete scenario by providing the initial marking to check whether the model works as expected. By doing this, users can observe the results of the individual steps of the simulation, which represent the different EPL operators, as we can observe at the end of the case study where a user can detect whether the preferred operator has been used, that is, if the specified pattern behaves as expected. On the other hand, there are certain advantages of performing automatic simulations. An automatic simulation allows us to actually execute the EPL code and compare the obtained output, that is, we can compare whether the results obtained from a given input are the same when we execute the EPL code in the Esper EPL online tool and in CPN Tools.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2713</post_id>
		<post_date><![CDATA[2017-07-08 04:35:15]]></post_date>
		<post_date_gmt><![CDATA[2017-07-08 02:35:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[complex-event-processing-modeling-by-prioritized-colored-petri-nets-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Complex Event Processing (CEP) is a technology that allows us to process and correlate large volumes of data by using event patterns, aiming at promptly detecting specific situations that could require special treatment. The event types and event patterns for a particular application domain are implemented by using an Event Processing Language (EPL). Although some current model-driven tools allow end users to easily define these patterns, which are then transformed automatically into a particular EPL, the generated code is syntactically but not semantically validated. To deal with this problem, a Prioritized Colored Petri Net model (PCPN) for CEP is proposed and conducted in this paper.

Thus, we have not only an event pattern graphical representation, but also the capability to perform formal analysis, and therefore semantic analysis, by means of the PCPN model obtained and the CPN Tools. This formal analysis is twofold. On the one hand, users can interact with the model itself by performing a step by step debugging, since the tool allows to simulate the model. With this in mind, users can specify a concrete scenario by providing the initial marking to check whether the model works as expected. By doing this, users can observe the results of the individual steps of the simulation, which represent the different EPL operators, as we can observe at the end of the case study where a user can detect whether the preferred operator has been used, that is, if the specified pattern behaves as expected. On the other hand, there are certain advantages of performing automatic simulations. An automatic simulation allows us to actually execute the EPL code and compare the obtained output, that is, we can compare whether the results obtained from a given input are the same when we execute the EPL code in the Esper EPL online tool and in CPN Tools.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/027]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499281447.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499281447.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Hermenegilda Macià]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[hermenegilda.macia@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[School of Computer Science, University of Castilla-La Mancha, Albacete]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Valentín Valero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[valentin.valero@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[School of Computer Science, University of Castilla-La Mancha, Albacete]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Gregorio Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gregorio.diaz@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[School of Computer Science, University of Castilla-La Mancha, Albacete]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science and Engineering, University of Cádiz, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science and Engineering, University of Cádiz, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modeling Service Level Agreements with Linked USDL Agreement (Resumen)</title>
		<link>https://biblioteca.sistedes.es/articulo/modeling-service-level-agreements-with-linked-usdl-agreement-resumen/</link>
		<pubDate>Sat, 08 Jul 2017 02:35:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/modeling-service-level-agreements-with-linked-usdl-agreement-resumen/</guid>
		<description></description>
		<content><![CDATA[A pesar de la importancia de los servicios en la economía, las tareas como la búsqueda, análisis de alternativas, y contratación de servicios en virtud de acuerdos de nivel de servicio (ANS), siguen realizándose manualmente. En la denominada Web de los servicios existen alternativas para facilitar  la automatización  de estas tareas basadas en diversos modelos conceptuales: genéricos como Linked USDL, o centrados en algún aspecto concreto, como
WS-Agreement con los ANS. Sin embargo,  estos últimos contemplan principalmente sólo aspectos técnicos, sin proporcionar una semántica explícita a los términos del ANS ni cumplir los principios de la Web, dificultando su adopción y análisis automático.

En este artículo presentamos Linked USDL Agreement, una extensión de la familia de ontologías Linked USDL que proporciona facilidades para especificar, gestionar y compartir descripciones de ANS en la Web. Este modelo semántico evita los problemas de interoperabilidad y heterogeneidad de las especificaciones de ANS actuales. Además, dado que nuestro modelo sigue los principios de la Web de los datos, las descripciones de ANS generadas son fácilmente publicables, compartibles y analizables, sirviendo como soporte del ciclo de vida de los servicios.

Nuestra propuesta ha sido validada tanto sobre servicios Web tradicionales (e.g. computación en la nube), como sobre servicios no-computacionales  (e.g. outsourcing de procesos de negocio). La comparación realizada con otras alternativas existentes, así como la implementación de una herramienta que facilita la creación, publicación, y análisis automático de documentos en Linked USDL Agreement, nos permite afirmar que nuestra propuesta  es capaz de soportar
completamente la gestión del ciclo de vida de los ANS.
]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2714</post_id>
		<post_date><![CDATA[2017-07-08 04:35:15]]></post_date>
		<post_date_gmt><![CDATA[2017-07-08 02:35:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modeling-service-level-agreements-with-linked-usdl-agreement-resumen]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>1</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A pesar de la importancia de los servicios en la economía, las tareas como la búsqueda, análisis de alternativas, y contratación de servicios en virtud de acuerdos de nivel de servicio (ANS), siguen realizándose manualmente. En la denominada Web de los servicios existen alternativas para facilitar  la automatización  de estas tareas basadas en diversos modelos conceptuales: genéricos como Linked USDL, o centrados en algún aspecto concreto, como
WS-Agreement con los ANS. Sin embargo,  estos últimos contemplan principalmente sólo aspectos técnicos, sin proporcionar una semántica explícita a los términos del ANS ni cumplir los principios de la Web, dificultando su adopción y análisis automático.

En este artículo presentamos Linked USDL Agreement, una extensión de la familia de ontologías Linked USDL que proporciona facilidades para especificar, gestionar y compartir descripciones de ANS en la Web. Este modelo semántico evita los problemas de interoperabilidad y heterogeneidad de las especificaciones de ANS actuales. Además, dado que nuestro modelo sigue los principios de la Web de los datos, las descripciones de ANS generadas son fácilmente publicables, compartibles y analizables, sirviendo como soporte del ciclo de vida de los servicios.

Nuestra propuesta ha sido validada tanto sobre servicios Web tradicionales (e.g. computación en la nube), como sobre servicios no-computacionales  (e.g. outsourcing de procesos de negocio). La comparación realizada con otras alternativas existentes, así como la implementación de una herramienta que facilita la creación, publicación, y análisis automático de documentos en Linked USDL Agreement, nos permite afirmar que nuestra propuesta  es capaz de soportar
completamente la gestión del ciclo de vida de los ANS.
]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/026]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499282110.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499282110.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José María García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[josemgarcia@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Carlos Pedrinaci]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[c.pedrinaci@open.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[The Open University, United Kingdom]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Jorge S. Cardoso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[jcardoso@dei.uc.pt]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[CISUC/Department of Informatics Engineering, University of Coimbra, Portugal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards an MDE-Based Approach to Test Entity Reconciliation Applications (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-an-mde-based-approach-to-test-entity-reconciliation-applications-summary/</link>
		<pubDate>Sat, 08 Jul 2017 02:35:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-an-mde-based-approach-to-test-entity-reconciliation-applications-summary/</guid>
		<description></description>
		<content><![CDATA[The management of large volumes of data has given rise to significant challenges to the entity reconciliation problem (which refers to combining data from different sources for a unified vision) due to the fact that the data are becoming more un-structured, un-clean and incomplete, need to be more linked, etc. Testing the applications that implement the entity reconciliation problem is crucial to ensure both the correctness of the reconciliation process and the quality of the reconciled data.

In this paper, we have presented a work-in-progress that aims to test applications that implement an entity reconciliation problem to ensure the quality of both the applications and the reconciled data. The approach allows the creation of test models for integration testing, taking into account the problem specification and the data models of the data sources and the solution. These test models are composed of several business rules, called integration rules, which can be used to automatically derive the test requirements. Besides, as the integration rules also describe the business logic of the entity reconciliation process, they can be used to partially derive the implementation of the application.

The proposal is based on two main pillars: MDE and virtual graph. The support of automation of the MDE paradigm allows us to build very scalable solutions at a low cost, whilst the virtual graphs allow us to dynamically build the entity reconciliation solution at runtime.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2715</post_id>
		<post_date><![CDATA[2017-07-08 04:35:15]]></post_date>
		<post_date_gmt><![CDATA[2017-07-08 02:35:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-an-mde-based-approach-to-test-entity-reconciliation-applications-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>2</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The management of large volumes of data has given rise to significant challenges to the entity reconciliation problem (which refers to combining data from different sources for a unified vision) due to the fact that the data are becoming more un-structured, un-clean and incomplete, need to be more linked, etc. Testing the applications that implement the entity reconciliation problem is crucial to ensure both the correctness of the reconciliation process and the quality of the reconciled data.

In this paper, we have presented a work-in-progress that aims to test applications that implement an entity reconciliation problem to ensure the quality of both the applications and the reconciled data. The approach allows the creation of test models for integration testing, taking into account the problem specification and the data models of the data sources and the solution. These test models are composed of several business rules, called integration rules, which can be used to automatically derive the test requirements. Besides, as the integration rules also describe the business logic of the entity reconciliation process, they can be used to partially derive the implementation of the application.

The proposal is based on two main pillars: MDE and virtual graph. The support of automation of the MDE paradigm allows us to build very scalable solutions at a low cost, whilst the virtual graphs allow us to dynamically build the entity reconciliation solution at runtime.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/025]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499282605.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499282605.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[J.G. Enríquez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jose.gonzalez@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Computer and Language Systems, University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Raquel Blanco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[rblanco@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computing, University of Oviedo, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[F.J. Domínguez-Mayo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fjdominguez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer and Language Systems, University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computing, University of Oviedo, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[M.J. Escalona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[mjescalona@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Department of Computer and Language Systems, University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Continuous Space Estimation: Increasing WiFi-Based Indoor Localization Resolution without Increasing the Site-Survery Effort (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/continuous-space-estimation-increasing-wifi-based-indoor-localization-resolution-without-increasing-the-site-survery-effort-summary/</link>
		<pubDate>Sat, 08 Jul 2017 02:35:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/continuous-space-estimation-increasing-wifi-based-indoor-localization-resolution-without-increasing-the-site-survery-effort-summary/</guid>
		<description></description>
		<content><![CDATA[This work is part of the BAI4SOW ("Inteligencia (Artificial) de Negocio para Flujos de Trabajo Sociales”) project, previously introduced in JCIS 2016, that deals with the study of the social workflows of consumers inside an open mall.

One key objective inside our sub-project is to localize and track the consumers by means of using the on board phone sensors (GPS in outdoors and WiFi, combined with other sensors, in indoors). This user localization represents the base of the activity recognition system that feeds the database. Using this
user positioning database and applying data mining processes the most frequent patterns of activity will be detected.

The objective of our proposal was to improve the resolution of fingerprint-based indoor WiFi localization systems without increasing the site survey effort. This way, WiFi indoor localization systems could be used to locate users in large environments (such as malls) reducing the effort of constructing the WiFi database. To do so, we proposed an approach, based on Support Vector Regression, to estimate the received signal strength at non-site-surveyed positions of
the environment. Experiments, performed in a real environment, showed that the number and distribution of the positions needed to train the system can be
reduced to almost half without significantly increasing the mean distance error.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2716</post_id>
		<post_date><![CDATA[2017-07-08 04:35:15]]></post_date>
		<post_date_gmt><![CDATA[2017-07-08 02:35:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[continuous-space-estimation-increasing-wifi-based-indoor-localization-resolution-without-increasing-the-site-survery-effort-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>1</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This work is part of the BAI4SOW ("Inteligencia (Artificial) de Negocio para Flujos de Trabajo Sociales”) project, previously introduced in JCIS 2016, that deals with the study of the social workflows of consumers inside an open mall.

One key objective inside our sub-project is to localize and track the consumers by means of using the on board phone sensors (GPS in outdoors and WiFi, combined with other sensors, in indoors). This user localization represents the base of the activity recognition system that feeds the database. Using this
user positioning database and applying data mining processes the most frequent patterns of activity will be detected.

The objective of our proposal was to improve the resolution of fingerprint-based indoor WiFi localization systems without increasing the site survey effort. This way, WiFi indoor localization systems could be used to locate users in large environments (such as malls) reducing the effort of constructing the WiFi database. To do so, we proposed an approach, based on Support Vector Regression, to estimate the received signal strength at non-site-surveyed positions of
the environment. Experiments, performed in a real environment, showed that the number and distribution of the positions needed to train the system can be
reduced to almost half without significantly increasing the mean distance error.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/024]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499282950.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499282950.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Noelia Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[noelia.hernandez@uc3m.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Carlos III de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Ocaña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mocana@depeca.uah.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Alcalá, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose M. Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[josemaria.alonso.moral@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidade de Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Euntai Kim]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[etkim@yonsei.ac.kr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Yonsei University, Republic of Korea]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hybrid business process modeling for the optimization of outcome data (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/hybrid-business-process-modeling-for-the-optimization-of-outcome-data-summary/</link>
		<pubDate>Sat, 08 Jul 2017 02:35:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/hybrid-business-process-modeling-for-the-optimization-of-outcome-data-summary/</guid>
		<description></description>
		<content><![CDATA[Declarative business processes are commonly used to describe permitted and prohibited actions in a BP. However, most current proposals of declarative languages fail in three aspects: (1) they tend to be oriented only towards the execution order of the activities; (2) the optimization is oriented only towards the minimization of the execution time or the resources used in the business process; and (3) there is an absence of capacity of execution of declarative models in commercial Business Process Management Systems.

Therefore, this contribution aims at taking into account these three aspects, by means of: (1) the formalization of a hybrid model oriented towards obtaining the outcome data optimization by combining a data-oriented declarative specification and a control-flow-oriented imperative specification; and (2) the automatic creation from this hybrid model to an imperative model that is executable in a standard Business Process Management System.

An approach, based on the definition of a hybrid business process, which uses a constraint programming paradigm, is presented. This approach enables the optimized outcome data to be obtained at runtime for the various instances. In order to work out our approach, a language capable of defining a hybrid model is provided, and applied to a case study. Likewise, the automatic creation of an executable constraint satisfaction problem is addressed, whose resolution allows us to attain the optimized outcome data. A brief computational study is also shown.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2717</post_id>
		<post_date><![CDATA[2017-07-08 04:35:15]]></post_date>
		<post_date_gmt><![CDATA[2017-07-08 02:35:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hybrid-business-process-modeling-for-the-optimization-of-outcome-data-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>3</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Declarative business processes are commonly used to describe permitted and prohibited actions in a BP. However, most current proposals of declarative languages fail in three aspects: (1) they tend to be oriented only towards the execution order of the activities; (2) the optimization is oriented only towards the minimization of the execution time or the resources used in the business process; and (3) there is an absence of capacity of execution of declarative models in commercial Business Process Management Systems.

Therefore, this contribution aims at taking into account these three aspects, by means of: (1) the formalization of a hybrid model oriented towards obtaining the outcome data optimization by combining a data-oriented declarative specification and a control-flow-oriented imperative specification; and (2) the automatic creation from this hybrid model to an imperative model that is executable in a standard Business Process Management System.

An approach, based on the definition of a hybrid business process, which uses a constraint programming paradigm, is presented. This approach enables the optimized outcome data to be obtained at runtime for the various instances. In order to work out our approach, a language capable of defining a hybrid model is provided, and applied to a case study. Likewise, the automatic creation of an executable constraint satisfaction problem is addressed, whose resolution allows us to attain the optimized outcome data. A brief computational study is also shown.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/030]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499283276.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499283276.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Luisa Parody]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[lparody@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[María Teresa Gómez-López]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[maytegomez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Rafael M. Gasca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gasca@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>ACon: A learning-based approach to deal with uncertainty in contextual requirements at runtime</title>
		<link>https://biblioteca.sistedes.es/articulo/acon-a-learning-based-approach-to-deal-with-uncertainty-in-contextual-requirements-at-runtime/</link>
		<pubDate>Tue, 11 Jul 2017 03:25:23 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/?post_type=articulo&#038;p=2744</guid>
		<description></description>
		<content><![CDATA[Autores: Alessia Knauss, Daniela Damian, Xavier Franch, Angela Rook, Hausi A. Müller, Alex Thomo Revista: Informacion &amp; Software Technology 70: 85-99 (2016) DOI: http://dx.doi.org/10.1016/j.infsof.2015.10.001 JCR IF 2015: 1.569 (primer cuartil de la categoría de ingeniería del software) 3 citas (excluyendo self-citations)]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2744</post_id>
		<post_date><![CDATA[2017-07-11 05:25:23]]></post_date>
		<post_date_gmt><![CDATA[2017-07-11 03:25:23]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[acon-a-learning-based-approach-to-deal-with-uncertainty-in-contextual-requirements-at-runtime]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="contextual-requirements"><![CDATA[Contextual requirements]]></category>
		<category domain="post_tag" nicename="requirements-engineering"><![CDATA[requirements engineering]]></category>
		<category domain="post_tag" nicename="self-adaptive-systems"><![CDATA[Self-adaptive systems]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2745]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/080]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Requirements engineering,Self-adaptive systems,Contextual requirements]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alessia Knauss]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Daniela Damian]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Xavier Franch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Angela Rook]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Hausi A. Müller]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Alex Thomo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[franch@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Victoria, Victoria, BC, Canada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Victoria, Victoria, BC, Canada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Victoria, Victoria, BC, Canada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Victoria, Victoria, BC, Canada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Victoria, Victoria, BC, Canada]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SIP: Optimal Product Selection from Feature Models Using Many-Objective Evolutionary Optimization</title>
		<link>https://biblioteca.sistedes.es/articulo/sip-optimal-product-selection-from-feature-models-using-many-objective-evolutionary-optimization/</link>
		<pubDate>Tue, 11 Jul 2017 03:32:42 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/?post_type=articulo&#038;p=2747</guid>
		<description></description>
		<content><![CDATA[Robert M. Hierons, Miqing Li, Xiaohui Liu, Sergio Segura, and Wei Zheng. 2016. SIP: Optimal Product Selection from Feature Models Using Many-Objective Evolutionary Optimization. ACM Trans. Softw. Eng. Methodol. 25, 2, Article 17 (April 2016), 39 pages. DOI: http://dx.doi.org/10.1145/2897760  Indicadores de calidad:   - Revista de referencia en el área de Ingeniería del Software (CS-SE: 21/106).   - Colaboración internacional con los profesores Robert Hierons [1] y XiaoHui Liu [2].  - Hemos sido invitados a presentar el trabajo en FSE16 e ICSE17 como parte de la iniciativa journal-first (ver programa de la conferencia [3]).   - Ha recibido 6 citas desde su publicación en abril de 2016 [4].   [1] http://dblp.uni-trier.de/pers/hd/h/Hierons:Robert_M= [2] http://dblp.uni-trier.de/pers/hd/l/Liu:Xiaohui [2] http://icse2017.gatech.edu/?q=technical-research-accepted [4] https://goo.gl/XyTmQR
]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2747</post_id>
		<post_date><![CDATA[2017-07-11 05:32:42]]></post_date>
		<post_date_gmt><![CDATA[2017-07-11 03:32:42]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[sip-optimal-product-selection-from-feature-models-using-many-objective-evolutionary-optimization]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>1</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="optimization"><![CDATA[Optimization]]></category>
		<category domain="post_tag" nicename="search-based-software-engineering"><![CDATA[Search-Based Software Engineering]]></category>
		<category domain="post_tag" nicename="software-product-lines"><![CDATA[software product lines]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2748]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/081]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[search-based software engineering,optimization,software product lines]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rob Hierons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Brunel University]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rob.hierons@brunel.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miqing Li]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Birmingham]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[limitsing@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Xiaohui Liu Liu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Birmingham]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[XiaoHui.Liu@brunel.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Wei Zheng]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Northwestern Polytechnical University]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[wzheng@nwpu.edu.cn]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An approach driven by mobile agents for data management in vehicular networks</title>
		<link>https://biblioteca.sistedes.es/articulo/an-approach-driven-by-mobile-agents-for-data-management-in-vehicular-networks/</link>
		<pubDate>Tue, 11 Jul 2017 03:38:19 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/?post_type=articulo&#038;p=2750</guid>
		<description></description>
		<content><![CDATA[In the last years, and thanks to improvements on computing and communications technologies, wireless networks formed by vehicles (called vehicular networks) have emerged as a key topic of interest. In these networks, the vehicles can exchange data by using short-range radio signals in order to get useful information related to traffic conditions, road safety, and other aspects. The availability of different types of sensors can be exploited by the vehicles to measure many parameters from their surroundings. These data can then be shared with other drivers who, on the other side, could also explicitly submit queries to retrieve information available in the network. This can be a challenging task, since the data is scattered among the vehicles belonging to the network and the communication links among them have usually a short life due to their constant movement.   In this paper, we use mobile agent technology to help to accomplish these tasks, since mobile agents have a number of features that are very well suited for mobile environments, such as autonomy, mobility, and intelligence. Specifically, we analyze the benefits that mobile agents can bring to vehicular networks and the potential difficulties for their adoption. Moreover, we describe a query processing approach based on the use of mobile agents. We focus on range queries that retrieve interesting information from the vehicles located within a geographic area, and perform an extensive experimental evaluation that shows the feasibility and the interest of the proposal.
]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2750</post_id>
		<post_date><![CDATA[2017-07-11 05:38:19]]></post_date>
		<post_date_gmt><![CDATA[2017-07-11 03:38:19]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-approach-driven-by-mobile-agents-for-data-management-in-vehicular-networks]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>2</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="data-management"><![CDATA[data management]]></category>
		<category domain="post_tag" nicename="mobile-agents"><![CDATA[mobile agents]]></category>
		<category domain="post_tag" nicename="query-processing"><![CDATA[query processing]]></category>
		<category domain="post_tag" nicename="vehicular-ad-hoc-networks"><![CDATA[vehicular ad hoc networks]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2751]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/082]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[vehicular ad hoc networks,mobile agents,data management,query processing]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Oscar Urra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ourra@itainnova.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Ilarri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[silarri@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Raquel Trillo-Lado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[raqueltl@unizar.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>QL: Object-oriented Queries on Relational Data (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/ql-object-oriented-queries-on-relational-data-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:47 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/ql-object-oriented-queries-on-relational-data-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Paper already published at: European Conference on Object-Oriented Programming (ECOOP) 2016 This paper describes QL, a language for querying complex, potentially recursive data structures. QL compiles to Datalog and runs on a standard relational database, yet it provides familiar-looking object-oriented features such as classes and methods, reinterpreted in logical terms: classes are logical properties describing sets of values, subclassing is implication, and virtual calls are dispatched dynamically by considering the most specific classes containing the receiver. Furthermore, types in QL are prescriptive and actively influence program evaluation rather than just describing it. In combination, these features enable the development of concise queries based on reusable libraries, which are written in a purely declarative style, yet can be efficiently executed even on very large data sets. In particular, we have used QL to implement static analyses for various programming languages, which scale to millions of lines of code.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2903</post_id>
		<post_date><![CDATA[2018-07-26 06:17:47]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[ql-object-oriented-queries-on-relational-data-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="code-exploration"><![CDATA[Code-exploration]]></category>
		<category domain="post_tag" nicename="databases"><![CDATA[Databases]]></category>
		<category domain="post_tag" nicename="datalog"><![CDATA[Datalog]]></category>
		<category domain="post_tag" nicename="logic-programming"><![CDATA[Logic Programming]]></category>
		<category domain="post_tag" nicename="object-oriented-programming"><![CDATA[Object-oriented programming]]></category>
		<category domain="post_tag" nicename="queries"><![CDATA[Queries]]></category>
		<category domain="post_tag" nicename="relational-algebra"><![CDATA[Relational Algebra]]></category>
		<category domain="post_tag" nicename="static-analysis"><![CDATA[Static Analysis]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Paper already published at: European Conference on Object-Oriented Programming (ECOOP) 2016                                                                          This paper describes QL, a language for querying complex, potentially recursive data structures. QL compiles to Datalog and runs on a standard relational database, yet it provides familiar-looking object-oriented features such as classes and methods, reinterpreted in logical terms: classes are logical properties describing sets of values, subclassing is implication, and virtual calls are dispatched dynamically by considering the most specific classes containing the receiver. Furthermore, types in QL are prescriptive and actively influence program evaluation rather than just describing it. In combination, these features enable the development of concise queries based on reusable libraries, which are written in a purely declarative style, yet can be efficiently executed even on very large data sets. In particular, we have used QL to implement static analyses for various programming languages, which scale to millions of lines of code.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-002.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-002.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pavel Avgustinov]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[publications@semmle.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Semmle Ltd - United Kingdom]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Oege de Moor]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[publications@semmle.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Semmle Ltd - United Kingdom]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Michael Peyton Jones]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[publications@semmle.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Semmle Ltd - United Kingdom]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Max Schäfer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[max@semmle.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Semmle Ltd - United Kingdom]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/001]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Correct Compiler from Mini-ML to a Big-Step Machine Verified Using Natural Semantics in Coq (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-correct-compiler-from-mini-ml-to-a-big-step-machine-verified-using-natural-semantics-in-coq-en-progreso/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:47 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-correct-compiler-from-mini-ml-to-a-big-step-machine-verified-using-natural-semantics-in-coq-en-progreso/</guid>
		<description></description>
		<content><![CDATA[This work has the objective to present a simple, clear and intuitive framework for compilers verification of functional languages in the proof assistant Coq, that, as a final product, can obtain a standalone verified compiler capable of being used in real life. With this in mind, we propose to use natural semantics as unifying framework, that is to say, to use this formalism to define each of the compiler's components in order to perform this task. To show this method, we present a correct compiler of the small functional language with call by value Mini-ML, formalized in Coq. As a result of following this approach, we introduce a new big-step  machine inspired by Landin's SECD and Leroy's Modern SECD as target machine. To the best of the authors' knowledge, this is the first correct compiler that is verified by using natural semantics as unifying framework in Coq from which we can obtain a verified compiler capable of being used in real life.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2904</post_id>
		<post_date><![CDATA[2018-07-26 06:17:47]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-correct-compiler-from-mini-ml-to-a-big-step-machine-verified-using-natural-semantics-in-coq-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="abstract-machine"><![CDATA[abstract machine]]></category>
		<category domain="post_tag" nicename="big-step-machine"><![CDATA[Big-step machine]]></category>
		<category domain="post_tag" nicename="compiler-verification"><![CDATA[compiler verification]]></category>
		<category domain="post_tag" nicename="coq"><![CDATA[Coq]]></category>
		<category domain="post_tag" nicename="de-bruijn-indices"><![CDATA[de Bruijn indices]]></category>
		<category domain="post_tag" nicename="mini-ml"><![CDATA[Mini-ML]]></category>
		<category domain="post_tag" nicename="natural-semantics"><![CDATA[natural semantics]]></category>
		<category domain="post_tag" nicename="secd"><![CDATA[SECD]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper presents a correct compiler of a small functional language, Mini-ML, formalized in Coq. The literature of functional compiler verification in proof assistants usually reports the use of ad hoc formalizations. This work emphasized the use of natural semantics as uniform and unifying framework for this task. As a result of following this approach, a new big-step semantics machine with call by value is introduced, inspired by the SECD of Landin and the MSECD of Leroy. Since this machine uses de Bruijn indices, as first step is giving a (correct verified) translation from named Mini-ML to de Bruijn notation Mini-ML in the natural semantics setting. To the best of the author's knowledge, this is the first mechanization of a correct compiler of a functional language, using natural semantics as verifying framework in a proof assistant, such as, a working compiler capable to be used in real life can be obtained from it.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-003.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-003.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ángel Zúñiga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[zuniga@ciencias.unam.mx]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[UNAM - Mexico]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Gemma Bel-Enguix]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gbele@iingen.unam.mx]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[UNAM - Mexico]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/002]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Constraint Answer Set Programming without Grounding (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/constraint-answer-set-programming-without-grounding-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:47 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/constraint-answer-set-programming-without-grounding-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Extending ASP with constraints (CASP) enhances its expressiveness and performance. This extension is not straightforward as the grounding phase, present in most ASP systems, removes variables and the links among them, and also causes a combinatorial explosion in the size of the program. This has led CASP systems to devise several methods to overcome this issue: restricting the constraint domains (e.g., discrete instead of dense), where constraints can appear, or the type (or number) of models that can be returned. In this paper we propose to incorporate constraints into s(ASP), a goal-directed, top-down execution model which implements ASP while retaining logical variables both during execution and in the answer sets. The resulting model, s(CASP), can constrain variables that (as in CLP) are kept during the execution and in the answer sets. s(CASP) inherits and generalizes the execution model of s(ASP) while parameterizing the constraint solver. We describe this novel execution model and show, through several examples, the enhanced expressiveness of s(CASP) w.r.t. ASP, CLP, and other ASP systems with constraints. We also report improved performance w.r.t. other very mature, highly optimized ASP systems in some benchmarks.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2905</post_id>
		<post_date><![CDATA[2018-07-26 06:17:47]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[constraint-answer-set-programming-without-grounding-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="constraints"><![CDATA[constraints]]></category>
		<category domain="post_tag" nicename="goal-directed-evaluation"><![CDATA[goal-directed evaluation]]></category>
		<category domain="post_tag" nicename="predicate"><![CDATA[predicate]]></category>
		<category domain="post_tag" nicename="stable-model"><![CDATA[stable model]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Extending ASP with constraints (CASP) enhances its expressiveness and performance. This extension is not straightforward as the grounding phase, present in most ASP systems, removes variables and the links among them, and also causes a combinatorial explosion in the size of the program. This has led CASP systems to devise several methods to overcome this issue: restricting the constraint domains (e.g., discrete instead of dense), where constraints can appear, or the type (or number) of models that can be returned. In this paper we propose to incorporate constraints into s(ASP), a goal-directed, top-down execution model which implements ASP while retaining logical variables both during execution and in the answer sets. The resulting model, s(CASP), can constrain variables that (as in CLP) are kept during the execution and in the answer sets. s(CASP) inherits and generalizes the execution model of s(ASP) while parameterizing the constraint solver. We describe this novel execution model and show, through several examples, the enhanced expressiveness of s(CASP) w.r.t. ASP, CLP, and other ASP systems with constraints. We also report improved performance w.r.t. other very mature, highly optimized ASP systems in some benchmarks.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-004.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-004.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Joaquín Arias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[joaquin.arias@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Carro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mcarro@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Technical University of Madrid (UPM) and IMDEA Software Institute - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Kyle Marple]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[kmarple1@utdallas.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[The University of Texas at Dallas - United States]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Elmer Salazar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[ees101020@utdallas.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[The University of Texas at Dallas - United States]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Gopal Gupta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[guptag@utdallas.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[The University of Texas at Dallas - United States]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/003]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Online Tool for Unfolding Symbolic Fuzzy Logic Programs (Demostración)</title>
		<link>https://biblioteca.sistedes.es/articulo/an-online-tool-for-unfolding-symbolic-fuzzy-logic-programs-demo/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:47 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-online-tool-for-unfolding-symbolic-fuzzy-logic-programs-demo/</guid>
		<description></description>
		<content><![CDATA[In many declarative frameworks, unfolding is a very well-known semantics-preserving transformation technique based on the application of computational steps on the bodies of program rules for improving efficiency. In this paper we describe an online tool which allows us to unfold a symbolic extension of a modern fuzzy logic language where program rules can embed concrete and/or symbolic fuzzy connectives and truth degrees on their bodies. The system offers a comfortable interaction with users for unfolding symbolic programs and it also provides useful options to navigate along the sequence of unfolded programs. Finally, the symbolic unfolding transformation is connected with some fuzzy tuning techniques that we previously implemented on the same tool.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2906</post_id>
		<post_date><![CDATA[2018-07-26 06:17:47]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-online-tool-for-unfolding-symbolic-fuzzy-logic-programs-demo]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="fuzzy-logic-programming"><![CDATA[Fuzzy Logic Programming]]></category>
		<category domain="post_tag" nicename="software-tools"><![CDATA[Software Tools]]></category>
		<category domain="post_tag" nicename="symbolic-execution"><![CDATA[symbolic execution]]></category>
		<category domain="post_tag" nicename="unfolding"><![CDATA[Unfolding]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In many declarative frameworks, unfolding is a very well-known semantics-preserving transformation technique based on the application of computational steps on the bodies of program rules for improving efficiency. In this paper we describe an online tool which allows us to unfold a symbolic extension of a modern fuzzy logic language where program rules can embed concrete and/or symbolic fuzzy connectives and truth degrees on their bodies. The system offers a comfortable interaction with users for unfolding symbolic programs and it also provides useful options to navigate along the sequence of unfolded programs. Finally, the symbolic unfolding transformation is connected with some fuzzy tuning techniques that we previously implemented on the same tool.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-005.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-005.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ginés Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[gines.moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Antonio Riaza Valverde]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[JoseAntonio.Riaza@alu.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/004]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Rule formats for nominal process calculi (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/rule-formats-for-nominal-process-calculi-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/rule-formats-for-nominal-process-calculi-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Artículo publicado en CONCUR 2017. The nominal transition systems (NTSs) of Parrow et al. describe the operational semantics of nominal process calculi. We study NTSs in terms of the nominal residual transition systems (NRTSs) that we introduce. We provide rule formats for the specifications of NRTSs that ensure that the associated NRTS is an NTS and apply them to the operational specification of the early pi-calculus. Our study stems from the recent Nominal SOS of Cimini et al. and from earlier works in nominal sets and nominal logic by Gabbay, Pitts and their collaborators.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2907</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[rule-formats-for-nominal-process-calculi-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="nominal-sets"><![CDATA[nominal sets]]></category>
		<category domain="post_tag" nicename="nominal-structural-operational-semantics"><![CDATA[nominal structural operational semantics]]></category>
		<category domain="post_tag" nicename="nominal-transition-systems"><![CDATA[nominal transition systems]]></category>
		<category domain="post_tag" nicename="process-algebra"><![CDATA[process algebra]]></category>
		<category domain="post_tag" nicename="rule-formats"><![CDATA[rule formats]]></category>
		<category domain="post_tag" nicename="scope-opening"><![CDATA[scope opening]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Artículo publicado en CONCUR 2017.

The nominal transition systems (NTSs) of Parrow et al. describe the operational semantics of nominal process calculi. We study NTSs in terms of the nominal residual transition systems (NRTSs) that we introduce. We provide rule formats for the specifications of NRTSs that ensure that the associated NRTS is an NTS and apply them to the operational specification of the early pi-calculus. Our study stems from the recent Nominal SOS of Cimini et al. and from earlier works in nominal sets and nominal logic by Gabbay, Pitts and their collaborators.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-006.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-006.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Luca Aceto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[luca@ru.is]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ICE-TCS, School of Computer Science, Reykjavik University - Iceland]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ignacio Fábregas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ignacio.fabregas@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Álvaro García Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[alvaro.garcia.perez@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Anna Ingólfsdóttir]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[annai@ru.is]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[ICE-TCS, School of Computer Science, Reykjavik University - Iceland]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Yolanda Ortega Mallén]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[yolanda@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/005]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Semantic Analysis of SQL Statements in DES (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/semantic-analysis-of-sql-statements-in-des-en-progreso/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/semantic-analysis-of-sql-statements-in-des-en-progreso/</guid>
		<description></description>
		<content><![CDATA[This paper presents an on-going work that includes semantic analysis of SQL statements in the database system DES. Following Brass&amp;Goldberg, SQL statements, while syntactically correct, can exhibit symptoms of bad design. By warning users about such symptoms, both the learning curve of students as well as productivity of SQL practitioners can be enhanced. Some errors include inconsistent conditions, lack of correlations in joins, unused tuple variables and the like. Here, we describe the semantic checker developed for DES, which applies several techniques. In particular, it applies abstraction with CLP solving, and specific algorithms for the different kind of errors. This proposal has been implemented in the deductive system DES and available at des.sourceforge.net.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2908</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[semantic-analysis-of-sql-statements-in-des-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="constraint-logic-programming"><![CDATA[Constraint Logic Programming]]></category>
		<category domain="post_tag" nicename="datalog"><![CDATA[Datalog]]></category>
		<category domain="post_tag" nicename="semantic-analysis"><![CDATA[Semantic Analysis]]></category>
		<category domain="post_tag" nicename="sql"><![CDATA[SQL]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper presents an on-going work that includes semantic analysis of SQL statements in the database system DES. Following Brass&Goldberg, SQL statements, while syntactically correct, can exhibit symptoms of bad design. By warning users about such symptoms, both the learning curve of students as well as productivity of SQL practitioners can be enhanced. Some errors include inconsistent conditions, lack of correlations in joins, unused tuple variables and the like. Here, we describe the semantic checker developed for DES, which applies several techniques. In particular, it applies abstraction with CLP solving, and specific algorithms for the different kind of errors. This proposal has been implemented in the deductive system DES and available at des.sourceforge.net.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-007.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-007.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Fernando Sáenz Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fernan@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/006]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Analysis of Rewriting-Based Systems as First-Order Theories (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/analysis-of-rewriting-based-systems-as-first-order-theories-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/analysis-of-rewriting-based-systems-as-first-order-theories-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Computational systems based on a first-order language that can be given a *canonical model* which captures provability in the corresponding calculus can often be seen as first-order theories S, and computational properties of such systems can be formulated as first-order sentences F that hold in such a canonical model of S. In this setting, standard results regarding the *preservation* of satisfiability of different classes of first-order sentences yield a number of interesting applications in program analysis. In particular, properties expressed as existentially quantified boolean combinations of atoms (for instance, a set of *unification problems*) can then be *disproved* by just finding an *arbitrary* model of the considered theory plus the *negation* of such a sentence. We show that rewriting-based systems fit into this approach. Many computational properties (e.g., infeasibility and non-joinability of critical pairs in (conditional) rewriting, non-loopingness, or the secure access to protected pages of a web site) can be investigated in this way. Interestingly, this semantic approach succeeds when specific techniques developed to deal with the aforementioned problems fail.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2909</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analysis-of-rewriting-based-systems-as-first-order-theories-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="logical-models"><![CDATA[Logical models]]></category>
		<category domain="post_tag" nicename="program-analysis"><![CDATA[Program analysis]]></category>
		<category domain="post_tag" nicename="rewriting-based-systems"><![CDATA[Rewriting-based systems]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Computational systems based on a first-order language that can be given a *canonical model* which captures provability in the corresponding calculus can often be seen as first-order theories S, and computational properties of such systems can be formulated as first-order sentences F that hold in such a canonical model of S. In this setting, standard results regarding the *preservation* of satisfiability of different classes of first-order sentences yield a number of interesting applications in program analysis. In particular, properties expressed as existentially quantified boolean combinations of atoms (for instance, a set of *unification problems*) can then be *disproved* by just finding an *arbitrary* model of the considered theory plus the *negation* of such a sentence. We show that rewriting-based systems fit into this approach. Many computational properties (e.g., infeasibility and non-joinability of critical pairs in (conditional) rewriting, non-loopingness, or the secure access to protected pages of a web site) can be investigated in this way. Interestingly, this semantic approach succeeds when specific techniques developed to deal with the aforementioned problems fail.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-008.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-008.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Lucas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[slucas@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/007]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Exercise in Proving Red-Black Trees Correct (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/an-exercise-in-proving-red-black-trees-correct-en-progreso/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-exercise-in-proving-red-black-trees-correct-en-progreso/</guid>
		<description></description>
		<content><![CDATA[Red-black trees are an efficient data structure that constitutes the basis for implementing maps, multimaps, sets and multisets, in the standard libraries of many programming languages. It achieves logarithmic costs for searching, inserting, and deleting keys, but keeping them balanced frequently requires to deal with a high number of cases. However, a variant called "Left-Leaning", due to Robert Sedgewick, reduces the number of cases to a few ones. We present here a functional version of these red-black trees and prove them correct with respect to a model-based specification, being the model of a red-black tree a set of elements. We have used the Dafny verification platform, which provides the programming language, the assertion language, and the verifier. The latter is an up-to-date SMT solver (Satisfiability Modulo Theories), which can deal with a rather large decidable fragment of the first-order logic.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2910</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-exercise-in-proving-red-black-trees-correct-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="balanced-trees"><![CDATA[Balanced Trees]]></category>
		<category domain="post_tag" nicename="data-structures"><![CDATA[Data Structures]]></category>
		<category domain="post_tag" nicename="formal-verification"><![CDATA[Formal Verification]]></category>
		<category domain="post_tag" nicename="verification-platforms"><![CDATA[verification platforms]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Red-black trees are an efficient data structure that constitutes the basis for implementing maps, multimaps, sets and multisets, in the standard libraries of many programming languages. It achieves logarithmic costs for searching, inserting, and deleting keys, but keeping them balanced frequently requires to deal with a high number of cases. However, a variant called "Left-Leaning", due to Robert Sedgewick, reduces the number of cases to a few ones. We present here a functional version of these red-black trees and prove them correct with respect to a model-based specification, being the model of a red-black tree a set of elements.

We have used the Dafny verification platform, which provides the programming language, the assertion language, and the verifier. The latter is an up-to-date SMT solver (Satisfiability Modulo Theories), which can deal with a rather large decidable fragment of the first-order logic.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-009.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-009.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ricardo Peña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ricardo@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/008]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Directions of Operational Termination (Trabajo original)</title>
		<link>https://biblioteca.sistedes.es/articulo/directions-of-operational-termination-original/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/directions-of-operational-termination-original/</guid>
		<description></description>
		<content><![CDATA[A theory S in a logic supplied with an inference system is operationally terminating if no goal has an infinite well-formed proof tree. Well-formed proof trees are those which an interpreter would incrementally build when trying to solve a condition at a time from left to right. For this reason, infinite well-formed proof trees have a unique infinite branch which is called the spine. This paper introduces the notion of a directed proof tree for S and a set of formulas Δ, which we call a direction. Intuitively, a direction Δ is intended to collect formulas that are infinitely often used in the spine of an infinite well-formed proof tree (which is then called Δ-directed) due to the repeated use of some specific inference rules. Then we introduce the notion of Δ-directed operational termination of a theory as the absence of Δ-directed proof trees. This new notion permits the definition of different termination properties which can be useful to distinguish different computational behaviors. It also gives a new characterization of operational termination of a (finite) theory S as the conjunction of the Δ-directed operational termination of S for each direction Δ in a (finite) set of directions.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2911</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[directions-of-operational-termination-original]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="general-logics"><![CDATA[General Logics]]></category>
		<category domain="post_tag" nicename="operational-termination"><![CDATA[Operational Termination]]></category>
		<category domain="post_tag" nicename="program-termination"><![CDATA[Program Termination]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A theory S in a logic supplied with an inference system is operationally terminating if no goal has an infinite well-formed proof tree. Well-formed proof trees are those which an interpreter would incrementally build when trying to solve a condition at a time from left to right. For this reason, infinite well-formed proof trees have a unique infinite branch which is called the spine. This paper introduces the notion of a directed proof tree for S and a set of formulas ?, which we call a direction. Intuitively, a direction ? is intended to collect formulas that are infinitely often used in the spine of an infinite well-formed proof tree (which is then called ?-directed) due to the repeated use of some specific inference rules. Then we introduce the notion of ?-directed operational termination of a theory as the absence of ?-directed proof trees. This new notion permits the definition of different termination properties which can be useful to distinguish different computational behaviors. It also gives a new characterization of operational termination of a (finite) theory S as the conjunction of the ?-directed operational termination of S for each direction ? in a (finite) set of directions.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-010.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-010.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Lucas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[slucas@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/009]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Event-driven Interval Temporal Logic for Hybrid Systems (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/an-event-driven-interval-temporal-logic-for-hybrid-systems-en-progreso/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-event-driven-interval-temporal-logic-for-hybrid-systems-en-progreso/</guid>
		<description></description>
		<content><![CDATA[Nowadays, hybrid systems are present in many crucial tasks of our daily life. The hybrid character derives from the merge of continuous and discrete dynamics that are intrinsically related. The verification of critical properties of hybrid systems is of special importance, but sometimes it is not feasible due to their inherent complexity. In the last few years, several model-based testing and runtime verification techniques have been proposed to support the verification and validation of hybrid systems. In this paper, we present an interval logic that is suitable for specifying properties of event-driven hybrid systems. We introduce the syntax and semantics of the logic, and propose an automatic mechanism to transform each logic formula into a network of timed automata that can act as observers of the property in each test case using the UPPAAL tool.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2912</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-event-driven-interval-temporal-logic-for-hybrid-systems-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="interval-temporal-logic"><![CDATA[interval temporal logic]]></category>
		<category domain="post_tag" nicename="timed-automata"><![CDATA[Timed automata]]></category>
		<category domain="post_tag" nicename="uppaal"><![CDATA[uppaal]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Nowadays, hybrid systems are present in many crucial tasks of our daily life. The hybrid character derives from the merge of continuous and discrete dynamics that are intrinsically related. The verification of critical properties of hybrid systems is of special importance, but sometimes it is not feasible due to their inherent complexity. In the last few years, several model-based testing and
runtime verification techniques have been proposed to support the verification and validation of hybrid systems. In this paper, we present an interval logic that is suitable for specifying properties of event-driven hybrid systems. We introduce the syntax and semantics of the logic, and propose an automatic mechanism to transform each logic formula into a network of timed automata that can act as observers of the property in each test case using the UPPAAL tool.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-011.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-011.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Maria del Mar Gallardo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[gallardo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Laura Panizo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[laurapanizo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/010]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Datalog Framework for Modeling Relationship-based Access Control Policies (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-datalog-framework-for-modeling-relationship-based-access-control-policies-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-datalog-framework-for-modeling-relationship-based-access-control-policies-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Relationships like friendship to limit access to resources have been part of social network applications since their beginnings. Describing access control policies in terms of relationships is not particular to social networks and it arises naturally in many situations. Hence, we have recently seen several proposals formalizing different Relationship-based Access Control (ReBAC) models. In this paper, we introduce a class of Datalog programs suitable for modeling ReBAC and argue that this class of programs, that we called ReBAC Datalog policies, provides a very general framework to specify and implement ReBAC policies. To support our claim, we first formalize the merging of two recent proposals for modeling ReBAC, one based on hybrid logic and the other one based on path regular expressions. We present extensions to handle negative authorizations and temporal policies. We describe mechanism for policy analysis, and then discuss the feasibility of using Datalog-based systems as implementations.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2913</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-datalog-framework-for-modeling-relationship-based-access-control-policies-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="datalog"><![CDATA[Datalog]]></category>
		<category domain="post_tag" nicename="relationship-based-access-control"><![CDATA[Relationship-based Access Control]]></category>
		<category domain="post_tag" nicename="security-and-privacy-policies"><![CDATA[Security and privacy policies]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Relationships like friendship to limit access to resources have been part of social network applications since their beginnings. Describing access control policies in terms of relationships is not particular to social networks and it arises naturally in many situations. Hence, we have recently seen several proposals formalizing different Relationship-based Access Control (ReBAC) models. In this paper, we introduce a class of Datalog programs suitable for modeling
ReBAC and argue that this class of programs, that we called ReBAC Datalog policies, provides a very general framework to specify and implement ReBAC policies. To support our claim, we first formalize the merging of two recent proposals for modeling ReBAC, one based on hybrid logic and the other one based on path regular expressions. We present extensions to handle negative authorizations and temporal policies. We describe mechanism for policy analysis, and then discuss the feasibility of using Datalog-based systems as implementations.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-012.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-012.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Edelmira Pasarella]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[edelmira@lsi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jorge Lobo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jorge.lobo@upf.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Institució Catalana de Recerca i Estudis Avançats (ICREA)-Universitat Pompeu Fabra, Barcelona, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/011]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>The 2D Dependency Pair Framework for conditional rewrite systems (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/the-2d-dependency-pair-framework-for-conditional-rewrite-systems-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/the-2d-dependency-pair-framework-for-conditional-rewrite-systems-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Different termination properties of conditional term rewriting systems have been recently described emphasizing the bidimensional nature of the termination behavior of conditional rewriting. The absence of infinite sequences of rewriting steps (termination in the usual sense), provides the horizontal dimension. The absence of infinitely many attempts to launch the subsidiary processes that are required to check the rule’s condition and perform a single rewriting step has been called V-termination and provides the vertical dimension. We have characterized these properties by means of appropriate notions of dependency pairs and dependency chains. In this paper we introduce a 2D Dependency Pair Framework for automatically proving and disproving all these termination properties. Our implementation of the framework as part of the termination tool MU-TERM and the benchmarks obtained so far suggest that the 2D Dependency Pair Framework is currently the most powerful technique for proving operational termination of conditional term rewriting systems.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2914</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[the-2d-dependency-pair-framework-for-conditional-rewrite-systems-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="conditional-term-rewriting"><![CDATA[Conditional term rewriting]]></category>
		<category domain="post_tag" nicename="dependency-pairs"><![CDATA[dependency pairs]]></category>
		<category domain="post_tag" nicename="operational-termination"><![CDATA[Operational Termination]]></category>
		<category domain="post_tag" nicename="program-analysis"><![CDATA[Program analysis]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Different termination properties of conditional term rewriting systems have been recently described emphasizing the bidimensional nature of the termination behavior of conditional rewriting. The absence of infinite sequences of rewriting steps (termination in the usual sense), provides the horizontal dimension. The absence of infinitely many attempts to launch the subsidiary processes that are required to check the rule’s condition and perform a single rewriting step has been called V-termination and provides the vertical dimension. We have characterized these properties by means of appropriate notions of dependency pairs and dependency chains. In this paper we introduce a 2D Dependency Pair Framework for automatically proving and disproving all these termination properties. Our implementation of the framework as part of the termination tool MU-TERM and the benchmarks obtained so far suggest that the 2D Dependency Pair Framework is currently the most powerful technique for proving operational termination of conditional term rewriting systems.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-013.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-013.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Lucas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[slucas@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Meseguer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[meseguer@cs.uiuc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Illinois at Urbana-Champaign - United States]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Raúl Gutiérrez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[rgutierrez11@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/012]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Efficient Proximity-based Unification Algorithm (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/an-efficient-proximity-based-unification-algorithm-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-efficient-proximity-based-unification-algorithm-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Unification is a central concept in deductive systems based on the resolution principle. Recently, we introduced a new weak unification algorithm based on proximity relations (i.e., reflexive, symmetric, fuzzy binary relations). Proximity relations are able to manage vague or imprecise information and, in combination with the unification algorithm, allow certain forms of approximate reasoning in a logic programming framework. In this paper, we present a reformulation of the weak unification algorithm and an elaborated method to implement it efficiently. [This work has been accepted for its presentation at the 27th IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2018)]]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2915</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-efficient-proximity-based-unification-algorithm-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="fuzzy-logic-programming"><![CDATA[Fuzzy Logic Programming]]></category>
		<category domain="post_tag" nicename="fuzzy-prolog"><![CDATA[Fuzzy Prolog]]></category>
		<category domain="post_tag" nicename="proximity-relations"><![CDATA[Proximity Relations]]></category>
		<category domain="post_tag" nicename="weak-unification"><![CDATA[Weak Unification]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Unification is a central concept in deductive systems based on the resolution principle. Recently, we introduced a new weak unification algorithm based on proximity relations (i.e., reflexive, symmetric, fuzzy binary relations). Proximity relations are able to manage vague or imprecise information and, in combination with the unification algorithm, allow certain forms of approximate reasoning in a logic programming framework. In this paper, we present a reformulation of the weak unification algorithm and an elaborated method to implement it efficiently.

[This work has been accepted for its presentation at the 27th IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2018)]]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-014.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-014.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pascual Julián Iranzo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pascual.julian@uclm.es ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando Sáenz Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fernan@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/013]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Institutions for navigational logics for graphical structures (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/institutions-for-navigational-logics-for-graphical-structures-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/institutions-for-navigational-logics-for-graphical-structures-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[We show that a Navigational Logic, i.e., a logic to express properties about graphs and about paths in graphs is a semi-exact institution. In this way, we can use a number of operations to structure and modularize our specifications. Moreover, using the properties of our institution, we also show how to structure single formulas, which in our formalism could be quite complex. Article in press in Theoretical Computer Science (2018) https://doi.org/10.1016/j.tcs.2018.02.031]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2916</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[institutions-for-navigational-logics-for-graphical-structures-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="graph-logics"><![CDATA[Graph logics]]></category>
		<category domain="post_tag" nicename="institutions"><![CDATA[Institutions]]></category>
		<category domain="post_tag" nicename="navigational-logics"><![CDATA[Navigational logics]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We show that a Navigational Logic, i.e., a logic to express properties about graphs and about paths in graphs is a semi-exact institution. In this way, we can use a number of operations to structure and modularize our specifications. Moreover, using the properties of our institution, we also show how to structure single formulas, which in our formalism could be quite complex.

Article in press in Theoretical Computer Science (2018)
https://doi.org/10.1016/j.tcs.2018.02.031]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-015.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-015.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Fernando Orejas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[orejas@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Elvira Pino ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pino@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Marisa Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[marisa.navarro@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU) - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Leen Lambers]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Leen.Lambers@hpi.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Hasso Plattner Institut, University of Potsdam - Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/014]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Behaviour Preservation across Code Versions in Erlang (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/behaviour-preservation-across-code-versions-in-erlang-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/behaviour-preservation-across-code-versions-in-erlang-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[In any alive and non-trivial program, the source code naturally evolves along the lifecycle for many reasons such as the implementation of new functionality, the optimisation of a bottle-neck, the refactoring of an obscure function, etc. Frequently, these code changes affect various different functions and modules, so it can be difficult to know whether the correct behaviour of the previous version has been preserved in the new version. In this paper, we face this problem in the context of the Erlang language, where most developers rely on a previously defined test suite to check the behaviour preservation. We propose an alternative approach to automatically obtain a test suite that specifically focusses on comparing the old and new versions of the code. Our test case generation is directed by a sophisticated combination of several already existing tools such as TypEr, CutEr, and PropEr; and it introduces novel ideas such as allowing the programmer to choose one or more expressions of interest that must preserve the behaviour, or the recording of the sequences of values to which those expressions are evaluated. All the presented work has been implemented in an open-source tool that is publicly available on GitHub.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2917</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[behaviour-preservation-across-code-versions-in-erlang-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="automated-regression-testing"><![CDATA[Automated regression testing]]></category>
		<category domain="post_tag" nicename="code-evolution-control"><![CDATA[Code evolution control]]></category>
		<category domain="post_tag" nicename="tracing"><![CDATA[Tracing]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In any alive and non-trivial program, the source code naturally evolves along the lifecycle for many reasons such as the implementation of new functionality, the optimisation of a bottle-neck, the refactoring of an obscure function, etc. Frequently, these code changes affect various different functions and modules, so it can be difficult to know whether the correct behaviour of the previous version has been preserved in the new version. In this paper, we face this problem in the context of the Erlang language, where most developers rely on a previously defined test suite to check the behaviour preservation. We propose an alternative approach to automatically obtain a test suite that specifically focusses on comparing the old and new versions of the code. Our test case generation is directed by a sophisticated combination of several already existing tools such as TypEr, CutEr, and PropEr; and it introduces novel ideas such as allowing the programmer to choose one or more expressions of interest that must preserve the behaviour, or the recording of the sequences of values to which those expressions are evaluated. All the presented work has been implemented in an open-source tool that is publicly available on GitHub.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-016.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-016.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Insa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[dinsa@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València  - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Pérez Rubio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sergio.perez.rubio@hotmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València  - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Josep Silva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jsilva@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València  - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Salvador Tamarit]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[stamarit@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València  - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/015]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modeling Systems and Proving their Correctness with Event-B and Rodin (Tutorial)</title>
		<link>https://biblioteca.sistedes.es/articulo/modeling-systems-and-proving-their-correctness-with-event-b-and-rodin-tutorial/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/modeling-systems-and-proving-their-correctness-with-event-b-and-rodin-tutorial/</guid>
		<description></description>
		<content><![CDATA[Event-B is a formal development method. It can be used to model and verify correctness of sequential, concurrent, and reactive systems. It uses (infinite) discrete transition systems to capture how the model evolves and first-order logic and typed set theory to express the desirable properties of the system. The proofs that these properties hold are performed using sequent calculus. There are deduction rules specific for useful theories. Event-B is however is not restricted to classical set-theoretical notations and the sequent calculus: it includes notations for defining transitions over states of the model which resembles a programming language, and a rich mathematical toolkit (including operations and relations on sets and functions) to build complex models easily.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2918</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modeling-systems-and-proving-their-correctness-with-event-b-and-rodin-tutorial]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="correctness-by-construction"><![CDATA[Correctness by Construction]]></category>
		<category domain="post_tag" nicename="formal-proofs"><![CDATA[Formal proofs]]></category>
		<category domain="post_tag" nicename="rigorous-software-development"><![CDATA[Rigorous software development]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Event-B is a formal development method. It can be used to model and verify correctness of sequential, concurrent, and reactive systems. It uses (infinite) discrete transition systems to capture how the model evolves and first-order logic and typed set theory to express the desirable properties of the system. The proofs that these properties hold are performed using sequent calculus. There are deduction rules specific for useful theories. Event-B is however is
not restricted to classical set-theoretical notations and the sequent calculus: it includes notations for defining transitions over states of the model which resembles a programming language, and a rich mathematical toolkit (including operations and relations on sets and functions) to build complex models easily.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-017.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-017.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel Carro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mcarro@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Technical University of Madrid (UPM) and IMDEA Software Institute - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/016]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Efficient Characterization of Petri Net Solvable Binary Words (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/an-efficient-characterization-of-petri-net-solvable-binary-words-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-efficient-characterization-of-petri-net-solvable-binary-words-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[We present a simple characterization of the set of Petri net solvable binary words. It states that they are exactly the extensions of the prefixes of Petri net cyclic solvable words, by some prefix x^k, where x is any letter of the binary alphabet being considered, and k is any natural number. We derive several consequences of this characterization which, in a way, shows that the set of solvable words is smaller than expected. Therefore, the existing conjecture that all of them can be generated by quite simple net is not only confirmed, but indeed reinforced. As a byproduct of the characterization, we also present a linear time algorithm for deciding whether a binary word is solvable. The key idea is that the connection with the cyclic solvable words induces certain structural regularity. Therefore, one just needs to look for possible irregularities, which can be done in a structural way, resulting in a rather surprising linearity of the decision algorithm. Finally, we employ the obtained results to provide a characterization of reversible binary transition systems. Artículo aceptado para su presentación en Petri Nets 2018 - The 39th International Conference on Applications and Theory of Petri Nets and Concurrency. Bratislava, Slovakia, June 24-29, 2018. Los "proceedings" serán publicados en el Volumen 10877 de la serie LNCS de Springer.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2919</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-efficient-characterization-of-petri-net-solvable-binary-words-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="binary-transition-systems"><![CDATA[Binary transition systems]]></category>
		<category domain="post_tag" nicename="binary-words"><![CDATA[Binary words]]></category>
		<category domain="post_tag" nicename="petri-nets"><![CDATA[Petri nets]]></category>
		<category domain="post_tag" nicename="reversibility"><![CDATA[Reversibility]]></category>
		<category domain="post_tag" nicename="word-solvability"><![CDATA[Word solvability]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We present a simple characterization of the set of Petri net solvable binary words. It states that they are exactly the extensions of the prefixes of Petri net cyclic solvable words, by some prefix x^k, where x is any letter of the binary alphabet being considered, and k is any natural number. We derive several consequences of this characterization which, in a way, shows that the set of solvable words is smaller than expected. Therefore, the existing conjecture that all of them can be generated by quite simple net is not only confirmed, but indeed reinforced. As a byproduct of the characterization, we also present a linear time algorithm for deciding whether a binary word is solvable. The key
idea is that the connection with the cyclic solvable words induces certain
structural regularity. Therefore, one just needs to look for possible irregularities, which can be done in a structural way, resulting in a rather surprising linearity of the decision algorithm. Finally, we employ the obtained results to provide a characterization of reversible binary transition systems.

Artículo aceptado para su presentación en Petri Nets 2018 - The 39th International Conference on Applications and Theory of Petri Nets and Concurrency. Bratislava, Slovakia, June 24-29, 2018.

Los "proceedings" serán publicados en el Volumen 10877 de la serie LNCS de Springer.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-018.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-018.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David de Frutos Escrig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[defrutos@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Maciej Koutny]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[maciej.koutny@ncl.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Newcastle University - United Kingdom]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Lukasz Mikulski]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lukasz.mikulski@mat.umk.pl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Nicolaus Copernicus University - Torun - Poland]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/017]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una librería para inteligencia de enjambre basada en la programación funcional (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/una-libreria-para-inteligencia-de-enjambre-basada-en-la-programacion-funcional-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/una-libreria-para-inteligencia-de-enjambre-basada-en-la-programacion-funcional-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[En este trabajo presentamos una librerÌa de esqueletos paralelos para manejar metaheurÌsticas basadas en inteligencia de enjambre. La librerÌa está implementada utilizando el lenguaje de programación funcional paralelo Eden, una extensión del lenguaje funcional Haskell. Gracias al orden superior presente en el lenguaje funcional, se simplifican las tareas de desarrollar código genérico, facilitando también la comparación entre distintas metaheurÌsticas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2920</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-libreria-para-inteligencia-de-enjambre-basada-en-la-programacion-funcional-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="functional-programming"><![CDATA[functional programming]]></category>
		<category domain="post_tag" nicename="metaheuristics"><![CDATA[Metaheuristics]]></category>
		<category domain="post_tag" nicename="parallel-programming"><![CDATA[Parallel programming]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[IIn this paper we present a library of parallel skeletons to deal with swarm intelligence metaheuristics. The library is implemented using the parallel functional language Eden, an extension of the sequential functional language Haskell. Due to the higher-order nature of functional languages, we simplify the task of writing generic code, and also the task of comparing different strategies. The paper illustrates how to develop new skeletons and presents empirical results.

The complete version of the paper was accepted for publication in IWANN 2017. The paper can be obtained at
https://link.springer.com/chapter/10.1007%2F978-3-319-59153-7_1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-019.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-019.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Fernando Rubio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fernando@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alberto de la Encina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[albertoe@sip.ucm.es ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pablo Rabanal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[prabanal@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ismael Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[isrodrig@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/018]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Context-based Model Checking using SMT-solvers (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/context-based-model-checking-using-smt-solvers-en-progreso/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/context-based-model-checking-using-smt-solvers-en-progreso/</guid>
		<description></description>
		<content><![CDATA[In this paper we propose a new idea for the implementation of symbolic model checking. Our pro- posal takes advantage of two technologies. First, SMT-solvers as efficient auxiliary tools to perform a large proportion of the computational task. Second, the context-based tableau that is especially well suited for providing certificates of proved properties, as well as counterexamples of disproved properties. We mainly introduce the algorithm to be implemented, along with illustrative examples.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2921</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[context-based-model-checking-using-smt-solvers-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="model-checking"><![CDATA[Model checking]]></category>
		<category domain="post_tag" nicename="sat"><![CDATA[SAT]]></category>
		<category domain="post_tag" nicename="smt"><![CDATA[SMT]]></category>
		<category domain="post_tag" nicename="solvers"><![CDATA[Solvers]]></category>
		<category domain="post_tag" nicename="tableux"><![CDATA[Tableux]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper we propose a new idea for the implementation of symbolic model checking. Our pro- posal takes advantage of two technologies. First, SMT-solvers as efficient auxiliary tools to perform a large proportion of the computational task. Second, the context-based tableau that is especially well suited for providing certificates of proved properties, as well as counterexamples of disproved properties. We mainly introduce the algorithm to be implemented, along with illustrative examples.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-020.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-020.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alex Abuin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aabuin@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Ik4-Ikerlan - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Unai Díaz de Cerio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[udiazcerio@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Ik4-Ikerlan - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Montserrat Hermo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[montserrat.hermo@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU) - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Paqui Lucio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[paqui.lucio@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU) - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/019]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Constrained Dynamic Partial Order Reduction (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/constrained-dynamic-partial-order-reduction-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/constrained-dynamic-partial-order-reduction-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[The cornerstone of dynamic partial order reduction (DPOR) is the notion of independence that is used to decide whether each pair of concurrent events p and t are in a race and thus both p·t and t·p must be explored. We present constrained dynamic partial order reduction (CDPOR), an extension of the DPOR framework which is able to avoid redundant explorations based on the notion of conditional independence —the execution of p and t commutes only when certain independence constraints (ICs) are satisfied. ICs can be declared by the programmer, but importantly, we present a novel SMT-based approach to automatically synthesize ICs in a static pre-analysis. A unique feature of our approach is that we have succeeded to exploit ICs within the state-of-the-art DPOR algorithm, achieving exponential reductions over existing implementations.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2922</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[constrained-dynamic-partial-order-reduction-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="conditional-independence"><![CDATA[Conditional Independence]]></category>
		<category domain="post_tag" nicename="dynamic-partial-order-reduction"><![CDATA[Dynamic Partial Order Reduction]]></category>
		<category domain="post_tag" nicename="model-checking"><![CDATA[Model checking]]></category>
		<category domain="post_tag" nicename="smt"><![CDATA[SMT]]></category>
		<category domain="post_tag" nicename="static-analysis"><![CDATA[Static Analysis]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The cornerstone of dynamic partial order reduction (DPOR) is the notion of independence that is used to decide whether each pair of concurrent events p and t are in a race and thus both p·t and t·p must be explored. We present constrained dynamic partial order reduction (CDPOR), an extension of the DPOR framework which is able to avoid redundant explorations based on the notion of conditional independence —the execution of p and t commutes only when certain independence constraints (ICs) are satisfied. ICs can be declared by the programmer, but importantly, we present a novel SMT-based approach to automatically synthesize ICs in a static pre-analysis. A unique feature of our
approach is that we have succeeded to exploit ICs within the state-of-the-art DPOR algorithm, achieving exponential reductions over existing implementations.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-021.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-021.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/020]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Fuzzy Queries of Social Networks involving Sentiment Analysis and Topic Detection (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/fuzzy-queries-of-social-networks-involving-sentiment-analysis-and-topic-detection-en-progreso/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/fuzzy-queries-of-social-networks-involving-sentiment-analysis-and-topic-detection-en-progreso/</guid>
		<description></description>
		<content><![CDATA[Social networks have become a source of data which are of interest in all areas, and their querying and analysis is a hot topic in computer science. Our research group has developed a fuzzy extension of the Semantic Web query language SPARQL, called FSA-SPARQL (Fuzzy Sets and Aggregators based SPARQL). This extension provides mechanisms to express fuzzy queries against RDF data. FSA-SPARQL works with social networks. With this aim, FSA-SPARQL enables the transformation and fuzzification of social network API data. Fuzzification of social networks data is automatic and user-defined enabling a wide range of mechanisms for ranking and categorization, including sentiment analysis and topic detection. As case study, FSA-SPARQL has been used to query three well-known social networks: Twitter, Foursquare and TMDb.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2923</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[fuzzy-queries-of-social-networks-involving-sentiment-analysis-and-topic-detection-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="fuzzy-logic"><![CDATA[Fuzzy Logic]]></category>
		<category domain="post_tag" nicename="semantic-web"><![CDATA[Semantic Web]]></category>
		<category domain="post_tag" nicename="social-networks"><![CDATA[Social Networks]]></category>
		<category domain="post_tag" nicename="sparql"><![CDATA[SPARQL]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Social networks have become a source of data which are of interest in all areas, and their querying and analysis is a hot topic in computer science. Our research group has developed a fuzzy extension of the Semantic Web query language SPARQL, called FSA-SPARQL (Fuzzy Sets and Aggregators based SPARQL). This extension provides mechanisms to express fuzzy queries against RDF data. FSA-SPARQL works with social networks. With this aim, FSA-SPARQL enables the transformation and fuzzification of social network API data. Fuzzification of social networks data is automatic and user-defined enabling a wide range of mechanisms for ranking and categorization, including sentiment analysis and topic detection. As case study, FSA-SPARQL has been used to query three well-known social networks: Twitter, Foursquare and TMDb.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-022.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-022.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús M. Almendros Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalmen@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Almeria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Becerra Terón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[abecerra@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Almeria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ginés Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gines.moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/021]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An extension of TRIANGLE testbed with model-based testing (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/an-extension-of-triangle-testbed-with-model-based-testing-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-extension-of-triangle-testbed-with-model-based-testing-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Traditional testing methods for mobile apps focus on detecting execution errors. However, the evolution of mobile networks towards 5G will require additional support for app developers to ensure also the performance and user-experience. Manual testing in a number of scenarios is not enough to satisfy the expectations of the apps final users. This paper presents the testing framework developed in the TRIANGLE project1 that integrates a complete mobile network testbed and a model-based testing approach, which is based on model checking, to automatically evaluate the apps performance in different network scenarios.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2924</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-extension-of-triangle-testbed-with-model-based-testing-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mobile-network-testbed"><![CDATA[mobile network testbed]]></category>
		<category domain="post_tag" nicename="model-checking"><![CDATA[Model checking]]></category>
		<category domain="post_tag" nicename="model-based-testing"><![CDATA[model-based testing]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Traditional testing methods for mobile apps focus on detecting execution errors. However, the evolution of mobile networks towards 5G will require additional support for app developers to ensure also the performance and user-experience. Manual testing in a number of scenarios is not enough to satisfy the expectations of the apps final users. This paper presents the testing framework developed in the TRIANGLE project1 that integrates a complete mobile network testbed and a model-based testing approach, which is based on model checking, to automatically evaluate the apps performance in different network scenarios.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-024.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-024.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Laura Panizo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[laurapanizo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Almudena Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[almudiaz@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Bruno García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[bgarcia@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/022]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Tool Demonstration: Testing JSON Web Services Using Jsongen (Demostración)</title>
		<link>https://biblioteca.sistedes.es/articulo/tool-demonstration-testing-json-web-services-using-jsongen-demo/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/tool-demonstration-testing-json-web-services-using-jsongen-demo/</guid>
		<description></description>
		<content><![CDATA[This article describes a tool, jsongen, which permits testing behavioural aspects of Web Services that communicate using the JSON data format. Provided a characterisation of the JSON data as a JSON schema, the jsongen tool will:(i) automatically derive a QuickCheck (the property-based testing tool)generator which can generate an infinite number of JSON values that validate against the schema, and (ii) provides a generic QuickCheck state machine which is capable of following the (hyper)links documented in the JSON schema, to automatically explore the web service. The default behaviour of the state machine can be easily customized to include web service specific checks. The approach is demonstrated by applying it to the task of testing a simplified web service for banking.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2925</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[tool-demonstration-testing-json-web-services-using-jsongen-demo]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="analysis-tools"><![CDATA[Analysis tools]]></category>
		<category domain="post_tag" nicename="json"><![CDATA[JSON]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<category domain="post_tag" nicename="web-services"><![CDATA[web services]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This article describes a tool, jsongen, which permits testing behavioural aspects of Web Services that communicate using the JSON data format. Provided a characterisation of the JSON data as a JSON schema, the jsongen tool will:
(i) automatically derive a QuickCheck (the property-based testing tool)
generator which can generate an infinite number of JSON values that validate against the schema, and (ii) provides a generic QuickCheck state machine which is capable of following the (hyper)links documented in the JSON schema, to automatically explore the web service. The default behaviour of the state machine can be easily customized to include web service specific checks. The approach is demonstrated by applying it to the task of testing a simplified web service for banking.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-025.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-025.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ignacio Ballesteros]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ignacioballesterosgonzalez@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Luis Eduardo Bueso de Barrio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[luiseduardo.bueso.debarrio@alumnos.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Lars-Ake Fredlund]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lfredlund@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Julio Mariño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jmarino@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/023]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Webpage Menu Detection Based on DOM (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/webpage-menu-detection-based-on-dom-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/webpage-menu-detection-based-on-dom-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[One of the key elements of a website is Web menus, which provide fundamental information about the topology of the own website. Menu detection is useful for humans, but also for crawlers and indexers because the menu provides essential information about the structure and contents of a website. For humans, identifying the main menu of a website is a relatively easy task. However, for computer tools identifying the menu is not trivial at all and, in fact, it is still a challenging unsolved problem. In this work, we propose a novel method for automatic Web menu detection that works at the level of DOM.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2926</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[webpage-menu-detection-based-on-dom-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="information-retrieval"><![CDATA[Information retrieval]]></category>
		<category domain="post_tag" nicename="menu-detection"><![CDATA[Menu detection]]></category>
		<category domain="post_tag" nicename="web-template-detection"><![CDATA[Web template detection]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[One of the key elements of a website is Web menus, which provide fundamental information about the topology of the own website. Menu detection is useful for humans, but also for crawlers and indexers because the menu provides essential information about the structure and contents of a website. For humans, identifying the main menu of a website is a relatively easy task. However, for computer tools identifying the menu is not trivial at all and, in fact, it is still a challenging unsolved problem. In this work, we propose a novel method for automatic Web menu detection that works at the level of DOM.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-026.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-026.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julián Alarte Aleixandre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[julianalarte@gmail.com ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València  - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David Insa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[dinsa@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València  - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Josep Silva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jsilva@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València  - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/024]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Smart Bound Selection for the Verification of UML/OCL Class Diagrams (YA PUBLICADO)</title>
		<link>https://biblioteca.sistedes.es/articulo/smart-bound-selection-for-the-verification-of-uml-ocl-class-diagrams-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/smart-bound-selection-for-the-verification-of-uml-ocl-class-diagrams-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Correctness of UML class diagrams annotated with OCL constraints can be checked using bounded verification techniques, e.g., SAT or constraint programming (CP) solvers. Bounded verification detects faults efficiently but, on the other hand, the absence of faults does not guarantee a correct behavior outside the bounded domain. Hence, choosing suitable bounds is a non-trivial process as there is a trade-off between the verification time (faster for smaller domains) and the confidence in the result (better for larger domains). Unfortunately, bounded verification tools provide little support in the bound selection process.In this paper, we present a technique that can be used to (i) automatically infer verification bounds whenever possible, (ii) tighten a set of bounds proposed by the user and (iii) guide the user in the bound selection process. This approach may increase the usability of UML/OCL bounded verification tools and improve the efficiency of the verification process.This paper has been published in IEEE Transactions on Software Engineering[http://dx.doi.org/10.1109/TSE.2017.2777830]]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2927</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[smart-bound-selection-for-the-verification-of-uml-ocl-class-diagrams-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="class-diagram"><![CDATA[Class Diagram]]></category>
		<category domain="post_tag" nicename="constraint-propagation"><![CDATA[Constraint Propagation]]></category>
		<category domain="post_tag" nicename="formal-verification"><![CDATA[Formal Verification]]></category>
		<category domain="post_tag" nicename="ocl"><![CDATA[OCL]]></category>
		<category domain="post_tag" nicename="sat"><![CDATA[SAT]]></category>
		<category domain="post_tag" nicename="uml"><![CDATA[UML]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Correctness of UML class diagrams annotated with OCL constraints can be checked using bounded verification techniques, e.g., SAT or constraint programming (CP) solvers. Bounded verification detects faults efficiently but, on the other hand, the absence of faults does not guarantee a correct behavior outside the bounded domain. Hence, choosing suitable bounds is a non-trivial process as there is a trade-off between the verification time (faster for smaller domains) and the confidence in the result (better for larger domains). Unfortunately, bounded verification tools provide little support in the bound selection process.

In this paper, we present a technique that can be used to (i) automatically infer verification bounds whenever possible, (ii) tighten a set of bounds proposed by the user and (iii) guide the user in the bound selection process. This approach may increase the usability of UML/OCL bounded verification tools and improve the efficiency of the verification process.

This paper has been published in IEEE Transactions on Software Engineering
[http://dx.doi.org/10.1109/TSE.2017.2777830]]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-001.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-001.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Robert Clarisó]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rclariso@uoc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Oberta de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carlos A. González]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[carlos.gonzalez@uni.lu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[SnT Centre for Security, Reliability and Trust - Luxembourg]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jordi Cabot]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jordi.cabot@icrea.cat]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ICREA - UOC (Internet interdisciplinary institute) - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/001]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>ARTICULO RELEVANTE:IoT–TEG: Test event generator system</title>
		<link>https://biblioteca.sistedes.es/articulo/articulo-relevanteiot-teg-test-event-generator-system/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/articulo-relevanteiot-teg-test-event-generator-system/</guid>
		<description></description>
		<content><![CDATA[Internet of Things (IoT) has been paid increasingly attention by the government, academe and industry all over the world. One of the main drawbacks of the IoT systems is the amount of information they have to handle. This information arrives as events that need to be processed in real time in order to make correct decisions. Given that processing the data is crucial, testing the IoT systems that will manage that information is required. In order to test IoT systems, it is necessary to generate a huge number of events with specific structures and values to test the functionalities required by these systems. As this task is very hard and very prone to error if done by hand, this paper addresses the automated generation of appropriate events for testing. For this purpose, a general specification to define event types and its representation are proposed and an event generator is developed based on this definition. Thanks to the adaptability of the proposed specification, the event generator can generate events of an event type, or events which combine the relevant attributes of several event types. Results from experiments and real-world tests show that the developed system meets the demanded requirements.Journal of Systems and Software, JSS Special Issue on Software Reliability EngineeringImpact factor: 2,444 (Q1)Available online 20 June 2017DOI: https://doi.org/10.1016/j.jss.2017.06.037]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2928</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[articulo-relevanteiot-teg-test-event-generator-system]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="complex-event-processing"><![CDATA[Complex Event Processing]]></category>
		<category domain="post_tag" nicename="event-generator"><![CDATA[Event generator]]></category>
		<category domain="post_tag" nicename="event-type-definition"><![CDATA[Event type definition]]></category>
		<category domain="post_tag" nicename="internet-of-things"><![CDATA[Internet of Things]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Internet of Things (IoT) has been paid increasingly attention by the government, academe and industry all over the world. One of the main drawbacks of the IoT systems is the amount of information they have to handle. This information arrives as events that need to be processed in real time in order to make correct decisions. Given that processing the data is crucial, testing the IoT systems that will manage that information is required. In order to test IoT systems, it is necessary to generate a huge number of events with specific structures and values to test the functionalities required by these systems. As this task is very hard and very prone to error if done by hand, this paper addresses the automated generation of appropriate events for testing. For this purpose, a general specification to define event types and its representation are proposed and an event generator is developed based on this definition. Thanks to the adaptability of the proposed specification, the event generator can generate events of an event type, or events which combine the relevant attributes of several event types. Results from experiments and real-world tests show that the developed system meets the demanded requirements.

Journal of Systems and Software, JSS Special Issue on Software Reliability Engineering
Impact factor: 2,444 (Q1)
Available online 20 June 2017
DOI: https://doi.org/10.1016/j.jss.2017.06.037]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-002.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-002.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Lorena Gutiérrez-Madroñal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[lorena.gutierrez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Cadiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan José Domínguez-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanjose.dominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Cadiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/002]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Practical Update Management in Ontology-based Data Access (YA PUBLICADO)</title>
		<link>https://biblioteca.sistedes.es/articulo/practical-update-management-in-ontology-based-data-access-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/practical-update-management-in-ontology-based-data-access-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Ontology-based Data Access (OBDA) is gaining importance both scientifically and practically. However, little attention has been paid so far to the problem of updating OBDA systems. This is an essential issue if we want to be able to cope with modifications of data both at the ontology and at the source level, while maintaining the independence of the data sources. In this paper, we propose mechanisms to properly handle updates in this context. We show that updating data both at the ontology and source level is first-order rewritable. We also provide a practical implementation of such updating mechanisms based on non-recursive Datalog.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2929</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[practical-update-management-in-ontology-based-data-access-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="dl-lite"><![CDATA[DL-Lite]]></category>
		<category domain="post_tag" nicename="obda"><![CDATA[OBDA]]></category>
		<category domain="post_tag" nicename="updates"><![CDATA[updates]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Ontology-based Data Access (OBDA) is gaining importance both scientifically and practically. However, little attention has been paid so far to the problem of updating OBDA systems. This is an essential issue if we want to be able to cope with modifications of data both at the ontology and at the source level, while maintaining the independence of the data sources. In this paper, we propose mechanisms to properly handle updates in this context. We show that updating data both at the ontology and source level is first-order rewritable. We also provide a practical implementation of such updating mechanisms based on non-recursive Datalog.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-003.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-003.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Giuseppe De Giacomo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[degiacomo@dis.uniroma1.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Sapienza University of Rome - Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Domenico Lembo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[lembo@dis.uniroma1.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Sapienza University of Rome - Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Xavier Oriol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[xoriol@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Domenico Fabio Savo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[savo@dis.uniroma1.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Sapienza University of Rome - Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Ernest Teniente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[teniente@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/003]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>ARTICULO RELEVANTE: Metamorphic Testing of RESTful Web APIs</title>
		<link>https://biblioteca.sistedes.es/articulo/articulo-relevante-metamorphic-testing-of-restful-web-apis/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/articulo-relevante-metamorphic-testing-of-restful-web-apis/</guid>
		<description></description>
		<content><![CDATA[S. Segura, J. A. Parejo, J. Troya and A. Ruiz-Cortés, "Metamorphic Testing of RESTful Web APIs" in IEEE Transactions on Software Engineering, Oct 2017 (online) vol. PP, no. 99, pp. 1-1. https://doi.org/10.1109/TSE.2017.2764464Aceptado para ser presentado en ICSE 2018 en la categoría de journal-first: https://www.icse2018.org/track/icse-2018-Journal-first-papers#event-overview166 lecturas en ResearchGate desde su publicación (118 en IEEE Xplore).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2930</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[articulo-relevante-metamorphic-testing-of-restful-web-apis]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="metamorphic-testing"><![CDATA[metamorphic testing]]></category>
		<category domain="post_tag" nicename="oracle-problem"><![CDATA[oracle problem]]></category>
		<category domain="post_tag" nicename="web-apis"><![CDATA[Web APIs]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[S. Segura, J. A. Parejo, J. Troya and A. Ruiz-Cortés, "Metamorphic Testing of RESTful Web APIs" in IEEE Transactions on Software Engineering, Oct 2017 (online) vol. PP, no. 99, pp. 1-1. https://doi.org/10.1109/TSE.2017.2764464

Aceptado para ser presentado en ICSE 2018 en la categoría de journal-first: https://www.icse2018.org/track/icse-2018-Journal-first-papers#event-overview

166 lecturas en ResearchGate desde su publicación (118 en IEEE Xplore).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-004.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-004.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Antonio Parejo Maestre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[japarejo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Troya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jtroya@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Identification and analysis of the elements required to manage technical debt by means of a systematic mapping study (Artículo relevante)</title>
		<link>https://biblioteca.sistedes.es/articulo/identification-and-analysis-of-the-elements-required-to-manage-technical-debt-by-means-of-a-systematic-mapping-study-articulo-relevante/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/identification-and-analysis-of-the-elements-required-to-manage-technical-debt-by-means-of-a-systematic-mapping-study-articulo-relevante/</guid>
		<description></description>
		<content><![CDATA[Artículo publicado en Journal of Systems and Software (JSS). JSS es clasificada como Q1 en JCR 2017. @article{FERNANDEZSANCHEZ201722,title = "Identification and analysis of the elements required to manage technical debt by means of a systematic mapping study",journal = "Journal of Systems and Software",volume = "124",pages = "22 - 38",year = "2017",issn = "0164-1212",doi = "https://doi.org/10.1016/j.jss.2016.10.018",url = "http://www.sciencedirect.com/science/article/pii/S0164121216302138",author = "Carlos FernÃ¡ndez-SÃ¡nchez and Juan Garbajosa and AgustÃ­n YagÃŒe and Jennifer Perez",keywords = "Technical debt, Technical debt management, Systematic mapping, Decision making, Basic decision-making factors, Cost estimation techniques, Practices and techniques for decision-making, Stakeholdersâ?? points of view, Engineering, Engineering management, Business-organizational management, Framework",abstract = "Technical debt, a metaphor for the long-term consequences of weak software development, must be managed to keep it under control. The main goal of this article is to identify and analyze the elements required to manage technical debt. The research method used to identify the elements is a systematic mapping, including a synthesis step to synthesize the elements definitions. Our perspective differs from previous literature reviews because it focused on the elements required to manage technical debt and not on the phenomenon of technical debt or the activities used in performing technical debt management. Additionally, the rigor and relevance for industry of the current techniques used to manage technical debt are studied. The elements were classified into three groups (basic decision-making factors, cost estimation techniques, practices and techniques for decision-making) and mapped according three stakeholdersâ?? points of view (engineering, engineering management, and business-organizational management). The definitions, classification, and analysis of the elements provide a framework that can be deployed to help in the development of models that are adapted to the specific stakeholdersâ?? interests to assist the decision-making required in technical debt management and to assess existing models and methods. The analysis indicated that technical debt management is context dependent."}]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2931</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[identification-and-analysis-of-the-elements-required-to-manage-technical-debt-by-means-of-a-systematic-mapping-study-articulo-relevante]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="basic-decision-making-factors"><![CDATA[Basic decision-making factors]]></category>
		<category domain="post_tag" nicename="business-orga"><![CDATA[Business-orga]]></category>
		<category domain="post_tag" nicename="cost-estimation-techniques"><![CDATA[Cost estimation techniques]]></category>
		<category domain="post_tag" nicename="decision-making"><![CDATA[Decision Making]]></category>
		<category domain="post_tag" nicename="engineering"><![CDATA[Engineering]]></category>
		<category domain="post_tag" nicename="engineering-management"><![CDATA[Engineering management]]></category>
		<category domain="post_tag" nicename="practices-and-techniques-for-decision-making"><![CDATA[Practices and techniques for decision-making]]></category>
		<category domain="post_tag" nicename="stakeholders-points-of-view"><![CDATA[Stakeholders’ points of view]]></category>
		<category domain="post_tag" nicename="systematic-mapping"><![CDATA[Systematic mapping]]></category>
		<category domain="post_tag" nicename="technical-debt"><![CDATA[technical debt]]></category>
		<category domain="post_tag" nicename="technical-debt-management"><![CDATA[Technical debt management]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Artículo publicado en Journal of Systems and Software (JSS). JSS es clasificada como Q1 en JCR 2017.

@article{FERNANDEZSANCHEZ201722,
title = "Identification and analysis of the elements required to manage technical debt by means of a systematic mapping study",
journal = "Journal of Systems and Software",
volume = "124",
pages = "22 - 38",
year = "2017",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2016.10.018",
url = "http://www.sciencedirect.com/science/article/pii/S0164121216302138",
author = "Carlos FernÃ¡ndez-SÃ¡nchez and Juan Garbajosa and AgustÃ­n YagÃŒe and Jennifer Perez",
keywords = "Technical debt, Technical debt management, Systematic mapping, Decision making, Basic decision-making factors, Cost estimation techniques, Practices and techniques for decision-making, Stakeholdersâ?? points of view, Engineering, Engineering management, Business-organizational management, Framework",
abstract = "Technical debt, a metaphor for the long-term consequences of weak software development, must be managed to keep it under control. The main goal of this article is to identify and analyze the elements required to manage technical debt. The research method used to identify the elements is a systematic mapping, including a synthesis step to synthesize the elements definitions. Our perspective differs from previous literature reviews because it focused on the elements required to manage technical debt and not on the phenomenon of technical debt or the activities used in performing technical debt management. Additionally, the rigor and relevance for industry of the current techniques used to manage technical debt are studied. The elements were classified into three groups (basic decision-making factors, cost estimation techniques, practices and techniques for decision-making) and mapped according three stakeholdersâ?? points of view (engineering, engineering management, and business-organizational management). The definitions, classification, and analysis of the elements provide a framework that can be deployed to help in the development of models that are adapted to the specific stakeholdersâ?? interests to assist the decision-making required in technical debt management and to assess existing models and methods. The analysis indicated that technical debt management is context dependent."
}]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-006.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-006.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Fernández-Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[nandez3@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Garbajosa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jgs@etsisi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Agustín Yagüe]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ayague@etsisi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jennifer Perez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jperez@etsisi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Improving feature location in long-living model-based product families designed with sustainability goals (YA PUBLICADO)</title>
		<link>https://biblioteca.sistedes.es/articulo/improving-feature-location-in-long-living-model-based-product-families-designed-with-sustainability-goals-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/improving-feature-location-in-long-living-model-based-product-families-designed-with-sustainability-goals-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[The benefits of Software Product Lines (SPL) are very appealing: software development becomes better, faster, and cheaper. Unfortunately, these benefits come at the expense of a migration from a family of products to a SPL. Feature Location could be useful in achieving the transition to SPLs. This work presents our FeLLaCaM approach for Feature Location. Our approach calculates similarity to a description of the feature to locate, occurrences where the candidate features remain unchanged, and changes performed to the candidate features throughout the retrospective of the product family. We evaluated our approach in two long-living industrial domains: a model-based family of firmwares for induction hobs that was developed over more than 15 years, and a model-based family of PLC software to control trains that was developed over more than 25 years. In our evaluation, we compare our FeLLaCaM approach with two other approaches for Feature Location: (1) FLL (Feature Location through Latent Semantic Analysis) and (2) FLC (Feature Location through Comparisons). We measure the performance of FeLLaCaM, FLL, and FLC in terms of recall, precision, Matthews Correlation Coefficient, and Area Under the Receiver Operating Characteristics curve. The results show that FeLLaCaM outperforms FLL and FLC.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2932</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[improving-feature-location-in-long-living-model-based-product-families-designed-with-sustainability-goals-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="architecture-sustainability"><![CDATA[Architecture sustainability]]></category>
		<category domain="post_tag" nicename="feature-location"><![CDATA[Feature location]]></category>
		<category domain="post_tag" nicename="long-living-software-systems"><![CDATA[Long-Living software systems]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<category domain="post_tag" nicename="software-product-lines"><![CDATA[software product lines]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The benefits of Software Product Lines (SPL) are very appealing: software development becomes better, faster, and cheaper. Unfortunately, these benefits come at the expense of a migration from a family of products to a SPL. Feature Location could be useful in achieving the transition to SPLs. This work presents our FeLLaCaM approach for Feature Location. Our approach calculates similarity to a description of the feature to locate, occurrences where the candidate features remain unchanged, and changes performed to the candidate features throughout the retrospective of the product family. We evaluated our approach in two long-living industrial domains: a model-based family of firmwares for induction hobs that was developed over more than 15 years, and a model-based family of PLC software to control trains that was developed over more than 25 years. In our evaluation, we compare our FeLLaCaM approach with two other approaches for Feature Location: (1) FLL (Feature Location through Latent Semantic Analysis) and (2) FLC (Feature Location through Comparisons). We measure the performance of FeLLaCaM, FLL, and FLC in terms of recall, precision, Matthews Correlation Coefficient, and Area Under the Receiver Operating Characteristics curve. The results show that FeLLaCaM outperforms FLL and FLC.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-007.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-007.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Cetina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ccetina@usj.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad San Jorge - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jaime Font]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jfont@usj.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad San Jorge - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Lorena Arcega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[larcega@usj.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad San Jorge - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Francisca Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mfperez@usj.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad San Jorge - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/006]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Artículo Relevante: Reverse engineering language product lines from existing DSL variants.</title>
		<link>https://biblioteca.sistedes.es/articulo/articulo-relevante-reverse-engineering-language-product-lines-from-existing-dsl-variants/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/articulo-relevante-reverse-engineering-language-product-lines-from-existing-dsl-variants/</guid>
		<description></description>
		<content><![CDATA[-Título: Reverse engineering language product lines from existing DSL variants.-Autores: David Méndez-Acuña, José A. Galindo, Benoît Combemale, Arnaud Blouin, Benoit Baudry-Revista de publicación: Journal of Systems and Software-Volumen 133. Noviembre de 2017. Páginas 145-158-DOI: 10.1016/j.jss.2017.05.042Indicios de calidad: JCR-IF: 2,444(22/106).JCR-Q: Q1. JCR-T: T1. JCR-Category/year: COMPUTER SCIENCE, SOFTWARE ENGINEERING - 2016. 9 citas según gscholar]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2933</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[articulo-relevante-reverse-engineering-language-product-lines-from-existing-dsl-variants]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="dsl"><![CDATA[DSL]]></category>
		<category domain="post_tag" nicename="models"><![CDATA[models]]></category>
		<category domain="post_tag" nicename="software-product-lines"><![CDATA[software product lines]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[-Título: Reverse engineering language product lines from existing DSL variants.
-Autores: David Méndez-Acuña, José A. Galindo, Benoît Combemale, Arnaud Blouin, Benoit Baudry
-Revista de publicación: Journal of Systems and Software
-Volumen 133. Noviembre de 2017. Páginas 145-158
-DOI: 10.1016/j.jss.2017.05.042

Indicios de calidad: JCR-IF: 2,444(22/106).JCR-Q: Q1. JCR-T: T1. JCR-Category/year: COMPUTER SCIENCE, SOFTWARE ENGINEERING - 2016. 9 citas según gscholar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-008.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-008.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Méndez-Acuña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[damenac@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[INRIA - France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José A. Galindo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jagalindo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/007]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación de eventos de prueba para un sistema IoT de detección de caídas</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-de-eventos-de-prueba-para-un-sistema-iot-de-deteccion-de-caidas/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/generacion-de-eventos-de-prueba-para-un-sistema-iot-de-deteccion-de-caidas/</guid>
		<description></description>
		<content><![CDATA[El Internet de las Cosas (IoT) se ha ido aplicando en diferentes áreas; como smartcyties , medicina, procesos de negocio, etc, convirtiéndolo en un paradigma muy popular. Uno de los inconvenientes de los sistemas IoT es la toma de decisiones en tiempo real según la gran cantidad de información, eventos, que manejan. Realizar pruebas en estos sistemas es crucial para la toma de decisiones, ya que si no se filtra la información correcta no se llevarán a cabo las acciones esperadas. En diversas ocasiones es difícil obtener los eventos con valores específicos para realizar pruebas: condiciones ambientales adversas, subida o bajada de la tensión arterial, paro cardíaco, caídas... Este trabajo está enfocado en analizar caídas y en generar los eventos de prueba que las simulen utilizando la herramienta IoT-TEG. Este análisis ha permitido detectar el comportamiento de los eventos durante las mismas y ampliar las funcionalidades de IoT-TEG: los eventos de prueba a generar siguen las reglas de comportamiento que el usuario defina.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2934</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-de-eventos-de-prueba-para-un-sistema-iot-de-deteccion-de-caidas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="deteccion-de-caidas"><![CDATA[Detección de caídas]]></category>
		<category domain="post_tag" nicename="eventos-de-prueba"><![CDATA[Eventos de prueba]]></category>
		<category domain="post_tag" nicename="iot-teg"><![CDATA[IoT-TEG]]></category>
		<category domain="post_tag" nicename="pruebas-en-sistemas-iot"><![CDATA[Pruebas en sistemas IoT]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El Internet de las Cosas (IoT) se ha ido aplicando en diferentes áreas; como smartcyties , medicina, procesos de negocio, etc, convirtiéndolo en un paradigma muy popular. Uno de los inconvenientes de los sistemas IoT es la toma de decisiones en tiempo real según la gran cantidad de información, eventos, que manejan. Realizar pruebas en estos sistemas es crucial para la toma de decisiones, ya que si no se filtra la información correcta no se llevarán a cabo las acciones esperadas. En diversas ocasiones es difícil obtener los eventos con valores específicos para realizar pruebas: condiciones ambientales adversas, subida o bajada de la tensión arterial, paro cardíaco, caídas... Este trabajo está enfocado en analizar caídas y en generar los eventos de prueba que las simulen utilizando la herramienta IoT-TEG. Este análisis ha permitido detectar el comportamiento de los eventos durante las mismas y ampliar las funcionalidades de IoT-TEG: los eventos de prueba a generar siguen las reglas de comportamiento que el usuario defina.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-009.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-009.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Lorena Gutiérrez-Madroñal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[lorena.gutierrez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Luigi La Blunda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[l.lablunda@fb2.fra-uas.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Frankfurt University of Applied Sciences - Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Matthias F. Wagner]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mfwagner@fb2.fra-uas.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Frankfurt University of Applied Sciences - Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Cadiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/008]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A tool to support the definition and enactment of model-driven migration processes (YA PUBLICADO)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-tool-to-support-the-definition-and-enactment-of-model-driven-migration-processes-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-tool-to-support-the-definition-and-enactment-of-model-driven-migration-processes-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[The Journal of Systems and Software, num. 128 (March 2017) pages: 106–129DOI: http://dx.doi.org/10.1016/j.jss.2017.03.0092016 Impact Factor: 2.444  (Q1 - rank 22/106)5-year Impact Factor: 2.619ABSTRACTOne of the main challenges to achieve the industrial adoption of Model-Driven Engineering (MDE) paradigm is building tools able to support model-driven software processes. We present a tool for the definition and enactment of model-driven migration processes. We have created a SPEM-based language for defining Abstract Migration models that represent an MDE migration solution for a particular pair of source and target technologies. For each legacy application to be migrated, the Abstract Migration model is transformed into a Concrete Migration model which contains all the information needed for the enactment. Then, these models are enacted by means of a process interpreter which generates Trac tickets for executing automated tasks by means of Ant scripts and managing manual tasks with the Mylyn tool. Our work has therefore two main contributions: i) it proposes a novel solution for the enactment that integrates the execution of the automated tasks with the generation of tickets to support the manual tasks, and ii) it describes how MDE techniques can be used to implement process engineering tools, in particular migration processes. The article presents the approach and describes in detail the essential aspects of our tool.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2935</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-tool-to-support-the-definition-and-enactment-of-model-driven-migration-processes-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<category domain="post_tag" nicename="process-enactment"><![CDATA[Process enactment]]></category>
		<category domain="post_tag" nicename="software-migrations"><![CDATA[Software migrations]]></category>
		<category domain="post_tag" nicename="software-processes"><![CDATA[Software processes]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The Journal of Systems and Software, num. 128 (March 2017) pages: 106–129
DOI: http://dx.doi.org/10.1016/j.jss.2017.03.009
2016 Impact Factor: 2.444  (Q1 - rank 22/106)
5-year Impact Factor: 2.619

ABSTRACT
One of the main challenges to achieve the industrial adoption of Model-Driven Engineering (MDE) paradigm is building tools able to support model-driven software processes. We present a tool for the definition and enactment of model-driven migration processes. We have created a SPEM-based language for defining Abstract Migration models that represent an MDE migration solution for a particular pair of source and target technologies. For each legacy application to be migrated, the Abstract Migration model is transformed into a Concrete Migration model which contains all the information needed for the enactment. Then, these models are enacted by means of a process interpreter which generates Trac tickets for executing automated tasks by means of Ant scripts and managing manual tasks with the Mylyn tool. Our work has therefore two main contributions: i) it proposes a novel solution for the enactment that integrates the execution of the automated tasks with the generation of tickets to support the manual tasks, and ii) it describes how MDE techniques can be used to implement process engineering tools, in particular migration processes. The article presents the approach and describes in detail the essential aspects of our tool.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-010.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-010.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Javier Bermúdez Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fjavier@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Óscar Sánchez Ramón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[osanchez@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesús Joaquín García Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jmolina@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/009]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>ARTICULO RELEVANTE:Incremental test data generation for database queries</title>
		<link>https://biblioteca.sistedes.es/articulo/articulo-relevanteincremental-test-data-generation-for-database-queries/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/articulo-relevanteincremental-test-data-generation-for-database-queries/</guid>
		<description></description>
		<content><![CDATA[Título: Incremental test data generation for database queriesAutores: María José Suárez-Cabal, Claudio de la Riva, Javier Tuya, Raquel BlancoRevista de publicación: Automated Software EngineeringNúmero, mes y año de la publicación: 24(4), Diciembre 2017Páginas: 719-755DOI: 10.1007/s10515-017-0212-7Indicios de calidad:  Factor de impacto: 2.625 (JCR, 2016)  Número de citas: 2      [1] R. Blanco and J. Tuya, "Modelling Test Views for Graph Database Applications", IEEE Latin America Transactions, vol. 15, no. 7, pp. 1312-1317, 2017. doi: 10.1109/TLA.2017.7959352       [2] W. Castelein, M. Aniche, M. Soltani, A. Panichella, A. Deursen, "Search-Based Test Data Generation for SQL Queries", Proceedings of the 40th International Conference on Software Engineering (ICSE 2018)]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2936</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[articulo-relevanteincremental-test-data-generation-for-database-queries]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="constraint-satisfaction-problem-csp"><![CDATA[Constraint satisfaction problem (CSP)]]></category>
		<category domain="post_tag" nicename="database-testing"><![CDATA[Database testing]]></category>
		<category domain="post_tag" nicename="software-testing"><![CDATA[Software Testing]]></category>
		<category domain="post_tag" nicename="test-coverage"><![CDATA[Test coverage]]></category>
		<category domain="post_tag" nicename="test-database-generation"><![CDATA[Test database generation]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Título: Incremental test data generation for database queries

Autores: María José Suárez-Cabal, Claudio de la Riva, Javier Tuya, Raquel Blanco

Revista de publicación: Automated Software Engineering

Número, mes y año de la publicación: 24(4), Diciembre 2017

Páginas: 719-755

DOI: 10.1007/s10515-017-0212-7

Indicios de calidad:
  Factor de impacto: 2.625 (JCR, 2016)
  Número de citas: 2
      [1] R. Blanco and J. Tuya, "Modelling Test Views for Graph Database Applications", IEEE Latin America Transactions, vol. 15, no. 7, pp. 1312-1317, 2017. doi: 10.1109/TLA.2017.7959352

      [2] W. Castelein, M. Aniche, M. Soltani, A. Panichella, A. Deursen, "Search-Based Test Data Generation for SQL Queries", Proceedings of the 40th International Conference on Software Engineering (ICSE 2018)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-011.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-011.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María José Suárez-Cabal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cabal@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Claudio De La Riva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[claudio@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Raquel Blanco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[rblanco@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/010]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Highlight&amp;Go: una extensión para automatizar la extracción de datos en revisiones sistemáticas de la literatura utilizando Google Sheets</title>
		<link>https://biblioteca.sistedes.es/articulo/highlightgo-una-extension-para-automatizar-la-extraccion-de-datos-en-revisiones-sistematicas-de-la-literatura-utilizando-google-sheets/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/highlightgo-una-extension-para-automatizar-la-extraccion-de-datos-en-revisiones-sistematicas-de-la-literatura-utilizando-google-sheets/</guid>
		<description></description>
		<content><![CDATA[Una revisión sistemática de la literatura no es tarea baladí. Conlleva almacenar, gestionar, validar y analizar una gran cantidad de datos. Extraer estos datos implica identificar los párrafos de los estudios primarios que justifican su clasificación en base a las dimensiones del estudio. Esto conlleva mover datos desde el entorno donde se ha realizado la lectura (p.e. Mendeley) al lugar dónde se recogen estos datos (p.e. Excel). Si estas actividades se mueven a la Web, este flujo de datos se puede automatizar. Este trabajo aborda este objetivo mediante la utilización de extensiones para navegadores. En concreto, hemos desarrollado Highlight&Go, una extensión de Google Chrome, donde el investigador subraya ("highlight") los estudios primarios, y se va ("go"): la hoja de cálculo se puebla sola a partir de las anotaciones realizadas. Los beneficios esperados incluyen: (1) mejoras en la eficiencia al eliminar el copiar&pegar; (2) mejoras en la fiabilidad al reducir los errores de la intervención manual; y (3) mejoras en la trazabilidad al recoger no sólo la clasificación sino también los párrafos que sustentan esta clasificación.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2937</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[highlightgo-una-extension-para-automatizar-la-extraccion-de-datos-en-revisiones-sistematicas-de-la-literatura-utilizando-google-sheets]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="automatization"><![CDATA[Automatization]]></category>
		<category domain="post_tag" nicename="color-coding-annotation"><![CDATA[Color-Coding Annotation]]></category>
		<category domain="post_tag" nicename="data-extraction"><![CDATA[Data Extraction]]></category>
		<category domain="post_tag" nicename="mapping-studies"><![CDATA[Mapping Studies]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Una revisión sistemática de la literatura no es tarea baladí. Conlleva almacenar, gestionar, validar y analizar una gran cantidad de datos. Extraer estos datos implica identificar los párrafos de los estudios primarios que justifican su clasificación en base a las dimensiones del estudio. Esto conlleva mover datos desde el entorno donde se ha realizado la lectura (p.e. Mendeley) al lugar dónde se recogen estos datos (p.e. Excel). Si estas actividades se mueven a la Web, este flujo de datos se puede automatizar. Este trabajo aborda este objetivo mediante la utilización de extensiones para navegadores. En concreto, hemos desarrollado Highlight&Go, una extensión de Google Chrome, donde el investigador subraya ("highlight") los estudios primarios, y se va ("go"): la hoja de cálculo se puebla sola a partir de las anotaciones realizadas. Los beneficios esperados incluyen: (1) mejoras en la eficiencia al eliminar el copiar&pegar; (2) mejoras en la fiabilidad al reducir los errores de la intervención manual; y (3) mejoras en la trazabilidad al recoger no sólo la clasificación sino también los párrafos que sustentan esta clasificación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-012.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-012.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Haritz Medina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[haritz.medina@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU) - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Oscar Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[oscar.diaz@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU) - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Felipe I. Anfurrutia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[felipe.anfurrutia@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU) - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/011]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Aggregation-based information retrieval system for geospatial data catalogs</title>
		<link>https://biblioteca.sistedes.es/articulo/aggregation-based-information-retrieval-system-for-geospatial-data-catalogs/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/aggregation-based-information-retrieval-system-for-geospatial-data-catalogs/</guid>
		<description></description>
		<content><![CDATA[Tipo de contribución: Artículo relevanteAutores: Lacasta, Javier; Lopez-Pellicer, F. Javier; Espejo-García, Borja; Nogueras-Iso, Javier; Zarazaga-Soria, F. Javier.Título: Aggregation-based information retrieval system for geospatial data catalogs.Publicación: INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE. 31 - 8, pp. 1583 - 1605. 2017. ISSN 1365-8816DOI: 10.1080/13658816.2017.1319949Indicios de Calidad - Factor de impacto:JCR-SCI 2016 impact factor: 2.502. Rank: Q2 (46/146) in Computer Science, Information Systems ; Q2 (19/49) in Geography, Physical]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2939</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[aggregation-based-information-retrieval-system-for-geospatial-data-catalogs]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="catalog-service-for-the-web"><![CDATA[Catalog Service for the Web]]></category>
		<category domain="post_tag" nicename="geospatial-data-catalog"><![CDATA[Geospatial Data Catalog]]></category>
		<category domain="post_tag" nicename="information-retrieval"><![CDATA[Information retrieval]]></category>
		<category domain="post_tag" nicename="spatial-data-infrastructure"><![CDATA[Spatial Data Infrastructure]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Tipo de contribución: Artículo relevante

Autores: Lacasta, Javier; Lopez-Pellicer, F. Javier; Espejo-García, Borja; Nogueras-Iso, Javier; Zarazaga-Soria, F. Javier.

Título: Aggregation-based information retrieval system for geospatial data catalogs.

Publicación: INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE. 31 - 8, pp. 1583 - 1605. 2017. ISSN 1365-8816
DOI: 10.1080/13658816.2017.1319949

Indicios de Calidad - Factor de impacto:
JCR-SCI 2016 impact factor: 2.502. Rank: Q2 (46/146) in Computer Science, Information Systems ; Q2 (19/49) in Geography, Physical]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-014.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-014.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Lacasta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jlacasta@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francisco J. Lopez-Pellicer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fjlopez@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Borja Espejo García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[borjaeg@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Javier Nogueras Iso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jnog@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[F.Javier Zarazaga-Soria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[javy@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universiad de Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/013]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A systematic mapping study about socio-technical congruence (Artículo relevante)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-systematic-mapping-study-about-socio-technical-congruence-articulo-relevante/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-systematic-mapping-study-about-socio-technical-congruence-articulo-relevante/</guid>
		<description></description>
		<content><![CDATA[Artículo Relevante ya publicado:Título: A systematic mapping study about socio-technical congruenceAutores: José María Sierra, Aurora Vizcaíno, Marcela Genero, Mario PiattiniNombre de la conferencia o revista de publicación: Information and Software Technology Número: Volume 94Mes: Februaro Año de la publicación: 2018 (Es importante resaltar que se aceptó el  6 de Octubre de 2017 por lo cual cumple los requisitos)Páginas: 111-129 DOI: https://doi.org/10.1016/j.infsof.2017.10.004Indicios de calidad (factor de impacto, número de citas, etc): ( posición de la revista: 16/106, factor de impacto: 2.694, puesto que se publicó en febrero de 2018 todavía no tiene citas)]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2940</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-systematic-mapping-study-about-socio-technical-congruence-articulo-relevante]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="coordination"><![CDATA[Coordination]]></category>
		<category domain="post_tag" nicename="distributed-and-global-software-development"><![CDATA[Distributed and Global Software Development]]></category>
		<category domain="post_tag" nicename="socio-technical-congruence"><![CDATA[Socio-technical Congruence]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Artículo Relevante ya publicado:

Título: A systematic mapping study about socio-technical congruence
Autores: José María Sierra, Aurora Vizcaíno, Marcela Genero, Mario Piattini
Nombre de la conferencia o revista de publicación: Information and Software Technology
Número: Volume 94
Mes: Februaro
Año de la publicación: 2018 (Es importante resaltar que se aceptó el  6 de Octubre de 2017 por lo cual cumple los requisitos)
Páginas: 111-129
DOI: https://doi.org/10.1016/j.infsof.2017.10.004
Indicios de calidad (factor de impacto, número de citas, etc): ( posición de la revista: 16/106, factor de impacto: 2.694, puesto que se publicó en febrero de 2018 todavía no tiene citas)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-015.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-015.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José María Sierra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jose.sierra@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Aurora Vizcaíno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[aurora.vizcaino@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla - La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Marcela Genero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[marcela.genero@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mario.piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/014]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>ARTICULO RELEVANTE:Assessment of C++ object-oriented mutation operators: A selective mutation approach</title>
		<link>https://biblioteca.sistedes.es/articulo/articulo-relevanteassessment-of-c-object-oriented-mutation-operators-a-selective-mutation-approach/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/articulo-relevanteassessment-of-c-object-oriented-mutation-operators-a-selective-mutation-approach/</guid>
		<description></description>
		<content><![CDATA[La prueba de mutaciones está considerada como una técnicaefectiva, pero que es costosa en contrapartida. Varios estudios han pues-to de manifiesto que pueden existir mutantes redundantes y que, unavez eliminados, no suponen pérdida de la efectividad de la técnica. De lamisma manera, algunos mutantes pueden ser más efectivos que otros ala hora de guiarnos en la generación de nuevos casos de pruebas de altacalidad. En base a estos dos hallazgos, en este artículo presentamos unaevaluación de los operadores de mutación definidos para C++ en la queclasificamos dichos operadores en dos rankings diferentes tras estudiar losmutantes que cada uno de los operadores genera. La primera clasificaciónordena los operadores según el grado de redundancia de sus mutantes yla segunda en base a la calidad de las pruebas que ayudan a diseñar. Unavez establecidos ambos rankings, llevamos a cabo un proceso de mutaciónselectiva en el que seleccionamos subconjuntos de operadores desechandolos menos valorados. El objetivo es determinar qué relación existe entrela reducción que se obtendría al eliminar estos operadores y la pérdidade efectividad. Los resultados experimentales muestran de una maneraconsistente que al seleccionar los operadores que están en la parte altadel ranking podemos obtener una reducción significativa en el númerode mutantes con una mínima pérdida de efectividad. Esto se produce enambas clasificaciones a pesar de que los operadores se ordenan de for-ma distinta, lo cual valida el planteamiento de valorar los operadores demutación de una manera diferente según nuestro objetivo sea evaluar orefinar el conjunto de pruebas.P. Delgado-Pérez, S. Segura and I. Medina-Bulo, “Assessment of C++ object-oriented mutation operators: A selective mutation approach,” Software Testing,Verification and Reliability, vol. 27, num. 4–5, pp. e1630, 2017. http://dx.doi.org/10.1002/stvr.1630Factor de impacto revista: 1.588]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2941</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[articulo-relevanteassessment-of-c-object-oriented-mutation-operators-a-selective-mutation-approach]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="c"><![CDATA[C++]]></category>
		<category domain="post_tag" nicename="calidad-de-operadores-de-mutacion"><![CDATA[calidad de operadores de mutación]]></category>
		<category domain="post_tag" nicename="mutacion-selectiva"><![CDATA[mutación selectiva]]></category>
		<category domain="post_tag" nicename="operadores-de-mutacion-de-clase"><![CDATA[operadores de mutación de clase]]></category>
		<category domain="post_tag" nicename="prueba-de-mutaciones"><![CDATA[prueba de mutaciones]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La prueba de mutaciones está considerada como una técnica
efectiva, pero que es costosa en contrapartida. Varios estudios han pues-
to de manifiesto que pueden existir mutantes redundantes y que, una
vez eliminados, no suponen pérdida de la efectividad de la técnica. De la
misma manera, algunos mutantes pueden ser más efectivos que otros a
la hora de guiarnos en la generación de nuevos casos de pruebas de alta
calidad. En base a estos dos hallazgos, en este artículo presentamos una
evaluación de los operadores de mutación definidos para C++ en la que
clasificamos dichos operadores en dos rankings diferentes tras estudiar los
mutantes que cada uno de los operadores genera. La primera clasificación
ordena los operadores según el grado de redundancia de sus mutantes y
la segunda en base a la calidad de las pruebas que ayudan a diseñar. Una
vez establecidos ambos rankings, llevamos a cabo un proceso de mutación
selectiva en el que seleccionamos subconjuntos de operadores desechando
los menos valorados. El objetivo es determinar qué relación existe entre
la reducción que se obtendría al eliminar estos operadores y la pérdida
de efectividad. Los resultados experimentales muestran de una manera
consistente que al seleccionar los operadores que están en la parte alta
del ranking podemos obtener una reducción significativa en el número
de mutantes con una mínima pérdida de efectividad. Esto se produce en
ambas clasificaciones a pesar de que los operadores se ordenan de for-
ma distinta, lo cual valida el planteamiento de valorar los operadores de
mutación de una manera diferente según nuestro objetivo sea evaluar o
refinar el conjunto de pruebas.

P. Delgado-Pérez, S. Segura and I. Medina-Bulo, “Assessment of C++ object-
oriented mutation operators: A selective mutation approach,” Software Testing,
Verification and Reliability, vol. 27, num. 4–5, pp. e1630, 2017.
http://dx.doi.org/10.1002/stvr.1630

Factor de impacto revista: 1.588]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-016.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-016.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Delgado-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pedro.delgado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/015]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>ARTICULO RELEVANTE:Evaluating Software Project Managers: A Multidimensional Perspective</title>
		<link>https://biblioteca.sistedes.es/articulo/articulo-relevanteevaluating-software-project-managers-a-multidimensional-perspective/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/articulo-relevanteevaluating-software-project-managers-a-multidimensional-perspective/</guid>
		<description></description>
		<content><![CDATA[Lawrence Peters, Ana M. Moreno. Evaluating Software Project Managers: A multidimensional perspective. IEEE Software, Nov-Dec. 2017, Vol 34 (6), pp 104-109. IEEE Software –  JCR Impact Factor (2016): 2,547 – Rank Computer Science, Software Engineering 26/106 - Q1Qualified and motivated software project managers are key contributors in software organizations. According to literature and supported by authors experience one of the most effective motivators for software practitioners is the recognition of their work. Feedback and recognition of the work done implies the evaluation of professionals and their work. Evaluating software project managers should go beyond a hasty analysis determining if their projects finished on time, under budget and met requirements. Software project managers develop their practice in an organizational context and their work directly impacts different groups within the organization. Each group has its own value system regarding what the software project should accomplish and what an effective software project manager is. This paper discuss a holistic approach for evaluating software project managers having in mind the value system of those groups.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2942</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[articulo-relevanteevaluating-software-project-managers-a-multidimensional-perspective]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="evaluating-software-project-managers"><![CDATA[Evaluating software project managers]]></category>
		<category domain="post_tag" nicename="motivating-software-engineers"><![CDATA[Motivating Software Engineers]]></category>
		<category domain="post_tag" nicename="software-project-management"><![CDATA[Software project management]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Lawrence Peters, Ana M. Moreno. Evaluating Software Project Managers: A multidimensional perspective. IEEE Software, Nov-Dec. 2017, Vol 34 (6), pp 104-109.
IEEE Software –  JCR Impact Factor (2016): 2,547 – Rank Computer Science, Software Engineering 26/106 - Q1

Qualified and motivated software project managers are key contributors in software organizations. According to literature and supported by authors experience one of the most effective motivators for software practitioners is the recognition of their work. Feedback and recognition of the work done implies the evaluation of professionals and their work. Evaluating software project managers should go beyond a hasty analysis determining if their projects finished on time, under budget and met requirements. Software project managers develop their practice in an organizational context and their work directly impacts different groups within the organization. Each group has its own value system regarding what the software project should accomplish and what an effective software project manager is. This paper discuss a holistic approach for evaluating software project managers having in mind the value system of those groups.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-018.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-018.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Lawrence Peters]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ljpeters42@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Consultant - United States]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ana M Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ammoreno@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/016]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A software reference architecture for semantic-aware Big Data systems</title>
		<link>https://biblioteca.sistedes.es/articulo/a-software-reference-architecture-for-semantic-aware-big-data-systems/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-software-reference-architecture-for-semantic-aware-big-data-systems/</guid>
		<description></description>
		<content><![CDATA[Information & Software Technology 90: 75-92 (2017)Impact Factor JCR 2017: 2.694https://doi.org/10.1016/j.infsof.2017.06.001Citas recibidas en 2017 (Google Scholar, 2-3-2018): 3https://scholar.google.es/scholar?oi=bibs&hl=en&cites=13041754256225380312&as_sdt=5---------------------------------- Abstract --------------------------------------Context: Big Data systems are a class of software systems that ingest, store, process and serve massive amounts of heterogeneous data, from multiple sources. Despite their undisputed impact in current society, their engineering is still in its infancy and companies find it difficult to adopt them due to their inherent complexity. Existing attempts to provide architectural guidelines for their engineering fail to take into account important Big Data characteristics, such as the management, evolution and quality of the data.Objective: In this paper, we follow software engineering principles to refine the ?-architecture, a reference model for Big Data systems, and use it as seed to create Bolster, a software reference architecture (SRA) for semantic-aware Big Data systems.Method: By including a new layer into the ?-architecture, the Semantic Layer, Bolster is capable of handling the most representative Big Data characteristics (i.e., Volume, Velocity, Variety, Variability and Veracity).Results: We present the successful implementation of Bolster in three industrial projects, involving five organizations. The validation results show high level of agreement among practitioners from all organizations with respect to standard quality factors.Conclusion: As an SRA, Bolster allows organizations to design concrete architectures tailored to their specific needs. A distinguishing feature is that it provides semantic-awareness in Big Data Systems. These are Big Data system implementations that have components to simplify data definition and exploitation. In particular, they leverage metadata (i.e., data describing data) to enable (partial) automation of data exploitation and to aid the user in their decision making processes. This simplification supports the differentiation of responsibilities into cohesive roles enhancing data governance.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2943</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-software-reference-architecture-for-semantic-aware-big-data-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="data-analysis"><![CDATA[Data analysis]]></category>
		<category domain="post_tag" nicename="data-management"><![CDATA[data management]]></category>
		<category domain="post_tag" nicename="semantic-aware"><![CDATA[Semantic-aware]]></category>
		<category domain="post_tag" nicename="software-reference-architecture"><![CDATA[Software reference architecture]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Information & Software Technology 90: 75-92 (2017)
Impact Factor JCR 2017: 2.694
https://doi.org/10.1016/j.infsof.2017.06.001
Citas recibidas en 2017 (Google Scholar, 2-3-2018): 3
https://scholar.google.es/scholar?oi=bibs&hl=en&cites=13041754256225380312&as_sdt=5

---------------------------------- Abstract --------------------------------------

Context: Big Data systems are a class of software systems that ingest, store, process and serve massive amounts of heterogeneous data, from multiple sources. Despite their undisputed impact in current society, their engineering is still in its infancy and companies find it difficult to adopt them due to their inherent complexity. Existing attempts to provide architectural guidelines for their engineering fail to take into account important Big Data characteristics, such as the management, evolution and quality of the data.

Objective: In this paper, we follow software engineering principles to refine the ?-architecture, a reference model for Big Data systems, and use it as seed to create Bolster, a software reference architecture (SRA) for semantic-aware Big Data systems.

Method: By including a new layer into the ?-architecture, the Semantic Layer, Bolster is capable of handling the most representative Big Data characteristics (i.e., Volume, Velocity, Variety, Variability and Veracity).

Results: We present the successful implementation of Bolster in three industrial projects, involving five organizations. The validation results show high level of agreement among practitioners from all organizations with respect to standard quality factors.

Conclusion: As an SRA, Bolster allows organizations to design concrete architectures tailored to their specific needs. A distinguishing feature is that it provides semantic-awareness in Big Data Systems. These are Big Data system implementations that have components to simplify data definition and exploitation. In particular, they leverage metadata (i.e., data describing data) to enable (partial) automation of data exploitation and to aid the user in their decision making processes. This simplification supports the differentiation of responsibilities into cohesive roles enhancing data governance.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-019.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-019.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Sergi Nadal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[sergi.nadal.francesch@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Víctor Herrero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[vherrero@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Oscar Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[oromero@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Alberto Abello]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aabello@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Xavi Franch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[franch@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Stijn Vansummeren]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[stijn.vansummeren@ulb.ac.be]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Université Libre de Bruxelles - Belgium]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Danilo Valerio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[danilo.valerio@siemens.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[SIEMENS - Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/017]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Consulta eficiente de datos moleculares: Situación actual y retos futuros</title>
		<link>https://biblioteca.sistedes.es/articulo/consulta-eficiente-de-datos-moleculares-situacion-actual-y-retos-futuros/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/consulta-eficiente-de-datos-moleculares-situacion-actual-y-retos-futuros/</guid>
		<description></description>
		<content><![CDATA[En los últimos años, sectores industriales como el químico o elfarmacéutico vienen demandando la gestión eficiente de datos analíticostales como espectros NMR, o estructuras moleculares. En la actualidadexisten varias bibliotecas quimioinformáticas que pueden ser incorporadasdentro de los SGBDs relacionales. Sin embargo, estas soluciones noson eficaces para todos los tipos de consultas necesarias (datos espectroscópicosy cromatográficos por ejemplo) y no son eficientes para trabajarcon el volumen de datos requerido en la actualidad. En este artículo sedescribe el problema de la búsqueda de datos moleculares y se proporcionauna breve introducción a las soluciones iniciales y retos futuros eneste campo dentro del marco del proyecto NEXTCHROM.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2944</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[consulta-eficiente-de-datos-moleculares-situacion-actual-y-retos-futuros]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="bases-de-datos-de-grafos"><![CDATA[Bases de datos de grafos]]></category>
		<category domain="post_tag" nicename="bases-de-datos-quimicas"><![CDATA[Bases de datos químicas]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="datos-moleculares"><![CDATA[Datos moleculares]]></category>
		<category domain="post_tag" nicename="quimioinformatica"><![CDATA[Quimioinformática]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años, sectores industriales como el químico o el
farmacéutico vienen demandando la gestión eficiente de datos analíticos
tales como espectros NMR, o estructuras moleculares. En la actualidad
existen varias bibliotecas quimioinformáticas que pueden ser incorporadas
dentro de los SGBDs relacionales. Sin embargo, estas soluciones no
son eficaces para todos los tipos de consultas necesarias (datos espectroscópicos
y cromatográficos por ejemplo) y no son eficientes para trabajar
con el volumen de datos requerido en la actualidad. En este artículo se
describe el problema de la búsqueda de datos moleculares y se proporciona
una breve introducción a las soluciones iniciales y retos futuros en
este campo dentro del marco del proyecto NEXTCHROM.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-020.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-020.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Luaces Cachaza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[david.luaces@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[COGRADE - CiTIUS - Universidade de Santiago de Compostela - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Michael Goebel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[michael@metrelab.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Mestrelab Research S.L. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José R.R. Viqueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jrr.viqueira@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Santiago de Compostela - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José Antonio García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jose@mestrelab.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Mestrelab Research S.L. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Tomás F. Pena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[tf.pena@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[CITIUS, University of Santiago de Compostela - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Carlos Cobas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[carlos@mestrelab.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Mestrelab Research S.L. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/018]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Semantic mediation of observation datasets through Sensor Observation Services</title>
		<link>https://biblioteca.sistedes.es/articulo/semantic-mediation-of-observation-datasets-through-sensor-observation-services/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/semantic-mediation-of-observation-datasets-through-sensor-observation-services/</guid>
		<description></description>
		<content><![CDATA[This paper describes a first effort for the semantic mediation between heterogeneous environmental observation datasets through the Sensor Observation Service (SOS) standard proposed by the Open Geospatial Consortium. The solution enables application domain experts to provide an ontology with semantic data integration knowledge, which is next combined with data source knowledge during the evaluation of global SOS GetObservation requests. This enables the development of a more general purpose solution that may be adapted to different application domains by just changing the ontology. Besides, users without specific application domain skills and knowledge may now develop new semantically enabled applications.Finally, the design of the framework is based on the well-known Mediator/Wrapper architecture and follows a Local As View data integration approach, which simplifies the incorporation of new datasets without having to change the existing data integration knowledge.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2945</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[semantic-mediation-of-observation-datasets-through-sensor-observation-services]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="environmental-data"><![CDATA[Environmental data]]></category>
		<category domain="post_tag" nicename="observation-data"><![CDATA[Observation data]]></category>
		<category domain="post_tag" nicename="semantic-mediation"><![CDATA[Semantic mediation]]></category>
		<category domain="post_tag" nicename="semantic-web"><![CDATA[Semantic Web]]></category>
		<category domain="post_tag" nicename="sensor-data"><![CDATA[Sensor data]]></category>
		<category domain="post_tag" nicename="web-service"><![CDATA[Web service]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper describes a first effort for the semantic mediation between heterogeneous environmental observation datasets through the Sensor Observation Service (SOS) standard proposed by the Open Geospatial Consortium. The solution enables application domain experts to provide an ontology with semantic data integration knowledge, which is next combined with data source knowledge during the evaluation of global SOS GetObservation requests. This enables the development of a more general purpose solution that may be adapted to different application domains by just changing the ontology. Besides, users without specific application domain skills and knowledge may now develop new semantically enabled applications.
Finally, the design of the framework is based on the well-known Mediator/Wrapper architecture and follows a Local As View data integration approach, which simplifies the incorporation of new datasets without having to change the existing data integration knowledge.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-021.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-021.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel A. Regueiro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[manuelantonio.regueiro@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Santiago de Compostela - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José R.R. Viqueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrr.viqueira@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Santiago de Compostela - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Christoph Stasch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[staschc@uni-muenster.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Institute for Geoinformatics; University of Muenster - Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jose Angel Taboada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Joseangel.taboada@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[USC - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/019]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evaluación y mejora de pruebas de rendimiento utilizando mutación del software: Un enfoque evolutivo</title>
		<link>https://biblioteca.sistedes.es/articulo/evaluacion-y-mejora-de-pruebas-de-rendimiento-utilizando-mutacion-del-software-un-enfoque-evolutivo/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/evaluacion-y-mejora-de-pruebas-de-rendimiento-utilizando-mutacion-del-software-un-enfoque-evolutivo/</guid>
		<description></description>
		<content><![CDATA[Los errores de rendimiento del software pueden causar una importante degradación en la experiencia de usuario y dar lugar a problemas muy costosos de detectar y resolver. Las pruebas de rendimiento persiguen detectar y reducir el impacto de estos errores. Sin embargo, no existen mecanismos para evaluar la calidad de las pruebas de rendimiento, causando en muchos casos, que estos errores pasen desapercibidos. La prueba de mutación es una técnica para evaluar y mejorar las pruebas funcionales a través de la introducción de errores artificiales en el programa bajo prueba. En este artículo, exploramos la aplicabilidad de la prueba de mutación junto con el empleo de un algoritmo evolutivo para buscar mutantes que simulen errores de rendimiento. Esta propuesta noPrueba de mutación, errores de rendimiento, pruebas de rendimiento, algoritmos evolutivos.vedosa contribuye a mejorar la confianza en las pruebas de rendimiento al mismo tiempo que reduce el coste de la prueba de mutación.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2947</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evaluacion-y-mejora-de-pruebas-de-rendimiento-utilizando-mutacion-del-software-un-enfoque-evolutivo]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="algoritmos-evolutivos"><![CDATA[algoritmos evolutivos]]></category>
		<category domain="post_tag" nicename="errores-de-rendimiento"><![CDATA[errores de rendimiento]]></category>
		<category domain="post_tag" nicename="prueba-de-mutacion"><![CDATA[prueba de mutación]]></category>
		<category domain="post_tag" nicename="pruebas-de-rendimiento"><![CDATA[Pruebas de Rendimiento]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los errores de rendimiento del software pueden causar una importante degradación en la experiencia de usuario y dar lugar a problemas muy costosos de detectar y resolver. Las pruebas de rendimiento persiguen detectar y reducir el impacto de estos errores. Sin embargo, no existen mecanismos para evaluar la calidad de las pruebas de rendimiento, causando en muchos casos, que estos errores pasen desapercibidos. La prueba de mutación es una técnica para evaluar y mejorar las pruebas funcionales a través de la introducción de errores artificiales en el programa bajo prueba. En este artículo, exploramos la aplicabilidad de la prueba de mutación junto con el empleo de un algoritmo evolutivo para buscar mutantes que simulen errores de rendimiento. Esta propuesta noPrueba de mutación, errores de rendimiento, pruebas de rendimiento, algoritmos evolutivos.vedosa contribuye a mejorar la confianza en las pruebas de rendimiento al mismo tiempo que reduce el coste de la prueba de mutación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-023.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-023.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana B. Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[anabsanchez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pedro Delgado-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pedro.delgado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/021]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación de Interfaces de Usuario a partir de Modelos BPMN con Estereotipos</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-de-interfaces-de-usuario-a-partir-de-modelos-bpmn-con-estereotipos/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/generacion-de-interfaces-de-usuario-a-partir-de-modelos-bpmn-con-estereotipos/</guid>
		<description></description>
		<content><![CDATA[La notación de modelo de procesos de negocio (BPMN – Business Process Model Notation) proporciona a las organizaciones un estándar que facilita una mayor compresión del proceso empresarial. BPMN se centra en los procesos funcionales, dejando el desarrollo de las interfaces a un lado. De este modo, el diseño de la interfaz generalmente depende de la experiencia subjetiva del analista y no existe un procedimiento para extraer la interfaz de los procesos. Este artículo propone un nuevo método para generar interfaces de usuario a partir de modelos BPMN y Diagramas de Clases. La propuesta se basa en la identificación de reglas de generación de procesos a interfaces. Se han definido estereotipos para extender la notación BPMN en aquellas reglas donde haya más de una posible transformación. Estos estereotipos permiten aplicar la regla de forma inequívoca. Las reglas se extrajeron de cinco proyectos, tres existentes en el repositorio de Bizagi y dos de empresas reales. Específicamente, la propuesta se basa en la extracción de reglas para generar interfaces de usuario basadas en tres patrones, Patrón de Secuencia, Patrón de Decisión Implícita y Patrón de Ejecución Intercalada. Como resultado de nuestra propuesta, se han agregado catorce nuevos estereotipos a la notación BPMN. Para ilustrar la propuesta, los estereotipos se aplicaron a un ejemplo ilustrativo. Los resultados muestran que este trabajo es un "paso adelante" para la generación automática de códigos a partir modelos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2948</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-de-interfaces-de-usuario-a-partir-de-modelos-bpmn-con-estereotipos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="bpmn"><![CDATA[BPMN]]></category>
		<category domain="post_tag" nicename="estereotipos"><![CDATA[Estereotipos]]></category>
		<category domain="post_tag" nicename="interfaces-de-usuario"><![CDATA[Interfaces de usuario]]></category>
		<category domain="post_tag" nicename="metodo"><![CDATA[Método]]></category>
		<category domain="post_tag" nicename="reglas"><![CDATA[Reglas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La notación de modelo de procesos de negocio (BPMN – Business Process Model Notation) proporciona a las organizaciones un estándar que facilita una mayor compresión del proceso empresarial. BPMN se centra en los procesos funcionales, dejando el desarrollo de las interfaces a un lado. De este modo, el diseño de la interfaz generalmente depende de la experiencia subjetiva del analista y no existe un procedimiento para extraer la interfaz de los procesos. Este artículo propone un nuevo método para generar interfaces de usuario a partir de modelos BPMN y Diagramas de Clases. La propuesta se basa en la identificación de reglas de generación de procesos a interfaces. Se han definido estereotipos para extender la notación BPMN en aquellas reglas donde haya más de una posible transformación. Estos estereotipos permiten aplicar la regla de forma inequívoca. Las reglas se extrajeron de cinco proyectos, tres existentes en el repositorio de Bizagi y dos de empresas reales. Específicamente, la propuesta se basa en la extracción de reglas para generar interfaces de usuario basadas en tres patrones, Patrón de Secuencia, Patrón de Decisión Implícita y Patrón de Ejecución Intercalada. Como resultado de nuestra propuesta, se han agregado catorce nuevos estereotipos a la notación BPMN. Para ilustrar la propuesta, los estereotipos se aplicaron a un ejemplo ilustrativo. Los resultados muestran que este trabajo es un "paso adelante" para la generación automática de códigos a partir modelos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-024.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-024.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Eduardo Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[diazsua@alumni.uv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Valencia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Ignacio Panach]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[joigpana@uv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Valencia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Silvia Rueda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[silvia.rueda@uv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Valencia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Oscar Pastor]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[opastor@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Métodos de Producción de Software, Universidad Politécnica de Valencia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/022]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>The MegaM@Rt2 ECSEL Project: MegaModelling at Runtime -- Scalable Model-based Framework for Continuous Development and Runtime Validation of Complex Systems</title>
		<link>https://biblioteca.sistedes.es/articulo/the-megamrt2-ecsel-project-megamodelling-at-runtime-scalable-model-based-framework-for-continuous-development-and-runtime-validation-of-complex-systems/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/the-megamrt2-ecsel-project-megamodelling-at-runtime-scalable-model-based-framework-for-continuous-development-and-runtime-validation-of-complex-systems/</guid>
		<description></description>
		<content><![CDATA[A major challenge for the European electronic components and systems (ECS) industry is to increase productivity and reduce costs while ensuring safety and quality. Model-Driven Engineering (MDE) principles have already shown valuable capabilities for the development of ECSs but still need to scale to support real-world scenarios implied by the full deployment and use of complex electronic systems, such as Cyber-Physical Systems, and real-time systems. Moreover, maintaining efficient traceability, integration and communication between fundamental stages of the development lifecycle (i.e., design time and runtime) is another challenge to the scalability of MDE tools and techniques. This paper presents "MegaModelling at runtime -- Scalable model-based framework for continuous development and runtime validation of complex systems" (MegaM@Rt2), an ECSEL--JU project whose main goal is to address the above mentioned challenges. Driven by both large and small industrial enterprises, with the support of research partners and technology providers, MegaM@Rt2 aims to deliver a framework of tools and methods for: (i) system engineering/design and continuous development,(ii) related runtime analysis, and (iii) global model and traceability management.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2949</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[the-megamrt2-ecsel-project-megamodelling-at-runtime-scalable-model-based-framework-for-continuous-development-and-runtime-validation-of-complex-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="megamodelling"><![CDATA[megamodelling]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<category domain="post_tag" nicename="runtime"><![CDATA[Runtime]]></category>
		<category domain="post_tag" nicename="system-design"><![CDATA[system design]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A major challenge for the European electronic components and systems (ECS) industry is to increase productivity and reduce costs while ensuring safety and quality. Model-Driven Engineering (MDE) principles have already shown valuable capabilities for the development of ECSs but still need to scale to support real-world scenarios implied by the full deployment and use of complex electronic systems, such as Cyber-Physical Systems, and real-time systems. Moreover, maintaining efficient traceability, integration and communication between fundamental stages of the development lifecycle (i.e., design time and runtime) is another challenge to the scalability of MDE tools and techniques. This paper presents "MegaModelling at runtime -- Scalable model-based framework for continuous development and runtime validation of complex systems" (MegaM@Rt2), an ECSEL--JU project whose main goal is to address the above mentioned challenges. Driven by both large and small industrial enterprises, with the support of research partners and technology providers, MegaM@Rt2 aims to deliver a framework of tools and methods for: (i) system engineering/design and continuous development,(ii) related runtime analysis, and (iii) global model and traceability management.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-025.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-025.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Abel Gómez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[agomezlla@uoc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Oberta de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Orlando Ávila-García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[orlando.avila@atos.net]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Atos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jordi Cabot]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jordi.cabot@icrea.cat]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ICREA - UOC (Internet interdisciplinary institute) - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José Ramón Juárez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jrjuarez@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[IK4-IKERLAN Research Center - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Aitor Urbieta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aurbieta@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[IK4-IKERLAN Research Center - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Eugenio Villar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[villar@teisa.unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad de Cantabria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/023]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evaluación automática de modelos aplicando técnicas de MBE</title>
		<link>https://biblioteca.sistedes.es/articulo/evaluacion-automatica-de-modelos-aplicando-tecnicas-de-mbe/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/evaluacion-automatica-de-modelos-aplicando-tecnicas-de-mbe/</guid>
		<description></description>
		<content><![CDATA[La construcción de modelos, como proceso de abstracción para definir una solución software, es una tarea que requiere ingenieros con cierta experiencia. Por un lado, modelos diferentes pueden ser igual de válidos para describir una misma solución y, por otro lado, disponer de una guía durante el aprendizaje de tareas de modelado puede ayudar a optimizar el proceso de desarrollo. Este artículo describe una propuesta para dar soporte a la evaluación de modelos utilizados durante las fases de análisis y diseño de un desarrollo de software. En particular, nuestro trabajo se aplica en la evaluación de modelos de casos de uso, clases y secuencias, como artefactos principales en la captura de requisitos, la descomposición modular y la descripción de comportamientos, respectivamente. Para evaluar dichos modelos, se ejecuta un conjunto de pruebas unitarias que son creadas automáticamente a partir de modelos de pruebas definidos conforme a un lenguaje específico de dominio.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2950</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evaluacion-automatica-de-modelos-aplicando-tecnicas-de-mbe]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="evaluacion"><![CDATA[Evaluación]]></category>
		<category domain="post_tag" nicename="generacion-automatica-de-pruebas"><![CDATA[Generación automática de pruebas]]></category>
		<category domain="post_tag" nicename="ingenieria-basada-en-modelos-mbe"><![CDATA[Ingeniería Basada en Modelos (MBE)]]></category>
		<category domain="post_tag" nicename="transformacion-modelo-a-texto-m2t"><![CDATA[Transformación Modelo-a-Texto (M2T)]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La construcción de modelos, como proceso de abstracción para definir una solución software, es una tarea que requiere ingenieros con cierta experiencia. Por un lado, modelos diferentes pueden ser igual de válidos para describir una misma solución y, por otro lado, disponer de una guía durante el aprendizaje de tareas de modelado puede ayudar a optimizar el proceso de desarrollo. Este artículo describe una propuesta para dar soporte a la evaluación de modelos utilizados durante las fases de análisis y diseño de un desarrollo de software. En particular, nuestro trabajo se aplica en la evaluación de modelos de casos de uso, clases y secuencias, como artefactos principales en la captura de requisitos, la descomposición modular y la descripción de comportamientos, respectivamente. Para evaluar dichos modelos, se ejecuta un conjunto de pruebas unitarias que son creadas automáticamente a partir de modelos de pruebas definidos conforme a un lenguaje específico de dominio.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-026.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-026.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Criado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[javi.criado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Informática Aplicada, Universidad de Almería - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Joaquín Cañadas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jjcanada@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Almería - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Luis Iribarne]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[luis.iribarne@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Informática Aplicada, Universidad de Almería - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/024]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Formally Modeling, Executing, and Testing Service-Oriented Systems with UML and OCL (YA PUBLICADO)</title>
		<link>https://biblioteca.sistedes.es/articulo/formally-modeling-executing-and-testing-service-oriented-systems-with-uml-and-ocl-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/formally-modeling-executing-and-testing-service-oriented-systems-with-uml-and-ocl-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[One of the issues that developers of service-oriented systems currently discuss is the lack of practical, but formal modeling notations and tools that can address the many different, important aspects. This paper presents an approach to model structural and behavioral properties of service-oriented systems with UML and OCL models. Essential service-oriented concepts as service request, service provision or orchestration are formally represented by UML concepts. The models can be executed, tested and analyzed. Feedback is given to the developer in terms of the UML and OCL model.Our approach supports the automatic generation of test scenarios in which, for example, the availability of services can be checked. Furthermore, the consistency of the service model can be proved by constructing test scenarios.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2951</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[formally-modeling-executing-and-testing-service-oriented-systems-with-uml-and-ocl-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="formal-modeling"><![CDATA[Formal modeling]]></category>
		<category domain="post_tag" nicename="service-oriented-systems"><![CDATA[Service-oriented systems]]></category>
		<category domain="post_tag" nicename="uml-ocl"><![CDATA[UML/OCL]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[One of the issues that developers of service-oriented systems currently discuss is the lack of practical, but formal modeling notations and tools that can address the many different, important aspects. This paper presents an approach to model structural and behavioral properties of service-oriented systems with UML and OCL models. Essential service-oriented concepts as service request, service provision or orchestration are formally represented by UML concepts. The models can be executed, tested and analyzed. Feedback is given to the developer in terms of the UML and OCL model.
Our approach supports the automatic generation of test scenarios in which, for example, the availability of services can be checked. Furthermore, the consistency of the service model can be proved by constructing test scenarios.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-027.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-027.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Loli Burgueño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[loli@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Málaga, GISUM/Atenea Research Group - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Martin Gogolla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gogolla@informatik.uni-bremen.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Database Systems Group, University of Bremen - Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/025]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia la integración de lenguajes de modelado para el diseño de servicios</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-la-integracion-de-lenguajes-de-modelado-para-el-diseno-de-servicios/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/hacia-la-integracion-de-lenguajes-de-modelado-para-el-diseno-de-servicios/</guid>
		<description></description>
		<content><![CDATA[A día de hoy existen diversas técnicas o notaciones para el modelado de negocio y/o procesos de negocio que permiten, con mayor o menor nivel de detalle, comprender, conceptualizar y representar la forma en que una organización es capaz de generar valor. Estas técnicas presentan similitudes y diferencias, pero en la mayoría de los casos la información que proporcionan es complementaria. Sin embargo, en la actualidad no existe un entorno tecnológico que permita trabajar eficazmente con varias de estas notaciones. Para afrontar este problema, en trabajos anteriores abordamos el desarrollo de un entorno de modelado que integrase un conjunto de DSLs visuales para dar soporte a la gestión integrada de diferentes notaciones para el modelado de negocio, como Canvas, e3value, Service Blueprint, PCN o BPMN. Una vez que disponemos de una primera versión funcional de este entorno, el siguiente paso que pretendemos abordar es el que se expone en este trabajo: el análisis de las correspondencias entre esas notaciones, y la consecuente automatización de las tareas o actividades que pueden derivarse de la identificación de esas relaciones.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2952</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-la-integracion-de-lenguajes-de-modelado-para-el-diseno-de-servicios]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="business-modeling"><![CDATA[Business Modeling]]></category>
		<category domain="post_tag" nicename="business-process-modeling"><![CDATA[Business Process Modeling]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<category domain="post_tag" nicename="service-design"><![CDATA[Service Design]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A día de hoy existen diversas técnicas o notaciones para el modelado de negocio y/o procesos de negocio que permiten, con mayor o menor nivel de detalle, comprender, conceptualizar y representar la forma en que una organización es capaz de generar valor. Estas técnicas presentan similitudes y diferencias, pero en la mayoría de los casos la información que proporcionan es complementaria. Sin embargo, en la actualidad no existe un entorno tecnológico que permita trabajar eficazmente con varias de estas notaciones. Para afrontar este problema, en trabajos anteriores abordamos el desarrollo de un entorno de modelado que integrase un conjunto de DSLs visuales para dar soporte a la gestión integrada de diferentes notaciones para el modelado de negocio, como Canvas, e3value, Service Blueprint, PCN o BPMN. Una vez que disponemos de una primera versión funcional de este entorno, el siguiente paso que pretendemos abordar es el que se expone en este trabajo: el análisis de las correspondencias entre esas notaciones, y la consecuente automatización de las tareas o actividades que pueden derivarse de la identificación de esas relaciones.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-028.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-028.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Javier Pérez Blanco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[francisco.perez@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group, University Rey Juan Carlos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group, University Rey Juan Carlos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[María Valeria De Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[valeria.decastro@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group, University Rey Juan Carlos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[David Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[david.granada@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group, University Rey Juan Carlos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group, University Rey Juan Carlos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/026]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evolutionary composition of QoS-aware web services: A many-objective perspective</title>
		<link>https://biblioteca.sistedes.es/articulo/evolutionary-composition-of-qos-aware-web-services-a-many-objective-perspective/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/evolutionary-composition-of-qos-aware-web-services-a-many-objective-perspective/</guid>
		<description></description>
		<content><![CDATA[Web service based applications often invoke services provided by third-parties in their workflow. The Quality of Service (QoS) provided by the invoked supplier can be expressed in terms of the Service Level Agreement specifying the values contracted for particular aspects like cost or throughput, among others. In this scenario, intelligent systems can support the engineer to scrutinise the service market in order to select those candidates that best fit with the expected composition focusing on different QoS aspects. This search problem, also known as QoS-aware web service composition, is characterised by the presence of many diverse QoS properties to be simultaneously optimised from a multi-objective perspective. Nevertheless, as the number of QoS properties considered during the design phase increases and a larger number of decision factors come into play, it becomes more difficult to find the most suitable candidate solutions, so more sophisticated techniques are required to explore and return diverse, competitive alternatives. With this aim, this paper explores the suitability of many objective evolutionary algorithms for addressing the binding problem of web services on the basis of a real-world benchmark with 9 QoS properties. A complete comparative study demonstrates that these techniques, never before applied to this problem, can achieve a better trade-off between all the QoS properties, or even promote specific QoS properties while keeping high values for the rest. In addition, this search process can be performed within a reasonable computational cost, enabling its adoption by intelligent and decision-support systems in the field of service oriented computation.Publicado en: Expert Systems with Applications, vol. 72, pp.357-370. 2017. DOI: http://dx.doi.org/10.1016/j.eswa.2016.10.047.IF(2016): 3,928 [18/133 Artificial Intelligence] (Q1).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2953</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evolutionary-composition-of-qos-aware-web-services-a-many-objective-perspective]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="many-objective-evolutionary-algorithms"><![CDATA[many-objective evolutionary algorithms]]></category>
		<category domain="post_tag" nicename="multi-objective-optimization"><![CDATA[multi-objective optimization]]></category>
		<category domain="post_tag" nicename="qos-aware-web-service-composition"><![CDATA[QoS-aware web service composition]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Web service based applications often invoke services provided by third-parties in their workflow. The Quality of Service (QoS) provided by the invoked supplier can be expressed in terms of the Service Level Agreement specifying the values contracted for particular aspects like cost or throughput, among others. In this scenario, intelligent systems can support the engineer to scrutinise the service market in order to select those candidates that best fit with the expected composition focusing on different QoS aspects. This search problem, also known as QoS-aware web service composition, is characterised by the presence of many diverse QoS properties to be simultaneously optimised from a multi-objective perspective. Nevertheless, as the number of QoS properties considered during the design phase increases and a larger number of decision factors come into play, it becomes more difficult to find the most suitable candidate solutions, so more sophisticated techniques are required to explore and return diverse, competitive alternatives. With this aim, this paper explores the suitability of many objective evolutionary algorithms for addressing the binding problem of web services on the basis of a real-world benchmark with 9 QoS properties. A complete comparative study demonstrates that these techniques, never before applied to this problem, can achieve a better trade-off between all the QoS properties, or even promote specific QoS properties while keeping high values for the rest. In addition, this search process can be performed within a reasonable computational cost, enabling its adoption by intelligent and decision-support systems in the field of service oriented computation.

Publicado en: Expert Systems with Applications, vol. 72, pp.357-370. 2017. DOI: http://dx.doi.org/10.1016/j.eswa.2016.10.047.

IF(2016): 3,928 [18/133 Artificial Intelligence] (Q1).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-029.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-029.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aurora Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aramirez@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Antonio Parejo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[japarejo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José Raúl Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/027]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Diseño de un marco de trabajo dirigido por modelos y soportado por herramientas para mejorar la gestión de guías clínicas y procesos asistenciales</title>
		<link>https://biblioteca.sistedes.es/articulo/diseno-de-un-marco-de-trabajo-dirigido-por-modelos-y-soportado-por-herramientas-para-mejorar-la-gestion-de-guias-clinicas-y-procesos-asistenciales/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/diseno-de-un-marco-de-trabajo-dirigido-por-modelos-y-soportado-por-herramientas-para-mejorar-la-gestion-de-guias-clinicas-y-procesos-asistenciales/</guid>
		<description></description>
		<content><![CDATA[El Proyecto IDE4ICDS se mueve en el contexto médico para dar solu-ción a la gestión del ciclo de vida de guías clínicas. Actualmente, las guías clíni-cas están definidas de forma textual, lo que las hace difíciles de seguir en el día a día. Esto provoca, entre otros factores, variabilidad en la práctica clínica. En este proyecto se presenta una metodología guiada por modelos que permite auto-matizar la gestión de guías clínicas, así como una plataforma software que le de soporte, permitiendo definir, ejecutar y monitorizar guías clínicas. Dicha plata-forma ha sido validada con profesionales sanitarios del Hospital Virgen del Rocío (Sevilla), obteniendo resultados prometedores. Actualmente se encuentra en fase de pilotaje en Atención Primaria con pacientes que sufren Diabetes Mellitus Tipo 2.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2954</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[diseno-de-un-marco-de-trabajo-dirigido-por-modelos-y-soportado-por-herramientas-para-mejorar-la-gestion-de-guias-clinicas-y-procesos-asistenciales]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="clinical-decision-support"><![CDATA[Clinical Decision Support]]></category>
		<category domain="post_tag" nicename="clinical-practices-guidelines"><![CDATA[Clinical Practices Guidelines]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El Proyecto IDE4ICDS se mueve en el contexto médico para dar solu-ción a la gestión del ciclo de vida de guías clínicas. Actualmente, las guías clíni-cas están definidas de forma textual, lo que las hace difíciles de seguir en el día a día. Esto provoca, entre otros factores, variabilidad en la práctica clínica. En este proyecto se presenta una metodología guiada por modelos que permite auto-matizar la gestión de guías clínicas, así como una plataforma software que le de soporte, permitiendo definir, ejecutar y monitorizar guías clínicas. Dicha plata-forma ha sido validada con profesionales sanitarios del Hospital Virgen del Rocío (Sevilla), obteniendo resultados prometedores. Actualmente se encuentra en fase de pilotaje en Atención Primaria con pacientes que sufren Diabetes Mellitus Tipo 2.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-030.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-030.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Virginia Cid De La Paz Furest]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[virginia.cid@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[IWT2 Group. University of Seville. Spain. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Julián Alberto García García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[julian.garcia@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[IWT2 Group. University of Seville. Spain. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Ramos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanmanuel.ramos@soltel.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Soltel S.A - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[M.J. Escalona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mjescalona@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/028]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Expansión cuantitativa del método MoSCoW para la priorización de requisitos</title>
		<link>https://biblioteca.sistedes.es/articulo/expansion-cuantitativa-del-metodo-moscow-para-la-priorizacion-de-requisitos/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/expansion-cuantitativa-del-metodo-moscow-para-la-priorizacion-de-requisitos/</guid>
		<description></description>
		<content><![CDATA[La priorización de los requisitos a ser incluidos en el producto ?nal es un complejo proceso de decisión multicriterio que suele implicar llegar al equilibrio entre el bene?cio para el negocio de cada requisito y el consumo de recursos. Existen distintos factores y dimensiones a considerar en la priorización de requisitos, muchos de ellos de carácter cualitativo. Sin embargo, algunos métodos también han utilizado las propiedades cuantitativas estimadas, siendo muchas de estas soluciones del ámbito de las técnicas de optimización. En este trabajo se propone y estudia la validez de un algoritmo de agrupamiento muy conocido, k-medias, junto con el método subjetivo más ampliamente utilizado, el método MoSCoW, para la priorización de requisitos. Los resultados experimentales, sobre dos casos de 20 y 100 requisitos respectivamente, muestran la validez de la propuesta en la identi?cación de los requisitos que dan mayor valor al sistema a construir y que aseguran el mayor bene?cio en el proyecto.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2955</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[expansion-cuantitativa-del-metodo-moscow-para-la-priorizacion-de-requisitos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="ingenieria-de-requisitos"><![CDATA[ingeniería de requisitos]]></category>
		<category domain="post_tag" nicename="k-medias"><![CDATA[k-medias]]></category>
		<category domain="post_tag" nicename="moscow"><![CDATA[MoSCoW]]></category>
		<category domain="post_tag" nicename="priorizacion-de-requisitos"><![CDATA[Priorización de requisitos]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La priorización de los requisitos a ser incluidos en el producto ?nal es un complejo proceso de decisión multicriterio que suele implicar llegar al equilibrio entre el bene?cio para el negocio de cada requisito y el consumo de recursos. Existen distintos factores y dimensiones a considerar en la priorización de requisitos, muchos de ellos de carácter cualitativo. Sin embargo, algunos métodos también han utilizado las propiedades cuantitativas estimadas, siendo muchas de estas soluciones del ámbito de las técnicas de optimización. En este trabajo se propone y estudia la validez de un algoritmo de agrupamiento muy conocido, k-medias, junto con el método subjetivo más ampliamente utilizado, el método MoSCoW, para la priorización de requisitos. Los resultados experimentales, sobre dos casos de 20 y 100 requisitos respectivamente, muestran la validez de la propuesta en la identi?cación de los requisitos que dan mayor valor al sistema a construir y que aseguran el mayor bene?cio en el proyecto.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-031.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-031.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Del Sagrado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jsagrado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Informatics, University of Almería - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Isabel María Del Águila]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[imaguila@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Almería - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/029]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Obtención de diagramas de objetivos para sistemas Teleo-Reactivos: una aproximación metodológica</title>
		<link>https://biblioteca.sistedes.es/articulo/obtencion-de-diagramas-de-objetivos-para-sistemas-teleo-reactivos-una-aproximacion-metodologica/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/obtencion-de-diagramas-de-objetivos-para-sistemas-teleo-reactivos-una-aproximacion-metodologica/</guid>
		<description></description>
		<content><![CDATA[Este artículo presenta un método para obtener un diagrama TRiStar partiendo de la descripción textual de un sistema Teleo-Reactivo. El método se ilustra con un ejemplo clásico en la literatura de sistemas Teleo-Reactivos: el recolector de latas. El uso de este método permitirá facilitar la especificación y la reutilización de sistemas Teleo-Reactivos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2956</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[obtencion-de-diagramas-de-objetivos-para-sistemas-teleo-reactivos-una-aproximacion-metodologica]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="metodologia"><![CDATA[Metodología]]></category>
		<category domain="post_tag" nicename="teleo-reactivo"><![CDATA[Teleo-Reactivo]]></category>
		<category domain="post_tag" nicename="tristar"><![CDATA[TRiStar]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo presenta un método para obtener un diagrama TRiStar partiendo de la descripción textual de un sistema Teleo-Reactivo. El método se ilustra con un ejemplo clásico en la literatura de sistemas Teleo-Reactivos: el recolector de latas. El uso de este método permitirá facilitar la especificación y la reutilización de sistemas Teleo-Reactivos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-032.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-032.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José M Morales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[josemiguel.morales@upct.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[UPCT - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pedro Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pedro.sanchez@upct.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[UPCT - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Bárbara Álvarez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[balvarez@upct.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[UPCT - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Sanchez Garcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[a.sanchez@electronica-submarina.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[SAES - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Elena Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[Elena.Navarro@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/030]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>MOTIV: selección de pruebas para algoritmos de detección de movimiento en vídeos usando técnicas de líneas de productos software</title>
		<link>https://biblioteca.sistedes.es/articulo/motiv-seleccion-de-pruebas-para-algoritmos-de-deteccion-de-movimiento-en-videos-usando-tecnicas-de-lineas-de-productos-software/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/motiv-seleccion-de-pruebas-para-algoritmos-de-deteccion-de-movimiento-en-videos-usando-tecnicas-de-lineas-de-productos-software/</guid>
		<description></description>
		<content><![CDATA[Las líneas de producto software se usan para gestionar la producción de sistemas software con un alto grado de variabilidad lo que puede permitir tener un mejor tiempo de respuesta para poder configurar un producto de acuerdo a sus especificaciones concretas en un escenario de uso determinado. La investigación en líneas de producto software se ha centrado en las últimas décadas en proponer procesos, técnicas, herramientas y métodos para gestionar la variabilidad a todos los niveles: desde los requisitos, hasta la generación de código. En este sentido, se han desarrollado distintas técnicas que pueden ser utilizadas en distintos escenarios  más allá de la gestión de líneas de producto software. Es el caso del conocido como análisis automático de modelos de características. En este proyecto se usaron técnicas que provienen de este área para afrontar un reto tecnológico en un consorcio con empresas que usaban distintos algoritmos para detectar movimientos en sistemas de vídeo vigilancia. En concreto, se usaron técnicas de modelado y selección de casos de prueba usando modelos de características. La aportación tecnológica permitió una reducción considerable de los costes en la producción de algoritmos de detección de movimientos y la mejora en la detección de fallos en los sistemas. El consorcio estuvo formado por dos empresas francesas e INRIA donde trabajaban varios de los autores del trabajo en el momento de la ejecución del proyecto. Además, se contó con el asesoramiento de la Universidad de Sevilla.   keywords{líneas de producto software, modelos de características, selección de pruebas]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2957</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[motiv-seleccion-de-pruebas-para-algoritmos-de-deteccion-de-movimiento-en-videos-usando-tecnicas-de-lineas-de-productos-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="lineas-de-producto-software"><![CDATA[Líneas de Producto Software]]></category>
		<category domain="post_tag" nicename="modelos-de-caracteristicas"><![CDATA[modelos de características]]></category>
		<category domain="post_tag" nicename="seleccion-de-pruebas"><![CDATA[selección de pruebas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las líneas de producto software se usan para gestionar la producción de sistemas software con un alto grado de variabilidad lo que puede permitir tener un mejor tiempo de respuesta para poder configurar un producto de acuerdo a sus especificaciones concretas en un escenario de uso determinado. La investigación en líneas de producto software se ha centrado en las últimas décadas en proponer procesos, técnicas, herramientas y métodos para gestionar la variabilidad a todos los niveles: desde los requisitos, hasta la generación de código. En este sentido, se han desarrollado distintas técnicas que pueden ser utilizadas en distintos escenarios  más allá de la gestión de líneas de producto software. Es el caso del conocido como análisis automático de modelos de características. En este proyecto se usaron técnicas que provienen de este área para afrontar un reto tecnológico en un consorcio con empresas que usaban distintos algoritmos para detectar movimientos en sistemas de vídeo vigilancia. En concreto, se usaron técnicas de modelado y selección de casos de prueba usando modelos de características. La aportación tecnológica permitió una reducción considerable de los costes en la producción de algoritmos de detección de movimientos y la mejora en la detección de fallos en los sistemas. El consorcio estuvo formado por dos empresas francesas e INRIA donde trabajaban varios de los autores del trabajo en el momento de la ejecución del proyecto. Además, se contó con el asesoramiento de la Universidad de Sevilla.
keywords{líneas de producto software, modelos de características, selección de pruebas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-033.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-033.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José A. Galindo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jagalindo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mauricio Alférez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[alferez@svv.lu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Luxembourg - Luxembourg]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Mathieu Acher]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mathieu.acher@irisa.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[INRIA - France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Benoit Baudry]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[baudry@kth.se]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[KTH Royal Institute of Technology - Sweden]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[David Benavides]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[benavides@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/031]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Usabilidad de Software: Una Apuesta Corporativa</title>
		<link>https://biblioteca.sistedes.es/articulo/usabilidad-de-software-una-apuesta-corporativa/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/usabilidad-de-software-una-apuesta-corporativa/</guid>
		<description></description>
		<content><![CDATA[Este trabajo presenta los resultados de una síntesis cualitativa de la literatura orientada a identificar pautas y recomendaciones que ayuden a integrar la usabilidad en una organización software desde el punto de vista corporativo. Los resultados constituyen el primer paso para definir un conjunto de guías y prácticas que puedan usar los gestores o responsables de calidad de las organizaciones software para crear una cultura de usabilidad que ayude a integrar dicho atributo de calidad de manera sostenible en los distintos proyectos de la organización. La metodología utilizada es la síntesis temática, con la que se han sintetizado 44 artículos dando como resultado la identificación de cinco prácticas generales que agrupan otras 13 prácticas más concretas para abordar este fin. Finalmente, se presenta un modelo de interrelaciones entre las distintas prácticas identificadas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2958</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[usabilidad-de-software-una-apuesta-corporativa]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="experiencia-de-usuarios"><![CDATA[experiencia de usuarios]]></category>
		<category domain="post_tag" nicename="sintesis-tematica"><![CDATA[síntesis temática]]></category>
		<category domain="post_tag" nicename="usabilidad"><![CDATA[usabilidad]]></category>
		<category domain="post_tag" nicename="usabilidad-a-nivel-organizativo"><![CDATA[usabilidad a nivel organizativo]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este trabajo presenta los resultados de una síntesis cualitativa de la literatura orientada a identificar pautas y recomendaciones que ayuden a integrar la usabilidad en una organización software desde el punto de vista corporativo. Los resultados constituyen el primer paso para definir un conjunto de guías y prácticas que puedan usar los gestores o responsables de calidad de las organizaciones software para crear una cultura de usabilidad que ayude a integrar dicho atributo de calidad de manera sostenible en los distintos proyectos de la organización. La metodología utilizada es la síntesis temática, con la que se han sintetizado 44 artículos dando como resultado la identificación de cinco prácticas generales que agrupan otras 13 prácticas más concretas para abordar este fin. Finalmente, se presenta un modelo de interrelaciones entre las distintas prácticas identificadas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-034.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-034.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carmen L. Carvajal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carmen.carvajal07@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ana M. Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ammoreno@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/032]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automated inference of likely metamorphic relations for model transformations (YA PUBLICADO)</title>
		<link>https://biblioteca.sistedes.es/articulo/automated-inference-of-likely-metamorphic-relations-for-model-transformations-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/automated-inference-of-likely-metamorphic-relations-for-model-transformations-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Model transformations play a cornerstone role in Model-Driven Engineering (MDE) as they provide the essential mechanisms for manipulating and transforming models. Checking whether the output of a model transformation is correct is a manual and errorprone task, referred to as the oracle problem. Metamorphic testing alleviates the oracle problem by exploiting the relations among different inputs and outputs of the program under test, so-called metamorphic relations (MRs). One of the main challenges in metamorphic testing is the automated inference of likely MRs. This paper proposes an approach to automatically infer likely MRs for ATL model transformations, where the tester does not need to have any knowledge of the transformation. The inferred MRs aim at detecting faults in model transformations in three application scenarios, namely regression testing, incremental transformations and migrations among transformation languages. In the experiments performed, the inferred likely MRs have proved to be quite accurate, with a precision of 96.4% from a total of 4101 true positives out of 4254 MRs inferred. Furthermore, they have been useful for identifying mutants in regression testing scenarios, with a mutation score of 93.3%. Finally, our approach can be used in conjunction with current approaches for the automatic generation of test cases. Artículo publicado en The Journal of Systems and Software, Vol 136, pp 188-208 (Available Online May 2017; Final Published Version February 2018) - Q1. http://dx.doi.org/10.1016/j.jss.2017.05.043]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2959</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automated-inference-of-likely-metamorphic-relations-for-model-transformations-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="automatic-inference"><![CDATA[Automatic inference]]></category>
		<category domain="post_tag" nicename="generic-approach"><![CDATA[Generic approach]]></category>
		<category domain="post_tag" nicename="metamorphic-relations"><![CDATA[Metamorphic relations]]></category>
		<category domain="post_tag" nicename="metamorphic-testing"><![CDATA[metamorphic testing]]></category>
		<category domain="post_tag" nicename="model-transformations"><![CDATA[model transformations]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Model transformations play a cornerstone role in Model-Driven Engineering (MDE) as they provide the essential mechanisms for manipulating and transforming models. Checking whether the output of a model transformation is correct is a manual and errorprone task, referred to as the oracle problem. Metamorphic testing alleviates the oracle problem by exploiting the relations among different inputs and outputs of the program under test, so-called metamorphic relations (MRs). One of the main challenges in metamorphic testing is the automated inference of likely MRs.

This paper proposes an approach to automatically infer likely MRs for ATL model transformations, where the tester does not need to have any knowledge of the transformation. The inferred MRs aim at detecting faults in model transformations in three application scenarios, namely regression testing, incremental transformations and migrations among transformation languages. In the experiments performed, the inferred likely MRs have proved to be quite accurate, with a precision of 96.4% from a total of 4101 true positives out of 4254 MRs inferred. Furthermore, they have been useful for identifying mutants in regression testing scenarios, with a mutation score of 93.3%. Finally, our approach can be used in conjunction with current approaches for the automatic
generation of test cases.

Artículo publicado en The Journal of Systems and Software, Vol 136, pp 188-208 (Available Online May 2017; Final Published Version February 2018) - Q1.
http://dx.doi.org/10.1016/j.jss.2017.05.043]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-036.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-036.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Troya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jtroya@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/033]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación de datos NoSQL usando esquemas de bases de datos inferidos</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-de-datos-nosql-usando-esquemas-de-bases-de-datos-inferidos/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/generacion-de-datos-nosql-usando-esquemas-de-bases-de-datos-inferidos/</guid>
		<description></description>
		<content><![CDATA[La generación automática de datos resulta muy adecuada para realizar pruebas sobre bases de datos. Para sistemas relacionales se han definido diferentes enfoques y existe un buen número de herramientas. Sin embargo, todavía se ha prestado escasa atención a este problema para sistemas NoSQL. En este trabajo se presenta un primer prototipo de una herramienta desarrollada para generar datos NoSQL a partir de esquemas inferidos y representados como modelos conformes al metamodelo NoSQLSchema. Se describe el proceso de generación y la validación realizados, y se comenta el trabajo futuro.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2960</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-de-datos-nosql-usando-esquemas-de-bases-de-datos-inferidos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="generacion-de-bases-de-datos"><![CDATA[Generación de bases de datos]]></category>
		<category domain="post_tag" nicename="mongodb"><![CDATA[MongoDB]]></category>
		<category domain="post_tag" nicename="sistemas-nosql"><![CDATA[Sistemas NoSQL]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La generación automática de datos resulta muy adecuada para realizar pruebas sobre bases de datos. Para sistemas relacionales se han definido diferentes enfoques y existe un buen número de herramientas. Sin embargo, todavía se ha prestado escasa atención a este problema para sistemas NoSQL. En este trabajo se presenta un primer prototipo de una herramienta desarrollada para generar datos NoSQL a partir de esquemas inferidos y representados como modelos conformes al metamodelo NoSQLSchema. Se describe el proceso de generación y la validación realizados, y se comenta el trabajo futuro.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-037.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-037.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alberto Hernández Chillón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alberto.hernandez1@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia, Cátedra SAES-UMU - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Diego Sevilla Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[dsevilla@ditec.um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesus Garcia-Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jmolina@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/034]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evaluación del mantenimiento de la consistencia lógica en Cassandra</title>
		<link>https://biblioteca.sistedes.es/articulo/evaluacion-del-mantenimiento-de-la-consistencia-logica-en-cassandra/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/evaluacion-del-mantenimiento-de-la-consistencia-logica-en-cassandra/</guid>
		<description></description>
		<content><![CDATA[En las bases de datos NoSQL como Cassandra es común que exista duplicidad de los datos entre las tablas, a diferencia de los modelos relacionales normalizados. Esto se debe a que las tablas son diseñadas en base a consultas y a la ausencia de relaciones entre ellas. Por tanto, si los datos no son modificados convenientemente se pueden producir inconsistencias en la información almace-nada. A su vez, es relativamente fácil que se introduzcan defectos que ocasionen inconsistencias en Cassandra, siendo éstos difíciles de detectar utilizando técnicas convencionales de pruebas dinámicas. Con el objetivo de ayudar al desarro-llador a evitar la producción de inconsistencias, proponemos un nuevo método que, usando un modelo conceptual, es capaz de establecer los procesos necesarios para asegurar la calidad de los datos desde el punto de vista de su consistencia a través de pruebas estáticas. En este trabajo evaluamos la eficiencia de este método ante un caso de estudio en el que insertamos tuplas en entidades y relaciones del modelo conceptual y extraemos qué es necesario para mantener la consistencia en el modelo lógico. Los resultados muestran como la desnormalización de los datos puede aumentar la complejidad del mantenimiento de la consistencia, no solo necesitando saber dónde se debe mantener la consistencia sino también cómo hay que mantenerla.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2961</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evaluacion-del-mantenimiento-de-la-consistencia-logica-en-cassandra]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="cassandra"><![CDATA[Cassandra]]></category>
		<category domain="post_tag" nicename="consistencia-logica"><![CDATA[Consistencia Lógica]]></category>
		<category domain="post_tag" nicename="evaluacion"><![CDATA[Evaluación]]></category>
		<category domain="post_tag" nicename="pruebas-estaticas"><![CDATA[Pruebas Estáticas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En las bases de datos NoSQL como Cassandra es común que exista duplicidad de los datos entre las tablas, a diferencia de los modelos relacionales normalizados. Esto se debe a que las tablas son diseñadas en base a consultas y a la ausencia de relaciones entre ellas. Por tanto, si los datos no son modificados convenientemente se pueden producir inconsistencias en la información almace-nada. A su vez, es relativamente fácil que se introduzcan defectos que ocasionen inconsistencias en Cassandra, siendo éstos difíciles de detectar utilizando técnicas convencionales de pruebas dinámicas. Con el objetivo de ayudar al desarro-llador a evitar la producción de inconsistencias, proponemos un nuevo método que, usando un modelo conceptual, es capaz de establecer los procesos necesarios para asegurar la calidad de los datos desde el punto de vista de su consistencia a través de pruebas estáticas. En este trabajo evaluamos la eficiencia de este método ante un caso de estudio en el que insertamos tuplas en entidades y relaciones del modelo conceptual y extraemos qué es necesario para mantener la consistencia en el modelo lógico. Los resultados muestran como la desnormalización de los datos puede aumentar la complejidad del mantenimiento de la consistencia, no solo necesitando saber dónde se debe mantener la consistencia sino también cómo hay que mantenerla.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-038.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-038.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Suárez-Otero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[suarezgpablo@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Maria José Suárez-Cabal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cabal@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/035]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Gestión de Proyectos con PMBOK y LEGO(R) SERIOUD PLAY(R)</title>
		<link>https://biblioteca.sistedes.es/articulo/gestion-de-proyectos-con-pmbok-y-legor-serioud-playr/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/gestion-de-proyectos-con-pmbok-y-legor-serioud-playr/</guid>
		<description></description>
		<content><![CDATA[La comunicación es una de las técnicas más importantes en la gestión de proyectos. La técnica más utilizada en A Guide to the Project Management Body of Knowledge (PMBOK) son los juicios de experto junto contras di-námicas de trabajo en grupo como reuniones. Sin embargo, las reuniones ha-bituales en las que una persona habla y el resto escucha presentan un por-centaje de actividad mental y de implicación muy bajo. Por tanto una mejora en la manera de trabajar en grupo supone una mejora en la gestión de un proyecto. En este trabajo, se explora el uso de la metodología de trabajo en grupo LEGO® SERIOUS PLAY® en la gestión de proyectos. Para ello, este trabajo propone 11 talleres utilizando esta metodología que dan soporte a los procesos basados en comunicación y trabajo en grupo de PMBOK. Las eva-luaciones preliminares de estos talleres por parte de sus asistentes muestran un alto grado de satisfacción y participación en los mismos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2962</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[gestion-de-proyectos-con-pmbok-y-legor-serioud-playr]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="comunicacion"><![CDATA[comunicación]]></category>
		<category domain="post_tag" nicename="gestion-de-proyectos"><![CDATA[gestión de proyectos]]></category>
		<category domain="post_tag" nicename="lego-serious-play"><![CDATA[LEGO SERIOUS PLAY]]></category>
		<category domain="post_tag" nicename="pmbok"><![CDATA[PMBOK]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La comunicación es una de las técnicas más importantes en la gestión de proyectos. La técnica más utilizada en A Guide to the Project Management Body of Knowledge (PMBOK) son los juicios de experto junto contras di-námicas de trabajo en grupo como reuniones. Sin embargo, las reuniones ha-bituales en las que una persona habla y el resto escucha presentan un por-centaje de actividad mental y de implicación muy bajo. Por tanto una mejora en la manera de trabajar en grupo supone una mejora en la gestión de un proyecto. En este trabajo, se explora el uso de la metodología de trabajo en grupo LEGO® SERIOUS PLAY® en la gestión de proyectos. Para ello, este trabajo propone 11 talleres utilizando esta metodología que dan soporte a los procesos basados en comunicación y trabajo en grupo de PMBOK. Las eva-luaciones preliminares de estos talleres por parte de sus asistentes muestran un alto grado de satisfacción y participación en los mismos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-039.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-039.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Gutierrez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[javierj@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[María José Escalona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mjescalona@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/036]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Pablo Suárez-Otero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[suarezgpablo@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[moranjesus@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesús Morán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>vEXgine: Extendiendo el Motor de Ejecución de CVL</title>
		<link>https://biblioteca.sistedes.es/articulo/vexgine-extendiendo-el-motor-de-ejecucion-de-cvl/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/vexgine-extendiendo-el-motor-de-ejecucion-de-cvl/</guid>
		<description></description>
		<content><![CDATA[El Lenguaje CVL (textit{Common Variability Language}) carece de una herramienta flexible que permita poner en práctica las necesidades industriales del modelado de la variabilidad en Líneas de Producto Software. Las herramientas existentes que proporcionan soporte para CVL son prototipos incompletos, o se centran principalmente en la especificación de la variabilidad, sin llegar a resolverla sobre modelos reales. Además, no existe una API que permita la interacción directa con el motor CVL para extenderlo o usarlo en una aplicación independiente. Este artículo presenta vEXgine, una implementación adaptable y extensible del motor de ejecución de la variabilidad de CVL.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2963</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[vexgine-extendiendo-el-motor-de-ejecucion-de-cvl]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="cvl"><![CDATA[CVL]]></category>
		<category domain="post_tag" nicename="linea-de-producto-software"><![CDATA[Línea de Producto Software]]></category>
		<category domain="post_tag" nicename="variabilidad"><![CDATA[Variabilidad]]></category>
		<category domain="post_tag" nicename="vexgine"><![CDATA[vEXgine]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El Lenguaje CVL (textit{Common Variability Language}) carece de una herramienta flexible que permita poner en práctica las necesidades industriales del modelado de la variabilidad en Líneas de Producto Software. Las herramientas existentes que proporcionan soporte para CVL son prototipos incompletos, o se centran principalmente en la especificación de la variabilidad, sin llegar a resolverla sobre modelos reales. Además, no existe una API que permita la interacción directa con el motor CVL para extenderlo o usarlo en una aplicación independiente. Este artículo presenta vEXgine, una implementación adaptable y extensible del motor de ejecución de la variabilidad de CVL.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-040.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-040.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Miguel Horcas Aguilera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[horcas@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mónica Pinto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pinto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Mlaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/037]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A First Approach towards Storage and Query Processing of Big Spatial Networks in Scalable and Distributed Systems</title>
		<link>https://biblioteca.sistedes.es/articulo/a-first-approach-towards-storage-and-query-processing-of-big-spatial-networks-in-scalable-and-distributed-systems/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-first-approach-towards-storage-and-query-processing-of-big-spatial-networks-in-scalable-and-distributed-systems/</guid>
		<description></description>
		<content><![CDATA[Due to the ubiquitous use of spatial data applications and the large amounts of spatial data that these applications generate, the processing of large-scale queries in distributed systems is becoming increasingly popular. Complex spatial systems are very often organized under the form of Spatial Networks, a type of graph where nodes and edges are embedded in space. Examples of these spatial networks are transportation and mobility networks, mobile phone networks, social and contact networks, etc. When these spatial networks are big enough that exceed the capacity of commonly-used spatial computing technologies, we have Big Spatial Networks, and to manage them is necessary the use of distributed graph-parallel systems. In this paper, we describe our emerging work concerning the design of new storage methods and query processing algorithms over big spatial networks in scalable and distributed systems, which is a very active research area in the past years.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2964</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-first-approach-towards-storage-and-query-processing-of-big-spatial-networks-in-scalable-and-distributed-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="distributed-systems"><![CDATA[Distributed Systems]]></category>
		<category domain="post_tag" nicename="query-processing"><![CDATA[query processing]]></category>
		<category domain="post_tag" nicename="spatial-networks"><![CDATA[Spatial Networks]]></category>
		<category domain="post_tag" nicename="storage-methods"><![CDATA[Storage Methods]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Due to the ubiquitous use of spatial data applications and the large amounts of spatial data that these applications generate, the processing of large-scale queries in distributed systems is becoming increasingly popular. Complex spatial systems are very often organized under the form of Spatial Networks, a type of graph where nodes and edges are embedded in space. Examples of these spatial networks are transportation and mobility networks, mobile phone networks, social and contact networks, etc. When these spatial networks are big enough that exceed the capacity of commonly-used spatial computing technologies, we have Big Spatial Networks, and to manage them is necessary the use of distributed graph-parallel systems. In this paper, we describe our emerging work concerning the design of new storage methods and query processing algorithms over big spatial networks in scalable and distributed systems, which is a very active research area in the past years.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-041.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-041.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manel Mena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[manel.mena@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Almeria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Corral]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[acorral@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Almeria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Luis Iribarne]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[luis.iribarne@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Almeria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/038]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una experiencia con transformaciones modelo-modelo en un proyecto de modernización</title>
		<link>https://biblioteca.sistedes.es/articulo/una-experiencia-con-transformaciones-modelo-modelo-en-un-proyecto-de-modernizacion/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/una-experiencia-con-transformaciones-modelo-modelo-en-un-proyecto-de-modernizacion/</guid>
		<description></description>
		<content><![CDATA[Las transformaciones modelo-modelo en procesos de reingeniería, en especial en la etapa de ingeniería inversa, suelen ser complejas e implican la escritura de mucho código imperativo. Este hecho junto a la falta de madurez de los lenguajes y entornos para el desarrollo de este tipo de transformaciones fueron los principales factores que influyeron en la decisión de usar Java y el API EMF dentro de un proyecto de migración de aplicaciones Oracle Forms a Java. En este artículo se presentan los resultados iniciales de una comparación entre diferentes soluciones para escribir transformaciones modelo-modelo a partir de las transformaciones implementadas en ese proyecto.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2965</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-experiencia-con-transformaciones-modelo-modelo-en-un-proyecto-de-modernizacion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="atl"><![CDATA[ATL]]></category>
		<category domain="post_tag" nicename="comparacion"><![CDATA[comparación]]></category>
		<category domain="post_tag" nicename="ingenieria-inversa"><![CDATA[Ingeniería Inversa]]></category>
		<category domain="post_tag" nicename="java"><![CDATA[Java]]></category>
		<category domain="post_tag" nicename="lenguajes-de-transformacion-modelo-modelo"><![CDATA[lenguajes de transformación modelo-modelo]]></category>
		<category domain="post_tag" nicename="migracion"><![CDATA[migración]]></category>
		<category domain="post_tag" nicename="qvt"><![CDATA[QVT]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las transformaciones modelo-modelo en procesos de reingeniería, en especial en la etapa de ingeniería inversa, suelen ser complejas e implican la escritura de mucho código imperativo. Este hecho junto a la falta de madurez de los lenguajes y entornos para el desarrollo de este tipo de transformaciones fueron los principales factores que influyeron en la decisión de usar Java y el API EMF dentro de un proyecto de migración de aplicaciones Oracle Forms a Java. En este artículo se presentan los resultados iniciales de una comparación entre diferentes soluciones para escribir transformaciones modelo-modelo a partir de las transformaciones implementadas en ese proyecto.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-042.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-042.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Javier Fernández Candel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cjferna@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jesús García-Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jmolina@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco Javier Bermúdez Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fjavier@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Diego Sevilla Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[dsevilla@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/039]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Confianza e Incertidumbre en Modelos y Transformaciones de Modelos</title>
		<link>https://biblioteca.sistedes.es/articulo/confianza-e-incertidumbre-en-modelos-y-transformaciones-de-modelos/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/confianza-e-incertidumbre-en-modelos-y-transformaciones-de-modelos/</guid>
		<description></description>
		<content><![CDATA[La incertidumbre, tanto en los datos como en los mecanismos que manipulan y operan sobre ellos, es un tema crucial en sistemas que trabajan con entornos físicos. Una incertidumbre que puede ser debida a diversos factores, como fuentes de datos poco fiables, tolerancia en las mediciones o la incapacidad para determinar si un determinado evento ha sucedido realmente o no. En este trabajo proponemos el uso de modelos con confianza, donde los objetos pueden llevar asociadas probabilidades. Al igual que en los modelos, la incertidumbre puede trasladarse a las transformaciones de modelos,  donde las reglas también pueden estar sujetas a incertidumbre.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2966</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[confianza-e-incertidumbre-en-modelos-y-transformaciones-de-modelos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="confianza"><![CDATA[Confianza]]></category>
		<category domain="post_tag" nicename="incertidumbre"><![CDATA[Incertidumbre]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="modelos"><![CDATA[Modelos]]></category>
		<category domain="post_tag" nicename="transformaciones-de-modelos"><![CDATA[Transformaciones de Modelos]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La incertidumbre, tanto en los datos como en los mecanismos que manipulan y operan sobre ellos, es un tema crucial en sistemas que trabajan con entornos físicos. Una incertidumbre que puede ser debida a diversos factores, como fuentes de datos poco fiables, tolerancia en las mediciones o la incapacidad para determinar si un determinado evento ha sucedido realmente o no. En este trabajo proponemos el uso de modelos con confianza, donde los objetos pueden llevar asociadas probabilidades. Al igual que en los modelos, la incertidumbre puede trasladarse a las transformaciones de modelos,  donde las reglas también pueden estar sujetas a incertidumbre.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-043.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-043.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Loli Burgueño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[loli@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Gala Barquero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gala@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Nathalie Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[moreno@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel F. Bertoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[bertoa@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Antonio Vallecillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[av@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/040]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Enhancing semantic consistency in anti-fraud rule-based expert systems</title>
		<link>https://biblioteca.sistedes.es/articulo/enhancing-semantic-consistency-in-anti-fraud-rule-based-expert-systems/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/enhancing-semantic-consistency-in-anti-fraud-rule-based-expert-systems/</guid>
		<description></description>
		<content><![CDATA[En este estudio, se propone un servicio guiado por ontología para la detección y clasificación de problemas de incoherencia semántica en sistemas expertos con bases de reglas de decisión. Se centra en el caso crítico de repositorios de reglas antifraude para la inspección de transacciones en entornos de comercio electrónico. La motivación principal consiste en examinar y seleccionar los conjuntos de datos de reglas antifraude para evitar conflictos semánticos que podrían llevar al sistema experto subyacente a funcionar incorrectamente, e. g., al aceptar transacciones fraudulentas y/o descartando las inofensivas. Se ha desarrollado una ontología OWL específica y una serie de reglas semánticas (SWRL) de razonamiento para evaluar dichas bases de reglas antifraude. Las tres principales contribuciones de este trabajo son: primero, la creación de un modelo de conocimiento conceptual para describir las reglas antifraude y sus relaciones; segundo, el desarrollo de reglas semánticas como métodos de detección de conflictos para sistemas expertos contra el fraude; en tercer lugar, se recopilan datos experimentales para evaluar y validar el modelo propuesto. Se utiliza un caso de uso real de la industria de comercio electrónico (e-Turismo) para explicar el diseño de la ontología y su uso. Los experimentos muestran que los enfoques ontológicos pueden descubrir y clasificar efectivamente conflictos en sistemas expertos basados en reglas para detección de fraude. La propuesta también se puede aplicar en otros dominios donde se trabaje con bases de reglas de conocimiento.Este trabajo se presenta como artículo relevante, con referencia: María del Mar Roldán-García, José García-Nieto, José F. Aldana-Montes. Enhancing semantic consistency in anti-fraud rule-based expert systems. Expert Systems with Applications, Volume 90, 2017, Pages 332-343, ISSN 0957-4174, https://doi.org/10.1016/j.eswa.2017.08.036.La revista Expert Systems with Applications está indexada en JCR-ISI en categorías: COMPUTER SCIENCE, ARTIFICIAL INTELLIGENCE - SCIE; ENGINEERING, ELECTRICAL & ELECTRONIC - SCIE; OPERATIONS RESEARCH & MANAGEMENT SCIENCE - SCIE; con ranking Q1 en todas ellas y cuenta con un factor de impacto 2016 de 3.928.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2967</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[enhancing-semantic-consistency-in-anti-fraud-rule-based-expert-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="modelo-semantico"><![CDATA[Modelo Semántico]]></category>
		<category domain="post_tag" nicename="ontologia"><![CDATA[Ontología]]></category>
		<category domain="post_tag" nicename="razonamiento"><![CDATA[Razonamiento]]></category>
		<category domain="post_tag" nicename="reglas-antifraude"><![CDATA[Reglas Antifraude]]></category>
		<category domain="post_tag" nicename="reglas-swrl"><![CDATA[Reglas SWRL]]></category>
		<category domain="post_tag" nicename="sistemas-expertos-de-base-de-reglas"><![CDATA[Sistemas Expertos de Base de Reglas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este estudio, se propone un servicio guiado por ontología para la detección y clasificación de problemas de incoherencia semántica en sistemas expertos con bases de reglas de decisión. Se centra en el caso crítico de repositorios de reglas antifraude para la inspección de transacciones en entornos de comercio electrónico. La motivación principal consiste en examinar y seleccionar los conjuntos de datos de reglas antifraude para evitar conflictos semánticos que podrían llevar al sistema experto subyacente a funcionar incorrectamente, e. g., al aceptar transacciones fraudulentas y/o descartando las inofensivas. Se ha desarrollado una ontología OWL específica y una serie de reglas semánticas (SWRL) de razonamiento para evaluar dichas bases de reglas antifraude. Las tres principales contribuciones de este trabajo son: primero, la creación de un modelo de conocimiento conceptual para describir las reglas antifraude y sus relaciones; segundo, el desarrollo de reglas semánticas como métodos de detección de conflictos para sistemas expertos contra el fraude; en tercer lugar, se recopilan datos experimentales para evaluar y validar el modelo propuesto. Se utiliza un caso de uso real de la industria de comercio electrónico (e-Turismo) para explicar el diseño de la ontología y su uso. Los experimentos muestran que los enfoques ontológicos pueden descubrir y clasificar efectivamente conflictos en sistemas expertos basados en reglas para detección de fraude. La propuesta también se puede aplicar en otros dominios donde se trabaje con bases de reglas de conocimiento.

Este trabajo se presenta como artículo relevante, con referencia:

María del Mar Roldán-García, José García-Nieto, José F. Aldana-Montes. Enhancing semantic consistency in anti-fraud rule-based expert systems. Expert Systems with Applications, Volume 90, 2017, Pages 332-343, ISSN 0957-4174, https://doi.org/10.1016/j.eswa.2017.08.036.

La revista Expert Systems with Applications está indexada en JCR-ISI en categorías: COMPUTER SCIENCE, ARTIFICIAL INTELLIGENCE - SCIE; ENGINEERING, ELECTRICAL & ELECTRONIC - SCIE; OPERATIONS RESEARCH & MANAGEMENT SCIENCE - SCIE; con ranking Q1 en todas ellas y cuenta con un factor de impacto 2016 de 3.928.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-044.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-044.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Maria Del Mar Roldan-Garcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mmar@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Manuel García-Nieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jnieto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of  Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose F Aldana Montes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jfam@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/041]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una propuesta de editor gráfico para el desarrollo de aplicaciones multiplaforma</title>
		<link>https://biblioteca.sistedes.es/articulo/una-propuesta-de-editor-grafico-para-el-desarrollo-de-aplicaciones-multiplaforma/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/una-propuesta-de-editor-grafico-para-el-desarrollo-de-aplicaciones-multiplaforma/</guid>
		<description></description>
		<content><![CDATA[El Internet de las Cosas (IoT) cubre una gran variedad de dispositivos y tecnologías. Esto permite que se puedan crear aplicaciones muy diversas de IoT, como por ejemplo en el ámbito de las Smart Cities, Smart Agro, Smart Buildings, Smart Home, y Smart Health. Cada uno de estos escenarios requiere que personas y  objetos se interconecten. Para llevar a cabo esta tarea, los desarrolladores deben tener un alto grado de conocimiento de los lenguajes de programación que se emplean en cada plataforma y las tecnologías sobre las cuales se ejecutan. El artículo presenta una solución basada en MDE para facilitar a los desarrolladores la implementación de aplicaciones para el IoT, sin necesidad de conocer en profundidad todas las características de los escenarios, ni los lenguajes de programación de cada una de las plataformas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2968</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-propuesta-de-editor-grafico-para-el-desarrollo-de-aplicaciones-multiplaforma]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="ingenieria-dirigida-por-modelos-mde"><![CDATA[Ingeniería Dirigida por Modelos (MDE)]]></category>
		<category domain="post_tag" nicename="internet-de-las-cosas-iot"><![CDATA[Internet de las cosas (IoT)]]></category>
		<category domain="post_tag" nicename="lenguaje-especifico-de-dominio-dsl"><![CDATA[Lenguaje específico de dominio (DSL)]]></category>
		<category domain="post_tag" nicename="sirius"><![CDATA[Sirius]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El Internet de las Cosas (IoT) cubre una gran variedad de dispositivos y tecnologías. Esto permite que se puedan crear aplicaciones muy diversas de IoT, como por ejemplo en el ámbito de las Smart Cities, Smart Agro, Smart Buildings, Smart Home, y Smart Health. Cada uno de estos escenarios requiere que personas y  objetos se interconecten. Para llevar a cabo esta tarea, los desarrolladores deben tener un alto grado de conocimiento de los lenguajes de programación que se emplean en cada plataforma y las tecnologías sobre las cuales se ejecutan. El artículo presenta una solución basada en MDE para facilitar a los desarrolladores la implementación de aplicaciones para el IoT, sin necesidad de conocer en profundidad todas las características de los escenarios, ni los lenguajes de programación de cada una de las plataformas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-045.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-045.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Darwin Alulema]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[doalulema@espe.edu.ec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de las Fuerzas Armadas ESPE, Sangolquí, Ecuador - Ecuador]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Criado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[javi.criado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, University of Almería, Spain - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Luis Iribarne]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[luis.iribarne@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, University of Almería, Spain - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/042]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Efficient query processing on large spatial databases: A performance study</title>
		<link>https://biblioteca.sistedes.es/articulo/efficient-query-processing-on-large-spatial-databases-a-performance-study/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/efficient-query-processing-on-large-spatial-databases-a-performance-study/</guid>
		<description></description>
		<content><![CDATA[Processing of spatial queries has been studied extensively in the literature. In most cases, it is accomplished by indexing spatial data using spatial access methods. Spatial indexes, such as those based on the Quadtree, are important in spatial databases for efficient execution of queries involving spatial constraints and objects. In this paper, we study a recent balanced disk-based index structure for point data, called xBR+-tree, that belongs to the Quadtree family and hierarchically decomposes space in a regular manner. For the most common spatial queries, like Point Location, Window, Distance Range, Nearest Neighbor and Distance-based Join, the R-tree family is a very popular choice of spatial index, due to its excellent query performance. For this reason, we compare the performance of the xBR+-tree with respect to the R?-tree and the R+-tree for tree building and processing the most studied spatial queries. To perform this comparison, we utilize existing algorithms and present new ones. We demonstrate through extensive experimental performance results (I/O efficiency and execution time), based on medium and large real and synthetic datasets, that the xBR+-tree is a big winner in execution time in all cases and a winner in I/O in most cases.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2969</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[efficient-query-processing-on-large-spatial-databases-a-performance-study]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="performance-evaluation"><![CDATA[Performance evaluation]]></category>
		<category domain="post_tag" nicename="quadtrees"><![CDATA[Quadtrees]]></category>
		<category domain="post_tag" nicename="query-processing"><![CDATA[query processing]]></category>
		<category domain="post_tag" nicename="r-trees"><![CDATA[R-trees]]></category>
		<category domain="post_tag" nicename="spatial-access-methods"><![CDATA[Spatial access methods]]></category>
		<category domain="post_tag" nicename="spatial-databases"><![CDATA[Spatial databases]]></category>
		<category domain="post_tag" nicename="xbr-trees"><![CDATA[xBR-trees]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Processing of spatial queries has been studied extensively in the literature. In most cases, it is accomplished by indexing spatial data using spatial access methods. Spatial indexes, such as those based on the Quadtree, are important in spatial databases for efficient execution of queries involving spatial constraints and objects. In this paper, we study a recent balanced disk-based index structure for point data, called xBR+-tree, that belongs to the Quadtree family and hierarchically decomposes space in a regular manner. For the most common spatial queries, like Point Location, Window, Distance Range, Nearest Neighbor and Distance-based Join, the R-tree family is a very popular choice of spatial index, due to its excellent query performance. For this reason, we compare the performance of the xBR+-tree with respect to the R?-tree and the R+-tree for tree building and processing the most studied spatial queries. To perform this comparison, we utilize existing algorithms and present new ones. We demonstrate through extensive experimental performance results (I/O efficiency and execution time), based on medium and large real and synthetic datasets, that the xBR+-tree is a big winner in execution time in all cases and a winner in I/O in most cases.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-046.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-046.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[George Roumelis]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[groumeli@csd.auth.gr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Aristotle University of Thessaloniki - Greece]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Michael Vassilakopoulos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mvasilako@uth.gr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Thessaly - Greece]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Corral]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[acorral@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Almeria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Yannis Manolopoulos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manolopo@csd.auth.gr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Aristotle University of Thessaloniki - Greece]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/043]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>(Trabajo relevante) Handling location uncertainty in probabilistic location-dependent queries</title>
		<link>https://biblioteca.sistedes.es/articulo/trabajo-relevante-handling-location-uncertainty-in-probabilistic-location-dependent-queries/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/trabajo-relevante-handling-location-uncertainty-in-probabilistic-location-dependent-queries/</guid>
		<description></description>
		<content><![CDATA[Este artículo se presenta a JISBD como trabajo relevante y ha sido publicado en la revista Information Sciences en el año 2017.Los datos del artículo son: - Autores: Jorge Bernad, Carlos Bobed, Sergio Ilarri, Eduardo Mena - Título: Handling location uncertainty in probabilistic location-dependent queries - Revista: Information Sciences  - Volumen: 388-389 - Páginas: 154-171 - Año: 2017 - DOI: http://dx.doi.org/10.1016/j.ins.2017.01.029Indicios de calidad: la revista tiene un JCR en el año 2016 de 4.832. Dentro la categoría "Computer Science, Information Systems" está situada dentro 5% de las mejores revistas (7/146), y pertenece al cuartil Q1.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2970</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[trabajo-relevante-handling-location-uncertainty-in-probabilistic-location-dependent-queries]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="location-dependent-queries"><![CDATA[Location-dependent queries]]></category>
		<category domain="post_tag" nicename="probabilistic-range-queries"><![CDATA[Probabilistic range queries]]></category>
		<category domain="post_tag" nicename="uncertainty-management"><![CDATA[Uncertainty management]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo se presenta a JISBD como trabajo relevante y ha sido publicado en la revista Information Sciences en el año 2017.

Los datos del artículo son:
 - Autores: Jorge Bernad, Carlos Bobed, Sergio Ilarri, Eduardo Mena
 - Título: Handling location uncertainty in probabilistic location-dependent queries
 - Revista: Information Sciences
 - Volumen: 388-389
 - Páginas: 154-171
 - Año: 2017
 - DOI: http://dx.doi.org/10.1016/j.ins.2017.01.029

Indicios de calidad: la revista tiene un JCR en el año 2016 de 4.832. Dentro la categoría "Computer Science, Information Systems" está situada dentro 5% de las mejores revistas (7/146), y pertenece al cuartil Q1.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-047.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-047.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jorge Bernad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jbernad@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carlos Bobed]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cbobed@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Rennes 1 - France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sergio Ilarri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[silarri@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Eduardo Mena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[emena@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/044]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Dynamic SLOD-BI: Infraestructura Dinamica de Inteligencia de Negocio Social</title>
		<link>https://biblioteca.sistedes.es/articulo/dynamic-slod-bi-infraestructura-dinamica-de-inteligencia-de-negocio-social/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/dynamic-slod-bi-infraestructura-dinamica-de-inteligencia-de-negocio-social/</guid>
		<description></description>
		<content><![CDATA[Este proyecto plantea nuevas perspectivas de analisis y nuevasextensiones en la funcionalidad de la infraestructura de datos desarrolladaen el proyecto SLOD-BI (Social Linked Open Data for BusinessIntelligence). SLOD-BI plantea una infraestructura de datos enlazados yabiertos (Linked Open Data -LOD-) orientada a capturar y publicar hechosextrados de las redes sociales que son relevantes para los objetivosestrategicos de empresas PYME. La principal limitacion de estas infraestructurases su naturaleza estatica, ya que los datos son generados ypublicados cada cierto tiempo como conjuntos de datos RDF. Sin embargo,los hechos generados en las redes sociales son altamente dinamicos,y muchas veces requieren ser analizados casi en tiempo real (right time).En el proyecto Dynamic SLOD-BI se aborda principalmente la generacion dinamica de hechos para el calculo a demanda de indicadores deredes sociales. El sistema planteado en el proyecto descansa en el modeloconceptual de SLOD-BI, y plantea nuevos desafos de investigacion talescomo la generacion dinamica de conocimiento y el mantenimiento de sucoherencia.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2971</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[dynamic-slod-bi-infraestructura-dinamica-de-inteligencia-de-negocio-social]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="indicadores-clave-de-desempeno"><![CDATA[Indicadores Clave de Desempeño]]></category>
		<category domain="post_tag" nicename="inteligencia-de-negocio"><![CDATA[Inteligencia de negocio]]></category>
		<category domain="post_tag" nicename="modelos-cognitivos"><![CDATA[Modelos Cognitivos]]></category>
		<category domain="post_tag" nicename="redes-sociales"><![CDATA[Redes sociales]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este proyecto plantea nuevas perspectivas de analisis y nuevas
extensiones en la funcionalidad de la infraestructura de datos desarrollada
en el proyecto SLOD-BI (Social Linked Open Data for Business
Intelligence). SLOD-BI plantea una infraestructura de datos enlazados y
abiertos (Linked Open Data -LOD-) orientada a capturar y publicar hechos
extrados de las redes sociales que son relevantes para los objetivos
estrategicos de empresas PYME. La principal limitacion de estas infraestructuras
es su naturaleza estatica, ya que los datos son generados y
publicados cada cierto tiempo como conjuntos de datos RDF. Sin embargo,
los hechos generados en las redes sociales son altamente dinamicos,
y muchas veces requieren ser analizados casi en tiempo real (right time).
En el proyecto Dynamic SLOD-BI se aborda principalmente la generaci
on dinamica de hechos para el calculo a demanda de indicadores de
redes sociales. El sistema planteado en el proyecto descansa en el modelo
conceptual de SLOD-BI, y plantea nuevos desafos de investigacion tales
como la generacion dinamica de conocimiento y el mantenimiento de su
coherencia.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-048.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-048.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rafael Berlanga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[berlanga@uji.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Jaume I - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Maria Jose Aramburu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[aramburu@icc.uji.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Jaume I - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Indira Lanza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lanza@uji.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Jaume I - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Dolores Mª Llidó]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[dllido@uji.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Jaume I - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Lledó Museros]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[museros@uji.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universitat Jaume I - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Ismael Sanz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[isanz@uji.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Universitat Jaume I - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/045]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Plataforma Escalable para el Almacenamiento y Procesamiento de Imágenes Multi e Hiperespectrales con Propiedades de Acceso Espacio-Temporal</title>
		<link>https://biblioteca.sistedes.es/articulo/plataforma-escalable-para-el-almacenamiento-y-procesamiento-de-imagenes-multi-e-hiperespectrales-con-propiedades-de-acceso-espacio-temporal/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/plataforma-escalable-para-el-almacenamiento-y-procesamiento-de-imagenes-multi-e-hiperespectrales-con-propiedades-de-acceso-espacio-temporal/</guid>
		<description></description>
		<content><![CDATA[Este artículo describe el desarrollo de una plataforma escalable y eficiente para el almacenamiento y gestión masiva de imágenes multi e hiperespectrales a diferente escala; imágenes de satélite a gran altura e imágenes a media y baja altura procedentes de vuelos con vehículos aéreos no tripulados, con propiedades de acceso espacio-temporal, que sea capaz de ofrecer una mejora en los procesos de gestión y productividad de explotaciones agrarias. Esta información se combina con el uso de tecnologías actuales como bases de datos NoSQL para la gestión del almacenamiento, así como el diseño de los modelos de datos necesarios que sean capaces de soportar la variabilidad de la característica espacio-tiempo de los datos citados, y de aquellas fuentes externas que necesitan ser analizadas y procesadas antes de incorporarse al sistema. Ofreciendo mediante esta integración de datos y tecnología una infraestructura digital que logre facilitar, dentro del ámbito agrícola, los procesos de toma de decisión y la optimización de la gestión de las zonas de cultivo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2972</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[plataforma-escalable-para-el-almacenamiento-y-procesamiento-de-imagenes-multi-e-hiperespectrales-con-propiedades-de-acceso-espacio-temporal]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="agricultura-de-precision"><![CDATA[Agricultura de Precisión]]></category>
		<category domain="post_tag" nicename="datos-espaciales"><![CDATA[Datos Espaciales]]></category>
		<category domain="post_tag" nicename="georreferenciacion"><![CDATA[Georreferenciación]]></category>
		<category domain="post_tag" nicename="imagenes-hiperespectrales"><![CDATA[Imágenes Hiperespectrales]]></category>
		<category domain="post_tag" nicename="imagenes-multiespectrales"><![CDATA[Imágenes Multiespectrales]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo describe el desarrollo de una plataforma escalable y eficiente para el almacenamiento y gestión masiva de imágenes multi e hiperespectrales a diferente escala; imágenes de satélite a gran altura e imágenes a media y baja altura procedentes de vuelos con vehículos aéreos no tripulados, con propiedades de acceso espacio-temporal, que sea capaz de ofrecer una mejora en los procesos de gestión y productividad de explotaciones agrarias. Esta información se combina con el uso de tecnologías actuales como bases de datos NoSQL para la gestión del almacenamiento, así como el diseño de los modelos de datos necesarios que sean capaces de soportar la variabilidad de la característica espacio-tiempo de los datos citados, y de aquellas fuentes externas que necesitan ser analizadas y procesadas antes de incorporarse al sistema. Ofreciendo mediante esta integración de datos y tecnología una infraestructura digital que logre facilitar, dentro del ámbito agrícola, los procesos de toma de decisión y la optimización de la gestión de las zonas de cultivo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-049.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-049.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel Sánchez Cabrera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mscabrera@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Barrena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[barrena@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Aurora Cuartero Sáez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[acuartero@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/046]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>RoQME: Dealing with Non-Functional Properties through Global Robot QoS Metrics</title>
		<link>https://biblioteca.sistedes.es/articulo/roqme-dealing-with-non-functional-properties-through-global-robot-qos-metrics/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/roqme-dealing-with-non-functional-properties-through-global-robot-qos-metrics/</guid>
		<description></description>
		<content><![CDATA[Non-functional properties are an essential part of any software solution. There is a lot of literature on what non-functional properties are but, unfortunately, there is also a lot of disagreement and different points of view on how to deal with them. Non-functional properties, such as safety or dependability, become particularly relevant in the context of robotics. In the EU H2020 RobMoSys Project, non-functional properties are treated as first-class citizens and considered key added-value services. In this vein, the RoQME Integrated Technical Project, funded by RobMoSys, aims at contributing a model-driven tool-chain for dealing with system-level non-functional properties, enabling the specification of global robot Quality of Service (QoS) metrics. The estimation of these metrics at runtime, in terms of the contextual information available, can then be used for different purposes, such as robot behavior adaptation or benchmarking.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2973</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[roqme-dealing-with-non-functional-properties-through-global-robot-qos-metrics]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="non-functional-properties"><![CDATA[Non-functional Properties]]></category>
		<category domain="post_tag" nicename="qos-metrics"><![CDATA[QoS metrics]]></category>
		<category domain="post_tag" nicename="service-robotics"><![CDATA[Service Robotics]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Non-functional properties are an essential part of any software solution. There is a lot of literature on what non-functional properties are but, unfortunately, there is also a lot of disagreement and different points of view on how to deal with them. Non-functional properties, such as safety or dependability, become particularly relevant in the context of robotics. In the EU H2020 RobMoSys Project, non-functional properties are treated as first-class citizens and considered key added-value services. In this vein, the RoQME Integrated Technical Project, funded by RobMoSys, aims at contributing a model-driven tool-chain for dealing with system-level non-functional properties, enabling the specification of global robot Quality of Service (QoS) metrics. The estimation of these metrics at runtime, in terms of the contextual information available, can then be used for different purposes, such as robot behavior adaptation or benchmarking.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-050.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-050.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cristina Vicente-Chicote]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cristinav@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José Manuel García-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juanher@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Antonio Bandera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[ajbandera@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Jesús Martínez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[jmcruz@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Adrián Romero-Garcés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[adrigtl@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_8]]></meta_key>
			<meta_value><![CDATA[Roberto Font]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_8]]></meta_key>
			<meta_value><![CDATA[roberto.font@biometricvox.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_8]]></meta_key>
			<meta_value><![CDATA[Biometric Vox S.L. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_9]]></meta_key>
			<meta_value><![CDATA[Juan Francisco Inglés-Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_9]]></meta_key>
			<meta_value><![CDATA[juanfran.ingles@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_9]]></meta_key>
			<meta_value><![CDATA[Biometric Vox, S.L. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/047]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Instituto Internacional de Investigacion e Innovacion del Envejecimiento</title>
		<link>https://biblioteca.sistedes.es/articulo/instituto-internacional-de-investigacion-e-innovacion-del-envejecimiento/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/instituto-internacional-de-investigacion-e-innovacion-del-envejecimiento/</guid>
		<description></description>
		<content><![CDATA[El Instituto Internacional de Investigacion e Innovacion del Envejecimiento es un proyecto transfronterizo y multidisciplinar centrado en la mejora de la calidad de vida de los ancianos mediante el uso de la tecnologia. En este proyecto colaboran la Universidad de Evora, el Instituto Politecnico de Porto Alegre, el Instituto Politecnico de Beja, la Administracion Regional de Salud de Alentejo y la Universidad de Extremadura. Los objetivos del proyecto se centran en comprender los aspectos biomedicos, funcionales y psicologicos del envejecimiento; generar nuevos modelos y procesos de cuidado a ancianos y desarrollar soluciones tecnologicas que contribuyan a la salud y calidad de vida de los ancianos y a la sostenibilidad de los servicios.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2975</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[instituto-internacional-de-investigacion-e-innovacion-del-envejecimiento]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="ambient-assisted-living"><![CDATA[Ambient Assisted Living]]></category>
		<category domain="post_tag" nicename="envejecimiento"><![CDATA[Envejecimiento]]></category>
		<category domain="post_tag" nicename="mobile-computing"><![CDATA[mobile computing]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El Instituto Internacional de Investigacion e Innovacion del Envejecimiento es un proyecto transfronterizo y multidisciplinar centrado en la mejora de la calidad de vida de los ancianos mediante el uso de la tecnologia. En este proyecto colaboran la Universidad de Evora, el Instituto Politecnico de Porto Alegre, el Instituto Politecnico de Beja, la Administracion Regional de Salud de Alentejo y la Universidad de Extremadura. Los objetivos del proyecto se centran en comprender los aspectos biomedicos, funcionales y psicologicos del envejecimiento; generar nuevos modelos y procesos de cuidado a ancianos y desarrollar soluciones tecnologicas que contribuyan a la salud y calidad de vida de los ancianos y a la sostenibilidad de los servicios.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-052.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-052.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jose García-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Borja Rivero Jimenez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[brivero@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[David Conde Caballero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[dcondecab@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Lorenzo Mariano Juárez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[lorenmariano@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Murillo Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[David Mendes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[diverzulu@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Universidade de Évora - Portugal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_8]]></meta_key>
			<meta_value><![CDATA[Cesar Fonseca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_8]]></meta_key>
			<meta_value><![CDATA[cfonseca@uevora.pt]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_8]]></meta_key>
			<meta_value><![CDATA[University of Evora - Portugal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_9]]></meta_key>
			<meta_value><![CDATA[Manuel Lopes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_9]]></meta_key>
			<meta_value><![CDATA[mjl@uevora.pt]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_9]]></meta_key>
			<meta_value><![CDATA[Universidade de Évora - Escola Superior de Enfermagem de S. João de Deus - Portugal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_10]]></meta_key>
			<meta_value><![CDATA[Alejandro Pérez Vereda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_10]]></meta_key>
			<meta_value><![CDATA[apvereda@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_10]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_11]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_11]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_11]]></meta_key>
			<meta_value><![CDATA[University of Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/049]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Benchmarking real-time vehicle data streaming models for a smart city</title>
		<link>https://biblioteca.sistedes.es/articulo/benchmarking-real-time-vehicle-data-streaming-models-for-a-smart-city/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/benchmarking-real-time-vehicle-data-streaming-models-for-a-smart-city/</guid>
		<description></description>
		<content><![CDATA[Artículo ya publicadoInformation Systems, Volume 72, December 2017, Pages 62-76https://doi.org/10.1016/j.is.2017.09.002Q2, (COMPUTER SCIENCE, INFORMATION SYSTEMS)---The information systems of smart cities offer project developers, institutions, industry and experts the possibility to handle massive incoming data from diverse information sources in order to produce new information services for citizens. Much of this information has to be processed as it arrives because a real-time response is often needed. Stream processing architectures solve this kind of problems, but sometimes it is not easy to benchmark the load capacity or the efficiency of a proposed architecture. This work presents a real case project in which an infrastructure was needed for gathering information from drivers in a big city, analyzing that information and sending real-time recommendations to improve driving efficiency and safety on roads. The challenge was to support the real-time recommendation service in a city with thousands of simultaneous drivers at the lowest possible cost. In addition, in order to estimate the ability of an infrastructure to handle load, a simulator that emulates the data produced by a given amount of simultaneous drivers was also developed. Experiments with the simulator show how recent stream processing platforms like Apache Kafka could replace custom-made streaming servers in a smart city to achieve a higher scalability and faster responses, together with cost reduction.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2976</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[benchmarking-real-time-vehicle-data-streaming-models-for-a-smart-city]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="data-streaming"><![CDATA[Data streaming]]></category>
		<category domain="post_tag" nicename="distributed-systems"><![CDATA[Distributed Systems]]></category>
		<category domain="post_tag" nicename="simulator"><![CDATA[Simulator]]></category>
		<category domain="post_tag" nicename="smart-city"><![CDATA[Smart city]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Artículo ya publicado
Information Systems, Volume 72, December 2017, Pages 62-76
https://doi.org/10.1016/j.is.2017.09.002
Q2, (COMPUTER SCIENCE, INFORMATION SYSTEMS)

---
The information systems of smart cities offer project developers, institutions, industry and experts the possibility to handle massive incoming data from diverse information sources in order to produce new information services for citizens. Much of this information has to be processed as it arrives because a real-time response is often needed. Stream processing architectures solve this kind of problems, but sometimes it is not easy to benchmark the load capacity or the efficiency of a proposed architecture. This work presents a real case project in which an infrastructure was needed for gathering information from drivers in a big city, analyzing that information and sending real-time recommendations to improve driving efficiency and safety on roads. The challenge was to support the real-time recommendation service in a city with thousands of simultaneous drivers at the lowest possible cost. In addition, in order to estimate the ability of an infrastructure to handle load, a simulator that emulates the data produced by a given amount of simultaneous drivers was also developed. Experiments with the simulator show how recent stream processing platforms like Apache Kafka could replace custom-made streaming servers in a smart city to achieve a higher scalability and faster responses, together with cost reduction.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-053.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-053.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jorge Y. Fernández-Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jorgeyago@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan A. Álvarez-García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jaalvarez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesús Arias Fisteus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jesus.arias@uc3m.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Carlos III de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Miguel R. Luaces]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[luaces@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of A Coruña - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Víctor Corcoba Magaña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[corcobavictor@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/050]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Designing a Tool for Linking Genetic Variations to Diseases</title>
		<link>https://biblioteca.sistedes.es/articulo/designing-a-tool-for-linking-genetic-variations-to-diseases/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/designing-a-tool-for-linking-genetic-variations-to-diseases/</guid>
		<description></description>
		<content><![CDATA[The technological advance in biomedicine field has led to the creation of large and dispersed heterogeneous data silos. The researchers manually explore the information from these silos to find the relationship between DNA alterations and diseases. This task is tedious and time-consuming due to a large number of dispersed data sources, the volume of information to analyze and the heterogeneity of the content format. In this article, we report the design of a tool based on mashups and interactions to identify the cause-effect relationship between diseases and alterations in the human genome considering the challenges of data integration and the support to different formats of content. The proposed tool is not limited to the genetic domain, rather it can be applied to several domains characterized by dispersed data sources and heterogeneous data formats.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2977</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[designing-a-tool-for-linking-genetic-variations-to-diseases]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="data-exploration"><![CDATA[Data Exploration]]></category>
		<category domain="post_tag" nicename="data-integration"><![CDATA[Data Integration]]></category>
		<category domain="post_tag" nicename="diseases"><![CDATA[Diseases.]]></category>
		<category domain="post_tag" nicename="genetic-variations"><![CDATA[Genetic Variations]]></category>
		<category domain="post_tag" nicename="user-interaction"><![CDATA[User Interaction]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The technological advance in biomedicine field has led to the creation of large and dispersed heterogeneous data silos. The researchers manually explore the information from these silos to find the relationship between DNA alterations and diseases. This task is tedious and time-consuming due to a large number of dispersed data sources, the volume of information to analyze and the heterogeneity of the content format. In this article, we report the design of a tool based on mashups and interactions to identify the cause-effect relationship between diseases and alterations in the human genome considering the challenges of data integration and the support to different formats of content. The proposed tool is not limited to the genetic domain, rather it can be applied to several domains characterized by dispersed data sources and heterogeneous data formats.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-054.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-054.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Iñiguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carlos.iniguez@epn.edu.ec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Escuela Politécnica Nacional - Ecuador]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Oscar Pastor]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[opastor@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/051]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards a model-driven engineering solution for language independent mutation testing</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-a-model-driven-engineering-solution-for-language-independent-mutation-testing/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-a-model-driven-engineering-solution-for-language-independent-mutation-testing/</guid>
		<description></description>
		<content><![CDATA[Mutation testing is a technique to assess test suite adequacy to distinguish between correct and incorrect programs. Mutation testing applies one or more small changes to a program to obtain variants called mutants. The adequacy of a test suite is measured by determining how many of the mutants it distinguishes from the original program. There are many works about mutation testing, but the existing approaches focus on a specific programming language, and usually, it is not easy to customize the set of mutation operators. In this paper, we present Wodel-Test, an extension of the Wodel tool that implements a language-independent mutation testing framework based on model-driven engineering principles.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2978</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-a-model-driven-engineering-solution-for-language-independent-mutation-testing]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="domain-specific-languages"><![CDATA[Domain Specific Languages]]></category>
		<category domain="post_tag" nicename="model-mutation"><![CDATA[model mutation]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<category domain="post_tag" nicename="mutation-testing"><![CDATA[Mutation testing]]></category>
		<category domain="post_tag" nicename="reverse-engineering"><![CDATA[reverse engineering]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Mutation testing is a technique to assess test suite adequacy to distinguish between correct and incorrect programs. Mutation testing applies one or more small changes to a program to obtain variants called mutants. The adequacy of a test suite is measured by determining how many of the mutants it distinguishes from the original program. There are many works about mutation testing, but the existing approaches focus on a specific programming language, and usually, it is not easy to customize the set of mutation operators. In this paper, we present Wodel-Test, an extension of the Wodel tool that implements a language-independent mutation testing framework based on model-driven engineering principles.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-055.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-055.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Gómez-Abajo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pablo.gomeza@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Autónoma de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Esther Guerra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[esther.guerra@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Autónoma de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan de Lara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juan.delara@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Autónoma de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Mercedes G. Merayo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mgmerayo@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/052]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generating Test Systems in Simulink Models for Testing Product Lines with ASTERYSCO</title>
		<link>https://biblioteca.sistedes.es/articulo/generating-test-systems-in-simulink-models-for-testing-product-lines-with-asterysco/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/generating-test-systems-in-simulink-models-for-testing-product-lines-with-asterysco/</guid>
		<description></description>
		<content><![CDATA[Simulink models are commonly employed to simulate and test complex systems such as Cyber-Physical Systems (CPSs). These systems are becoming highly configurable, and techniques from the product line engineering context (e.g., feature models) are being acquired by industrial practitioners to model the variability. Having variability in these systems means that there might be several configurations to test. Selecting relevant configurations by considering feature models following combinatorial techniques has been widely investigated by the software engineering community. However, efficiently testing each configuration has attracted little attention, which is not that trivial. One important aspect when testing such systems is automation. This tool paper presents ASTERYSCO, which aims at automatically generating test system instances in Simulink for testing specific configurations of configurable CPSs.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2979</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generating-test-systems-in-simulink-models-for-testing-product-lines-with-asterysco]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="cyber-physical-systems"><![CDATA[Cyber-Physical Systems]]></category>
		<category domain="post_tag" nicename="feature-modeling"><![CDATA[Feature Modeling]]></category>
		<category domain="post_tag" nicename="matlabsimulink"><![CDATA[MATLAB/Simulink]]></category>
		<category domain="post_tag" nicename="product-line-engineering"><![CDATA[Product Line Engineering]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Simulink models are commonly employed to simulate and test complex systems such as Cyber-Physical Systems (CPSs). These systems are becoming highly configurable, and techniques from the product line engineering context (e.g., feature models) are being acquired by industrial practitioners to model the variability. Having variability in these systems means that there might be several configurations to test. Selecting relevant configurations by considering feature models following combinatorial techniques has been widely investigated by the software engineering community. However, efficiently testing each configuration has attracted little attention, which is not that trivial. One important aspect when testing such systems is automation. This tool paper presents ASTERYSCO, which aims at automatically generating test system instances in Simulink for testing specific configurations of configurable CPSs.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-056.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-056.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aitor Arrieta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aarrieta@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Leire Etxeberria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[letxeberria@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Mondragon Uniberstitatea - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Justyna Zander]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[justyna.zander@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[NVIDIA - United States]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/053]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A continuous deployment-based approach for the collaborative creation, maintenance, testing and deployment of CityGML models</title>
		<link>https://biblioteca.sistedes.es/articulo/a-continuous-deployment-based-approach-for-the-collaborative-creation-maintenance-testing-and-deployment-of-citygml-models/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-continuous-deployment-based-approach-for-the-collaborative-creation-maintenance-testing-and-deployment-of-citygml-models/</guid>
		<description></description>
		<content><![CDATA[Publicado en: International Journal of Geographical Information ScienceVolume 32, 2018 - Issue 2, pp. 282-301 (ya publicado online el 26 Oct 2017)https://doi.org/10.1080/13658816.2017.1393543La revista está 46/146 en COMPUTER SCIENCE, INFORMATION SYSTEMS en el JCR (Q2)Abstract:Georeferenced 3D models are an increasingly common choice to store and display urban data in many application areas. CityGML is an open and standardized data model, and exchange format that provides common semantics for 3D city entities and their relations and one of the most common options for this kind of information.Currently, creating and maintaining CityGML models is costly and difficult. This is in part because both the creation of the geometries and the semantic annotation can be complex processes that require at least some manual work. In fact, many publicly available CityGML models have errors. This paper proposes a method to facilitate the regular maintenance of correct city models in CityGML. This method is based on the continuous deployment strategy and tools used in software development, but adapted to the problem of creating,maintaining and deploying CityGML models, even when several people are working on them at the same time. The method requires designing and implementing CityGML deployment pipelines. These pipelines are automatic implementations of the process of building, testing and deploying CityGML models. These pipelines must berun by the maintainers of the models when they make changes that are intended to be shared with others. The pipelines execute increasingly complex automatic tests in order to detect errors as soon as possible, and can even automate the deployment step, where the CityGML models are made available to their end users. In order to demonstrate the feasibility of this method, and as an example of its application, a CityGML deployment pipeline has been developed for an example scenario where three actors maintain the same city model. This scenario is representative of the kind of problems that this method intends to solve, and it is based on real work in progress. The main bene fits of this method are the automation of model testing, every change to the model is tested in a repeatable way; the automation of the model deployment,every change to the model can reach its end users as fast as possible; the systematic approach to integrating changes made by different people working together on the models, including the possibility of keeping parallel versions with a common core; anautomatic record of every change made to the models (who did what and when) and the possibility of undoing some of those changes at any time.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2980</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-continuous-deployment-based-approach-for-the-collaborative-creation-maintenance-testing-and-deployment-of-citygml-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="3d-city-model"><![CDATA[3D City Model]]></category>
		<category domain="post_tag" nicename="automated-testing"><![CDATA[Automated Testing]]></category>
		<category domain="post_tag" nicename="citygml"><![CDATA[CityGML]]></category>
		<category domain="post_tag" nicename="collaborative-edition"><![CDATA[Collaborative Edition]]></category>
		<category domain="post_tag" nicename="continuous-deployment"><![CDATA[Continuous Deployment]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Publicado en: International Journal of Geographical Information Science
Volume 32, 2018 - Issue 2, pp. 282-301 (ya publicado online el 26 Oct 2017)

https://doi.org/10.1080/13658816.2017.1393543

La revista está 46/146 en COMPUTER SCIENCE, INFORMATION SYSTEMS en el JCR (Q2)

Abstract:

Georeferenced 3D models are an increasingly common choice to store and display urban data in many application areas. CityGML is an open and standardized data model, and exchange format that provides common semantics for 3D city entities and their relations and one of the most common options for this kind of information.

Currently, creating and maintaining CityGML models is costly and difficult. This is in part because both the creation of the geometries and the semantic annotation can be complex processes that require at least some manual work. In fact, many publicly available CityGML models have errors.

This paper proposes a method to facilitate the regular maintenance of correct city models in CityGML. This method is based on the continuous deployment strategy and tools used in software development, but adapted to the problem of creating,
maintaining and deploying CityGML models, even when several people are working on them at the same time. The method requires designing and implementing CityGML deployment pipelines. These pipelines are automatic implementations of the process of building, testing and deploying CityGML models. These pipelines must be
run by the maintainers of the models when they make changes that are intended to be shared with others. The pipelines execute increasingly complex automatic tests in order to detect errors as soon as possible, and can even automate the deployment step, where the CityGML models are made available to their end users.

In order to demonstrate the feasibility of this method, and as an example of its application, a CityGML deployment pipeline has been developed for an example scenario where three actors maintain the same city model. This scenario is representative of the kind of problems that this method intends to solve, and it is based on real work in progress.

The main bene fits of this method are the automation of model testing, every change to the model is tested in a repeatable way; the automation of the model deployment,
every change to the model can reach its end users as fast as possible; the systematic approach to integrating changes made by different people working together on the models, including the possibility of keeping parallel versions with a common core; anautomatic record of every change made to the models (who did what and when) and the possibility of undoing some of those changes at any time.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-057.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-057.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Iñaki Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Sustainable Construction Division, Tecnalia Research & Innovation - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose Luis Izkara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Sustainable Construction Division, Tecnalia Research & Innovation - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Rubén Béjar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[rbejar@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/054]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una propuesta para componer APIs orientadas a datos</title>
		<link>https://biblioteca.sistedes.es/articulo/una-propuesta-para-componer-apis-orientadas-a-datos/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/una-propuesta-para-componer-apis-orientadas-a-datos/</guid>
		<description></description>
		<content><![CDATA[En los últimos años un gran número de compañías y entidades públicas han liberado sus datos vía APIs REST. Esto ha provocado un incremento en el número de APIs REST, motivando la creación de mashups para combinar y reutilizar datos provenientes de diferentes fuentes. Sin embargo, la creación de este tipo de aplicaciones es tediosa y propensa a errores ya que hay que invertir un gran esfuerzo en analizar y explicitar el modelo de datos de cada API, definir una estrategia de composición y, finalmente, implementar la aplicación de tipo mashup. En este artículo presentamos una propuesta para la composición de APIs REST orientadas a datos. Dado un conjunto de APIs REST iniciales, nuestra propuesta es capaz de descubrir su modelo de datos, crear un modelo de datos global y publicarlo como una API REST.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2981</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-propuesta-para-componer-apis-orientadas-a-datos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="odata"><![CDATA[OData]]></category>
		<category domain="post_tag" nicename="openapi"><![CDATA[OpenAPI]]></category>
		<category domain="post_tag" nicename="rest-api"><![CDATA[REST API]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años un gran número de compañías y entidades públicas han liberado sus datos vía APIs REST. Esto ha provocado un incremento en el número de APIs REST, motivando la creación de mashups para combinar y reutilizar datos provenientes de diferentes fuentes. Sin embargo, la creación de este tipo de aplicaciones es tediosa y propensa a errores ya que hay que invertir un gran esfuerzo en analizar y explicitar el modelo de datos de cada API, definir una estrategia de composición y, finalmente, implementar la aplicación de tipo mashup. En este artículo presentamos una propuesta para la composición de APIs REST orientadas a datos. Dado un conjunto de APIs REST iniciales, nuestra propuesta es capaz de descubrir su modelo de datos, crear un modelo de datos global y publicarlo como una API REST.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-058.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-058.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Hamza Ed-Douibi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[hed-douibi@uoc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[IN3 - UOC - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Luis Canovas Izquierdo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jcanovasi@uoc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[IN3 - UOC - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jordi Cabot]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jordi.cabot@icrea.cat]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ICREA - UOC (Internet interdisciplinary institute) - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/055]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Restricción de coetaneidad: cómo detectar y neutralizar inconsistencias temporales</title>
		<link>https://biblioteca.sistedes.es/articulo/restriccion-de-coetaneidad-como-detectar-y-neutralizar-inconsistencias-temporales/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/restriccion-de-coetaneidad-como-detectar-y-neutralizar-inconsistencias-temporales/</guid>
		<description></description>
		<content><![CDATA[La preocupación por la propagación de información falsa crece y el análisis de grandes volúmenes de datos correctos se hace imprescindible en los procesos de toma de decisiones de las organizaciones. Pese a ello, no se han extendido mecanismos automáticos que aseguren la consistencia de los datos relativos al tiempo cronológico, que abundan en los grandes sistemas de información.En este artículo se define y formaliza la restricción de coetaneidad, un mecanismo para la detección y el marcado masivos de datos inconsistentes gracias a la comparación cruzada de valores de tiempo con el consiguiente incremento en la calidad de la información en diferentes contextos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2982</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[restriccion-de-coetaneidad-como-detectar-y-neutralizar-inconsistencias-temporales]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="calidad-de-datos"><![CDATA[Calidad de Datos]]></category>
		<category domain="post_tag" nicename="coetaniedad"><![CDATA[coetaniedad]]></category>
		<category domain="post_tag" nicename="consistencia-de-datos"><![CDATA[consistencia de datos]]></category>
		<category domain="post_tag" nicename="curacion-de-contenidos"><![CDATA[curación de contenidos]]></category>
		<category domain="post_tag" nicename="limpieza-de-datos"><![CDATA[limpieza de datos]]></category>
		<category domain="post_tag" nicename="restricciones-temporales"><![CDATA[restricciones temporales]]></category>
		<category domain="post_tag" nicename="wikidata"><![CDATA[Wikidata]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La preocupación por la propagación de información falsa crece y el análisis de grandes volúmenes de datos correctos se hace imprescindible en los procesos de toma de decisiones de las organizaciones. Pese a ello, no se han extendido mecanismos automáticos que aseguren la consistencia de los datos relativos al tiempo cronológico, que abundan en los grandes sistemas de información.
En este artículo se define y formaliza la restricción de coetaneidad, un mecanismo para la detección y el marcado masivos de datos inconsistentes gracias a la comparación cruzada de valores de tiempo con el consiguiente incremento en la calidad de la información en diferentes contextos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-059.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-059.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Abián]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[da@davidabian.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jorge Bernad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jbernad@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Raquel Trillo-Lado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[raqueltl@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/056]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un primer enfoque para medir la calidad de FIWARE</title>
		<link>https://biblioteca.sistedes.es/articulo/un-primer-enfoque-para-medir-la-calidad-de-fiware/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/un-primer-enfoque-para-medir-la-calidad-de-fiware/</guid>
		<description></description>
		<content><![CDATA[FIWARE es un ecosistema tecnológico abierto que pretendeconvertirse en la plataforma de referencia para los servicios y aplicaciones del Internet del Futuro. Para ello, primero se necesita solventar lasdudas existentes en cuanto a la calidad de FIWARE, ya que la plata-forma manejará datos sensibles tanto personales como esenciales parala correcta gestión de las ciudades inteligentes. Hay muchas formas deestudiar la calidad de un middleware complejo como este. En nuestrocaso seguimos las pautas de un estándar ISO usando herramientas existentes en una primera fase de identicación de problemas. Tras estudiar26 habilitadores genéricos de referencia de FIWARE, hemos detectadonumerosos puntos de mejora. En el caso de la conconfiabilidad y seguridadse podrán solventar en poco tiempo, mientras que los defectos relativosa mantenibilidad requeriran del orden de meses de trabajo. Esto posiblemente es debido al carácter tan heterogéneo del equipo de desarrolladode FIWARE (miembros de diversas empresas), que afecta directamentea la mantenibilidad del código.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2983</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-primer-enfoque-para-medir-la-calidad-de-fiware]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="calidad"><![CDATA[Calidad]]></category>
		<category domain="post_tag" nicename="ciudades-inteligentes"><![CDATA[Ciudades Inteligentes]]></category>
		<category domain="post_tag" nicename="confiabilidad"><![CDATA[Confiabilidad]]></category>
		<category domain="post_tag" nicename="fiware"><![CDATA[FIWARE]]></category>
		<category domain="post_tag" nicename="mantenibilidad"><![CDATA[mantenibilidad]]></category>
		<category domain="post_tag" nicename="metricas"><![CDATA[métricas]]></category>
		<category domain="post_tag" nicename="seguridad"><![CDATA[seguridad]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[FIWARE es un ecosistema tecnológico abierto que pretende
convertirse en la plataforma de referencia para los servicios y aplicaciones del Internet del Futuro. Para ello, primero se necesita solventar las
dudas existentes en cuanto a la calidad de FIWARE, ya que la plata-
forma manejará datos sensibles tanto personales como esenciales para
la correcta gestión de las ciudades inteligentes. Hay muchas formas de
estudiar la calidad de un middleware complejo como este. En nuestro
caso seguimos las pautas de un estándar ISO usando herramientas existentes en una primera fase de identicación de problemas. Tras estudiar
26 habilitadores genéricos de referencia de FIWARE, hemos detectado
numerosos puntos de mejora. En el caso de la conconfiabilidad y seguridad
se podrán solventar en poco tiempo, mientras que los defectos relativos
a mantenibilidad requeriran del orden de meses de trabajo. Esto posiblemente es debido al carácter tan heterogéneo del equipo de desarrollado
de FIWARE (miembros de diversas empresas), que afecta directamente
a la mantenibilidad del código.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-060.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-060.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ignacio Villalobos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[nacho@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Ferrer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ferrer@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Enrique Alba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[eat@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/057]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>FEETINGS: Un Marco para la Sostenibilidad del Software</title>
		<link>https://biblioteca.sistedes.es/articulo/feetings-un-marco-para-la-sostenibilidad-del-software/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/feetings-un-marco-para-la-sostenibilidad-del-software/</guid>
		<description></description>
		<content><![CDATA[El desarrollo del software no debe de permanecer indiferente a la necesidad de construir productos que sean sostenibles y respetuosos con el medioambiente a lo largo de su ciclo de vida. Sin embargo, uno de los principales problemas actuales, es la falta de herramientas que permitan medir el consumo de energía cuando un software es ejecutado, y detectar, por ejemplo, cuáles son las partes del software que tienen un consumo de energía excesivo. Por esta razón, se ha propuesto FEETINGS (Framework for Energy Efficiency Testing to Improve eNviromental Goals of the Software), un marco que permite medir la eficiencia energética del software y así mejorar la sostenibilidad del mismo. En este trabajo, nos hemos centrado en el núcleo del marco, EET (Energy Efficiency Tester). EET es un dispositivo hardware de medición dedicado a recopilar los datos de consumo específicos del software que se está evaluando. A lo largo del documento se presenta las principales funciones de EET, y un caso de estudio usando el dispositivo de medición EET, donde se pretende observar si existe una correlación entre los requisitos de usabilidad de un software determinado con el consumo de ener-gía que conlleva al ser ejecutado.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2984</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[feetings-un-marco-para-la-sostenibilidad-del-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="dispositivo-de-medicion"><![CDATA[Dispositivo de medición]]></category>
		<category domain="post_tag" nicename="green-software"><![CDATA[Green Software]]></category>
		<category domain="post_tag" nicename="medicion-del-consumo-del-software"><![CDATA[Medición del consumo del software]]></category>
		<category domain="post_tag" nicename="phr"><![CDATA[PHR]]></category>
		<category domain="post_tag" nicename="software-sostenible"><![CDATA[Software sostenible]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El desarrollo del software no debe de permanecer indiferente a la necesidad de construir productos que sean sostenibles y respetuosos con el medioambiente a lo largo de su ciclo de vida. Sin embargo, uno de los principales problemas actuales, es la falta de herramientas que permitan medir el consumo de energía cuando un software es ejecutado, y detectar, por ejemplo, cuáles son las partes del software que tienen un consumo de energía excesivo. Por esta razón, se ha propuesto FEETINGS (Framework for Energy Efficiency Testing to Improve eNviromental Goals of the Software), un marco que permite medir la eficiencia energética del software y así mejorar la sostenibilidad del mismo. En este trabajo, nos hemos centrado en el núcleo del marco, EET (Energy Efficiency Tester). EET es un dispositivo hardware de medición dedicado a recopilar los datos de consumo específicos del software que se está evaluando. A lo largo del documento se presenta las principales funciones de EET, y un caso de estudio usando el dispositivo de medición EET, donde se pretende observar si existe una correlación entre los requisitos de usabilidad de un software determinado con el consumo de ener-gía que conlleva al ser ejecutado.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-061.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-061.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Mancebo Pavón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[javier.mancebo@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Felix Garcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[felix.garcia@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Coral Calero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[coral.calero@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José Alberto García-Berna]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[JoseAlberto.Garcia1@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática y Sistemas, Universidad de Murcia, Murcia, España - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[José Luis Fenández-Alemán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aleman@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática y Sistemas, Universidad de Murcia, Murcia, España - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Ambrosio Toval]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[AToval@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática y Sistemas, Universidad de Murcia, Murcia, España - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/058]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Análisis de los datos del acelerómetro para detección de actividades</title>
		<link>https://biblioteca.sistedes.es/articulo/analisis-de-los-datos-del-acelerometro-para-deteccion-de-actividades/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/analisis-de-los-datos-del-acelerometro-para-deteccion-de-actividades/</guid>
		<description></description>
		<content><![CDATA[Las enfermedades cardiovasculares son la principal causa de muerte en España, siendo necesaria la prevención de factores de riesgos como la obesidad o los altos niveles de colesterol. La actividad física previene estos problemas, y su seguimiento usando pulseras de actividad permite tomar decisiones para su corrección. En este trabajo se presenta un experimento para evaluar la viabilidad de detección automática de ciertas actividades a través de algoritmos supervisados de Deep Learning]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2985</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analisis-de-los-datos-del-acelerometro-para-deteccion-de-actividades]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="classification"><![CDATA[classification]]></category>
		<category domain="post_tag" nicename="deep-learning"><![CDATA[Deep Learning]]></category>
		<category domain="post_tag" nicename="har"><![CDATA[HAR]]></category>
		<category domain="post_tag" nicename="wearable-sensors"><![CDATA[wearable sensors]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las enfermedades cardiovasculares son la principal causa de muerte en España, siendo necesaria la prevención de factores de riesgos como la obesidad o los altos niveles de colesterol. La actividad física previene estos problemas, y su seguimiento usando pulseras de actividad permite tomar decisiones para su corrección. En este trabajo se presenta un experimento para evaluar la viabilidad de detección automática de ciertas actividades a través de algoritmos supervisados de Deep Learning]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-062.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-062.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Sandro Hurtado-Requena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[sandrohurtadorequena@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Cristobal Barba-Gonzalez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cbarba@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Maciej Rybinski]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[maciek.rybinski@lcc.umaes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Francisco J Baron-Lopez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[fjbaron@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Julia Warnberg]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[jwarnberg@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Ismael Navas-Delgado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[ismael@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Jose F Aldana-Montes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[jfam@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/059]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>AIRPORTS: Análisis de Eficiencia Operacional basado en Trayectorias de Vuelo</title>
		<link>https://biblioteca.sistedes.es/articulo/airports-analisis-de-eficiencia-operacional-basado-en-trayectorias-de-vuelo/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/airports-analisis-de-eficiencia-operacional-basado-en-trayectorias-de-vuelo/</guid>
		<description></description>
		<content><![CDATA[AIRPORTS es un proyecto liderado por Boeing Research & Technology Europe (BR&T-E) en el que se coordinan varias líneas de investigación centradas en mejorar la eficiencia del sistema de transporte aéreo futuro. En particular, nuestro trabajo en AIRPORTS aborda la explotación de los datos que describen las trayectorias de vuelo para caracterizar la eficiencia de las operaciones realizadas en el entorno aeroportuario. Este documento introduce las particularidades básicas del contexto en el que estamos desarrollando nuestra investigación y presenta, brevemente, tanto el entorno tecnológico en el que se está realizando el proyecto, como los resultados que se esperan del mismo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2986</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[airports-analisis-de-eficiencia-operacional-basado-en-trayectorias-de-vuelo]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="ads-b"><![CDATA[ADS-B]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="integracion-de-datos"><![CDATA[Integración de datos]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[AIRPORTS es un proyecto liderado por Boeing Research & Technology Europe (BR&T-E) en el que se coordinan varias líneas de investigación centradas en mejorar la eficiencia del sistema de transporte aéreo futuro. En particular, nuestro trabajo en AIRPORTS aborda la explotación de los datos que describen las trayectorias de vuelo para caracterizar la eficiencia de las operaciones realizadas en el entorno aeroportuario. Este documento introduce las particularidades básicas del contexto en el que estamos desarrollando nuestra investigación y presenta, brevemente, tanto el entorno tecnológico en el que se está realizando el proyecto, como los resultados que se esperan del mismo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-063.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-063.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Álvaro Alonso-Isla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alvaro.alonso.isla@uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Matemáticas (IMUVA), Universidad de Valladolid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pedro C. Álvarez-Esteban]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pedroc@eio.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Matemáticas (IMUVA), Universidad de Valladolid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Aníbal Bregón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[anibal@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Valladolid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Luís D'Alto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[luis.p.dalto@boeing.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Boeing Research & Technology Europe - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Fernando Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[fdiaz@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Valladolid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Iván García-Miranda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[ivangmasir@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Matemáticas (IMUVA), Universidad de Valladolid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Paula Gordaliza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[Paula.Gordaliza@math.univ-toulouse.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Matemáticas (IMUVA), Universidad de Valladolid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_8]]></meta_key>
			<meta_value><![CDATA[Javier López-Leonés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_8]]></meta_key>
			<meta_value><![CDATA[javier.lopezleones@boeing.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_8]]></meta_key>
			<meta_value><![CDATA[Boeing Research & Technology Europe - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_9]]></meta_key>
			<meta_value><![CDATA[Miguel A. Martinez-Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_9]]></meta_key>
			<meta_value><![CDATA[migumar2@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_9]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Valladolid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_10]]></meta_key>
			<meta_value><![CDATA[David Scarlatti]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_10]]></meta_key>
			<meta_value><![CDATA[david.scarlatti@boeing.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_10]]></meta_key>
			<meta_value><![CDATA[Boeing Research & Technology Europe - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_11]]></meta_key>
			<meta_value><![CDATA[Miguel Vilaplana]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_11]]></meta_key>
			<meta_value><![CDATA[miguel.vilaplana@boeing.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_11]]></meta_key>
			<meta_value><![CDATA[Boeing Research & Technology Europe - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/060]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Aplicabilidad de la Caracterización de Benchmarks a Modelos de Variabilidad</title>
		<link>https://biblioteca.sistedes.es/articulo/aplicabilidad-de-la-caracterizacion-de-benchmarks-a-modelos-de-variabilidad/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/aplicabilidad-de-la-caracterizacion-de-benchmarks-a-modelos-de-variabilidad/</guid>
		<description></description>
		<content><![CDATA[Los Benchmarks utilizados para comparar el rendimiento de diferentes sistemas presentan una alta variabilidad que puede ser representada en modelos de variabilidad como los feature models. En este artículo presentamos las ventajas de la caracterización de Benchmarks (dada por sus cargas de trabajo), junto a los problemas de escalabilidad y complejidad de selección por objetivos de los Feature Models. Para solucionar esos problemas, formalizamos un modelo de caracterización de paquetes de cargas de trabajo para Feature Models, basándonos en ocho atributos abstractos (operaciones matemáticas, memoria, ...). Este modelo y sus ventajas son evaluados en el eco-asistente HADAS, junto a un Benchmark PHP, y al Benchmark de sistemas empotrados BEEBS, obteniendo una capacidad de selección más intuitiva, y un decremento en el tiempo de obtención de configuraciones válidas y sus métricas en HADAS, con respecto a la representación estándar.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2987</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[aplicabilidad-de-la-caracterizacion-de-benchmarks-a-modelos-de-variabilidad]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="atributos"><![CDATA[Atributos]]></category>
		<category domain="post_tag" nicename="benchmarking"><![CDATA[Benchmarking]]></category>
		<category domain="post_tag" nicename="caracterizacion"><![CDATA[Caracterización]]></category>
		<category domain="post_tag" nicename="eficiencia"><![CDATA[Eficiencia]]></category>
		<category domain="post_tag" nicename="escalabilidad"><![CDATA[escalabilidad]]></category>
		<category domain="post_tag" nicename="features"><![CDATA[Features]]></category>
		<category domain="post_tag" nicename="software"><![CDATA[Software]]></category>
		<category domain="post_tag" nicename="variabilidad"><![CDATA[Variabilidad]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los Benchmarks utilizados para comparar el rendimiento de diferentes sistemas presentan una alta variabilidad que puede ser representada en modelos de variabilidad como los feature models. En este artículo presentamos las ventajas de la caracterización de Benchmarks (dada por sus cargas de trabajo), junto a los problemas de escalabilidad y complejidad de selección por objetivos de los Feature Models. Para solucionar esos problemas, formalizamos un modelo de caracterización de paquetes de cargas de trabajo para Feature Models, basándonos en ocho atributos abstractos (operaciones matemáticas, memoria, ...). Este modelo y sus ventajas son evaluados en el eco-asistente HADAS, junto a un Benchmark PHP, y al Benchmark de sistemas empotrados BEEBS, obteniendo una capacidad de selección más intuitiva, y un decremento en el tiempo de obtención de configuraciones válidas y sus métricas en HADAS, con respecto a la representación estándar.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-064.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-064.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Daniel Jesus Munoz Guerra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[danimg@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/061]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una Propuesta para Especificar Cambios de Replicaciones de Experimentos en Ingeniería del Software</title>
		<link>https://biblioteca.sistedes.es/articulo/una-propuesta-para-especificar-cambios-de-replicaciones-de-experimentos-en-ingenieria-del-software/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/una-propuesta-para-especicar-cambios-de-replicaciones-de-experimentos-en-ingenieria-del-software/</guid>
		<description></description>
		<content><![CDATA[Contexto: La replicación de estudios empíricos en Ingeniería del Software es necesaria para consolidar el conocimiento adquirido. No obstante, para incrementar el conocimiento que se genera mediante la replicación, es necesario que la información se publique de forma que permita una comprensión profunda del estudio. Objetivo: Al diseñar una replicación, habitualmente surge la necesidad de introducir cambios. El objetivo de este trabajo es facilitar la especificación de dichos cambios proponiendo una plantilla que permita definirlos sistemáticamente y documentarlos de forma homogénea. Método: Se ha definido el metamodelo para formalizar la información sobre replicaciones y cambios que son relevantes para la plantilla propuesta. Posteriormente, se ha detallado la plantilla y se ha aplicado a una replicación concreta. Resultados y Conclusiones: La aplicación de la plantilla a una replicación concreta ha sido satisfactoria pero se debe aplicar a otras replicaciones o familias de experimentos para su validación y mejora a través de la retroalimentación obtenida.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2988</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-propuesta-para-especificar-cambios-de-replicaciones-de-experimentos-en-ingenieria-del-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="estudio-empirico"><![CDATA[estudio empírico]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software-empirica"><![CDATA[Ingeniería del Software empírica]]></category>
		<category domain="post_tag" nicename="patrones-linguisticos"><![CDATA[patrones lingüísticos]]></category>
		<category domain="post_tag" nicename="plantilla"><![CDATA[plantilla]]></category>
		<category domain="post_tag" nicename="replicacion"><![CDATA[Replicación]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Contexto: La replicación de estudios empíricos en Ingeniería del Software es necesaria para consolidar el conocimiento adquirido. No obstante, para incrementar el conocimiento que se genera mediante la replicación, es necesario que la información se publique de forma que permita una comprensión profunda del estudio. Objetivo: Al diseñar una replicación, habitualmente surge la necesidad de introducir cambios. El objetivo de este trabajo es facilitar la especi?cación de dichos cambios proponiendo una plantilla que permita de?nirlos sistemáticamente y documentarlos de forma homogénea. Método: Se ha de?nido el metamodelo para formalizar la información sobre replicaciones y cambios que son relevantes para la plantilla propuesta. Posteriormente, se ha detallado la plantilla y se ha aplicado a una replicación concreta. Resultados y Conclusiones: La aplicación de la plantilla a una replicación concreta ha sido satisfactoria pero se debe aplicar a otras replicaciones o familias de experimentos para su validación y mejora a través de la retroalimentación obtenida.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-065.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-065.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Margarita Cruz Risco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cruz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Beatriz Bernárdez Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[beat@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Amador Durán Toro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[amador@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/062]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_wp_old_slug]]></meta_key>
			<meta_value><![CDATA[una-propuesta-para-especicar-cambios-de-replicaciones-de-experimentos-en-ingenieria-del-software]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Analizando la Integración Humano-Sistema en Sistemas Autónomos</title>
		<link>https://biblioteca.sistedes.es/articulo/analizando-la-integracion-humano-sistema-en-sistemas-autonomos/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/analizando-la-integracion-humano-sistema-en-sistemas-autonomos/</guid>
		<description></description>
		<content><![CDATA[Los sistemas autónomos (SA) están diseñados para actuar de forma autónoma en gran parte de su trabajo; sin embargo, la autonomía completa es una utopía a medio y corto plazo. Este hecho hace necesario que el humano ayude a completar su funcionalidad (‘human-in-the-loop’). Este tipo de sistemas deben garantizar en todo momento un correcto funcionamiento autónomo, a la vez que de-be ceder, bajo ciertas condiciones, total o parcialmente el control al humano para la realización de algunas tareas. Esto requiere analizar y diseñar los siste-mas para que involucren al humano de forma adecuada ante situaciones donde no es posible alcanzar la autonomía, procurando garantizar una correcta integración humano-sistema. En este trabajo se proporcionan las bases para analizar y diseñar las interacciones humano-sistema. En este artículo se presenta un análisis que permite identificar los aspectos esenciales de la participación del humano en el SA y se propone una técnica para especificar como integrar el humano y el sistema en las primeras fases de desarrollo. Los coches autónomos se toman como ejemplo para ilustrar la propuesta mediante escenarios reales.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2989</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analizando-la-integracion-humano-sistema-en-sistemas-autonomos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="coches-autonomos"><![CDATA[Coches Autónomos]]></category>
		<category domain="post_tag" nicename="human-in-the-loop"><![CDATA[Human in the Loop]]></category>
		<category domain="post_tag" nicename="interaccion-humano-sistema"><![CDATA[Interacción Humano-Sistema]]></category>
		<category domain="post_tag" nicename="sistemas-autonomos"><![CDATA[Sistemas Autónomos]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los sistemas autónomos (SA) están diseñados para actuar de forma autónoma en gran parte de su trabajo; sin embargo, la autonomía completa es una utopía a medio y corto plazo. Este hecho hace necesario que el humano ayude a completar su funcionalidad (‘human-in-the-loop’). Este tipo de sistemas deben garantizar en todo momento un correcto funcionamiento autónomo, a la vez que de-be ceder, bajo ciertas condiciones, total o parcialmente el control al humano para la realización de algunas tareas. Esto requiere analizar y diseñar los siste-mas para que involucren al humano de forma adecuada ante situaciones donde no es posible alcanzar la autonomía, procurando garantizar una correcta integración humano-sistema. En este trabajo se proporcionan las bases para analizar y diseñar las interacciones humano-sistema. En este artículo se presenta un análisis que permite identificar los aspectos esenciales de la participación del humano en el SA y se propone una técnica para especificar como integrar el humano y el sistema en las primeras fases de desarrollo. Los coches autónomos se toman como ejemplo para ilustrar la propuesta mediante escenarios reales.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-066.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-066.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miriam Gil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mgil@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manoli Albert]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[malbert@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Joan Fons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jjfons@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[pele@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/063]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Técnicas creativas para la captura de requisitos en el desarrollo ágil: una revisión sistemática de la literatura</title>
		<link>https://biblioteca.sistedes.es/articulo/tecnicas-creativas-para-la-captura-de-requisitos-en-el-desarrollo-agil-una-revision-sistematica-de-la-literatura/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/tecnicas-creativas-para-la-captura-de-requisitos-en-el-desarrollo-agil-una-revision-sistematica-de-la-literatura/</guid>
		<description></description>
		<content><![CDATA[Si bien uno de los objetivos de las metodologías ágiles es proporcionar un contexto que facilite la innovación, el afán de las técnicas tradicionales para la captura de requisitos por conseguir una especificación completa y pormenorizada de requisitos que guíe el proceso de desarrollo, parece no encajar a priori con el carácter innovador de las metodologías ágiles. Aplicar el pensamiento creativo a la captura de requisitos, permitiría en principio seguir contemplando la captura de requisitos como una fase más del desarrollo ágil, sin penalizar el carácter innovador de estas metodologías. Para evaluar las iniciativas al respecto que existen hasta la fecha, este trabajo presenta una revisión sistemática que identifica y analiza los trabajos que proponen alguna forma de combinar la utilización de técnicas creativas para la toma de requisitos con el desarrollo ágil. El estudio revela que hasta el momento las metodologías ágiles  basadas en modelado rápido son las más populares como forma de introducir la creatividad en la toma de de requisitos. Asimismo, el estudio muestra que la creatividad en la toma de requisitos debe venir acompañada de un alto nivel de compromiso por parte del usuario y de un contexto que favorezca la flexibilidad, si queremos favorecer la innovación en el desarrollo de software.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2990</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[tecnicas-creativas-para-la-captura-de-requisitos-en-el-desarrollo-agil-una-revision-sistematica-de-la-literatura]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="captura-de-requisitos"><![CDATA[Captura de requisitos]]></category>
		<category domain="post_tag" nicename="desarrollo-de-software"><![CDATA[Desarrollo de software]]></category>
		<category domain="post_tag" nicename="gestion-de-proyectos-de-software"><![CDATA[Gestión de proyectos de software]]></category>
		<category domain="post_tag" nicename="metodologias-agiles"><![CDATA[Metodologías Ágiles]]></category>
		<category domain="post_tag" nicename="pensamiento-creativo"><![CDATA[Pensamiento creativo]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Si bien uno de los objetivos de las metodologías ágiles es proporcionar un contexto que facilite la innovación, el afán de las técnicas tradicionales para la captura de requisitos por conseguir una especificación completa y pormenorizada de requisitos que guíe el proceso de desarrollo, parece no encajar a priori con el carácter innovador de las metodologías ágiles. Aplicar el pensamiento creativo a la captura de requisitos, permitiría en principio seguir contemplando la captura de requisitos como una fase más del desarrollo ágil, sin penalizar el carácter innovador de estas metodologías. Para evaluar las iniciativas al respecto que existen hasta la fecha, este trabajo presenta una revisión sistemática que identifica y analiza los trabajos que proponen alguna forma de combinar la utilización de técnicas creativas para la toma de requisitos con el desarrollo ágil. El estudio revela que hasta el momento las metodologías ágiles  basadas en modelado rápido son las más populares como forma de introducir la creatividad en la toma de de requisitos. Asimismo, el estudio muestra que la creatividad en la toma de requisitos debe venir acompañada de un alto nivel de compromiso por parte del usuario y de un contexto que favorezca la flexibilidad, si queremos favorecer la innovación en el desarrollo de software.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-067.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-067.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ainhoa Aldave]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[a.aparicioa@alumnos.urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group, University Rey Juan Carlos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group, University Rey Juan Carlos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[David Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[david.granada@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group, University Rey Juan Carlos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[david.gr4n4d4@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group, University Rey Juan Carlos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/064]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Scalable and queryable compressed storage structure for raster data</title>
		<link>https://biblioteca.sistedes.es/articulo/scalable-and-queryable-compressed-storage-structure-for-raster-data/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/scalable-and-queryable-compressed-storage-structure-for-raster-data/</guid>
		<description></description>
		<content><![CDATA[Titulo: Scalable and queryable compressed storage structure for raster data Autores: Susana Ladra, José R. Paramá, Fernando Silva-Coira Revista: Information Systems Volume 72, December 2017, Pages 179-204Factor de impacto: 2.777Ranking JCR: Q2Citas: 1 DOI: https://doi.org/10.1016/j.is.2017.10.007]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2991</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[scalable-and-queryable-compressed-storage-structure-for-raster-data]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="compresion-de-datos"><![CDATA[Compresión de datos]]></category>
		<category domain="post_tag" nicename="raster"><![CDATA[Ráster]]></category>
		<category domain="post_tag" nicename="sistemas-de-informacion-geografica"><![CDATA[Sistemas de Informacíon Geográfica]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Titulo: Scalable and queryable compressed storage structure for raster data
Autores: Susana Ladra, José R. Paramá, Fernando Silva-Coira

Revista: Information Systems Volume 72, December 2017, Pages 179-204

Factor de impacto: 2.777
Ranking JCR: Q2
Citas: 1

DOI: https://doi.org/10.1016/j.is.2017.10.007]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-068.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-068.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Susana Ladra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[susana.ladra@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose R. Parama]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[parama@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Fernando Silva-Coira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fernando.silva@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/065]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>DataGenCARS: A generator of synthetic data for the evaluation of context-aware recommendation systems</title>
		<link>https://biblioteca.sistedes.es/articulo/trabajo-relevante-datagencars-a-generator-of-synthetic-data-for-the-evaluation-of-context-aware-recommendation-systems/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/trabajo-relevante-datagencars-a-generator-of-synthetic-data-for-the-evaluation-of-context-aware-recommendation-systems/</guid>
		<description></description>
		<content><![CDATA[Este artículo se presenta a JISBD como trabajo relevante y ha sido publicado en la revista Pervasive and Mobile Computing en el año 2017.María del Carmen Rodríguez-Hernández, Sergio Ilarri, Ramón Hermoso, Raquel Trillo-Lado, "DataGenCARS: A Generator of Synthetic Data for the Evaluation of Context-Aware Recommendation Systems", Pervasive and Mobile Computing, ISSN 1574-1192, volume 38, part 2, pp. 516-541, Elsevier, July 2017. Special Issue on Context-aware Mobile Recommender Systems.DOI: 10.1016/j.pmcj.2016.09.020.JCR 2016 (última edición del JCR publicada): factor de impacto: 2,349; 53/146 en Computer Science, Information Systems (Q2, T2); 34/89 en Telecommunications (Q2, T2). Revista en el top 36,3% (considerando la mejor categoría del JCR).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2992</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[trabajo-relevante-datagencars-a-generator-of-synthetic-data-for-the-evaluation-of-context-aware-recommendation-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="context-aware-recommendation-systems"><![CDATA[Context-aware recommendation systems]]></category>
		<category domain="post_tag" nicename="dataset-generation"><![CDATA[Dataset generation]]></category>
		<category domain="post_tag" nicename="evaluation"><![CDATA[Evaluation]]></category>
		<category domain="post_tag" nicename="mobile-recommendations"><![CDATA[Mobile recommendations]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo se presenta a JISBD como trabajo relevante y ha sido publicado en la revista Pervasive and Mobile Computing en el año 2017.

María del Carmen Rodríguez-Hernández, Sergio Ilarri, Ramón Hermoso, Raquel Trillo-Lado, "DataGenCARS: A Generator of Synthetic Data for the Evaluation of Context-Aware Recommendation Systems", Pervasive and Mobile Computing, ISSN 1574-1192, volume 38, part 2, pp. 516-541, Elsevier, July 2017. Special Issue on Context-aware Mobile Recommender Systems.
DOI: 10.1016/j.pmcj.2016.09.020.

JCR 2016 (última edición del JCR publicada): factor de impacto: 2,349; 53/146 en Computer Science, Information Systems (Q2, T2); 34/89 en Telecommunications (Q2, T2).
Revista en el top 36,3% (considerando la mejor categoría del JCR).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-069.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-069.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Del Carmen Rodríguez Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mary0485@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[UNIZAR - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Ilarri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[silarri@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ramon Hermoso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[rhermoso@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Raquel Trillo-Lado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[raqueltl@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/066]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Quid: A web-based DSL for defining User Interfaces applied to Web Components</title>
		<link>https://biblioteca.sistedes.es/articulo/quid-a-web-based-dsl-for-defining-user-interfaces-applied-to-web-components/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/quid-a-web-based-dsl-for-defining-user-interfaces-applied-to-web-components/</guid>
		<description></description>
		<content><![CDATA[User Interface construction is a recurrent topic in Software Engineering: multiples tools ranging from textual, graphical design tools exists to help in this task.On the other hand, the fast pace of front-end industrial frameworks makes such editors tools obsolete as soon as new technology emerges.The work presented here, introduces Quid, a web based DSL with focus on minimal accidental complexity, removing accessory markup and a WUYIWYG environment to provide real-time feedback to users.Moreover, the UI specification built in this way is catalog neutral: in the way its primitives can be extended, and target platform agnostic: using model transformations and code generation for generating software artifacts like Native Web Components or Angular Elements code.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2993</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[quid-a-web-based-dsl-for-defining-user-interfaces-applied-to-web-components]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="code-generation"><![CDATA[code generation]]></category>
		<category domain="post_tag" nicename="dsl"><![CDATA[DSL]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="user-interface-design"><![CDATA[User Interface Design]]></category>
		<category domain="post_tag" nicename="web-components"><![CDATA[Web Components]]></category>
		<category domain="post_tag" nicename="web-dsl"><![CDATA[Web DSL]]></category>
		<category domain="post_tag" nicename="wysiwygw"><![CDATA[WYSIWYGW]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[User Interface construction is a recurrent topic in Software Engineering: multiples tools ranging from textual, graphical design tools exists to help in this task.
On the other hand, the fast pace of front-end industrial frameworks makes such editors tools obsolete as soon as new technology emerges.
The work presented here, introduces <<Quid>>, a web based DSL with focus on minimal accidental complexity, removing accessory markup and a WUYIWYG environment to provide real-time feedback to users.
Moreover, the UI specification built in this way is catalog neutral: in the way its primitives can be extended, and target platform agnostic: using model transformations and code generation for generating software artifacts like Native Web Components or Angular Elements code.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-070.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-070.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro J. Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pjmolina@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Metadev S.L. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/067]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Mecanismos de Reconfiguración Eco-eficiente de Código en Aplicaciones Móviles Android</title>
		<link>https://biblioteca.sistedes.es/articulo/mecanismos-de-reconfiguracion-eco-eficiente-de-codigo-en-aplicaciones-moviles-android/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/mecanismos-de-reconfiguracion-eco-eficiente-de-codigo-en-aplicaciones-moviles-android/</guid>
		<description></description>
		<content><![CDATA[Los dispositivos móviles ofrecen cada vez mayores prestaciones a costa de un mayor consumo energético. La energía consumida por un móvil no sólo depende de las aplicaciones en sí, sino también de las interacciones del usuario con la aplicación. Si un recurso no está siendo utilizado por la aplicación, no debería estar consumiendo energía. En este artículo se presenta un modelo de adaptación de aplicaciones móviles al contexto del usuario con el objetivo de reducir el consumo energético de las aplicaciones. Se desarrollan y evalúan cuatro implementaciones diferentes de la propuesta en busca del mecanismo de reconfiguración más eficiente energéticamente.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2994</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mecanismos-de-reconfiguracion-eco-eficiente-de-codigo-en-aplicaciones-moviles-android]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="adaptabilidad"><![CDATA[Adaptabilidad]]></category>
		<category domain="post_tag" nicename="android"><![CDATA[Android]]></category>
		<category domain="post_tag" nicename="dispositivos-moviles"><![CDATA[Dispositivos móviles]]></category>
		<category domain="post_tag" nicename="eco-eficiente"><![CDATA[Eco-Eficiente]]></category>
		<category domain="post_tag" nicename="energia"><![CDATA[Energía]]></category>
		<category domain="post_tag" nicename="reconfiguracion-dinamica"><![CDATA[reconfiguración dinámica]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los dispositivos móviles ofrecen cada vez mayores prestaciones a costa de un mayor consumo energético. La energía consumida por un móvil no sólo depende de las aplicaciones en sí, sino también de las interacciones del usuario con la aplicación. Si un recurso no está siendo utilizado por la aplicación, no debería estar consumiendo energía. En este artículo se presenta un modelo de adaptación de aplicaciones móviles al contexto del usuario con el objetivo de reducir el consumo energético de las aplicaciones. Se desarrollan y evalúan cuatro implementaciones diferentes de la propuesta en busca del mecanismo de reconfiguración más eficiente energéticamente.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-071.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-071.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Angel Canete]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[angelcv@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Miguel Horcas Aguilera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[horcas@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Mlaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/068]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>MRG4BPEL: herramienta para generar relaciones metamórficas candidatas en composiciones WS-BPEL</title>
		<link>https://biblioteca.sistedes.es/articulo/mrg4bpel-herramienta-para-generar-relaciones-metamorficas-candidatas-en-composiciones-ws-bpel/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/mrg4bpel-herramienta-para-generar-relaciones-metamorficas-candidatas-en-composiciones-ws-bpel/</guid>
		<description></description>
		<content><![CDATA[En el contexto de la prueba de software, existen diversas técnicas que permiten probar las composiciones de servicios web. Una de ellas, que va adquiriendo importancia y visibilidad en este campo es la Prueba Metamórfica (PM).Dentro los aspectos que esta técnica requiere considerar, está la obtención y generación de Relaciones Metamórficas (RM), parte esencial y la más compleja de automatizar. En este trabajo se abordan las mejoras  tanto en la arquitectura inicialmente propuesta (que representa un framework para probar composiciones de servicios web en el lenguaje WS-BPEL), como en los módulos que la componen. Es decir, se describen los avances en la herramienta de análisis (Analyzer4BPEL) y se presenta una nueva  aplicación para generar RM candidatas, MRG4BPEL. Se muestra un caso de uso, donde, a partir de una composición, se obtienen y aplican RM utilizando estas herramientas, así como las conclusiones obtenidas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2995</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mrg4bpel-herramienta-para-generar-relaciones-metamorficas-candidatas-en-composiciones-ws-bpel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="casos-de-prueba-siguientes"><![CDATA[casos de prueba siguientes]]></category>
		<category domain="post_tag" nicename="prueba-metamorfica"><![CDATA[prueba metamórfica]]></category>
		<category domain="post_tag" nicename="relaciones-metamorficas"><![CDATA[relaciones metamórficas]]></category>
		<category domain="post_tag" nicename="ws-bpel"><![CDATA[WS-BPEL]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En el contexto de la prueba de software, existen diversas técnicas que permiten probar las composiciones de servicios web. Una de ellas, que va adquiriendo importancia y visibilidad en este campo es la Prueba Metamórfica (PM).
Dentro los aspectos que esta técnica requiere considerar, está la obtención y generación de Relaciones Metamórficas (RM), parte esencial y la más compleja de automatizar. En este trabajo se abordan las mejoras  tanto en la arquitectura inicialmente propuesta (que representa un framework para probar composiciones de servicios web en el lenguaje WS-BPEL), como en los módulos que la componen. Es decir, se describen los avances en la herramienta de análisis (Analyzer4BPEL) y se presenta una nueva  aplicación para generar RM candidatas, MRG4BPEL. Se muestra un caso de uso, donde, a partir de una composición, se obtienen y aplican RM utilizando estas herramientas, así como las conclusiones obtenidas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-072.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-072.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[M.Carmen De Castro-Cabrera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[maricarmen.decastro@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Cadiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Kevin J. Valle-Gómez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[kevin.valle@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Cadiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Pablo Tena-Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[pablo.tenasanchez@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/069]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evaluación de la Sobrecarga en Pruebas de Transformaciones de Modelos</title>
		<link>https://biblioteca.sistedes.es/articulo/evaluacion-de-la-sobrecarga-en-pruebas-de-transformaciones-de-modelos/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/evaluacion-de-la-sobrecarga-en-pruebas-de-transformaciones-de-modelos/</guid>
		<description></description>
		<content><![CDATA[En el Desarrollo Software Dirigido por Modelos, el desarrollo y mantenimiento de transformaciones entre modelos conlleva grandes costes. La definición de pruebas permite mejorar la calidad y reducir los costes de estos procesos. Sin embargo, hasta ahora no se ha considerado la sobrecarga introducida por las actuales propuestas de pruebas. En este trabajo, se identifican las principales fuentes de sobrecarga en propuestas de pruebas basadas en contratos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2996</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evaluacion-de-la-sobrecarga-en-pruebas-de-transformaciones-de-modelos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="desarrollo-software-dirigido-por-modelos"><![CDATA[Desarrollo Software Dirigido por Modelos]]></category>
		<category domain="post_tag" nicename="especificacion-basada-en-contratos"><![CDATA[Especificación basada en contratos]]></category>
		<category domain="post_tag" nicename="pruebas-de-transformaciones-de-modelos"><![CDATA[Pruebas de Transformaciones de Modelos]]></category>
		<category domain="post_tag" nicename="sobrecarga"><![CDATA[Sobrecarga]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En el Desarrollo Software Dirigido por Modelos, el desarrollo y mantenimiento de transformaciones entre modelos conlleva grandes costes. La definición de pruebas permite mejorar la calidad y reducir los costes de estos procesos. Sin embargo, hasta ahora no se ha considerado la sobrecarga introducida por las actuales propuestas de pruebas. En este trabajo, se identifican las principales fuentes de sobrecarga en propuestas de pruebas basadas en contratos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-073.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-073.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Roberto Rodriguez-Echeverria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rre@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando Macías]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fmac@hvl.no]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Western Norway University of Applied Sciences - Norway]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose Maria Conejero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[chemacm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Carlos Preciado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jcpreciado@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Alvaro Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aeprieto@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Adrian Rutle]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[aru@hib.no]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Faculty of Engineering and Business Administration - Norway]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/070]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generacio?n de pruebas del sistema en el desarrollo del proyecto ADAGIO mediante la aplicacio?n de NDT</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-de-pruebas-del-sistema-en-el-desarrollo-del-proyecto-adagio-mediante-la-aplicacion-de-ndt/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/generacion-de-pruebas-del-sistema-en-el-desarrollo-del-proyecto-adagio-mediante-la-aplicacion-de-ndt/</guid>
		<description></description>
		<content><![CDATA[La ingenieri?a guiada por modelos (MDE) se ha utilizado en los u?ltimos an?os para promover mejores resultados en el desarrollo de aplicaciones web, en el campo que se ha denominado ingenieri?a web guiada por modelos (MDWE). Una de las ventajas de aplicar MDWE es que ofrece una solucio?n para reducir el coste de las pruebas sin afectar su ejecucio?n ni la calidad de las mismas. Navigational Development Techinques (NDT), es una metodologi?a que proporciona soporte para todas las fases del ciclo de vida del desarrollo de un proyecto de software, proponiendo transformaciones automa?ticas entre dichas fases, sin embargo, en este trabajo, aunque se describe brevemente co?mo se ha hecho uso de NDT para la definicio?n de las fases de requisitos y ana?lisis, se hace hincapie? en el uso de la metodologi?a para la definicio?n de la fase de pruebas de un proyecto real denominado ADAGIO. La aplicacio?n de esta metodologi?a, proporciona un mayor i?ndice de cobertura de pruebas del sistema, y, consecuentemente, un incremento en la calidad del producto.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2997</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-de-pruebas-del-sistema-en-el-desarrollo-del-proyecto-adagio-mediante-la-aplicacion-de-ndt]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="ingenieria-web-guiada-por-modelos"><![CDATA[Ingenieri?a web guiada por modelos]]></category>
		<category domain="post_tag" nicename="metodologia"><![CDATA[Metodología]]></category>
		<category domain="post_tag" nicename="ndt"><![CDATA[NDT]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La ingenieri?a guiada por modelos (MDE) se ha utilizado en los u?ltimos an?os para promover mejores resultados en el desarrollo de aplicaciones web, en el campo que se ha denominado ingenieri?a web guiada por modelos (MDWE). Una de las ventajas de aplicar MDWE es que ofrece una solucio?n para reducir el coste de las pruebas sin afectar su ejecucio?n ni la calidad de las mismas. Navigational Development Techinques (NDT), es una metodologi?a que proporciona soporte para todas las fases del ciclo de vida del desarrollo de un proyecto de software, proponiendo transformaciones automa?ticas entre dichas fases, sin embargo, en este trabajo, aunque se describe brevemente co?mo se ha hecho uso de NDT para la definicio?n de las fases de requisitos y ana?lisis, se hace hincapie? en el uso de la metodologi?a para la definicio?n de la fase de pruebas de un proyecto real denominado ADAGIO. La aplicacio?n de esta metodologi?a, proporciona un mayor i?ndice de cobertura de pruebas del sistema, y, consecuentemente, un incremento en la calidad del producto.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-074.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-074.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[S. Moreno-Leonardo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[sara.moreno@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[J.G. Enríquez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jose.gonzalez@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[L. Morales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[leticia.morales@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[F.J. Dominguez-Mayo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[fjdominguez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/071]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>API para el desarrollo de algoritmos interactivos en ingeniería del software basada en búsqueda</title>
		<link>https://biblioteca.sistedes.es/articulo/api-para-el-desarrollo-de-algoritmos-interactivos-en-ingenieria-del-software-basada-en-busqueda/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/api-para-el-desarrollo-de-algoritmos-interactivos-en-ingenieria-del-software-basada-en-busqueda/</guid>
		<description></description>
		<content><![CDATA[La experiencia y la intuición son factores clave a la hora de dar solución a los complejos problemas que plantea la ingeniería del software. Sin embargo, este tipo de criterios no suelen ser considerados cuando su resolución se aborda por medio de técnicas de búsqueda automática. La ingeniería del software basada en búsqueda (SBSE) no puede ni debe obviar la opinión del ingeniero, razón por la que cada vez es más frecuente encontrar propuestas que le invitan a participar en el proceso. Diseñar e implementar un mecanismo de interacción efectivo, a la par que atractivo para el ingeniero, puede resultar complejo. Por ello, este trabajo presenta una API para dar soporte al desarrollo de algoritmos interactivos en SBSE. En base a los enfoques interactivos actuales en SBSE, esta API expone cuáles son los requisitos propios de la interactividad que deben programarse como, por ejemplo, la forma de evaluar las soluciones y las acciones que el ingeniero puede realizar sobre ellas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2999</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[api-para-el-desarrollo-de-algoritmos-interactivos-en-ingenieria-del-software-basada-en-busqueda]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="application-programming-interface"><![CDATA[Application Programming Interface]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software-basada-en-busqueda"><![CDATA[ingeniería del software basada en búsqueda]]></category>
		<category domain="post_tag" nicename="interactividad"><![CDATA[interactividad]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La experiencia y la intuición son factores clave a la hora de dar solución a los complejos problemas que plantea la ingeniería del software. Sin embargo, este tipo de criterios no suelen ser considerados cuando su resolución se aborda por medio de técnicas de búsqueda automática. La ingeniería del software basada en búsqueda (SBSE) no puede ni debe obviar la opinión del ingeniero, razón por la que cada vez es más frecuente encontrar propuestas que le invitan a participar en el proceso. Diseñar e implementar un mecanismo de interacción efectivo, a la par que atractivo para el ingeniero, puede resultar complejo. Por ello, este trabajo presenta una API para dar soporte al desarrollo de algoritmos interactivos en SBSE. En base a los enfoques interactivos actuales en SBSE, esta API expone cuáles son los requisitos propios de la interactividad que deben programarse como, por ejemplo, la forma de evaluar las soluciones y las acciones que el ingeniero puede realizar sobre ellas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-076.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-076.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aurora Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aramirez@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Raúl Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sebastián Ventura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sventura@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/073]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un Repositorio RDF para la Integración y Consulta de Datos de Pacientes Hepáticos</title>
		<link>https://biblioteca.sistedes.es/articulo/un-repositorio-rdf-para-la-integracion-y-consulta-de-datos-de-pacientes-hepaticos/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/un-repositorio-rdf-para-la-integracion-y-consulta-de-datos-de-pacientes-hepaticos/</guid>
		<description></description>
		<content><![CDATA[Los casos médicos pasados, y por lo tanto, la experiencia clínica, son recursos de valor incalculable para apoyar la práctica clínica, la investigación y la formación. Los profesionales médicos deben poder intercambiar información sobre casos médicos de pacientes y explorarlos desde distintas perspectivas subjetivas. Esto requiere de una metodología sistemática y flexible para la representación de los casos médicos que soporte el intercambio de información procesable del paciente. En este artículo presentamos un enfoque basado en ontologías para modelar casos médicos de pacientes que utiliza pacientes con enfermedades hepáticas como ejemplo. Para este fin, se propone una nueva ontología, LiCO, que utiliza estándares médicos bien conocidos para representar casos de pacientes con enfermedades hepáticas. La utilidad del enfoque propuesto se demuestra con consultas semánticas y razonamiento utilizando datos recopilados de pacientes reales. Los resultados preliminares son prometedores con respecto al potencial de la representación de casos médicos basada en ontologías para la construcción de sistemas de búsqueda y recuperación de información de casos médicos, allanando el camino hacia una plataforma de intercambio de experiencias clínicas para comparar diagnósticos, para investigación y para formación.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3000</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-repositorio-rdf-para-la-integracion-y-consulta-de-datos-de-pacientes-hepaticos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="integracion-de-datos"><![CDATA[Integración de datos]]></category>
		<category domain="post_tag" nicename="ontologias"><![CDATA[Ontologías]]></category>
		<category domain="post_tag" nicename="rdf"><![CDATA[RDF]]></category>
		<category domain="post_tag" nicename="representacion-de-casos-medicos"><![CDATA[Representación de casos médicos]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los casos médicos pasados, y por lo tanto, la experiencia clínica, son recursos de valor incalculable para apoyar la práctica clínica, la investigación y la formación. Los profesionales médicos deben poder intercambiar información sobre casos médicos de pacientes y explorarlos desde distintas perspectivas subjetivas. Esto requiere de una metodología sistemática y flexible para la representación de los casos médicos que soporte el intercambio de información procesable del paciente. En este artículo presentamos un enfoque basado en ontologías para modelar casos médicos de pacientes que utiliza pacientes con enfermedades hepáticas como ejemplo. Para este fin, se propone una nueva ontología, LiCO, que utiliza estándares médicos bien conocidos para representar casos de pacientes con enfermedades hepáticas. La utilidad del enfoque propuesto se demuestra con consultas semánticas y razonamiento utilizando datos recopilados de pacientes reales. Los resultados preliminares son prometedores con respecto al potencial de la representación de casos médicos basada en ontologías para la construcción de sistemas de búsqueda y recuperación de información de casos médicos, allanando el camino hacia una plataforma de intercambio de experiencias clínicas para comparar diagnósticos, para investigación y para formación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-077.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-077.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Maria Del Mar Roldan-Garcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mmar@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose F. Aldana-Montes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jfam@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/074]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Infrastructure Modelling Tool for Cloud Provisioning</title>
		<link>https://biblioteca.sistedes.es/articulo/an-infrastructure-modelling-tool-for-cloud-provisioning/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-infrastructure-modelling-tool-for-cloud-provisioning/</guid>
		<description></description>
		<content><![CDATA[Autores: Julio Sandobalin, Emilio Insfran, Silvia Abrahao(Universitat Politècnica de València y Escuela Politécnica NacionalQuito, Ecuador)Conferencia: The 14th IEEE International Conference on Services ComputingJun 25, 2017 - Jun 30, 2017 Honolulu, Hawaii, USAPáginas: 8Editorial: IEEEElectronic ISSN: 2474-2473DOI: 10.1109/SCC.2017.52Indicios de calidad de acuerdo al GII-GRIN-SCIE (GGS) Conference Rating: GGS Class 2; GGS Rating A; Qualified Classes CORE:A, LiveSHINE:A; Collected Classes A, A.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3001</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-infrastructure-modelling-tool-for-cloud-provisioning]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cloud-services"><![CDATA[Cloud Services]]></category>
		<category domain="post_tag" nicename="devops"><![CDATA[DevOps]]></category>
		<category domain="post_tag" nicename="infrastructure-provisioning"><![CDATA[Infrastructure Provisioning]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Autores: Julio Sandobalin, Emilio Insfran, Silvia Abrahao
(Universitat Politècnica de València y Escuela Politécnica Nacional
Quito, Ecuador)
Conferencia: The 14th IEEE International Conference on Services Computing
Jun 25, 2017 - Jun 30, 2017 Honolulu, Hawaii, USA
Páginas: 8
Editorial: IEEE
Electronic ISSN: 2474-2473
DOI: 10.1109/SCC.2017.52

Indicios de calidad de acuerdo al GII-GRIN-SCIE (GGS) Conference Rating: GGS Class 2; GGS Rating A; Qualified Classes CORE:A, LiveSHINE:A; Collected Classes A, A.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-078.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-078.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julio Sandobalin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[julio.sandobalin@epn.edu.ec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática y Ciencias de la Computación, Escuela Politécnica Nacional, Ecuador]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Emilio Insfran]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[einsfran@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Silvia Abrahao]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sabrahao@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/075]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Coordinación de dispositivos IoT mediante Web Semántica y Ontologías en Situational-Context</title>
		<link>https://biblioteca.sistedes.es/articulo/coordinacion-de-dispositivos-iot-mediante-web-semantica-y-ontologias-en-situational-context/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/coordinacion-de-dispositivos-iot-mediante-web-semantica-y-ontologias-en-situational-context/</guid>
		<description></description>
		<content><![CDATA[El ritmo al que crece Internet de las Cosas (IoT) es imparable. Existen multitud de fabricantes que desarrollan dispositivos IoT, siguiendo sus propias especificaciones y sin atender a un estándar que todavía no existe como tal. Esto nos lleva a una situación donde la gran heterogeneidad de dispositivos que podemos encontrar en el mercado, provoca que esta interconexión sea compleja o incluso no sea posible, impidiendo así que los dispositivos puedan coordinarse para desarrollar tareas colaborativas. Esta interconexión además depende del contexto, pues los dispositivos IoT deben adaptar su comportamiento dependiendo de las características de las personas que les rodean. Con nuestra propuesta, abordamos esta situación proponiendo un sistema que permita identificar una interconexión dinámica de dispositivos IoT que surja de situaciones cambiantes. Gracias a nuestro trabajo conseguimos que esta interconexión sea dependiente del contexto, creando un entorno colaborativo entre personas y dispositivos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3002</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[coordinacion-de-dispositivos-iot-mediante-web-semantica-y-ontologias-en-situational-context]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="contexto"><![CDATA[Contexto]]></category>
		<category domain="post_tag" nicename="interconexion"><![CDATA[Interconexión]]></category>
		<category domain="post_tag" nicename="internet-de-las-cosas"><![CDATA[Internet de las Cosas]]></category>
		<category domain="post_tag" nicename="personas"><![CDATA[Personas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El ritmo al que crece Internet de las Cosas (IoT) es imparable. Existen multitud de fabricantes que desarrollan dispositivos IoT, siguiendo sus propias especificaciones y sin atender a un estándar que todavía no existe como tal. Esto nos lleva a una situación donde la gran heterogeneidad de dispositivos que podemos encontrar en el mercado, provoca que esta interconexión sea compleja o incluso no sea posible, impidiendo así que los dispositivos puedan coordinarse para desarrollar tareas colaborativas. Esta interconexión además depende del contexto, pues los dispositivos IoT deben adaptar su comportamiento dependiendo de las características de las personas que les rodean. Con nuestra propuesta, abordamos esta situación proponiendo un sistema que permita identificar una interconexión dinámica de dispositivos IoT que surja de situaciones cambiantes. Gracias a nuestro trabajo conseguimos que esta interconexión sea dependiente del contexto, creando un entorno colaborativo entre personas y dispositivos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-079.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-079.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Daniel Flores-Martin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[dfloresm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alejandro Pérez Vereda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[apvereda@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Murillo Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/076]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Application of Data Mining techniques to identify relevant Key Performance Indicators</title>
		<link>https://biblioteca.sistedes.es/articulo/application-of-data-mining-techniques-to-identify-relevant-key-performance-indicators/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/application-of-data-mining-techniques-to-identify-relevant-key-performance-indicators/</guid>
		<description></description>
		<content><![CDATA[Datos:Revista: Computer Standards & Interfaces (CSI)Volumen, páginas y fecha: Vol. 54(2), pp 76-85, Noviembre de 2017DOI: https://doi.org/10.1016/j.csi.2016.11.006Indicios de calidad:- Revista en Ranking: Q2, 40/106 COMPUTER SCIENCE, SOFTWARE ENGINEERING- Factor de Impacto: 1.633- Citas: 2 (Scopus)]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3003</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[application-of-data-mining-techniques-to-identify-relevant-key-performance-indicators]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="data-mining"><![CDATA[Data Mining]]></category>
		<category domain="post_tag" nicename="kpis"><![CDATA[KPIs]]></category>
		<category domain="post_tag" nicename="open-data"><![CDATA[Open Data]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Datos:

Revista: Computer Standards & Interfaces (CSI)
Volumen, páginas y fecha: Vol. 54(2), pp 76-85, Noviembre de 2017
DOI: https://doi.org/10.1016/j.csi.2016.11.006

Indicios de calidad:
- Revista en Ranking: Q2, 40/106 COMPUTER SCIENCE, SOFTWARE ENGINEERING
- Factor de Impacto: 1.633
- Citas: 2 (Scopus)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-080.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-080.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesus Peral]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jperal@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Alicante - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alejandro Maté]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[amate@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Alicante - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manolo Marco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[marco@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Alicante - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/077]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>RESDEC: Un prototipo de herramienta para la selección de configuraciones de despliegue basada en Sistemas de Recomendación</title>
		<link>https://biblioteca.sistedes.es/articulo/resdec-un-prototipo-de-herramienta-para-la-seleccion-de-configuraciones-de-despliegue-basada-en-sistemas-de-recomendacion/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/resdec-un-prototipo-de-herramienta-para-la-seleccion-de-configuraciones-de-despliegue-basada-en-sistemas-de-recomendacion/</guid>
		<description></description>
		<content><![CDATA[Los sistemas de alta variabilidad son sistemas que representan cientos de configuraciones distintas. En un contexto particular, estas configuraciones pueden ser desplegadas en distintos entornos de despliegue lo cual es una decisión crítica para el correcto funcionamiento de la misma. Por ejemplo, determinar en qué dispositivo móvil se va a ejecutar correctamente nuestra app, es una tarea difícil de resolver. En este artículo presentamos RESDEC, un prototipo de herramienta para asistir al ingeniero de software en la toma de decisiones para el despliegue. Concretamente RESDEC provee algoritmos de recomendación para tres escenarios de despliegue distintos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3006</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[resdec-un-prototipo-de-herramienta-para-la-seleccion-de-configuraciones-de-despliegue-basada-en-sistemas-de-recomendacion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="configuraciones"><![CDATA[Configuraciones]]></category>
		<category domain="post_tag" nicename="sistemas-de-alta-variabilidad"><![CDATA[Sistemas de alta variabilidad]]></category>
		<category domain="post_tag" nicename="sistemas-de-recomendacion"><![CDATA[Sistemas de recomendación]]></category>
		<category domain="post_tag" nicename="valoraciones"><![CDATA[Valoraciones]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los sistemas de alta variabilidad son sistemas que representan cientos de configuraciones distintas. En un contexto particular, estas configuraciones pueden ser desplegadas en distintos entornos de despliegue lo cual es una decisión crítica para el correcto funcionamiento de la misma. Por ejemplo, determinar en qué dispositivo móvil se va a ejecutar correctamente nuestra app, es una tarea difícil de resolver. En este artículo presentamos RESDEC, un prototipo de herramienta para asistir al ingeniero de software en la toma de decisiones para el despliegue. Concretamente RESDEC provee algoritmos de recomendación para tres escenarios de despliegue distintos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-083.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-083.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jorge Rodas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jorge.rodass@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Milagro - Ecuador]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José A. Galindo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jagalindo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[David Benavides]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[benavides@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/080]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Entorno de Validación Configurable para Software Embebido Refactorizado y su Aplicación en Ascensores</title>
		<link>https://biblioteca.sistedes.es/articulo/entorno-de-validacion-configurable-para-software-embebido-refactorizado-y-su-aplicacion-en-ascensores/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/entorno-de-validacion-configurable-para-software-embebido-refactorizado-y-su-aplicacion-en-ascensores/</guid>
		<description></description>
		<content><![CDATA[Los ascensores son sistemas complejos que integran ademásde software, componentes eléctricos, mecánicos, etc. La complejidad deestos sistemas es aumentada además al tener en cuenta la variabilidad:un ascensor puede ser instalado en edificios de más o menos pisos, puedetener diferente puertas, los actuadores y sensores pueden variar, etc.La validación del software de estos sistemas es compleja en diferentesaspectos. Este artículo presenta un trabajo industrial para la validaciónde software embebido congurable refactorizado en el contexto del sectordel transporte vertical.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3007</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[entorno-de-validacion-configurable-para-software-embebido-refactorizado-y-su-aplicacion-en-ascensores]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="ascensores"><![CDATA[Ascensores]]></category>
		<category domain="post_tag" nicename="test"><![CDATA[Test]]></category>
		<category domain="post_tag" nicename="validacion"><![CDATA[Validación]]></category>
		<category domain="post_tag" nicename="variabilidad"><![CDATA[Variabilidad]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los ascensores son sistemas complejos que integran además
de software, componentes eléctricos, mecánicos, etc. La complejidad de
estos sistemas es aumentada además al tener en cuenta la variabilidad:
un ascensor puede ser instalado en edificios de más o menos pisos, puede
tener diferente puertas, los actuadores y sensores pueden variar, etc.
La validación del software de estos sistemas es compleja en diferentes
aspectos. Este artículo presenta un trabajo industrial para la validación
de software embebido congurable refactorizado en el contexto del sector
del transporte vertical.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-084.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-084.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Goiuria Sagardui]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[gsagardui@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Mondragon - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Leire Etxeberria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[letxeberria@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Mondragon Uniberstitatea - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Joseba Andoni Agirre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jaagirre@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Mondragon - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Aitor Arrieta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aarrieta@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Carlos F. Nicolas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[cfnicolas@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Ikerlan - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Jose Maria Martin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[jmmartinc@orona-group.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Orona EIC - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/081]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Patrón de seguridad para la autorización de bases de datos NoSQL (par clave-valor)</title>
		<link>https://biblioteca.sistedes.es/articulo/patron-de-seguridad-para-la-autorizacion-de-bases-de-datos-nosql-par-clave-valor/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/patron-de-seguridad-para-la-autorizacion-de-bases-de-datos-nosql-par-clave-valor/</guid>
		<description></description>
		<content><![CDATA[Aunque las bases de datos de tipo NoSQL surgieron hace unos años, son cada vez más usadas en diversos contextos, debido al crecimiento de los sistemas web y su uso en sistemas analíticos como Big Data. Sin embargo, generalmente este tipo de sistemas de almacenamiento no ha sido concebido con la seguridad en mente, pues se centran en resolver otros problemas como la velocidad de acceso o su uso en entornos distribuidos. Uno de los principales problemas de seguridad que se pueden identificar en estos entornos es la falta de un mecanismo de control de acceso nativo. Aunque existen numerosas propuestas hechas por investigadores que solucionan esta problemática para una tecnología concreta, faltan propuestas con un mayor nivel de abstracción que propongan soluciones más generales. En este sentido, una solución para este tipo de problemas generales es la creación de un patrón de seguridad. En este artículo proponemos un patrón de seguridad específico para realizar el control de acceso de bases de datos NoSQL de tipo clave-valor y se definen los diferentes elementos que lo conforman.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3008</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[patron-de-seguridad-para-la-autorizacion-de-bases-de-datos-nosql-par-clave-valor]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="nosql"><![CDATA[NoSQL]]></category>
		<category domain="post_tag" nicename="patrones-de-seguridad"><![CDATA[Patrones de Seguridad]]></category>
		<category domain="post_tag" nicename="seguridad-de-la-informacion"><![CDATA[Seguridad de la información]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Aunque las bases de datos de tipo NoSQL surgieron hace unos años, son cada vez más usadas en diversos contextos, debido al crecimiento de los sistemas web y su uso en sistemas analíticos como Big Data. Sin embargo, generalmente este tipo de sistemas de almacenamiento no ha sido concebido con la seguridad en mente, pues se centran en resolver otros problemas como la velocidad de acceso o su uso en entornos distribuidos. Uno de los principales problemas de seguridad que se pueden identificar en estos entornos es la falta de un mecanismo de control de acceso nativo. Aunque existen numerosas propuestas hechas por investigadores que solucionan esta problemática para una tecnología concreta, faltan propuestas con un mayor nivel de abstracción que propongan soluciones más generales. En este sentido, una solución para este tipo de problemas generales es la creación de un patrón de seguridad. En este artículo proponemos un patrón de seguridad específico para realizar el control de acceso de bases de datos NoSQL de tipo clave-valor y se definen los diferentes elementos que lo conforman.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-085.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-085.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julio Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[julio.moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de investigación GSyA. Universidad de Castilla La-Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Eduardo B. Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ed@cse.fau.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Florida Atlantic University - United States]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Serrano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Manuel.Serrano@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de investigación Alarcos. Universidad de Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Eduardo Fernandez-Medina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[eduardo.fdezmedina@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de investigación GSyA. Universidad de Castilla La-Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/082]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Descripción de pruebas de benchmark para plataformas de tercera generación</title>
		<link>https://biblioteca.sistedes.es/articulo/descripcion-de-pruebas-de-benchmark-para-plataformas-de-tercera-generacion/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/descripcion-de-pruebas-de-benchmark-para-plataformas-de-tercera-generacion/</guid>
		<description></description>
		<content><![CDATA[La irrupción del big data y la computación en la nube ha impulsado un cambio de paradigma en la construcción de nuevos sistemas basados en plataformas distribuidas escalables y orientadas al dato como servicio. La existencia de diversas tecnologías y la necesidad de evaluar el rendimiento de las aplicaciones construidas con ellas tanto en fase de prototipo como ya una vez implementadas y desplegadas en el entorno operativo, nos ha llevado a proponer un modelo de datos para describir pruebas de benchmark destinadas a la comparación de estas plataformas de tercera generación. El modelo incorpora información sobre todos los aspectos de la prueba: recursos, fuentes de datos, cargas de trabajo y métricas; cubre varios casos de uso y permite adaptar la información que contiene a las diferentes fases del ciclo de desarrollo del sistema. En las fases iniciales de desarrollo de prototipos, el modelo describe estimaciones de la carga de trabajo, de las prestaciones previstas para los recursos y componentes del sistema y de las métricas que se quieren valorar; mientras que en las fases finales de validación, el modelo sólo ha de incluir la identificación de las fuentes que generan las cargas de trabajo, de los recursos utilizados y de los componente desplegados, a fin de evaluar las métricas de interés.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3009</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[descripcion-de-pruebas-de-benchmark-para-plataformas-de-tercera-generacion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="benchmark"><![CDATA[Benchmark]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="distributed-system"><![CDATA[Distributed System]]></category>
		<category domain="post_tag" nicename="performance-metric"><![CDATA[Performance Metric]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La irrupción del big data y la computación en la nube ha impulsado un cambio de paradigma en la construcción de nuevos sistemas basados en plataformas distribuidas escalables y orientadas al dato como servicio. La existencia de diversas tecnologías y la necesidad de evaluar el rendimiento de las aplicaciones construidas con ellas tanto en fase de prototipo como ya una vez implementadas y desplegadas en el entorno operativo, nos ha llevado a proponer un modelo de datos para describir pruebas de benchmark destinadas a la comparación de estas plataformas de tercera generación. El modelo incorpora información sobre todos los aspectos de la prueba: recursos, fuentes de datos, cargas de trabajo y métricas; cubre varios casos de uso y permite adaptar la información que contiene a las diferentes fases del ciclo de desarrollo del sistema. En las fases iniciales de desarrollo de prototipos, el modelo describe estimaciones de la carga de trabajo, de las prestaciones previstas para los recursos y componentes del sistema y de las métricas que se quieren valorar; mientras que en las fases finales de validación, el modelo sólo ha de incluir la identificación de las fuentes que generan las cargas de trabajo, de los recursos utilizados y de los componente desplegados, a fin de evaluar las métricas de interés.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-086.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-086.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Luis Martin de La Rubia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[luis.martind@alumnos.unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ISTR-Universidad de Cantabria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miguel Algorri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[miguel.algorria@alumnos.unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ISTR-Universidad de Cantabria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Marta Elena Zorrilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[marta.zorrilla@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ISTR-Universidad de Cantabria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José María Drake]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[drakej@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[ISTR-Universidad de Cantabria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/083]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Building Scalable Graphical Modelling Environments with EMFSplitter (tool demo)</title>
		<link>https://biblioteca.sistedes.es/articulo/building-scalable-graphical-modelling-environments-with-emfsplitter-tool-demo/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/building-scalable-graphical-modelling-environments-with-emfsplitter-tool-demo/</guid>
		<description></description>
		<content><![CDATA[In Model-Driven Engineering the creation of Domain-Specific Modelling Languages (DSMLs) is a recurrent demanding task. Usually DSMLs are built in an ad-hoc manner and the generated environments do not scale well to face scenarios with complex systems. To improve this situation, we propose an approach to facilitate the engineering of DSMLs through a catalogue of patterns and a set of wizards to reduce the implementation time of such environments. Our approach is supported by a tool called EMFSplitter, which proposes a Modularity pattern to fragment the models and a Graphical Representation pattern, for the definition of graphical and tabular syntax.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3010</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[building-scalable-graphical-modelling-environments-with-emfsplitter-tool-demo]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="domain-specific-modelling-languages"><![CDATA[Domain-Specific Modelling Languages]]></category>
		<category domain="post_tag" nicename="graphical-modelling-environments"><![CDATA[Graphical Modelling Environments]]></category>
		<category domain="post_tag" nicename="meta-modelling"><![CDATA[Meta-modelling]]></category>
		<category domain="post_tag" nicename="modularity"><![CDATA[Modularity]]></category>
		<category domain="post_tag" nicename="scalable-modelling"><![CDATA[Scalable Modelling]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In Model-Driven Engineering the creation of Domain-Specific Modelling Languages (DSMLs) is a recurrent demanding task. Usually DSMLs are built in an ad-hoc manner and the generated environments do not scale well to face scenarios with complex systems. To improve this situation, we propose an approach to facilitate the engineering of DSMLs through a catalogue of patterns and a set of wizards to reduce the implementation time of such environments. Our approach is supported by a tool called EMFSplitter, which proposes a Modularity pattern to fragment the models and a Graphical Representation pattern, for the definition of graphical and tabular syntax.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-087.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-087.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Garmendia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[antonio.garmendia@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[UAM - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Esther Guerra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[esther.guerra@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Autónoma de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan De Lara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juan.delara@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Autonoma de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/084]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Data-Interoperability Aware Software Architecture</title>
		<link>https://biblioteca.sistedes.es/articulo/a-data-interoperability-aware-software-architecture/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-data-interoperability-aware-software-architecture/</guid>
		<description></description>
		<content><![CDATA[Making heterogeneous data sources homogeneous manually and off-line can become a high time-consuming task. This paper presents a software architecture that extends the standardized-based architectures for heterogeneous sensors with components to also support devices and data that are not compliant with standards. The defined architecture is based on Internet of Things (IoT) layered architectures that establish perception, network, middleware, application, and business as main layers. To define the architecture, an architectural framework was used; this framework supports the identification of non-compliant data, providing then a different processing path. This proposed architecture covers a wide spectrum of data interoperability addressing the IoT challenge of ``Interoperability and Standardization''. The implemented solution proved that the processing time between data acquisition and the feeding of analysis algorithms can be reduced from 100% to approximately to 1% with systems based on the proposed architecture compared with those that manage data manually and off-line.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3011</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-data-interoperability-aware-software-architecture]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="interoperability"><![CDATA[interoperability]]></category>
		<category domain="post_tag" nicename="iot"><![CDATA[IoT]]></category>
		<category domain="post_tag" nicename="software-architecture"><![CDATA[Software Architecture]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Making heterogeneous data sources homogeneous manually and off-line can become a high time-consuming task. This paper presents a software architecture that extends the standardized-based architectures for heterogeneous sensors with components to also support devices and data that are not compliant with standards. The defined architecture is based on Internet of Things (IoT) layered architectures that establish perception, network, middleware, application, and business as main layers. To define the architecture, an architectural framework was used; this framework supports the identification of non-compliant data, providing then a different processing path. This proposed architecture covers a wide spectrum of data interoperability addressing the IoT challenge of ``Interoperability and Standardization''. The implemented solution proved that the processing time between data acquisition and the feeding of analysis algorithms can be reduced from 100% to approximately to 1% with systems based on the proposed architecture compared with those that manage data manually and off-line.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-088.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-088.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Hector Humanes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[h.humanes@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Agustin Yague]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[agustin.yague@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jennifer Perez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jenifer.perez@etsisi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Garbajosa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jgs@etsisi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Llorenç Burgas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[llorenc.burgas@udg.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universitat de Girona - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Joan Colomer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[joan.colomer@udg.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Universitat de Girona - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Joaquim Melendez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[joaquim.melendez@udg.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Universitat de Girona - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_8]]></meta_key>
			<meta_value><![CDATA[Carles Pous]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_8]]></meta_key>
			<meta_value><![CDATA[carles.pous@udg.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_8]]></meta_key>
			<meta_value><![CDATA[Universitat de Girona - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/085]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automatización de la localización de defectos en el diseño de aplicaciones MapReduce</title>
		<link>https://biblioteca.sistedes.es/articulo/automatizacion-de-la-localizacion-de-defectos-en-el-diseno-de-aplicaciones-mapreduce/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/automatizacion-de-la-localizacion-de-defectos-en-el-diseno-de-aplicaciones-mapreduce/</guid>
		<description></description>
		<content><![CDATA[Los programas MapReduce analizan grandes cantidades de datos sobre una infraestructura distribuida. En cambio, estos programas pueden desarrollarse independientemente de la infraestructura ya que un framework gestiona automáticamente la asignación de recursos y la gestión de fallos. Una vez que se detecta un defecto, suele ser complicado localizar su causa raíz ya que diversas funciones se ejecutan simultáneamente en una infraestructura distribuida que cambia continuamente y que es difícil tanto de controlar como depurar. En este artículo se describe una técnica que, a partir de un caso de prueba que produce fallo, localiza su causa raíz analizando dinámicamente las características del diseño que se cubren cuando se produce fallo y aquellas que no.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3013</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automatizacion-de-la-localizacion-de-defectos-en-el-diseno-de-aplicaciones-mapreduce]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="localizacion-de-defectos"><![CDATA[Localización de defectos]]></category>
		<category domain="post_tag" nicename="mapreduce"><![CDATA[MapReduce]]></category>
		<category domain="post_tag" nicename="pruebas-del-software"><![CDATA[Pruebas del software]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los programas MapReduce analizan grandes cantidades de datos sobre una infraestructura distribuida. En cambio, estos programas pueden desarrollarse independientemente de la infraestructura ya que un framework gestiona automáticamente la asignación de recursos y la gestión de fallos. Una vez que se detecta un defecto, suele ser complicado localizar su causa raíz ya que diversas funciones se ejecutan simultáneamente en una infraestructura distribuida que cambia continuamente y que es difícil tanto de controlar como depurar. En este artículo se describe una técnica que, a partir de un caso de prueba que produce fallo, localiza su causa raíz analizando dinámicamente las características del diseño que se cubren cuando se produce fallo y aquellas que no.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-090.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-090.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús Morán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[moranjesus@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Claudio De La Riva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[claudio@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/087]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia la automatización de pruebas funcionales y de rendimiento en Android con algoritmos basados en búsqueda</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-la-automatizacion-de-pruebas-funcionales-y-de-rendimiento-en-android-con-algoritmos-basados-en-busqueda/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/hacia-la-automatizacion-de-pruebas-funcionales-y-de-rendimiento-en-android-con-algoritmos-basados-en-busqueda/</guid>
		<description></description>
		<content><![CDATA[Actualmente existen millones de aplicaciones para smartphone que deben ejecutarse correctamente en entornos software, hardware y de conectividad muy variados y cambiantes. El testing de dichas aplicaciones es por tanto un reto importante, para el que ligeras mejoras de la productividad suponen grandes beneficios para usuarios y desarrolladores. Este artículo presenta una primera aproximación de trabajo en curso para la  la automatización de pruebas funcionales y de rendimiento en aplicaciones android usando algoritmos basados en búsqueda. La viabilidad de la propuesta se ha validado aplicándola a dos aplicaciones simples. Generando casos de pruebas que detectan cierres abruptos en la aplicación y maximizan el tiempo de ejecución.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3014</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-la-automatizacion-de-pruebas-funcionales-y-de-rendimiento-en-android-con-algoritmos-basados-en-busqueda]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="android"><![CDATA[Android]]></category>
		<category domain="post_tag" nicename="automation"><![CDATA[automation]]></category>
		<category domain="post_tag" nicename="search-based-algorithms"><![CDATA[search based algorithms]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Actualmente existen millones de aplicaciones para smartphone que deben ejecutarse correctamente en entornos software, hardware y de conectividad muy variados y cambiantes. El testing de dichas aplicaciones es por tanto un reto importante, para el que ligeras mejoras de la productividad suponen grandes beneficios para usuarios y desarrolladores. Este artículo presenta una primera aproximación de trabajo en curso para la  la automatización de pruebas funcionales y de rendimiento en aplicaciones android usando algoritmos basados en búsqueda. La viabilidad de la propuesta se ha validado aplicándola a dos aplicaciones simples. Generando casos de pruebas que detectan cierres abruptos en la aplicación y maximizan el tiempo de ejecución.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-091.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-091.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Antonio Parejo Maestre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[japarejo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/088]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Enriquecimiento Automático de Ontologías Biomédicas mediante el uso de Mappings</title>
		<link>https://biblioteca.sistedes.es/articulo/enriquecimiento-automatico-de-ontologias-biomedicas-mediante-el-uso-de-mappings/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/enriquecimiento-automatico-de-ontologias-biomedicas-mediante-el-uso-de-mappings/</guid>
		<description></description>
		<content><![CDATA[Dione es una representación en OWL del ICD-10-CM, consistente lógicamente, cuyos axiomas definen las inclusiones y exclusiones del ICD-10-CM mediante una metodología basada en los mappings ICD-10-CM/SNOMED-CT, proporcionados por UMLS y BioPortal, y que han sido validados por una comunidad de expertos en el ámbito biomédico. En este artículo se presenta una metodología automática que permite la población con axiomas en Dione a partir de los mappings establecidos entre ICD-10-CM y otra ontología biomédica que hayan sido proporcionados por BioPortal. Para mostrar el funcionamiento de esta metodología, se han utilizado los mappings entre Dione y ORDO. Esta última es una ontología que incluye el conjunto de enfermedades raras, genes y otras características para la población de nuevos axiomas en Dione. Una vez que estos axiomas se incluyeron en Dione, se comprobó su consistencia utilizando el razonador ELK y se mostró con un caso de uso que las clases equivalentes entre las ontologías DIONE-ORDO permitían la inferencia de axiomas que definen una clase ICD-10-CM en DIONE a una clase que representa una enfermedad rara en ORDO y, viceversa. Esta nueva metodología se puede aplicar a dos ontologías biomédicas cualquiera cuyos mappings estén previamente definidos en BioPortal.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3016</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[enriquecimiento-automatico-de-ontologias-biomedicas-mediante-el-uso-de-mappings]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="enfermedades-raras"><![CDATA[Enfermedades Raras]]></category>
		<category domain="post_tag" nicename="icd-10-cm"><![CDATA[ICD-10-CM]]></category>
		<category domain="post_tag" nicename="mappings"><![CDATA[Mappings]]></category>
		<category domain="post_tag" nicename="ontologias-biomedicas"><![CDATA[Ontologías Biomédicas]]></category>
		<category domain="post_tag" nicename="razonamiento"><![CDATA[Razonamiento]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Dione es una representación en OWL del ICD-10-CM, consistente lógicamente, cuyos axiomas definen las inclusiones y exclusiones del ICD-10-CM mediante una metodología basada en los mappings ICD-10-CM/SNOMED-CT, proporcionados por UMLS y BioPortal, y que han sido validados por una comunidad de expertos en el ámbito biomédico. En este artículo se presenta una metodología automática que permite la población con axiomas en Dione a partir de los mappings establecidos entre ICD-10-CM y otra ontología biomédica que hayan sido proporcionados por BioPortal. Para mostrar el funcionamiento de esta metodología, se han utilizado los mappings entre Dione y ORDO. Esta última es una ontología que incluye el conjunto de enfermedades raras, genes y otras características para la población de nuevos axiomas en Dione. Una vez que estos axiomas se incluyeron en Dione, se comprobó su consistencia utilizando el razonador ELK y se mostró con un caso de uso que las clases equivalentes entre las ontologías DIONE-ORDO permitían la inferencia de axiomas que definen una clase ICD-10-CM en DIONE a una clase que representa una enfermedad rara en ORDO y, viceversa. Esta nueva metodología se puede aplicar a dos ontologías biomédicas cualquiera cuyos mappings estén previamente definidos en BioPortal.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-093.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-093.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Jesús García Godoy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mjgarciag@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Esteban López-Camacho]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[esteban@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[María Del Mar Roldán-García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mmar@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jose F Aldana Montes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jfam@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/090]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>CMSA para el problema de la generación de casos de prueba priorizados en líneas de productos software</title>
		<link>https://biblioteca.sistedes.es/articulo/cmsa-para-el-problema-de-la-generacion-de-casos-de-prueba-priorizados-en-lineas-de-productos-software/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/cmsa-para-el-problema-de-la-generacion-de-casos-de-prueba-priorizados-en-lineas-de-productos-software/</guid>
		<description></description>
		<content><![CDATA[En las líneas de producto software puede ser difícil o incluso imposible probar todos los productos de la familia debido al gran número de combinaciones de características que pueden existir. Esto conlleva la necesidad de buscar un subconjunto de productos de la familia que nos permita probar todas las posibles combinaciones. Los algoritmos del estado del arte basados en heurísticos junto con programación lineal entera (ILP) son lo bastante rápidos para instancias de tamaño pequeño o mediano. Sin embargo, existen algunas instancias del mundo real que son demasiado grandes para obtener una respuesta en un tiempo razonable, debido al crecimiento exponencial del espacio de búsqueda. Por otro lado, estos heurísticos no siempre conducen a las mejores soluciones. En este trabajo proponemos un nuevo enfoque basado en un algoritmo metaheurístico híbrido llamado Construct, Merge, Solve & Adapt (CMSA). Comparamos este enfoque con un algoritmo del estado del arte basado en ILP y en algoritmos híbridos. El análisis muestra que el algoritmo propuesto conduce a soluciones de mayor calidad.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3017</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[cmsa-para-el-problema-de-la-generacion-de-casos-de-prueba-priorizados-en-lineas-de-productos-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="aleatorizacion"><![CDATA[Aleatorización]]></category>
		<category domain="post_tag" nicename="hibridos-exactos-heuristicos"><![CDATA[Híbridos exactos/heurísticos]]></category>
		<category domain="post_tag" nicename="lineas-de-productos-software"><![CDATA[Líneas de Productos Software]]></category>
		<category domain="post_tag" nicename="modelos-de-caracteristicas"><![CDATA[modelos de características]]></category>
		<category domain="post_tag" nicename="optimizacion-combinatoria"><![CDATA[Optimización Combinatoria]]></category>
		<category domain="post_tag" nicename="testeo-por-pares"><![CDATA[Testeo por pares]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En las líneas de producto software puede ser difícil o incluso imposible probar todos los productos de la familia debido al gran número de combinaciones de características que pueden existir. Esto conlleva la necesidad de buscar un subconjunto de productos de la familia que nos permita probar todas las posibles combinaciones. Los algoritmos del estado del arte basados en heurísticos junto con programación lineal entera (ILP) son lo bastante rápidos para instancias de tamaño pequeño o mediano. Sin embargo, existen algunas instancias del mundo real que son demasiado grandes para obtener una respuesta en un tiempo razonable, debido al crecimiento exponencial del espacio de búsqueda. Por otro lado, estos heurísticos no siempre conducen a las mejores soluciones. En este trabajo proponemos un nuevo enfoque basado en un algoritmo metaheurístico híbrido llamado Construct, Merge, Solve & Adapt (CMSA). Comparamos este enfoque con un algoritmo del estado del arte basado en ILP y en algoritmos híbridos. El análisis muestra que el algoritmo propuesto conduce a soluciones de mayor calidad.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-094.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-094.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Antonio Ortega-Toro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[joseaortegatoro@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[CERN - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Ferrer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ferrer@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco Chicano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[chicano@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/091]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>GREEN-BANNER: Una propuesta para mejorar la responsabilidad energética de los usuarios en las organizaciones</title>
		<link>https://biblioteca.sistedes.es/articulo/green-banner-una-propuesta-para-mejorar-la-responsabilidad-energetica-de-los-usuarios-en-las-organizaciones/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/green-banner-una-propuesta-para-mejorar-la-responsabilidad-energetica-de-los-usuarios-en-las-organizaciones/</guid>
		<description></description>
		<content><![CDATA[La sostenibilidad en su sentido más amplio y desde el punto de vista de la ecología comprende todo aquello que se puede mantener durante largo tiempo sin agotarlo o causar un daño grave al medio ambiente. Desde su descubrimiento en la revolución industrial hasta la actualidad no se ha prestado una atención especial a las consecuencias que supone para el medio ambiente la producción y uso de la energía eléctrica. Es en la actualidad, con la indiscutible supremacía de demanda de este recurso, cuando se destaca que el gasto de cantidades ingentes de energía supone un daño para el planeta. Con el firme propósito de que los usuarios de los ordenadores de las Aulas de Libre Acceso (ALAs) de la Universidad de Murcia (UMU) sean conscientes de la importancia que tiene para el medio ambiente el buen uso de este recurso, pretendemos realizar un experimento de concienciación para estudiar si mediante mensajes mostrados en la pantalla o con pegatinas adheridas a la carcasa del ordenador es posible modificar los hábitos de uso de estos dispositivos. Trataremos de conseguir que los usuarios suspendan los equipos cuando terminen de utilizarlos en lugar de solamente cerrar la sesión, evitando que se queden encendidos desperdiciando energía. En este trabajo proponemos el diseño y la infraestructura para llevar a cabo el experimento propuesto y detallaremos el estudio estadístico a seguir con los datos que recabemos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3019</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[green-banner-una-propuesta-para-mejorar-la-responsabilidad-energetica-de-los-usuarios-en-las-organizaciones]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="aulas-informaticas"><![CDATA[Aulas Informáticas]]></category>
		<category domain="post_tag" nicename="concienciacion-energetica"><![CDATA[Concienciación Energética]]></category>
		<category domain="post_tag" nicename="experimento"><![CDATA[Experimento]]></category>
		<category domain="post_tag" nicename="sostenibilidad"><![CDATA[Sostenibilidad]]></category>
		<category domain="post_tag" nicename="universidad"><![CDATA[Universidad]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La sostenibilidad en su sentido más amplio y desde el punto de vista de la ecología comprende todo aquello que se puede mantener durante largo tiempo sin agotarlo o causar un daño grave al medio ambiente. Desde su descubrimiento en la revolución industrial hasta la actualidad no se ha prestado una atención especial a las consecuencias que supone para el medio ambiente la producción y uso de la energía eléctrica. Es en la actualidad, con la indiscutible supremacía de demanda de este recurso, cuando se destaca que el gasto de cantidades ingentes de energía supone un daño para el planeta. Con el firme propósito de que los usuarios de los ordenadores de las Aulas de Libre Acceso (ALAs) de la Universidad de Murcia (UMU) sean conscientes de la importancia que tiene para el medio ambiente el buen uso de este recurso, pretendemos realizar un experimento de concienciación para estudiar si mediante mensajes mostrados en la pantalla o con pegatinas adheridas a la carcasa del ordenador es posible modificar los hábitos de uso de estos dispositivos. Trataremos de conseguir que los usuarios suspendan los equipos cuando terminen de utilizarlos en lugar de solamente cerrar la sesión, evitando que se queden encendidos desperdiciando energía. En este trabajo proponemos el diseño y la infraestructura para llevar a cabo el experimento propuesto y detallaremos el estudio estadístico a seguir con los datos que recabemos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-096.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-096.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José A. García-Berná]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[josealberto.garcia1@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan M. Carrillo de Gea]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jmcdg1@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José L. Fernández Alemán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aleman@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Joaquín Nicolás]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jnr@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Begoña Moros]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[bmoros@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Ambrosio Toval]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[atoval@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[José María Abellán Perpiñán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[dionisos@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_8]]></meta_key>
			<meta_value><![CDATA[Francisco Maeso Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_8]]></meta_key>
			<meta_value><![CDATA[fmaeso@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_8]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/093]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Diseño de operadores de mutación para características de sensibilidad al contexto en aplicaciones móviles</title>
		<link>https://biblioteca.sistedes.es/articulo/diseno-de-operadores-de-mutacion-para-caracteristicas-de-sensibilidad-al-contexto-en-aplicaciones-moviles/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/diseno-de-operadores-de-mutacion-para-caracteristicas-de-sensibilidad-al-contexto-en-aplicaciones-moviles/</guid>
		<description></description>
		<content><![CDATA[Este artículo presenta el diseño arquitectónico de un conjunto de operadores de mutación. Este diseño mejora el tiempo y coste de implementación de nuevos operadores respecto de la experiencia previa de los autores en el desarrollo de otras herramientas de mutación. El diseño, además, se está utilizando para la creación de operadores específicamente diseñados para reproducir artificialmente errores sobre las características de sensibilidad al contexto de aplicaciones móviles.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3020</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[diseno-de-operadores-de-mutacion-para-caracteristicas-de-sensibilidad-al-contexto-en-aplicaciones-moviles]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="operadores-de-mutacion"><![CDATA[operadores de mutación]]></category>
		<category domain="post_tag" nicename="tecnologia-movil"><![CDATA[Tecnología móvil]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo presenta el diseño arquitectónico de un conjunto de operadores de mutación. Este diseño mejora el tiempo y coste de implementación de nuevos operadores respecto de la experiencia previa de los autores en el desarrollo de otras herramientas de mutación. El diseño, además, se está utilizando para la creación de operadores específicamente diseñados para reproducir artificialmente errores sobre las características de sensibilidad al contexto de aplicaciones móviles.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-098.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-098.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Macario Polo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[macario.polo@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Isyed De La Caridad Rodriguez Trujillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[isyedcrt@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Concepcion - Chile]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/094]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Empirical Evaluation of the Effects of Experience on Code Quality and Programmer Productivity: An Exploratory Study (Artículo Relevante)</title>
		<link>https://biblioteca.sistedes.es/articulo/empirical-evaluation-of-the-effects-of-experience-on-code-quality-and-programmer-productivity-an-exploratory-study-articulo-relevante/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:55 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/empirical-evaluation-of-the-effects-of-experience-on-code-quality-and-programmer-productivity-an-exploratory-study-articulo-relevante/</guid>
		<description></description>
		<content><![CDATA[Context. There is a widespread belief in both SE and other branches of science that experience helps professionals to improve their performance. However, cases have been reported where experience not only does not have a positive influence but sometimes even degrades the performance of professionals. Aim. Determinewhether years of experience influence programmer performance. Method. We have analysed 10 quasi-experiments executed both in academia with graduate and postgraduate students and in industry with professionals. The experimental task was to apply ITLD on two experimental problems and then measure external code quality and programmer productivity. Results. Programming experience gained in industry does not appear to have any effect whatsoever on quality and productivity. Overall programming experience gained in academia does tend to have a positive influence on programmer performance. These two findings may be related to the fact that, as opposed to deliberate practice, routine practice does not appear to lead to improved performance. Experience in the use of productivity tools, such as testing frameworks and IDE also has positive effects. Conclusion. Years of experience are a poor predictor of programmer performance. Academic background and specialized knowledge of task-relatedaspects appear to be rather good predictors.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3022</post_id>
		<post_date><![CDATA[2018-07-26 06:17:55]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:55]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[empirical-evaluation-of-the-effects-of-experience-on-code-quality-and-programmer-productivity-an-exploratory-study-articulo-relevante]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="academy"><![CDATA[academy]]></category>
		<category domain="post_tag" nicename="experience"><![CDATA[experience]]></category>
		<category domain="post_tag" nicename="external-quality"><![CDATA[external quality]]></category>
		<category domain="post_tag" nicename="industry"><![CDATA[industry]]></category>
		<category domain="post_tag" nicename="iterative-test-last-development"><![CDATA[iterative test-last development]]></category>
		<category domain="post_tag" nicename="performance"><![CDATA[Performance]]></category>
		<category domain="post_tag" nicename="productivity"><![CDATA[productivity]]></category>
		<category domain="post_tag" nicename="programming"><![CDATA[programming]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Context. There is a widespread belief in both SE and other branches of science that experience helps professionals to improve their performance. However, cases have been reported where experience not only does not have a positive influence but sometimes even degrades the performance of professionals. Aim. Determine
whether years of experience influence programmer performance. Method. We have analysed 10 quasi-experiments executed both in academia with graduate and postgraduate students and in industry with professionals. The experimental task was to apply ITLD on two experimental problems and then measure external code quality and programmer productivity. Results. Programming experience gained in industry does not appear to have any effect whatsoever on quality and productivity. Overall programming experience gained in academia does tend to have a positive influence on programmer performance. These two findings may be related to the fact that, as opposed to deliberate practice, routine practice does not appear to lead to improved performance. Experience in the use of productivity tools, such as testing frameworks and IDE also has positive effects. Conclusion. Years of experience are a poor predictor of programmer performance. Academic background and specialized knowledge of task-related
aspects appear to be rather good predictors.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-100.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-100.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Oscar Dieste]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[odieste@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/096]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una aproximación Web para la gestión dinámica de segmentos poblacionales</title>
		<link>https://biblioteca.sistedes.es/articulo/una-aproximacion-web-para-la-gestion-dinamica-de-segmentos-poblacionales/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:55 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/una-aproximacion-web-para-la-gestion-dinamica-de-segmentos-poblacionales/</guid>
		<description></description>
		<content><![CDATA[En los últimos años, el concepto de Smart City ha estado en los planes estratégicos y agendas digitales de muchas administraciones públicas tanto de ámbito local como regional o nacional. Así, se ha hecho un importante esfuerzo por sensorizar ciudades, generando un gran volumen de datos de las mismas. Sin embargo, actualmente sólo el 5% de los datos generados llega a ser procesado, obteniendo un beneficio muy inferior al potencial que estos datos ofrecen. En este trabajo se presenta un prototipo basado en la utilización de Flujos Dinámicos de Actividad Geo-Temporal que pretende dar soporte al consumo de estos datos mediante el uso de un recurso ampliamente utilizado para representar las ciudades a lo largo de la historia, sus mapas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3023</post_id>
		<post_date><![CDATA[2018-07-26 06:17:55]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:55]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-aproximacion-web-para-la-gestion-dinamica-de-segmentos-poblacionales]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="actividad-geo-temporal"><![CDATA[Actividad Geo-Temporal]]></category>
		<category domain="post_tag" nicename="flujos-de-datos-inteligentes"><![CDATA[Flujos de Datos Inteligentes]]></category>
		<category domain="post_tag" nicename="smart-cities"><![CDATA[Smart Cities]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años, el concepto de Smart City ha estado en los planes estratégicos y agendas digitales de muchas administraciones públicas tanto de ámbito local como regional o nacional. Así, se ha hecho un importante esfuerzo por sensorizar ciudades, generando un gran volumen de datos de las mismas. Sin embargo, actualmente sólo el 5% de los datos generados llega a ser procesado, obteniendo un beneficio muy inferior al potencial que estos datos ofrecen. En este trabajo se presenta un prototipo basado en la utilización de Flujos Dinámicos de Actividad Geo-Temporal que pretende dar soporte al consumo de estos datos mediante el uso de un recurso ampliamente utilizado para representar las ciudades a lo largo de la historia, sus mapas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-101.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-101.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Álvaro E. Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aeprieto@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José María Conejero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[chemacm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Carlos Preciado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jcpreciado@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/097]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Linking Data and BPMN Processes to Achieve Executable Models (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/linking-data-and-bpmn-processes-to-achieve-executable-models-summary/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/linking-data-and-bpmn-processes-to-achieve-executable-models-summary/</guid>
		<description></description>
		<content><![CDATA[Summary of the Contribution The two main assets of any organization are (i) information, i.e., data, which are the things that the organization knows about, and (ii) processes, which are collections of activities that describe how work is performed within an organiza- tion. Recent research has highlighted the importance of considering both process and data as key elements in process and service design. However, models that represent processes and data are typically developed by different teams, resulting in unrelated models which neglect the interaction between the two.
Bearing this in mind, in this paper we propose to connect processes and data, and a way to automatically execute the resulting model. To do so, we assume that processes are represented using BPMN and data in a UML class diagram.
In order to link both formalisms, we propose the following: (1) the creation of an Artifact, which represents a set of process variables associated to a certain process instance, and (2) the specification of the activities or tasks in the process, showing how they make changes to the data. We propose representing the artifact as an additional class in the UML class diagram. On the other hand, we opt for OCL operation contracts (with a pre and a postcondition) to specify details of the process activities. Note that other languages could be used to represent the data, the process and the contracts, as long as they have unambiguous semantics and whose expressiveness is equivalent to first-order logic.
Following this framework, we can then achieve executability of the frame- work, by relying on SQL technology. The UML class diagram is encoded as a relational database, the BPMN diagram can be formalized as a Petri net, and the OCL contracts can be encoded as logic rules from which SQL statements can be derived and applied to the database.
To prove the feasiblity of our approach, we have developed a prototype tool in Java which can load the models in our framework and execute the operations at runtime in a relational database.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3116</post_id>
		<post_date><![CDATA[2018-08-02 18:53:01]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[linking-data-and-bpmn-processes-to-achieve-executable-models-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Summary of the Contribution The two main assets of any organization are (i) information, i.e., data, which are the things that the organization knows about, and (ii) processes, which are collections of activities that describe how work is performed within an organiza- tion. Recent research has highlighted the importance of considering both process and data as key elements in process and service design. However, models that represent processes and data are typically developed by different teams, resulting in unrelated models which neglect the interaction between the two.
Bearing this in mind, in this paper we propose to connect processes and data, and a way to automatically execute the resulting model. To do so, we assume that processes are represented using BPMN and data in a UML class diagram.
In order to link both formalisms, we propose the following: (1) the creation of an Artifact, which represents a set of process variables associated to a certain process instance, and (2) the specification of the activities or tasks in the process, showing how they make changes to the data. We propose representing the artifact as an additional class in the UML class diagram. On the other hand, we opt for OCL operation contracts (with a pre and a postcondition) to specify details of the process activities. Note that other languages could be used to represent the data, the process and the contracts, as long as they have unambiguous semantics and whose expressiveness is equivalent to first-order logic.
Following this framework, we can then achieve executability of the frame- work, by relying on SQL technology. The UML class diagram is encoded as a relational database, the BPMN diagram can be formalized as a Petri net, and the OCL contracts can be encoded as logic rules from which SQL statements can be derived and applied to the database.
To prove the feasiblity of our approach, we have developed a prototype tool in Java which can load the models in our framework and execute the operations at runtime in a relational database.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-001.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-001.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Giuseppe De Giacomo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[degiacomo@dis.uniroma1.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Sapienza Università di Roma, Rome, Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Xavier Oriol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[oriol@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya, Barcelona, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Montserrat Estañol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[estanyol@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya, Barcelona, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/001]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>VISUAL PPINOT: A Graphical Notation for Process Performance Indicators (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/visual-ppinot-a-graphical-notation-for-process-performance-indicators-summary/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/visual-ppinot-a-graphical-notation-for-process-performance-indicators-summary/</guid>
		<description></description>
		<content><![CDATA[Summary of the contribution

Process performance indicators (PPIs) allow the quantitative evaluation of business processes (BPs), providing essential information for decision making. However, PPI management is not only restricted to the evaluation phase of the BPM lifecycle, but also includes a number of steps that must be carried out throughout the whole lifecycle. PPIs need to be defined, the corresponding BPs must be instrumented, PPI values have to be computed, then they can be monitored and analysed using techniques such as business activity monitoring or process mining, and finally, a PPI redefinition can be required in case of the evolution of either the associated BPs or the PPIs themselves. It is common practice today that BPs and PPIs are usually modelled separately using graphical notations for the former and natural language for the latter. This approach makes PPI definitions simple to read and write, but it hinders maintenance consistency between BPs and PPIs. It also requires their manual translation into lower–level implementation languages for their operationalisation, which is a time–consuming, error– prone task because of the ambiguities inherent to natural language definitions. In this article we present Visual ppinot, a graphical notation for defining PPIs together with BP models aimed at facilitating and automating PPI management. This is mainly achieved by means of the following features. First, Visual ppinot is based on the ppinot metamodel, which provides a precise and unambiguous definition of PPIs, thus allowing their automated processing in the different ac- tivities of the lifecycle. Second, Visual ppinot provides traceability by design between PPIs and BPs because PPIs must be explicitly connected to BP elements, thus avoiding inconsistencies and promoting their co–evolution. Finally, Visual ppinot enables a definition of PPIs that is independent of the platforms used to support the PPIs in the BP lifecycle, which reduces vendor lock–in and allows definitions of PPIs encompassing several information systems. In addition, it improves current state–of–the–art proposals in terms of expressiveness and of providing an explicit visualisation of the link between PPIs and BPs. The reference implementation, developed as a complete tool suite, has allowed its validation in a multiple-case study, in which five dimensions were studied: expressiveness, precision, automation, understandability, and traceability.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3117</post_id>
		<post_date><![CDATA[2018-08-02 18:53:01]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[visual-ppinot-a-graphical-notation-for-process-performance-indicators-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Summary of the contribution

Process performance indicators (PPIs) allow the quantitative evaluation of busi- ness processes (BPs), providing essential information for decision making. How- ever, PPI management is not only restricted to the evaluation phase of the BPM lifecycle, but also includes a number of steps that must be carried out through- out the whole lifecycle. PPIs need to be defined, the corresponding BPs must be instrumented, PPI values have to be computed, then they can be monitored and analysed using techniques such as business activity monitoring or process mining, and finally, a PPI redefinition can be required in case of the evolution of either the associated BPs or the PPIs themselves. It is common practice today that BPs and PPIs are usually modelled separately using graphical notations for the former and natural language for the latter. This approach makes PPI definitions simple to read and write, but it hinders maintenance consistency between BPs and PPIs. It also requires their manual translation into lower–level implemen- tation languages for their operationalisation, which is a time–consuming, error– prone task because of the ambiguities inherent to natural language definitions. In this article we present Visual ppinot, a graphical notation for defining PPIs together with BP models aimed at facilitating and automating PPI management. This is mainly achieved by means of the following features. First, Visual ppinot is based on the ppinot metamodel, which provides a precise and unambiguous definition of PPIs, thus allowing their automated processing in the di?erent ac- tivities of the lifecycle. Second, Visual ppinot provides traceability by design between PPIs and BPs because PPIs must be explicitly connected to BP ele- ments, thus avoiding inconsistencies and promoting their co–evolution. Finally, Visual ppinot enables a definition of PPIs that is independent of the platforms used to support the PPIs in the BP lifecycle, which reduces vendor lock–in and allows definitions of PPIs encompassing several information systems. In addi- tion, it improves current state–of–the–art proposals in terms of expressiveness and of providing an explicit visualisation of the link between PPIs and BPs. The reference implementation, developed as a complete tool suite, has allowed its validation in a multiple-case study, in which five dimensions were studied: expressiveness, precision, automation, understandability, and traceability.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-002.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-002.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Adela del-R??o-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[adeladelrio@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Amador Durán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[amador@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Beatriz Bernárdez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[beat@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Miguel Toro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[migueltoro@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/002]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Run-time prediction of business process indicators using evolutionary decision rules (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/run-time-prediction-of-business-process-indicators-using-evolutionary-decision-rules-summary/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/run-time-prediction-of-business-process-indicators-using-evolutionary-decision-rules-summary/</guid>
		<description></description>
		<content><![CDATA[Summary of the contribution

Predictive monitoring of business processes is a challenging topic of process min- ing which is concerned with the prediction of process indicators of running pro- cess instances. The main value of predictive monitoring is to provide information in order to take proactive and corrective actions to improve process performance and mitigate risks in real time. In this paper, we present an approach for pre- dictive monitoring based on the use of evolutionary algorithms. Our method provides a novel event window-based encoding and generates a set of decision rules for the run-time prediction of process indicators according to event log properties. These rules can be interpreted by users to extract further insight of the business processes while keeping a high level of accuracy. Furthermore, a full software stack consisting of a tool to support the training phase and a framework that enables the integration of run-time predictions with business process man- agement systems, has been developed. Obtained results show the validity of our proposal for two large real-life datasets: BPI Challenge 2013 and IT Department of Andalusian Health Service (SAS).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3118</post_id>
		<post_date><![CDATA[2018-08-02 18:53:01]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[run-time-prediction-of-business-process-indicators-using-evolutionary-decision-rules-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="business-process-indicator"><![CDATA[Business process indicator]]></category>
		<category domain="post_tag" nicename="business-process-management"><![CDATA[Business Process Management]]></category>
		<category domain="post_tag" nicename="evolutionary-algorithm"><![CDATA[Evolutionary algorithm]]></category>
		<category domain="post_tag" nicename="predictive-mon-itoring"><![CDATA[Predictive mon- itoring]]></category>
		<category domain="post_tag" nicename="process-mining"><![CDATA[Process Mining]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Summary of the contribution

Predictive monitoring of business processes is a challenging topic of process min- ing which is concerned with the prediction of process indicators of running pro- cess instances. The main value of predictive monitoring is to provide information in order to take proactive and corrective actions to improve process performance and mitigate risks in real time. In this paper, we present an approach for pre- dictive monitoring based on the use of evolutionary algorithms. Our method provides a novel event window-based encoding and generates a set of decision rules for the run-time prediction of process indicators according to event log properties. These rules can be interpreted by users to extract further insight of the business processes while keeping a high level of accuracy. Furthermore, a full software stack consisting of a tool to support the training phase and a framework that enables the integration of run-time predictions with business process man- agement systems, has been developed. Obtained results show the validity of our proposal for two large real-life datasets: BPI Challenge 2013 and IT Department of Andalusian Health Service (SAS).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-003.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-003.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alfonso E. Márquez-Chamorro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[amarquez6@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, University of Seville, Seville, Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/003]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>CARED-SOA: a Context-AwaRe Event-Driven Service Oriented Architecture (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/cared-soa-a-context-aware-event-driven-service-oriented-architecture-summary/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/cared-soa-a-context-aware-event-driven-service-oriented-architecture-summary/</guid>
		<description></description>
		<content><![CDATA[Summary of the Contribution

Context awareness takes part of citizens’ day-to-day life. However, there is a limited amount of context-aware services that users can benefit from; there are still many of- fered services which are not context-aware. This need for being aware of what happens at every instant, requires a software infrastructure, not only for receiving the context information but also to make use of it to provide advantageous customized services. In parallel, the impressive evolution of the Internet of Things (IoT) over the last years has strongly favored the provision of a large amount of data that software applications can easily consume. Such data requires constant streaming processing for business decision-making. Technologies, such as Complex Event Processing (CEP), rise in order to provide such constant data processing in streaming. Additionally, currently the strategy for software development for citizens and other agents is mainly based on services, since Service Oriented Architectures (SOAs) are platform-independent and loosely coupled. Also, Representational State Transfer (REST) services have become very successful since they are light services which can be easily consumed by third-parties. Due to all these facts, in this paper we provided CARED-SOA to face this challenge. CARED-SOA is an Event-Driven SOA (ED-SOA) supported by an Enterprise Service Bus (ESB) which (1) facilitates the incorporation of data coming from devices con- nected to the IoT through several connectors and (2) facilitates communications among all involved agents. Besides, the architecture (3) provides real-time stream data processing through the integration of CEP technology and (4) offers REST services to the users, which will be context-aware. Besides, the paper also provides the implementation of a real-world case study, which permits the evaluation of the architecture.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3119</post_id>
		<post_date><![CDATA[2018-08-02 18:53:01]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[cared-soa-a-context-aware-event-driven-service-oriented-architecture-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Summary of the Contribution

Context awareness takes part of citizens’ day-to-day life. However, there is a limited amount of context-aware services that users can benefit from; there are still many of- fered services which are not context-aware. This need for being aware of what happens at every instant, requires a software infrastructure, not only for receiving the context information but also to make use of it to provide advantageous customized services. In parallel, the impressive evolution of the Internet of Things (IoT) over the last years has strongly favored the provision of a large amount of data that software applications can easily consume. Such data requires constant streaming processing for business deci- sion-making. Technologies, such as Complex Event Processing (CEP), rise in order to provide such constant data processing in streaming. Additionally, currently the strategy for software development for citizens and other agents is mainly based on services, since Service Oriented Architectures (SOAs) are platform-independent and loosely coupled. Also, Representational State Transfer (REST) services have become very suc- cessful since they are light services which can be easily consumed by third-parties. Due to all these facts, in this paper we provided CARED-SOA to face this challenge. CARED-SOA is an Event-Driven SOA (ED-SOA) supported by an Enterprise Service Bus (ESB) which (1) facilitates the incorporation of data coming from devices con- nected to the IoT through several connectors and (2) facilitates communications among all involved agents. Besides, the architecture (3) provides real-time stream data pro- cessing through the integration of CEP technology and (4) offers REST services to the users, which will be context-aware. Besides, the paper also provides the implementa- tion of a real-world case study, which permits the evaluation of the architecture.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-004.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-004.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alfonso García de Prado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alfonso.garciadeprado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/004]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Detección de concept drift en minería de procesos basado en agrupamiento de trazas</title>
		<link>https://biblioteca.sistedes.es/articulo/deteccion-de-concept-drift-en-mineria-de-procesos-basado-en-agrupamiento-de-trazas/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/deteccion-de-concept-drift-en-mineria-de-procesos-basado-en-agrupamiento-de-trazas/</guid>
		<description></description>
		<content><![CDATA[En este artículo se presenta un método para la detección y localización de concept drift en minería de procesos, que, a diferencia del resto de propuestas del estado del arte, combina técnicas de agrupamiento de trazas y descubrimiento de modelos para realizar una clasificación de las trazas de ejecución contra una serie de modelos que constituyen el ground truth de nuestro sistema. Esta aproximación permite detectar, localizar y caracterizar los cambios y evaluar la evolución sufrida por el proceso. El algoritmo ha sido validado con un registro de eventos sintético que presenta puntos de concept drift, demostrando que la aproximación tomada es válida a la hora de detectar cuándo tiene lugar un cambio en la estructura del modelo de proceso.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3120</post_id>
		<post_date><![CDATA[2018-08-02 18:53:01]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[deteccion-de-concept-drift-en-mineria-de-procesos-basado-en-agrupamiento-de-trazas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este artículo se presenta un método para la detección y localización de concept drift en minería de procesos, que, a diferencia del resto de propuestas del estado del arte, combina técnicas de agrupamien- to de trazas y descubrimiento de modelos para realizar una clasificación de las trazas de ejecución contra una serie de modelos que constituyen el ground truth de nuestro sistema. Esta aproximación permite detectar, localizar y caracterizar los cambios y evaluar la evolución sufrida por el proceso. El algoritmo ha sido validado con un registro de eventos sintético que presenta puntos de concept drift, demostrando que la aproximación tomada es válida a la hora de detectar cuándo tiene lugar un cambio en la estructura del modelo de proceso.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-005.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-005.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Víctor José Gallego Fontenla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[victorjose.gallego@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Carlos Vidal Aguiar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juan.vidal@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Lama]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuel.lama@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/005]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Discovering Infrequent Behavioral Patterns in Process Models (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/discovering-infrequent-behavioral-patterns-in-process-models-summary/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/discovering-infrequent-behavioral-patterns-in-process-models-summary/</guid>
		<description></description>
		<content><![CDATA[In this paper we present WoMine-i, a novel algorithm to detect infrequent behavioural patterns from a process model, measuring their frequency with the instances of the log. A behavioural pattern is a subgraph of the process model, com- posed by all type of structures —sequences, selections, parallels and/or loops—, which represents the behaviour of a part of the process. And it is considered infrequent when its complete execution happens in a number of cases from the log below a predefined threshold. To find the infrequent patterns, WoMine-i performs an a priori search starting with the minimal structures of the model. In this search, there is an expansion stage done in two ways: i) adding other minimal structures not contained in the current pattern, and ii) adding arcs. This expansion is followed by a pruning strategy that verifies the upward-closure property of support —also known as monotonicity. This property ensures that if a pattern is infrequent, all patterns containing it will be infrequent and, thus, it is no necessary to continue expanding it —the minimum pattern itself expresses all the infrequent behaviour containing it. This pruning presents an exception in order to simplify the results: If a pattern is infrequent and maintains the value of its frequency with the expansion, it is not removed from the expansion stage —it means it is being expanded with a selection branch with less frequency. In this way, WoMine-i returns the largest patterns expressing the minimum infrequent behaviour. In each step of the iterative process, WoMine-i reduces the search space by pruning some of the generated patterns. For this, an algorithm to check the frequency of a pattern is needed. WoMine-i generates the different paths of a pattern, henceforth simple patterns, and checks the frequency of each one. To measure the frequency of a simple pattern, WoMine-i replays the traces of the log and checks how many of them are compliant with it. At each step of the replay, the algorithm checks if the simple pattern is being correctly executed. Afterwards, WoMine-i assigns to the pattern the higher of its simple patterns frequency, and checks if the pattern is considered frequent w.r.t. the threshold. Thereby, given a log and a corresponding model, WoMine-i is able to return the infrequent patterns of it. Allowing to study them and enhance the process consequently.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3121</post_id>
		<post_date><![CDATA[2018-08-02 18:53:01]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[discovering-infrequent-behavioral-patterns-in-process-models-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper we present WoMine-i, a novel algorithm to detect infrequent be- havioural patterns from a process model, measuring their frequency with the in- stances of the log. A behavioural pattern is a subgraph of the process model, com- posed by all type of structures —sequences, selections, parallels and/or loops—, which represents the behaviour of a part of the process. And it is considered infrequent when its complete execution happens in a number of cases from the log below a predefined threshold. To find the infrequent patterns, WoMine-i performs an a priori search starting with the minimal structures of the model. In this search, there is an expansion stage done in two ways: i) adding other minimal structures not contained in the current pattern, and ii) adding arcs. This expansion is followed by a pruning strategy that verifies the upward-closure property of support —also known as monotonicity. This property ensures that if a pattern is infrequent, all patterns containing it will be infrequent and, thus, it is no necessary to continue expanding it —the minimum pattern itself expresses all the infrequent behaviour containing it. This pruning presents an exception in order to simplify the results: If a pattern is infrequent and maintains the value of its frequency with the expansion, it is not removed from the expansion stage —it means it is being expanded with a selection branch with less frequency. In this way, WoMine-i returns the largest patterns expressing the minimum infrequent behaviour. In each step of the iterative process, WoMine-i reduces the search space by pruning some of the generated patterns. For this, an algorithm to check the frequency of a pattern is needed. WoMine-i generates the different paths of a pattern, henceforth simple patterns, and checks the frequency of each one. To measure the frequency of a simple pattern, WoMine-i replays the traces of the log and checks how many of them are compliant with it. At each step of the replay, the algorithm checks if the simple pattern is being correctly executed. Afterwards, WoMine-i assigns to the pattern the higher of its simple patterns frequency, and checks if the pattern is considered frequent w.r.t. the threshold. Thereby, given a log and a corresponding model, WoMine-i is able to return the infrequent patterns of it. Allowing to study them and enhance the process consequently.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-006.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-006.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Chapela-Campa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[david.chapela@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS) Universidade de Santiago de Compostela. Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Mucientes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[manuel.mucientes@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS) Universidade de Santiago de Compostela. Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Lama]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuel.lama@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS) Universidade de Santiago de Compostela. Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/006]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación de Datos Sintéticos para Arquitecturas de Procesamiento de Datos del Internet de las Cosas</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-de-datos-sinteticos-para-arquitecturas-de-procesamiento-de-datos-del-internet-de-las-cosas/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/generacion-de-datos-sinteticos-para-arquitecturas-de-procesamiento-de-datos-del-internet-de-las-cosas/</guid>
		<description></description>
		<content><![CDATA[La vertiginosa evolución del Internet de las Cosas, sumada a las grandes cantidades de datos heterogéneos que fluyen por los sistemas de información, han dado lugar a diversas plataformas software que analizan dichos datos con el objetivo de mejorar la toma de decisiones. Estas plataformas requieren de una prueba en materia de eficacia y eficiencia antes de su puesta en producción; para ello requieren de grandes cantidades de datos del dominio tecnológico y de aplicación en cuestión. Con este fin se implementa nITROGEN: un generador de datos sintéticos para el IoT que cubre las necesidades de estos sistemas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3122</post_id>
		<post_date><![CDATA[2018-08-02 18:53:01]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-de-datos-sinteticos-para-arquitecturas-de-procesamiento-de-datos-del-internet-de-las-cosas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="arquitecturas-orientadas-a-servicios"><![CDATA[arquitecturas orientadas a servicios]]></category>
		<category domain="post_tag" nicename="consciencia-del-contexto"><![CDATA[Consciencia del Contexto]]></category>
		<category domain="post_tag" nicename="generador-de-datos-sinteticos"><![CDATA[Generador de Datos Sintéticos]]></category>
		<category domain="post_tag" nicename="internet-de-las-cosas"><![CDATA[Internet de las Cosas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La vertiginosa evolución del Internet de las Cosas, sumada a las gran- des cantidades de datos heterogéneos que fluyen por los sistemas de información, han dado lugar a diversas plataformas software que analizan dichos datos con el objetivo de mejorar la toma de decisiones. Estas plataformas requieren de una prueba en materia de eficacia y eficiencia antes de su puesta en producción; para ello requieren de grandes cantidades de datos del dominio tecnológico y de apli- cación en cuestión. Con este fin se implementa nITROGEN: un generador de datos sintéticos para el IoT que cubre las necesidades de estos sistemas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-007.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-007.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alfonso García de Prado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alfonso.garciadeprado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software Escuela Superior de Ingeniería, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software Escuela Superior de Ingeniería, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanher@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo Quercus de Ingeniería del Software INTIA, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Enrique Moguel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[enrique@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo Quercus de Ingeniería del Software INTIA, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/007]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Analysis of users’ behavior in structured e-commerce websites (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/analysis-of-users-behavior-in-structured-e-commerce-websites-summary/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/analysis-of-users-behavior-in-structured-e-commerce-websites-summary/</guid>
		<description></description>
		<content><![CDATA[Los portales de comercio electrónico almacenan información sobre las páginas que visitan sus clientes y las acciones y servicios que estos usan durante la navegación. Esta información se puede enriquecer combinándola con los datos personales, geográficos, demográficos e historiales de compra de cada cliente particular. El análisis de todos estos datos permite ofrecer servicios más personalizados, mejorar la estructura y contenidos del portal, evaluar el impacto de las campañas publicitarias o fidelizar a nuevos clientes, entre otros usos. En este trabajo se propone el uso de técnicas de “model-checking” para el análisis del comportamiento que presentan los usuarios de un comercio electrónico. El procesado de los ficheros log del servidor permite extraer información sobre las sesiones de usuario. Una sesión se describe por medio de una secuencia de eventos (visitar un producto, visitar una categoría, añadir/eliminar un producto del carro, usar el buscador, comprar, etc.), donde cada evento consta de una colección de atributos que ofrece una visión detallada de lo sucedido. La técnica de análisis propuesta permite al experto en el negocio descubrir patrones de comportamiento habituales e inusuales de sus usuarios/clientes. Este descubrimiento se realiza por medio de una estrategia de inspección, es decir, a través de preguntas que son evaluadas contras las sesiones de usuario. Estas preguntas indagan sobre relaciones de causalidad de interés entre los eventos y son expresadas por medio de un nuevo tipo de lógica temporal lineal y evaluadas con un “model-checker”. En este artículo se presenta la metodología de análisis, la herramienta construida y un caso de aplicación real. Este caso corresponde con el análisis del portal de venta de la empresa Up&amp;Scrap, el principal distribuidor español online de productos de scrapbooking. Este trabajo de investigación está financiado por los proyectos TIN2014- 56633-C3-2-R y TIN2017-84796-C2-2-R del Ministerio de Economía, Industria y Competitividad del Gobierno de España.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3123</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analysis-of-users-behavior-in-structured-e-commerce-websites-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los portales de comercio electrónico almacenan información sobre las páginas que visitan sus clientes y las acciones y servicios que estos usan durante la navegación. Esta información se puede enriquecer combinándola con los datos personales, geográficos, demográficos e historiales de compra de cada cliente particular. El análisis de todos estos datos permite ofrecer servicios más personalizados, mejorar la estructura y contenidos del portal, evaluar el impacto de las campañas publicitarias o fidelizar a nuevos clientes, entre otros usos. En este trabajo se propone el uso de técnicas de “model-checking” para el análisis del comportamiento que presentan los usuarios de un comercio electrónico. El procesado de los ficheros log del servidor permite extraer información sobre las sesiones de usuario. Una sesión se describe por medio de una secuencia de eventos (visitar un producto, visitar una categor??a, añadir/eliminar un producto del carro, usar el buscador, comprar, etc.), donde cada evento consta de una colección de atributos que ofrece una visión detallada de lo sucedido. La técnica de análisis propuesta permite al experto en el negocio descubrir patrones de comportamiento habituales e inusuales de sus usuarios/clientes. Este descubrimiento se realiza por medio de una estrategia de inspección, es decir, a través de preguntas que son evaluadas contras las sesiones de usuario. Estas preguntas indagan sobre relaciones de causalidad de interés entre los eventos y son expresadas por medio de un nuevo tipo de lógica temporal lineal y evaluadas con un “model-checker”. En este art??culo 1 se presenta la metodolog??a de análisis, la herramienta construida y un caso de aplicación real. Este caso corresponde con el análisis del portal de venta de la empresa Up&Scrap, el principal distribuidor español online de productos de scrapbooking. Este trabajo de investigación está financiado por los proyectos TIN2014- 56633-C3-2-R y TIN2017-84796-C2-2-R del Ministerio de Econom??a, Industria y Competitividad del Gobierno de España.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-008.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-008.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[S. Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[shernandez@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Aragón Institute of Engineering Research (I3A) Department of Computer Science and Systems Engineering University of Zaragoza, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pedro Álvarez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[alvaper@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Aragón Institute of Engineering Research (I3A) Department of Computer Science and Systems Engineering University of Zaragoza, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[J. Fabra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jfabra@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Aragón Institute of Engineering Research (I3A) Department of Computer Science and Systems Engineering University of Zaragoza, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[J. Ezpeleta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[ezpeleta@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Aragón Institute of Engineering Research (I3A) Department of Computer Science and Systems Engineering University of Zaragoza, Spain  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/008]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Enhancing EUCalipTool Service Composition through Natural Language Processing</title>
		<link>https://biblioteca.sistedes.es/articulo/enhancing-eucaliptool-service-composition-through-natural-language-processing/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/enhancing-eucaliptool-service-composition-through-natural-language-processing/</guid>
		<description></description>
		<content><![CDATA[Although end-users have available a lot of on-line services to be con- sumed individually, it is their composed usage what has the potential to create new value-added services for end-users. In this sense, many efforts have been done to allow end-users to compose the services that they need by themselves. However, most of these solutions present two main problems: (1) they provide little support to help end-users to browse interminable lists of services, and (2) they present the blank piece of paper problem, which appears when end-users have to face an empty canvas to define a composition without any help to find the services that better fit their needs. In this paper, we present a solution to im- prove these problems by using natural language processing techniques in order to search and select the services end-users need to accomplish a specific goal. This solution has been implemented in the context of the EUCalipTool platform.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3124</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[enhancing-eucaliptool-service-composition-through-natural-language-processing]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mobile-authoring-tool"><![CDATA[Mobile authoring Tool]]></category>
		<category domain="post_tag" nicename="natural-language-processing"><![CDATA[Natural Language Processing]]></category>
		<category domain="post_tag" nicename="service-selection-and-composition"><![CDATA[Service Selection and Composition]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Although end-users have available a lot of on-line services to be con- sumed individually, it is their composed usage what has the potential to create new value-added services for end-users. In this sense, many efforts have been done to allow end-users to compose the services that they need by themselves. However, most of these solutions present two main problems: (1) they provide little support to help end-users to browse interminable lists of services, and (2) they present the blank piece of paper problem, which appears when end-users have to face an empty canvas to define a composition without any help to find the services that better fit their needs. In this paper, we present a solution to im- prove these problems by using natural language processing techniques in order to search and select the services end-users need to accomplish a specific goal. This solution has been implemented in the context of the EUCalipTool platform.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-009.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-009.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Valderas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pvalderas@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Victoria Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[vtorres@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pele@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/009]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Model-driven Migration Approach among Cloud Providers</title>
		<link>https://biblioteca.sistedes.es/articulo/a-model-driven-migration-approach-among-cloud-providers/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-model-driven-migration-approach-among-cloud-providers/</guid>
		<description></description>
		<content><![CDATA[Cloud computing has become the primary model of pay-per-use to ob- tain cloud services in a short time. Companies are using the cloud services to get access to computing resources located in a virtualized environment. However, the traditional method of using a single cloud provider has numerous limitation in terms of privacy, security, performance, and geography reach. Furthermore, companies are focusing their efforts on avoiding dependent on a single vendor for products and services. As a result, companies start to use multiple clouds and look for methods to move or migrate their infrastructure from a cloud provider to another one. In previous work, we have presented ARGON, which is an infra- structure modeling tool for cloud provisioning. In this paper, we propose an ex- tension of ARGON to provide a model-driven migration approach among cloud providers.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3125</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-model-driven-migration-approach-among-cloud-providers]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cloud-computing"><![CDATA[Cloud Computing]]></category>
		<category domain="post_tag" nicename="infrastructure-as-a-service"><![CDATA[Infrastructure as a Service]]></category>
		<category domain="post_tag" nicename="infrastructure-as-code"><![CDATA[Infrastructure as Code]]></category>
		<category domain="post_tag" nicename="infrastructure-migra-tion"><![CDATA[Infrastructure Migra- tion]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Cloud computing has become the primary model of pay-per-use to ob- tain cloud services in a short time. Companies are using the cloud services to get access to computing resources located in a virtualized environment. However, the traditional method of using a single cloud provider has numerous limitation in terms of privacy, security, performance, and geography reach. Furthermore, companies are focusing their efforts on avoiding dependent on a single vendor for products and services. As a result, companies start to use multiple clouds and look for methods to move or migrate their infrastructure from a cloud provider to another one. In previous work, we have presented ARGON, which is an infra- structure modeling tool for cloud provisioning. In this paper, we propose an ex- tension of ARGON to provide a model-driven migration approach among cloud providers.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-010.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-010.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julio Sandobalín]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[julio.sandobalin@epn.edu.ec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática y Ciencias de la Computación, Escuela Politécnica Nacional, Ecuador]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Emilio Insfran]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[einsfran@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Silvia Abrahao]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sabrahao@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/010]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Fostering SLA-Driven API Specifications</title>
		<link>https://biblioteca.sistedes.es/articulo/fostering-sla-driven-api-specifications/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/fostering-sla-driven-api-specifications/</guid>
		<description></description>
		<content><![CDATA[Software architecture tendencies are shifting to a microser- vice paradigm. In this context, RESTful APIs are being established the standard of integration. API designer often identifies two key issues to be competitive in such growing market. On the one hand, the generation of accurate documentation of the behavior and capabilities of the API to promote its usage; on the other hand, the design of a pricing plan that fits into the potential API user’s needs. Besides the increasing number of API modeling alternatives is emerging, there is a lack of proposals on the definition of flexible pricing plans usually contained in the Service Level Agreements (SLAs). In this paper we propose two different modeling techniques for the de- scription of SLA in a RESTful API context: iAgree and SLA4OAI.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3126</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[fostering-sla-driven-api-specifications]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Software architecture tendencies are shifting to a microser- vice paradigm. In this context, RESTful APIs are being established the standard of integration. API designer often identifies two key issues to be competitive in such growing market. On the one hand, the generation of accurate documentation of the behavior and capabilities of the API to promote its usage; on the other hand, the design of a pricing plan that fits into the potential API user’s needs. Besides the increasing number of API modeling alternatives is emerging, there is a lack of proposals on the definition of flexible pricing plans usually contained in the Service Level Agreements (SLAs). In this paper we propose two different modeling techniques for the de- scription of SLA in a RESTful API context: iAgree and SLA4OAI.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-011.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-011.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Gámez-Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[agamez2@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/011]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia una arquitectura para el procesamiento y análisis en tiempo real de datos heterogéneos en IoT</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-una-arquitectura-para-el-procesamiento-y-analisis-en-tiempo-real-de-datos-heterogeneos-en-iot/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/hacia-una-arquitectura-para-el-procesamiento-y-analisis-en-tiempo-real-de-datos-heterogeneos-en-iot/</guid>
		<description></description>
		<content><![CDATA[Uno de los grandes retos del Internet de las Cosas es la falta de un formato de datos común o una estructura homogénea que facilite el procesamiento y análisis de estos datos. Ser capaces de recibir información heterogénea de múltiples fuentes y, a continuación, poder procesarla para su análisis en tiempo real ofrece la posibilidad de reaccionar a situaciones críticas detectadas de forma inmediata. En este artículo se propone una arquitectura para inferir situaciones críticas en tiempo real que permita dar una respuesta adecuada lo más rápidamente posible.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3127</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-una-arquitectura-para-el-procesamiento-y-analisis-en-tiempo-real-de-datos-heterogeneos-en-iot]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="analisis-en-tiempo-real"><![CDATA[Análisis en Tiempo Real]]></category>
		<category domain="post_tag" nicename="internet-de-las-cosas"><![CDATA[Internet de las Cosas]]></category>
		<category domain="post_tag" nicename="procesamiento-de-eventos-complejos"><![CDATA[procesamiento de eventos complejos]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Uno de los grandes retos del Internet de las Cosas es la falta de un formato de datos común o una estructura homogénea que facilite el procesa- miento y análisis de estos datos. Ser capaces de recibir información heterogénea de múltiples fuentes y, a continuación, poder procesarla para su análisis en tiempo real ofrece la posibilidad de reaccionar a situaciones críticas detectadas de forma inmediata. En este artículo se propone una arquitectura para inferir situaciones críticas en tiempo real que permita dar una respuesta adecuada lo más rápida- mente posible.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-012.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-012.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Corral-Plaza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[david.corral@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Escuela Superior de Ingeniería Avda. de la Universidad de Cádiz 10, 11519 Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Escuela Superior de Ingeniería Avda. de la Universidad de Cádiz 10, 11519 Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Escuela Superior de Ingeniería Avda. de la Universidad de Cádiz 10, 11519 Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Escuela Superior de Ingeniería Avda. de la Universidad de Cádiz 10, 11519 Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/012]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un Recorrido por los Principales Proveedores de Servicios de Machine Learning y Predicción en la Nube</title>
		<link>https://biblioteca.sistedes.es/articulo/un-recorrido-por-los-principales-proveedores-de-servicios-de-machine-learning-y-prediccion-en-la-nube/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/un-recorrido-por-los-principales-proveedores-de-servicios-de-machine-learning-y-prediccion-en-la-nube/</guid>
		<description></description>
		<content><![CDATA[Los medios tecnológicos para el consumo, producción e intercambio de información no hacen más que aumentar cada día que pasa. Nos encontramos envueltos en el fenómeno Big Data, donde ser capaces de analizar esta informa- ción con el objetivo de poder inferir situaciones del futuro basándonos en datos del pasado y del presente, nos puede reportar una ventaja competitiva que nos distinga claramente de otras opciones. Dentro de las múltiples disciplinas exis- tentes para el análisis de grandes cantidades información encontramos el Ma- chine Learning y, a su vez, dentro de este podemos destacar la capacidad predic- tiva que nos proporcionan muchas de las opciones existentes actualmente en el mercado. En este trabajo realizamos un análisis de estas principales opciones de APIs predictivas en la nube, las comparamos entre sí, y finalmente llevamos a cabo una experimentación con datos reales de la Red de Vigilancia y Control de la Calidad del Aire de la Junta de Andalucía. Los resultados demuestran que estas herramientas son una opción muy interesante a considerar a la hora de tratar de predecir valores de contaminantes que pueden afectar a nuestra salud seriamente, pudiéndose llevar a cabo acciones preventivas sobre la población afectada.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3128</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-recorrido-por-los-principales-proveedores-de-servicios-de-machine-learning-y-prediccion-en-la-nube]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="api"><![CDATA[API]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="cloud"><![CDATA[Cloud]]></category>
		<category domain="post_tag" nicename="machine-learning"><![CDATA[Machine Learning]]></category>
		<category domain="post_tag" nicename="prediccion"><![CDATA[Predicción]]></category>
		<category domain="post_tag" nicename="software-as-a-service"><![CDATA[Software as a Service]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los medios tecnológicos para el consumo, producción e intercambio de información no hacen más que aumentar cada día que pasa. Nos encontramos envueltos en el fenómeno Big Data, donde ser capaces de analizar esta informa- ción con el objetivo de poder inferir situaciones del futuro basándonos en datos del pasado y del presente, nos puede reportar una ventaja competitiva que nos distinga claramente de otras opciones. Dentro de las múltiples disciplinas exis- tentes para el análisis de grandes cantidades información encontramos el Ma- chine Learning y, a su vez, dentro de este podemos destacar la capacidad predic- tiva que nos proporcionan muchas de las opciones existentes actualmente en el mercado. En este trabajo realizamos un análisis de estas principales opciones de APIs predictivas en la nube, las comparamos entre sí, y finalmente llevamos a cabo una experimentación con datos reales de la Red de Vigilancia y Control de la Calidad del Aire de la Junta de Andalucía. Los resultados demuestran que estas herramientas son una opción muy interesante a considerar a la hora de tratar de predecir valores de contaminantes que pueden afectar a nuestra salud seriamente, pudiéndose llevar a cabo acciones preventivas sobre la población afectada.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-013.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-013.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Corral-Plaza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[david.corral@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/013]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Template-based Approach for Responsibility Management in Executable Business Processes (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-template-based-approach-for-responsibility-management-in-executable-business-processes-summary/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-template-based-approach-for-responsibility-management-in-executable-business-processes-summary/</guid>
		<description></description>
		<content><![CDATA[Summary of the Contribution

Process-oriented organisations need to manage the different types of responsi- bilities their employees may have w.r.t. the activities involved in their business processes. Despite several approaches provide support for responsibility modelling, in current Business Process Management Systems (BPMS) the only responsibility considered at run time is the one related to performing the work required for activity completion. Others like accountability or consultation must be implemented by manually adding activities in the executable process model, which is time-consuming and error-prone. This paper addresses this limitation by enabling current BPMS to execute processes in which people with different responsibilities interact to complete the activities. A metamodel based on Responsibility Assignment Matrices (RAM) is designed to model the responsibility assignment for each activity, and a template- based mechanism that automatically transforms such information into BPMN elements is developed. The approach is independent of the platform and hence, the output models can be interpreted and executed by BPMS that support BPMN. Furthermore, the original structure of the process model remains unchanged, as the templates for modelling responsibilities are defined at subprocess level. This provides transparency and does not affect the readability of the original model. As our approach does not enforce any specific behaviour but new templates can be modelled to specify the interaction that best suits the activity requirements, there is high flexibility and generalisability. Moreover, template libraries can be created and reused in different processes. We provide a reference implementation and build a library of templates for a well-known set of responsibilities.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3129</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-template-based-approach-for-responsibility-management-in-executable-business-processes-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Summary of the Contribution

Process-oriented organisations need to manage the di?erent types of responsi- bilities their employees may have w.r.t. the activities involved in their business processes. Despite several approaches provide support for responsibility mod- elling, in current Business Process Management Systems (BPMS) the only re- sponsibility considered at run time is the one related to performing the work required for activity completion. Others like accountability or consultation must be implemented by manually adding activities in the executable process model, which is time-consuming and error-prone. This paper addresses this limitation by enabling current BPMS to execute processes in which people with di?erent responsibilities interact to complete the activities. A metamodel based on Responsibility Assignment Matrices (RAM) is designed to model the responsibility assignment for each activity, and a template- based mechanism that automatically transforms such information into BPMN el- ements is developed. The approach is independent of the platform and hence, the output models can be interpreted and executed by BPMS that support BPMN. Furthermore, the original structure of the process model remains unchanged, as the templates for modelling responsibilities are defined at subprocess level. This provides transparency and does not a?ect the readability of the original model. As our approach does not enforce any specific behaviour but new templates can be modelled to specify the interaction that best suits the activity requirements, there is high flexibility and generalisability. Moreover, template libraries can be created and reused in different processes. We provide a reference implementation and build a library of templates for a well-known set of responsibilities.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-014.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-014.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cristina Cabanillas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cristina.cabanillas@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Vienna University of Economics and Business, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/014]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automated analysis of cloud offerings for optimal service provisioning (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/automated-analysis-of-cloud-offerings-for-optimal-service-provisioning-summary/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/automated-analysis-of-cloud-offerings-for-optimal-service-provisioning-summary/</guid>
		<description></description>
		<content><![CDATA[Resumen de la contribución

La aparición del paradigma de la computación en la nube ha conllevado un cambio significativo dentro de la industria de las tecnologías de la información, tanto para proveedores de servicios como para los propios consumidores. Así, existen servicios como los de Amazon Elastic Computing Cloud (EC2) o Google Compute Engine que ofrecen computación virtualizada y almacenamiento de recursos (comúmente denominados Infraestructuras como Servicios o IaaS por sus siglas en inglés), de forma que los clientes pueden adquirirlos para reducir los costes de operación de sus sistemas, en comparación con el aprovisionamiento de las mismas infraestructuras de computación en un entorno local. Sin embargo, el aprovisionamiento de servicios en la nube resulta una tarea muy compleja dada la abrumadora variedad de proveedores, configuraciones y opciones de compra disponibles. En este escenario aparecen además diversas dificultades para comparar las ofertas de los distintos proveedores, debido a la heterogeneidad en la descripción de las configuraciones, opciones de compra, o incluso descuentos aplicables. A su vez, las necesidades concretas de los consumidores podrían incluir restricciones adicionales para tener en cuenta una planificación temporal previa en cuanto al número de instancias de IaaS que necesitarán en determinados momentos. Aunque existen algunas herramientas y calculadoras on-line que permiten buscar configuraciones concretas de IaaS, éstas no tienen en cuenta cuestiones como la planificación y la optimización de las opciones de compra. En este trabajo presentamos un framework de análisis automático que es capaz de analizar y comparar ofertas de servicios en la nube de distintos proveedores para obtener un plan de aprovisionamiento óptimo de acuerdo con las necesidades de los consumidores. Dicho plan especifica la cantidad y el tipo de instancias de IaaS que deben adquirirse, junto con la planificación de su uso. Hemos desarrollado un prototipo que ha sido validado en un escenario de virtualización de clases de laboratorio, comparando las opciones de dos proveedores.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3130</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automated-analysis-of-cloud-offerings-for-optimal-service-provisioning-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen de la contribución

La aparición del paradigma de la computación en la nube ha conllevado un cambio significativo dentro de la industria de las tecnolog??as de la información, tanto para proveedores de servicios como para los propios consumidores. As??, existen servicios como los de Amazon Elastic Computing Cloud (EC2) o Google Compute Engine que ofrecen computación virtualizada y almacenamiento de recursos (comúmente denomi- nados Infraestructuras como Servicios o IaaS por sus siglas en inglés), de forma que los clientes pueden adquirirlos para reducir los costes de operación de sus sistemas, en comparación con el aprovisionamiento de las mismas infraestructuras de computación en un entorno local. Sin embargo, el aprovisionamiento de servicios en la nube resulta una tarea muy compleja dada la abrumadora variedad de proveedores, configuraciones y opciones de compra disponibles. En este escenario aparecen además diversas dificultades para comparar las ofer- tas de los distintos proveedores, debido a la heterogeneidad en la descripción de las configuraciones, opciones de compra, o incluso descuentos aplicables. A su vez, las ne- cesidades concretas de los consumidores podr??an incluir restricciones adicionales para tener en cuenta una planificación temporal previa en cuanto al número de instancias de IaaS que necesitarán en determinados momentos. Aunque existen algunas herramientas y calculadoras on-line que permiten buscar configuraciones concretas de IaaS, éstas no tienen en cuenta cuestiones como la plani- ficación y la optimización de las opciones de compra. En este trabajo presentamos un framework de análisis automático que es capaz de analizar y comparar ofertas de ser- vicios en la nube de distintos proveedores para obtener un plan de aprovisionamiento óptimo de acuerdo con las necesidades de los consumidores. Dicho plan especifica la cantidad y el tipo de instancias de IaaS que deben adquirirse, junto con la planificación de su uso. Hemos desarrollado un prototipo que ha sido validado en un escenario de virtualización de clases de laboratorio, comparando las opciones de dos proveedores. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-015.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-015.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José María García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[josemgarcia@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Octavio Mart??n-D??az]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[omartindiaz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Miguel Toro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[migueltoro@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/015]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Entorno extensible para la monitorización y detección de síntomas de depresión</title>
		<link>https://biblioteca.sistedes.es/articulo/entorno-extensible-para-la-monitorizacion-y-deteccion-de-sintomas-de-depresion/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/entorno-extensible-para-la-monitorizacion-y-deteccion-de-sintomas-de-depresion/</guid>
		<description></description>
		<content><![CDATA[La depresión es una enfermedad silenciosa que está aumentando de forma alarmante debido al ritmo de vida de la sociedad. Los propios síntomas de la depresión hacen que los pacientes se enfrenten a barreras psicológicas que dificultan la búsqueda de tratamiento. Actualmente, los dispositivos móviles están siendo usados para monitorizar el comportamiento de las personas y, así, identificar si presentan distintas enfermedades. En este artículo se presenta un conjunto de aplicaciones que detectan síntomas de depresión de forma pasiva para el usuario, reduciendo los posibles obstáculos para la identificación de esta enfermedad. Estas aplicaciones han sido desarrolladas para que los datos monitorizados puedan ser reutilizados por otros sistemas, sin que ello conlleve un incremento en el consumo de recursos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3131</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[entorno-extensible-para-la-monitorizacion-y-deteccion-de-sintomas-de-depresion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="contexto"><![CDATA[Contexto]]></category>
		<category domain="post_tag" nicename="depresion"><![CDATA[Depresión]]></category>
		<category domain="post_tag" nicename="salud"><![CDATA[Salud]]></category>
		<category domain="post_tag" nicename="telefono-inteligente"><![CDATA[Teléfono Inteligente]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La depresión es una enfermedad silenciosa que está aumen- tando de forma alarmante debido al ritmo de vida de la sociedad. Los propios s??ntomas de la depresión hacen que los pacientes se enfrenten a barreras psicológicas que dificultan la búsqueda de tratamiento. Actual- mente, los dispositivos móviles están siendo usados para monitorizar el comportamiento de las personas y, así, identificar si presentan distintas enfermedades. En este art??culo se presenta un conjunto de aplicaciones que detectan síntomas de depresión de forma pasiva para el usuario, redu- ciendo los posibles obstáculos para la identificación de esta enfermedad. Estas aplicaciones han sido desarrolladas para que los datos monitoriza- dos puedan ser reutilizados por otros sistemas, sin que ello conlleve un incremento en el consumo de recursos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-016.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-016.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Garcia-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Daniel Flores-Martin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[dfloresm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jaime Galán-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jaime@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Alejandro Pérez-Vereda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[apvereda@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Juan M. Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/016]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un Framework de Programación Dinámica para IoT</title>
		<link>https://biblioteca.sistedes.es/articulo/un-framework-de-programacion-dinamica-para-iot/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/un-framework-de-programacion-dinamica-para-iot/</guid>
		<description></description>
		<content><![CDATA[El crecimiento del Internet of Things está permitiendo la conexión a la red de muchos dispositivos. La tecnología debería permitir a estos dispositivos adaptarse automáticamente a las necesidades de sus usuarios. Con este propósito, desarrollamos en trabajos anteriores la arquitectura de referencia People as a Service, para crear perfiles virtuales de los usuarios almacenados en sus smartphones. Sin embargo, para la obtención de un perfil completo necesitamos información de contexto, que solo pueden proporcionarnos estos dispositivos del entorno. Nuestro objetivo es desarrollar un framework en el que usuarios y dispositivos conectados se integren de manera transparente y dinámica, permitiendo una actualización programática de los perfiles y el comportamiento de los dispositivos. De esta forma, damos un primer paso hacia un Mundo Programable.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3132</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-framework-de-programacion-dinamica-para-iot]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="beacons"><![CDATA[Beacons]]></category>
		<category domain="post_tag" nicename="framework-de-programacion"><![CDATA[Framework de programación]]></category>
		<category domain="post_tag" nicename="internet-of-things"><![CDATA[Internet of Things]]></category>
		<category domain="post_tag" nicename="mundo-programable"><![CDATA[Mundo Programable]]></category>
		<category domain="post_tag" nicename="people-as-a-service"><![CDATA[People as a Service]]></category>
		<category domain="post_tag" nicename="perfiles-virtuales-de-usuarios"><![CDATA[Perfiles virtuales de usuarios]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El crecimiento del Internet of Things está permitiendo la conexión a la red de muchos dispositivos. La tecnología debería permitir a estos dispositivos adaptarse automáticamente a las necesidades de sus usuarios. Con este propósito, desarrollamos en trabajos anteriores la arquitectura de referencia People as a Ser- vice, para crear perfiles virtuales de los usuarios almacenados en sus smartpho- nes. Sin embargo, para la obtención de un perfil completo necesitamos informa- ción de contexto, que solo pueden proporcionarnos estos dispositivos del entorno. Nuestro objetivo es desarrollar un framework en el que usuarios y dispositivos conectados se integren de manera transparente y dinámica, permitiendo una ac- tualización programática de los perfiles y el comportamiento de los dispositivos. De esta forma, damos un primer paso hacia un Mundo Programable.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-018.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-018.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alejandro Pérez-Vereda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[apvereda@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Malaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Daniel Flores-Martin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[dfloresm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan M. Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/017]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un breve estudio sobre las metodologías para el proceso de “Service Design”</title>
		<link>https://biblioteca.sistedes.es/articulo/un-breve-estudio-sobre-las-metodologias-para-el-proceso-de-service-design/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/un-breve-estudio-sobre-las-metodologias-para-el-proceso-de-service-design/</guid>
		<description></description>
		<content><![CDATA[El sector servicios es en la actualidad uno de los más importantes en la economía mundial y el diseño de servicios es una actividad clave dentro de este sector. A pesar de ello, existen muy pocos estudios que profundicen en cómo deben llevarse a cabo esta actividad. Es por ello, que este trabajo pretende estudiar brevemente las diferentes aportaciones existentes en la literatura sobre cómo llevar a cabo el proceso de “Service Design”. Dicho estudio se ha realizado siguiendo el método de revisión sistemática de la literatura. Como resultado se han obtenido 14 estudios primarios. Una vez efectuado este estudio se ha podido percibir la importancia de dos componentes fundamentales, la co-creation y la experiencia del cliente, los cuales son indispensable en una metodología que permita diseñar servicios cada vez más adaptados al mercado actual.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3133</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-breve-estudio-sobre-las-metodologias-para-el-proceso-de-service-design]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="creacion-de-servicio"><![CDATA[Creación de servicio]]></category>
		<category domain="post_tag" nicename="diseno-de-servicios"><![CDATA[Diseño de servicios]]></category>
		<category domain="post_tag" nicename="herramienta"><![CDATA[Herramienta]]></category>
		<category domain="post_tag" nicename="innovacion-de-servicio"><![CDATA[Innovación de servicio]]></category>
		<category domain="post_tag" nicename="metodologia"><![CDATA[Metodología]]></category>
		<category domain="post_tag" nicename="modelo"><![CDATA[Modelo]]></category>
		<category domain="post_tag" nicename="servitizacion"><![CDATA[Servitización]]></category>
		<category domain="post_tag" nicename="tecnica"><![CDATA[Técnica]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El sector servicios es en la actualidad uno de los más importantes en la economía mundial y el diseño de servicios es una actividad clave dentro de este sector. A pesar de ello, existen muy pocos estudios que profundicen en cómo deben llevarse a cabo esta actividad. Es por ello, que este trabajo pretende estu- diar brevemente las diferentes aportaciones existentes en la literatura sobre cómo llevar a cabo el proceso de “Service Design”. Dicho estudio se ha realizado si- guiendo el método de revisión sistemática de la literatura. Como resultado se han obtenido 14 estudios primarios. Una vez efectuado este estudio se ha podido per- cibir la importancia de dos componentes fundamentales, la co-creation y la ex- periencia del cliente, los cuales son indispensable en una metodología que per- mita diseñar servicios cada vez más adaptados al mercado actual.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-019.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-019.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Maricela Salgado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[maricela.salgado@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Calle Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Calle Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan M. Vara, Marcos López]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Calle Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Marí­a Valeria De Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[valeria.decastro@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Calle Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/018]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards a new Tool for Managing Declarative Temporal Business Process Models</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-a-new-tool-for-managing-declarative-temporal-business-process-models/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-a-new-tool-for-managing-declarative-temporal-business-process-models/</guid>
		<description></description>
		<content><![CDATA[Business processes which require a high flexibility are com- monly specified in a declarative (e.g., constraint-based) way. In general, offering operational support (e.g., generating possible execution traces) to declarative business process models entails more complexity when compared to imperative modeling alternatives. Such support becomes even more complex in many real scenarios where the management of complex temporal relations between the process activities is crucial (i.e., the temporal perspective should be managed). Despite the needs for enabling process flexibility and dealing with temporal constraints, most existing tools are unable to manage both. In a previous work, we then proposed TConDec-R, which is a constraint-based process modeling lan- guage which allows for the specification of temporal constraints. In this paper we introduce the basis and a prototype of a constraint-based tool with a client/server architecture for providing operational support to TConDec-R process models.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3134</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-a-new-tool-for-managing-declarative-temporal-business-process-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="business-process-modeling-support"><![CDATA[business process modeling support]]></category>
		<category domain="post_tag" nicename="constraint-programming"><![CDATA[Constraint programming]]></category>
		<category domain="post_tag" nicename="constraint-satisfaction-problems"><![CDATA[constraint satisfaction problems]]></category>
		<category domain="post_tag" nicename="process-flexibility"><![CDATA[process flexibility]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Business processes which require a high flexibility are com- monly specified in a declarative (e.g., constraint-based) way. In general, offering operational support (e.g., generating possible execution traces) to declarative business process models entails more complexity when compared to imperative modeling alternatives. Such support becomes even more complex in many real scenarios where the management of complex temporal relations between the process activities is crucial (i.e., the temporal perspective should be managed). Despite the needs for en- abling process flexibility and dealing with temporal constraints, most existing tools are unable to manage both. In a previous work, we then proposed TConDec-R, which is a constraint-based process modeling lan- guage which allows for the specification of temporal constraints. In this paper we introduce the basis and a prototype of a constraint-based tool with a client/server architecture for providing operational support to TConDec-R process models.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-020.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-020.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Andrés Jiménez-Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ajramirez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Irene Barba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[irenebr@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Carmelo del Valle]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[carmelo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/019]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Análisis de los datos y coreografia de múltiples procesos en entornos logísticos</title>
		<link>https://biblioteca.sistedes.es/articulo/analisis-de-los-datos-y-coreografia-de-multiples-procesos-en-entornos-logisticos/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/analisis-de-los-datos-y-coreografia-de-multiples-procesos-en-entornos-logisticos/</guid>
		<description></description>
		<content><![CDATA[Los procesos de negocio permiten la descripción de modelos colaborativos donde varios procesos y sus instancias se puedan coreografiar. Un ejemplo de la dificultad que implican dichos procesos se encuentra en los entornos logísticos, donde instancias de diferentes procesos y con diferentes cardinalidades deben de trabajar para alcanzar un objetivo común. En este trabajo se identifican el conjunto de retos a resolver para facilitar la incorporación de la ingeniería de los procesos de negocio a entornos logísticos. En el artículo se analizan además los trabajos previos, y se esboza una solución basada en el análisis de los artefactos de datos involucrados y la capacidad del modelado orientado a actividades de los procesos de negocios.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3135</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analisis-de-los-datos-y-coreografia-de-multiples-procesos-en-entornos-logisticos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="artefactos"><![CDATA[Artefactos]]></category>
		<category domain="post_tag" nicename="coreografia-de-procesos-de-negocio"><![CDATA[Coreografia de Procesos de Negocio]]></category>
		<category domain="post_tag" nicename="procesos-de-logstica"><![CDATA[Procesos de Log??stica]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los procesos de negocio permiten la descripción de mode- los colaborativos donde varios procesos y sus instancias se puedan core- ografiar. Un ejemplo de la dificultad que implican dichos procesos se encuentra en los entornos log??sticos, donde instancias de diferentes pro- cesos y con diferentes cardinalidades deben de trabajar para alcanzar un objetivo común. En este trabajo se identifican el conjunto de retos a resolver para facilitar la incorporación de la ingeniería de los procesos de negocio a entornos logísticos. En el artículo se analizan además los trabajos previos, y se esboza una solución basada en el análisis de los artefactos de datos involucrados y la capacidad del modelado orientado a actividades de los procesos de negocios.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-021.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-021.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Kevin Daniel Cisneros Carreño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[kev.cisn@hotmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Tecnológico Nacional de México, Instituto Tecnológico de Zacatepec, México]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Angel Jesus Varela Vaca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ajvarela@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Luisa Parody]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mlparody@uloyola.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Loyola Andalucía, Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[María Teresa Gómez-López]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[maytegomez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/020]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
</rss>
