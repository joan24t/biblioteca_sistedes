<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0"
	xmlns:excerpt="http://wordpress.org/export/1.2/excerpt/"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:wp="http://wordpress.org/export/1.2/"
>
	<item>
		<title>Un índice espacio-temporal compacto para consultas time-slice y time-interval</title>
		<link>https://biblioteca.sistedes.es/articulo/un-indice-espacio-temporal-compacto-para-consultas-time-slice-y-time-interval/</link>
		<pubDate>Mon, 10 Aug 2015 19:30:45 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=123</guid>
		<description></description>
		<content><![CDATA[La indexación de datos espacio-temporales es fundamental para responder de manera eficiente consultas acerca de objetos móviles que se encuentran en una región durante un instante o intervalo temporal determinado. Esto es de interés, por ejemplo, para detectar embarcaciones que invaden zonas de navegación prohibidas. Este artículo presenta un índice espacio-temporal compacto (eficiente en espacio) que permite responder ambos tipos de consultas. La evaluación experimental muestra que el índice propuesto es competitivo en tiempo al compararlo con el MVR-Tree usando significativamente menos espacio.]]></content>
		<excerpt><![CDATA[La indexación de datos espacio-temporales es fundamental para responder de manera eficiente consultas acerca de objetos móviles que se encuentran en una región durante un instante o intervalo temporal determinado. Esto es de interés, por ejemplo, para detectar embarcaciones que invaden zonas de navegación prohibidas. Este artículo presenta un índice espacio-temporal compacto (eficiente en espacio) que permite responder ambos tipos de consultas. La evaluación experimental muestra que el índice propuesto es competitivo en tiempo al compararlo con el MVR-Tree usando significativamente menos espacio.]]></excerpt>
		<post_id>123</post_id>
		<post_date><![CDATA[2015-08-10 21:30:45]]></post_date>
		<post_date_gmt><![CDATA[2015-08-10 19:30:45]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-indice-espacio-temporal-compacto-para-consultas-time-slice-y-time-interval]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="espacio-temporal"><![CDATA[espacio-temporal]]></category>
		<category domain="post_tag" nicename="estructura-de-datos-compacta"><![CDATA[estructura de datos compacta]]></category>
		<category domain="post_tag" nicename="indexacion"><![CDATA[indexación]]></category>
		<category domain="post_tag" nicename="objeto-movil"><![CDATA[Objeto móvil]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Nieves R. Brisaboa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de datos, Universidade da Coruña Campus de Elviña, 15071 A Coruña, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[brisaboa@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ramón Casares]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de datos, Universidade da Coruña Campus de Elviña, 15071 A Coruña, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[rcasares@enxenio.es 2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Andrea Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Concepción, Departamento de Ingeniería Informática y Ciencias de la Computación, Edmundo Larenas 215, 4070409 Concepción, Chile]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[andrea@udec.cl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Miguel Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad del Bío-Bío, Departamento de Ciencias de la Computación y Tecnologías de la Información Andrés Bello s/n, 3800708 Chillán, Chile]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[miguel.romero@ubiobio.cl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Diego Seco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Concepción, Departamento de Ingeniería Informática y Ciencias de la Computación, Edmundo Larenas 215, 4070409 Concepción, Chile]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[dseco@udec.cl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La indexación de datos espacio-temporales es fundamental para responder de manera eficiente consultas acerca de objetos móviles que se encuentran en una región durante un instante o intervalo temporal determinado. Esto es de interés, por ejemplo, para detectar embarcaciones que invaden zonas de navegación prohibidas. Este artículo presenta un índice espacio-temporal compacto (eficiente en espacio) que permite responder ambos tipos de consultas. La evaluación experimental muestra que el índice propuesto es competitivo en tiempo al compararlo con el MVR-Tree usando significativamente menos espacio.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Objeto móvil, espacio-temporal, estructura de datos compacta, indexación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[gestion de datos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[124]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/009]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Query approximation in the case of incompletely aligned datasets</title>
		<link>https://biblioteca.sistedes.es/articulo/query-approximation-in-the-case-of-incompletely-aligned-datasets/</link>
		<pubDate>Mon, 10 Aug 2015 19:39:38 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=128</guid>
		<description></description>
		<content><![CDATA[Clouds of Linked Open Data about the same domain promote the formulation of a query over a source dataset and then try to process the same query over different target datasets, one after another, in order to obtain a broader set of answers. However, heterogeneity of vocabularies used in the datasets and the scarce number of alignments among those datasets makes that querying task extremely difficult. This paper presents a proposal that allows on demand transformations of queries by using a set of transformation rules that are able to rewrite a query formulated over a source dataset into another query adequate for a target dataset, which approximates the original one. The approach relieves users from knowing the vocabulary used in the targeted datasets and even more it considers situations where alignments do not exist or they are not suitable for the formulated query. Therefore, in order to favor the possibility of getting answers, sometimes there is no guarantee of obtaining a semantically equivalent translation. Experiments with benchmark queries validate the feasibility of the proposal.]]></content>
		<excerpt><![CDATA[Clouds of Linked Open Data about the same domain promote the formulation of a query over a source dataset and then try to process the same query over different target datasets, one after another, in order to obtain a broader set of answers. However, heterogeneity of vocabularies used in the datasets and the scarce number of alignments among those datasets makes that querying task extremely difficult. This paper presents a proposal that allows on demand transformations of queries by using a set of transformation rules that are able to rewrite a query formulated over a source dataset into another query adequate for a target dataset, which approximates the original one. The approach relieves users from knowing the vocabulary used in the targeted datasets and even more it considers situations where alignments do not exist or they are not suitable for the formulated query. Therefore, in order to favor the possibility of getting answers, sometimes there is no guarantee of obtaining a semantically equivalent translation. Experiments with benchmark queries validate the feasibility of the proposal.]]></excerpt>
		<post_id>128</post_id>
		<post_date><![CDATA[2015-08-10 21:39:38]]></post_date>
		<post_date_gmt><![CDATA[2015-08-10 19:39:38]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[query-approximation-in-the-case-of-incompletely-aligned-datasets]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana I. Torre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Tecnalia Research & Innovation]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[isabel.torre@tecnalia.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jesus Bermudez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country UPV/EHU]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jesus.bermudez@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Arantza Illarramendi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country UPV/EHU]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[a.illarramendi@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Clouds of Linked Open Data about the same domain promote the formulation of a query over a source dataset and then try to process the same query over different target datasets, one after another, in order to obtain a broader set of answers. However, heterogeneity of vocabularies used in the datasets and the scarce number of alignments among those datasets makes that querying task extremely difficult. This paper presents a proposal that allows on demand transformations of queries by using a set of transformation rules that are able to rewrite a query formulated over a source dataset into another query adequate for a target dataset, which approximates the original one. The approach relieves users from knowing the vocabulary used in the targeted datasets and even more it considers situations where alignments do not exist or they are not suitable for the formulated query. Therefore, in order to favor the possibility of getting answers, sometimes there is no guarantee of obtaining a semantically equivalent translation. Experiments with benchmark queries validate the feasibility of the proposal.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[129]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/008]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A First Step Towards Keyword-Based Searching for Recommendation Systems</title>
		<link>https://biblioteca.sistedes.es/articulo/a-first-step-towards-keyword-based-searching-for-recommendation-systems/</link>
		<pubDate>Mon, 10 Aug 2015 19:45:00 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=131</guid>
		<description></description>
		<content><![CDATA[Due to the high availability of data, users are frequently overloaded with a huge amount of alternatives when they need to choose a particular item. This has motivated an increased interest in research on recommendation systems, which filter the options and provide users with suggestions about specific elements (e.g., movies, restaurants, hotels, news, etc.) that are estimated to be potentially relevant for the user. Recommendation systems are still an active area of research, and particularly in the last years the concept of context-aware recommendation systems has started to be popular, due to the interest of considering the context of the user in the recommendation process. In this paper, we describe our work-in-progress concerning pull-based recommendations (i.e., recommendations about certain types of items that are explicitly requested by the user). In particular, we focus on the problem of detecting the type of item the user is interested in. Due to its popularity, we consider a keyword-based user interface: the user types a few keywords and the system must determine what the user is searching for. Whereas there is extensive work in the field of keyword-based search, which is still a very active research area, keyword searching has not been applied so far in most recommendation contexts.]]></content>
		<excerpt><![CDATA[Due to the high availability of data, users are frequently overloaded with a huge amount of alternatives when they need to choose a particular item. This has motivated an increased interest in research on recommendation systems, which filter the options and provide users with suggestions about specific elements (e.g., movies, restaurants, hotels, news, etc.) that are estimated to be potentially relevant for the user. Recommendation systems are still an active area of research, and particularly in the last years the concept of context-aware recommendation systems has started to be popular, due to the interest of considering the context of the user in the recommendation process. In this paper, we describe our work-in-progress concerning pull-based recommendations (i.e., recommendations about certain types of items that are explicitly requested by the user). In particular, we focus on the problem of detecting the type of item the user is interested in. Due to its popularity, we consider a keyword-based user interface: the user types a few keywords and the system must determine what the user is searching for. Whereas there is extensive work in the field of keyword-based search, which is still a very active research area, keyword searching has not been applied so far in most recommendation contexts.]]></excerpt>
		<post_id>131</post_id>
		<post_date><![CDATA[2015-08-10 21:45:00]]></post_date>
		<post_date_gmt><![CDATA[2015-08-10 19:45:00]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-first-step-towards-keyword-based-searching-for-recommendation-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="keyword-based-search"><![CDATA[keyword-based search]]></category>
		<category domain="post_tag" nicename="mobile-computing"><![CDATA[mobile computing]]></category>
		<category domain="post_tag" nicename="recommendation-systems"><![CDATA[recommendation systems]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María del Carmen Rodríguez-Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science and Systems Engineering University of Zaragoza, Zaragoza, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mary0485@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francesco Guerra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Modena and Reggio Emilia, Modena, Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[francesco.guerra@unimore.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sergio Ilarri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science and Systems Engineering University of Zaragoza, Zaragoza, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[silarri@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Raquel Trillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science and Systems Engineering University of Zaragoza, Zaragoza, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[raqueltl@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Due to the high availability of data, users are frequently overloaded with a huge amount of alternatives when they need to choose a particular item. This has motivated an increased interest in research on recommendation systems, which filter the options and provide users with suggestions about specific elements (e.g., movies, restaurants, hotels, news, etc.) that are estimated to be potentially relevant for the user. Recommendation systems are still an active area of research, and particularly in the last years the concept of context-aware recommendation systems has started to be popular, due to the interest of considering the context of the user in the recommendation process. In this paper, we describe our work-in-progress concerning pull-based recommendations (i.e., recommendations about certain types of items that are explicitly requested by the user). In particular, we focus on the problem of detecting the type of item the user is interested in. Due to its popularity, we consider a keyword-based user interface: the user types a few keywords and the system must determine what the user is searching for. Whereas there is extensive work in the field of keyword-based search, which is still a very active research area, keyword searching has not been applied so far in most recommendation contexts.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[keyword-based search, recommendation systems, mobile computing]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[132]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/007]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Integración semántica de datos de observación mediante servicios SOS</title>
		<link>https://biblioteca.sistedes.es/articulo/integracion-semantica-de-datos-de-observacion-mediante-servicios-sos/</link>
		<pubDate>Mon, 10 Aug 2015 19:51:47 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=134</guid>
		<description></description>
		<content><![CDATA[En este documento se describe el trabajo en marcha de diseño e implementación de un servicio de acceso a datos de observación medioambiental SOS (Sensor Observation Service) que permite la integración semántica de fuentes de datos accesible a través de este estándar.]]></content>
		<excerpt><![CDATA[En este documento se describe el trabajo en marcha de diseño e implementación de un servicio de acceso a datos de observación medioambiental SOS (Sensor Observation Service) que permite la integración semántica de fuentes de datos accesible a través de este estándar.]]></excerpt>
		<post_id>134</post_id>
		<post_date><![CDATA[2015-08-10 21:51:47]]></post_date>
		<post_date_gmt><![CDATA[2015-08-10 19:51:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[integracion-semantica-de-datos-de-observacion-mediante-servicios-sos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="integracion-semantica"><![CDATA[Integración Semántica]]></category>
		<category domain="post_tag" nicename="observacion-medioambiental"><![CDATA[Observación Medioambiental]]></category>
		<category domain="post_tag" nicename="ogc"><![CDATA[OGC]]></category>
		<category domain="post_tag" nicename="ontologias"><![CDATA[Ontologías]]></category>
		<category domain="post_tag" nicename="sensor-web"><![CDATA[Sensor Web]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel A. Regueiro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Computer Graphics and Data Engineering Group (COGRADE) Centro de Investigaci´on en Tecnolox´ıas da Informaci´on (CITIUS) Universidade de Santiago de Compostela (USC) Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[manuelantonio.regueiro@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José  R.R. Viqueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Computer Graphics and Data Engineering Group (COGRADE) Centro de Investigaci´on en Tecnolox´ıas da Informaci´on (CITIUS) Universidade de Santiago de Compostela (USC) Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrr.viqueira@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Christoph Stasch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[52 North Initiative for Geospatial Open Source Software GmbH Martin-Luther-King-Weg 24, 48155 Muenster, Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[c.stasch@52north.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José M. Cotos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Computer Graphics and Data Engineering Group (COGRADE) Centro de Investigaci´on en Tecnolox´ıas da Informaci´on (CITIUS) Universidade de Santiago de Compostela (USC) Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manel.cotos@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este documento se describe el trabajo en marcha de diseño e implementación de un servicio de acceso a datos de observación medioambiental SOS (Sensor Observation Service) que permite la integración semántica de fuentes de datos accesible a través de este estándar.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[OGC, Sensor Web, Observación Medioambiental, Ontologías, Integración Semántica]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[135]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/006]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Optimización del Almacenamiento de Datos en la Gestión Energética de Edificios Inteligentes</title>
		<link>https://biblioteca.sistedes.es/articulo/optimizacion-del-almacenamiento-de-datos-en-la-gestion-energetica-de-edificios-inteligentes/</link>
		<pubDate>Mon, 10 Aug 2015 20:02:42 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=137</guid>
		<description></description>
		<content><![CDATA[El objetivo principal del proyecto LIFE-OPERE es mejorar la gestión energética en grandes instalaciones de la Universidad de Santiago de Compostela (USC). Se almacenará y analizará la información de sensorización de los edificios para determinar el impacto de las nuevas medidas adoptadas. Para ello, se ha diseñado e implementado un sistema de adquisición, almacenamiento y publicación de datos. Este artículo se centra en la optimización del modelo de datos para hacer frente a los problemas y retos que han surgido durante el proyecto. Además, se valora también la necesidad de implantar una infraestructura big data.]]></content>
		<excerpt><![CDATA[El objetivo principal del proyecto LIFE-OPERE es mejorar la gestión energética en grandes instalaciones de la Universidad de Santiago de Compostela (USC). Se almacenará y analizará la información de sensorización de los edificios para determinar el impacto de las nuevas medidas adoptadas. Para ello, se ha diseñado e implementado un sistema de adquisición, almacenamiento y publicación de datos. Este artículo se centra en la optimización del modelo de datos para hacer frente a los problemas y retos que han surgido durante el proyecto. Además, se valora también la necesidad de implantar una infraestructura big data.]]></excerpt>
		<post_id>137</post_id>
		<post_date><![CDATA[2015-08-10 22:02:42]]></post_date>
		<post_date_gmt><![CDATA[2015-08-10 20:02:42]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[optimizacion-del-almacenamiento-de-datos-en-la-gestion-energetica-de-edificios-inteligentes]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="automatizacion"><![CDATA[automatización]]></category>
		<category domain="post_tag" nicename="base-de-datos"><![CDATA[base de datos]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="edificio-inteligente"><![CDATA[edificio inteligente]]></category>
		<category domain="post_tag" nicename="sensor"><![CDATA[sensor]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Samuel Otero Paz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[COGRADE – Centro de Investigación en Tecnoloxías da Información, Systems Laboratory – Instituto de Investigacións Tecnolóxicas, Universidade de Santiago de Compostela, Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[samuel.otero@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose A. Taboada González]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[COGRADE – Centro de Investigación en Tecnoloxías da Información]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[joseangel.taboada@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose R.R. Viqueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[COGRADE – Centro de Investigación en Tecnoloxías da Información]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jrr.viqueira@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan E. Arias Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Systems Laboratory – Instituto de Investigacións Tecnolóxicas, Universidade de Santiago de Compostela, Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juan.arias@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El objetivo principal del proyecto LIFE-OPERE es mejorar la gestión energética en grandes instalaciones de la Universidad de Santiago de Compostela (USC). Se almacenará y analizará la información de sensorización de los edificios para determinar el impacto de las nuevas medidas adoptadas. Para ello, se ha diseñado e implementado un sistema de adquisición, almacenamiento y publicación de datos. Este artículo se centra en la optimización del modelo de datos para hacer frente a los problemas y retos que han surgido durante el proyecto. Además, se valora también la necesidad de implantar una infraestructura big data.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[sensor, automatización, big data, base de datos, edificio inteligente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[139]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un marco para democratizar la minería de datos: propuesta inicial y retos</title>
		<link>https://biblioteca.sistedes.es/articulo/un-marco-para-democratizar-la-mineria-de-datos-propuesta-inicial-y-retos/</link>
		<pubDate>Mon, 10 Aug 2015 20:12:40 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=140</guid>
		<description></description>
		<content><![CDATA[Movimientos como el de datos abiertos posibilitan que cada vez haya una mayor disponibilidad de datos accesibles para su reuti lización. A pesar de que el número de herramientas analíticas que están a nuestra disposición crece cada día, lamentablemente ninguna permite realizar un proceso de extracción de conocimiento directo a usuarios con poca o nula experiencia en el uso de la estadística y de algoritmos de minería de datos. En este artículo se presenta una aproximación a un marco KaaS (Knowledge as a Service) que posibilite a usuarios no ex pertos la extracción de conocimiento a partir de un conjunto de datos. Se muestra que la propuesta es viable y se plantean los retos aún abiertos.]]></content>
		<excerpt><![CDATA[Movimientos como el de datos abiertos posibilitan que cada vez haya una mayor disponibilidad de datos accesibles para su reuti lización. A pesar de que el número de herramientas analíticas que están a nuestra disposición crece cada día, lamentablemente ninguna permite realizar un proceso de extracción de conocimiento directo a usuarios con poca o nula experiencia en el uso de la estadística y de algoritmos de minería de datos. En este artículo se presenta una aproximación a un marco KaaS (Knowledge as a Service) que posibilite a usuarios no ex pertos la extracción de conocimiento a partir de un conjunto de datos. Se muestra que la propuesta es viable y se plantean los retos aún abiertos.]]></excerpt>
		<post_id>140</post_id>
		<post_date><![CDATA[2015-08-10 22:12:40]]></post_date>
		<post_date_gmt><![CDATA[2015-08-10 20:12:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-marco-para-democratizar-la-mineria-de-datos-propuesta-inicial-y-retos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="analitica"><![CDATA[Analítica]]></category>
		<category domain="post_tag" nicename="conocimiento-como-servicio"><![CDATA[Conocimiento como Servicio]]></category>
		<category domain="post_tag" nicename="meta-aprendizaje"><![CDATA[Meta-aprendizaje]]></category>
		<category domain="post_tag" nicename="mineria-de-datos"><![CDATA[Minería de datos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Diego García-Saiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería Informática y Electrónica, Universidad de Cantabria, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[diego.garcias@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Roberto Espinosa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[WaKe Research, Universidad de Matanzas, Cuba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[roberto.espinosa@umcc.cu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José Jacobo Zubcoff]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[WaKe Research, Dpto. Ciencias del Mar y Biología Aplicada, Universidad de Alicante, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jose.zubcoff@ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José-Norberto Mazón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[WaKe Research, Dpto. Lenguajes y Sistemas Informáticos, Instituto Universitari de Investigación Informática, Universidad de Alicante, Espa˜na]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jnmazon@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Marta Zorrilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería Informática y Electrónica, Universidad de Cantabria, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[marta.zorrilla@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Movimientos como el de datos abiertos posibilitan que cada vez haya una mayor disponibilidad de datos accesibles para su reuti lización. A pesar de que el número de herramientas analíticas que están a nuestra disposición crece cada día, lamentablemente ninguna permite realizar un proceso de extracción de conocimiento directo a usuarios con poca o nula experiencia en el uso de la estadística y de algoritmos de minería de datos. En este artículo se presenta una aproximación a un marco KaaS (Knowledge as a Service) que posibilite a usuarios no ex pertos la extracción de conocimiento a partir de un conjunto de datos. Se muestra que la propuesta es viable y se plantean los retos aún abiertos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Conocimiento como Servicio, Minería de datos, Analítica, Meta-aprendizaje]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[141]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>JET: A Proof of Concept Enabling Mobile Devices as Personal Profile Providers</title>
		<link>https://biblioteca.sistedes.es/articulo/jet-a-proof-of-concept-enabling-mobile-devices-as-personal-profile-providers/</link>
		<pubDate>Sat, 29 Aug 2015 16:43:58 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=158</guid>
		<description></description>
		<content><![CDATA[In recent years smartphone users have increased the number of cloud services and platforms used from them. These platforms and services are usually used, by users, to interact with others people and, by
the mobile telephony firms, to create a sociological profile of the people and, thus, achieving a more adapted advertising. However, the information uploaded to these platforms is usually very similar. Uploading it to every platform entails an irrational consumption of the device resources.
But, if it is not the same, the sociological profiles created could be inconsistent. The capabilities of current smartphones enable them to keep all the owner’s information and to provide services for accessing it. To achieve such paradigm shift new tools and platforms are needed. This paper reports a proof of concept of a mobile application that creates and stores the sociological profiles of their users, allowing them to send messages based on those profiles. The use of this new paradigm reduces the consumption of the smartphone resources and facilitates the creation of comprehensive sociological profiles.]]></content>
		<excerpt><![CDATA[In recent years smartphone users have increased the number
of cloud services and platforms used from them. These platforms and services are usually used, by users, to interact with others people and, by
the mobile telephony firms, to create a sociological profile of the people
and, thus, achieving a more adapted advertising. However, the information uploaded to these platforms is usually very similar. Uploading it to
every platform entails an irrational consumption of the device resources.
But, if it is not the same, the sociological profiles created could be inconsistent. The capabilities of current smartphones enable them to keep
all the owner’s information and to provide services for accessing it. To
achieve such paradigm shift new tools and platforms are needed. This
paper reports a proof of concept of a mobile application that creates and
stores the sociological profiles of their users, allowing them to send messages based on those profiles. The use of this new paradigm reduces the
consumption of the smartphone resources and facilitates the creation of
comprehensive sociological profiles.]]></excerpt>
		<post_id>158</post_id>
		<post_date><![CDATA[2015-08-29 18:43:58]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 16:43:58]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[jet-a-proof-of-concept-enabling-mobile-devices-as-personal-profile-providers]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mobile-computing"><![CDATA[mobile computing]]></category>
		<category domain="post_tag" nicename="smartphones"><![CDATA[Smartphones]]></category>
		<category domain="post_tag" nicename="sociological-profiles"><![CDATA[Sociological Profiles]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose Garcia-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Niko Mäkitalo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Tampere University of Technology]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[niko.makitalo@cs.tut.fi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Tommi Mikkonen]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Tampere University of Technology]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[tjm@cs.tut.fi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In recent years smartphone users have increased the number of cloud services and platforms used from them. These platforms and services are usually used, by users, to interact with others people and, by
the mobile telephony firms, to create a sociological profile of the people and, thus, achieving a more adapted advertising. However, the information uploaded to these platforms is usually very similar. Uploading it to every platform entails an irrational consumption of the device resources.
But, if it is not the same, the sociological profiles created could be inconsistent. The capabilities of current smartphones enable them to keep all the owner’s information and to provide services for accessing it. To achieve such paradigm shift new tools and platforms are needed. This paper reports a proof of concept of a mobile application that creates and stores the sociological profiles of their users, allowing them to send messages based on those profiles. The use of this new paradigm reduces the consumption of the smartphone resources and facilitates the creation of comprehensive sociological profiles.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Smartphones, Mobile Computing, Sociological Profiles]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Ingeniería Web y Sistemas Colaborativos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[159]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Javier Miranda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Juan M. Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[Gloin S.L.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[jmiranda@gloin.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/011]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>GeoNews: Generación automática de contextos geográficos para programas de noticias a través de HbbTV</title>
		<link>https://biblioteca.sistedes.es/articulo/geonews-generaci-n-autom-tica-de-contextos-o-a-geogr-ficos-para-programas-de-noticias-a-trav-s-a-e-de-hbbtv/</link>
		<pubDate>Sat, 29 Aug 2015 16:56:13 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=161</guid>
		<description></description>
		<content><![CDATA[Varios estudios recientes han detectado nuevos hábitos en la audiencia de televisió relacionados con el acceso a travé de otros
dispositivos a información que complemente los contenidos de televisión.
En este documento se describe una solución preliminar para la generación de contextos geográficos para programas de noticias en lengua castellana y para su visualización sincronizada en un televisor a través de tecnología HbbTV.]]></content>
		<excerpt><![CDATA[Varios estudios recientes han detectado nuevos hábitos en la audiencia de televisió relacionados con el acceso a travé de otros
dispositivos a información que complemente los contenidos de televisión.
En este documento se describe una solución preliminar para la generación de contextos geográficos para programas de noticias en lengua castellana y para su visualización  sincronizada en un televisor a través de tecnología HbbTV.]]></excerpt>
		<post_id>161</post_id>
		<post_date><![CDATA[2015-08-29 18:56:13]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 16:56:13]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[geonews-generaci-n-autom-tica-de-contextos-o-a-geogr-ficos-para-programas-de-noticias-a-trav-s-a-e-de-hbbtv]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="contexto-geogr-fico"><![CDATA[Contexto geogr ́fico]]></category>
		<category domain="post_tag" nicename="geoetiquetado"><![CDATA[Geoetiquetado]]></category>
		<category domain="post_tag" nicename="gis"><![CDATA[GIS]]></category>
		<category domain="post_tag" nicename="hbbtv"><![CDATA[HbbTV]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Moisés Vilar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Computer Graphics and Data Engineering Group (COGRADE) Centro de Investigaci ́n en Tecnolox ́ da Informaci ́n (CiTIUS) o ıas o Universidade de Santiago de Compostela (USC) Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[moises.vilar@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sebastián Villarroya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Computer Graphics and Data Engineering Group (COGRADE) Centro de Investigaci ́n en Tecnolox ́ da Informaci ́n (CiTIUS) o ıas o Universidade de Santiago de Compostela (USC) Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sebastian.villarroya@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José R.R. Viqueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Computer Graphics and Data Engineering Group (COGRADE) Centro de Investigaci ́n en Tecnolox ́ da Informaci ́n (CiTIUS) o ıas o Universidade de Santiago de Compostela (USC) Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[rr.viqueira@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José M. Cotos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Computer Graphics and Data Engineering Group (COGRADE) Centro de Investigaci ́n en Tecnolox ́ da Informaci ́n (CiTIUS) o ıas o Universidade de Santiago de Compostela (USC) Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manel.cotos@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Varios estudios recientes han detectado nuevos hábitos en la audiencia de televisió relacionados con el acceso a travé de otros
dispositivos a información que complemente los contenidos de televisión.
En este documento se describe una solución preliminar para la generación de contextos geográficos para programas de noticias en lengua castellana y para su visualización  sincronizada en un televisor a través de tecnología HbbTV.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[HbbTV, Geoetiquetado, Contexto geogr ́fico, GIS]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[162]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/010]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modelos de Contexto en el Desarrollo de Interfaces PostWIMP: una Revisión Crítica</title>
		<link>https://biblioteca.sistedes.es/articulo/modelos-de-contexto-en-el-desarrollo-de-interfaces-postwimp-una-revision-critica/</link>
		<pubDate>Sat, 29 Aug 2015 17:00:16 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=165</guid>
		<description></description>
		<content><![CDATA[A lo largo de los últimos años, el avance de la tecnología y la aparición
de nuevos dispositivos ha dado lugar a nuevos paradigmas de interacción persona-ordenador que cada vez son más comunes entre los usuarios finales. La hegemonía de las interfaces clásicas WIMP (Windows, Icons, Menus, Pointers) ha
quedado en un segundo plano, dando paso a nuevos tipos de interacción basados
en tecnologías, otrora llamadas futuristas, como realidad virtual, dispositivos corporales, reconocimiento de voz y gestos, entre otros. El desarrollo de este nuevo
tipo de interfaces, llamadas Post-WIMP, está fuertemente ligado al análisis del
contexto, que en muchos casos determinará la viabilidad e idoneidad de las mismas. De esta forma, la interfaz final tendrá en cuenta las necesidades del usuario
y las características específicas del entorno y la plataforma en la que se desarrolla,
mejorando así la usabilidad de la aplicación. Por otro lado, el contexto de una
aplicación ha sido interpretado desde distintos puntos de vista, pero existe cierto
consenso a la hora de asociarlo a aspectos relativos al usuario, la plataforma y el
entorno. En este sentido, se han propuesto numerosos meta-modelos que ayudan
a especificar el contexto durante el análisis de una aplicación. Sin embargo, la
mayoría de estos meta-modelos no están enfocados a describir las necesidades
que aparecen en el desarrollo de sistemas con interfaces Post-WIMP, sino que
tienen como objetivo el desarrollo de sistemas sensibles al contexto específicos
o sistemas con interfaces clásicas WIMP. En este artículo, repasaremos el concepto de contexto, su relación con el desarrollo de interfaces Post-WIMP y analizaremos, desde la perspectiva del desarrollo de sistemas con interfaces PostWIMP dirigido por modelos, varios meta-modelos de contexto.]]></content>
		<excerpt><![CDATA[A lo largo de los últimos años, el avance de la tecnología y la aparición
de nuevos dispositivos ha dado lugar a nuevos paradigmas de interacción persona-ordenador que cada vez son más comunes entre los usuarios finales. La hegemonía de las interfaces clásicas WIMP (Windows, Icons, Menus, Pointers) ha
quedado en un segundo plano, dando paso a nuevos tipos de interacción basados
en tecnologías, otrora llamadas futuristas, como realidad virtual, dispositivos corporales, reconocimiento de voz y gestos, entre otros. El desarrollo de este nuevo
tipo de interfaces, llamadas Post-WIMP, está fuertemente ligado al análisis del
contexto, que en muchos casos determinará la viabilidad e idoneidad de las mismas. De esta forma, la interfaz final tendrá en cuenta las necesidades del usuario
y las características específicas del entorno y la plataforma en la que se desarrolla,
mejorando así la usabilidad de la aplicación. Por otro lado, el contexto de una
aplicación ha sido interpretado desde distintos puntos de vista, pero existe cierto
consenso a la hora de asociarlo a aspectos relativos al usuario, la plataforma y el
entorno. En este sentido, se han propuesto numerosos meta-modelos que ayudan
a especificar el contexto durante el análisis de una aplicación. Sin embargo, la
mayoría de estos meta-modelos no están enfocados a describir las necesidades
que aparecen en el desarrollo de sistemas con interfaces Post-WIMP, sino que
tienen como objetivo el desarrollo de sistemas sensibles al contexto específicos
o sistemas con interfaces clásicas WIMP. En este artículo, repasaremos el concepto de contexto, su relación con el desarrollo de interfaces Post-WIMP y analizaremos, desde la perspectiva del desarrollo de sistemas con interfaces PostWIMP dirigido por modelos, varios meta-modelos de contexto.]]></excerpt>
		<post_id>165</post_id>
		<post_date><![CDATA[2015-08-29 19:00:16]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 17:00:16]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modelos-de-contexto-en-el-desarrollo-de-interfaces-postwimp-una-revision-critica]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="contexto"><![CDATA[Contexto]]></category>
		<category domain="post_tag" nicename="interfaces-post-wimp"><![CDATA[Interfaces Post-WIMP]]></category>
		<category domain="post_tag" nicename="meta-modelos"><![CDATA[Meta-Modelos]]></category>
		<category domain="post_tag" nicename="modelos"><![CDATA[Modelos]]></category>
		<category domain="post_tag" nicename="revision"><![CDATA[Revisión]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Arturo C. Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación LoUISE, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Arturo.Rodriguez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Cristina Roda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación LoUISE, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Cristina.Roda@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Elena Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación LoUISE, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Elena.Navarro@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Pascual González]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación LoUISE, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Pascual.Gonzalez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A lo largo de los últimos años, el avance de la tecnología y la aparición
de nuevos dispositivos ha dado lugar a nuevos paradigmas de interacción persona-ordenador que cada vez son más comunes entre los usuarios finales. La hegemonía de las interfaces clásicas WIMP (Windows, Icons, Menus, Pointers) ha
quedado en un segundo plano, dando paso a nuevos tipos de interacción basados
en tecnologías, otrora llamadas futuristas, como realidad virtual, dispositivos corporales, reconocimiento de voz y gestos, entre otros. El desarrollo de este nuevo
tipo de interfaces, llamadas Post-WIMP, está fuertemente ligado al análisis del
contexto, que en muchos casos determinará la viabilidad e idoneidad de las mismas. De esta forma, la interfaz final tendrá en cuenta las necesidades del usuario
y las características específicas del entorno y la plataforma en la que se desarrolla,
mejorando así la usabilidad de la aplicación. Por otro lado, el contexto de una
aplicación ha sido interpretado desde distintos puntos de vista, pero existe cierto
consenso a la hora de asociarlo a aspectos relativos al usuario, la plataforma y el
entorno. En este sentido, se han propuesto numerosos meta-modelos que ayudan
a especificar el contexto durante el análisis de una aplicación. Sin embargo, la
mayoría de estos meta-modelos no están enfocados a describir las necesidades
que aparecen en el desarrollo de sistemas con interfaces Post-WIMP, sino que
tienen como objetivo el desarrollo de sistemas sensibles al contexto específicos
o sistemas con interfaces clásicas WIMP. En este artículo, repasaremos el concepto de contexto, su relación con el desarrollo de interfaces Post-WIMP y analizaremos, desde la perspectiva del desarrollo de sistemas con interfaces PostWIMP dirigido por modelos, varios meta-modelos de contexto.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Modelos, Meta-Modelos, Contexto, Interfaces Post-WIMP, Revisión]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Ingeniería Web y Sistemas Colaborativos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[166]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/037]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Pruebas basadas en flujo de datos para programas MapReduce</title>
		<link>https://biblioteca.sistedes.es/articulo/pruebas-basadas-en-flujo-de-datos-para-programas-mapreduce/</link>
		<pubDate>Sat, 29 Aug 2015 17:17:29 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=170</guid>
		<description></description>
		<content><![CDATA[MapReduce es un paradigma de procesamiento masivo de información. Estos programas realizan varias transformaciones de los datos hasta que se obtiene la salida representando la lógica de negocio del programa. En este artículo se elabora una técnica de prueba basada en data flow y que deriva las pruebas a partir de las transformaciones que ocurren en el programa. Se muestran resultados de la ejecución de los casos de prueba derivados de la aplicación de la técnica, los cuales permiten detectar algunos defectos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>170</post_id>
		<post_date><![CDATA[2015-08-29 19:17:29]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 17:17:29]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[pruebas-basadas-en-flujo-de-datos-para-programas-mapreduce]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mapreduce"><![CDATA[MapReduce]]></category>
		<category domain="post_tag" nicename="pruebas-data-flow"><![CDATA[pruebas data flow]]></category>
		<category domain="post_tag" nicename="pruebas-de-software"><![CDATA[Pruebas de Software]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús Morán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo, Gijón, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[moranjesus@lsi.uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Claudio de la Riva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo, Gijón, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[claudio@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo, Gijón, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[MapReduce es un paradigma de procesamiento masivo de información. Estos programas realizan varias transformaciones de los datos hasta que se obtiene la salida representando la lógica de negocio del programa. En este artículo se elabora una técnica de prueba basada en data flow y que deriva las pruebas a partir de las transformaciones que ocurren en el programa. Se muestran resultados de la ejecución de los casos de prueba derivados de la aplicación de la técnica, los cuales permiten detectar algunos defectos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Pruebas de Software, pruebas data flow, MapReduce]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[171]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/013]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>I8K&#124;DQ-BigData: Extensión Arquitectura I8K para Calidad de Datos en Big Data</title>
		<link>https://biblioteca.sistedes.es/articulo/i8kdq-bigdata-extension-arquitectura-i8k-para-calidad-de-datos-en-big-data/</link>
		<pubDate>Sat, 29 Aug 2015 17:21:04 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=173</guid>
		<description></description>
		<content><![CDATA[Durante la ejecución de procesos de negocios que implican a varias
organizaciones, normalmente se intercambian Datos Maestros. Es necesario que dichos datos tengan niveles adecuados de calidad, ya que de otro modo, puede ocurrir que los procesos de negocio fallen. Si los datos intercambiados llevasen información sobre su nivel de calidad, entonces sería posible decidir si pueden
usarse o no en dichos procesos. Las partes 100 a 140 de ISO/TS 8000 pueden ayudar a proporcionar esta información de forma usable. En concreto I8K, una implementación de referencia con fines académicos del citado estándar, puede ser usado para tal fin. Lamentablemente, la eficiencia de I8K cae cuando se trata de evaluar la calidad de grandes volúmenes de Datos Maestros. Este artículo describe la extensión realizada sobre la arquitectura I8K para solventar los problemas de rendimiento al evaluar grandes volúmenes de datos utilizando tecnologías Big Data.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>173</post_id>
		<post_date><![CDATA[2015-08-29 19:21:04]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 17:21:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[i8kdq-bigdata-extension-arquitectura-i8k-para-calidad-de-datos-en-big-data]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="big-data-calidad-de-datos-i8k-intercambio-de-datos-maestros"><![CDATA[Big Data - Calidad de Datos - I8K – Intercambio de datos Maestros]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Bibiano Rivas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información Universidad de Castilla–La Mancha.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Bibiano.Rivas@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jorge Merino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información Universidad de Castilla–La Mancha.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Jorge.Merino@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Serrano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información Universidad de Castilla–La Mancha.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Manuel.Serrano@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ismael Caballero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información Universidad de Castilla–La Mancha.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Ismael.Caballero@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información Universidad de Castilla–La Mancha.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[Mario.Piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Durante la ejecución de procesos de negocios que implican a varias
organizaciones, normalmente se intercambian Datos Maestros. Es necesario que dichos datos tengan niveles adecuados de calidad, ya que de otro modo, puede ocurrir que los procesos de negocio fallen. Si los datos intercambiados llevasen información sobre su nivel de calidad, entonces sería posible decidir si pueden
usarse o no en dichos procesos. Las partes 100 a 140 de ISO/TS 8000 pueden ayudar a proporcionar esta información de forma usable. En concreto I8K, una implementación de referencia con fines académicos del citado estándar, puede ser usado para tal fin. Lamentablemente, la eficiencia de I8K cae cuando se trata de evaluar la calidad de grandes volúmenes de Datos Maestros. Este artículo describe la extensión realizada sobre la arquitectura I8K para solventar los problemas de rendimiento al evaluar grandes volúmenes de datos utilizando tecnologías Big Data.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Big Data - Calidad de Datos - I8K – Intercambio de datos Maestros]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[174]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/036]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Herramienta para la Prueba de Mutaciones en el Lenguaje C++</title>
		<link>https://biblioteca.sistedes.es/articulo/herramienta-para-la-prueba-de-mutaciones-en-el-lenguaje-c/</link>
		<pubDate>Sat, 29 Aug 2015 17:24:10 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=176</guid>
		<description></description>
		<content><![CDATA[La prueba de mutaciones es una técnica basada en fallos en torno a la cual se han elaborado herramientas para un amplio abanico de lenguajes de programación. Sin embargo, el desarrollo de un marco de prueba de mutaciones no comercial para C++ estaba pendiente. En este artículo se presenta una herramienta que permite analizar código C++, generar mutantes y ejecutar un conjunto de casos de prueba para obtener resultados que nos permitan determinar su efectividad en la detección de errores en el código. La herramienta está diseñada para permitir la inclusión de nuevos operadores para cubrir cualquier característica del lenguaje. En este documento, el uso de la herramienta se muestra a través de un operador de mutación al nivel de clase.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>176</post_id>
		<post_date><![CDATA[2015-08-29 19:24:10]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 17:24:10]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[herramienta-para-la-prueba-de-mutaciones-en-el-lenguaje-c]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="c"><![CDATA[C++]]></category>
		<category domain="post_tag" nicename="prueba-de-mutaciones"><![CDATA[prueba de mutaciones]]></category>
		<category domain="post_tag" nicename="prueba-de-software"><![CDATA[Prueba de software]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Delgado-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software, Departamento de Ingeniería Informática, Universidad de Cádiz, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pedro.delgado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software, Departamento de Ingeniería Informática, Universidad de Cádiz, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan José Domínguez-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software, Departamento de Ingeniería Informática, Universidad de Cádiz, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanjose.dominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La prueba de mutaciones es una técnica basada en fallos en torno a la cual se han elaborado herramientas para un amplio abanico de lenguajes de programación. Sin embargo, el desarrollo de un marco  de prueba de mutaciones no comercial para C++ estaba pendiente. En este artículo se presenta una herramienta que permite analizar código C++, generar mutantes y ejecutar un conjunto de casos de prueba para obtener resultados que nos permitan determinar su efectividad en la detección de errores en el código. La herramienta está diseñada para permitir la inclusión de nuevos operadores para cubrir cualquier característica del lenguaje. En este documento, el uso de la herramienta se muestra a través de un operador de mutación al nivel de clase.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Prueba de software, prueba de mutaciones, C++]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Calidad y Pruebas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[177]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/012]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>CEViNEdit: mejorando el proceso de creación de editores gráficos cognitivamente eficaces con GMF</title>
		<link>https://biblioteca.sistedes.es/articulo/cevinedit-mejorando-el-proceso-de-creacion-de-editores-graficos-cognitivamente-eficaces-con-gmf/</link>
		<pubDate>Sat, 29 Aug 2015 17:34:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=182</guid>
		<description></description>
		<content><![CDATA[Durante los últimos años, el auge de los Lenguajes Específicos de Dominio (visuales) y la complejidad inherente del desarrollo de editores gráficos para estos lenguajes, ha provocado la aparición de propuestas que proporcionan soporte técnico para esta tarea. La mayoría de estas propuestas utilizan como base EMF y GMF, que en efecto ayudan a simplificar y aumentar el nivel de automatización del proceso de desarrollo. Sin embargo, el desarrollo de herramientas sobre EMF y GMF no está exento de problemas, en su mayoría relacionados con la curva de aprendizaje de estas tecnologías, la escasa documentación o la complejidad que implica proporcionar todas las posibilidades de personalización al usuario. Con el fin de aliviar la complejidad intrínseca del enfoque EMF/GMF para el desarrollo de editores gráficos, en este trabajo presentamos CEViNEdit, una herramienta intuitiva que soporta la generación semi-automática de editores gráficos y, al mismo tiempo, la evaluación de la eficacia cognitiva de la notación visual que implementa el editor.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>182</post_id>
		<post_date><![CDATA[2015-08-29 19:34:07]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 17:34:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[cevinedit-mejorando-el-proceso-de-creacion-de-editores-graficos-cognitivamente-eficaces-con-gmf]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="ingenieria-dirigida-por-modelos"><![CDATA[Ingeniería Dirigida por Modelos]]></category>
		<category domain="post_tag" nicename="lenguajes-esp"><![CDATA[Lenguajes Esp]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Calle Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[david.granada@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ángel Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Calle Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[angel.moreno@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan M. Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Calle Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Verónica A. Bollati]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Calle Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[veronica.bollati@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Calle Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Durante los últimos años, el auge de los Lenguajes Específicos de Dominio (visuales) y la complejidad inherente del desarrollo de editores gráficos para estos lenguajes, ha provocado la aparición de propuestas que proporcionan soporte técnico para esta tarea. La mayoría de estas propuestas utilizan como base EMF y GMF, que en efecto ayudan a simplificar y aumentar el nivel de automatización del proceso de desarrollo. Sin embargo, el  desarrollo de herramientas sobre EMF y GMF no está exento de problemas, en su mayoría relacionados con la curva de aprendizaje de estas tecnologías, la escasa documentación o la complejidad que implica proporcionar todas las posibilidades de personalización al usuario. Con el fin de aliviar la complejidad intrínseca del enfoque EMF/GMF para el desarrollo de editores gráficos, en este trabajo presentamos CEViNEdit, una herramienta intuitiva que soporta la generación semi-automática de editores gráficos y, al mismo tiempo, la evaluación de la eficacia cognitiva de la notación visual que implementa el editor.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Ingeniería Dirigida por Modelos, Lenguajes Esp]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Desrrollo de Software Dirigido por Modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[183]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/024]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automatización para la edición de modelos basada en vistas de dominio</title>
		<link>https://biblioteca.sistedes.es/articulo/automatizacion-para-la-edicion-de-modelos-basada-en-vistas-de-dominio/</link>
		<pubDate>Sat, 29 Aug 2015 17:37:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=185</guid>
		<description></description>
		<content><![CDATA[Este trabajo aborda la generación automática de recursos para la edición asistida de modelos de un dominio en base a vistas especializadas de su meta-modelo. La tarea de un diseñador que construye modelos conformes a un meta-modelo de dominio complejo se ve facilitada si el editor le requiere la información según una vista del meta-modelo acorde a su conceptualización o a la estrategia específica de creación que utiliza. Se presenta el meta-modelo con el que el experto de dominio formula la estrategia de creación de modelos que quiere utilizar, la herramienta que a partir de esta información sobre la estrategia genera el meta-modelo que dirige la introducción de datos y la transformación M2M que genera el modelo final que es conforme al meta-modelo de dominio de partida y que contiene los nuevos datos introducidos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>185</post_id>
		<post_date><![CDATA[2015-08-29 19:37:48]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 17:37:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automatizacion-para-la-edicion-de-modelos-basada-en-vistas-de-dominio]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="hot"><![CDATA[HOT]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="meta-herramienta"><![CDATA[meta-herramienta]]></category>
		<category domain="post_tag" nicename="meta-modelo"><![CDATA[meta-modelo]]></category>
		<category domain="post_tag" nicename="vista"><![CDATA[vista]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[César Cuevas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ISTR, Universidad de Cantabria, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cuevasce@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Patricia López Martínez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ISTR, Universidad de Cantabria, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[lopezpa@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José M. Drake]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ISTR, Universidad de Cantabria, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[drakej@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este trabajo aborda la generación automática de recursos para la edición asistida de modelos de un dominio en base a vistas especializadas de su meta-modelo. La tarea de un diseñador que construye modelos conformes a un meta-modelo de dominio complejo se ve facilitada si el editor le requiere la información según una vista del meta-modelo acorde a su conceptualización o a la estrategia específica de creación que utiliza. Se presenta el meta-modelo con el que el experto de dominio formula la estrategia de creación de modelos que quiere utilizar, la herramienta que a partir de esta información sobre la estrategia genera el meta-modelo que dirige la introducción de datos y la transformación M2M que genera el modelo final que es conforme al meta-modelo de dominio de partida y que contiene los nuevos datos introducidos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[MDE, meta-modelo, vista, meta-herramienta, HOT]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Desrrollo de Software Dirigido por Modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[186]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/023]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>PyEmofUC: Un entorno MDE/EMOF minimalista</title>
		<link>https://biblioteca.sistedes.es/articulo/pyemofuc-un-entorno-mdeemof-minimalista/</link>
		<pubDate>Sat, 29 Aug 2015 17:41:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=188</guid>
		<description></description>
		<content><![CDATA[Se presenta el entorno PyEmofUC para la creación, procesado, transformación y visualización de información en base al paradigma de ingeniería dirigida por modelos (MDE). Los meta-modelos se formulan de acuerdo con la especificación EMOF de la organización OMG y se implementan utilizando el lenguaje de programación Python. El entorno es multiplataforma, abierto y minimalista. Además del espacio tecnológico de modelado nativo, basado en Python y EMOF, el entorno da soporte al espacio tecnológico basado en lenguajes específicos como medio de facilitar la interacción con los expertos de dominio, y al espacio tecnológico de serialización para el almacenamiento persistente de los modelos y para la inter-operación con otros entornos. Por último, PyEmofUC permite formular transformaciones de modelos utilizando estilos imperativo, declarativo e híbrido.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>188</post_id>
		<post_date><![CDATA[2015-08-29 19:41:05]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 17:41:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[pyemofuc-un-entorno-mdeemof-minimalista]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="emof"><![CDATA[EMOF]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="meta-modelado"><![CDATA[meta-modelado]]></category>
		<category domain="post_tag" nicename="python"><![CDATA[Python]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José M. Drake]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ISTR, Universidad de Cantabria, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[drakej@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[César Cuevas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ISTR, Universidad de Cantabria, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cuevasce@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan R. Fernández Castañera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ISTR, Universidad de Cantabria, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Patricia López Martínez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[ISTR, Universidad de Cantabria, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[lopezpa@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Se presenta el entorno PyEmofUC para la creación, procesado, transformación y visualización de información en base al paradigma de ingeniería dirigida por modelos (MDE). Los meta-modelos se formulan de acuerdo con la especificación EMOF de la organización OMG y se implementan utilizando el lenguaje de programación Python. El entorno es multiplataforma, abierto y minimalista. Además del espacio tecnológico de modelado nativo, basado en Python y EMOF, el entorno da soporte al espacio tecnológico basado en lenguajes específicos como medio de facilitar la interacción con los expertos de dominio, y al espacio tecnológico de serialización para el almacenamiento persistente de los modelos y para la inter-operación con otros entornos. Por último, PyEmofUC permite formular transformaciones de modelos utilizando estilos imperativo, declarativo e híbrido.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[MDE, EMOF, meta-modelado, Python]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[189]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/022]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Model-Driven NoSQL Data Engineering</title>
		<link>https://biblioteca.sistedes.es/articulo/model-driven-nosql-data-engineering/</link>
		<pubDate>Sat, 29 Aug 2015 17:44:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=191</guid>
		<description></description>
		<content><![CDATA[While the concept of database schema plays a central role in relational database systems, most NoSQL systems do not require having to formally define an schema. Instead, it is implicit in the stored data. This lack of schema definition offers a greater flexibility. More specifically, schemaless databases ease both the recording of non-uniform data and data evolution. However, this comes at the cost of losing some of the benefits provided by schemas, for instance, static checking that assure that stored data conforms to the database schema. We have started a research work aimed at inferring schemas from NoSQL databases, with the purpose of building database utilities able of automating tasks such as data validation, schema visualization, and data migration. This work has evidenced the benefits of using MDE techniques within the new “NoSQL Data Engineering” field.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>191</post_id>
		<post_date><![CDATA[2015-08-29 19:44:05]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 17:44:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[model-driven-nosql-data-engineering]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="json-schema"><![CDATA[JSON Schema]]></category>
		<category domain="post_tag" nicename="model-driven-data-reverse-engineering"><![CDATA[Model-Driven Data Reverse Engineering]]></category>
		<category domain="post_tag" nicename="nosql-databases"><![CDATA[NoSQL Databases]]></category>
		<category domain="post_tag" nicename="schema-inference"><![CDATA[Schema Inference]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Diego Sevilla Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Faculty of Computer Science, University of Murcia Campus Espinardo, Murcia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[dsevilla@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Severino Feliciano Morales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Faculty of Computer Science, University of Murcia Campus Espinardo, Murcia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[severino.feliciano@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesús García Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Faculty of Computer Science, University of Murcia Campus Espinardo, Murcia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jmolina@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[While the concept of database schema plays a central role in relational database systems, most NoSQL systems do not require having to formally define an schema. Instead, it is implicit in the stored data. This lack of schema definition offers a greater flexibility. More specifically, schemaless databases ease both the recording of non-uniform data and data evolution. However, this comes at the cost of losing some of the benefits provided by schemas, for instance, static checking that assure that stored data conforms to the database schema. We have started a research work aimed at inferring schemas from NoSQL databases, with the purpose of building database utilities able of automating tasks such as data validation, schema visualization, and data migration. This work has evidenced the benefits of using MDE techniques within the new “NoSQL Data Engineering” field.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[NoSQL Databases, Schema Inference, Model-Driven Data Reverse Engineering, JSON Schema]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[192]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/021]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Achieving software-assisted knowledge generation through model-driven interoperability</title>
		<link>https://biblioteca.sistedes.es/articulo/achieving-software-assisted-knowledge-generation-through-model-driven-interoperability/</link>
		<pubDate>Sat, 29 Aug 2015 18:31:40 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=194</guid>
		<description></description>
		<content><![CDATA[A software system is a complex artefact involving several aspects, such as requirements and behavioural workflows. Information systems engineering has generated several approaches to create software models reflecting these aspects. To obtain the necessary integration, the relations between the involved models must be expressed formally. Currently, this necessity is particularly evident in systems built to assist users in performing knowledge generation, such as scientific knowledge-management systems. Model-Driven Engineering provides some interoperability techniques for expressing inter-model relations. In this paper, a specific metamodel is proposed for integrating different modelling perspectives of software systems built for assisting users in knowledge generation. Furthermore, the integration metamodel is initially validated through its application to the integration of modelling perspectives of a system to assist knowledge generation in the cultural heritage domain. The integration metamodel proposed allows the system to make knowledge generation decisions by manipulating the relations between the involved models on behalf of the user.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>194</post_id>
		<post_date><![CDATA[2015-08-29 20:31:40]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 18:31:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[achieving-software-assisted-knowledge-generation-through-model-driven-interoperability]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="conceptual-modelling"><![CDATA[conceptual modelling]]></category>
		<category domain="post_tag" nicename="cultural-heritage"><![CDATA[cultural heritage]]></category>
		<category domain="post_tag" nicename="interoperability"><![CDATA[interoperability]]></category>
		<category domain="post_tag" nicename="knowledge-generation"><![CDATA[knowledge generation]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="software-assistance"><![CDATA[software assistance]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Patricia Martín-Rodilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ Institute of Heritage Sciences (Incipit), Spanish National Research Council (CSIC), Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[patricia.martin-rodilla@incipit.csic.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Giovanni Giachetti]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Facultad de Ingeniería, Universidad Andrés Bello, Santiago de Chile, Chile]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[giovanni.giachetti@unab.c]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Cesar Gonzalez-Perez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ Institute of Heritage Sciences (Incipit), Spanish National Research Council (CSIC), Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[cesar.gonzalez-perez@incipit.csic.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A software system is a complex artefact involving several aspects, such as requirements and behavioural workflows. Information systems engineering has generated several approaches to create software models reflecting these aspects. To obtain the necessary integration, the relations between the involved models must be expressed formally. Currently, this necessity is particularly evident in systems built to assist users in performing knowledge generation, such as scientific knowledge-management systems. Model-Driven Engineering provides some interoperability techniques for expressing inter-model relations. In this paper, a specific metamodel is proposed for integrating different modelling perspectives of software systems built for assisting users in knowledge generation. Furthermore, the integration metamodel is initially validated through its application to the integration of modelling perspectives of a system to assist knowledge generation in the cultural heritage domain. The integration metamodel proposed allows the system to make knowledge generation decisions by manipulating the relations between the involved models on behalf of the user.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[knowledge generation, interoperability, software assistance, MDE, conceptual modelling, cultural heritage]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[195]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/020]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Mediación semántica A* basada en MDE para la generación de arquitecturas en tiempo de ejecución</title>
		<link>https://biblioteca.sistedes.es/articulo/mediacion-semantica-a-basada-en-mde-para-la-generacion-de-arquitecturas-en-tiempo-de-ejecucion/</link>
		<pubDate>Sat, 29 Aug 2015 18:36:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=197</guid>
		<description></description>
		<content><![CDATA[Existen aplicaciones software que necesitan ser adaptadas en tiempo de ejecución debido a que los componentes que conforman su arquitectura no representan la configuración óptima. En estos casos, las arquitecturas deben ser reconfiguradas, por ejemplo, a˜nadiendo y eliminando componentes, o modificando las relaciones entre ellos. Este artículo presenta una propuesta para la generación de arquitecturas en tiempo de ejecución. Está enfocado en la descripción del proceso que ocurre desde que existe una definición de arquitectura que hay que resolver, hasta que se genera la mejor configuración que da solución a dicha arquitectura. Para construir dicha configuración, se utilizan técnicas de modelado, mecanismos de trading y un algoritmo de búsqueda A*. Dicho algoritmo hace uso de una heurística basada en la información sintáctica y semántica de los componentes. Como dominio de aplicación, se muestra un caso estudio para la generación de interfaces de usuario.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>197</post_id>
		<post_date><![CDATA[2015-08-29 20:36:09]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 18:36:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mediacion-semantica-a-basada-en-mde-para-la-generacion-de-arquitecturas-en-tiempo-de-ejecucion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="a"><![CDATA[A*]]></category>
		<category domain="post_tag" nicename="componentes"><![CDATA[Componentes]]></category>
		<category domain="post_tag" nicename="heuristica"><![CDATA[Heurística]]></category>
		<category domain="post_tag" nicename="m2m"><![CDATA[M2M]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="trading"><![CDATA[Trading]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Criado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Informática Aplicada, Universidad de Almería, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[javi.criado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Luis Iribarne]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Informática Aplicada, Universidad de Almería, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[luis.iribarne@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Nicolás Padilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Informática Aplicada, Universidad de Almería, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[npadilla@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Existen aplicaciones software que necesitan ser adaptadas en tiempo de ejecución debido a que los componentes que conforman su arquitectura no representan la configuración óptima. En estos casos, las arquitecturas deben ser reconfiguradas, por ejemplo, a˜nadiendo y eliminando componentes, o modificando las relaciones entre ellos. Este artículo presenta una propuesta para la generación de arquitecturas en tiempo de ejecución. Está enfocado en la descripción del proceso que ocurre desde que existe una definición de arquitectura que hay que resolver, hasta que se genera la mejor configuración que da solución a dicha arquitectura. Para construir dicha configuración, se utilizan técnicas de modelado, mecanismos de trading y un algoritmo de búsqueda A*. Dicho algoritmo hace uso de una heurística basada en la información sintáctica y semántica de los componentes. Como dominio de aplicación, se muestra un caso estudio para la generación de interfaces de usuario.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Componentes, Trading, Heurística, A*, MDE, M2M]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[198]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/019]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modular DSLs for flexible analysis: An e-Motions reimplementation of Palladio (High-level Work)</title>
		<link>https://biblioteca.sistedes.es/?post_type=articulo&#038;p=729</link>
		<pubDate>Mon, 30 Nov -0001 00:00:00 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=729</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>729</post_id>
		<post_date><![CDATA[2016-04-24 02:50:10]]></post_date>
		<post_date_gmt><![CDATA[0000-00-00 00:00:00]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[]]></post_name>
		<status><![CDATA[draft]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Boletín nº 1. Febrero de 2018</title>
		<link>https://biblioteca.sistedes.es/?post_type=articulo&#038;p=2805</link>
		<pubDate>Mon, 30 Nov -0001 00:00:00 +0000</pubDate>
		<creator><![CDATA[jhcanos]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/?post_type=articulo&#038;p=2805</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[Resumen de las noticias más destacables en los campos de actuación de la Comunidad SISTEDES]]></excerpt>
		<post_id>2805</post_id>
		<post_date><![CDATA[2018-03-01 18:42:12]]></post_date>
		<post_date_gmt><![CDATA[0000-00-00 00:00:00]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[]]></post_name>
		<status><![CDATA[draft]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SociAALML: Lenguaje de Modelado para Escenarios de Inteligencia Ambiental</title>
		<link>https://biblioteca.sistedes.es/articulo/sociaalml-lenguaje-de-modelado-para-escenarios-de-inteligencia-ambiental/</link>
		<pubDate>Sat, 29 Aug 2015 18:50:04 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=200</guid>
		<description></description>
		<content><![CDATA[El estudio y desarrollo de sistemas de inteligencia ambiental puede llegar a ser complejo y costoso, especialmente en fases avanzadas que se ejecutan en laboratorios vivientes (living labs). En la última década, los avances en tecnologías 3D permiten plantear entornos virtuales donde se puedan desplegar dispositivos y usuarios. Así se podría reducir costes y potenciar la investigación de este tipo de sistemas. En este trabajo se presenta SociAALML, un lenguaje específico de dominio para modelar escenarios de la vida cotidiana en el hogar, incluyendo el modelado de personas con Parkinson. Usando modelos creados con este lenguaje, se generan simuladores 3D que incluyen usuarios simulados, el propio entorno y los dispositivos que componen el sistema de inteligencia ambiental.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>200</post_id>
		<post_date><![CDATA[2015-08-29 20:50:04]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 18:50:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[sociaalml-lenguaje-de-modelado-para-escenarios-de-inteligencia-ambiental]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="inteligencia-ambiental"><![CDATA[Inteligencia Ambiental]]></category>
		<category domain="post_tag" nicename="modelado-de-la-actividad-diaria"><![CDATA[Modelado de la Actividad Diaria]]></category>
		<category domain="post_tag" nicename="modelado-de-parkinson"><![CDATA[Modelado de Parkinson]]></category>
		<category domain="post_tag" nicename="simulacion-dirigida-por-modelos"><![CDATA[Simulaci´on dirigida por modelos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Campillo-Sanchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Computense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pabcampi@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jorge J. Gómez-Sanz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Computense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jpavon@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Pavón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Computense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jjgomez@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El estudio y desarrollo de sistemas de inteligencia ambiental puede llegar a ser complejo y costoso, especialmente en fases avanzadas que se ejecutan en laboratorios vivientes (living labs). En la última década, los avances en tecnologías 3D permiten plantear entornos virtuales donde se puedan desplegar dispositivos y usuarios. Así se podría reducir costes y potenciar la investigación de este tipo de sistemas. En este trabajo se presenta SociAALML, un lenguaje específico de dominio para modelar escenarios de la vida cotidiana en el hogar, incluyendo el modelado de personas con Parkinson. Usando modelos creados con este lenguaje, se generan simuladores 3D que incluyen usuarios simulados, el propio entorno y los dispositivos que componen el sistema de inteligencia ambiental.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Simulaci´on dirigida por modelos, Inteligencia Ambiental, Modelado de la Actividad Diaria, Modelado de Parkinson]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Desrrollo de Software Dirigido por Modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[201]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/018]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Aplicando DSDM al Diseño, Implementación y Verificación de Software para Drones: Una Primera Aproximación</title>
		<link>https://biblioteca.sistedes.es/articulo/aplicando-dsdm-al-diseno-implementacion-y-verificacion-de-software-para-drones-una-primera-aproximacion/</link>
		<pubDate>Sat, 29 Aug 2015 18:53:55 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=203</guid>
		<description></description>
		<content><![CDATA[Hasta hace poco, el uso de sistemas de vuelo no tripulados (Unmanned Aerial Vehicles, UAV), también conocidos como drones, estaba limitado al campo militar. Sin embargo, en la actualidad, su uso en el ámbito civil y de la investigación prolifera con rapidez. En este artículo se presenta una primera aproximación al diseño de alto nivel tanto de la infraestructura (diseño físico) como de las misiones (diseño lógico) de los UAV utilizando un enfoque dirigido por modelos. El objetivo de este trabajo es ofrecer a los diseñadores un conjunto de herramientas que faciliten el diseño, la documentación y la implementación, así como la verificación temprana y formal de las restricciones físicas, lógicas y legales que deben guiar la construcción de estos sistemas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>203</post_id>
		<post_date><![CDATA[2015-08-29 20:53:55]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 18:53:55]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[aplicando-dsdm-al-diseno-implementacion-y-verificacion-de-software-para-drones-una-primera-aproximacion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="dron"><![CDATA[dron]]></category>
		<category domain="post_tag" nicename="dsdm"><![CDATA[DSDM]]></category>
		<category domain="post_tag" nicename="uav"><![CDATA[UAV]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Enrique Moguel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[QSEG, Escuela Politécnica de Cáceres, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[enrique@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Cristina Vicente-Chicote]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[QSEG, Escuela Politécnica de Cáceres, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cristinav@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[QSEG, Escuela Politécnica de Cáceres, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanher@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Carlos Preciado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[QSEG, Escuela Politécnica de Cáceres, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jcpreciado@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Fernando Sánchez-Figueroa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[QSEG, Escuela Politécnica de Cáceres, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[fernando@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Hasta hace poco, el uso de sistemas de vuelo no tripulados (Unmanned Aerial Vehicles, UAV), también conocidos como drones, estaba limitado al campo militar. Sin embargo, en la actualidad, su uso en el ámbito civil y de la investigación prolifera con rapidez. En este artículo se presenta una primera aproximación al diseño de alto nivel tanto de la infraestructura (diseño físico) como de las misiones (diseño lógico) de los UAV utilizando un enfoque dirigido por modelos. El objetivo de este trabajo es ofrecer a los diseñadores un conjunto de herramientas que faciliten el diseño, la documentación y la implementación, así como la verificación temprana y formal de las restricciones físicas, lógicas y legales que deben guiar la construcción de estos sistemas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[DSDM, dron, UAV]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Desrrollo de Software Dirigido por Modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[204]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/017]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Lenguaje específico del dominio para generación de aplicaciones de procesos administrativos</title>
		<link>https://biblioteca.sistedes.es/articulo/lenguaje-especifico-del-dominio-para-generacion-de-aplicaciones-de-procesos-administrativos/</link>
		<pubDate>Sat, 29 Aug 2015 18:57:03 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=206</guid>
		<description></description>
		<content><![CDATA[Muchas organizaciones reimplementan una y otra vez el mismo tipo de proceso de negocio «administrativo», en el que un formulario es manipulado por múltiples roles a lo largo de varios estados. Esta reimplementación hace perder un tiempo que se podría haber usado en entender mejor el proceso o cubrir los detalles que sí son específicos del proceso. Por otro lado, las soluciones existentes basadas en motores de procesos de negocio requieren formación e infraestructura específicas y pueden encerrar al usuario en una tecnología concreta. En este trabajo se propone usar un lenguaje de alto nivel para describir el proceso administrativo y producir a partir de él un sitio web en un marco estándar de desarrollo web que sea fácil de mantener por los técnicos de la organización. Se ha implementado el enfoque mediante tecnologías de código abierto, y se ilustra a través de un caso de estudio.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>206</post_id>
		<post_date><![CDATA[2015-08-29 20:57:03]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 18:57:03]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[lenguaje-especifico-del-dominio-para-generacion-de-aplicaciones-de-procesos-administrativos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio García Domínguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[antonio.garciadominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ismael Jerez Ibañez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ismael.jerezibanez@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Muchas organizaciones reimplementan una y otra vez el mismo tipo de proceso de negocio «administrativo», en el que un formulario es manipulado por múltiples roles a lo largo de varios estados. Esta reimplementación hace perder un tiempo que se podría haber usado en entender mejor el proceso o cubrir los detalles que sí son específicos del proceso. Por otro lado, las soluciones existentes basadas en motores de procesos de negocio requieren formación e infraestructura específicas y pueden encerrar al usuario en una tecnología concreta. En este trabajo se propone usar un lenguaje de alto nivel para describir el proceso administrativo y producir a partir de él un sitio web en un marco estándar de desarrollo web que sea fácil de mantener por los técnicos de la organización. Se ha implementado el enfoque mediante tecnologías de código abierto, y se ilustra a través de un caso de estudio.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Desrrollo de Software Dirigido por Modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[207]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/016]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Arquitectura basada en modelos para la generación de especificaciones textuales de requisitos a partir de procesos de negocio definidos mediante BPMN</title>
		<link>https://biblioteca.sistedes.es/articulo/arquitectura-basada-en-modelos-para-la-generacion-de-especificaciones-textuales-de-requisitos-a-partir-de-procesos-de-negocio-definidos-mediante-bpmn/</link>
		<pubDate>Sat, 29 Aug 2015 19:02:39 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=209</guid>
		<description></description>
		<content><![CDATA[En la ingeniería del software, la gestión de procesos de negocio (BPM) se suele aplicar para modelar y optimizar los procesos de negocio de un sistema. Junto con la Ingeniería de Requisitos (IR), constituye una base sobre la que especificar un sistema software. Sin embargo, a menudo existe una falta de alineación entre ambas especificaciones que repercute negativamente en el sistema. Este artículo presenta una arquitectura basada en modelos para la generación de especificaciones textuales de requisitos a partir de procesos de negocio representados mediante BPMN y su aplicación a un caso de estudio. El objetivo es agilizar y mejorar la etapa de análisis de un sistema software, generando un subconjunto de los requisitos del sistema para facilitar la escritura de una especificación completa y sincronizada con los procesos de negocio.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>209</post_id>
		<post_date><![CDATA[2015-08-29 21:02:39]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:02:39]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[arquitectura-basada-en-modelos-para-la-generacion-de-especificaciones-textuales-de-requisitos-a-partir-de-procesos-de-negocio-definidos-mediante-bpmn]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="generacion-de-requisitos-a-partir-de-procesos-de-negocio"><![CDATA[generación de requisitos a partir de procesos de negocio]]></category>
		<category domain="post_tag" nicename="generacion-de-requisitos-basada-en-modelos"><![CDATA[generación de requisitos basada en modelos]]></category>
		<category domain="post_tag" nicename="generacion-de-requisitos-textuales"><![CDATA[generación de requisitos textuales]]></category>
		<category domain="post_tag" nicename="transformacion-bpmn-requisitos"><![CDATA[transformación BPMN-requisitos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Manuel Cruz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación de Ingeniería del Software. Departamento de Informática y Sistemas. Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[josemanuel.cruz@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Begoña Moros Valle]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación de Ingeniería del Software. Departamento de Informática y Sistemas. Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[bmoros@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ambrosio Toval]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación de Ingeniería del Software. Departamento de Informática y Sistemas. Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[atoval@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En la ingeniería del software, la gestión de procesos de negocio (BPM) se suele aplicar para modelar y optimizar los procesos de negocio de un sistema. Junto con la Ingeniería de Requisitos (IR), constituye una base sobre la que especificar un sistema software. Sin embargo, a menudo existe una falta de alineación entre ambas especificaciones que repercute negativamente en el sistema. Este artículo presenta una arquitectura basada en modelos para la generación de especificaciones textuales de requisitos a partir de procesos de negocio representados mediante BPMN y su aplicación a un caso de estudio. El objetivo es agilizar y mejorar la etapa de análisis de un sistema software, generando un subconjunto de los requisitos del sistema para facilitar la escritura de una especificación completa y sincronizada con los procesos de negocio.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[transformación BPMN-requisitos, generación de requisitos textuales, generación de requisitos basada en modelos, generación de requisitos a partir de procesos de negocio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Desrrollo de Software Dirigido por Modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[210]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/015]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Analysis of the Scientific Production of the Spanish Software Engineering Community</title>
		<link>https://biblioteca.sistedes.es/articulo/analysis-of-the-scientific-production-of-the-spanish-software-engineering-community/</link>
		<pubDate>Sat, 29 Aug 2015 19:05:26 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=212</guid>
		<description></description>
		<content><![CDATA[Our group has been working on a report for the SpanishúSociety of Software Engineering and Software Development Technologies (SISTEDES) to provide a general overview of the Spanish scientificúproduction and its contributions worldwide in the field of Software Engineering. Although a Database solution could have been used, we decidedúto employ Model-Driven Development (MDD) techniques in order toúevaluate their applicability, suitability and fitness for these kinds of purposes, and to learn from the experience in this domain, which combinesúdata integration, large scale models, and complex queries.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>212</post_id>
		<post_date><![CDATA[2015-08-29 21:05:26]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:05:26]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analysis-of-the-scientific-production-of-the-spanish-software-engineering-community]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mdd"><![CDATA[MDD]]></category>
		<category domain="post_tag" nicename="scientific-contribution"><![CDATA[scientific contribution]]></category>
		<category domain="post_tag" nicename="sistedes"><![CDATA[SISTEDES]]></category>
		<category domain="post_tag" nicename="software-engineering"><![CDATA[software engineering]]></category>
		<category domain="post_tag" nicename="spain"><![CDATA[Spain]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Loli Burgueño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Atenea Research Group, Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[loli@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Moreno-Delgado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Atenea Research Group, Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[amoreno@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Vallecillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Atenea Research Group, Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[av@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Our group has been working on a report for the SpanishúSociety of Software Engineering and Software Development Technologies (SISTEDES) to provide a general overview of the Spanish scientificúproduction and its contributions worldwide in the field of Software Engineering. Although a Database solution could have been used, we decidedúto employ Model-Driven Development (MDD) techniques in order toúevaluate their applicability, suitability and fitness for these kinds of purposes, and to learn from the experience in this domain, which combinesúdata integration, large scale models, and complex queries.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[SISTEDES, scientific contribution, Spain, software engineering, MDD]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Desrrollo de Software Dirigido por Modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[213]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/014]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Desarrollo de una Línea de Productos Software utilizando las clases parciales C#: el patrón Slicer</title>
		<link>https://biblioteca.sistedes.es/articulo/desarrollo-de-una-linea-de-productos-software-utilizando-las-clases-parciales-c-el-patron-slicer/</link>
		<pubDate>Sat, 29 Aug 2015 19:10:13 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=217</guid>
		<description></description>
		<content><![CDATA[Las clases parciales de C# permiten dividir el comportamiento global de una clase en diversos fragmentos. Estos fragmentos pueden luego combinarse de diversas formas, produciendo clases completas con comportamientos similares pero ligeramente diferentes, en función de nuestras necesidades. La semejanza de este mecanismo con la programación orientada a características ha hecho que algunos autores hayan considerado las clases parciales de C# como un mecanismo apropiado para el desarrollo de líneas de productos de software. Sin embargo, un reciente estudio ha demostrado que las clases parciales de C# por sí solas no son suficientes para tal propósito, ya que presentan problemas a la hora de extender comportamientos preexistente. Para solventar dicha deficiencia, este artículo presenta un patrón, denominado Slicer Pattern, mediante el cual es posible implementar de forma completa diseños orientados a características en C# mediante clases parciales. La principal ventaja de dicho patrón es que permite utilizar el lenguaje C# como lenguaje orientado a características, sin necesidad de extender dicho lenguaje.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>217</post_id>
		<post_date><![CDATA[2015-08-29 21:10:13]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:10:13]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[desarrollo-de-una-linea-de-productos-software-utilizando-las-clases-parciales-c-el-patron-slicer]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="net"><![CDATA[.NET]]></category>
		<category domain="post_tag" nicename="clases-parciales-c"><![CDATA[Clases Parciales C#]]></category>
		<category domain="post_tag" nicename="desarrollo-software-orientado-a-caracteristicas"><![CDATA[Desarrollo Software Orientado a Características]]></category>
		<category domain="post_tag" nicename="linea-de-productos-software"><![CDATA[Línea de Productos Software]]></category>
		<category domain="post_tag" nicename="tente"><![CDATA[TENTE]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alejandro Pérez Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería Informática y Electrónica Universidad de Cantabria Santander (Cantabria), España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[perezruiza@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Sánchez Barreiro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería Informática y Electrónica Universidad de Cantabria Santander (Cantabria), España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[p.sanchez@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las clases parciales de C# permiten dividir el comportamiento global de una clase en diversos fragmentos. Estos fragmentos pueden luego combinarse de diversas formas, produciendo clases completas con comportamientos similares pero ligeramente diferentes, en función de nuestras necesidades. La semejanza de este mecanismo con la programación orientada a características ha hecho que algunos autores hayan considerado las clases parciales de C# como un mecanismo apropiado para el desarrollo de líneas de productos de software. Sin embargo, un reciente estudio ha demostrado que las clases parciales de C# por sí solas no son suficientes para tal propósito, ya que presentan problemas a la hora de extender comportamientos preexistente. Para solventar dicha deficiencia, este artículo presenta un patrón, denominado Slicer Pattern, mediante el cual es posible implementar de forma completa diseños orientados a características en C# mediante clases parciales. La principal ventaja de dicho patrón es que permite utilizar el lenguaje C# como lenguaje orientado a características, sin necesidad de extender dicho lenguaje.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Línea de Productos Software, Desarrollo Software Orientado a Características, TENTE, Clases Parciales C#, .NET]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Arquitecturas Software y Variabilidad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[219]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/027]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Propuesta para un acceso homogéneo a servicios PaaS en la Nube</title>
		<link>https://biblioteca.sistedes.es/articulo/propuesta-para-un-acceso-homogeneo-a-servicios-paas-en-la-nube/</link>
		<pubDate>Sat, 29 Aug 2015 19:15:11 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=221</guid>
		<description></description>
		<content><![CDATA[En el ámbito del Cloud Computing existen multitud de proveedores ofreciendo plataformas como un servicio, que proporcionan un conjunto de funcionalidades para apoyar el ciclo de vida completo de una aplicación, desde su desarrollo hasta el despliegue en la nube (incluso abordando la monitorización en ocasiones). Aunque la existencia de un número elevado de proveedores aumenta y enriquece la potencia de este tipo de servicios, el inconveniente surge cuando cada uno de ellos define servicios distintos, dando lugar a la problemática de la dependencia del vendedor o vendor lock-in. Esta variabilidad complica la selección y uso de los distintos proveedores, ya que cada uno de ellos especifica sus propios conceptos para el modelado de las aplicaciones y de los servicios requeridos durante el despliegue y ejecución de las mismas. En este trabajo, proponemos las bases para la descripción, tanto de las plataformas cloud como de las aplicaciones a desplegar, con el fin de generar una capa de homogeneización capaz de abstraer la interfaz de los servicios ofertados por las distintas plataformas, haciendo uso de una API unificada. Esto facilitará el manejo y selección de los servicios de los distintos proveedores. Para ilustrar la idea, se presenta un escenario de aplicación de chat usando servicios de plataformas cloud.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>221</post_id>
		<post_date><![CDATA[2015-08-29 21:15:11]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:15:11]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[propuesta-para-un-acceso-homogeneo-a-servicios-paas-en-la-nube]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cloud-computing"><![CDATA[Cloud Computing]]></category>
		<category domain="post_tag" nicename="computacion-en-la-nube"><![CDATA[Computación en la Nube]]></category>
		<category domain="post_tag" nicename="homegeneidad"><![CDATA[Homegeneidad]]></category>
		<category domain="post_tag" nicename="plataformas-cloud"><![CDATA[Plataformas Cloud]]></category>
		<category domain="post_tag" nicename="platform-as-a-service"><![CDATA[Platform-as-a-Service]]></category>
		<category domain="post_tag" nicename="unificacion"><![CDATA[Unificación]]></category>
		<category domain="post_tag" nicename="variabilidad"><![CDATA[Variabilidad]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel Barrientos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mbarrientos@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose Carrasco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[josec@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Cubo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[cubo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ernesto Pimentel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[ernesto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En el ámbito del Cloud Computing existen multitud de proveedores ofreciendo plataformas como un servicio, que proporcionan un conjunto de funcionalidades para apoyar el ciclo de vida completo de una aplicación, desde su desarrollo hasta el despliegue en la nube (incluso abordando la monitorización en ocasiones). Aunque la existencia de un número elevado de proveedores aumenta y enriquece la potencia de este tipo de servicios, el inconveniente surge cuando cada uno de ellos define servicios distintos, dando lugar a la problemática de la dependencia del vendedor o vendor lock-in. Esta variabilidad complica la selección y uso de los distintos proveedores, ya que cada uno de ellos especifica sus propios conceptos para el modelado de las aplicaciones y de los servicios requeridos durante el despliegue y ejecución de las mismas. En este trabajo, proponemos las bases para la descripción, tanto de las plataformas cloud como de las aplicaciones a desplegar, con el fin de generar una capa de homogeneización capaz de abstraer la interfaz de los servicios ofertados por las distintas plataformas, haciendo uso de una API unificada. Esto facilitará el manejo y selección de los servicios de los distintos proveedores. Para ilustrar la idea, se presenta un escenario de aplicación de chat usando servicios de plataformas cloud.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Computación en la Nube, Cloud Computing, Plataformas Cloud, Platform-as-a-Service, Variabilidad,Homegeneidad,Unificación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Arquitecturas Software y Variabilidad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[222]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/026]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Exploring the Synergies between Join Point Interfaces and Feature-Oriented Programming</title>
		<link>https://biblioteca.sistedes.es/articulo/exploring-the-synergies-between-join-point-interfaces-and-feature-oriented-programming/</link>
		<pubDate>Sat, 29 Aug 2015 19:18:34 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=224</guid>
		<description></description>
		<content><![CDATA[Feature-oriented programming FOP, and aspect-oriented programming AOP have been used to develop modular software product lines SPL. Both approaches focus on modularizing classes behavior and crosscutting concerns CC. Therefore, the symbiosis of FOP and AOP would permit reaching pros and cons of both software development approaches. Concretely, FOP permits a modular refinement of classes collaboration for software product lines SPL -an adequate structural representation of heterogeneous CC, but FOP does not well represent homogeneous CC. On the other hand, traditional AOP structurally well modularizes homogeneous CC, but aspects are not adequate to represent collaboration of classes for software evolution. In addition, AOP solutions present implicit dependencies and strong coupling between classes and aspects. Since Join Point Interface JPI solves mentioned AOP issues, this paper present JPI Feature Modules to represent and modularize the structure of FOP and JPI SPL instances, i.e., classes and join point interfaces for a transparent implementation in a FOP and JPI context. This paper, highlights benefits of a FOP and JPI symbiosis for the modular software conception using a case study to exemplify its use.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>224</post_id>
		<post_date><![CDATA[2015-08-29 21:18:34]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:18:34]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[exploring-the-synergies-between-join-point-interfaces-and-feature-oriented-programming]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="classic-aop"><![CDATA[classic AOP]]></category>
		<category domain="post_tag" nicename="fop"><![CDATA[FOP]]></category>
		<category domain="post_tag" nicename="jpi"><![CDATA[JPI]]></category>
		<category domain="post_tag" nicename="jpi-fm"><![CDATA[JPI-FM]]></category>
		<category domain="post_tag" nicename="modular-software"><![CDATA[modular software]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cristian Vidal Silva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Computaci´on e Inform´atica Facultad de Ingenier´ıa, Universidad de Playa Ancha Av. Leopoldo Bertossi 270, Playa Ancha, Valpara´ıso, Chile]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cristian.vidal@upla.cl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David Benavides]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville Av. de la Reina Mercedes S/N, 41012 Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[benavides@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José Angel Galindo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[INRIA Renes, France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jagalindo@inria.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Paul Leger]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Escuela de Ciencias Empresariales Universidad Católica del Norte Coquimbo, Chile]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[pleger@ucn.cl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Feature-oriented programming FOP, and aspect-oriented programming AOP have been used to develop modular software product lines SPL. Both approaches focus on modularizing classes behavior and crosscutting concerns CC. Therefore, the symbiosis of FOP and AOP would permit reaching pros and cons of both software development approaches. Concretely, FOP permits a modular refinement of classes collaboration for software product lines SPL -an adequate structural representation of heterogeneous CC, but FOP does not well represent homogeneous CC. On the other hand, traditional AOP structurally well modularizes homogeneous CC, but aspects are not adequate to represent collaboration of classes for software evolution. In addition, AOP solutions present implicit dependencies and strong coupling between classes and aspects. Since Join Point Interface JPI solves mentioned AOP issues, this paper present JPI Feature Modules to represent and modularize the structure of FOP and JPI SPL instances, i.e., classes and join point interfaces for a transparent implementation in a FOP and JPI context. This paper, highlights benefits of a FOP and JPI symbiosis for the modular software conception using a case study to exemplify its use.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[FOP, classic AOP, JPI, modular software, JPI-FM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Arquitecturas Software y Variabilidad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/025]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Análisis de las soluciones guiadas por búsqueda para el problema de selección de requisitos</title>
		<link>https://biblioteca.sistedes.es/articulo/analisis-de-las-soluciones-guiadas-por-busqueda-para-el-problema-de-seleccion-de-requisitos/</link>
		<pubDate>Sat, 29 Aug 2015 19:28:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=230</guid>
		<description></description>
		<content><![CDATA[La Ingeniería del Software guiada por búsqueda propone la utilización de algoritmos de optimización en los problemas de Ingeniería del Software. Este área de investigación ha sido muy prolífica durante los últimos a˜nos, formulando y dando soluciones a problemas de optimización multiobjetivo, como el de la selección de requisitos. Pero cuando los desarrolladores de software tienen que tomar la última decisión acerca de cuál es el conjunto de requisitos a implementar, de entre las soluciones ofrecidas por los métodos multiobjetivo, necesitan revisar y analizar una gran cantidad de datos. Para ayudar en este proceso de toma de decisiones, este trabajo propone un conjunto de indicadores de calidad que facilitan el análisis del problema a nivel de requisitos, soluciones y clientes. El proceso de análisis utilizado combina estos indicadores de calidad con resúmenes estadísticos y visualización de datos. El caso de estudio abordado muestra la forma en la que el proceso de análisis ayuda en la definición de criterios de selección de soluciones, apoyándose en el estudio y visualización de los indicadores de calidad propuestos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>230</post_id>
		<post_date><![CDATA[2015-08-29 21:28:02]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:28:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analisis-de-las-soluciones-guiadas-por-busqueda-para-el-problema-de-seleccion-de-requisitos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software-guiada-por-busqueda"><![CDATA[Ingeniería del Software guiada por búsqueda]]></category>
		<category domain="post_tag" nicename="optimos-de-pareto"><![CDATA[óptimos de Pareto]]></category>
		<category domain="post_tag" nicename="problema-de-seleccion-de-requisitos"><![CDATA[problema de selección de requisitos]]></category>
		<category domain="post_tag" nicename="procesos-de-toma-de-decisiones"><![CDATA[procesos de toma de decisiones]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Isabel María del Aguila]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad of Almería, Crtra. de la Playa s/n, 04120 Almería, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[imaguila@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José del Sagrado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad of Almería, Crtra. de la Playa s/n, 04120 Almería, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jsagrado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alfonso Bosch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad of Almería, Crtra. de la Playa s/n, 04120 Almería, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[abosch@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La Ingeniería del Software guiada por búsqueda propone la utilización de algoritmos de optimización en los problemas de Ingeniería del Software. Este área de investigación ha sido muy prolífica durante los últimos a˜nos, formulando y dando soluciones a problemas de optimización multiobjetivo, como el de la selección de requisitos. Pero cuando los desarrolladores de software tienen que tomar la última decisión acerca de cuál es el conjunto de requisitos a implementar, de entre las soluciones ofrecidas por los métodos multiobjetivo, necesitan revisar y analizar una gran cantidad de datos. Para ayudar en este proceso de toma de decisiones, este trabajo propone un conjunto de indicadores de calidad que facilitan el análisis del problema a nivel de requisitos, soluciones y clientes. El proceso de análisis utilizado combina estos indicadores de calidad con resúmenes estadísticos y visualización de datos. El caso de estudio abordado muestra la forma en la que el proceso de análisis ayuda en la definición de criterios de selección de soluciones, apoyándose en el estudio y visualización de los indicadores de calidad propuestos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Ingeniería del Software guiada por búsqueda, problema de selección de requisitos, óptimos de Pareto, procesos de toma de decisiones]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Ingeniería del Software Guiada por Búsqueda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[231]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/033]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Resolviendo un problema multi-objetivo de selección de requisitos mediante resolutores del problema SAT</title>
		<link>https://biblioteca.sistedes.es/articulo/resolviendo-un-problema-multi-objetivo-de-seleccion-de-requisitos-mediante-resolutores-del-problema-sat/</link>
		<pubDate>Sat, 29 Aug 2015 19:33:31 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=233</guid>
		<description></description>
		<content><![CDATA[El problema de selección de requisitos (o Next Release Problem, NRP) consiste en seleccionar el subconjunto de requisitos que se va a desarrollar en la siguiente versión de una aplicación software. Esta selección se debe hacer de tal forma que maximice la satisfacción de las partes interesadas a la vez que se minimiza el esfuerzo empleado en el desarrollo y se cumplen un conjunto de restricciones. Este es un problema de optimización combinatorio multi-objetivo para el que se han utilizado en el pasado técnicas heurísticas y metaheurísticas en su resolución, ya que es NP-difícil. En el presente trabajo proponemos la traducción de este problema a lógica proposicional y el uso de resolutores del problema SAT en una estrategia para encontrar el frente de Pareto de forma exacta.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>233</post_id>
		<post_date><![CDATA[2015-08-29 21:33:31]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:33:31]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[resolviendo-un-problema-multi-objetivo-de-seleccion-de-requisitos-mediante-resolutores-del-problema-sat]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="next-release-problem"><![CDATA[next release problem]]></category>
		<category domain="post_tag" nicename="optimizacion-multi-objetivo"><![CDATA[optimización multi-objetivo]]></category>
		<category domain="post_tag" nicename="resolutores-sat"><![CDATA[resolutores SAT]]></category>
		<category domain="post_tag" nicename="seleccion-de-requisitos"><![CDATA[Selección de requisitos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Isabel María del Aguila]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Almería, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[imaguila@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José del Sagrado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Almería, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jsagrado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco Chicano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[chicano@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Enrique Alba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[eat@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El problema de selección de requisitos (o Next Release Problem, NRP) consiste en seleccionar el subconjunto de requisitos que se va a desarrollar en la siguiente versión de una aplicación software. Esta selección se debe hacer de tal forma que maximice la satisfacción de las partes interesadas a la vez que se minimiza el esfuerzo empleado en el desarrollo y se cumplen un conjunto de restricciones. Este es un problema de optimización combinatorio multi-objetivo para el que se han utilizado en el pasado técnicas heurísticas y metaheurísticas en su resolución, ya que es NP-difícil. En el presente trabajo proponemos la traducción de este problema a lógica proposicional y el uso de resolutores del problema SAT en una estrategia para encontrar el frente de Pareto de forma exacta.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Selección de requisitos, next release problem, optimización multi-objetivo, resolutores SAT]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Ingeniería del Software Guiada por Búsqueda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[234]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/032]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>TESTAR - from academic protoype towards an industry-ready tool for automated testing at the User Interface level</title>
		<link>https://biblioteca.sistedes.es/articulo/testar-from-academic-protoype-towards-an-industry-ready-tool-for-automated-testing-at-the-user-interface-level/</link>
		<pubDate>Sat, 29 Aug 2015 19:37:20 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=236</guid>
		<description></description>
		<content><![CDATA[Testing applications with a Graphical User Interface (GUI) is an important, though challenging and time consuming task. The state of the art in the industry are still capture and replay tools, which may simplify the recording and execution of input sequences, but do not support the tester in finding fault-sensitive test cases and leads to a huge overhead on maintenance of the test cases when the GUI changes. While search-based test case generation strategies are well researched for various areas of testing, relatively little work has been done on applying these techniques to an entire GUI of an application. In this paper we present the tool TESTAR, an automated search-based approach to test applications at the GUI level whose objective is to solve part of the maintenance problem by automatically generating test cases based on a structure that is automatically derived from the GUI.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>236</post_id>
		<post_date><![CDATA[2015-08-29 21:37:20]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:37:20]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[testar-from-academic-protoype-towards-an-industry-ready-tool-for-automated-testing-at-the-user-interface-level]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="automated"><![CDATA[Automated]]></category>
		<category domain="post_tag" nicename="search-based"><![CDATA[Search-Based]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<category domain="post_tag" nicename="user-interface-level"><![CDATA[User Interface level]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Urko Rueda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Valencia, Spain, Camino de vera s/n, 46022 Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[urueda@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Tanja E.J. Vos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Valencia, Spain, Camino de vera s/n, 46022 Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[tvos@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco Almenar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Valencia, Spain, Camino de vera s/n, 46022 Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fraalpe2@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Mirella Oreto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Valencia, Spain, Camino de vera s/n, 46022 Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mimarmu1@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Anna Esparcia Alcazar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Valencia, Spain, Camino de vera s/n, 46022 Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aesparcia@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Testing applications with a Graphical User Interface (GUI) is an important, though challenging and time consuming task. The state of the art in the industry are still capture and replay tools, which may simplify the recording and execution of input sequences, but do not support the tester in finding fault-sensitive test cases and leads to a huge overhead on maintenance of the test cases when the GUI changes. While search-based test case generation strategies are well researched for various areas of testing, relatively little work has been done on applying these techniques to an entire GUI of an application. In this paper we present the tool TESTAR, an automated search-based approach to test applications at the GUI level whose objective is to solve part of the maintenance problem by automatically generating test cases based on a structure that is automatically derived from the GUI.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Automated, Search-Based, Testing, User Interface level]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Ingeniería del Software Guiada por Búsqueda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[237]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/031]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>People as a Service y la Ingeniería del Software Guiada por Búsqueda</title>
		<link>https://biblioteca.sistedes.es/articulo/people-as-a-service-y-la-ingenieria-del-software-guiada-por-busqueda/</link>
		<pubDate>Sat, 29 Aug 2015 19:45:21 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=239</guid>
		<description></description>
		<content><![CDATA[People as a Service es un nuevo paradigma de computación centrada en los dispositivos móviles que permite generar perfiles sociológicos de sus due˜nos y proporcionarlos como servicios de forma segura desde los propios dispositivos. Dentro de este paradigma, la Ingeniería del Software Guiada por Búsqueda proporciona aportaciones relevantes en dos áreas. Por una parte, las nuevas arquitecturas software habilitadas por el paradigma de People as a Service, facilitan el desarrollo de un nuevo tipo de aplicaciones móviles en el que los dispositivos sean usados como agentes de un sistema de inteligencia de . Por otra parte, la implementación de este paradigma, con las restricciones impuestas por los sistemas operativos móviles actuales, se enfrenta a una serie de limitaciones que pueden ser abordadas aplicando técnicas de Ingeniería del Software Guiada por Búsqueda. En este trabajo se exploran las posibles aplicaciones de estas técnicas dentro del paradigma de People as a Service y se establecen los próximos pasos a seguir en esta línea.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>239</post_id>
		<post_date><![CDATA[2015-08-29 21:45:21]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:45:21]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[people-as-a-service-y-la-ingenieria-del-software-guiada-por-busqueda]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software-guiada-por-busqueda"><![CDATA[Ingeniería del Software guiada por búsqueda]]></category>
		<category domain="post_tag" nicename="inteligencia-de-enjambre"><![CDATA[Inteligencia de enjambre]]></category>
		<category domain="post_tag" nicename="people-as-a-service"><![CDATA[People as a Service]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jose Garcia-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[People as a Service es un nuevo paradigma de computación centrada en los dispositivos móviles que permite generar perfiles sociológicos de sus due˜nos y proporcionarlos como servicios de forma segura desde los propios dispositivos. Dentro de este paradigma, la Ingeniería del Software Guiada por Búsqueda proporciona aportaciones relevantes en dos áreas. Por una parte, las nuevas arquitecturas software habilitadas por el paradigma de People as a Service, facilitan el desarrollo de un nuevo tipo de aplicaciones móviles en el que los dispositivos sean usados como agentes de un sistema de inteligencia de  . Por otra parte, la implementación de este paradigma, con las restricciones impuestas por los sistemas operativos móviles actuales, se enfrenta a una serie de limitaciones que pueden ser abordadas aplicando técnicas de Ingeniería del Software Guiada por Búsqueda. En este trabajo se exploran las posibles aplicaciones de estas técnicas dentro del paradigma de People as a Service y se establecen los próximos pasos a seguir en esta línea. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[People as a Service, Ingeniería del Software Guiada por Búsqueda, Inteligencia de enjambre ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Ingeniería del Software Guiada por Búsqueda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[240]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/030]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Interactividad en el descubrimiento evolutivo de arquitecturas</title>
		<link>https://biblioteca.sistedes.es/articulo/interactividad-en-el-descubrimiento-evolutivo-de-arquitecturas/</link>
		<pubDate>Sat, 29 Aug 2015 19:48:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=242</guid>
		<description></description>
		<content><![CDATA[Resolver tareas propias del dise˜no arquitectónico de manera automática es un reto complejo, puesto que los arquitectos cuentan con habilidades que difícilmente pueden simularse y son capaces, además, de mantener una visión global de la actividad que realizan. Por su parte, la ingeniería del software basada en búsqueda está demostrando que las técnicas metaheurísticas son útiles cuando se desea prestar apoyo al ingeniero, especialmente cuando éste puede intervenir activamente en el proceso. Este trabajo analiza los retos que plantea esta colaboración a la hora de desarrollar modelos metaheurísticos para resolver tareas en una fase temprana del software como es el dise˜no arquitectónico. Se estudian aspectos como el papel del ingeniero y los criterios que van a guiar su intervención durante la búsqueda, sirviendo como paso previo para la propuesta de un modelo inicial con el que abordar el descubrimiento de arquitecturas software mediante un algoritmo evolutivo interactivo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>242</post_id>
		<post_date><![CDATA[2015-08-29 21:48:48]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:48:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[interactividad-en-el-descubrimiento-evolutivo-de-arquitecturas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="algoritmos-evolutivos"><![CDATA[algoritmos evolutivos]]></category>
		<category domain="post_tag" nicename="dise%cb%9cno-arquitectonico"><![CDATA[Dise˜no arquitectónico]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software-basada-en-busqueda"><![CDATA[ingeniería del software basada en búsqueda]]></category>
		<category domain="post_tag" nicename="interactividad"><![CDATA[interactividad]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aurora Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico Universidad de Córdoba, Campus de Rabanales, 14071 Córdoba, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aramirez@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Raúl Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico Universidad de Córdoba, Campus de Rabanales, 14071 Córdoba, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sebastián Ventura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico Universidad de Córdoba, Campus de Rabanales, 14071 Córdoba, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ sventura@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resolver tareas propias del dise˜no arquitectónico de manera automática es un reto complejo, puesto que los arquitectos cuentan con habilidades que difícilmente pueden simularse y son capaces, además, de mantener una visión global de la actividad que realizan. Por su parte, la ingeniería del software basada en búsqueda está demostrando que las técnicas metaheurísticas son útiles cuando se desea prestar apoyo al ingeniero, especialmente cuando éste puede intervenir activamente en el proceso. Este trabajo analiza los retos que plantea esta colaboración a la hora de desarrollar modelos metaheurísticos para resolver tareas en una fase temprana del software como es el dise˜no arquitectónico. Se estudian aspectos como el papel del ingeniero y los criterios que van a guiar su intervención durante la búsqueda, sirviendo como paso previo para la propuesta de un modelo inicial con el que abordar el descubrimiento de arquitecturas software mediante un algoritmo evolutivo interactivo. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Dise˜no arquitectónico, ingeniería del software basada en búsqueda, algoritmos evolutivos, interactividad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Ingeniería del Software Guiada por Búsqueda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[243]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/029]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Análisis y determinación del impacto del operador de mutación en la generación genética de casos de prueba para WS-BPEL</title>
		<link>https://biblioteca.sistedes.es/articulo/analisis-y-determinacion-del-impacto-del-operador-de-mutacion-en-la-generacion-genetica-de-casos-de-prueba-para-ws-bpel/</link>
		<pubDate>Sat, 29 Aug 2015 19:55:40 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=245</guid>
		<description></description>
		<content><![CDATA[La prueba basada en búsqueda permite generar casos de prueba automáticamente mediante la codificación de un criterio de cobertura como una función de aptitud que guía la búsqueda. Los algoritmos genéticos se han aplicado con éxito a este tipo de prueba utilizando principalmente criterios de cobertura estructural. Este trabajo presenta el análisis realizado para mejorar el comportamiento del generador de casos de prueba Rodan, que emplea un algoritmo genético para generar casos de prueba que matan mutantes producidos a partir de composiciones WS-BPEL. Se presentan los resultados obtenidos sobre un caso de estudio clásico en la literatura de prueba (un clasificador de triángulos) para tres operadores de mutación, con siembra y sin ella, y con distintos tamaños del espacio de búsqueda. Estos resultados se comparan con los obtenidos mediante generación aleatoria de casos de prueba.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>245</post_id>
		<post_date><![CDATA[2015-08-29 21:55:40]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 19:55:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analisis-y-determinacion-del-impacto-del-operador-de-mutacion-en-la-generacion-genetica-de-casos-de-prueba-para-ws-bpel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonia Estero-Botaro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Avenida de la Universidad de Cádiz, 10, 11519, Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[antonia.estero@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Álvaro Cortijo-García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Avenida de la Universidad de Cádiz, 10, 11519, Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[alvaro.cortijogarcia@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio García-Domínguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Avenida de la Universidad de Cádiz, 10, 11519, Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[antonio.garciadominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Francisco Palomo-Lozano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Avenida de la Universidad de Cádiz, 10, 11519, Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[francisco.palomo@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Juan José Domínguez-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Avenida de la Universidad de Cádiz, 10, 11519, Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[juanjose.dominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz C/Avenida de la Universidad de Cádiz, 10, 11519, Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La prueba basada en búsqueda permite generar casos de prueba automáticamente mediante la codificación de un criterio de cobertura como una función de aptitud que guía la búsqueda. Los algoritmos genéticos se han aplicado con éxito a este tipo de prueba utilizando principalmente criterios de cobertura estructural. Este trabajo presenta el análisis realizado para mejorar el comportamiento del generador de casos de prueba Rodan, que emplea un algoritmo genético para generar casos de prueba que matan mutantes producidos a partir de composiciones WS-BPEL. Se presentan los resultados obtenidos sobre un caso de estudio clásico en la literatura de prueba (un clasificador de triángulos) para tres operadores de mutación, con siembra y sin ella, y con distintos tamaños del espacio de búsqueda. Estos resultados se comparan con los obtenidos mediante generación aleatoria de casos de prueba.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Ingeniería del Software Guiada por Búsqueda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[246]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/028]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un entorno de gestión de casos para la resolución  flexible de emergencias</title>
		<link>https://biblioteca.sistedes.es/articulo/un-entorno-de-gestion-de-casos-para-la-resolucion-flexible-de-emergencias/</link>
		<pubDate>Sat, 29 Aug 2015 23:06:31 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=250</guid>
		<description></description>
		<content><![CDATA[Los lenguajes basados en procesos han sido utilizados durante la última década para modelar procedimientos de respuesta a situaciones de emergencia. La validez práctica y operativa de tales modelos depende de la capacidad de los mismos para manejar contingencias y situaciones excepcionales durante la respuesta a emergencias. Estos modelos proporcionan una flexibilidad limitada, ya que suelen tener únicamente en cuenta un número pequeño de variaciones y excepciones, donde los participantes en el proceso tienen poca libertad para decidir qué debería hacerse en cada momento. La gestión flexible de casos (Adaptive Case Management, ACM) es una aproximación nueva que se utiliza para gestionar procesos intensivos en conocimiento. ACM permite a los participantes en un proceso gestionar situaciones donde el nivel de flexibilidad es más avanzado que el proporcionado por los procesos clásicos. ACM supone un salto desde los modelos de procesos estructurados, de naturaleza imperativa, a modelos fuertemente declarativos. En este trabajo presentamos una extensión al módulo de ejecución de planes de emergencia de SAGA (Sistema de Apoyo a la Gestión de la Autoprotección), un marco para la gestión de planes de emergencia, para permitir la ejecución de planes modelados con un lenguaje de gestión de casos. De manera adicional hemos enriquecido, mediante la Arquitectura de Objetos Digitales, el módulo de definición de planes de SAGA para que el motor de ejecución pueda proporcionar a los participantes todos los recursos de información necesarios para llevar a cabo una tarea de respuesta.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>250</post_id>
		<post_date><![CDATA[2015-08-30 01:06:31]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 23:06:31]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-entorno-de-gestion-de-casos-para-la-resolucion-flexible-de-emergencias]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="gestion-de-casos"><![CDATA[gestión de casos]]></category>
		<category domain="post_tag" nicename="objetos-digitales"><![CDATA[objetos digitales]]></category>
		<category domain="post_tag" nicename="planes-de-emergencia"><![CDATA[planes de emergencia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan Sánchez Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ISSI-DSIC Universitat Politècnica de València Camino de Vera s/n. 46022 Valencia. España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jsanchez@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Carsí Cubel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ISSI-DSIC Universitat Politècnica de València Camino de Vera s/n. 46022 Valencia. España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pcarsi@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[M. Carmen Penadés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ISSI-DSIC Universitat Politècnica de València Camino de Vera s/n. 46022 Valencia. España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mpenades@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los lenguajes basados en procesos han sido utilizados durante la última década para modelar procedimientos de respuesta a situaciones de emergencia. La validez práctica y operativa de tales modelos depende de la capacidad de los mismos para manejar contingencias y situaciones excepcionales durante la respuesta a emergencias. Estos modelos proporcionan una flexibilidad limitada, ya que suelen tener únicamente en cuenta un número pequeño de variaciones y excepciones, donde los participantes en el proceso tienen poca libertad para decidir qué debería hacerse en cada momento. La gestión flexible de casos (Adaptive Case Management, ACM) es una aproximación nueva que se utiliza para gestionar procesos intensivos en conocimiento. ACM permite a los participantes en un proceso gestionar situaciones donde el nivel de flexibilidad es más avanzado que el proporcionado por los procesos clásicos. ACM supone un salto desde los modelos de procesos estructurados, de naturaleza imperativa, a modelos fuertemente declarativos. En este trabajo presentamos una extensión al módulo de ejecución de planes de emergencia de SAGA (Sistema de Apoyo a la Gestión de la Autoprotección), un marco para la gestión de planes de emergencia, para permitir la ejecución de planes modelados con un lenguaje de gestión de casos. De manera adicional hemos enriquecido, mediante la Arquitectura de Objetos Digitales, el módulo de definición de planes de SAGA para que el motor de ejecución pueda proporcionar a los participantes todos los recursos de información necesarios para llevar a cabo una tarea de respuesta.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[planes de emergencia, gestión de casos, objetos digitales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Open]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[251]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/035]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>KVLEAP: Interacción sin contacto (touchless) con ordenadores</title>
		<link>https://biblioteca.sistedes.es/articulo/kvleap-interaccion-sin-contacto-touchless-con-ordenadores/</link>
		<pubDate>Sat, 29 Aug 2015 23:12:14 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=254</guid>
		<description></description>
		<content><![CDATA[Hoy en día existen diferentes alternativas para interactuar con los ordenadores. Las más extendidas y utilizadas son el teclado, el ratón o la pantalla táctil, aunque en los tres casos resulta necesario que las manos del usuario entren en contacto con algún dispositivo. Sin embargo, en determinadas circunstancias en las que la higiene de las manos es un factor importante, puede suponer un inconveniente. Mostraremos una aplicación, KVLEAP, que usando el controlador Leap Motion, un dispositivo que detecta y rastrea la posición y los movimientos de las manos en el aire, permite interactuar con un ordenador sin que las manos del usuario tengan que entrar en contacto con ningún dispositivo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>254</post_id>
		<post_date><![CDATA[2015-08-30 01:12:14]]></post_date>
		<post_date_gmt><![CDATA[2015-08-29 23:12:14]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[kvleap-interaccion-sin-contacto-touchless-con-ordenadores]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="captura-de-movimiento"><![CDATA[Captura de movimiento]]></category>
		<category domain="post_tag" nicename="interaccion-touchless"><![CDATA[Interacción touchless]]></category>
		<category domain="post_tag" nicename="leap-motion"><![CDATA[Leap Motion]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[K. Villalobos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática UPV/EHU, Pº Manuel Lardizabal, 1 - 20018 Donostia-San Sebastián]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[kvillalobos001@ikasle.ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[D. Antón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática UPV/EHU, Pº Manuel Lardizabal, 1 - 20018 Donostia-San Sebastián]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[A. Goñi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática UPV/EHU, Pº Manuel Lardizabal, 1 - 20018 Donostia-San Sebastián]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[A. Illarramendi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática UPV/EHU, Pº Manuel Lardizabal, 1 - 20018 Donostia-San Sebastián]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Hoy en día existen diferentes alternativas para interactuar con los ordenadores. Las más extendidas y utilizadas son el teclado, el ratón o la pantalla táctil, aunque en los tres casos resulta necesario que las manos del usuario entren en contacto con algún dispositivo. Sin embargo, en determinadas circunstancias en las que la higiene de las manos es un factor importante, puede suponer un inconveniente. Mostraremos una aplicación, KVLEAP, que usando el controlador Leap Motion, un dispositivo que detecta y rastrea la posición y los movimientos de las manos en el aire, permite interactuar con un ordenador sin que las manos del usuario tengan que entrar en contacto con ningún dispositivo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Captura de movimiento, Leap Motion, Interacción touchless]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Open]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[255]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2015/034]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>BETaaS: A Distributed Platform for Things as a Service</title>
		<link>https://biblioteca.sistedes.es/articulo/betaas-a-distributed-platform-for-things-as-a-service/</link>
		<pubDate>Tue, 01 Sep 2015 00:58:22 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=316</guid>
		<description></description>
		<content><![CDATA[Internet of Things (IoT) has become an important research topic during the last years due to the increasing number of devices, sensors and actuators available, and the expected trends in the availability of these elements. BETaaS aims at providing a horizontal solution which will facilitate things management, exploiting their full potential and providing advanced capabilities such as Quality of Service (QoS), security, trust, virtualization, linked data and dependability, so things will be used as services with all the guarantees required by end users executing their applications in any environment.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>316</post_id>
		<post_date><![CDATA[2015-09-01 02:58:22]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 00:58:22]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[betaas-a-distributed-platform-for-things-as-a-service]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="internet-of-things"><![CDATA[Internet of Things]]></category>
		<category domain="post_tag" nicename="local-cloud"><![CDATA[Local Cloud]]></category>
		<category domain="post_tag" nicename="things-as-a-service"><![CDATA[Things as a Service]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Javier Nieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ATOS Research and Innovation Bilbao, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Francisco.nieto@atos.net]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[ Internet of Things (IoT) has become an important research topic during the last years due to the increasing number of devices, sensors and actuators available, and the expected trends in the availability of these elements. BETaaS aims at providing a horizontal solution which will facilitate things management, exploiting their full potential and providing advanced capabilities such as Quality of Service (QoS), security, trust, virtualization, linked data and dependability, so things will be used as services with all the guarantees required by end users executing their applications in any environment.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Internet of Things, Local Cloud, Things as a Service]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Experiencias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[317]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/019]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>CloudWave: Agile Service Engineering for the Future Internet</title>
		<link>https://biblioteca.sistedes.es/articulo/cloudwave-agile-service-engineering-for-the-future-internet/</link>
		<pubDate>Tue, 01 Sep 2015 01:01:19 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=319</guid>
		<description></description>
		<content><![CDATA[After achieving initial market penetration, Cloud Computing stakeholders now call for a next generation of Infrastructure and Software as a Service offering (IaaS and SaaS). CloudWave, an EU-funded FP7 research project, looks to dynamically adapt cloud services to their environment, resulting in improved service quality and optimized resource use. This is supported with an enhanced cloud monitoring that provides holistic analytics of IaaS and SaaS layer services running on the cloud, leading to CloudWave’s innovative, automated adaptation of the infrastructure and application, as well as enabling DevOps-like data and interfaces for the developer. DevOps-like data and interfaces for the developer.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>319</post_id>
		<post_date><![CDATA[2015-09-01 03:01:19]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:01:19]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[cloudwave-agile-service-engineering-for-the-future-internet]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cloud-computing"><![CDATA[Cloud Computing]]></category>
		<category domain="post_tag" nicename="devops"><![CDATA[DevOps]]></category>
		<category domain="post_tag" nicename="iaas"><![CDATA[IaaS]]></category>
		<category domain="post_tag" nicename="monitoring"><![CDATA[Monitoring]]></category>
		<category domain="post_tag" nicename="optimization"><![CDATA[Optimization]]></category>
		<category domain="post_tag" nicename="qos"><![CDATA[QoS]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Javier Nieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ATOS Research and Innovation ATOS Bilbao, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Francisco.nieto@atos.net]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[James Ahtes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ATOS Research and Innovation ATOS Barcelona, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[james.ahtes@atos.net]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[After achieving initial market penetration, Cloud Computing stakeholders now call for a next generation of Infrastructure and Software as a Service offering (IaaS and SaaS). CloudWave, an EU-funded FP7 research project, looks to dynamically adapt cloud services to their environment, resulting in improved service quality and optimized resource use. This is supported with an enhanced cloud monitoring that provides holistic analytics of IaaS and SaaS layer services running on the cloud, leading to CloudWave’s innovative, automated adaptation of the infrastructure and application, as well as enabling DevOps-like data and interfaces for the developer. DevOps-like data and interfaces for the developer.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ Cloud Computing, IaaS, Monitoring, DevOps, QoS, Optimization]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Experiencias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[320]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/018]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SeaClouds: An Application Management System over the Clouds</title>
		<link>https://biblioteca.sistedes.es/articulo/seaclouds-an-application-management-system-over-the-clouds/</link>
		<pubDate>Tue, 01 Sep 2015 01:08:37 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=322</guid>
		<description></description>
		<content><![CDATA[How to deploy and manage, in an efficient and adaptive way, complex applications across multiple heterogeneous cloud platforms is one of the problems that have emerged with the cloud revolution. Here we present the context, motivations, objectives, proposal and initial results of SeaClouds: an european research project, which aims at enabling a seamless adaptive multi-cloud management of complex applications by supporting the distribution, monitoring and migration of application modules over multiple heterogeneous cloud platforms.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>322</post_id>
		<post_date><![CDATA[2015-09-01 03:08:37]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:08:37]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[seaclouds-an-application-management-system-over-the-clouds]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="app-management"><![CDATA[app management]]></category>
		<category domain="post_tag" nicename="cloud-deployment"><![CDATA[Cloud deployment]]></category>
		<category domain="post_tag" nicename="cloud-interoperability"><![CDATA[cloud interoperability]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel Barrientos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[barrientos@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Leonardo Bartoloni]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Pisa, Dept. Computer Science, Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[bartolon@di.unipi.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Brogi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Pisa, Dept. Computer Science, Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[brogi@di.unipi.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Mattia Buccarella]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Pisa, Dept. Computer Science, Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[buccarella@di.unipi.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Jose Carrasco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[josec@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Javier Cubo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[cubo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Francesco D’Andria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[francesco.dandria@atos.net]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[ATOS Researcg and Innovation, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[How to deploy and manage, in an efficient and adaptive way, complex applications across multiple heterogeneous cloud platforms is one of the problems that have emerged with the cloud revolution. Here we present the context, motivations, objectives, proposal and initial results of SeaClouds: an european research project, which aims at enabling a seamless adaptive multi-cloud management of complex applications by supporting the distribution, monitoring and migration of application modules over multiple heterogeneous cloud platforms.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Cloud deployment, cloud interoperability, app management]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Experiencias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[323]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/017]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>ProDiGen: minando modelos completos, precisos y simples con un algoritmo genético</title>
		<link>https://biblioteca.sistedes.es/articulo/prodigen-minando-modelos-completos-precisos-y-simples-con-un-algoritmo-genetico/</link>
		<pubDate>Tue, 01 Sep 2015 01:13:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=325</guid>
		<description></description>
		<content><![CDATA[Un proceso se puede entender como una secuencia de tareas que se llevan a cabo para alcanzar un determinado objetivo. Por ejemplo, en educación, el dise˜no de aprendizaje es un proceso en el que los alumnos deben realizar una secuencia de actividades —escribir en el foro, hacer un examen, etc.— para poder lograr los objetivos pedagógicos del curso. En general, estos procesos están perfectamente detallados, sin embargo, incluso en estas situaciones, pueden existir diferencias entre lo que está sucediendo en el proceso, y lo que se cree que está a suceder en realidad. Por ejemplo, siguiengo el ejemplo del dominio educativo, los alumnos pueden realizar trabajos adicionales, como puede ser revisar la bibliografía o interactuar entre ellos. Es así como el descubrimiento de procesos es necesario para obtener información de qué es lo que está sucediendo en realidad durante la ejecución del proceso, y no lo que creemos que está a suceder. Típicamente, estas técnicas trabajan sobre registros que contienen la información sobre los eventos detectados y almacenados por el sistema de información donde tuvo lugar el proceso. El descubrimiento de procesos tiene como objetivo obtener el flujo de trabajo que mejor representa el comportamiento almacenado en dicho registro. En la última década se han desarrollado decenas de algoritmos que abordan esta problemática de descubrimiento, sin embargo, las técnicas actuales o bien generan modelos difíciles de leer, modelos que no son capaces de representar todo el comportamiento del registro, o bien modelos que no permiten hacer frente a todas las estructuras de control al mismo tiempo. Este artículo describe ProDiGen (Process Discovery through a Genetic algorithm), un algoritmo de descubrimiento de flujos de trabajo que guía su búsqueda en torno a modelos completos, precisos y simples. ProDiGen se basa en una función de fitness jerárquica que tiene en cuenta la completitud, la precisión y la simpicidad, utilizando dos métricas nuevas para los dos últimos criterios. Además, utiliza heurísticas para optimizar tanto el cruce —teniendo en cuenta los errores del modelo minado— como la mutación —guianda por las dependencias causales del log. ProDiGen se ha validado con 111 registros y se ha comparado con cuatro algoritmos del estado del arte, validándo los resultados con test estadísticos no paramétricos. Los resultados muestran una mejora significativa de ProDiGen respecto al resto de algoritmos utilizados en la comparativa.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>325</post_id>
		<post_date><![CDATA[2015-09-01 03:13:07]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:13:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[prodigen-minando-modelos-completos-precisos-y-simples-con-un-algoritmo-genetico]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Borja Vázquez-Barreiros]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnoloxías da Información (CiTIUS) Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[borja.vazquez@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Mucientes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnoloxías da Información (CiTIUS) Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[manuel.mucientes@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Lama]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnoloxías da Información (CiTIUS) Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuel.lama@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Un proceso se puede entender como una secuencia de tareas que se llevan a cabo para alcanzar un determinado objetivo. Por ejemplo, en educación, el dise˜no de aprendizaje es un proceso en el que los alumnos deben realizar una secuencia de actividades —escribir en el foro, hacer un examen, etc.— para poder lograr los objetivos pedagógicos del curso. En general, estos procesos están perfectamente detallados, sin embargo, incluso en estas situaciones, pueden existir diferencias entre lo que está sucediendo en el proceso, y lo que se cree que está a suceder en realidad. Por ejemplo, siguiengo el ejemplo del dominio educativo, los alumnos pueden realizar trabajos adicionales, como puede ser revisar la bibliografía o interactuar entre ellos. Es así como el descubrimiento de procesos es necesario para obtener información de qué es lo que está sucediendo en realidad durante la ejecución del proceso, y no lo que creemos que está a suceder. Típicamente, estas técnicas trabajan sobre registros que contienen la información sobre los eventos detectados y almacenados por el sistema de información donde tuvo lugar el proceso. El descubrimiento de procesos tiene como objetivo obtener el flujo de trabajo que mejor representa el comportamiento almacenado en dicho registro. En la última década se han desarrollado decenas de algoritmos que abordan esta problemática de descubrimiento, sin embargo, las técnicas actuales o bien generan modelos difíciles de leer, modelos que no son capaces de representar todo el comportamiento del registro, o bien modelos que no permiten hacer frente a todas las estructuras de control al mismo tiempo. Este artículo describe ProDiGen (Process Discovery through a Genetic algorithm), un algoritmo de descubrimiento de flujos de trabajo que guía su búsqueda en torno a modelos completos, precisos y simples. ProDiGen se basa en una función de fitness jerárquica que tiene en cuenta la completitud, la precisión y la simpicidad, utilizando dos métricas nuevas para los dos últimos criterios. Además, utiliza heurísticas para optimizar tanto el cruce —teniendo en cuenta los errores del modelo minado— como la mutación —guianda por las dependencias causales del log. ProDiGen se ha validado con 111 registros y se ha comparado con cuatro algoritmos del estado del arte, validándo los resultados con test estadísticos no paramétricos. Los resultados muestran una mejora significativa de ProDiGen respecto al resto de algoritmos utilizados en la comparativa.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[326]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/020]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Conservación de una Reserva Natural con un Enfoque Orientado a Servicios y Dirigido por Eventos</title>
		<link>https://biblioteca.sistedes.es/articulo/conservacion-de-una-reserva-natural-con-un-enfoque-orientado-a-servicios-y-dirigido-por-eventos/</link>
		<pubDate>Tue, 01 Sep 2015 01:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=328</guid>
		<description></description>
		<content><![CDATA[Las reservas naturales son una fuente de biodiversidad de inestimable valor que pretenden proteger la vida animal y vegetal manteniendo el equilibrio ecológico. La superpoblación de la tierra, las empresas constructoras, las empresas madereras y de extracción de recursos naturales, la caza furtiva descontrolada y la deposición de residuos, entre otros, amenazan con violar estas reservas protegidas. Por ello, se requieren nuevos enfoques tecnológicos para la observación, control, prevención y actuación, que garanticen el futuro de las reservas naturales. En este artículo se propone la monitorización en tiempo real de estos territorios usando un enfoque orientado a servicios y dirigido por eventos para la protección de los ecosistemas, haciendo hincapié en el uso de elementos electrónicos de bajo coste. Los beneficios derivados de esta propuesta redundarán en la protección de las especies autóctonas, la prevención de incendios, la obtención de datos sobre los cambios en los distintos hábitats y el apoyo a las unidades de guardabosques.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>328</post_id>
		<post_date><![CDATA[2015-09-01 03:17:54]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[conservacion-de-una-reserva-natural-con-un-enfoque-orientado-a-servicios-y-dirigido-por-eventos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="arquitectura-orientada-a-servicios-y-dirigida-por-eventos"><![CDATA[arquitectura orientada a servicios y dirigida por eventos]]></category>
		<category domain="post_tag" nicename="conservacion-de-reserva-natural"><![CDATA[conservación de reserva natural]]></category>
		<category domain="post_tag" nicename="procesamiento-de-eventos-complejos"><![CDATA[procesamiento de eventos complejos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio J. Arjona-Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Escuela Superior de Ingeniería, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[antonio.arjonarodriguez@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las reservas naturales son una fuente de biodiversidad de inestimable valor que pretenden proteger la vida animal y vegetal manteniendo el equilibrio ecológico. La superpoblación de la tierra, las empresas constructoras, las empresas madereras y de extracción de recursos naturales, la caza furtiva descontrolada y la deposición de residuos, entre otros, amenazan con violar estas reservas protegidas. Por ello, se requieren nuevos enfoques tecnológicos para la observación, control, prevención y actuación, que garanticen el futuro de las reservas naturales. En este artículo se propone la monitorización en tiempo real de estos territorios usando un enfoque orientado a servicios y dirigido por eventos para la protección de los ecosistemas, haciendo hincapié en el uso de elementos electrónicos de bajo coste. Los beneficios derivados de esta propuesta redundarán en la protección de las especies autóctonas, la prevención de incendios, la obtención de datos sobre los cambios en los distintos hábitats y el apoyo a las unidades de guardabosques.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[procesamiento de eventos complejos, arquitectura orientada a servicios y dirigida por eventos, conservación de reserva natural]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[329]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/016]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Estimación del coste de aprovisionar instancias de cómputo para ejecutar aplicaciones bag-of-task en el cloud de Amazon</title>
		<link>https://biblioteca.sistedes.es/articulo/estimacion-del-coste-de-aprovisionar-instancias-de-computo-para-ejecutar-aplicaciones-bag-of-task-en-el-cloud-de-amazon/</link>
		<pubDate>Tue, 01 Sep 2015 01:22:58 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=331</guid>
		<description></description>
		<content><![CDATA[Sin duda, el coste económico es un factor decisivo cuando se valora la posibilidad de ejecutar una aplicación en cloud. Hoy en día, estimar cuál es el precio a pagar no es sencillo si se trata de aplicaciones que requieren un elevado número de recursos de cómputo y almacenamiento. En este trabajo, se propone un método para minimizar el coste de ejecución de aplicaciones paralelas bag-of-task en un entorno de cómputo tipo cloud. Este método no sólo calcula una estimación del precio a pagar, sino que también determina qué recursos deberían ser contratados para minimizar ese precio. Una contribución importante de la solución es que considera la heterogeneidad de los proveedores cloud a nivel de catálogo de recursos, modelos y plazos de arrendamiento, opciones de pago, etc. La propuesta ha sido aplicada a un problema intenso en cómputo y ejecutado en el entorno de Amazon Elastic Compute Cloud (EC2).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>331</post_id>
		<post_date><![CDATA[2015-09-01 03:22:58]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:22:58]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[estimacion-del-coste-de-aprovisionar-instancias-de-computo-para-ejecutar-aplicaciones-bag-of-task-en-el-cloud-de-amazon]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="amazon-ec2"><![CDATA[Amazon EC2]]></category>
		<category domain="post_tag" nicename="aplicaciones-paralelas"><![CDATA[aplicaciones paralelas]]></category>
		<category domain="post_tag" nicename="aprovisionamiento-de-recursos"><![CDATA[aprovisionamiento de recursos]]></category>
		<category domain="post_tag" nicename="computacion-en-la-nube"><![CDATA[Computación en la Nube]]></category>
		<category domain="post_tag" nicename="minimizacion-de-costes"><![CDATA[minimización de costes]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Alvarez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Ingeniería de Aragón (I3A) Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alvaper@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Ingeniería de Aragón (I3A) Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[shernandez@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Fabra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Ingeniería de Aragón (I3A) Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jfabra@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Joaquín Ezpeleta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Ingeniería de Aragón (I3A) Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[ezpeleta@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Sin duda, el coste económico es un factor decisivo cuando se valora la posibilidad de ejecutar una aplicación en cloud. Hoy en día, estimar cuál es el precio a pagar no es sencillo si se trata de aplicaciones que requieren un elevado número de recursos de cómputo y almacenamiento. En este trabajo, se propone un método para minimizar el coste de ejecución de aplicaciones paralelas bag-of-task en un entorno de cómputo tipo cloud. Este método no sólo calcula una estimación del precio a pagar, sino que también determina qué recursos deberían ser contratados para minimizar ese precio. Una contribución importante de la solución es que considera la heterogeneidad de los proveedores cloud a nivel de catálogo de recursos, modelos y plazos de arrendamiento, opciones de pago, etc. La propuesta ha sido aplicada a un problema intenso en cómputo y ejecutado en el entorno de Amazon Elastic Compute Cloud (EC2).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Computación en la nube, minimización de costes, aplicaciones paralelas, aprovisionamiento de recursos, Amazon EC2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[332]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/015]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>What are the Three Top Challenges in Service Engineering?</title>
		<link>https://biblioteca.sistedes.es/articulo/what-are-the-three-top-challenges-in-service-engineering/</link>
		<pubDate>Tue, 01 Sep 2015 01:24:42 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=334</guid>
		<description></description>
		<content><![CDATA[This is a thought/position statement contribution for JCIS 2015 with the objective of promoting discussions on major challenges in the context of service engineering. It proposes to conduct the discussion as part of a research quality process for influencing future research and increasing impact. Gathering and processing inputs both from the JCIS/SISTEDES community and from outside to elaborate the list of top challenges is the proposed approach. This could further lead a debate on the role of JCIS/SISTEDES community for addressing them.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>334</post_id>
		<post_date><![CDATA[2015-09-01 03:24:42]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:24:42]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[what-are-the-three-top-challenges-in-service-engineering]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="scalable-computing"><![CDATA[Scalable Computing]]></category>
		<category domain="post_tag" nicename="service-engineering"><![CDATA[Service Engineering]]></category>
		<category domain="post_tag" nicename="ubiquitous-intelligence"><![CDATA[Ubiquitous Intelligence]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesus Bermejo Muñoz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[OSGi Users´ Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jesus@bermejo.link]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This is a thought/position statement contribution for JCIS 2015 with the objective of promoting discussions on major challenges in the context of service engineering. It proposes to conduct the discussion as part of a research quality process for influencing future research and increasing impact. Gathering and processing inputs both from the JCIS/SISTEDES community and from outside to elaborate the list of top challenges is the proposed approach. This could further lead a debate on the role of JCIS/SISTEDES community for addressing them.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Service Engineering, Scalable Computing, Ubiquitous Intelligence]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[335]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/014]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Definición de Mecanismos Personalizados de Monitorización de Servicios Cloud</title>
		<link>https://biblioteca.sistedes.es/articulo/definicion-de-mecanismos-personalizados-de-monitorizacion-de-servicios-cloud/</link>
		<pubDate>Tue, 01 Sep 2015 01:27:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=337</guid>
		<description></description>
		<content><![CDATA[Actualmente muchas empresas están adoptando tecnologías cloud como solución de provisión de recursos tecnológicos, para sus necesidades de infraestructura y software. Como consecuencia de esto, se hace necesario contar con mecanismos de monitorización flexibles, que permitan tanto al cliente como al proveedor, evaluar la calidad de los servicios ofertados con el fin de ofrecer una adecuada provisión de los mismos. Existen muchas soluciones en el mercado para la monitorización de servicios desplegados en la nube. Sin embargo, la mayoría provee métricas simples, que no están directamente relacionadas a los Acuerdos de Nivel de Servicios (SLA) y tampoco cuentan con mecanismos personalizados, que permitan especificar nuevas fórmulas para el cálculo de métricas complejas. En trabajos anteriores, hemos propuesto una infraestructura de monitorización de servicios de software desplegados en la nube, que utiliza modelos en tiempo de ejecución, los cuales proporcionan un alto grado de flexibilidad a la hora de realizar cambios en los requisitos no funcionales a ser monitorizados, sin necesidad de parar el sistema de monitorización o realizar cambios sustanciales en la infraestructura. En este trabajo, extendemos la infraestructura propuesta, con mecanismos personalizados de monitorización de servicios, que permite hacer uso de información provista por la plataforma cloud, de herramientas de monitorización de terceros y de cálculos de métricas programados directamente en los servicios que están siendo monitorizados. Finalmente, se muestra el uso de estos mecanismos personalizados para la monitorización de servicios desplegados en la plataforma Microsoft Azure©]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>337</post_id>
		<post_date><![CDATA[2015-09-01 03:27:48]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:27:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[definicion-de-mecanismos-personalizados-de-monitorizacion-de-servicios-cloud]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Priscila Cedillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València Camino de Vera s/n, 46022 Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[icedillo@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Jimenez-Gomez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València Camino de Vera s/n, 46022 Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jajimgme@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Silvia Abrahao]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València Camino de Vera s/n, 46022 Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sabrahao@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Emilio Insfran]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València Camino de Vera s/n, 46022 Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[einsfran@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Actualmente muchas empresas están adoptando tecnologías cloud como solución de provisión de recursos tecnológicos, para sus necesidades de infraestructura y software. Como consecuencia de esto, se hace necesario contar con mecanismos de monitorización flexibles, que permitan tanto al cliente como al proveedor, evaluar la calidad de los servicios ofertados con el fin de ofrecer una adecuada provisión de los mismos. Existen muchas soluciones en el mercado para la monitorización de servicios desplegados en la nube. Sin embargo, la mayoría provee métricas simples, que no están directamente relacionadas a los Acuerdos de Nivel de Servicios (SLA) y tampoco cuentan con mecanismos personalizados, que permitan especificar nuevas fórmulas para el cálculo de métricas complejas. En trabajos anteriores, hemos propuesto una infraestructura de monitorización de servicios de software desplegados en la nube, que utiliza modelos en tiempo de ejecución, los cuales proporcionan un alto grado de flexibilidad a la hora de realizar cambios en los requisitos no funcionales a ser monitorizados, sin necesidad de parar el sistema de monitorización o realizar cambios sustanciales en la infraestructura. En este trabajo, extendemos la infraestructura propuesta, con mecanismos personalizados de monitorización de servicios, que permite hacer uso de información provista por la plataforma cloud, de herramientas de monitorización de terceros y de cálculos de métricas programados directamente en los servicios que están siendo monitorizados. Finalmente, se muestra el uso de estos mecanismos personalizados para la monitorización de servicios desplegados en la plataforma Microsoft Azure©]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[338]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/013]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Algoritmo Híbrido de Composición Automática de Servicios con QoS</title>
		<link>https://biblioteca.sistedes.es/articulo/algoritmo-hibrido-de-composicion-automatica-de-servicios-con-qos/</link>
		<pubDate>Tue, 01 Sep 2015 01:31:13 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=340</guid>
		<description></description>
		<content><![CDATA[En este trabajo se presenta una aproximación híbrida para la composición automática de servicios mediante el emparejamiento semántico de entradas y salidas, optimizando el número de servicios y la calidad de servicio (QoS) de las composiciones. La aproximación propuesta está dividida en 4 fases: 1) generación del grafo de composición para un problema concreto de composición definido mediante entradas y salidas; 2) cálculo de la calidad de servicio óptima en el grafo; 3) optimización secuencial del grafo de composición identificando servicios equivalentes y dominados; 4) búsqueda híbrida para extraer la solución con calidad de servicio óptima y menor número de servicios. Los resultados experimentales con conjuntos de datos del Web Service Challenge 2009-2010 demuestran la efectividad de esta técnica.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>340</post_id>
		<post_date><![CDATA[2015-09-01 03:31:13]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:31:13]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[algoritmo-hibrido-de-composicion-automatica-de-servicios-con-qos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Rodriguez-Mier]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnologías de la Información (CITIUS) Universidad de Santiago de Compostela, E-15782 Spain,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pablo.rodriguez.mier@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Mucientes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnologías de la Información (CITIUS) Universidad de Santiago de Compostela, E-15782 Spain,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[manuel.mucientes@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Lama]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnologías de la Información (CITIUS) Universidad de Santiago de Compostela, E-15782 Spain,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuel.lama@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este trabajo se presenta una aproximación híbrida para la composición automática de servicios mediante el emparejamiento semántico de entradas y salidas, optimizando el número de servicios y la calidad de servicio (QoS) de las composiciones. La aproximación propuesta está dividida en 4 fases: 1) generación del grafo de composición para un problema concreto de composición definido mediante entradas y salidas; 2) cálculo de la calidad de servicio óptima en el grafo; 3) optimización secuencial del grafo de composición identificando servicios equivalentes y dominados; 4) búsqueda híbrida para extraer la solución con calidad de servicio óptima y menor número de servicios. Los resultados experimentales con conjuntos de datos del Web Service Challenge 2009-2010 demuestran la efectividad de esta técnica.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[341]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/012]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards Defining Data-Based Thresholds for Process-Related KPIs</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-defining-data-based-thresholds-for-process-related-kpis/</link>
		<pubDate>Tue, 01 Sep 2015 01:37:46 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=343</guid>
		<description></description>
		<content><![CDATA[The definition of process-related key performance indicators (KPIs) is a key part of performance measurement and one of the most challenging because of the lack of one best way to define businessapplicable KPIs that are both aligned with the strategic goals that the organisation wants to achieve and, at the same time, achievable in its context. It requires the identification of relevant threshold values able to distinguish different levels of process execution quality. However, obtaining these values remains an organization-specific task based on human abilities and no consensual technique exists. To overcome this problem, this paper introduces a methodology for threshold determination that considers not only the expert opinion but also data from real process executions.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>343</post_id>
		<post_date><![CDATA[2015-09-01 03:37:46]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:37:46]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-defining-data-based-thresholds-for-process-related-kpis]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Adela del-Río-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[adeladelrio@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Félix García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla La Mancha, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Felix.Garcia@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Francisco Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla La Mancha, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Francisco.RuizG@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The definition of process-related key performance indicators (KPIs) is a key part of performance measurement and one of the most challenging because of the lack of one best way to define businessapplicable KPIs that are both aligned with the strategic goals that the organisation wants to achieve and, at the same time, achievable in its context. It requires the identification of relevant threshold values able to distinguish different levels of process execution quality. However, obtaining these values remains an organization-specific task based on human abilities and no consensual technique exists. To overcome this problem, this paper introduces a methodology for threshold determination that considers not only the expert opinion but also data from real process executions.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[344]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/011]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards Assessing Open Source Communities’ Health using SOC Concepts</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-assessing-open-source-communities-health-using-soc-concepts/</link>
		<pubDate>Tue, 01 Sep 2015 01:43:27 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=346</guid>
		<description></description>
		<content><![CDATA[Quality of an open source software ecosystem (OSS ecosystem) is key for different ecosystem actors such as contributors or adopters. In fact, the consideration of several quality aspects(e.g., activeness, visibility, interrelatedness, etc.) as a whole may provide a measure of the healthiness of OSS ecosystems. The more health a OSS ecosystem is, the more and better contributors and adopters it will gather. Some research tools have been developed to gather specific quality information from open source community data sources. However, there exist no frameworks available that can be used to evaluate their quality as a whole in order to obtain the health of an OSS ecosystem. To assess the health of these ecosystems, we propose to adopt robust principles and methods from the Service Oriented Computing field.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>346</post_id>
		<post_date><![CDATA[2015-09-01 03:43:27]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:43:27]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-assessing-open-source-communities-health-using-soc-concepts]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Oscar Franco-Bedoya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ohernan@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Marc Oriol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[moriol@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Carlos Müller]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[cmuller@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jordi Marco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jmarco@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Pablo Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Xavier Franch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[franch@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_8]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_8]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_8]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Quality of an open source software ecosystem (OSS ecosystem) is key for different ecosystem actors such as contributors or adopters. In fact, the consideration of several quality aspects(e.g., activeness, visibility, interrelatedness, etc.) as a whole may provide a measure of the healthiness of OSS ecosystems. The more health a OSS ecosystem is, the more and better contributors and adopters it will gather. Some research tools have been developed to gather specific quality information from open source community data sources. However, there exist no frameworks available that can be used to evaluate their quality as a whole in order to obtain the health of an OSS ecosystem. To assess the health of these ecosystems, we propose to adopt robust principles and methods from the Service Oriented Computing field.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[348]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/010]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards Collaborative Human-Centric CPS</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-collaborative-human-centric-cps/</link>
		<pubDate>Tue, 01 Sep 2015 01:50:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=351</guid>
		<description></description>
		<content><![CDATA[The massive involvement of human in Cyber-Physical Systems is to a large extend managed through their smart devices. So far, these devices have been used as simple set of sensors capable of capturing the users context and uploading it to a central server. However, this architecture leads to a high consumption of the device’s resources. Consumption that is dramatically increased when similar data are used in several CPS. Nevertheless, smart devices even increasing storage and computing capacities allow them to take a more active role in these systems. This paper presents an architecture where smart devices are treated as the bridge between the physical world and the cyber space. In this architecture, smart devices store and infer the user contextual and sociological information, reacting to the state of the user or collaborating with other computational infrastructures. This architecture enables the development of human-centric CPS with clear social orientation.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>351</post_id>
		<post_date><![CDATA[2015-09-01 03:50:05]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:50:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-collaborative-human-centric-cps]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cps"><![CDATA[CPS]]></category>
		<category domain="post_tag" nicename="human-cetric-cps"><![CDATA[Human-Cetric CPS]]></category>
		<category domain="post_tag" nicename="mobile-computing"><![CDATA[mobile computing]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose Garcia-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Hernádez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juanher@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Niko Mäkitalo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Tampere University of Technology, Finland]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[niko.makitalo@cs.tut.fi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Tommi Mikkonen]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Tampere University of Technology, Finland]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[tjm@cs.tut.fi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Juan M. Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The massive involvement of human in Cyber-Physical Systems is to a large extend managed through their smart devices. So far, these devices have been used as simple set of sensors capable of capturing the users context and uploading it to a central server. However, this architecture leads to a high consumption of the device’s resources. Consumption that is dramatically increased when similar data are used in several CPS. Nevertheless, smart devices even increasing storage and computing capacities allow them to take a more active role in these systems. This paper presents an architecture where smart devices are treated as the bridge between the physical world and the cyber space. In this architecture, smart devices store and infer the user contextual and sociological information, reacting to the state of the user or collaborating with other computational infrastructures. This architecture enables the development of human-centric CPS with clear social orientation.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ CPS, Human-Cetric CPS, Mobile Computing]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[352]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/009]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Reduciendo la complejidad gráfica de indicadores de procesos de negocio usando abstracción</title>
		<link>https://biblioteca.sistedes.es/articulo/reduciendo-la-complejidad-grafica-de-indicadores-de-procesos-de-negocio-usando-abstraccion/</link>
		<pubDate>Tue, 01 Sep 2015 01:54:28 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=354</guid>
		<description></description>
		<content><![CDATA[La representación de indicadores de rendimiento sobre los procesos de negocio facilita la comprensión y definición en el cálculo y obtención de datos. Al incluir varios indicadores sobre un proceso puede ser necesario incorporar una gran cantidad de elementos de medición, generando un exceso de información y dificultando el análisis visual de los datos. En este artículo se presenta una ampliación de la notación gráfica Visual PPINOT, que permite modelar gráficamente indicadores de rendimiento sobre los procesos de negocio. A la notación se incorporan elementos de abstracción para facilitar la representación de patrones recurrentes en indicadores y para mejorar la legibilidad del diagrama del proceso. La implementación se valida utilizando el Modelo de Referencia SCOR. Se propone una clasificación de sus métricas y éstas se utilizan como referencia para estudiar las diferencias del modelado con la notación original en comparación con la notación ampliada.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>354</post_id>
		<post_date><![CDATA[2015-09-01 03:54:28]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:54:28]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[reduciendo-la-complejidad-grafica-de-indicadores-de-procesos-de-negocio-usando-abstraccion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Bedilia Estrada-Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas, Universidad de Sevilla. España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Adela del-Río-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas, Universidad de Sevilla. España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas, Universidad de Sevilla. España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas, Universidad de Sevilla. España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La representación de indicadores de rendimiento sobre los procesos de negocio facilita la comprensión y definición en el cálculo y obtención de datos. Al incluir varios indicadores sobre un proceso puede ser necesario incorporar una gran cantidad de elementos de medición, generando un exceso de información y dificultando el análisis visual de los datos. En este artículo se presenta una ampliación de la notación gráfica Visual PPINOT, que permite modelar gráficamente indicadores de rendimiento sobre los procesos de negocio. A la notación se incorporan elementos de abstracción para facilitar la representación de patrones recurrentes en indicadores y para mejorar la legibilidad del diagrama del proceso. La implementación se valida utilizando el Modelo de Referencia SCOR. Se propone una clasificación de sus métricas y éstas se utilizan como referencia para estudiar las diferencias del modelado con la notación original en comparación con la notación ampliada.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[355]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/008]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>IoT Compositions by and for the Crowd</title>
		<link>https://biblioteca.sistedes.es/articulo/iot-compositions-by-and-for-the-crowd/</link>
		<pubDate>Tue, 01 Sep 2015 01:57:56 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=357</guid>
		<description></description>
		<content><![CDATA[<a href="http://biblioteca.sistedes.es/wp-content/uploads/2016/02/JCIS_2015_submission_10.pdf" rel="">JCIS_2015_submission_10</a>The Internet of Things (IoT) offers a new eco-system of heterogeneous and distributed services that is available anytime and anywhere and that can be potentially accessed by any properly connected device. However, these available services are usually consumed in isolation, missing the potential that their combined usage can bring as new added-value services. In addition, the massive end-user adoption and usage of smartphones together with their powerful capabilities turn this type of devices into a promising platform to develop and execute these added-value services compositions. Moreover, end-users are nowadays getting more and more familiar with technology, fact that allows them to participate more actively in the development of new types of applications. However, this will not happen until we provide end-users with more powerful and easy-to-use tools. To this end, this paper presents an architectural solution to allow end-users building IoT services compositions by just focusing on domain-logic issues.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>357</post_id>
		<post_date><![CDATA[2015-09-01 03:57:56]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 01:57:56]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[iot-compositions-by-and-for-the-crowd]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="end-user-development"><![CDATA[End-user Development]]></category>
		<category domain="post_tag" nicename="iot"><![CDATA[IoT]]></category>
		<category domain="post_tag" nicename="service-compositions"><![CDATA[Service Compositions]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ignacio Mansanet]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia, Spain. Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[imansanet@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Victoria Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia, Spain. Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[vtorres@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pedro Valderas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia, Spain. Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pvalderas@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia, Spain. Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[pele@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The Internet of Things (IoT) offers a new eco-system of heterogeneous and distributed services that is available anytime and anywhere and that can be potentially accessed by any properly connected device. However, these available services are usually consumed in isolation, missing the potential that their combined usage can bring as new added-value services. In addition, the massive end-user adoption and usage of smartphones together with their powerful capabilities turn this type of devices into a promising platform to develop and execute these added-value services compositions. Moreover, end-users are nowadays getting more and more familiar with technology, fact that allows them to participate more actively in the development of new types of applications. However, this will not happen until we provide end-users with more powerful and easy-to-use tools. To this end, this paper presents an architectural solution to allow end-users building IoT services compositions by just focusing on domain-logic issues.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Service Compositions, IoT, End-user Development]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[671]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/007]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>On the Calculation of Process Performance Indicators</title>
		<link>https://biblioteca.sistedes.es/articulo/on-the-calculation-of-process-performance-indicators/</link>
		<pubDate>Tue, 01 Sep 2015 02:02:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=360</guid>
		<description></description>
		<content><![CDATA[Performance calculation is a key factor to match corporate goals between different partners in process execution. However, although, a number of standards protocols and languages have recently emerged to support business process services in the industry, there is no standard related to monitoring of performance indicators over processes in these systems. As a consequence, BPMS use propietary languages to define measures and calculate them over process execution. In this paper, we describe two different approaches to compute performance mea- sures on business process decoupled from specific Business Process Man- agement System (BPMS) with an existing BPMS-independent language (PPINOT) to define indicators over business processes. Finally, some optimization techniques are described to increase calculation performance based on computing aggregated measures incrementally.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>360</post_id>
		<post_date><![CDATA[2015-09-01 04:02:06]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 02:02:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[on-the-calculation-of-process-performance-indicators]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="business-process-management"><![CDATA[Business Process Management]]></category>
		<category domain="post_tag" nicename="complex-event-processing"><![CDATA[Complex Event Processing]]></category>
		<category domain="post_tag" nicename="key-performance-indicators"><![CDATA[Key Performance Indicators]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Manuel Gutiérrez–Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[School of Computer Engineering 6 University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[amgutierrez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[School of Computer Engineering 6 University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Adela del–Río–Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[School of Computer Engineering 6 University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[adeladelrio@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz–Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[School of Computer Engineering 6 University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Performance calculation is a key factor to match corporate goals between different partners in process execution. However, although, a number of standards protocols and languages have recently emerged to support business process services in the industry, there is no standard related to monitoring of performance indicators over processes in these systems. As a consequence, BPMS use propietary languages to define measures and calculate them over process execution. In this paper, we describe two different approaches to compute performance mea- sures on business process decoupled from specific Business Process Man- agement System (BPMS) with an existing BPMS-independent language (PPINOT) to define indicators over business processes. Finally, some optimization techniques are described to increase calculation performance based on computing aggregated measures incrementally.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Business Process Management, Key Performance Indicators, Complex Event Processing]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[361]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/006]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards SLA-Driven API Gateways</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-sla-driven-api-gateways/</link>
		<pubDate>Tue, 01 Sep 2015 02:04:59 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=363</guid>
		<description></description>
		<content><![CDATA[As APIs are becoming popular to build Service-Based Applications (SBA), API Gateways are being increasingly used to facilitate API features management. They offer API management functionalities such as pricing plans support, user authentication, API versioning or response caching. Some parts of the information that an API Gateway needs are already included into a Service Level Agreement (SLA), that providers use to describe the rights and the obligations of involved parties in the service. Unfortunately, current API Gateways do not use any SLA representation model nor SLA underlying technology, thereby missing potential opportunities. In this paper we analyze the state of the art to justify the current situation and we identify some research challenges so as to achieve SLA-Driven API Gateways.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>363</post_id>
		<post_date><![CDATA[2015-09-01 04:04:59]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 02:04:59]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-sla-driven-api-gateways]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Gámez-Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[agamez2@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Fernández-Montes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[As APIs are becoming popular to build Service-Based Applications (SBA), API Gateways are being increasingly used to facilitate API features management. They offer API management functionalities such as pricing plans support, user authentication, API versioning or response caching. Some parts of the information that an API Gateway needs are already included into a Service Level Agreement (SLA), that providers use to describe the rights and the obligations of involved parties in the service. Unfortunately, current API Gateways do not use any SLA representation model nor SLA underlying technology, thereby missing potential opportunities. In this paper we analyze the state of the art to justify the current situation and we identify some research challenges so as to achieve SLA-Driven API Gateways.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[364]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards a Comprehensive Purchasing Model for Cloud Services</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-a-comprehensive-purchasing-model-for-cloud-services/</link>
		<pubDate>Tue, 01 Sep 2015 02:08:12 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=366</guid>
		<description></description>
		<content><![CDATA[The Cloud Service Market has evolved into a complex landscape that challenges the decision making of users as they develop their purchasing process. In particular, we explore the case of cloud infrastructure (IaaS) providers as an example of heterogeneous variety of purchasing options and discounts; this variability represents an important drawback during the decision making process where there is a need to compare and select the best option. In this work, we define a common model to describe purchasing models from different providers taking into account such heterogeneity. This purchasing model represents a first step towards the automated support of decision making problems during the purchasing process. In order to illustrate our approach we apply the model in a real case study of IaaS purchasing.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>366</post_id>
		<post_date><![CDATA[2015-09-01 04:08:12]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 02:08:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-a-comprehensive-purchasing-model-for-cloud-services]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cloud-services"><![CDATA[Cloud Services]]></category>
		<category domain="post_tag" nicename="decision-making"><![CDATA[Decision Making]]></category>
		<category domain="post_tag" nicename="purchasing-options"><![CDATA[Purchasing Options]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Octavio Martín-Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática – Universidad de Sevilla 41012 Sevilla, España – Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[omartindiaz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática – Universidad de Sevilla 41012 Sevilla, España – Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José María García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática – Universidad de Sevilla 41012 Sevilla, España – Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[josemgarcia@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática – Universidad de Sevilla 41012 Sevilla, España – Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The Cloud Service Market has evolved into a complex landscape that challenges the decision making of users as they develop their purchasing process. In particular, we explore the case of cloud infrastructure (IaaS) providers as an example of heterogeneous variety of purchasing options and discounts; this variability represents an important drawback during the decision making process where there is a need to compare and select the best option. In this work, we define a common model to describe purchasing models from different providers taking into account such heterogeneity. This purchasing model represents a first step towards the automated support of decision making problems during the purchasing process. In order to illustrate our approach we apply the model in a real case study of IaaS purchasing.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Cloud Services, Purchasing Options, Decision Making]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[367]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Perfil UML para el Modelado de la Integración de Servicios Cloud en Procesos de Desarrollo Incremental</title>
		<link>https://biblioteca.sistedes.es/articulo/perfil-uml-para-el-modelado-de-la-integracion-de-servicios-cloud-en-procesos-de-desarrollo-incremental/</link>
		<pubDate>Tue, 01 Sep 2015 02:10:17 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=369</guid>
		<description></description>
		<content><![CDATA[En procesos de desarrollo incremental de servicios cloud, la integración de nuevos servicios puede requerir la reconfiguración de la arquitectura actual de la aplicación, siendo importante que dicha reconfiguración sea dinámica para evitar interrupciones en el sistema. En este artículo presentamos un perfil de UML para especificar cómo nuevos servicios deben integrarse en la arquitectura de la aplicación cloud. Esta información de integración es utilizada para generar una nueva orquestación de servicios y los scripts necesarios que actualizan los enlaces entre los nuevos servicios, produciendo por tanto una reconfiguración arquitectónica en tiempo de ejecución. Esta propuesta se ilustra con un caso de estudio práctico en la plataforma Windows Azure© utilizando WCF Workflow para la orquestación de servicios y archivos XML Document Transformation para actualizar la configuración de enlaces de los servicios involucrados.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>369</post_id>
		<post_date><![CDATA[2015-09-01 04:10:17]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 02:10:17]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[perfil-uml-para-el-modelado-de-la-integracion-de-servicios-cloud-en-procesos-de-desarrollo-incremental]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="arquitectura-de-software"><![CDATA[arquitectura de software]]></category>
		<category domain="post_tag" nicename="computacion-cloud"><![CDATA[computación cloud]]></category>
		<category domain="post_tag" nicename="perfil-uml"><![CDATA[perfil UML]]></category>
		<category domain="post_tag" nicename="reconfiguracion-dinamica"><![CDATA[reconfiguración dinámica]]></category>
		<category domain="post_tag" nicename="soaml"><![CDATA[SoaML]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel Zuñiga-Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universitat Politècnica de València Camino de Vera, s/n, 46022, Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mzuniga@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Silvia Abrahao]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universitat Politècnica de València Camino de Vera, s/n, 46022, Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sabrahao@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Emilio Insfran]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universitat Politècnica de València Camino de Vera, s/n, 46022, Valencia, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[einsfran@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En procesos de desarrollo incremental de servicios cloud, la integración de nuevos servicios puede requerir la reconfiguración de la arquitectura actual de la aplicación, siendo importante que dicha reconfiguración sea dinámica para evitar interrupciones en el sistema. En este artículo presentamos un perfil de UML para especificar cómo nuevos servicios deben integrarse en la arquitectura de la aplicación cloud. Esta información de integración es utilizada para generar una nueva orquestación de servicios y los scripts necesarios que actualizan los enlaces entre los nuevos servicios, produciendo por tanto una reconfiguración arquitectónica en tiempo de ejecución. Esta propuesta se ilustra con un caso de estudio práctico en la plataforma Windows Azure© utilizando WCF Workflow para la orquestación de servicios y archivos XML Document Transformation para actualizar la configuración de enlaces de los servicios involucrados.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[arquitectura de software, reconfiguración dinámica, computación cloud, SoaML, perfil UML]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[370]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/003]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SafeWalks: aplicación móvil de supervisión de pacientes de Alzheimer</title>
		<link>https://biblioteca.sistedes.es/articulo/safewalks-aplicacion-movil-de-supervision-de-pacientes-de-alzheimer/</link>
		<pubDate>Tue, 01 Sep 2015 02:12:59 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=372</guid>
		<description></description>
		<content><![CDATA[El principal objetivo de Internet of Things (IoT) es integrar las tecnologías informáticas en el quehacer cotidiano de las personas, facilitando su interacción con un entorno de dispositivos interconectados, pero el estado actual del arte hace que dicha interacción esté aún lejos de resultar trivial, precisando de continua intervención del usuario. El modelo People as a Service (PeaaS) pretende facilitar estas tareas por medio del uso del teléfono móvil como interfaz del usuario con IoT. PeaaS permite elaborar un perfil sociológico del usuario, que puede ser explotado por el mismo y servido a terceros de forma controlada. En este trabajo presentamos una aplicación móvil para la supervisión de personas afectadas de alzheimer como prueba de concepto del modelo PeaaS, teniendo como resultado una funcionalidad que va mucho más allá de la ofrecida por otros productos similares en este campo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>372</post_id>
		<post_date><![CDATA[2015-09-01 04:12:59]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 02:12:59]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[safewalks-aplicacion-movil-de-supervision-de-pacientes-de-alzheimer]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Pérez Lozano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pperezlo@alumnos.unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alejandro Pérez Vereda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[apvereda@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El principal objetivo de Internet of Things (IoT) es integrar las tecnologías informáticas en el quehacer cotidiano de las personas, facilitando su interacción con un entorno de dispositivos interconectados, pero el estado actual del arte hace que dicha interacción esté aún lejos de resultar trivial, precisando de continua intervención del usuario. El modelo People as a Service (PeaaS) pretende facilitar estas tareas por medio del uso del teléfono móvil como interfaz del usuario con IoT. PeaaS permite elaborar un perfil sociológico del usuario, que puede ser explotado por el mismo y servido a terceros de forma controlada. En este trabajo presentamos una aplicación móvil para la supervisión de personas afectadas de alzheimer como prueba de concepto del modelo PeaaS, teniendo como resultado una funcionalidad que va mucho más allá de la ofrecida por otros productos similares en este campo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[373]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/002]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Propuesta de una Arquitectura de Dispositivos como Servicios con Procesamiento de Eventos</title>
		<link>https://biblioteca.sistedes.es/articulo/propuesta-de-una-arquitectura-de-dispositivos-como-servicios-con-procesamiento-de-eventos/</link>
		<pubDate>Tue, 01 Sep 2015 02:17:20 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=375</guid>
		<description></description>
		<content><![CDATA[Internet de las Cosas representa un paradigma en el que los objetos que nos rodean están interconectados. En esta visión, existen problemas como la detección de dispositivos heterogéneos, la inexistencia de estándares para interoperar con los dispositivos, o la eficiencia en la obtención de la información. Para la detección e interacción, existen estándares e iniciativas que exponen los dispositivos y las cosas como servicios, siguiendo un enfoque de arquitecturas orientadas a servicios. Para procesar la información generada, además del análisis de datos, es fundamental reaccionar ante cambios en los dispositivos, estableciendo pautas de comportamiento. Las técnicas de procesamiento de eventos complejos junto con las arquitecturas dirigidas por eventos permiten dise˜nar sistemas reactivos y desacoplados, analizando los cambios en el entorno y adaptando su comportamiento en base a patrones de eventos. Actualmente, la mayoría de las soluciones que permiten interactuar con dispositivos heterogéneos son complejas y requieren conocimiento avanzado. En este trabajo, proponemos una arquitectura de dispositivos orientada a servicios y dirigida por eventos, exponiendo los dispositivos como servicios para unificar su manejo, que interactúan con el entorno mediante eventos que son procesados, y dotando al ecosistema de la capacidad de comportarse de forma autónoma y reactiva.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>375</post_id>
		<post_date><![CDATA[2015-09-01 04:17:20]]></post_date>
		<post_date_gmt><![CDATA[2015-09-01 02:17:20]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[propuesta-de-una-arquitectura-de-dispositivos-como-servicios-con-procesamiento-de-eventos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cep"><![CDATA[CEP]]></category>
		<category domain="post_tag" nicename="daas"><![CDATA[DaaS]]></category>
		<category domain="post_tag" nicename="dpws"><![CDATA[DPWS]]></category>
		<category domain="post_tag" nicename="iot"><![CDATA[IoT]]></category>
		<category domain="post_tag" nicename="soa-2-0"><![CDATA[SOA 2.0]]></category>
		<category domain="post_tag" nicename="soda"><![CDATA[SODA]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Dpto. Ingeniería Informática, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Cubo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dpto. Lenguajes y Ciencias de la Computación, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cubo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Adrián Nieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dpto. Lenguajes y Ciencias de la Computación, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[adrian@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, Dpto. Ingeniería Informática, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Ernesto Pimentel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dpto. Lenguajes y Ciencias de la Computación, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[ernesto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Internet de las Cosas representa un paradigma en el que los objetos que nos rodean están interconectados. En esta visión, existen problemas como la detección de dispositivos heterogéneos, la inexistencia de estándares para interoperar con los dispositivos, o la eficiencia en la obtención de la información. Para la detección e interacción, existen estándares e iniciativas que exponen los dispositivos y las cosas como servicios, siguiendo un enfoque de arquitecturas orientadas a servicios. Para procesar la información generada, además del análisis de datos, es fundamental reaccionar ante cambios en los dispositivos, estableciendo pautas de comportamiento. Las técnicas de procesamiento de eventos complejos junto con las arquitecturas dirigidas por eventos permiten dise˜nar sistemas reactivos y desacoplados, analizando los cambios en el entorno y adaptando su comportamiento en base a patrones de eventos. Actualmente, la mayoría de las soluciones que permiten interactuar con dispositivos heterogéneos son complejas y requieren conocimiento avanzado. En este trabajo, proponemos una arquitectura de dispositivos orientada a servicios y dirigida por eventos, exponiendo los dispositivos como servicios para unificar su manejo, que interactúan con el entorno mediante eventos que son procesados, y dotando al ecosistema de la capacidad de comportarse de forma autónoma y reactiva.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[IoT, DaaS, CEP, SOA 2.0, SODA, DPWS]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Submissions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[376]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2015/001]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Restricted Predicates for Hypothetical Datalog</title>
		<link>https://biblioteca.sistedes.es/articulo/restricted-predicates-for-hypothetical-datalog/</link>
		<pubDate>Fri, 11 Sep 2015 02:09:46 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=492</guid>
		<description></description>
		<content><![CDATA[Hypothetical Datalog is based on an intuitionistic semantics rather than on a classical logic semantics, and embedded implications are allowed in rule bodies. While the usual implication (i.e., the neck of a Horn clause) stands for inferring facts, an embedded implication plays the role of assuming its premise for deriving its consequence. A former work introduced both a formal framework and a goal-oriented tabled implementation, allowing negation in rule bodies. While in that work positive assumptions for both facts and rules can occur in the premise, negative assumptions are not allowed. In this work, we cover this subject by introducing a new concept: a restricted predicate, which allows negative assumptions by pruning the usual semantics of a predicate. This new setting has been implemented in the deductive system DES.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>492</post_id>
		<post_date><![CDATA[2015-09-11 04:09:46]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:09:46]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[restricted-predicates-for-hypothetical-datalog]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[493]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Hypothetical Datalog is based on an intuitionistic semantics rather than on a classical logic semantics, and embedded implications are allowed in rule bodies. While the usual implication (i.e., the neck of a Horn clause) stands for inferring facts, an embedded implication plays the role of assuming its premise for deriving its consequence. A former work introduced both a formal framework and a goal-oriented tabled implementation, allowing negation in rule bodies. While in that work positive assumptions for both facts and rules can occur in the premise, negative assumptions are not allowed. In this work, we cover this subject by introducing a new concept: a restricted predicate, which allows negative assumptions by pruning the usual semantics of a predicate. This new setting has been implemented in the deductive system DES.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[track]]></meta_key>
			<meta_value><![CDATA[Logic and Learning on Databases ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Fernando Sáenz-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fernan@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/021]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Declarative Semantics for a Fuzzy Logic Language Managing Similarities and Truth Degrees</title>
		<link>https://biblioteca.sistedes.es/articulo/a-declarative-semantics-for-a-fuzzy-logic-language-managing-similarities-and-truth-degrees/</link>
		<pubDate>Fri, 11 Sep 2015 02:18:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=495</guid>
		<description></description>
		<content><![CDATA[This work proposes a declarative semantics based on a fuzzy variant of the classical notion of least Herbrand model for the so-called FASILL language (acronym of “Fuzzy Aggregators and Similarity Into a Logic Language”) which has being recently designed and implemented in our research group for coping with implicit/explicit truth degree annotations, a great variety of connectives and unification by similarity.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>495</post_id>
		<post_date><![CDATA[2015-09-11 04:18:54]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:18:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-declarative-semantics-for-a-fuzzy-logic-language-managing-similarities-and-truth-degrees]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="fuzzy-logic-programming"><![CDATA[Fuzzy Logic Programming]]></category>
		<category domain="post_tag" nicename="herbrand-model"><![CDATA[Herbrand Model]]></category>
		<category domain="post_tag" nicename="similarity-relations"><![CDATA[Similarity Relations]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[496]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This work proposes a declarative semantics based on a fuzzy variant of the classical notion of least Herbrand model for the so-called FASILL language (acronym of “Fuzzy Aggregators and Similarity Into a Logic Language”) which has being recently designed and implemented in our research group for coping with implicit/explicit truth degree annotations, a great variety of connectives and unification by similarity.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Fuzzy Logic Programming, Similarity Relations, Herbrand Model]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pascual Julián-Iranzo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Technologies and Information Systems University of Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Pascual.Julian@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ginés Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computing Systems University of Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Gines.Moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jaime Penabad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Mathematics University of Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Jaime.Penabad@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Carlos Vázquez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computing Systems University of Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Carlos.Vazquez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/013]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A liberal type system for functional logic programs</title>
		<link>https://biblioteca.sistedes.es/articulo/a-liberal-type-system-for-functional-logic-programs/</link>
		<pubDate>Fri, 11 Sep 2015 02:23:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=499</guid>
		<description></description>
		<content><![CDATA[We propose a new type system for functional logic programming which is more liberal than the classical DamasMilner usually adopted, but it is also restrictive enough to ensure type soundness. Starting from DamasMilner typing of expressions, we propose a new notion of well-typed program that adds support for type-indexed functions, a particular form of existential types, opaque higherorder patterns and generic functions as shown by an extensive collection of examples that illustrate the possibilities of our proposal. In the negative side, the types of functions must be declared, and therefore types are checked but not inferred. Another consequence is that parametricity is lost, although the impact of this flaw is limited as free theorems were already compromised in functional logic programming because of non-determinism.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>499</post_id>
		<post_date><![CDATA[2015-09-11 04:23:51]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:23:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-liberal-type-system-for-functional-logic-programs]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[500]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We propose a new type system for functional logic programming which is more liberal than the classical DamasMilner usually adopted, but it is also restrictive enough to ensure type soundness. Starting from DamasMilner typing of expressions, we propose a new notion of well-typed program that adds support for type-indexed functions, a particular form of existential types, opaque higherorder patterns and generic functions as shown by an extensive collection of examples that illustrate the possibilities of our proposal. In the negative side, the types of functions must be declared, and therefore types are checked but not inferred. Another consequence is that parametricity is lost, although the impact of this flaw is limited as free theorems were already compromised in functional logic programming because of non-determinism.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco J. López-Fraguas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DSIC-UCM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fraguas@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Enrique Martin-Martin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[DSIC-UCM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[emartinm@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Rodríguez-Hortalá]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DSIC-UCM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanrh@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/024]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>HR-SQL: An SQL Database System with Extended Recursion and Hypothetical Reasoning</title>
		<link>https://biblioteca.sistedes.es/articulo/hr-sql-an-sql-database-system-with-extended-recursion-and-hypothetical-reasoning/</link>
		<pubDate>Fri, 11 Sep 2015 02:27:25 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=502</guid>
		<description></description>
		<content><![CDATA[In a former work we described the system and language R-SQL that overcomes some limitations of recursion of the relational database language SQL. Such limitations are non-linearity, mutual recursion, and some combinations of negation with recursion. In addition, R-SQL improved termination properties of recursive definitions. Next, this language was extended to include a restricted form of hypothetical relations and queries using assumptions, obtaining the language HR-SQL, and a preliminary implementation was developed for it. Here, we develop a new system HR-SQL from scratch and enhance the former system in several areas. First, hypothetical reasoning is fully integrated with recursive definitions. Second, the Python script generated by the system for computing the extension (materialization) of a database is now targeted to several state-of-the-art relational database systems. Third, the system has been interfaced to the integrated development environment ACIDE, allowing both a more friendly user interaction and a graphical view of the dependency graph that shows dependencies between relations. Fourth, being developed in Prolog, we have targeted it to both SICStus Prolog and SWI-Prolog, also providing standalone executables. Finally, the system has been extended with a bundle of commands, highly improving its capabilities with respect to the former system.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>502</post_id>
		<post_date><![CDATA[2015-09-11 04:27:25]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:27:25]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hr-sql-an-sql-database-system-with-extended-recursion-and-hypothetical-reasoning]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[503]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In a former work we described the system and language R-SQL that overcomes some limitations of recursion of the relational database language SQL. Such limitations are non-linearity, mutual recursion, and some combinations of negation with recursion. In addition, R-SQL improved termination properties of recursive definitions. Next, this language was extended to include a restricted form of hypothetical relations and queries using assumptions, obtaining the language HR-SQL, and a preliminary implementation was developed for it. Here, we develop a new system HR-SQL from scratch and enhance the former system in several areas. First, hypothetical reasoning is fully integrated with recursive definitions. Second, the Python script generated by the system for computing the extension (materialization) of a database is now targeted to several state-of-the-art relational database systems. Third, the system has been interfaced to the integrated development environment ACIDE, allowing both a more friendly user interaction and a graphical view of the dependency graph that shows dependencies between relations. Fourth, being developed in Prolog, we have targeted it to both SICStus Prolog and SWI-Prolog, also providing standalone executables. Finally, the system has been extended with a bundle of commands, highly improving its capabilities with respect to the former system.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Susana Nieva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[nieva@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando Sáenz-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fernan@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jaime Sánchez-Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Facultad de Informática Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jaime@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/020]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Haskell Implementation of a Rule-Based Program Transformation for C Programs</title>
		<link>https://biblioteca.sistedes.es/articulo/a-haskell-implementation-of-a-rule-based-program-transformation-for-c-programs/</link>
		<pubDate>Fri, 11 Sep 2015 02:30:56 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=505</guid>
		<description></description>
		<content><![CDATA[Obtaining good performance when programming heterogeneous computing platforms poses significant challenges for the programmer. We present a program transformation environment, implemented in Haskell, where architecture-agnostic scientific C code is transformed into a functionally equivalent one better suited for a given platform. The transformation rules are formalized in a domain-specific language (STML) that takes care of the syntactic and semantic conditions required to apply a given transformation. STML rules are compiled into Haskell function definitions that operate at AST level. Program properties, to be matched with rule conditions, can be automatically inferred or, alternatively, stated as annotations in the source code. Early experimental results are described.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>505</post_id>
		<post_date><![CDATA[2015-09-11 04:30:56]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:30:56]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-haskell-implementation-of-a-rule-based-program-transformation-for-c-programs]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[506]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Obtaining good performance when programming heterogeneous computing platforms poses significant challenges for the programmer. We present a program transformation environment, implemented in Haskell, where architecture-agnostic scientific C code is transformed into a functionally equivalent one better suited for a given platform. The transformation rules are formalized in a domain-specific language (STML) that takes care of the syntactic and semantic conditions required to apply a given transformation. STML rules are compiled into Haskell function definitions that operate at AST level. Program properties, to be matched with rule conditions, can be automatically inferred or, alternatively, stated as annotations in the source code. Early experimental results are described.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Tamarit]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[salvador.tamarit@upm.e]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Guillermo Vigueras]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[guillermo.vigueras@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Carro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuel.carro@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Julio Mariño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[julio.marino@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/006]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Declarative Debugger for Concurrent Erlang Programs</title>
		<link>https://biblioteca.sistedes.es/articulo/a-declarative-debugger-for-concurrent-erlang-programs/</link>
		<pubDate>Fri, 11 Sep 2015 02:35:03 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=508</guid>
		<description></description>
		<content><![CDATA[Erlang is a concurrent language with features such as actor model concurrency, no shared memory, message passing communication, high scalability and availability. However, the development of concurrent programs is a complex and error prone task. In this paper we present a declarative debugging approach for concurrent Erlang programs. Our debugger asks questions about the validity of transitions between the different points of the program that involve message passing and/or process creation. The answers, which represent the intended behavior of the program, are compared with the transitions obtained in an actual execution of the program. The differences allow us to detect program errors and to point out the pieces of source code responsible for the bugs. In order to represent the computations we present a semantic calculus for concurrent Core Erlang programs. The debugger uses the proof trees in this calculus as debugging trees used for selecting the questions asked to the user. The relation between the debugging trees and the semantic calculus allows us to establish the soundness of the approach. The theoretical ideas have been implemented in a debugger prototype.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>508</post_id>
		<post_date><![CDATA[2015-09-11 04:35:03]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:35:03]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-declarative-debugger-for-concurrent-erlang-programs]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="concurrency"><![CDATA[Concurrency]]></category>
		<category domain="post_tag" nicename="declarative-debugging"><![CDATA[Declarative Debugging]]></category>
		<category domain="post_tag" nicename="erlang"><![CDATA[Erlang]]></category>
		<category domain="post_tag" nicename="semantics"><![CDATA[Semantics]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[509]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Erlang is a concurrent language with features such as actor model concurrency, no shared memory, message passing communication, high scalability and availability. However, the development of concurrent programs is a complex and error prone task. In this paper we present a declarative debugging approach for concurrent Erlang programs. Our debugger asks questions about the validity of transitions between the different points of the program that involve message passing and/or process creation. The answers, which represent the intended behavior of the program, are compared with the transitions obtained in an actual execution of the program. The differences allow us to detect program errors and to point out the pieces of source code responsible for the bugs. In order to represent the computations we present a semantic calculus for concurrent Core Erlang programs. The debugger uses the proof trees in this calculus as debugging trees used for selecting the questions asked to the user. The relation between the debugging trees and the semantic calculus allows us to establish the soundness of the approach. The theoretical ideas have been implemented in a debugger prototype. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Concurrency, Declarative Debugging, Erlang, Semantics]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[R. Caballero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rafacr@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[E. Martin-Martin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[emartinm@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[A. Riesco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ariesco@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Salvador Tamarit]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[stamarit@babel.ls.fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/016]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Constraint Programming Meets SQL</title>
		<link>https://biblioteca.sistedes.es/articulo/constraint-programming-meets-sql/</link>
		<pubDate>Fri, 11 Sep 2015 02:38:04 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=511</guid>
		<description></description>
		<content><![CDATA[We present a proposal for introducing SQL tuples into the modeling programming language MINIZINC. The domain of the new decision variables is defined by arbitrary relational database tables indicated by the user. The new setting increases the expressiveness of MINIZINC, allowing the modeler to mix the usual finite domains already existing in the language with string constraints typical from SQL such as concat, substr, or like. In order to obtain the solutions of these combined models, we first replace the atomic constraints involving strings by boolean variables. The result is a standard MINIZINC model, which can be solved by any off-the-shelf solver. Then, each individual solution is applied to the remainder string constraints, which are then solved using an SQL query. We discuss how both languages, MINIZINC and SQL, benefit from this combination.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>511</post_id>
		<post_date><![CDATA[2015-09-11 04:38:04]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:38:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[constraint-programming-meets-sql]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[512]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We present a proposal for introducing SQL tuples into the modeling programming language MINIZINC. The domain of the new decision variables is defined by arbitrary relational database tables indicated by the user. The new setting increases the expressiveness of MINIZINC, allowing the modeler to mix the usual finite domains already existing in the language with string constraints typical from SQL such as concat, substr, or like. In order to obtain the solutions of these combined models, we first replace the atomic constraints involving strings by boolean variables. The result is a standard MINIZINC model, which can be solved by any off-the-shelf solver. Then, each individual solution is applied to the remainder string constraints, which are then solved using an SQL query. We discuss how both languages, MINIZINC and SQL, benefit from this combination.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rafael Caballero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University Complutense de Madrid Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rafacr@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carlo Ieva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Simula Research Laboratory Oslo, Norway]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[carlo@simula.no]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/018]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Proving Continuity of Coinductive Global Bisimulation Distances: A Never Ending Story</title>
		<link>https://biblioteca.sistedes.es/articulo/proving-continuity-of-coinductive-global-bisimulation-distances-a-never-ending-story/</link>
		<pubDate>Fri, 11 Sep 2015 02:53:40 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=514</guid>
		<description></description>
		<content><![CDATA[We have developed a global approach to define bisimulation distances which goes somehow further away than the bisimulation distances based on the bisimulation game, previously proposed by some other authors. Our proposal is based on the cost of transformations: how much we need to modify one of the compared processes to obtain the other. Our original definition only covered finite processes, but a coinductive approach extends it to cover infinite but finitary trees. We have shown many interesting properties of our distances, and we wanted to prove their continuity with respect to projections, bur unfortunately we have not been able to accomplish that task. However, we have obtained several partial results that we now present in this paper.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>514</post_id>
		<post_date><![CDATA[2015-09-11 04:53:40]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:53:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[proving-continuity-of-coinductive-global-bisimulation-distances-a-never-ending-story]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[515]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We have developed a global approach to define bisimulation distances which goes somehow further away than the bisimulation distances based on the bisimulation game, previously proposed by some other authors. Our proposal is based on the cost of transformations: how much we need to modify one of the compared processes to obtain the other. Our original definition only covered finite processes, but a coinductive approach extends it to cover infinite but finitary trees. We have shown many interesting properties of our distances, and we wanted to prove their continuity with respect to projections, bur unfortunately we have not been able to accomplish that task. However, we have obtained several partial results that we now present in this paper.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Romero-Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ Facultad CC. Matematicas, Universidad Complutense de Madrid Madrid, Spain. Departamento de Sistemas Informaticos y Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[dromeroh@pdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David de Frutos-Escrig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ Facultad CC. Matematicas, Universidad Complutense de Madrid Madrid, Spain. Departamento de Sistemas Informaticos y Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[defrutos@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Dario Della Monica]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ ICE-TCS, School of Computer Science, Reykjavik University, Reykjavik, Iceland]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[dariodm@ru.is]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/012]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Generic Intermediate Representation for Verification Condition Generation, Work in Progress</title>
		<link>https://biblioteca.sistedes.es/articulo/a-generic-intermediate-representation-for-verification-condition-generation-work-in-progress/</link>
		<pubDate>Fri, 11 Sep 2015 02:56:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=517</guid>
		<description></description>
		<content><![CDATA[As part of a platform for computer-assisted verification, we present an intermediate representation of programs that is both language independent and appropriate for the generation of verification conditions. We show how many imperative and functional languages can be translated to this generic internal representation, and how the generated conditions faithfully reflect the semantics of the original program. At this representation level, loop invariants and preconditions of recursive functions belonging to the original program are represented by assertions placed at certain edges of a directed graph. The paper defines the generic representation, sketches the transformation algorithms, and describes how the places where the invariants should be placed are computed. Assuming that, either manually or assisted by the platform, the invariants have been settled, it is shown how the verification conditions are generated. A running example illustrates the process.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>517</post_id>
		<post_date><![CDATA[2015-09-11 04:56:50]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:56:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-generic-intermediate-representation-for-verification-condition-generation-work-in-progress]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="intermediate-representation"><![CDATA[intermediate representation]]></category>
		<category domain="post_tag" nicename="program-transformation"><![CDATA[program transformation.]]></category>
		<category domain="post_tag" nicename="verification-conditions"><![CDATA[verification conditions]]></category>
		<category domain="post_tag" nicename="verification-platforms"><![CDATA[verification platforms]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[518]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[As part of a platform for computer-assisted verification, we present an intermediate representation of programs that is both language independent and appropriate for the generation of verification conditions. We show how many imperative and functional languages can be translated to this generic internal representation, and how the generated conditions faithfully reflect the semantics of the original program. At this representation level, loop invariants and preconditions of recursive functions belonging to the original program are represented by assertions placed at certain edges of a directed graph. The paper defines the generic representation, sketches the transformation algorithms, and describes how the places where the invariants should be placed are computed. Assuming that, either manually or assisted by the platform, the invariants have been settled, it is shown how the verification conditions are generated. A running example illustrates the process.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[verification platforms, intermediate representation, verification conditions, program transformation.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel Montenegro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[montenegro@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Ricardo Peña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ricardo@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jaime Sánchez-Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jaime@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/027]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Productivity of rewrite systems without transformations</title>
		<link>https://biblioteca.sistedes.es/articulo/productivity-of-rewrite-systems-without-transformations/</link>
		<pubDate>Fri, 11 Sep 2015 02:59:43 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=522</guid>
		<description></description>
		<content><![CDATA[Termination of programs, i.e., the absence of infinite computations, ensures the existence of normal forms for all initial expressions, thus providing an essential ingredient for the definition of a normalization semantics for functional programs. In lazy functional languages, though, infinite data structures are often delivered as the outcome of computations. For instance, the list of all prime numbers can be returned as a neverending stream of numerical expressions or data structures. If such streams are allowed, requiring termination is hopeless. In this setting, the notion of productivity can be used to provide an account of computations with infinite data structures, as it “captures the idea of computability, of progress of infinite-list programs” (B.A. Sijtsma, On the Productivity of Recursive List Definitions, ACM Transactions on Programming Languages and Systems 11(4):633- 649, 1989). However, in the realm of Term Rewriting Systems, which can be seen as (first-order, untyped, unconditional) functional programs, termination of Context-Sensitive Rewriting (CSR) has been showed equivalent to productivity of rewrite systems through appropriate transformations. In this way, tools for proving termination of CSR can be used to prove productivity. In term rewriting, CSR is the restriction of rewriting that arises when reductions are allowed on selected arguments of function symbols only. In this paper we show that well-known results about the computational power or CSR are useful to better understand the existing connections between productivity of rewrite systems and termination of CSR, and also to obtain more powerful techniques to prove productivity of rewrite systems.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>522</post_id>
		<post_date><![CDATA[2015-09-11 04:59:43]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 02:59:43]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[productivity-of-rewrite-systems-without-transformations]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="context-sensitive-rewriting"><![CDATA[context-sensitive rewriting]]></category>
		<category domain="post_tag" nicename="functional-programming"><![CDATA[functional programming]]></category>
		<category domain="post_tag" nicename="productivity"><![CDATA[productivity]]></category>
		<category domain="post_tag" nicename="termination"><![CDATA[termination]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[523]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Termination of programs, i.e., the absence of infinite computations, ensures the existence of normal forms for all initial expressions, thus providing an essential ingredient for the definition of a normalization semantics for functional programs. In lazy functional languages, though, infinite data structures are often delivered as the outcome of computations. For instance, the list of all prime numbers can be returned as a neverending stream of numerical expressions or data structures. If such streams are allowed, requiring termination is hopeless. In this setting, the notion of productivity can be used to provide an account of computations with infinite data structures, as it “captures the idea of computability, of progress of infinite-list programs” (B.A. Sijtsma, On the Productivity of Recursive List Definitions, ACM Transactions on Programming Languages and Systems 11(4):633- 649, 1989). However, in the realm of Term Rewriting Systems, which can be seen as (first-order, untyped, unconditional) functional programs, termination of Context-Sensitive Rewriting (CSR) has been showed equivalent to productivity of rewrite systems through appropriate transformations. In this way, tools for proving termination of CSR can be used to prove productivity. In term rewriting, CSR is the restriction of rewriting that arises when reductions are allowed on selected arguments of function symbols only. In this paper we show that well-known results about the computational power or CSR are useful to better understand the existing connections between productivity of rewrite systems and termination of CSR, and also to obtain more powerful techniques to prove productivity of rewrite systems.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ context-sensitive rewriting, functional programming, productivity, termination]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Lucas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politécnica de Valéncia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[http://users.dsic.upv.es/~slucas/]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/015]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Collection of Website Benchmarks Labelled for Template Detection and Content Extraction</title>
		<link>https://biblioteca.sistedes.es/articulo/a-collection-of-website-benchmarks-labelled-for-template-detection-and-content-extraction/</link>
		<pubDate>Fri, 11 Sep 2015 03:03:57 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=525</guid>
		<description></description>
		<content><![CDATA[Template detection and content extraction are two of the main areas of information retrieval applied to the Web. They perform different analyses over the structure and content of webpages to extract some part of the document. However, their objectives are different. While template detection identifies the template of a webpage (usually comparing with other webpages of the same website), content extraction identifies the main content of the webpage discarding the other part. Therefore, they are somehow complementary, because the main content is not part of the template. It has been measured that templates represent between 40% and 50% of data on the Web. Therefore, identifying templates is essential for indexing tasks because templates usually contain irrelevant information such as advertisements, menus and banners. Processing and storing this information is likely to lead to a waste of resources (storage space, bandwidth, etc.). Similarly, identifying the main content is essential for many information retrieval tasks. In this paper, we present a benchmark suite to test different approaches for template detection and content extraction. The suite is public, and it contains real heterogeneous webpages that have been labelled so that different techniques can be suitable (and automatically) compared.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>525</post_id>
		<post_date><![CDATA[2015-09-11 05:03:57]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:03:57]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-collection-of-website-benchmarks-labelled-for-template-detection-and-content-extraction]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[526]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Template detection and content extraction are two of the main areas of information retrieval applied to the Web. They perform different analyses over the structure and content of webpages to extract some part of the document. However, their objectives are different. While template detection identifies the template of a webpage (usually comparing with other webpages of the same website), content extraction identifies the main content of the webpage discarding the other part. Therefore, they are somehow complementary, because the main content is not part of the template. It has been measured that templates represent between 40% and 50% of data on the Web. Therefore, identifying templates is essential for indexing tasks because templates usually contain irrelevant information such as advertisements, menus and banners. Processing and storing this information is likely to lead to a waste of resources (storage space, bandwidth, etc.). Similarly, identifying the main content is essential for many information retrieval tasks. In this paper, we present a benchmark suite to test different approaches for template detection and content extraction. The suite is public, and it contains real heterogeneous webpages that have been labelled so that different techniques can be suitable (and automatically) compared.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julián Alarte]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalarte@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David Insa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[dinsa@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Josep Silva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jsilva@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Salvador Tamarit]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[stamarit@babel.ls.fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/009]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Reasoning about policy behavior in logic-based trust management systems: Some complexity results and an operational framework</title>
		<link>https://biblioteca.sistedes.es/articulo/reasoning-about-policy-behavior-in-logic-based-trust-management-systems-some-complexity-results-and-an-operational-framework/</link>
		<pubDate>Fri, 11 Sep 2015 03:08:58 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=528</guid>
		<description></description>
		<content><![CDATA[In this paper we show that the logical framework proposed by Becker et al. [1] to reason about security policy behavior in a trust management context can be captured by an operational framework that is based on the language proposed by Miller in 1989 to deal with scoping and/or modules in logic programming. The framework of Becker et al. uses propositional Horn clauses to represent both policies and credentials, implications in clauses are interpreted in counterfactual logic, a Hilbertstyle proof system is defined and a system based on SAT is used to prove whether properties about credentials, permissions and policies are valid, i.e. true under all possible policies. Our contributions in this paper are three. First, we show that this kind of validation can rely on an operational semantics (derivability relation) of a language very similar to Miller’s language, which is very close to derivability in logic programs. Second, we are able to establish that, as in propositional logic, validity of formulas is a co-NP-complete problem. And third, we present a provably correct implementation of a goal-oriented algorithm for validity.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>528</post_id>
		<post_date><![CDATA[2015-09-11 05:08:58]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:08:58]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[reasoning-about-policy-behavior-in-logic-based-trust-management-systems-some-complexity-results-and-an-operational-framework]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[529]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper we show that the logical framework proposed by Becker et al. [1] to reason about security policy behavior in a trust management context can be captured by an operational framework that is based on the language proposed by Miller in 1989 to deal with scoping and/or modules in logic programming. The framework of Becker et al. uses propositional Horn clauses to represent both policies and credentials, implications in clauses are interpreted in counterfactual logic, a Hilbertstyle proof system is defined and a system based on SAT is used to prove whether properties about credentials, permissions and policies are valid, i.e. true under all possible policies. Our contributions in this paper are three. First, we show that this kind of validation can rely on an operational semantics (derivability relation) of a language very similar to Miller’s language, which is very close to derivability in logic programs. Second, we are able to establish that, as in propositional logic, validity of formulas is a co-NP-complete problem. And third, we present a provably correct implementation of a goal-oriented algorithm for validity.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Edelmira Pasarella]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departament de Ciencies de la Computació Universitat Politecnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[edelmira@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jorge Lobo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Institució Catalana de Recerca i Estudis Avancats (ICREA) DTIC – Universitat Pompeu Fabra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jorge.lobo@upf.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/011]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Inferring Specifications in the K framework</title>
		<link>https://biblioteca.sistedes.es/articulo/inferring-specifications-in-the-k-framework/</link>
		<pubDate>Fri, 11 Sep 2015 03:14:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=531</guid>
		<description></description>
		<content><![CDATA[Despite its many unquestionable benefits, formal specifications are not widely used in industrial software development. In order to reduce the time and effort required to write formal specifications, in this paper we propose a technique for automatically discovering specifications from real code. The proposed methodology relies on the symbolic execution capabilities recently provided by the K framework that we exploit to automatically infer formal specifications from programs that are written in a non–trivial fragment of C, called KERNELC. Roughly speaking, our symbolic analysis of KERNELC programs explains the execution of a (modifier) function by using other (observer) routines in the program. We implemented our technique in the automated tool KINDSPEC 2.0, which generates axioms that describe the precise input/output behavior of C routines that handle pointerbased structures (i.e., result values and state change). We describe the implementation of our system and discuss the differences w.r.t. our previous work on inferring specifications from C code.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>531</post_id>
		<post_date><![CDATA[2015-09-11 05:14:07]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:14:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[inferring-specifications-in-the-k-framework]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[532]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Despite its many unquestionable benefits, formal specifications are not widely used in industrial software development. In order to reduce the time and effort required to write formal specifications, in this paper we propose a technique for automatically discovering specifications from real code. The proposed methodology relies on the symbolic execution capabilities recently provided by the K framework that we exploit to automatically infer formal specifications from programs that are written in a non–trivial fragment of C, called KERNELC. Roughly speaking, our symbolic analysis of KERNELC programs explains the execution of a (modifier) function by using other (observer) routines in the program. We implemented our technique in the automated tool KINDSPEC 2.0, which generates axioms that describe the precise input/output behavior of C routines that handle pointerbased structures (i.e., result values and state change). We describe the implementation of our system and discuss the differences w.r.t. our previous work on inferring specifications from C code.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Alpuente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alpuente@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Daniel Pardo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[dparpon@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alicia Villanueva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[villanue@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/023]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Satisfiability of Constraint Specifications on XML Documents</title>
		<link>https://biblioteca.sistedes.es/articulo/satisfiability-of-constraint-specifications-on-xml-documents/</link>
		<pubDate>Fri, 11 Sep 2015 03:19:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=534</guid>
		<description></description>
		<content><![CDATA[In this work, we present an approach for specifying the structure of XML documents using three kinds of constraints based on XPath, together with a sound and complete method for reasoning about them. Currently, the standard specification of classes of XML documents is done by means of DTDs or XML Schemas. In both cases, we essentially describe the abstract syntax of the class of documents and the types of its attributes. This is quite limited. In particular, we may want to state more complex conditions about the structure of documents in a given class or about their contents. For example, with respect to the structure of documents, we may want to state that if an element includes an attribute with a given content, then these documents should not include some other element. Or, with respect to the contents of documents, we may want to express that the value of some numeric attribute of a certain element is smaller than the value of another attribute of a different element. In this paper, we concentrate on the specification of the structure of documents, not paying much attention to their contents. In this sense, we present an abstract approach for the specification of (the structure of) classes of XML documents using sets of constraints that are based on XPath [8, 9] queries, as given in [4], using the concept of tree patterns. Roughly, a tree pattern describes a basic property on the structure of documents. Its root repre sents the root of documents. Nodes represent elements that must be present on the given documents and their labels represent their contents, i.e. the names of elements and their value, if any. A wild card (the symbol ∗), means that we don’t know or we don’t care about the contents of that element. Finally, single edges represent parent/child relations between elements, while double edges represent a descendant relationship between elements. Again, if any of these two relations is included in a tree pattern, then it should also be included in the documents satisfying that property. For instance, on the left of Fig. 1 we show a tree pattern p describing documents D whose root node is labelled with a, some child node of the root node in D is labelled b, and some descendant node of the root node in D has two child nodes labelled c and d, respectively. Similarly, we represent, in an abstract way, XML documents using the same kind of trees. The difference between a document and a tree pattern is that a document does not include double edges or wildcards. For example, on the right of Fig. 1 we show a document that satisfies the pattern on the left. In particular, we may see that the root of the document is labelled by a. Moreover, that root has a child node labelled b and a descendant node (the element labelled f) that has two child nodes labelled c and d, respectively. We consider three kinds of (atomic) constraints. The first one, called positive constraints, are tree patterns. The second one are negative constraints, ¬p, where p is a tree pattern, expressing that documents should not satisfy p. Finally, the third sort of constraint are conditional constraints, written ∀(c : p → q), where both p and q are tree patterns. Roughly speaking, these constraints express that if a document satisfies p then it must also satisfy q. Moreover, these constraints can be combined using the connectives ∧ and ∨. These kinds of constraints are similar to the graph constraints studied in [6, 7] in the context of graph transformation. The work presented in those papers, shows how to use graph constraints as a specification formalism, and how to reason about these specifications. However, the application of these ideas to our setting is not trivial. Specifically, the descendant relation in our constraints makes non-trivial the application of these techniques since, the descendent relation would be second-order in the logic of graph constraints defined in [6, 7]. Obviously, there are conditions on the structure of XML documents that are not expressible using the kind of constraints studied in this paper. However, our experience in the area of graph transformation [6, 7] shows that, in practice, these constraints are sufficient in most cases. Nevertheless, we believe that the ideas presented here can be extended to a class of XML constraints, similar to the class of nested graph conditions that has been shown equivalent to first-order logic of graphs [2]. However, we also believe that this extension is not straightforward. Since our aim is to be able to reason about these specifications, we present inference rules that are shown, by means of tableaux, to define a sound and complete refutation procedure for checking satisfiability of a given specification. We strongly believe that satisfiability problem for this class of constraints is only semidecidable, since we believe that it would be similar to the (un)decidability of the satisfiability problem for the Horn clause fragment of first-order logic. As a consequence, if a given specification is inconsistent, we can be sure that our procedure will terminate showing that unsatisfiability. However, our procedure may not terminate if the given specification is satisfiable. Nevertheless, we may like to have an idea about the performance of our approach when the procedure terminates. One could think, that this performance would be quite poor, since checking if there is a monomorphism between two trees (a basic operation in our deduction procedure) is an NP-complete problem [3]. Actually, this is not our experience with the tool that we have implemented [1]. We think that the situation is similar to what happens with graph transformation tools. In these tools, applying a graph transformation rule means finding a subgraph isomorphism, which is also a wellknown NP-complete problem. However, the fact that the graphs are typed (in our case, the trees are labelled), in practice, reduces considerably the search. Finally, in the future, we plan to extend our approach to consider also cross-references and properties about the contents of documents. The former problem means, in fact, to extend our approach to graphs and graph patterns. For the latter case, we plan to follow the same approach that we used to extend our results for graphs in [6, 7] to the case of attributed graphs in [5].]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>534</post_id>
		<post_date><![CDATA[2015-09-11 05:19:52]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:19:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[satisfiability-of-constraint-specifications-on-xml-documents]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[535]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this work, we present an approach for specifying the structure of XML documents using three kinds of constraints based on XPath, together with a sound and complete method for reasoning about them. Currently, the standard specification of classes of XML documents is done by means of DTDs or XML Schemas. In both cases, we essentially describe the abstract syntax of the class of documents and the types of its attributes. This is quite limited. In particular, we may want to state more complex conditions about the structure of documents in a given class or about their contents. For example, with respect to the structure of documents, we may want to state that if an element includes an attribute with a given content, then these documents should not include some other element. Or, with respect to the contents of documents, we may want to express that the value of some numeric attribute of a certain element is smaller than the value of another attribute of a different element. In this paper, we concentrate on the specification of the structure of documents, not paying much attention to their contents. In this sense, we present an abstract approach for the specification of (the structure of) classes of XML documents using sets of constraints that are based on XPath [8, 9] queries, as given in [4], using the concept of tree patterns. Roughly, a tree pattern describes a basic property on the structure of documents. Its root repre sents the root of documents. Nodes represent elements that must be present on the given documents and their labels represent their contents, i.e. the names of elements and their value, if any. A wild card (the symbol ∗), means that we don’t know or we don’t care about the contents of that element. Finally, single edges represent parent/child relations between elements, while double edges represent a descendant relationship between elements. Again, if any of these two relations is included in a tree pattern, then it should also be included in the documents satisfying that property. For instance, on the left of Fig. 1 we show a tree pattern p describing documents D whose root node is labelled with a, some child node of the root node in D is labelled b, and some descendant node of the root node in D has two child nodes labelled c and d, respectively. Similarly, we represent, in an abstract way, XML documents using the same kind of trees. The difference between a document and a tree pattern is that a document does not include double edges or wildcards. For example, on the right of Fig. 1 we show a document that satisfies the pattern on the left. In particular, we may see that the root of the document is labelled by a. Moreover, that root has a child node labelled b and a descendant node (the element labelled f) that has two child nodes labelled c and d, respectively. We consider three kinds of (atomic) constraints. The first one, called positive constraints, are tree patterns. The second one are negative constraints, ¬p, where p is a tree pattern, expressing that documents should not satisfy p. Finally, the third sort of constraint are conditional constraints, written ∀(c : p → q), where both p and q are tree patterns. Roughly speaking, these constraints express that if a document satisfies p then it must also satisfy q. Moreover, these constraints can be combined using the connectives ∧ and ∨. These kinds of constraints are similar to the graph constraints studied in [6, 7] in the context of graph transformation. The work presented in those papers, shows how to use graph constraints as a specification formalism, and how to reason about these specifications. However, the application of these ideas to our setting is not trivial. Specifically, the descendant relation in our constraints makes non-trivial the application of these techniques since, the descendent relation would be second-order in the logic of graph constraints defined in [6, 7]. Obviously, there are conditions on the structure of XML documents that are not expressible using the kind of constraints studied in this paper. However, our experience in the area of graph transformation [6, 7] shows that, in practice, these constraints are sufficient in most cases. Nevertheless, we believe that the ideas presented here can be extended to a class of XML constraints, similar to the class of nested graph conditions that has been shown equivalent to first-order logic of graphs [2]. However, we also believe that this extension is not straightforward. Since our aim is to be able to reason about these specifications, we present inference rules that are shown, by means of tableaux, to define a sound and complete refutation procedure for checking satisfiability of a given specification. We strongly believe that satisfiability problem for this class of constraints is only semidecidable, since we believe that it would be similar to the (un)decidability of the satisfiability problem for the Horn clause fragment of first-order logic. As a consequence, if a given specification is inconsistent, we can be sure that our procedure will terminate showing that unsatisfiability. However, our procedure may not terminate if the given specification is satisfiable. Nevertheless, we may like to have an idea about the performance of our approach when the procedure terminates. One could think, that this performance would be quite poor, since checking if there is a monomorphism between two trees (a basic operation in our deduction procedure) is an NP-complete problem [3]. Actually, this is not our experience with the tool that we have implemented [1]. We think that the situation is similar to what happens with graph transformation tools. In these tools, applying a graph transformation rule means finding a subgraph isomorphism, which is also a wellknown NP-complete problem. However, the fact that the graphs are typed (in our case, the trees are labelled), in practice, reduces considerably the search. Finally, in the future, we plan to extend our approach to consider also cross-references and properties about the contents of documents. The former problem means, in fact, to extend our approach to graphs and graph patterns. For the latter case, we plan to follow the same approach that we used to extend our results for graphs in [6, 7] to the case of attributed graphs in [5].]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Marisa Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad del País Vasco Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[marisa.navarro@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando Orejas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[orejas@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Elvira Pino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pino@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/022]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Property based Testing of XQuery Programs</title>
		<link>https://biblioteca.sistedes.es/articulo/property-based-testing-of-xquery-programs/</link>
		<pubDate>Fri, 11 Sep 2015 03:24:23 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=537</guid>
		<description></description>
		<content><![CDATA[In this paper we present the elements of an XQuery testing tool which makes possible to automatically test XQuery programs. The tool is able to systematically generate XML instances (i.e., test cases) from a given XML schema. The number and type of instances is defined by the human tester. These instances are used to execute the given XQuery program. In addition, the tool makes possible to provide an user defined property to be tested against the output of the XQuery program. The property can be specified with a Boolean XQuery function. The tool is implemented as an oracle able to report whether the XQuery program passes the test, that is, all the test cases satisfy the property, as well as the number of test cases used for testing. In the case when the XQuery program fails the testing, the tool shows counterexamples found in the test cases. The tool has been implemented as an XQuery library which makes possible to be used from any XQuery interpreter.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>537</post_id>
		<post_date><![CDATA[2015-09-11 05:24:23]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:24:23]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[property-based-testing-of-xquery-programs]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[538]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper we present the elements of an XQuery testing tool which makes possible to automatically test XQuery programs. The tool is able to systematically generate XML instances (i.e., test cases) from a given XML schema. The number and type of instances is defined by the human tester. These instances are used to execute the given XQuery program. In addition, the tool makes possible to provide an user defined property to be tested against the output of the XQuery program. The property can be specified with a Boolean XQuery function. The tool is implemented as an oracle able to report whether the XQuery program passes the test, that is, all the test cases satisfy the property, as well as the number of test cases used for testing. In the case when the XQuery program fails the testing, the tool shows counterexamples found in the test cases. The tool has been implemented as an XQuery library which makes possible to be used from any XQuery interpreter.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesus M. Almendros-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informatica. Universidad de Almería. 04120-Almería. SPAIN.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalmen@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Antonio Becerra-Terón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informatica. Universidad de Almería. 04120-Almería. SPAIN.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[abecerra@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/008]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A discretized operational semantics for the implementation of Hy-tccp</title>
		<link>https://biblioteca.sistedes.es/articulo/a-discretized-operational-semantics-for-the-implementation-of-hy-tccp/</link>
		<pubDate>Fri, 11 Sep 2015 03:27:34 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=540</guid>
		<description></description>
		<content><![CDATA[The language Hy-tccp was proposed as an extension of the Timed Concurrent Constraint paradigm (tccp) with continuous time and suitable mechanisms to handle continuous behaviors. This language provides a powerful model for hybrid and cyber-physical systems including concurrency and syn chronization features. In this paper, we propose a discretized operational semantics for Hy-tccp and an extension of the standard LTL to reason about temporal properties of Hy-tccp programs. The semantics and the logics will be the basis for the definition of formal verification and analysis tools, such as model checkers and theorem provers.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>540</post_id>
		<post_date><![CDATA[2015-09-11 05:27:34]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:27:34]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-discretized-operational-semantics-for-the-implementation-of-hy-tccp]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[541]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The language Hy-tccp was proposed as an extension of the Timed Concurrent Constraint paradigm (tccp) with continuous time and suitable mechanisms to handle continuous behaviors. This language provides a powerful model for hybrid and cyber-physical systems including concurrency and syn chronization features. In this paper, we propose a discretized operational semantics for Hy-tccp and an extension of the standard LTL to reason about temporal properties of Hy-tccp programs. The semantics and the logics will be the basis for the definition of formal verification and analysis tools, such as model checkers and theorem provers.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María del Mar Gallardo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dept. Lenguajes y Ciencias de la Computación E.T.S.I. Informatica University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[gallardo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Laura Panizo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dept. Lenguajes y Ciencias de la Computación E.T.S.I. Informatica University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[laurapanizo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Laura Titolo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dept. Lenguajes y Ciencias de la Computación E.T.S.I. Informatica University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[laura.titolo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/010]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Learning a Subclass of Multivalued Dependencies Formulas from Entailments</title>
		<link>https://biblioteca.sistedes.es/articulo/learning-a-subclass-of-multivalued-dependencies-formulas-from-entailments/</link>
		<pubDate>Fri, 11 Sep 2015 03:30:44 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=543</guid>
		<description></description>
		<content><![CDATA[Functional and multivalued dependencies play an important role in the design of relational databases. There is a strong connection between data dependencies and some fragments of the propositional logic. In particular, functional dependencies are closely related to Horn formulas. Also, multivalued dependencies are characterized in terms of multivalued formulas. It is known that both Horn formulas and sets of functional dependencies are efficiently learnable in the exact model of learning with queries. In this work, we study the learnability of a non-trivial subclass of multivalued formulas called CRMVDF. We use Angluin’s exact learning model with membership and equivalence queries and present a polynomial time algorithm which exactly learns CRMVDF from entailments.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>543</post_id>
		<post_date><![CDATA[2015-09-11 05:30:44]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:30:44]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[learning-a-subclass-of-multivalued-dependencies-formulas-from-entailments]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[544]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Functional and multivalued dependencies play an important role in the design of relational databases. There is a strong connection between data dependencies and some fragments of the propositional logic. In particular, functional dependencies are closely related to Horn formulas. Also, multivalued dependencies are characterized in terms of multivalued formulas. It is known that both Horn formulas and sets of functional dependencies are efficiently learnable in the exact model of learning with queries. In this work, we study the learnability of a non-trivial subclass of multivalued formulas called CRMVDF. We use Angluin’s exact learning model with membership and equivalence queries and present a polynomial time algorithm which exactly learns CRMVDF from entailments.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Montserrat Hermo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Languages and Information Systems The University of the Basque Country (UPV/EHU)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[montserrat.hermo@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ana Ozaki]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science University of Liverpool, UK]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[anaozaki@liverpool.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/019]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Abstract Diagnosis for tccp using a Linear Temporal Logic</title>
		<link>https://biblioteca.sistedes.es/articulo/abstract-diagnosis-for-tccp-using-a-linear-temporal-logic/</link>
		<pubDate>Fri, 11 Sep 2015 03:33:41 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=546</guid>
		<description></description>
		<content><![CDATA[This extended abstract is a summary of [5], where we provided an automatic decision method to check whether a given property, specified in a linear temporal logic, is valid w.r.t. a tccp program. Our proposal (based on abstract interpretation techniques) does not require to build any model of the program, in constrast with standard verification methods such as model checking. Our results guarantee correctness but, as usual when using an abstract semantics, completeness is lost.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>546</post_id>
		<post_date><![CDATA[2015-09-11 05:33:41]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:33:41]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[abstract-diagnosis-for-tccp-using-a-linear-temporal-logic]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[10]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[547]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This extended abstract is a summary of [5], where we provided an automatic decision method to check whether a given property, specified in a linear temporal logic, is valid w.r.t. a tccp program. Our proposal (based on abstract interpretation techniques) does not require to build any model of the program, in constrast with standard verification methods such as model checking. Our results guarantee correctness but, as usual when using an abstract semantics, completeness is lost.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[M. Comini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dipartimento di Matematica e Informatica, U. di Udine]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[L. Titolo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dipartimento di Matematica e Informatica, U. di Udine]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[A. Villanueva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politécnica de Valéncia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/026]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Using Model Checking to Generate Test Cases for Android Applications</title>
		<link>https://biblioteca.sistedes.es/articulo/using-model-checking-to-generate-test-cases-for-android-applications/</link>
		<pubDate>Fri, 11 Sep 2015 03:36:45 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=549</guid>
		<description></description>
		<content><![CDATA[The behavior of mobile devices is highly non deterministic and barely predictable due to the interaction of the user with its applications. In consequence, analyzing the correctness of applications running on a smartphone involves dealing with the complexity of its environment. In this paper, we propose the use of model-based testing to describe the potential behaviors of users interacting with mobile applications. These behaviors are modeled by composing specially-designed state machines. These composed state machines can be exhaustively explored using a model checking tool to automatically generate all possible user interactions. Each generated trace model checker can be interpreted as a test case to drive a runtime analysis of actual applications. We have implemented a tool that follows the proposed methodology to analyze ANDROID devices using the model checker SPIN as the exhaustive generator of test cases.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>549</post_id>
		<post_date><![CDATA[2015-09-11 05:36:45]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:36:45]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[using-model-checking-to-generate-test-cases-for-android-applications]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[550]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The behavior of mobile devices is highly non deterministic and barely predictable due to the interaction of the user with its applications. In consequence, analyzing the correctness of applications running on a smartphone involves dealing with the complexity of its environment. In this paper, we propose the use of model-based testing to describe the potential behaviors of users interacting with mobile applications. These behaviors are modeled by composing specially-designed state machines. These composed state machines can be exhaustively explored using a model checking tool to automatically generate all possible user interactions. Each generated trace model checker can be interpreted as a test case to drive a runtime analysis of actual applications. We have implemented a tool that follows the proposed methodology to analyze ANDROID devices using the model checker SPIN as the exhaustive generator of test cases.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana Rosario Espada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dept. Lenguajes y Ciencias de la Computación E.T.S.I. Informatica University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[anarosario@lcc.uma.e]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[María del Mar Gallardo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dept. Lenguajes y Ciencias de la Computación E.T.S.I. Informatica University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gallardo@lcc.uma.e]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alberto Salmerón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dept. Lenguajes y Ciencias de la Computación E.T.S.I. Informatica University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[salmeron@lcc.uma.e]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Pedro Merino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dept. Lenguajes y Ciencias de la Computación E.T.S.I. Informatica University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[pedro@lcc.uma.e]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/007]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards a Formal Semantics-Based Technique for Interprocedural Slicing</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-a-formal-semantics-based-technique-for-interprocedural-slicing/</link>
		<pubDate>Fri, 11 Sep 2015 03:39:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=552</guid>
		<description></description>
		<content><![CDATA[Interprocedural slicing is a technique applied on programs with procedures which relies on how the information is passed at procedure call/return sites. Such a technique computes program slices (i.e. program fragments restricted w.r.t. a given criterion). The existing approaches to interprocedural slicing exploit the particularities of the underlying language semantics in order to compute program slices. In this paper we propose a generic technique for interprocedural slicing. More specifically, our approach works with inferred particularities of a language semantics, given as a rewriting-logic specification, and computes program slices using a term slicing-based algorithm.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>552</post_id>
		<post_date><![CDATA[2015-09-11 05:39:53]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:39:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-a-formal-semantics-based-technique-for-interprocedural-slicing]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[553]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Interprocedural slicing is a technique applied on programs with procedures which relies on how the information is passed at procedure call/return sites. Such a technique computes program slices (i.e. program fragments restricted w.r.t. a given criterion). The existing approaches to interprocedural slicing exploit the particularities of the underlying language semantics in order to compute program slices. In this paper we propose a generic technique for interprocedural slicing. More specifically, our approach works with inferred particularities of a language semantics, given as a rewriting-logic specification, and computes program slices using a term slicing-based algorithm.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Irina Mariuca Asavoae]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Swansea University, United Kingdom]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[I.M.Asavoae@swansea.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mihail Asavoae]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Inria Rocquencourt, France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mihail.asavoae@inria.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Adrian Riesco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ariesco@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automatic generation of logical models for order-sorted first-order theories in program analysis</title>
		<link>https://biblioteca.sistedes.es/articulo/automatic-generation-of-logical-models-for-order-sorted-first-order-theories-in-program-analysis/</link>
		<pubDate>Fri, 11 Sep 2015 03:42:37 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=555</guid>
		<description></description>
		<content><![CDATA[Computations are often viewed as proofs of specific sentences in some computational logic describing the operational semantics of the programming language or computational system. Since the semantics of programs (i.e., the set of such specific sentences that are provable in the logic) is usually incomputable, and most program properties undecidable, abstraction is essential in program analysis. Abstractions can be formalized as semantic models which should be automatically generated in a push-the-button-and-wait style of program analysis and verification. We investigate the automatic generation of numerical models for order-sorted first-order logics and its use in program analysis. Our development systematically uses the recently introduced convex domains which are well-suited for representing domains for different sorts; we use them to interpret the ranked symbols of sorted signatures by means of appropriately adapted convex matrix interpretations. Such numerical interpretations permit the use of existing algorithms and tools from linear algebra (e.g., Farkas’ Lemma), real algebraic geometry, and arithmetic constraint solving in the implementation of the analyses.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>555</post_id>
		<post_date><![CDATA[2015-09-11 05:42:37]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:42:37]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automatic-generation-of-logical-models-for-order-sorted-first-order-theories-in-program-analysis]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="abstraction"><![CDATA[Abstraction]]></category>
		<category domain="post_tag" nicename="logical-models"><![CDATA[Logical models]]></category>
		<category domain="post_tag" nicename="order-sorted-first-order-logic"><![CDATA[Order-sorted first-order logic]]></category>
		<category domain="post_tag" nicename="program-analysis"><![CDATA[Program analysis]]></category>
		<category domain="post_tag" nicename="termination"><![CDATA[termination]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[556]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Computations are often viewed as proofs of specific sentences in some computational logic describing the operational semantics of the programming language or computational system. Since the semantics of programs (i.e., the set of such specific sentences that are provable in the logic) is usually incomputable, and most program properties undecidable, abstraction is essential in program analysis. Abstractions can be formalized as semantic models which should be automatically generated in a push-the-button-and-wait style of program analysis and verification. We investigate the automatic generation of numerical models for order-sorted first-order logics and its use in program analysis. Our development systematically uses the recently introduced convex domains which are well-suited for representing domains for different sorts; we use them to interpret the ranked symbols of sorted signatures by means of appropriately adapted convex matrix interpretations. Such numerical interpretations permit the use of existing algorithms and tools from linear algebra (e.g., Farkas’ Lemma), real algebraic geometry, and arithmetic constraint solving in the implementation of the analyses.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Abstraction, Logical models, Order-sorted first-order logic, Program analysis, Termination]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Lucas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politécnica de Valéncia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[http://users.dsic.upv.es/~slucas/]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Assertional Proof of the Stability and Correctness of Natural Mergesort</title>
		<link>https://biblioteca.sistedes.es/articulo/an-assertional-proof-of-the-stability-and-correctness-of-natural-mergesort/</link>
		<pubDate>Fri, 11 Sep 2015 03:45:11 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=558</guid>
		<description></description>
		<content><![CDATA[Natural Mergesort [9] is a sorting algorithm for linear data structures (arrays and lists) that has been widely studied mainly due to its good properties. It has Nlog(N) worst-case complexity and, even in the case of arrays, is slightly easier to code than heapsort. Further, it performs very well on input data that is already mostly sorted. Another good property is stability. A sorting algorithm is stable if it maintains the relative order of records with equal keys. The most obvious application of a stable algorithm is sorting using different (primary, secondary, etc.) keys. Stability is, as we show in lemma EqMultisets, stronger than the property of preserving the multiset of elements (from the input list to the sorted output list). Hence, stability, along with sortedness, implies the correctness of sorting algorithms (including the permutation property). Recently, Sternagel [13] has published an Isabelle/HOL proof of the correctness and stability of natural mergesort as a proof pearl. Sternagel [13], firstly, specifies the algorithm as a functional program and, then, formalizes and proves the desired properties using the proof-assistant Isabelle/HOL. The proof is non-assertional and uses higher-order constructions. Indeed, it is strongly based on two skillful ad-hoc induction schemes. The first one for handling the mutually recursive functions involved in the splitting of the input into ascending sequences. The second induction scheme is related to the merging of the ascending lists. Correctness and stability are deduced from auxiliary lemmas which are proved by means of these induction schemes and with the help of a subtle generalization of the predicate sorted. The definition of that generalization and the induction schemes require the power of higher-order logic. In particular, the stability property is formalized in higher-order logic. More recently, de Gouw et al. [7] discussed a semi-automated formal proof of the correctness and stability of two sorting algorithms on arrays: Counting sort and Radix sort. This proof is formalized using the theorem-prover KeY [2]. The implementation code is written in Java. The specification is written (using the Java Modeling Language, JML) in an extension of first-order logic with permutation predicates, which have recently been added [1] to the KeY system. There are many other formalizations of the natural mergesort algorithm and also of different sorting algorithms (e.g. insertion sort, quicksort, heapsort, radix sort, etc.) in various systems, such as Coq [3], Isabelle/HOL [12], Why3 [6], ACL2 [8], KeY [2], etc. However, to the best of our knowledge, stability is only considered in [13], [7], and in our assertional proof. In this paper, we present an implementation of natural mergesort over an algebraic data type of lists. The code is enriched with its contract-based specification and a proof of its correctness and its stability. Our proof is assertional, i.e. it uses assert statements, inserted in the code, to enable the (fully) automatic verification. The assertions are first-order formulas that explain how and why the program works. The proof is supported by a few definitions that are easy to understand, and a few lemmas that isolate useful properties. Moreover, only non-trivial lemmas have detailed proofs and these are short and easy to read and to understand. Hence, in our opinion, the presented proof is quite clear and elegant. The program-proof is implemented in the state-of-the-art verifier Dafny [10]. The Dafny programming language supports a mixture of imperative, object-oriented programming and functional programming. In this paper, we use mostly functions, methods, and algebraic datatypes. The Dafny specification language includes the usual assertional language for contracts of pre/post conditions, invariants, decreasing expressions for termination proofs, etc. Since Dafny is designed with the main purpose of facilitating the construction of correct code, Dafny notation is compact and easy to understand. For the sake of readability and conciseness, the Dafny proof language includes constructs for structuring proofs such as lemmas and calculational proofs [11]. Dafny automatically generates executable .NET code for verified programs. The presented proof is made on the basis of some lemmas that ensure natural properties. Most of the proofs are inductive and use calculations [11] when appropriate. We believe that our program-proof is a simple and intuitive example of how a practical verification tool can be used by software developers with a minimum of familiarity with contract-based specifications and first-order assertions. We aim to contribute to the spread of the educational use of automatic tools in the development of formally verified software. We are convinced that this kind of example is useful for the introduction of formal software development methods and tools in software engineering courses. To sum up, we present a mechanically verified implementation of the sorting algorithm Natural Mergesort that consists of a few methods specified by their contracts of pre/post conditions. Methods are annotated with assertions that allow the automatic verification of the contract satisfaction. Along the paper we provide and explain the complete text of the program-proof.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>558</post_id>
		<post_date><![CDATA[2015-09-11 05:45:11]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:45:11]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-assertional-proof-of-the-stability-and-correctness-of-natural-mergesort]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[559]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Natural Mergesort [9] is a sorting algorithm for linear data structures (arrays and lists) that has been widely studied mainly due to its good properties. It has Nlog(N) worst-case complexity and, even in the case of arrays, is slightly easier to code than heapsort. Further, it performs very well on input data that is already mostly sorted. Another good property is stability. A sorting algorithm is stable if it maintains the relative order of records with equal keys. The most obvious application of a stable algorithm is sorting using different (primary, secondary, etc.) keys. Stability is, as we show in lemma EqMultisets, stronger than the property of preserving the multiset of elements (from the input list to the sorted output list). Hence, stability, along with sortedness, implies the correctness of sorting algorithms (including the permutation property). Recently, Sternagel [13] has published an Isabelle/HOL proof of the correctness and stability of natural mergesort as a proof pearl. Sternagel [13], firstly, specifies the algorithm as a functional program and, then, formalizes and proves the desired properties using the proof-assistant Isabelle/HOL. The proof is non-assertional and uses higher-order constructions. Indeed, it is strongly based on two skillful ad-hoc induction schemes. The first one for handling the mutually recursive functions involved in the splitting of the input into ascending sequences. The second induction scheme is related to the merging of the ascending lists. Correctness and stability are deduced from auxiliary lemmas which are proved by means of these induction schemes and with the help of a subtle generalization of the predicate sorted. The definition of that generalization and the induction schemes require the power of higher-order logic. In particular, the stability property is formalized in higher-order logic. More recently, de Gouw et al. [7] discussed a semi-automated formal proof of the correctness and stability of two sorting algorithms on arrays: Counting sort and Radix sort. This proof is formalized using the theorem-prover KeY [2]. The implementation code is written in Java. The specification is written (using the Java Modeling Language, JML) in an extension of first-order logic with permutation predicates, which have recently been added [1] to the KeY system. There are many other formalizations of the natural mergesort algorithm and also of different sorting algorithms (e.g. insertion sort, quicksort, heapsort, radix sort, etc.) in various systems, such as Coq [3], Isabelle/HOL [12], Why3 [6], ACL2 [8], KeY [2], etc. However, to the best of our knowledge, stability is only considered in [13], [7], and in our assertional proof. In this paper, we present an implementation of natural mergesort over an algebraic data type of lists. The code is enriched with its contract-based specification and a proof of its correctness and its stability. Our proof is assertional, i.e. it uses assert statements, inserted in the code, to enable the (fully) automatic verification. The assertions are first-order formulas that explain how and why the program works. The proof is supported by a few definitions that are easy to understand, and a few lemmas that isolate useful properties. Moreover, only non-trivial lemmas have detailed proofs and these are short and easy to read and to understand. Hence, in our opinion, the presented proof is quite clear and elegant. The program-proof is implemented in the state-of-the-art verifier Dafny [10]. The Dafny programming language supports a mixture of imperative, object-oriented programming and functional programming. In this paper, we use mostly functions, methods, and algebraic datatypes. The Dafny specification language includes the usual assertional language for contracts of pre/post conditions, invariants, decreasing expressions for termination proofs, etc. Since Dafny is designed with the main purpose of facilitating the construction of correct code, Dafny notation is compact and easy to understand. For the sake of readability and conciseness, the Dafny proof language includes constructs for structuring proofs such as lemmas and calculational proofs [11]. Dafny automatically generates executable .NET code for verified programs. The presented proof is made on the basis of some lemmas that ensure natural properties. Most of the proofs are inductive and use calculations [11] when appropriate. We believe that our program-proof is a simple and intuitive example of how a practical verification tool can be used by software developers with a minimum of familiarity with contract-based specifications and first-order assertions. We aim to contribute to the spread of the educational use of automatic tools in the development of formally verified software. We are convinced that this kind of example is useful for the introduction of formal software development methods and tools in software engineering courses. To sum up, we present a mechanically verified implementation of the sorting algorithm Natural Mergesort that consists of a few methods specified by their contracts of pre/post conditions. Methods are annotated with assertions that allow the automatic verification of the contract satisfaction. Along the paper we provide and explain the complete text of the program-proof.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[K. Rustan M. Leino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Microsoft Research]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[leino@microsoft.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Paqui Lucio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[The University of the Basque Country (UPV/EHU)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[paqui.lucio@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/025]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Thresholded Debugging of XPath Queries</title>
		<link>https://biblioteca.sistedes.es/articulo/thresholded-debugging-of-xpath-queries/</link>
		<pubDate>Fri, 11 Sep 2015 03:58:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=561</guid>
		<description></description>
		<content><![CDATA[We have recently designed/implemented a method for debugging Fuzzy-XPath queries which produces a set of alternative Fuzzy-XPath expressions with higher chances for retrieving answers from XML files. The main goal of the present paper consists in the introduction of a new fuzzy command inside the Fuzzy-XPath debugger which comfortably relies on our implementation based on fuzzy logic programming. So, when &lt;&lt;[FILTER=r]&gt;&gt; precedes a fuzzy query the debugger lazily explores an input XML document for dynamically disregarding as soon as possible those branches of the XML tree leading to irrelevant solutions (i.e., with a chance degree degraded below r), thus allowing the possibility of efficiently managing large files without reducing the set of answers for which users are mainly interested in. Hence, advice that this dynamic thresholding technique embedded into the core of the Fuzzy-XPath debugger has two advantages: • firstly it permits to concentrate on significant answers (i.e., alternative queries which do not excessively deviate from the original one) without disturbing the attention with useless information, and • secondly, the computational behavior of the debugging process is highly improved (both in time and space) since a great amount of work is avoided when discriminating useless branches of the XML tree.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>561</post_id>
		<post_date><![CDATA[2015-09-11 05:58:09]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 03:58:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[thresholded-debugging-of-xpath-queries]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We have recently designed/implemented a method for debugging Fuzzy-XPath queries which produces a set of alternative Fuzzy-XPath expressions with higher chances for retrieving answers from XML files. The main goal of the present paper consists in the introduction of a new fuzzy command inside the Fuzzy-XPath debugger which comfortably relies on our implementation based on fuzzy logic programming. So, when <<[FILTER=r]>> precedes a fuzzy query the debugger lazily explores an input XML document for dynamically disregarding as soon as possible those branches of the XML tree leading to irrelevant solutions (i.e., with a chance degree degraded below r), thus allowing the possibility of efficiently managing large files without reducing the set of answers for which users are mainly interested in. Hence, advice that this dynamic thresholding technique embedded into the core of the Fuzzy-XPath debugger has two advantages: • firstly it permits to concentrate on significant answers (i.e., alternative queries which do not excessively deviate from the original one) without disturbing the attention with useless information, and • secondly, the computational behavior of the debugging process is highly improved (both in time and space) since a great amount of work is avoided when discriminating useless branches of the XML tree.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesus M. Almendros-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dept. of Informatics Universidad de Almería 04120 Almería (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalmen@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alejandro Luna]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dept. of Computing Systems University of Castilla-La Mancha 02071 Albacete (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Alejandro.Luna@alu.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ginés Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dept. of Computing Systems University of Castilla-La Mancha 02071 Albacete (Spain)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Gines.Moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/014]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Analysing the Termination of Term Rewriting Systems using Data Mining</title>
		<link>https://biblioteca.sistedes.es/articulo/analysing-the-termination-of-term-rewriting-systems-using-data-mining/</link>
		<pubDate>Fri, 11 Sep 2015 04:02:34 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=564</guid>
		<description></description>
		<content><![CDATA[During the last decades, researchers in the field of Term Rewriting System (TRS) have devoted a lot of effort in order to develop techniques and methods able to demonstrate the termination property of a TRS. As a consequence, some of the proposed techniques have been implemented and several termination tools have been developed in order to automatize the termination proofs. From 2004, the annual Termination Competition is the foro in which research groups compare their tools trying to provide termination proofs of as many TRS as possible. This event generates a large amount of information (results obtained by the different tools, time spent on each proof, ...) that is recorded in databases. In this paper, we propose an alternative approach to study the termination of TRS: to use data mining techniques that, based on the historical information collected in the competition, generate models to explore the termination of a TRS. The goal of our study is not to develop a termination tool but to show, for the first time, what machine learning techniques can offer to the analysis of TRS termination.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>564</post_id>
		<post_date><![CDATA[2015-09-11 06:02:34]]></post_date>
		<post_date_gmt><![CDATA[2015-09-11 04:02:34]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analysing-the-termination-of-term-rewriting-systems-using-data-mining]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[565]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[During the last decades, researchers in the field of Term Rewriting System (TRS) have devoted a lot of effort in order to develop techniques and methods able to demonstrate the termination property of a TRS. As a consequence, some of the proposed techniques have been implemented and several termination tools have been developed in order to automatize the termination proofs. From 2004, the annual Termination Competition is the foro in which research groups compare their tools trying to provide termination proofs of as many TRS as possible. This event generates a large amount of information (results obtained by the different tools, time spent on each proof, ...) that is recorded in databases. In this paper, we propose an alternative approach to study the termination of TRS: to use data mining techniques that, based on the historical information collected in the competition, generate models to explore the termination of a TRS. The goal of our study is not to develop a termination tool but to show, for the first time, what machine learning techniques can offer to the analysis of TRS termination.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[J. Piris]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politecnica de Valéncia, Camí de Vera s/n, 46022 Valéncia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jpiris@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[H. Fabregat]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politecnica de Valéncia, Camí de Vera s/n, 46022 Valéncia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[herfabma@inf.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[M.J. Ramírez-Quintana]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politecnica de Valéncia, Camí de Vera s/n, 46022 Valéncia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mramirez@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2015/017]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Site-Level Template Extraction Based on Hyperlink Analysis (Original Work)</title>
		<link>https://biblioteca.sistedes.es/articulo/site-level-template-extraction-based-on-hyperlink-analysis-original-work/</link>
		<pubDate>Sun, 24 Apr 2016 01:11:42 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=740</guid>
		<description></description>
		<content><![CDATA[Web templates are one of the main development resources for website engineers. Templates allow them to increase productivity by plugin content into already formatted and prepared pagelets. For the final user templates are also useful, because they provide uniformity and a common look and feel for all webpages. However, from the point of view of crawlers and indexers, templates are an important problem, because templates usually contain irrelevant information such as advertisements, menus, and banners. Processing and storing this information is likely to lead to a waste of resources (storage space, bandwidth, etc.). It has been measured that templates represent between 40% and 50% of data on the Web. Therefore, identifying templates is essential for indexing tasks. In this work we propose a novel method for automatic template extraction that is based on similarity analysis between the DOM trees of a collection of webpages that are detected using menus information. Our implementation and experiments demonstrate the usefulness of the technique.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>740</post_id>
		<post_date><![CDATA[2016-04-24 03:11:42]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 01:11:42]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[site-level-template-extraction-based-on-hyperlink-analysis-original-work]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[741]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Web templates are one of the main development resources for website engineers. Templates allow them to increase productivity by plugin content into already formatted and prepared pagelets. For the final user templates are also useful, because they provide uniformity and a common look and feel for all webpages. However, from the point of view of crawlers and indexers, templates are an important problem, because templates usually contain irrelevant information such as advertisements, menus, and banners. Processing and storing this information is likely to lead to a waste of resources (storage space, bandwidth, etc.). It has been measured that templates represent between 40% and 50% of data on the Web. Therefore, identifying templates is essential for indexing tasks. In this work we propose a novel method for automatic template extraction that is based on similarity analysis between the DOM trees of a collection of webpages that are detected using menus information. Our implementation and experiments demonstrate the usefulness of the technique.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julián Alarte]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universitat Politécnica de Valéncia, Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalarte@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David Insa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universitat Politécnica de Valéncia, Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[dinsa@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Josep Silva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación Universitat Politécnica de Valéncia, Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jsilva@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Salvador Tamarit]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Babel Research Group Universidad Politécnica de Madrid, Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[stamarit@babel.ls.fi.upm.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Improving the Deductive System DES with Persistence by Using SQL DBMS&#039;s (Original Work)</title>
		<link>https://biblioteca.sistedes.es/articulo/improving-the-deductive-system-des-with-persistence-by-using-sql-dbmss-original-work/</link>
		<pubDate>Sun, 24 Apr 2016 01:16:34 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=746</guid>
		<description></description>
		<content><![CDATA[This work presents how persistent predicates have been included in the in-memory deductive system DES by relying on external SQL database management systems. We introduce how persistence is supported from a user-point of view and the possible applications the system opens up, as the deductive expressive power is projected to relational databases. Also, we describe how it is possible to intermix computations of the deductive engine and the external database, explaining its implementation and some optimizations. Finally, a performance analysis is undertaken, comparing the system with current relational database systems.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>746</post_id>
		<post_date><![CDATA[2016-04-24 03:16:34]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 01:16:34]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[improving-the-deductive-system-des-with-persistence-by-using-sql-dbmss-original-work]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[747]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This work presents how persistent predicates have been included in the in-memory deductive system DES by relying on external SQL database management systems. We introduce how persistence is supported from a user-point of view and the possible applications the system opens up, as the deductive expressive power is projected to relational databases. Also, we describe how it is possible to intermix computations of the deductive engine and the external database, explaining its implementation and some optimizations. Finally, a performance analysis is undertaken, comparing the system with current relational database systems.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Fernando Sáenz-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Programación Declarativa (GPD) Dept. Ingenier´ia del Software e Inteligencia Artificial Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ fernan@sip.ucm.es ]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Embedding Widgets-as-a-Service into Dynamic GUI</title>
		<link>https://biblioteca.sistedes.es/articulo/embedding-widgets-as-a-service-into-dynamic-gui/</link>
		<pubDate>Sun, 24 Apr 2016 05:07:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=986</guid>
		<description></description>
		<content><![CDATA[The service-oriented computing offers an ideal development framework for carrying out business processes related to the dynamic management of component-based web user interfaces. This article proposes an architecture for specification, storage, management and visualization of web user interfaces built from widgets that follow the recommendation of the W3C. It describes a Widgets-as-a-Service (WaaS) approach for interface deployment and a three-level data model for the definition of components that take part in the architecture. In addition, it shows some particularities of the used technology and the implementation developed. To illustrate this proposal, an example of WaaS-based graphical interface developed for the Environmental Information Network of Andalusia (REDIAM) is shown.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>986</post_id>
		<post_date><![CDATA[2016-04-24 07:07:09]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 05:07:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[embedding-widgets-as-a-service-into-dynamic-gui]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="architectures"><![CDATA[architectures]]></category>
		<category domain="post_tag" nicename="components"><![CDATA[components]]></category>
		<category domain="post_tag" nicename="gui"><![CDATA[GUI]]></category>
		<category domain="post_tag" nicename="widgets"><![CDATA[widgets]]></category>
		<category domain="post_tag" nicename="wookie"><![CDATA[Wookie]]></category>
		<category domain="post_tag" nicename="wsdl"><![CDATA[WSDL]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[987]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The service-oriented computing offers an ideal development framework for carrying out business processes related to the dynamic management of component-based web user interfaces. This article proposes an architecture for specification, storage, management and visualization of web user interfaces built from widgets that follow the recommendation of the W3C. It describes a Widgets-as-a-Service (WaaS) approach for interface deployment and a three-level data model for the definition of components that take part in the architecture. In addition, it shows some particularities of the used technology and the implementation developed. To illustrate this proposal, an example of WaaS-based graphical interface developed for the Environmental Information Network of Andalusia (REDIAM) is shown.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[components, architectures, widgets, Wookie, WSDL, GUI]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús Vallecillos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, University of Almería, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jesus.vallecillos,@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Criado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, University of Almería, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[javi.criado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Luis Iribarne]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, University of Almería, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[luis.iribarne@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Nicolás Padilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, University of Almería, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[npadilla@ual.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards the automation of claiming in SLA-driven services</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-the-automation-of-claiming-in-sla-driven-services/</link>
		<pubDate>Sun, 24 Apr 2016 05:10:31 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=989</guid>
		<description></description>
		<content><![CDATA[Current software industry is evolving into a service­centric scenario and consequently, the importance to create reliable service consumptions amongst organizations is a key point. In such a context, the concept of Service Level Agreement (SLA) represents the foundation to express the responsibilities (i.e. rights and obligations) of service consumer and provider during the consumption. However, in spite there has been a major effort in both academia and industry to develop languages and frameworks to support SLAs, there still remain important challenges to address such as how to automate the detection of a violation of the SLAs and how to react accordingly in order to claim for a compensation. Specifically, in this paper we focus on the definition of the automated claiming of SLAs problem characterized as the set of processes of gathering, checking and explaining the evidences associated with the service consumption within the context of an SLA. In order to identify the key requirements to automate the claiming of SLAs, we analyse the real case of the Simple Storage Service (S3) provided by Amazon, that is regulated by an SLA. Based on our analysis we propose a set of extensions to current prominent SLA language specification (WS­Agreement) and conceptualize a list of research challenges to automate the management of the claiming process.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>989</post_id>
		<post_date><![CDATA[2016-04-24 07:10:31]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 05:10:31]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-the-automation-of-claiming-in-sla-driven-services]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[990]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Current software industry is evolving into a service­centric scenario and consequently, the importance to create reliable service consumptions amongst organizations is a key point. In such a context, the concept of Service Level Agreement (SLA) represents the foundation to express the responsibilities (i.e. rights and obligations) of service consumer and provider during the consumption. However, in spite there has been a major effort in both academia and industry to develop languages and frameworks to support SLAs, there still remain important challenges to address such as how to automate the detection of a violation of the SLAs and how to react accordingly in order to claim for a compensation. Specifically, in this paper we focus on the definition of the automated claiming of SLAs problem characterized as the set of processes of gathering, checking and explaining the evidences associated with the service consumption within the context of an SLA. In order to identify the key requirements to automate the claiming of SLAs, we analyse the real case of the Simple Storage Service (S3) provided by Amazon, that is regulated by an SLA. Based on our analysis we propose a set of extensions to current prominent SLA language specification (WS­Agreement) and conceptualize a list of research challenges to automate the management of the claiming process.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel Léon]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mjleon@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Metaherramienta para la generacíon de aplicaciones científicas basadas en workflows</title>
		<link>https://biblioteca.sistedes.es/articulo/metaherramienta-para-la-generacion-de-aplicaciones-cientificas-basadas-en-workflows/</link>
		<pubDate>Sun, 24 Apr 2016 05:13:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=992</guid>
		<description></description>
		<content><![CDATA[El uso de la programación visual en el ámbito científico ha contribuido al desarrollo de aplicaciones que facilitan la realizacíon de experimentos. Actualmente, existen aplicaciones para trabajar sobre un único dominio, limitadas a procedimientos propios de ese dominio, y aplicaciones multidominio, cuya complejidad para la configuracíon de sus elementos supone un gran esfuerzo para el usuario. Por tanto, es necesario ofrecer flexibilidad para trabajar sobre diversos dominios y permitir una adaptacíon intuitiva a dominios conocidos por el usuario. En este trabajo se presenta una metaherramienta para la generacíon automática de aplicaciones adaptadas a un dominio, o conjunto de dominios, para la composición y ejecucíon de workflows científicos en términos de procesos locales y servicios remotos. Estas nuevas aplicaciones disponen de una infraestructura que proporciona interoperabilidad con aplicaciones externas, presentan interfaces de usuario personalizadas y abstraen al usuario final de la complejidad de configuracíon al ofrecer elementos de trabajo ya adaptados a su campo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>992</post_id>
		<post_date><![CDATA[2016-04-24 07:13:53]]></post_date>
		<post_date_gmt><![CDATA[2016-04-24 05:13:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[metaherramienta-para-la-generacion-de-aplicaciones-cientificas-basadas-en-workflows]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="metaherramienta"><![CDATA[metaherramienta]]></category>
		<category domain="post_tag" nicename="programacion-visual"><![CDATA[programacíon visual]]></category>
		<category domain="post_tag" nicename="servicios-remotos"><![CDATA[servicios remotos]]></category>
		<category domain="post_tag" nicename="workflow-cientifico"><![CDATA[workflow científico]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[993]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El uso de la programación visual en el ámbito científico ha contribuido al desarrollo de aplicaciones que facilitan la realizacíon de experimentos. Actualmente, existen aplicaciones para trabajar sobre un único dominio, limitadas a procedimientos propios de ese dominio, y aplicaciones multidominio, cuya complejidad para la configuracíon de sus elementos supone un gran esfuerzo para el usuario. Por tanto, es necesario ofrecer flexibilidad para trabajar sobre diversos dominios y permitir una adaptacíon intuitiva a dominios conocidos por el usuario. En este trabajo se presenta una metaherramienta para la generacíon automática de aplicaciones adaptadas a un dominio, o conjunto de dominios, para la composición y ejecucíon de workflows científicos en términos de procesos locales y servicios remotos. Estas nuevas aplicaciones disponen de una infraestructura que proporciona interoperabilidad con aplicaciones externas, presentan interfaces de usuario personalizadas y abstraen al usuario final de la complejidad de configuracíon al ofrecer elementos de trabajo ya adaptados a su campo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[workflow científico, metaherramienta, programacíon visual, servicios remotos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rubén Salado-Cid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico Universidad de Córdoba, Campus de Rabanales, 14071 Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rsalado@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Raúl Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico Universidad de Córdoba, Campus de Rabanales, 14071 Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sebastián Ventura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico Universidad de Córdoba, Campus de Rabanales, 14071 Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sventura@uco.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Involucrando al humano en el bucle de control de sistemas auto-adaptativos</title>
		<link>https://biblioteca.sistedes.es/articulo/involucrando-al-humano-en-el-bucle-de-control-de-sistemas-auto-adaptativos/</link>
		<pubDate>Thu, 18 Aug 2016 14:47:08 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1802</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1802</post_id>
		<post_date><![CDATA[2016-08-18 16:47:08]]></post_date>
		<post_date_gmt><![CDATA[2016-08-18 14:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[involucrando-al-humano-en-el-bucle-de-control-de-sistemas-auto-adaptativos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1803]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La auto-adaptación juega un papel clave en los sistemas software del futuro, los cuales están formados por complejos ecosistemas heterogéneos teniendo que ser capaces de adaptarse continua y autónomamente, en tiempo de ejecución, a su contexto (nuevas condiciones del entorno, situaciones impredecibles, necesidades cambiantes de los usuarios, nuevos recursos, etc.). Aunque estas adaptaciones deben gestionarse de forma autónoma, la experiencia demuestra que los humanos no pueden excluirse completamente del bucle de adaptación, ya sea para solucionar conflictos difíciles de resolver autónomamente o para mejorar las estrategias de adaptación con su realimentación. En este artículo se abre una línea de trabajo para involucrar al humano en el bucle de control de los sistemas auto-adaptativos ("human in the loop") y que éstos puedan participar en la toma de decisiones de adaptación, siempre intentando maximizar la autonomía y evitar sistemas intrusivos y molestos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Auto-adaptación, Computación Autónoma, "Human in the Loop", Interacción Persona-Ordenador, Experiencia de Usuario]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miriam	Gil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mgil@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pele@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Joan	Fons 	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jjfons@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manoli Albert	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[malbert@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/048]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Uso de Juegos Serios para la Formación en los Procesos del Ciclo de Vida y Mejora del Software</title>
		<link>https://biblioteca.sistedes.es/articulo/uso-de-juegos-serios-para-la-formacion-en-los-procesos-del-ciclo-de-vida-y-mejora-del-software/</link>
		<pubDate>Thu, 18 Aug 2016 15:11:12 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1806</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1806</post_id>
		<post_date><![CDATA[2016-08-18 17:11:12]]></post_date>
		<post_date_gmt><![CDATA[2016-08-18 15:11:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[uso-de-juegos-serios-para-la-formacion-en-los-procesos-del-ciclo-de-vida-y-mejora-del-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1807]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La formación en proceso software es un tema de gran relevancia a tener en cuenta por los profesionales de la industria de la ingeniería del software en el camino hacia el desarrollo de software de calidad con éxito. Sin embargo, los estudios realizados muestran como dicha formación es altamente teórica y en la mayoría de los casos suele impartirse de forma separada a la formación en las actividades del desarrollo del software, en un entorno donde los futuros profesionales apenas adquieren experiencia práctica en la aplicación de los procesos del ciclo de vida y mejora del software. En este artículo, analizamos el uso de los juegos serios para la formación en proceso software, y los grupos de procesos del ciclo de vida del software definidos por el estándar ISO/IEC 12207. Además, proponemos un juego serio basado en simulación para formar en dirección y gestión de proyectos software, y lo relacionamos con los procesos del estándar ISO/IEC 12207. Por último, presentamos los resultados de la evaluación realizada por expertos (n=10) sobre el uso del juego serio propuesto para la formación en proceso software, concluyendo que su uso durante el curso ayuda a los alumnos en la adquisición de los conocimientos del proceso software de forma práctica.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Proceso Software, ISO/IEC 12207, Juegos Serios, Formación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alejandro Calderón Sánchez	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alejandro.calderonsanchez@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mercedes Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mercedes.ruiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/050]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>AgileRoadmap: Un modelo y estrategia para implantación de prácticas ágiles</title>
		<link>https://biblioteca.sistedes.es/articulo/agileroadmap-un-modelo-y-estrategia-para-implantacion-de-practicas-agiles/</link>
		<pubDate>Thu, 18 Aug 2016 15:18:27 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1809</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1809</post_id>
		<post_date><![CDATA[2016-08-18 17:18:27]]></post_date>
		<post_date_gmt><![CDATA[2016-08-18 15:18:27]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[agileroadmap-un-modelo-y-estrategia-para-implantacion-de-practicas-agiles]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1810]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La comunidad que trabaja con métodos ágiles no cuenta con un cuerpo de conocimiento consensuado. Si bien esto ha permitido que los métodos ágiles se hayan difundido rápidamente, sin la regulación centralizada de alguna institución, como contrapartida la aplicación de métodos ágiles en muchos casos carece de rigor o su valoración resulta demasiado subjetiva. Claramente existen unos métodos ágiles más populares; Scrum, Kanban, Lean Development y Extreme Programming, cada uno de ellos tiene sus propias fuentes de información y en general, se ha fomentado su aplicación de forma exclusiva. Sin embargo, las prácticas ágiles detrás de dichos métodos son complementarias, e incluso muchas de ellas son comunes a varios métodos. A través de implantaciones reales de métodos ágiles en diferentes empresas hemos ido refinando un enfoque para implantación de agilismo que hemos denominado AgileRoadmap. Nuestra propuesta incluye un modelo y una estrategia para la implantación del agilismo, integrando las prácticas ágiles de dichos métodos más populares y centrándose en la aplicación de prácticas, no en la aplicación de un método en concreto. AgileRoadmap incluye un catálogo de prácticas ágiles y una serie de criterios que ayudan en la selección de prácticas ágiles para un cierto contexto de trabajo. Así, AgileRoadmap puede ayudar a elaborar una hoja de ruta para la implantación del agilismo en equipos de trabajo. En este artículo se presenta AgileRoadmap y una herramienta de apoyo que hemos desarrollado para facilitar su aplicación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Métodos ágiles, Scrum, Kanban, Lean Development, Extreme Programming]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Patricio Letelier	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[letelier@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mª Carmen Penadés		]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mpenades@dsic.upv.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/051]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Categorización de Actividades de Seguridad en el Desarrollo de Software</title>
		<link>https://biblioteca.sistedes.es/articulo/categorizacion-de-actividades-de-seguridad-en-el-desarrollo-de-software/</link>
		<pubDate>Thu, 18 Aug 2016 15:25:08 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1812</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1812</post_id>
		<post_date><![CDATA[2016-08-18 17:25:08]]></post_date>
		<post_date_gmt><![CDATA[2016-08-18 15:25:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[categorizacion-de-actividades-de-seguridad-en-el-desarrollo-de-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1813]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resulta evidente la necesidad de considerar la seguridad en todas las tareas del ciclo de vida del software. Su inclusión desde las fases más tempranas de desarrollo evitará futuros sobrecostes en las fases finales, que suelen ser las más complejas. La detección de fallos de seguridad o vulnerabilidades en las fases iniciales de desarrollo garantizan la reducción de posibles ataques maliciosos, además de contribuir a la reputación corporativa de las empresas que desarrollan software. En el camino hacia particularizar un modelo de desarrollo de software seguro por defecto, y tras analizar diferentes marcos de trabajo, se han identificado una serie de prácticas de seguridad recurrentes en todos ellos, y, por ello, fundamentales. Las carencias detectadas en los modelos estudiados se subsanan añadiendo nuevas actividades de seguridad, propuestas por los autores. Este trabajo realiza una categorización de las actividades de seguridad del ciclo de vida del software, de manera que se encuentren correctamente planificadas y se implementen de forma sistemática, garantizando una mayor seguridad del software desarrollado.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Modelo de Seguridad, Software Seguro, Ciclo de Vida, Desarrollo Seguro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Carlos Sancho Núñez		]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Viewnext S.A.	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jcsanchon@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Andrés Caro Lindo			]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[andresc@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pablo García Rodríguez		]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pablogr@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/052]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación automática de eventos de prueba para sistemas de IoT</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-automatica-de-eventos-de-prueba-para-sistemas-de-iot/</link>
		<pubDate>Tue, 30 Aug 2016 12:03:48 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1817</guid>
		<description></description>
		<content><![CDATA[CEDI_2016_paper_78]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1817</post_id>
		<post_date><![CDATA[2016-08-30 14:03:48]]></post_date>
		<post_date_gmt><![CDATA[2016-08-30 12:03:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-automatica-de-eventos-de-prueba-para-sistemas-de-iot]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1818]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La aplicación en diversas áreas de Internet de las Cosas (IoT) ha ido en aumento en los últimos años. Uno de los principales inconvenientes que tienen los sistemas IoT es la cantidad de información que tienen que manejar. Esta información llega en forma de eventos, cuyo receptor ha de tomar las decisiones correctas, en tiempo real, según los datos recibidos. Viendo la relevancia que tiene el procesado de esta información, resulta fundamental analizar y probar los sistemas IoT que van a trabajar con ella. Para probar las distintas funcionalidades de los sistemas IoT, se necesita una gran cantidad de eventos con estructuras y valores específicos. Conseguir estos eventos de forma manual puede ser una tarea muy costosa y propensa a errores. En este trabajo se presenta un método para la generación automática de eventos de prueba para sistemas de IoT. Los resultados obtenidos en los casos de prueba utilizados muestran su viabilidad.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Generador de eventos, Pruebas, Definición de tipo de evento, Internet de las Cosas, Procesado de Eventos Complejos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Lorena Gutiérrez-Madroñal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[lorena.gutierrez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo		]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan José	Domínguez Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanjose.dominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/007]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Software Engineering Experiments to value MDE in testing. Learning Lessons</title>
		<link>https://biblioteca.sistedes.es/articulo/a-software-engineering-experiments-to-value-mde-in-testing-learning-lessons/</link>
		<pubDate>Tue, 30 Aug 2016 12:15:23 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1820</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1820</post_id>
		<post_date><![CDATA[2016-08-30 14:15:23]]></post_date>
		<post_date_gmt><![CDATA[2016-08-30 12:15:23]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-software-engineering-experiments-to-value-mde-in-testing-learning-lessons]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1821]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Controlled experiments are commonly used to evaluate Software Engineer-ing methods, processes and tools. Validating results of Software Engineering research in industrial settings is a direct way to obtain feedback about its value. However, few software engineering experiments are running in indus-try. The lack of communication between companies and research teams does not make the necessary cooperation among them possible. This paper pre-sents our experiences when running an experiment dealing with Early Test-ing at the University of Seville. It also introduces the strategy we followed to obtain the participation of 97 practitioners from 32 different software com-panies. Such strategy is pointed out as a set of guidelines to successfully in-volve this large number of companies and practitioners.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Software experiments in enterprise, early testing experiences, enterprise experiences]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María José Escalona		]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mjescalona@us.es	Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Guillermo Lopez Nicolás]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto Tecnológico de Aragón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[glopez@itainnova.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sira	Vegas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[svegas@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Laura García-Borgoñón	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Instituto Tecnológico de Aragón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[laurag@itainnova.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Julián Alberto	García García	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[julian.garcia@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Natalia Juristo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[natalia@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/008]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia un entorno extensible basado en ADM para la refactorización de sistemas heredados</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-un-entorno-extensible-basado-en-adm-para-la-refactorizacion-de-sistemas-heredados/</link>
		<pubDate>Tue, 30 Aug 2016 12:24:54 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1824</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1824</post_id>
		<post_date><![CDATA[2016-08-30 14:24:54]]></post_date>
		<post_date_gmt><![CDATA[2016-08-30 12:24:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-un-entorno-extensible-basado-en-adm-para-la-refactorizacion-de-sistemas-heredados]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1826]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Hoy en día siguen activos muchos sistemas heredados que presentan problemas que afectan a las distintas características la calidad del software. Para mejorar estos problemas, existen herramientas de refactorización, cuyo objetivo es mejorar aspectos de calidad concretos sin afectar al comportamiento del sistema heredado. ADM (Modernización Dirigida por la Arquitectura), se presenta como el paradigma que basa el entendimiento y evolución de los sistemas software en MDA. Existen multitud de entornos que implementan estrategias de refactorización clásicas para mejorar la calidad de los sistemas, pero estas herramientas ofrecen un catálogo fijo de refactorizaciones. La propuesta que se presenta en este artículo consiste en un entorno flexible basado en ADM que permite la definición de “bad-smells” (clásicos y nuevos), aplicables a contextos concretos y su identificación en sistemas heredados, teniendo así una herramienta totalmente flexible y extensible.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Refactorización, ADM, Flexible, Extensible, Calidad, Sistemas Heredados]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Abel	Lorente Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información (ITSI), Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[abel.lorente@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ignacio García-Rodríguez de Guzmán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información (ITSI), Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Ignacio.GRodriguez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información (ITSI), Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Mario.Piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/014]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Pruebas sobre aplicaciones de bases de datos orientadas a grafos: un enfoque basado en modelos</title>
		<link>https://biblioteca.sistedes.es/articulo/pruebas-sobre-aplicaciones-de-bases-de-datos-orientadas-a-grafos-un-enfoque-basado-en-modelos/</link>
		<pubDate>Tue, 30 Aug 2016 12:30:17 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1828</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1828</post_id>
		<post_date><![CDATA[2016-08-30 14:30:17]]></post_date>
		<post_date_gmt><![CDATA[2016-08-30 12:30:17]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[pruebas-sobre-aplicaciones-de-bases-de-datos-orientadas-a-grafos-un-enfoque-basado-en-modelos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1829]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las bases de datos NoSQL plantean nuevos desafíos a la hora de probar las aplicaciones que las utilizan, debido a que sus modelos de datos y sus modos de acceso difieren de las bases de datos relacionales. La prueba de aplicaciones que acceden a bases de datos relacionales ha atraído el interés de muchos investigadores, mientras que la prueba de aplicaciones que acceden a bases de datos NoSQL es un área que aún no ha sido prácticamente explorada. Este trabajo describe un enfoque que permite crear modelos que definen objetivos de prueba para aplicaciones que utilizan bases de datos orientadas a grafo, a partir de la especificación del sistema y del modelo de datos conceptual. Estos modelos son empleados posteriormente para derivar los requisitos de prueba que guían la generación de los casos de prueba. El enfoque ha sido aplicado a una aplicación que representa un problema del mundo real y los resultados muestran que permite diseñar casos de prueba capaces de detectar fallos que pueden aparecer tanto en la especificación del sistema como en la implementación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Pruebas sobre bases de datos orientadas a grafos, Pruebas basadas en la especificación, Base de datos de prueba, Model-based testing]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Raquel Blanco	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rblanco@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Tuya	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/009]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación y Ejecución de Escenarios de Prueba para Aplicaciones MapReduce</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-y-ejecucion-de-escenarios-de-prueba-para-aplicaciones-mapreduce/</link>
		<pubDate>Tue, 30 Aug 2016 12:35:30 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1831</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1831</post_id>
		<post_date><![CDATA[2016-08-30 14:35:30]]></post_date>
		<post_date_gmt><![CDATA[2016-08-30 12:35:30]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-y-ejecucion-de-escenarios-de-prueba-para-aplicaciones-mapreduce]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1832]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los programas que procesan grandes cantidades de datos se suelen ejecutar sobre una infraestructura distribuida, como es el caso de las aplicaciones implementadas bajo el modelo de procesamiento MapReduce. Estos modelos permiten al desarrollador centrarse en la funcionalidad de la aplicación y abstraer aspectos relacionados con la infraestructura en la que se ejecutará. Sin embargo, su configuración y estado pueden causar que ciertos defectos sean difíciles de detectar debido a que las pruebas se suelen ejecutar en un entorno controlado, con bajo nivel de paralelismo y con pocos datos de entrada. En este artículo se elabora una técnica de prueba que partiendo de unos datos de entrada, genera y reproduce diferentes configuraciones de la infraestructura con el objetivo de detectar aquellas que revelen defectos funcionales en la aplicación. Esta técnica se automatiza en un motor de ejecución de pruebas y se aplica a un caso de estudio que actualmente se encuentra en producción. Como resultado, partiendo de un caso de prueba de tamaño reducido, se han identificado automáticamente varias configuraciones de la infraestructura que ocasionarían fallos de la aplicación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Pruebas del software, MapReduce, Big Data engineering]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús Morán		]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[moranjesus@lsi.uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Claudio de la Riva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[claudio@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/010]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Sobre el grado de acuerdo entre evaluadores en la detección de Design Smells</title>
		<link>https://biblioteca.sistedes.es/articulo/sobre-el-grado-de-acuerdo-entre-evaluadores-en-la-deteccion-de-design-smells/</link>
		<pubDate>Tue, 30 Aug 2016 12:42:34 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1834</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1834</post_id>
		<post_date><![CDATA[2016-08-30 14:42:34]]></post_date>
		<post_date_gmt><![CDATA[2016-08-30 12:42:34]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[sobre-el-grado-de-acuerdo-entre-evaluadores-en-la-deteccion-de-design-smells]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1835]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La detección de Design Smells ha ido experimentado un auge en resultados de investigación publicados. La primera definición de Design Smells data del año 2000. La primera herramienta se reporta en 2002. A partir de 2004 comienza un crecimiento continuado, proliferando la aparición de nuevas herramientas para la detección automática de Design Smells. Particularmente a partir de 2009-2010 se produce un incremento notable en la actividad en este ámbito. La detección automática de Design Smells ha evolucionado a la par que las herramientas automáticas de refactoring. Sin embargo se constata que no ha sido comparable su adopción por parte de los desarrolladores en la producción y mantenimiento del software, con la forma en la que se han adoptado las herramientas de refactoring. En este trabajo partimos de la suposición de que la diferencia reside en la objetividad y pragmatismo de una operación de refactoring comparada con el grado de subjetividad que suponemos en la definición e identificación de Design Smells. Para estudiar este problema se diseñó una encuesta difundida vía correo electrónico en la que se obtuvieron 92 respuestas de personas tanto de la academia como de la industria acerca de la presencia de Design Smells en 5 clases de un proyecto de código abierto. El estudio se ha realizado centrándose en la detección de dos tipos de Design Smells: God Class y Feature Envy. La selección se basa en que son dos de los Design Smells más populares en la literatura y en que además se trata de Design Smells de diferente naturaleza en cuanto al ámbito y al efecto en el software. Se ha realizado un estudio en el que se valora el grado de acuerdo en la identificación de Design Smells entre los encuestados. En el trabajo se analizan la interrelación entre diferentes factores como la experiencia del evaluador, su contexto de trabajo, etc. Los resultados obtenidos muestran que no existe acuerdo en general y que es muy pobre en los casos en los que sí existe algún acuerdo. A partir de los resultados obtenidos se concluye con recomendaciones a tener en cuenta en las nuevas tendencias para la detección automática de Design Smells que pueden influir positivamente en la adopción por la industria de técnicas y herramientas para la detección de Design Smells.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Detección de Design Smells, encuesta, acuerdo entre evaluadores, Kappa-Fleiss, calidad, evolución, mantenimiento]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Khalid Alkharabsheh	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnologías de la Información Universidad de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[khalid.alkharabsheh@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Yania Crespo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Informática, Universidad de Valladolid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[yania@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Esperanza Manso	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Informática, Universidad de Valladolid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manso@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jose Angel Taboada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnologías de la Información Universidad de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Joseangel.taboada@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/011]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Comparación de herramientas de Detección de Design Smells</title>
		<link>https://biblioteca.sistedes.es/articulo/comparacion-de-herramientas-de-deteccion-de-design-smells/</link>
		<pubDate>Tue, 30 Aug 2016 15:12:04 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1837</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1837</post_id>
		<post_date><![CDATA[2016-08-30 17:12:04]]></post_date>
		<post_date_gmt><![CDATA[2016-08-30 15:12:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[comparacion-de-herramientas-de-deteccion-de-design-smells]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1838]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La detección de Design Smells ha experimentado un auge en actividad entre los años 2010 y 2014.
Proliferan las herramientas de detección automática pero se percibe un problema de falta de acuerdo en la identificación de Design Smells. En este trabajo se presentan dos experimentos. El primero es un experimento diseñado como estudio preliminar en el que se comparan una selección de 6 herramientas (inCode, inFusion, iPlasma, Together, JDeodorant y JSmellSensor) usándolas para detectar Design Smells en un proyecto software de código abierto. Del proyecto seleccionado se eligieron 100 clases aleatoriamente para este primer estudio exploratorio. El análisis consistió en valorar el grado de acuerdo en la identificación de Design Smells en el grupo de herramientas. En este primer experimento el estudio se realizó centrándose en la detección de dos tipos de Design Smells: God Class y Feature Envy. De este primer estudio se detectó un grupo de tres herramientas (inCode, inFusion, iPlasma) con un grado de acuerdo muy bueno. Se analizó que esto es así debido a que las tres fueron desarrolladas en el mismo grupo de investigación. Entre el resto de herramientas el acuerdo es inexistente (peor que al azar) o débil. El acuerdo débil se detectó entre el grupo de tres herramientas antes mencionadas y la herramienta JSmellSensor. JSmellSensor es una herramienta experimental desarrollada en nuestro grupo de investigación que parte de conocimiento aportado por iPlasma. Debido a estas circunstancias y para profundizar en el problema se diseñó una réplica. En esta réplica se comparan 5 herramientas (iPlasma, PMD, JDeodorant, DECOR, Together). Del grupo de tres herramientas identificado en el primer experimento se eligió como representante iPlasma. Se decidió que JSmellSensor no participase en esta réplica. En este segundo experimento se analizaron 12588 clases fruto de la preparación de un dataset con todas las clases de 24 proyectos de código abierto obtenidos de SourceForge. Este segundo experimento se centró únicamente en el estudio del acuerdo en la identificación de God Clss. Los resultados obtenidos en este segundo experimento muestran que tanto el acuerdo entre las herramientas tomadas conjuntamente como analizadas dos a dos es muy pobre.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Detección de Design Smells, Kappa-Fleiss, FCA, calidad, evolución, mantenimiento]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Khalid Alkharabsheh	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnologías de la Información Universidad de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[khalidkh1980@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Yania Crespo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Informática, Universidad de Valladolid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[yania@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Esperanza Manso	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Informática, Universidad de Valladolid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manso@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jose Angel Taboada	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnologías de la Información Universidad de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Joseangel.taboada@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/012]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Calidad Ágil: Patrones de Diseño en un contexto de Desarrollo Dirigido por Pruebas</title>
		<link>https://biblioteca.sistedes.es/articulo/calidad-agil-patrones-de-diseno-en-un-contexto-de-desarrollo-dirigido-por-pruebas/</link>
		<pubDate>Wed, 31 Aug 2016 12:33:22 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1840</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1840</post_id>
		<post_date><![CDATA[2016-08-31 14:33:22]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 12:33:22]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[calidad-agil-patrones-de-diseno-en-un-contexto-de-desarrollo-dirigido-por-pruebas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1841]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En esta investigación se propone un conjunto inicial de patrones de diseño que pueden ser utilizados en un contexto de TDD. Se analizan las características de calidad de software de cada uno de los patrones del conjunto seleccionado según el estándar de calidad de software vigente ISO/IEC 25010:2011~cite{ISO/IEC}.

Para cada patrón y característica ISO, se discute si las propiedades esperadas del código resultan aumentadas o inhibidas con la incorporación del patrón.

Se realiza un análisis crítico de cada patrón seleccionado según tres dimensiones: (1)capacidad de prueba (testability), (2)características de calidad propiciadas y (3)características de calidad inhibidas. Esto deriva en un resumen para cada patrón seleccionado, incluyendo una breve descripción de cada patrón, componentes, y su impacto (beneficios y desventajas ) en la calidad del código de pruebas desarrollado a través de su utilización.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[TDD design patterns, Analysis patterns, Quality Assessment, Java unit tests, ISO/IEC 25010 quality attributes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel I. Capel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[manuelcapel@ugr.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Anna C. Grimán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Procesos y Sistemas, Universidad Simón Bolívar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[agriman@usb.ve]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Eladio Garví]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[egarvi@ugr.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/013]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Static analysis of textual models</title>
		<link>https://biblioteca.sistedes.es/articulo/static-analysis-of-textual-models/</link>
		<pubDate>Wed, 31 Aug 2016 14:10:45 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1845</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1845</post_id>
		<post_date><![CDATA[2016-08-31 16:10:45]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 14:10:45]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[static-analysis-of-textual-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1846]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Domain specific languages (DSLs) based on textual notations are useful to describe the semantics of a given problem. Software frameworks, such as Xtext, enable to easily design and develop textual DSLs. The use of interactive quality platforms for analysing source code such as SonarQube is increasing. For evaluating the quality of a program written with an Xtext-designed DSL, all the artifacts required by SonarQube to parse and query the source code must be developed, which becomes time-consuming and error-prone. A transformation tool and its application to a DSL are presented to bridge the gap between Xtext and SonarQube grammar formats by following a model-driven interoperability strategy.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[DSL, Xtext, SonarQube, Model-driven Interoperability]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Iván	Ruiz-Rube	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ivan.ruiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Tatiana Person]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[tatiana.personmontero@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Dodero	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanma.dodero@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/020]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evaluating Embedded Relational Databases for Large Model Persistence and Query</title>
		<link>https://biblioteca.sistedes.es/articulo/evaluating-embedded-relational-databases-for-large-model-persistence-and-query/</link>
		<pubDate>Wed, 31 Aug 2016 14:20:33 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1848</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1848</post_id>
		<post_date><![CDATA[2016-08-31 16:20:33]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 14:20:33]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evaluating-embedded-relational-databases-for-large-model-persistence-and-query]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1849]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Large models are increasingly used in Model Driven Development. Different studies have proved that XMI (default persistence in Eclipse Modelling Framework) has some limitations when operating with large models. To overcome them, recent approaches have used databases for persistence of models. EDBM (Embedded DataBase for Models) is an approach for persisting models in an embedded relational database, which provides scalable querying mechanism by runtime translation of model-level queries to SQL. In this paper, we present an evaluation of EDBM in terms of scalability with existing approaches. GraBaTs 2009 case study (models from 8.8MB to 646MB) is used for evaluation. EDBM is 70% faster than compared approaches to persist XMI GraBats models into databases and executes the GraBats query faster, as well as having a low memory usage. These results indicate that embedded relational database, combined with a scalable query mechanism provide a promising alternative for persisting and querying large models.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Model-Driven Development, Large-Scale Models, Persistence, Query, Runtime Translation, Evaluation]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Xabier De Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[IK4-Ikerlan Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[xdecarlos@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Goiuria Sagardui]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Mondragon Unibertsitatea]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gsagardui@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Salvador Trujillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[IK4-Ikerlan Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[strujillo@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Alain Perkaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[IK4-Ikerlan Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aperkaz@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Mikel Cañizo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[IK4-Ikerlan Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[mcanizo@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Aitziber Iglesias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[IK4-Ikerlan Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[aiglesias@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/015]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Performance Analysis of Persistence Technologies for Cloud Repositories of Models</title>
		<link>https://biblioteca.sistedes.es/articulo/performance-analysis-of-persistence-technologies-for-cloud-repositories-of-models/</link>
		<pubDate>Wed, 31 Aug 2016 14:27:12 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1851</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1851</post_id>
		<post_date><![CDATA[2016-08-31 16:27:12]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 14:27:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[performance-analysis-of-persistence-technologies-for-cloud-repositories-of-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1852]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The growing adoption of Model Driven Development (MDD) in companies during last decade arises some model interchange problems. Companies need support to interchange models and reuse parts of them for developing new projects. Traditional tools for model edition and model interchange have different performance issues related to the models storage. There are mainly two styles to organize the persistence of models into repositories: a complex and large model or a large amount of small models. This last approach is common in companies that generate software from models. In this paper, we analyse performance properties of different persistence technologies to store small/medium-scale models, the analysis results should be considered in the design of model repositories in the cloud. With this aim, we have designed and developed a generic architecture to evaluate each persistence technology under similar situations.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[model repository, persistence technology, performance analysis]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan-Pablo Salazar-Álvarez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Center for Open Middleware, Universidad Politécnica de Madrid (UPM)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jpsalalv@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Elena Gómez-Martínez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Center for Open Middleware, Universidad Politécnica de Madrid (UPM)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[elena.gomez@centeropenmiddleware.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Miguel de Miguel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DIT, Universidad Politécnica de Madrid (UPM)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mmiguel@dit.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/016]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una Propuesta de Editor Gráfico para el Modelado y la Generación de Código de Patrones de Eventos sobre Drones</title>
		<link>https://biblioteca.sistedes.es/articulo/una-propuesta-de-editor-grafico-para-el-modelado-y-la-generacion-de-codigo-de-patrones-de-eventos-sobre-drones/</link>
		<pubDate>Wed, 31 Aug 2016 14:35:03 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1854</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1854</post_id>
		<post_date><![CDATA[2016-08-31 16:35:03]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 14:35:03]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-propuesta-de-editor-grafico-para-el-modelado-y-la-generacion-de-codigo-de-patrones-de-eventos-sobre-drones]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1855]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los lenguajes de procesamiento de eventos (EPL) permiten declarar e implementar patrones de eventos que son procesados posteriormente por motores de procesamiento de eventos complejos (CEP) y así poder detectar situaciones de interés del usuario en tiempo real. Para llevar a cabo esta tarea, el usuario debe tener un alto grado de experiencia en estos lenguajes. Sin embargo, y en el ámbito de los drones, los usuarios suelen tener un vasto conocimiento en el dominio para el que se necesitan definir ciertos patrones de eventos (motores, dispositivos de navegación, pilotos automáticos, etc.), pero que son inexpertos tanto en EPLs como en el lenguaje requerido para implementar las acciones a llevar a cabo en el dron tras la detección de los eventos. En este artículo presentamos un editor de modelado de patrones con el propósito de facilitar a los usuarios finales un entorno amigable e intuitivo con el que poder definir gráficamente las situaciones críticas y relevantes que se requieran detectar en los drones, y sin necesidad de conocer ningún lenguaje de programación en particular. Además, este editor transforma estos modelos gráficos de patrones al código que los implementa.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Procesamiento de Eventos Complejos, Lenguaje de Procesamiento de Eventos, Desarrollo de Software Dirigido por Modelos, Editor de Modelado Gráfico, Dron]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanher@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Enrique Moguel	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[enrique@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Carlos Preciado	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jcpreciado@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Fernando Sánchez-Figueroa	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[fernando@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/021]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards Distributed Model Transformations with LinTra</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-distributed-model-transformations-with-lintra/</link>
		<pubDate>Wed, 31 Aug 2016 14:40:39 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1857</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1857</post_id>
		<post_date><![CDATA[2016-08-31 16:40:39]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 14:40:39]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-distributed-model-transformations-with-lintra]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1858]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Performance and scalability of model transformations are becoming prominent topics in Model-Driven Engineering. In previous work, we introduced LinTra, a platform for executing model transformations in parallel. LinTra is based on the Linda model of a coordination language and is intended to be used as a middleware where high-level model transformation languages are compiled. In this paper we present an approach to achieve scalable out-place model-to-model transformation executions in LinTra by distributing the models involved in the transformation over a set of machines.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Model Transformation, Distribution, LinTra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Loli Burgueño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[loli@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Wimmer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Business Informatics Group, Vienna University of Technology]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[wimmer@big.tuwien.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Vallecillo	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[av@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/022]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards the Automation of Metamorphic Testing in Model Transformations</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-the-automation-of-metamorphic-testing-in-model-transformations/</link>
		<pubDate>Wed, 31 Aug 2016 14:49:32 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1860</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1860</post_id>
		<post_date><![CDATA[2016-08-31 16:49:32]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 14:49:32]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-the-automation-of-metamorphic-testing-in-model-transformations]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1861]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Model transformations are the cornerstone of Model-Driven Engineering, and provide the essential mechanisms for manipulating and transforming models. Checking whether the output of a model transformation is correct is a manual and error-prone task, this is refereed to as the oracle problem in the software testing literature. The correctness of the model transformation program is crucial for the proper generation of its output, so they should be tested. Metamorphic testing is a testing technique to alleviate the oracle problem consisting on exploiting the relations between different inputs and outputs of the program under test, so-called metamorphic relations. In this paper we give an insight into our approach to generically define metamorphic relations for model transformations, which can be automatically instantiated given any specific model transformation.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Metamorphic Testing, Model Transformation, Automation, Generic]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Troya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jtroya@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/023]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Lenguaje específico para el modelado de flujos de trabajo aplicados a ciencia de datos</title>
		<link>https://biblioteca.sistedes.es/articulo/lenguaje-especifico-para-el-modelado-de-flujos-de-trabajo-aplicados-a-ciencia-de-datos/</link>
		<pubDate>Wed, 31 Aug 2016 14:59:40 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1863</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1863</post_id>
		<post_date><![CDATA[2016-08-31 16:59:40]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 14:59:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[lenguaje-especifico-para-el-modelado-de-flujos-de-trabajo-aplicados-a-ciencia-de-datos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1864]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La ciencia de datos permite la extracción de conocimiento utilizando fuentes no heterogéneas con grandes volúmenes de datos. Este campo es actualmente una de las áreas de mayor crecimiento debido al aumento exponencial de datos disponibles, con aplicación en un amplio rango de dominios. De hecho, es frecuente que los usuarios no posean conocimientos específicos en computación. Para ellos los flujos de trabajo son un mecanismo adecuado de representación y modelización de su proceso de trabajo, ya que permiten definir a alto nivel la secuencia de acciones que permitiría capturar la información y transformarla en conocimiento. Los sistemas de gestión de flujos de trabajo son los encargados de ejecutarlos de forma transparente. En este trabajo se presenta, formalizando su sintaxis abstracta, un lenguaje para la definición de flujos de trabajo a distintos niveles de abstracción. El desarrollo de este lenguaje, por su independencia de la notación concreta, se hace necesario para alcanzar un mayor nivel de interoperabilidad entre las aplicaciones ya desarrolladas para este fin.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[lenguaje específico del dominio, flujos de trabajo, ciencia de datos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rubén Salado-Cid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico, Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rsalado@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Raúl	Romero	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico, Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/017]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>MDDE: Una concepción genérica para diseño de entornos de desarrollo de software basados en MDSE</title>
		<link>https://biblioteca.sistedes.es/articulo/mdde-una-concepcion-generica-para-diseno-de-entornos-de-desarrollo-de-software-basados-en-mdse/</link>
		<pubDate>Wed, 31 Aug 2016 15:03:57 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1866</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1866</post_id>
		<post_date><![CDATA[2016-08-31 17:03:57]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 15:03:57]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mdde-una-concepcion-generica-para-diseno-de-entornos-de-desarrollo-de-software-basados-en-mdse]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1867]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Se presenta MDDE (Model-Driven Development Environment), una concepción genérica para diseño de entornos de desarrollo de software basados en MDSE. Su objetivo es facilitar el uso de esta disciplina a los ingenieros software que di-señan e implementan entornos de soporte a las metodologías que proponen y que necesitan incluir en ellos nuevos modelos de información, herramientas y proce-sos de desarrollo. El componente principal de la concepción propuesta es un mo-delo de referencia que define las capacidades básicas, tanto funcionales como de interacción, que son comunes a cualquier entorno. En ella, la especificación e im-plementación de entornos, el soporte a los procesos que determinan su funciona-lidad y la definición de las opciones de interacción, supervisión y control por par-te de los operadores, se realizan íntegramente mediante la formulación de mode-los. Para dar soporte a esta capacidad, el modelo de referencia incluye un meta-modelo que formaliza tales modelos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[MDSE, meta-modelado, entorno de desarrollo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[César Cuevas		]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Ingeniería Software y Tiempo Real, Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cuevasce@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Patricia López Martínez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Ingeniería Software y Tiempo Real, Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[lopezpa@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose M. Drake]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Ingeniería Software y Tiempo Real, Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[drakej@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/018]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Desarrollo Eficiente de Lenguajes Específicos de Dominio para la Ejecución de Procesos de Minería de Datos</title>
		<link>https://biblioteca.sistedes.es/articulo/desarrollo-eficiente-de-lenguajes-especificos-de-dominio-para-la-ejecucion-de-procesos-de-mineria-de-datos/</link>
		<pubDate>Wed, 31 Aug 2016 15:09:08 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1869</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1869</post_id>
		<post_date><![CDATA[2016-08-31 17:09:08]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 15:09:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[desarrollo-eficiente-de-lenguajes-especificos-de-dominio-para-la-ejecucion-de-procesos-de-mineria-de-datos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1870]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Aunque las técnicas de minería de datos están consiguiendo cada día una mayor popularidad, su complejidad impide que sean aún utilizables por personas sin un sólido conocimiento en las mismas. Una posible solución, ya explorada por los autores de este artículo, es la construcción de Lenguajes Específicos de Dominio que proporcionen una serie de primitivas de alto nivel para la ejecución de procesos de minería de datos. Dichas primitivas sólo hacen referencia a terminología propia del dominio analizado, enmascarando detalles técnicos de bajo nivel. No obstante, la construcción de un lenguaje específico de dominio puede ser un proceso costoso. Este artículo muestra como reducir los tiempos de desarrollo de estos lenguajes de análisis mediante la reutilización de partes comunes de estos DSLs.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Lenguajes Específicos de Dominio, Desarrollo de Software Dirigido por Modelos, Minería de Datos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alfonso de La Vega	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería Informática y Electrónica Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alfonso.delavega@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Diego García-Saiz	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería Informática y Electrónica Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[diego.garciasuc@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Marta Zorrilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería Informática y Electrónica Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[marta.zorrilla@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Pablo Sánchez	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería Informática y Electrónica Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[p.sanchez@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/019]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Bringing together existing Business Modeling flavors</title>
		<link>https://biblioteca.sistedes.es/articulo/bringing-together-existing-business-modeling-flavors/</link>
		<pubDate>Wed, 31 Aug 2016 15:15:10 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1872</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1872</post_id>
		<post_date><![CDATA[2016-08-31 17:15:10]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 15:15:10]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[bringing-together-existing-business-modeling-flavors]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1873]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[There are currently several techniques or notations for business modeling that allow the idea of business to be explored in greater or less detail, while simultaneously helping to understand, conceptualize and represent the services that add value to an organization. All of these techniques have similarities and differences, but are in many cases complementary. However, there is no integrated environment that makes it possible to work with several models simultaneously, and much less that provides support as regards identifying, registering and managing the relationships among them. This work is a first step towards attempting to fill this lack by constructing a technological environment that will integrate tools in order to support different business modeling techniques and to register and manage the relationships among different models.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Business Modeling, Toolkit, Model Engineering]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan M. Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Valeria De Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[valeria.decastro@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[David Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[david.granada@urjc.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[ Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/024]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una herramienta para evaluar el rendimiento de aplicaciones intensivas en datos</title>
		<link>https://biblioteca.sistedes.es/articulo/una-herramienta-para-evaluar-el-rendimiento-de-aplicaciones-intensivas-en-datos/</link>
		<pubDate>Wed, 31 Aug 2016 15:19:45 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1875</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1875</post_id>
		<post_date><![CDATA[2016-08-31 17:19:45]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 15:19:45]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-herramienta-para-evaluar-el-rendimiento-de-aplicaciones-intensivas-en-datos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1876]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las aplicaciones intensivas en datos (AID) que usan tecnologías de Big Data se están convirtiendo en una parte importante del mercado de desarrollo de software. Sin embargo, las técnicas --y su automatización-- para el asesoramiento de la calidad para este tipo de aplicaciones es claramente insuficiente. El proyecto DICE H2020 tiene como objetivo definir metodologías y crear herramientas para desarrollar y monitorizar AID mediante técnicas de ingeniería dirigida por modelos. En este artículo presentamos un componente clave del proyecto DICE: su herramienta de simulación. Esta herramienta es capaz de evaluar el rendimiento de AID simulando su comportamiento mediante modelos de redes de Petri. Como complemento, existe a disposición un vídeo mostrando la herramienta en http://tiny.cc/z1qzay. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Aplicaciones Intensivas en Datos, Lenguaje de Modelado Unificado (UML), Redes de Petri, Herramientas de simulación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Abel Gómez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[abel.gomez@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José	Merseguer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática e Ingeniería de Sistemas Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jmerse@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/026]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Análisis de transformaciones de modelos ATL con AnATLyzer</title>
		<link>https://biblioteca.sistedes.es/articulo/analisis-de-transformaciones-de-modelos-atl-con-anatlyzer/</link>
		<pubDate>Wed, 31 Aug 2016 15:29:57 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1878</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1878</post_id>
		<post_date><![CDATA[2016-08-31 17:29:57]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 15:29:57]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analisis-de-transformaciones-de-modelos-atl-con-anatlyzer]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1879]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las transformaciones de modelos son un elemento clave del Desarrollo de Software Dirigido por Modelos puesto que permiten automatizar muchas tareas de manipulación de modelos. Por tanto, disponer de métodos que permitan detectar errores no triviales resulta esencial. Sin embargo no existen herramientas prácticas de análisis de transformaciones que sean capaces de tratar con transformaciones complejas.

En esta demostración se presentará anATLyzer un analizador estático para transformaciones ATL que hace uso de "constraint solving" para mejorar la precisión del análisis. AnATLyzer no se limita a un subconjunto de ATL sino que intenta cubrir ATL completamente. Se integra con el editor de ATL en Eclipse, y ofrece servicios adicionales como visualización y quick fixes, así como una API para ser utilizado de manera programática.

La demostración se ilustrará con un ejemplo sobre el que se mostrarán algunos de los tipos de errores que hemos encontrado analizando transformaciones del Zoo de ATL, con el objetivo de motivar la necesidad de este tipo de herramientas y mostrar sus características principales.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Transformaciones de modelos, ATL, AnATLyzer, Análisis estático, Constraint solving]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús Sánchez Cuadrado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de investigación Miso, Universidad Autónoma de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jesus.sanchez.cuadrado@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Esther Guerra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de investigación Miso, Universidad Autónoma de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[esther.guerra@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan de Lara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de investigación Miso, Universidad Autónoma de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juan.delara@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/025]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Auditorías de Green in IT: Un Mapeo Sistemático</title>
		<link>https://biblioteca.sistedes.es/articulo/auditorias-de-green-in-it-un-mapeo-sistematico/</link>
		<pubDate>Wed, 31 Aug 2016 22:01:19 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1881</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1881</post_id>
		<post_date><![CDATA[2016-09-01 00:01:19]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 22:01:19]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[auditorias-de-green-in-it-un-mapeo-sistematico]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2191]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años el mundo ha ido experimentando una serie de cambios ambientales que han hecho que en la sociedad surja una fuerte convicción en pos de proteger el medioambiente. Las Tecnologías de la Información (TI) y, de manera especial, las tecnologías software, pueden contribuir a la ecosostenibilidad de dos maneras: “Green By IT”, en el sentido de que las TI pueden proporcionar herramientas que permitan llevar a cabo tareas de una manera adecuada para el medioambiente, y “Green In IT”, cuando las propias TI tienen impacto en el medioambiente, debido a su consumo energético. Sin embargo, las técnicas de Green in IT son relativamente jóvenes y no existe ningún estándar o marco que permita controlar su correcta implementación y/o funcionamiento. Por ello, el objetivo del presente mapeo sistemático es recopilar el conocimiento actual en relación a las auditorías de Green in IT, con el fin de poder determinar cuáles son las características más importantes a la hora de desarrollar un marco de auditoría de Green in IT. Los resultados obtenidos demuestran la novedad de esta área y la casi nula existencia de estudios relacionados con ésta, y, por ello, la necesidad de elaborar un marco de auditoría de Green in IT.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Auditoría, Green in IT, Mapeo sistemático]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[J. David Patón-Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Alarcos, Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[JDavid.Paton@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Alarcos, Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Mario.Piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/053]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>¿Qué desafíos presenta el desarrollo global del software? Aprende jugando</title>
		<link>https://biblioteca.sistedes.es/articulo/que-desafios-presenta-el-desarrollo-global-del-software-aprende-jugando/</link>
		<pubDate>Wed, 31 Aug 2016 22:06:22 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1885</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1885</post_id>
		<post_date><![CDATA[2016-09-01 00:06:22]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 22:06:22]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[que-desafios-presenta-el-desarrollo-global-del-software-aprende-jugando]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las empresas de desarrollo de software intentan unirse al mercado global con el fin de poder contratar mano de obra en otros países, buscando reducir los costes, aumentar la productividad y así obtener ventajas competitivas. Esto es lo que se conoce como Desarrollo Global del Software (DGS o GSD, por sus siglas en inglés: Global Software Development). Para realizar esta práctica las empresas requieren desarrolladores que posean conocimientos y habilidades para solventar los problemas que surgen a causa de la distancia geográfica, temporal y cultural. Es aquí donde los juegos serios pueden jugar un papel importante, ya que se trata de juegos educativos que permiten adquirir conocimientos y habilidades con un bajo coste. En este artículo se describe un juego con el cual se puedan adquirir algunas de las competencias necesarias en el DGS. El juego simula escenarios que suelen presentarse durante el desarrollo global de un proyecto software, de manera que el usuario pueda tomar conciencia de los problemas referentes al DGS y adquirir una cierta experiencia a la hora de solventar estos problemas. Además, se describe una evaluación preliminar del mismo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Desarrollo Global del Software, Juegos Serios, Desarrollo Distribuido del Software]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aurora Vizcaíno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Alarcos, Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aurora.vizcaino@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Alarcos, Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[david.valencia1@alu.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Pablo Soto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Alarcos, Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jpsoto@mat.uson.mx]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Lilia García-Mundo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Alarcos, Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[liliacarmen.garcia@alu.uclm.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Alarcos, Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[mario.piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2190]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/055]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia el uso de sistemas de recomendación en sistemas de alta variabilidad</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-el-uso-de-sistemas-de-recomendacion-en-sistemas-de-alta-variabilidad/</link>
		<pubDate>Wed, 31 Aug 2016 22:21:13 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1888</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1888</post_id>
		<post_date><![CDATA[2016-09-01 00:21:13]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 22:21:13]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-el-uso-de-sistemas-de-recomendacion-en-sistemas-de-alta-variabilidad]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1889]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los sistemas de alta variabilidad son sistemas software cuyo comportamiento puede ser personalizado de acuerdo con las necesidades de un contexto particular. De hecho, existen sistemas de alta variabilidad que representan miles de productos. Por otra parte, en la industria encontramos los sistemas de recomendación, los cuales, permiten recomendar la serie de productos que mejor se adapten a un usuario o un contexto de uso particular. En este artículo de prospección exploramos el uso de sistemas de recomendación en el contexto de los sistemas de alta variabilidad. Asimismo, identificamos algunas tareas donde podrían ayudar a la gestión de los sistemas de variabilidad.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[feature models, recommender systems, variability-intensive systems, software product lines]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jorge L. Rodas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Milagro, Ecuador]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jrodass@unemi.edu.ec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Olivares]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Inria - Rennes, France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[javier.olivares@inria.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José A. Galindo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Inria - Rennes, France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jagalindog@inria.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[David Benavides]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[benavides@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Aplicando Scaffolding en el desarrollo de Líneas de Producto Software</title>
		<link>https://biblioteca.sistedes.es/articulo/aplicando-scaffolding-en-el-desarrollo-de-lineas-de-producto-software/</link>
		<pubDate>Wed, 31 Aug 2016 22:35:36 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1893</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1893</post_id>
		<post_date><![CDATA[2016-09-01 00:35:36]]></post_date>
		<post_date_gmt><![CDATA[2016-08-31 22:35:36]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[aplicando-scaffolding-en-el-desarrollo-de-lineas-de-producto-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1894]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las Líneas de Producto Software (LPS) constituyen una tecnología madura para producir software que ha sido objeto de una gran cantidad de investigación, por lo que existen numerosas técnicas, metodologías y herramientas para crearlas. Sin embargo, es complicado utilizar algunas de estas herramientas en la industria debido a factores como la rápida evolución que han tenido los entornos de desarrollo, lo que provoca que estas herramientas estén obsoletas, la falta de soporte para proyectos que utilizan diferentes lenguajes de desarrollo, o la dificultad en el mantenimiento del código de los productos generados por la LPS. Por otra parte, la popularidad de la técnica de scaffolding no ha parado de aumentar entre los desarrolladores de software desde que apareció hace unos años, a pesar de recurrir a alternativas poco valoradas en la academia tales como el uso de preprocesadores.

En este trabajo proponemos la utilización de la técnica de scaffolding para implementar una LPS, lo que nos permite superar algunas de las limitaciones clásicas de otras herramientas LPS.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ingeniería de líneas de producto software, scaffolding, arquitectura software de propósito general, gestión de la variabilidad, desarrollo de software orientado a características]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Nieves R. Brisaboa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de Datos, Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[brisaboa@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alejandro Cortiñas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de Datos, Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[alejandro.cortinas@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Miguel R. Luaces]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de Datos, Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[luaces@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[ Oscar Pedreira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de Datos, Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[opedreira@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/001]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Herramienta de Soporte a la Evaluación y Mejora de la Gestión de Planes de Emergencia</title>
		<link>https://biblioteca.sistedes.es/articulo/herramienta-de-soporte-a-la-evaluacion-y-mejora-de-la-gestion-de-planes-de-emergencia/</link>
		<pubDate>Thu, 01 Sep 2016 14:08:12 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1900</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1900</post_id>
		<post_date><![CDATA[2016-09-01 16:08:12]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 14:08:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[herramienta-de-soporte-a-la-evaluacion-y-mejora-de-la-gestion-de-planes-de-emergencia]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1901]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La gestión de planes de emergencia es un tema que compete a todas las organizaciones y a la comunidad en general. La falta de propuestas para evaluar un plan de emergencia, más allá de una simple auditoría, hace que los planificadores construyan planes de emergencia basándose en su propia formación y experiencia. A pesar de las regulaciones legales existentes sobre formato y contenido de los mismos, pensamos que la definición de un marco de referencia para evaluar su gestión, aumentará la capacidad de los planificadores de construir cada vez mejores planes. QuEP define un modelo de evaluación y mejora basado en niveles de madurez, respecto a la gestión que una organización hace de su plan de emergencia; cada nivel identifica principios, prácticas, cuestiones y técnicas. Una vez realizada la evaluación de la organización, se le sugieren las técnicas a seguir para mejorar el ciclo de vida de su plan de emergencia, aumentando así la calidad del mismo, y por tanto, mejorando la gestión de emergencias en la organización. En este artículo se presenta el desarrollo iterativo de una herramienta web de soporte al marco QuEP para la evaluación de la gestión de planes de emergencia, generando la estrategia de mejora a seguir como un conjunto de buenas prácticas organizadas por niveles y por actores.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Modelo de evaluación y mejora, Gestión de Planes de Emergencia, Marco QuEP, Herramienta de soporte]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana Gabriela Núñez Ávila]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[anunez@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mª Carmen Penadés Gramage	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mpenades@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José H. Canós Cerda	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jhcanos@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/054]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Smart Spaces: sistema de tecnoinclusión inteligente</title>
		<link>https://biblioteca.sistedes.es/articulo/smart-spaces-sistema-de-tecnoinclusion-inteligente/</link>
		<pubDate>Thu, 01 Sep 2016 14:12:49 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1903</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1903</post_id>
		<post_date><![CDATA[2016-09-01 16:12:49]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 14:12:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[smart-spaces-sistema-de-tecnoinclusion-inteligente]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El mundo se está transformando y la sociedad está cambiando gracias al uso de las nuevas tecnologías. En los últimos años las ciudades están evolucionando mejorando sus infraestructuras, su manera de gestionar los recursos, etc., y por consiguiente, facilitando y mejorando la vida de sus ciudadanos. Pero existe un sector de la sociedad que no está siendo muy considerado en esta evolución de las ciudades: las personas con diversidad funcional. Smart Spaces es una propuesta estratégica para la integración de personas con discapacidad en el área de movilidad mediante la combinación fundamentos tecnológicos de entornos inteligentes y el soporte a los servicios de voluntariado para la atención a la diversidad funcional en la Universidad de Extremadura. El objetivo principal de este proyecto es facilitar el acceso a la información que nos rodea a las personas con discapacidad mediante una plataforma Web y aplicación para dispositivos móviles con la que se pretende ayudar a las personas con discapacidad, mostrándoles la información que ellos requieren y en el formato apropiado. Haciendo uso de una estrategia colaborativa para la adquisición de puntos de interés y mostrando dichos puntos a través de una capa de Realidad Aumentada. Las personas con movilidad reducida podrán conocer si el establecimiento o punto de destino tiene plazas de aparcamiento adaptadas, podrán consultar su estado, podrán conocer la localización de las rampas de acceso, lavabos adaptados, ascensores, etc.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Smart Cities, Accesibilidad, Movilidad Reducida, Puntos de Interés, Realidad Aumentada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Enrique Moguel	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group. Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[enrique@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Carlos Preciado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group. Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jcpreciado@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Fernando Sánchez-Figueroa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group. Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fernando@unex.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group. Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juanher@unex.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1947]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/056]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Estudio del Soporte a la Variabilidad en la Nube en un entorno con Multitenencia: Plataforma GPaaS</title>
		<link>https://biblioteca.sistedes.es/articulo/estudio-del-soporte-a-la-variabilidad-en-la-nube-en-un-entorno-con-multitenencia-plataforma-gpaas/</link>
		<pubDate>Thu, 01 Sep 2016 14:37:11 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1906</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1906</post_id>
		<post_date><![CDATA[2016-09-01 16:37:11]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 14:37:11]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[estudio-del-soporte-a-la-variabilidad-en-la-nube-en-un-entorno-con-multitenencia-plataforma-gpaas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1907]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los requisitos de la sociedad actual y la nueva era de Internet de las Cosas (IoT), entre otros múltiples factores, explican el auge del “Software as a Service” (SaaS) y el paradigma de computación en la nube (Cloud Computing). La tendencia en el desarrollo software apunta hacia la producción de software cada vez más flexible, dinámico y personalizado, que a su vez, es accesible a través de Internet (off-premises), sin necesidad de ser instalado y gestionado localmente (on-premises). Una de las propiedades clave de Cloud Computing es la multitenancia: la instan-ciación de varias ocurrencias software a partir de una aplicación base o recursos compartidos. En este artículo se presenta: (i) un estudio de la multitenancia y el soporte a la variabilidad en la nube; y (ii) una experiencia de desarrollo SaaS cuyo objetivo es analizar la capacidad de la multitenancia para soportar la flexibilidad, adaptabilidad y variabilidad del software en la nube, así como sus limitaciones, con el fin identificar líneas de investigación futuras. En particular, el análisis se ha realizado utilizando la plataforma Cloud de Minsait (Indra) sobre Microsoft Azu-re en el laboratorio iSSF de la UPM.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Cloud Computing, Multitenancia, Variabilidad, Flexibilidad, Personalización Masiva, Adaptabilidad, Reconfiguración Dinámica]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Héctor Humanes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[CITSEM, Universidad Politecnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[h.humanes@alumnos.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Iván Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[CITSEM, Universidad Politecnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ivan.htemprano@alumnos.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jessica Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[CITSEM, Universidad Politecnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[yesica.diaz@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[ Jennifer Perez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[CITSEM, Universidad Politecnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jenifer.perez@eui.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Alfonso Ríos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Minsait, Indra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[ariosa@minsait.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[ Javier Gonzalez- Rodriguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Minsait, Indra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[jvgonzalez@minsait.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[ Jordi Paraire]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[jjparaire@minsait.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Minsait, Indra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/002]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evolución arquitectónica de servicios basada en modelos CVL con cardinalidad</title>
		<link>https://biblioteca.sistedes.es/articulo/evolucion-arquitectonica-de-servicios-basada-en-modelos-cvl-con-cardinalidad/</link>
		<pubDate>Thu, 01 Sep 2016 14:42:15 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1909</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1909</post_id>
		<post_date><![CDATA[2016-09-01 16:42:15]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 14:42:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evolucion-arquitectonica-de-servicios-basada-en-modelos-cvl-con-cardinalidad]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1910]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La computación en la nube se está convirtiendo en un mecanismo predominante para desplegar fácilmente aplicaciones con requisitos especiales, tales como el almacenamiento masivo compartido, o el equilibrado de carga. Esta funcionalidad se proporciona normalmente como servicios por las plataformas en la nube.
Un desarrollador puede mejorar tanto el despliegue de sus aplicaciones como la productividad siguiendo un enfoque multi-tenancy, donde diferentes variantes de la misma aplicación pueden adaptarse rápidamente a las necesidades de cada usuario (tenant). Sin embargo, gestionar la variabilidad inherente a las aplicaciones multi-tenant, con cientos de usuarios y miles de configuraciones arquitectónicas diferentes, puede llegar a ser una tarea intratable de abordar manualmente. En este artículo, se propone un enfoque de línea de producto software en el cual: (1) usamos modelos de variabilidad con cardinalidad para modelar cada tenant como una característica clonable, (2) automatizamos el proceso de evolución de las arquitecturas de aplicaciones multi-tenant, y (3) demostramos que la implementación de los procesos de evolución es correcta y eficiente para un número elevado de tenants en un tiempo razonable.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Cardinalidad, Evolución, Línea de Producto Arquitectónica, Variabilidad CVL]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Miguel Horcas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Andalucía Tech, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[horcas@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mónica Pinto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Andalucía Tech, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pinto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Andalucía Tech, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/003]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Measuring the quality of transformation alternatives in software architectures evolution</title>
		<link>https://biblioteca.sistedes.es/articulo/measuring-the-quality-of-transformation-alternatives-in-software-architectures-evolution/</link>
		<pubDate>Thu, 01 Sep 2016 14:48:57 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1912</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1912</post_id>
		<post_date><![CDATA[2016-09-01 16:48:57]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 14:48:57]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[measuring-the-quality-of-transformation-alternatives-in-software-architectures-evolution]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1913]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Many today's software systems need to be self-adapted at run-time. Model transformation is a good approach to adapt the component-based architecture of such software systems. However, existing model transformation processes focus on the functionalities of systems, giving less importance to the quality attributes. The goal of this study is to improve model transformation processes by also considering quality attributes in the generation and adaptation of component-based architectures (i.e., driving the selection among many alternative model transformations by software architecture metrics). Such metrics evaluate the qualities of an architecture, such as flexibility and modifiability. This paper provides some measures of quality for different transformation alternatives and an example in the ENIA software.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[component-based software architecture, conguration, architecture metrics, quality-driven transformation, model transformation]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Criado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[javi.criado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Silverio Martínez-Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[GESSI Research Group, Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[smartinez@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[David Ameller]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[GESSI Research Group, Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[dameller@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Luis Iribarne]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[luis.iribarne@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>El uso de modelos de características con atributos para pruebas en sistemas de alta variabilidad: primeros pasos</title>
		<link>https://biblioteca.sistedes.es/articulo/el-uso-de-modelos-de-caracteristicas-con-atributos-para-pruebas-en-sistemas-de-alta-variabilidad-primeros-pasos/</link>
		<pubDate>Thu, 01 Sep 2016 14:55:55 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1915</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1915</post_id>
		<post_date><![CDATA[2016-09-01 16:55:55]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 14:55:55]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[el-uso-de-modelos-de-caracteristicas-con-atributos-para-pruebas-en-sistemas-de-alta-variabilidad-primeros-pasos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los modelos de características con atributos representan todos los productos de una línea de productos junto con información adicional. En la literatura encontramos modelos representando miles de productos distintos. La selección de estos productos para hacer pruebas es un reto que se está estudiando en la literatura, en algunas de estas propuestas utilizan modelos de características con atributos para seleccionar este subconjunto de productos. Sin embargo no existe una guía de como utilizar los atributos para selección de casos de pruebas en distintos escenarios, con el objetivo de alimentar esa guía, nos proponemos buscar en la literatura la manera de caracterizar los modelos usados por otros investigadores con el objetivo de ayudar a modelar atributos en modelos de características para realizar las pruebas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Modelo de características, Atributos, Pruebas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Mariuxi Vinueza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad of Milagro, Ecuador]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mvinuezam@unemi.edu.ec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Jorge L. Rodas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad of Milagro, Ecuador]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrodass@unemi.edu.ec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José A. Galindo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[INRIA - Rennes, France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jagalindo@inria.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[David Benavides]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[benavides@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/006]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una herramienta de programación para usuarios finales de aplicaciones móviles basadas en datos abiertos</title>
		<link>https://biblioteca.sistedes.es/articulo/una-herramienta-de-programacion-para-usuarios-finales-de-aplicaciones-moviles-basadas-en-datos-abiertos/</link>
		<pubDate>Thu, 01 Sep 2016 15:08:27 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1919</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1919</post_id>
		<post_date><![CDATA[2016-09-01 17:08:27]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 15:08:27]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-herramienta-de-programacion-para-usuarios-finales-de-aplicaciones-moviles-basadas-en-datos-abiertos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1920]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Durante los últimos años los teléfonos inteligentes (smartphones) han experimentado un rápido crecimiento. De manera que, actualmente, los dispositivos móviles constituyen la opción más frecuente de acceso a internet. De hecho, casi se puede decir que existe una aplicación móvil para cada aspecto de nuestra vida tanto profesional como personal. Por otro lado, últimamente, impulsado por las políticas internacionales de transparencia, se han puesto a disposición pública un gran número de recursos de datos abiertos. Datos abiertos de turismo, de meteorología y geográficos, por citar algunos, se han puesto disponibles para su reutilización por parte de instituciones públicas de todos los niveles. Sin embargo, a pesar de las acciones realizadas para la generación de aplicaciones que exploten estas nuevas fuentes de datos, la gran mayoría está enfocada en datos de un solo dominio y, normalmente, en datos de un solo conjunto de datos. Por lo tanto, los usuarios finales se ven forzados a utilizar varias aplicaciones al mismo tiempo para poder satisfacer sus necesidades particulares. En este trabajo, proponemos una herramienta de desarrollo de aplicaciones por parte de usuarios finales para la creación de aplicaciones basadas en datos abiertos personalizadas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[End-User Development, Mobile Application Development, Open Data]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Roberto Rodríguez-Echeverría]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rre@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Eneas Macías]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[enmaciasm@alumnos.unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José M. Conejero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Quercus Software Engineering Group, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[chemacm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/049]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un Repositorio RDF para la Integración de Flujos de Datos de Analítica Web y Comercio Electrónico</title>
		<link>https://biblioteca.sistedes.es/articulo/un-repositorio-rdf-para-la-integracion-de-flujos-de-datos-de-analitica-web-y-comercio-electronico/</link>
		<pubDate>Thu, 01 Sep 2016 15:15:54 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1922</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1922</post_id>
		<post_date><![CDATA[2016-09-01 17:15:54]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 15:15:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-repositorio-rdf-para-la-integracion-de-flujos-de-datos-de-analitica-web-y-comercio-electronico]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1923]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La Analítica Web supone hoy en día una tarea ineludible para las empresas de comercio electrónico, ya que les permite analizar el comportamiento de sus clientes. El proyecto Europeo SME-Ecompass tiene como objetivo desarrollar herramientas avanzadas de análitica web accesibles para las PYMES. Con esta motivación, proponemos servicio de integración de datos basado en ontologías para recopilar, integrar y almacenar información de traza web procedente de distintas fuentes. Estas se consolidan en un Repositorio RDF diseñado para proporcionar
semántica común a los datos de análisis y dar servicio homogéneo a algoritmos de Minería de Datos. El servicio propuesto se ha validado mediante traza digital real (Google Analitics y Piwik) de 15 tiendas virtuales de diferentes sectores y países europeos (UK, España, Grecia y
Alemania) durante varios meses de actividad. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Integraciónn de datos, RDF, Ontologías, Análisis Web, Google Analytics]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Maria del Mar Roldán-García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mmar@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose García-Nieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jnieto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[ Jose F. Aldana-Montes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jfam@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/027]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>v-RDFCSA: Compresión e Indexación de Colecciones de Versiones RDF</title>
		<link>https://biblioteca.sistedes.es/articulo/v-rdfcsa-compresion-e-indexacion-de-colecciones-de-versiones-rdf/</link>
		<pubDate>Thu, 01 Sep 2016 15:29:43 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1926</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1926</post_id>
		<post_date><![CDATA[2016-09-01 17:29:43]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 15:29:43]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[v-rdfcsa-compresion-e-indexacion-de-colecciones-de-versiones-rdf]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1927]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento – NoComercial – CompartirIgual (by-nc-sa)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La compresión, la indexación y la consulta de colecciones RDF son tópicos emergentes en la conocida como Web de Datos. Sin embargo, las técnicas más relevantes en el estado del arte no van más allá de la visión estática de los datos y obvian el cómo estos archivos RDF evolucionan a lo largo del tiempo, generando múltiples versiones de la colección que precisan ser preservadas para su explotación en diferentes tipos de aplicaciones.

En este artículo presentamos una nueva solución para la compresión de archivos RDF. Nuestra propuesta, referida como v-RDFCSA, extiende el auto-índice RDFCSA con estructuras de bits que implementan la codificación de la información de versionado. De esta manera, conseguimos preservar los triples RDF en espacio comprimido y, sobre ellos, resolver tanto patrones SPARQL como operaciones temporales de consulta basadas en dichos patrones. Los experimentos realizados, sobre el benchmark BEAR, muestran que v-RDFCSA reduce los requisitos de almacenamiento entre 35 y 60 veces respecto al estado del arte y consigue más de un orden magnitud de ventaja en la resolución de consultas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Archivos RDF, Compresión, Consultas de versiones, RDFCSA]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana Cerdeira-Pena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de Datos, Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[acerdeira@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Antonio Fariña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Laboratorio de Bases de Datos, Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fari@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier D. Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Vienna University of Economics and Business (WU)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jfernand@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Miguel A. Martínez-Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[DataWeb Research, Universidad de Valladolid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[migumar2@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/028]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Compresión de Big Semantic Data basada en HDT y MapReduce</title>
		<link>https://biblioteca.sistedes.es/articulo/compresion-de-big-semantic-data-basada-en-hdt-y-mapreduce/</link>
		<pubDate>Thu, 01 Sep 2016 16:00:40 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1931</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1931</post_id>
		<post_date><![CDATA[2016-09-01 18:00:40]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 16:00:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[compresion-de-big-semantic-data-basada-en-hdt-y-mapreduce]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1932]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[HDT es un formato binario diseñado para la serialización de grandes colecciones RDF que surgió con el objetivo de reducir los requisitos de almacenamiento que presentaban otros formatos RDF. Además de su capacidad para la compresión, la estructura interna de los ficheros HDT permite acceder a los datos comprimidos y, con ello, resolver algunas consultas interés en el ámbito de la Web Semántica. Existen diferentes aplicaciones basadas en HDT, como la exitosa Linked Data Fragments, que sacan provecha de sus particularidades para propósitos de publicación intercambio y consumo de colecciones RDF. Sin embargo, la obtención de estas representaciones está gravada por un proceso de compresión que resulta muy exigente en el consumo de memoria principal. Este hecho, limita la adopción de HDT en aplicaciones basadas en la explotación de Big Semantic Data.  En este artículo presentamos HDT-MR, una revisión del algoritmo de construcción de HDT basada en tecnología MapReduce. Esta nueva propuesta plantea configuraciones optimizadas de jobs MapReduce que permiten i) identificar los vocabularios de URIs y literales, necesarios para la construcción del diccionario HDT y ii) codificar los triples utilizando los diccionarios ya comprimidos. Nuestra experimentación muestra que el rendimiento de HDT-MR es lineal con el volumen de los datos de la entrada y que el despliegue actual, realizado sobre un cluster Hadoop, es capaz de serializar colecciones RDF que contienen miles de millones de triples.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Web Semántica, Compresión, RDF, HDT, MapReduce, Hadoop]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José M. Giménez-García	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Univ Lyon, UJM-Saint-Etienne, CNRS, Laboratoire Hubert Curien, France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jose.gimenez.garcia@univ-st-etienne.fr	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier D.	Fernández	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Institute for Information Business Vienna University of Economics and Business (WU), Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jfernand@wu.ac.at	 ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Miguel A.	Martinez-Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DataWeb Research, Department of Computer Science, University of Valladolid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[migumar2@infor.uva.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/029]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Arquitectura software basada en tecnologías Smart para agricultura de precisión</title>
		<link>https://biblioteca.sistedes.es/articulo/arquitectura-software-basada-en-tecnologias-smart-para-agricultura-de-precision/</link>
		<pubDate>Thu, 01 Sep 2016 16:12:36 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1934</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1934</post_id>
		<post_date><![CDATA[2016-09-01 18:12:36]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 16:12:36]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[arquitectura-software-basada-en-tecnologias-smart-para-agricultura-de-precision]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1935]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo describe la arquitectura de un sistema de información en el contexto de la agricultura de precisión. Una red de sensores instalados sobre las zonas de cultivo se encarga de monitorizar las variables que finalmente alimentan el modelo de riego y fertilización implementado. Las mediciones obtenidas se almacenan de manera autónoma y continua sobre una base de datos MongoDB, cuyo diseño prevé la variabilidad espacio-temporal de los diversos componentes de la aplicación (zonas, cultivos, sectores de irrigación, etc.). Datos obtenidos de otras fuentes, tales como servicios meteorológicos o análisis de suelo completan el modelo, cuyo objetivo final es el de mejorar la eficiencia en la gestión de la explotación agraria. Los procesos que combinan toda esta información y ponen en marcha el modelo se implantan mediante el uso del framework de edición de flujos Node-RED, con el desarrollo de flujos de datos para establecer la conexión con la red de sensores y servicios meteorológicos y proveer de datos al sistema, consiguiendo al integrar estas tecnologías una infraestructura digital para la explotación rentable de recursos agrarios.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Agricultura de Precisión, Modelo de riego, Flujo de Datos, MongoDB]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mscabrera@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Manuel Barrena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[barrena@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pablo Bustos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Tecnología de Computadores y de las Comunicaciones, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pbustos@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Carlos Campillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Centro de Investigaciones Científicas y Tecnológicas de Extremadura (CICYTEX)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[carlos.campillo@gobex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Pablo García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Dpto. Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[pablogr@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/030]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>TINTIN: comprobación incremental de aserciones SQL</title>
		<link>https://biblioteca.sistedes.es/articulo/tintin-comprobacion-incremental-de-aserciones-sql/</link>
		<pubDate>Thu, 01 Sep 2016 16:17:11 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1937</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1937</post_id>
		<post_date><![CDATA[2016-09-01 18:17:11]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 16:17:11]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[tintin-comprobacion-incremental-de-aserciones-sql]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1938]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Ninguno de los SGBD más populares del momento implementa aserciones SQL, obligando así a implementar manualmente su comprobación. Por ello, presentamos TINTIN: una aplicación que genera automáticamente el código SQL para comprobar aserciones. Dicho código captura las tuplas insertadas/borradas en una transacción, comprueba que ninguna de ellas viole ninguna aserción mediante consultas SQL, y materializa los cambios en caso que sean satisfechas. La eficiencia del código se basa en la comprobación incremental de las aserciones.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[aserción, restricción de integridad, comprobación incremental, SQL]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Xavier Oriol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[xoriol@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ernest Teniente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ernest.teniente@upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Guillem Rull]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[grull@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/036]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>RecSim: Hacia la Evaluación de Sistemas de Recomendación Utilizando un Simulador</title>
		<link>https://biblioteca.sistedes.es/articulo/recsim-hacia-la-evaluacion-de-sistemas-de-recomendacion-utilizando-un-simulador/</link>
		<pubDate>Thu, 01 Sep 2016 16:22:57 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1940</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1940</post_id>
		<post_date><![CDATA[2016-09-01 18:22:57]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 16:22:57]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[recsim-hacia-la-evaluacion-de-sistemas-de-recomendacion-utilizando-un-simulador]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1941]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los sistemas de recomendación ofrecen recomendaciones personalizadas a usuarios acerca de ítems de distinto tipo (películas, libros, restaurantes, hoteles, lugares a visitar, etc.), aliviando así la sobrecarga de datos que estos experimentan cuando tienen que tomar decisiones al elegir entre diversas alternativas. Debido a su interés tanto para usuarios finales como para empresas, este tipo de sistemas han atraído una intensa actividad investigadora. En concreto, en los últimos años ha crecido el interés por los sistemas de recomendación dependientes del contexto y por su aplicación en escenarios de computación móvil.

Sin embargo, existen dificultades para evaluar las propuestas existentes debido a la carencia de conjuntos de datos apropiados para evaluación. En este artículo motivamos el interés de evaluar sistemas de recomendación mediante la realización de simulaciones para recoger datos y opiniones de usuarios reales. Asimismo, describimos las ideas principales detrás de la herramienta RecSim que hemos desarrollado.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Sistemas de recomendación, Simulación, Computación Móvil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Sergio Ilarri	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[silarri@unizar.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Slavcho Ivanov]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[619885@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/032]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>WikInfoboxer: A Tool to Create Wikipedia Infoboxes Using DBpedia</title>
		<link>https://biblioteca.sistedes.es/articulo/wikinfoboxer-a-tool-to-create-wikipedia-infoboxes-using-dbpedia/</link>
		<pubDate>Thu, 01 Sep 2016 16:27:38 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1943</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1943</post_id>
		<post_date><![CDATA[2016-09-01 18:27:38]]></post_date>
		<post_date_gmt><![CDATA[2016-09-01 16:27:38]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[wikinfoboxer-a-tool-to-create-wikipedia-infoboxes-using-dbpedia]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1944]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Wikipedia infoboxes present a summary, in a semistructured format, of the articles they are associated to. Therefore, they have become the main information source used by projects to leverage the knowledge in Wikipedia, such as DBpedia. However, creating quality infoboxes is complicated as current mechanisms are based on simple templates which, for example, do not check whether the information provided is semantically correct.

In this paper, we present WikInfoboxer, a tool to help Wikipedia editors to create rich and accurate infoboxes. WikInfoboxer computes attributes that might be interesting for an article and suggests possible values for them after analyzing similar articles from DBpedia. To make the process easier for editors, WikInfoboxer presents this information in a friendly user interface.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Infobox, Wikipedia, DBpedia, Semantic Web]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ismael Rodríguez-Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ismaro.394@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Raquel Trillo-Lado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[raqueltl@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Roberto Yus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ryus@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/037]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Aproximación a la búsqueda basada en términos sobre conjuntos de datos medioambientales</title>
		<link>https://biblioteca.sistedes.es/articulo/aproximacion-a-la-busqueda-basada-en-terminos-sobre-conjuntos-de-datos-medioambientales/</link>
		<pubDate>Mon, 05 Sep 2016 15:19:11 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1973</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1973</post_id>
		<post_date><![CDATA[2016-09-05 17:19:11]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 15:19:11]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[aproximacion-a-la-busqueda-basada-en-terminos-sobre-conjuntos-de-datos-medioambientales]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1974]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este artículo se discuten los trabajos, actualmente en curso, de diseño e implementación de un sistema de búsqueda por términos sobre fuentes de datos medioambientales, entre las que se incluyen fuentes de entidades geográficas y arrays que almacenan la variación espacio-temporal de distintas variables geo-físicas. Este tipo de sistemas facilitan el descubrimiento y el acceso a fuentes de datos de naturaleza científica a usuarios no expertos, que pueden utilizarlas en aplicaciones de muy diverso tipo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Búsqueda basada en términos, Datos Medioambientales, Recuperación de Información]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Álvarez-Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[david.alvarez.castro@rai.usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José R.R. Viqueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrr.viqueira@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alberto Bugarín]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[alberto.bugarin.diz@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/033]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Federated Approach for Array and Entity Environmental Linked Data</title>
		<link>https://biblioteca.sistedes.es/articulo/a-federated-approach-for-array-and-entity-environmental-linked-data/</link>
		<pubDate>Mon, 05 Sep 2016 15:24:54 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1976</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1976</post_id>
		<post_date><![CDATA[2016-09-05 17:24:54]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 15:24:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-federated-approach-for-array-and-entity-environmental-linked-data]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1977]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Available environmental and spatial data is increasing in size and every time new application domains take advantage of this fact. The need for accessing them through linked data paradigm is also increased, due to the interest of their combination with already available linked data repositories. Entity based environmental data fits perfectly to the graph data model of RDF, however, much environmental data are array-based, and such data are clearly not efficiently represented with RDF. In fact, transforming array environmental data to RDF triples in some datasets will generate huge RDF datasets. Querying these datasets through SPARQL will lead to low performance solutions. In this paper, we propose a federated architecture that integrates entity and array-based repositories into a single SPARQL-based framework, where SPARQL queries are translated into SQL and array-based queries. New operations will be added to SPARQL algebra in order to embed those relational and array-based queries into SPARQL query plans. This will make SPARQL able to access two different database paradigms (entity and array) in one query to answer questions like “What is the predicted average of temperature of each municipality of Spain for the next week?”]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Linked Data, Geospatial and environmental data, GeoSPARQL, SPARQL Query Processing]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Shahed Bassam Almobydeen]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CITIUS). Universidade de Santiago de Compostela ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[shahed.almobydeen@rai.usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José R.R. Viqueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CITIUS). Universidade de Santiago de Compostela ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrr.viqueira@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Lama Penín]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CITIUS). Universidade de Santiago de Compostela ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuel.lama@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/034]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Procesamiento paralelo de datos medioambientales con Apache Spark</title>
		<link>https://biblioteca.sistedes.es/articulo/procesamiento-paralelo-de-datos-medioambientales-con-apache-spark/</link>
		<pubDate>Mon, 05 Sep 2016 15:30:10 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1979</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1979</post_id>
		<post_date><![CDATA[2016-09-05 17:30:10]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 15:30:10]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[procesamiento-paralelo-de-datos-medioambientales-con-apache-spark]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En la actualidad existen enormes volúmenes de datos de tipo medioambiental que son resultado o bien de campañas de recolección de datos de campo en las que se involucran muchos expertos o bien del procesamiento de datos generados por dispositivos de sensorización. En general, los primeros se modelan y gestionan con tecnologías de bases de datos, mientras que los segundos pueden requerir de formatos de array de tipo científico más específicos. El procesamiento declarativo de cualquiera de los tipos de datos está resuelto, con tecnologías de almacenes de datos tradicionales o con bases de datos de arrays. Sin embargo el procesamiento declarativo integrado de ambos tipos de dato todavía demanda soluciones ad-hoc. En este artículo se proporciona una descripción breve de los primeros pasos hacia la implementación de un sistema de procesamiento paralelo integrado de datos relacionales y de arrrays.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Big Data, Environmental Data, OLAP, Spark]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Diego Ferrón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnoloxías da Información (CITIUS). Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[diego.ferron@rai.usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sebastián Villarroya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnoloxías da Información (CITIUS). Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sebastian.villarroya@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José R.R. Viqueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnoloxías da Información (CITIUS). Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jrr.viqueira@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Tomás F. Pena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Tecnoloxías da Información (CITIUS). Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[tf.pena@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/035]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Distance Range Queries in SpatialHadoop</title>
		<link>https://biblioteca.sistedes.es/articulo/distance-range-queries-in-spatialhadoop/</link>
		<pubDate>Mon, 05 Sep 2016 16:24:51 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1982</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1982</post_id>
		<post_date><![CDATA[2016-09-05 18:24:51]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 16:24:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[distance-range-queries-in-spatialhadoop]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1983]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Efficient processing of Distance Range Queries (DRQs) is of great importance in spatial databases due to the wide area of applications. This type of spatial query is characterized by a distance range over one or two datasets. The most representative and known DRQs are the eDistance Range Query (eDRQ) and the eDistance Range Join Query (eDRJQ). Given the increasing volume of spatial data, it is difficult to perform a DRQ on a centralized machine efficiently. Moreover, the eDRJQ is an expensive spatial operation, since it can be considered a combination of the eDR and the spatial join queries. For this reason, this paper addresses the problem of computing DRQs on big spatial datasets in SpatialHadoop, an extension of Hadoop that supports spatial operations efficiently, and proposes new algorithms in SpatialHadoop to perform efficient parallel DRQs on large-scale spatial datasets. We have evaluated the performance of the proposed algorithms in several situations with big synthetic and real-world datasets. The experiments have demonstrated the efficiency (in terms of total execution time and number of distance computations) and scalability (in terms of epsilon values, sizes of datasets and number of computing nodes) of our proposal.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Distance Range Queries, Distance Join, Spatial Data, Processing SpatialHadoop, MapReduce]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Corral	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dept. of Informatics, University of Almeria, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[acorral@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francisco	 García-García		]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dept. of Informatics, University of Almeria, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[paco.garcia@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Luis	Iribarne	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dept. of Informatics, University of Almeria, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[liribarn@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Michael Vassilakopoulos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dept. of Electrical and Computer Engineering, University of Thessaly, Volos, Greece]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mvasilako@uth.gr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/031]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Providing Support for the Optimized Management of Declarative Processes</title>
		<link>https://biblioteca.sistedes.es/articulo/providing-support-for-the-optimized-management-of-declarative-processes/</link>
		<pubDate>Mon, 05 Sep 2016 16:49:08 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1985</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1985</post_id>
		<post_date><![CDATA[2016-09-05 18:49:08]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 16:49:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[providing-support-for-the-optimized-management-of-declarative-processes]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1986]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Declarative process models are becoming increasingly popular due to the high flexibility they offer to process participants. Based on a declarative process model, there exist numerous possible enactment plans, each one with specific values for relevant objective functions (e.g., overall completion time). How to actually execute such a model is quite challenging due to several reasons: (1) proper objective functions must be considered to find optimized enactment plans, (2) users often do not have an understanding of the overall process, (3) the presence of a variety of temporal constraints to be met during process enactment, and (4) the need to coordinate multiple instances of a process concurrently exe- cuted (which compete for shared resources). This is further complicated by the fact that the enactment of new process instances may continuously start over time and many organizations do not exactly know their future demands. In such con- text, to properly support users in enacting declarative process models, this paper suggests generating optimized enactment plans from declarative process models. The generated enactment plans may be used for different purposes, e.g., to pro- vide personal schedules to users. Moreover, they may be dynamically adapted if required. To evaluate the applicability of our approach in practical settings we apply it to a real process scenario from the healthcare domain. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Process flexibility, declarative process model, temporal constraints, constraint programming, scheduling, healthcare processes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Irene Barba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[irenebr@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Andreas Lanz ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Institute of Databases and Information Systems, Ulm University, Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[andreas.lanz@uni-ulm.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Andrés Jiménez Ramírez	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ajramirez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Barbara Weber]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science, University of Innsbruck, Austria, Technical University of Denmark, Denmark]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[bweb@dtu.dk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Manfred	Reichert]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Institute of Databases and Information Systems, Ulm University, Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[manfred.reichert@uni-ulm.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Carmelo Del Valle	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[carmelo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/044]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Prueba de Mutación Evolutiva Aplicada a Sistemas Orientados a Objetos</title>
		<link>https://biblioteca.sistedes.es/articulo/prueba-de-mutacion-evolutiva-aplicada-a-sistemas-orientados-a-objetos/</link>
		<pubDate>Mon, 05 Sep 2016 17:00:06 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1988</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1988</post_id>
		<post_date><![CDATA[2016-09-05 19:00:06]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 17:00:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[prueba-de-mutacion-evolutiva-aplicada-a-sistemas-orientados-a-objetos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1989]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A pesar del beneficio que puede reportar la prueba de mutaciones en el proceso de prueba de software, el coste que supone su aplicación siempre ha sido visto como un obstáculo para una mayor acogida por parte de la industria. Por esta razón se han desarrollado diversas técnicas que tratan de paliar el problema, principalmente mediante la reducción del número de mutantes que son generados. Entre ellas se encuentra la Prueba de Mutación Evolutiva, que propone el empleo de algoritmos evolutivos para encontrar un subconjunto de mutantes que presenta mayor posibilidad de ayudar a refinar el conjunto de casos de prueba empleado. La técnica solo había sido probada con éxito en operadores para el lenguaje de programación WS-BPEL. En este artículo se presentan los experimentos llevados a cabo aplicando la Prueba de Mutación Evolutiva con mutantes generados por operadores de mutación para C++ relacionados con la orientación a objetos. Los resultados obtenidos, usando los parámetros considerados como más apropiados para la configuración del algoritmo, revelan que la técnica también es más efectiva que una estrategia aleatoria con operadores de clase para sistemas en C++.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Prueba de software, Prueba de mutaciones, Algoritmos evolutivos, C++, Orientación a objetos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Delgado-Pérez	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pedro.delgado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sergio Segura	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Garcia-Dominguez	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science, University of York, United Kingdom]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[antonio.garcia-dominguez@york.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Juan José	Domínguez-Jiménez	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[juanjose.dominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/038]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Flujo de trabajo para la experimentación colaborativa en Ingeniería del Software guiada por búsqueda</title>
		<link>https://biblioteca.sistedes.es/articulo/flujo-de-trabajo-para-la-experimentacion-colaborativa-en-ingenieria-del-software-guiada-por-busqueda/</link>
		<pubDate>Mon, 05 Sep 2016 17:59:21 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1991</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1991</post_id>
		<post_date><![CDATA[2016-09-05 19:59:21]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 17:59:21]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[flujo-de-trabajo-para-la-experimentacion-colaborativa-en-ingenieria-del-software-guiada-por-busqueda]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Isabel María del Águila]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad of Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[imaguila@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José del Sagrado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad of Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jsagrado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alfonso Bosch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad of Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[abosch@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/039]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2330]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La Ingeniería del Software Guiada por Búsqueda persigue reformular problemas de Ingeniería del Software que a menudo comprenden objetivos en conﬂicto, como problemas de optimización. Así, las técnicas que se aplican en esta disciplina buscan una o un conjunto de soluciones casi-óptimas en un espacio de soluciones candidatas con la ayuda de una función de aptitud que les permita distinguir las mejores soluciones. La naturaleza estocástica de los algoritmos de optimización requiere de la repetición de las búsquedas para mitigar los efectos de la aleatoriedad. A la hora de comparar algoritmos, el investigador comparará los resultados con mejor calidad (mejores valores en la función de aptitud, en indicadores de calidad y rendimiento) devueltos en las búsquedas, lo que conlleva un trabajo adicional por parte del investigador. La sobrecarga que implica esta actividad puede aminorarse si la experimentación se enfoca de manera colaborativa. Este artículo propone un ﬂujo de trabajo para la experimentación colaborativa basado en resultados e indicadores de calidad y rendimiento.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[metaheurísticas, experimentación cooperativa, indicadores de calidad]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Configuración guiada por búsqueda de aplicaciones basadas en micro-servicios</title>
		<link>https://biblioteca.sistedes.es/articulo/configuracion-guiada-por-busqueda-de-aplicaciones-basadas-en-micro-servicios/</link>
		<pubDate>Mon, 05 Sep 2016 18:14:49 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1993</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1993</post_id>
		<post_date><![CDATA[2016-09-05 20:14:49]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 18:14:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[configuracion-guiada-por-busqueda-de-aplicaciones-basadas-en-micro-servicios]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1994]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Organizaciones como Netflix, Google o Amazon hacen uso de arquitecturas basadas en micro-servicios, lo que ha disparado el interés de la comunidad en ingeniería del software por este estilo arquitectónico, en el que los distintos módulos de la aplicación se implementan como servicios web RESTful independientes. De esta forma, se alcanza un nivel de modularidad que facilita el control del re-despliegue en únicamente aquellas partes que soportan mayor carga de trabajo y, consecuentemente, evitan el uso indiscriminado de la infraestructura. Todos estos servicios, además, se coordinan e invocan orquestando las interacciones necesarias para satisfacer los requisitos del sistema. No obstante, el buen uso de este estilo arquitectónico supone nuevos retos, como determinar qué instancias de servicios se despliegan o establecer la mejor configuración de la nube que los aloja, conforme a la carga esperada y para cumplir los Acuerdos de Nivel de Servicio. Se trata de un problema de optimización en el que deben considerarse simultáneamente múltiples propiedades, a menudo en conflicto entre sí. Por ello, tras formular este caso como un problema de búsqueda, se discutirá cómo el uso de técnicas multi-objetivo puede mejorar las soluciones actuales, permitiéndonos escoger los proveedores y configuraciones apropiadas para dismuir los costes de explotación, asegurar la disponibilidad de los servicios críticos, sin empobrecer la latencia y el tiempo de respuesta.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[micro-services, optimización multi-objetivo, cloud computing, Acuerdos de Nivel de Servicio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Antonio Parejo Maestre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[japarejo@us.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Aurora Ramírez	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico, Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[aramirez@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José Raúl	Romero	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico, Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Sergio Segura	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/045]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Minimización de conjuntos de casos de prueba en la prueba de mutaciones de composiciones BPEL</title>
		<link>https://biblioteca.sistedes.es/articulo/minimizacion-de-conjuntos-de-casos-de-prueba-en-la-prueba-de-mutaciones-de-composiciones-bpel/</link>
		<pubDate>Mon, 05 Sep 2016 18:19:03 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1996</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1996</post_id>
		<post_date><![CDATA[2016-09-05 20:19:03]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 18:19:03]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[minimizacion-de-conjuntos-de-casos-de-prueba-en-la-prueba-de-mutaciones-de-composiciones-bpel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[1997]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Tanto en la aplicación de prueba de mutaciones a composiciones BPEL como en la realización de estudios experimentales sobre diversas métricas de calidad, surge la necesidad de minimizar conjuntos de casos de prueba manteniendo la máxima cobertura de mutación. La prueba de este tipo de software presenta algunas peculiaridades. Normalmente, las composiciones son relativamente pequeñas cuando se comparan con aplicaciones desarrolladas en lenguajes
tradicionales, pues se encargan exclusivamente de la orquestación de los servicios, y no se dispone de un gran número de casos de prueba para ellas. No obstante, su ejecución puede resultar muy costosa, y debe realizarse para un número de mutantes que, normalmente, supera ampliamente al de casos de prueba. Proponemos aquí como técnica de minimización una reducción a programación lineal entera y evaluamos su rendimiento para distintas
composiciones.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Minimización de conjuntos de casos de prueba, Programación lineal entera, Prueba de mutaciones, Composiciones BPEL]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco	Palomo-Lozano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[francisco.palomo@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonia Estero-Botaro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[antonia.estero@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/046]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un algoritmo híbrido para el problema NRP con interdependencias</title>
		<link>https://biblioteca.sistedes.es/articulo/un-algoritmo-hibrido-para-el-problema-nrp-con-interdependencias/</link>
		<pubDate>Mon, 05 Sep 2016 18:23:31 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=1999</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>1999</post_id>
		<post_date><![CDATA[2016-09-05 20:23:31]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 18:23:31]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-algoritmo-hibrido-para-el-problema-nrp-con-interdependencias]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2000]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este artículo presentamos un algoritmo híbrido para una variante del problema de la siguiente versión (NRP). En esta variante existe un conjunto de requisitos para los que se dispone de una estimación del esfuerzo necesario para su implementación y de la satisfacción
percibida por los potenciales clientes con la inclusión de dichos requisitos. Entre estos requisitos existen relaciones de interdependencia, que establecen a ciertos requisitos como prerequisitos de otros, o que obligan a implementar determinados requisitos simultáneamente en caso
de incluirse alguno de ellos en la siguiente versión del producto a desarrollar. Dado un límite superior de esfuerzo prefijado, el objetivo es seleccionar un subconjunto de requisitos que cumpla todas las restricciones y maximice la satisfacción global de los clientes. La propuesta combina heurísticas con técnicas exactas para una versión simplificada del problema. El rendimiento del algoritmo resultante en distintos escenarios realistas se compara con el de otras técnicas metaheurísticas previamente empleadas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Técnicas metaheurísticas, Ingeniería de requisitos, Problema de la siguiente versión, Interdependencias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco	 Palomo-Lozano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[francisco.palomo@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Isabel María del Águila]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[imaguila@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/040]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Dos estrategias de búsqueda anytime basadas en programación lineal entera para resolver el problema de selección de requisitos</title>
		<link>https://biblioteca.sistedes.es/articulo/dos-estrategias-de-busqueda-anytime-basadas-en-programacion-lineal-entera-para-resolver-el-problema-de-seleccion-de-requisitos/</link>
		<pubDate>Mon, 05 Sep 2016 18:29:40 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2002</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2002</post_id>
		<post_date><![CDATA[2016-09-05 20:29:40]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 18:29:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[dos-estrategias-de-busqueda-anytime-basadas-en-programacion-lineal-entera-para-resolver-el-problema-de-seleccion-de-requisitos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2003]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El problema de selección de requisitos (o Next Release Problem, NRP) consiste en seleccionar el subconjunto de requisitos que se va a desarrollar en la siguiente versión de una aplicación software. Esta selección se debe hacer de tal forma que maximice la satisfacción de las partes interesadas a la vez que se minimiza el esfuerzo empleado en el desarrollo y se cumplen un conjunto de restricciones. Trabajos recientes han abordado la formulación bi-objetivo de este problema usando técnicas exactas basadas en resolutores SAT y resolutores de programación lineal entera. Ambos se enfrentan a dificultades cuando las instancias tienen un gran tamaño, sin embargo la programación lineal entera (ILP) parece ser más efectiva que los resolutores SAT. En la práctica, no es necesario calcular todas las soluciones del frente de Pareto (que pueden llegar a ser muchas) y basta con obtener un buen número de soluciones eficientes bien distribuidas en el espacio objetivo. Las estrategias de búsqueda basadas en ILP que se han utilizado en el pasado para encontrar un frente bien distribuido en cualquier instante de tiempo solo buscan soluciones soportadas. En este trabajo proponemos dos estrategias basadas en ILP que son capaces de encontrar el frente completo con suficiente tiempo y que, además, tienen la propiedad de aportar un conjunto de soluciones bien distribuido en el frente objetivo en cualquier momento de la búsqueda.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[problema de selección de requisitos, programación lineal entera, optimización multi-objetivo, optimización combinatoria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco  Chicano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Andalucía Tech]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[chicano@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miguel Ángel	Domínguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Andalucía Tech]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[miguel.angel.dominguez.rios@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Isabel María del Águila	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[imaguila@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José	Del Sagrado	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jsagrado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Enrique Alba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Andalucía Tech]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[eat@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/041]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Aplicando programación lineal entera a la búsqueda de conjuntos de productos de prueba priorizados para líneas de productos software</title>
		<link>https://biblioteca.sistedes.es/articulo/aplicando-programacion-lineal-entera-a-la-busqueda-de-conjuntos-de-productos-de-prueba-priorizados-para-lineas-de-productos-software/</link>
		<pubDate>Mon, 05 Sep 2016 18:34:37 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2005</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2005</post_id>
		<post_date><![CDATA[2016-09-05 20:34:37]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 18:34:37]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[aplicando-programacion-lineal-entera-a-la-busqueda-de-conjuntos-de-productos-de-prueba-priorizados-para-lineas-de-productos-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2006]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las líneas de productos software son familias de productos que están íntimamente relacionados entre sí, normalmente formados por combinaciones de un conjunto de características software. Generalmente no es factible testar todos los productos de la familia, ya que el número de productos es muy elevado debido a la explosión combinatoria de características. Por este motivo, se han propuesto criterios de cobertura que pretenden probar al menos todas las interacciones entre características sin necesidad de probar todos los productos, por ejemplo todos los pares de características (emph{pairwise coverage}). Además, es deseable testar primero los productos compuestos por un conjunto de características prioritarias. Este problema es conocido como emph{Prioritized Pairwise Test Data Generation}. En este trabajo proponemos una técnica basada en programación lineal entera para generar este conjunto de pruebas priorizado. Nuestro estudio revela que la propuesta basada en programación lineal entera consigue mejores resultados estadísticamente tanto en calidad como en tiempo de computación con respecto a las técnicas existentes para este problema.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Líneas de productos software, Pruebas de software, Programación lineal entera, Optimización multi-objetivo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Ferrer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ferrer@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francisco	 Chicano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[chicano@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Roberto Erick Lopez-Herrejon]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Systems Engineering and Automation, Johannes Kepler University, Linz, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[roberto.lopezherrejon@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Enrique Alba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[eat@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/042]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Estudio de mecanismos de hibridación para el descubrimiento evolutivo de arquitecturas</title>
		<link>https://biblioteca.sistedes.es/articulo/estudio-de-mecanismos-de-hibridacion-para-el-descubrimiento-evolutivo-de-arquitecturas/</link>
		<pubDate>Mon, 05 Sep 2016 18:41:27 +0000</pubDate>
		<creator><![CDATA[jgarcia]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2008</guid>
		<description></description>
		<content><![CDATA[]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2008</post_id>
		<post_date><![CDATA[2016-09-05 20:41:27]]></post_date>
		<post_date_gmt><![CDATA[2016-09-05 18:41:27]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[estudio-de-mecanismos-de-hibridacion-para-el-descubrimiento-evolutivo-de-arquitecturas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-jgarcia"><![CDATA[jgarcia]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2009]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las decisiones que los ingenieros software toman durante el análisis arquitectónico pueden verse influenciadas por aspectos como la naturaleza del sistema bajo estudio o los criterios de calidad que deben guiar su desarrollo, generalmente expresados en términos de métricas software. A la hora de abordar tareas de diseño arquitectónico como problemas de optimización, factores como los anteriores también deben ser tenidos en cuenta, ya que podrían afectar al funcionamiento de cualquier algoritmo de búsqueda. Incluir técnicas de búsqueda local en un algoritmo evolutivo constituye un mecanismo habitual para intentar mejorar su rendimiento, si bien diseñar un modelo híbrido añade nuevas variables a ser estudiadas. En este trabajo se analiza la idoneidad de este tipo de enfoque para la resolución del problema del descubrimiento de arquitecturas software. El estudio experimental realizado muestra que las características del problema pueden influir tanto en la eficiencia de la búsqueda local como en la calidad de las soluciones obtenidas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Ingeniería del software basada en búsqueda, Arquitecturas software, Algoritmos evolutivos, Búsqueda local]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aurora Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico. Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aramirez@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Antonio Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico. Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[i12momej@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José Raúl	Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico. Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Sebastián Ventura	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. de Informática y Análisis Numérico. Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sventura@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2016/043]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>BPMS-Game: Herramienta para la Gamificación de Procesos de Negocio</title>
		<link>https://biblioteca.sistedes.es/articulo/bpms-game-herramienta-para-la-gamificacion-de-procesos-de-negocio/</link>
		<pubDate>Tue, 06 Sep 2016 11:58:39 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2015</guid>
		<description></description>
		<content><![CDATA[En los últimos años, el paradigma BPM está teniendo una repercusión significativa en las organizaciones a la hora de dar soporte a la mejora continua de sus procesos de negocio. Uno de los aspectos que puede promover un mejor desempeño de dichos procesos es el factor humano, por lo que es de gran importancia mejorar la motivación de los usuarios para la realización de las tareas que tienen encomendadas. En este contexto, resulta de interés el área de “Gamificación”, que está muy presente en muchos aspectos la sociedad actual, con el objetivo de mejorar la participación y el compromiso de un usuario para la realización de sus tareas aplicando mecanismos de juegos. La gamificación puede ser por tanto un mecanismo adecuado para su aplicación en los procesos de las organizaciones para mejorar la motivación y el rendimiento de los usuarios involucrados. Por todo ello, en el presente artículo se describe la herramienta BPMS-Game, que da soporte a la aplicación de gamificación en sistemas BPMS. La utilidad potencial de la herramienta se ilustra con un caso de ejemplo.]]></content>
		<excerpt><![CDATA[Procesos de Negocio, Gamificación, BPMS]]></excerpt>
		<post_id>2015</post_id>
		<post_date><![CDATA[2016-09-06 13:58:39]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 11:58:39]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[bpms-game-herramienta-para-la-gamificacion-de-procesos-de-negocio]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="bpms"><![CDATA[BPMS]]></category>
		<category domain="post_tag" nicename="gamificacion"><![CDATA[gamificación]]></category>
		<category domain="post_tag" nicename="procesos-de-negocio"><![CDATA[Procesos de Negocio]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2025]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años, el paradigma BPM está teniendo una repercusión significativa en las organizaciones a la hora de dar soporte a la mejora continua de sus procesos de negocio. Uno de los aspectos que puede promover un mejor desempeño de dichos procesos es el factor humano, por lo que es de gran importancia mejorar la motivación de los usuarios para la realización de las tareas que tienen encomendadas. En este contexto, resulta de interés el área de “Gamificación”, que está muy presente en muchos aspectos la sociedad actual, con el objetivo de mejorar la participación y el compromiso de un usuario para la realización de sus tareas aplicando mecanismos de juegos. La gamificación puede ser por tanto un mecanismo adecuado para su aplicación en los procesos de las organizaciones para mejorar la motivación y el rendimiento de los usuarios involucrados. Por todo ello, en el presente artículo se describe la herramienta BPMS-Game, que da soporte a la aplicación de gamificación en sistemas BPMS. La utilidad potencial de la herramienta se ilustra con un caso de ejemplo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Procesos de Negocio, Gamificación, BPMS]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Mancebo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla la Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[javier.mancbo@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Félix García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla la Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[felix.garcia@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/027]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Servitización: Un estudio de Técnicas de Modelado de Negocio</title>
		<link>https://biblioteca.sistedes.es/articulo/servitizacion-un-estudio-de-tecnicas-de-modelado-de-negocio/</link>
		<pubDate>Tue, 06 Sep 2016 12:12:12 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2048</guid>
		<description></description>
		<content><![CDATA[El concepto de servitización se puede resumir en la idea de ofrecer servicios en combinación con productos con el objetivo de mejorar la oferta de valor al cliente. Para afrontar exitosamente un proceso de servitización, las empresas necesitan rediseñar su modelo de negocio. Definir el modelo de negocio implica un proceso de innovación y la conceptualización de la idea de negocio de una organización. El objetivo de este trabajo es analizar brevemente el proceso de servitización en la literatura y presentar un estudio sobre las técnicas y metodologías para el modelado de negocio que pueden ayudar en este proceso.]]></content>
		<excerpt><![CDATA[Servitización, Servicios, Modelo de Negocio]]></excerpt>
		<post_id>2048</post_id>
		<post_date><![CDATA[2016-09-06 14:12:12]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 12:12:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[servitizacion-un-estudio-de-tecnicas-de-modelado-de-negocio]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="modelo-de-negocio"><![CDATA[Modelo de Negocio]]></category>
		<category domain="post_tag" nicename="servicios"><![CDATA[Servicios]]></category>
		<category domain="post_tag" nicename="servitizacion"><![CDATA[Servitización]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El concepto de servitización se puede resumir en la idea de ofrecer servicios en combinación con productos con el objetivo de mejorar la oferta de valor al cliente. Para afrontar exitosamente un proceso de servitización, las empresas necesitan rediseñar su modelo de negocio. Definir el modelo de negocio implica un proceso de innovación y la conceptualización de la idea de negocio de una organización. El objetivo de este trabajo es analizar brevemente el proceso de servitización en la literatura y presentar un estudio sobre las técnicas y metodologías para el modelado de negocio que pueden ayudar en este proceso.
]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Servitización, Servicios, Modelo de Negocio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Valeria de Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[valeria.decastro@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan M. Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Eloísa Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[eloisa.diaz@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[María Luz Martín]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[luz.martin@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2055]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/002]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automatización de la etapa de análisis para la aplicación de la técnica de prueba metamórfica a composiciones de servicios WS-BPEL</title>
		<link>https://biblioteca.sistedes.es/articulo/automatizacion-de-la-etapa-de-analisis-para-la-aplicacion-de-la-tecnica-de-prueba-metamorfica-a-composiciones-de-servicios-ws-bpel/</link>
		<pubDate>Tue, 06 Sep 2016 12:39:31 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2057</guid>
		<description></description>
		<content><![CDATA[La importancia de los servicios web en el mundo actual está en auge, y el impacto social que están teniendo gracias a las nuevas tecnologías desarrolladas, hace necesario el diseño de mejores técnicas de prueba para el software específico de composición de estos servicios web. Una de las técnicas propuestas para las composiciones WS-BPEL es la técnica de prueba metamórfica. En trabajos anteriores se ha presentado una arquitectura para su aplicación y se han aportado algunas ideas para la automatización de la etapa inicial de la misma, que se corresponde con el análisis y obtención de propiedades, pero no se llegaron a desarrollar ni implementar. En este trabajo se presenta el diseño de una solución para automatizar ciertos aspectos de la etapa de análisis y obtención de propiedades, la cual ha sido probada en diferentes casos de prueba obteniéndose buenos resultados.]]></content>
		<excerpt><![CDATA[pruebas metamórficas, relaciones metamórficas, WS-BPEL, composiciones de servicios web, solución, análisis]]></excerpt>
		<post_id>2057</post_id>
		<post_date><![CDATA[2016-09-06 14:39:31]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 12:39:31]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automatizacion-de-la-etapa-de-analisis-para-la-aplicacion-de-la-tecnica-de-prueba-metamorfica-a-composiciones-de-servicios-ws-bpel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="analisis"><![CDATA[análisis]]></category>
		<category domain="post_tag" nicename="composiciones-de-servicios-web"><![CDATA[composiciones de servicios web]]></category>
		<category domain="post_tag" nicename="pruebas-metamorficas"><![CDATA[pruebas metamórficas]]></category>
		<category domain="post_tag" nicename="relaciones-metamorficas"><![CDATA[relaciones metamórficas]]></category>
		<category domain="post_tag" nicename="solucion"><![CDATA[solución]]></category>
		<category domain="post_tag" nicename="ws-bpel"><![CDATA[WS-BPEL]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2058]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La importancia de los servicios web en el mundo actual está en auge, y el impacto social que están teniendo gracias a las nuevas tecnologías desarrolladas, hace necesario el diseño de mejores técnicas de prueba para el software específico de composición de estos servicios web. Una de las técnicas propuestas para las composiciones WS-BPEL es la técnica de prueba metamórfica. En trabajos anteriores se ha presentado una arquitectura para su aplicación y se han aportado algunas ideas para la automatización de la etapa inicial de la misma, que se corresponde con el análisis y obtención de propiedades, pero no se llegaron a desarrollar ni implementar. En este trabajo se presenta el diseño de una solución para automatizar ciertos aspectos de la etapa de análisis y obtención de propiedades, la cual ha sido probada en diferentes casos de prueba obteniéndose buenos resultados.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[pruebas metamórficas, relaciones metamórficas, WS-BPEL, composiciones de servicios web, solución, análisis]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[M Carmen de Castro-Cabrera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[maricarmen.decastro@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Kevin J Valle-Gómez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[kevin.vallegomez@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/008]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Defining PPIs for Process Variants based on Change Patterns</title>
		<link>https://biblioteca.sistedes.es/articulo/defining-ppis-for-process-variants-based-on-change-patterns/</link>
		<pubDate>Tue, 06 Sep 2016 12:46:30 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2060</guid>
		<description></description>
		<content><![CDATA[Business Process (BP) families are made up of BP variants that share commonalities but also show differences to accommodate the specific necessities of different application contexts (i.e., country regulations, industrial domain, etc.). Even though there are modelling techniques to represent these families (e.g., C-EPC, Provop), there is no work aimed at the performance measurement of the different BP variants that conform the family. Process Performance Indicators (PPI) are commonly used to study and analyse the performance of business processes. However, the application of such indicators in BP families increases the modelling and management complexity of the whole family. To deal with this complexity, this work introduces a modelling solution for managing PPI variability based on the concepts of change patterns for process families (CP4PF). The proposed solution includes a set of patterns aimed at 1) reducing the number of operations required to specify PPIs and 2) ensuring PPI family correctness.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2060</post_id>
		<post_date><![CDATA[2016-09-06 14:46:30]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 12:46:30]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[defining-ppis-for-process-variants-based-on-change-patterns]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2061]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Bedilia Estrada-Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Victoria Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Métodos de Producción de Software, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Adela del-Río-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Métodos de Producción de Software, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Business Process (BP) families are made up of BP variants that share commonalities but also show differences to accommodate the specific necessities of different application contexts (i.e., country regulations, industrial domain, etc.). Even though there are modelling techniques to represent these families (e.g., C-EPC, Provop), there is no work aimed at the performance measurement of the different BP variants that conform the family. Process Performance Indicators (PPI) are commonly used to study and analyse the performance of business processes. However, the application of such indicators in BP families increases the modelling and management complexity of the whole family. To deal with this complexity, this work introduces a modelling solution for managing PPI variability based on the concepts of change patterns for process families (CP4PF). The proposed solution includes a set of patterns aimed at 1) reducing the number of operations required to specify PPIs and 2) ensuring PPI family correctness.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/018]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Incertidumbre de Datos en el Modelado de Procesos de Negocio</title>
		<link>https://biblioteca.sistedes.es/articulo/incertidumbre-de-datos-en-el-modelado-de-procesos-de-negocio/</link>
		<pubDate>Tue, 06 Sep 2016 12:55:32 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2066</guid>
		<description></description>
		<content><![CDATA[Este artículo describe nuestro trabajo en curso sobre el modelado de procesos de negocio teniendo en cuenta la incertidumbre de los datos. Esto es un aspecto esencial para modelar con mayor precisión y fidelidad procesos industriales en donde ciertos parámetros –como la duración de las tareas o el coste de algunos recursos– no pueden determinarse con exactitud, pero son necesarios tenerlos en cuenta a la hora de analizar los sistemas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2066</post_id>
		<post_date><![CDATA[2016-09-06 14:55:32]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 12:55:32]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[incertidumbre-de-datos-en-el-modelado-de-procesos-de-negocio]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2067]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo describe nuestro trabajo en curso sobre el modelado de procesos de negocio teniendo en cuenta la incertidumbre de los datos. Esto es un aspecto esencial para modelar con mayor precisión y fidelidad procesos industriales en donde ciertos parámetros –como la duración de las tareas o el coste de algunos recursos– no pueden determinarse con exactitud, pero son necesarios tenerlos en cuenta a la hora de analizar los sistemas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Priscill Orue]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[priscill.orue@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carmen Morcillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[aixela@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Vallecillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[av@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/019]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automatic Generation of Purchasing Plans for Cloud Services</title>
		<link>https://biblioteca.sistedes.es/articulo/automatic-generation-of-purchasing-plans-for-cloud-services/</link>
		<pubDate>Tue, 06 Sep 2016 13:06:51 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2069</guid>
		<description></description>
		<content><![CDATA[The myriad of cloud service providers, as well as their overwhelming variety of configuration and purchasing options, result in a highly complex purchasing scenario. Furthermore, users may specify their needs for cloud services provisioning with a certain scheduling restrictions. There is a need for an automatic support for obtaining an appropriate purchasing plan, which takes into account both service configurations and scheduling needs, while allowing the comparison among different providers and their various offerings. In this work, we present an automatic purchasing plan generator, which analyzes cloud service offerings from several providers to obtain an optimized purchasing plan according to user needs. From the obtained purchasing plan, our solution can provide the corresponding charge plan, possibly including discounts, which serves the purpose of comparing offerings to get the best option.]]></content>
		<excerpt><![CDATA[Cloud Services, Purchasing Plan, Discounts]]></excerpt>
		<post_id>2069</post_id>
		<post_date><![CDATA[2016-09-06 15:06:51]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 13:06:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automatic-generation-of-purchasing-plans-for-cloud-services]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="cloud-services"><![CDATA[Cloud Services]]></category>
		<category domain="post_tag" nicename="discounts"><![CDATA[Discounts]]></category>
		<category domain="post_tag" nicename="purchasing-plan"><![CDATA[Purchasing Plan]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2070]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The myriad of cloud service providers, as well as their overwhelming variety of configuration and purchasing options, result in a highly complex purchasing scenario. Furthermore, users may specify their needs for cloud services provisioning with a certain scheduling restrictions. There is a need for an automatic support for obtaining an appropriate purchasing plan, which takes into account both service configurations and scheduling needs, while allowing the comparison among different providers and their various offerings. In this work, we present an automatic purchasing plan generator, which analyzes cloud service offerings from several providers to obtain an optimized purchasing plan according to user needs. From the obtained purchasing plan, our solution can provide the corresponding charge plan, possibly including discounts, which serves the purpose of comparing offerings to get the best option.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Cloud Services, Purchasing Plan, Discounts]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Octavio Martín-Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática – Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[omartindiaz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José María García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática – Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[josemgarcia@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática – Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos ETS. Ingeniería Informática – Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/015]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SOA 2.0 para el Control y Alerta de Riesgos para la Salud Derivados de la Calidad del Aire</title>
		<link>https://biblioteca.sistedes.es/articulo/soa-2-0-para-el-control-y-alerta-de-riesgos-para-la-salud-derivados-de-la-calidad-del-aire/</link>
		<pubDate>Tue, 06 Sep 2016 16:13:01 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2091</guid>
		<description></description>
		<content><![CDATA[La calidad del aire es un factor al que se la ha dado gran relevancia en los últimos años dado que puede afectar seriamente a la salud y a la calidad de vida de las personas. En la actualidad carecemos de medios que nos proporcionen información sobre la calidad del aire en tiempo real y de fácil acceso para los ciudadanos; y en especial no hay medios que se puedan particularizar para las condiciones específicas de cada individuo. En este artículo mostramos nuestros avances en la propuesta, implementación y prueba de una arquitectura orientada a servicios y dirigida por eventos que nos permite detectar en tiempo real los cambios en la calidad del aire y ponerlos al alcance de los ciudadanos enviándoles notificaciones y alertas personalizadas en función de sus características personales, previniendo así mayores riesgos para la salud.]]></content>
		<excerpt><![CDATA[Arquitecturas Orientadas a Servicios, Arquitecturas Dirigidas por Eventos, Procesamiento de Eventos Complejos, Bus de Servicios Empresariales, Calidad del Aire]]></excerpt>
		<post_id>2091</post_id>
		<post_date><![CDATA[2016-09-06 18:13:01]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 16:13:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[soa-2-0-para-el-control-y-alerta-de-riesgos-para-la-salud-derivados-de-la-calidad-del-aire]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="arquitecturas-dirigidas-por-eventos"><![CDATA[Arquitecturas Dirigidas por Eventos]]></category>
		<category domain="post_tag" nicename="arquitecturas-orientadas-a-servicios"><![CDATA[arquitecturas orientadas a servicios]]></category>
		<category domain="post_tag" nicename="bus-de-servicios-empresariales"><![CDATA[Bus de Servicios Empresariales]]></category>
		<category domain="post_tag" nicename="calidad-del-aire"><![CDATA[calidad del aire]]></category>
		<category domain="post_tag" nicename="procesamiento-de-eventos-complejos"><![CDATA[procesamiento de eventos complejos]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2092]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La calidad del aire es un factor al que se la ha dado gran relevancia en los últimos años dado que puede afectar seriamente a la salud y a la calidad de vida de las personas. En la actualidad carecemos de medios que nos proporcionen información sobre la calidad del aire en tiempo real y de fácil acceso para los ciudadanos; y en especial no hay medios que se puedan particularizar para las condiciones específicas de cada individuo. En este artículo mostramos nuestros avances en la propuesta, implementación y prueba de una arquitectura orientada a servicios y dirigida por eventos que nos permite detectar en tiempo real los cambios en la calidad del aire y ponerlos al alcance de los ciudadanos enviándoles notificaciones y alertas personalizadas en función de sus características personales, previniendo así mayores riesgos para la salud.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Arquitecturas Orientadas a Servicios, Arquitecturas Dirigidas por Eventos, Procesamiento de Eventos Complejos, Bus de Servicios Empresariales, Calidad del Aire]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alfonso García de Prado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software Escuela Superior de Ingeniería, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alfonso.garciadeprado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software Escuela Superior de Ingeniería, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software Escuela Superior de Ingeniería, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Adolfo R. de Soto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingenierías Mecánica, Informática y Aeroespacial, Universidad de León]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[adolfo.rdesoto@unileon.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/025]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Recompilación de procesos de educación a partir de registros de eventos (resumen)</title>
		<link>https://biblioteca.sistedes.es/articulo/recompilacion-de-procesos-de-educacion-a-partir-de-registros-de-eventos/</link>
		<pubDate>Tue, 06 Sep 2016 16:24:06 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2095</guid>
		<description></description>
		<content><![CDATA[Resumen de artículo publicado como:

Vidal, J.C., Vázquez-Barreiros, B., Lama, M., Mucientes, M.: Recompiling learning processes from event logs.Knowledge-Based Systems 100 (2016) 160-174.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2095</post_id>
		<post_date><![CDATA[2016-09-06 18:24:06]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 16:24:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[recompilacion-de-procesos-de-educacion-a-partir-de-registros-de-eventos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2098]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen de artículo publicado como:

Vidal, J.C., Vázquez-Barreiros, B., Lama, M., Mucientes, M.: Recompiling learning processes from event logs.Knowledge-Based Systems 100 (2016) 160-174.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan C. Vidal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Informacióon (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[juan.vidal@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Borja Vázquez-Barreiros]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Informacióon (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[borja.vazquez@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Lama]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Informacióon (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuel.lama@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel Mucientes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Informacióon (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manuel.mucientes@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/026]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Supporting Compensations with WS-Agreement</title>
		<link>https://biblioteca.sistedes.es/articulo/supporting-compensations-with-ws-agreement/</link>
		<pubDate>Tue, 06 Sep 2016 16:32:48 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2101</guid>
		<description></description>
		<content><![CDATA[During the last years the use of service level agreements (SLA) is rising uncontrollably to describe the rights and obligations of parties involved in service provisioning (typically the service consumer and the service provider); amongst other information, SLA could define guarantees associated with the idea of service level objectives (SLOs) that normally represent key performance indicators of either the consumer or the provider. In case the guarantee is under or over fulfilled SLAs could also define some compensations (i.e. penalties or rewards). In such a context, there have been important steps towards the automation of the analysis of SLAs. One of these steps is a characterization model of SLAs with compensations proposed by the authors in a previous work; and another step is the standardisation effort in the SLAs notation made by WS-Agreement. However, real-world SLAs includes complex concepts that must be considered, namely: (i) SLA terms that specify compensations without an explicit SLO; and (ii) a limit for the compensations. In this paper we extend our prior characterization model considering these complex concepts. Specifically, (i) we provide up to five real-world scenarios whose SLAs incorporate aforementioned new concepts; (ii) we extend our model for compensable guarantees considering terms without an explicit SLO; and (iii) we provide a novel WS-Agreement-based syntax to model SLAs with compensations considering these concepts. These contributions aim to establish a foundation to elaborate tools that could provide an automated support to the modelling and analysis of SLAs with compensations.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2101</post_id>
		<post_date><![CDATA[2016-09-06 18:32:48]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 16:32:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[supporting-compensations-with-ws-agreement]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2102]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[During the last years the use of service level agreements (SLA) is rising uncontrollably to describe the rights and obligations of parties involved in service provisioning (typically the service consumer and the service provider); amongst other information, SLA could define guarantees associated with the idea of service level objectives (SLOs) that normally represent key performance indicators of either the consumer or the provider. In case the guarantee is under or over fulfilled SLAs could also define some compensations (i.e. penalties or rewards). In such a context, there have been important steps towards the automation of the analysis of SLAs. One of these steps is a characterization model of SLAs with compensations proposed by the authors in a previous work; and another step is the standardisation effort in the SLAs notation made by WS-Agreement. However, real-world SLAs includes complex concepts that must be considered, namely: (i) SLA terms that specify compensations without an explicit SLO; and (ii) a limit for the compensations. In this paper we extend our prior characterization model considering these complex concepts. Specifically, (i) we provide up to five real-world scenarios whose SLAs incorporate aforementioned new concepts; (ii) we extend our model for compensable guarantees considering terms without an explicit SLO; and (iii) we provide a novel WS-Agreement-based syntax to model SLAs with compensations considering these concepts. These contributions aim to establish a foundation to elaborate tools that could provide an automated support to the modelling and analysis of SLAs with compensations.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Müller]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Octavio Martín-Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio M. Gutierrez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/023]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Reparación de alineamientos en modelos de proceso similares</title>
		<link>https://biblioteca.sistedes.es/articulo/reparacion-de-alineamientos-en-modelos-de-proceso-similares/</link>
		<pubDate>Tue, 06 Sep 2016 16:41:18 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2104</guid>
		<description></description>
		<content><![CDATA[Una de las ramas más importantes de la minería de procesos es el análisis de conformidad, es decir, analizar hasta qué punto un proceso de negocio se ajusta a los datos de ejecución de los procesos de negocio observados. Los alineamientos son el instrumento estándar de facto dentro de las analíticas de conformidad. Los alineamientos relacionan elementos de un registro de eventos con las actividades presentes en un modelo de proceso. Sin embargo, calcularlos es un problema combinatorio y, por lo tanto, extremadamente costoso. En este artículo mostramos como es posible reparar un alineamiento para un proceso dado, utilizando como punto de partida un modelo y un alineamiento previo. De este modo, demostramos cómo es posible obtener un nuevo alineamiento, en un tiempo significativamente mejor, reparando aquellas partes que ya no se ajustan al comportamiento del nuevo modelo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2104</post_id>
		<post_date><![CDATA[2016-09-06 18:41:18]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 16:41:18]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[reparacion-de-alineamientos-en-modelos-de-proceso-similares]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2105]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Una de las ramas más importantes de la minería de procesos es el análisis de conformidad, es decir, analizar hasta qué punto un proceso de negocio se ajusta a los datos de ejecución de los procesos de negocio observados. Los alineamientos son el instrumento estándar de facto dentro de las analíticas de conformidad. Los alineamientos relacionan elementos de un registro de eventos con las actividades presentes en un modelo de proceso. Sin embargo, calcularlos es un problema combinatorio y, por lo tanto, extremadamente costoso. En este artículo mostramos cómo es posible reparar un alineamiento para un proceso dado, utilizando como punto de partida un modelo y un alineamiento previo. De este modo, demostramos cómo es posible obtener un nuevo alineamiento, en un tiempo significativamente mejor, reparando aquellas partes que ya no se ajustan al comportamiento del nuevo modelo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[B. Vázquez-Barreiros]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[borja.vazquez@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[S.J. van Zelst]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Mathematics and Computer Science, Eindhoven University of Technology]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[s.j.v.zelst@tue.nl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[J.C.A.M. Buijs]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Mathematics and Computer Science Eindhoven, University of Technology]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[j.c.a.m.buijs@tue.nl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[M. Lama]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manuel.lamausc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[M. Mucientes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[manuel.mucientesg@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/017]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>RALph: A Graphical Notation for Resource Assignments in Business Processes (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/ralph-a-graphical-notation-for-resource-assignments-in-business-processes-abstract/</link>
		<pubDate>Tue, 06 Sep 2016 16:50:02 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2108</guid>
		<description></description>
		<content><![CDATA[Resumen de artículo publicado como:

Cristina Cabanillas, David Knuplesch, Manuel Resinas, Manfred Reichert, Jan Mendling, Antonio Ruiz-Cortés: RALph: A Graphical Notation for Resource Assignments in Business Processes. International Conference on Advanced Information Systems Engineering (CAiSE) 2015: 53-68. DOI: 10.1007/978-3-319-19069-3_4.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2108</post_id>
		<post_date><![CDATA[2016-09-06 18:50:02]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 16:50:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[ralph-a-graphical-notation-for-resource-assignments-in-business-processes-abstract]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2109]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen de artículo publicado en:

Cristina Cabanillas, David Knuplesch, Manuel Resinas, Manfred Reichert, Jan Mendling, Antonio Ruiz-Cortés: RALph: A Graphical Notation for Resource Assignments in Business Processes. International Conference on Advanced Information Systems Engineering (CAiSE) 2015: 53-68. DOI: 10.1007/978-3-319-19069-3_4.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cristina Cabanillas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Vienna University of Economics and Business]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cristina.cabanillas@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David Knuplesch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Ulm University]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[david.knuplesch@uni-ulm.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manfred Reichert]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Ulm University]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manfred.reichert@uni-ulm.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Jan Mendling]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Vienna University of Economics and Business]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[jan.mendling@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/029]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Opening up Context-aware Services Compositions to End-Users</title>
		<link>https://biblioteca.sistedes.es/articulo/opening-up-context-aware-services-compositions-to-end-users/</link>
		<pubDate>Tue, 06 Sep 2016 17:01:11 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2111</guid>
		<description></description>
		<content><![CDATA[The interconnected world in which we live opens many possibilities to create, consume, and share knowledge and services. Even though end-users are more than ever prepared in terms of technology (e.g., by using smartphones), their specific context (i.e., personal interests, geographical location, etc.) is not yet properly considered in existing solutions to explore these possibilites. Therefore, we need to provide end-users with tools that allow them to create, consume, and share added value services by using the proper knowledge and services according to their context. In this sense this paper discusses how existing solutions could be integrated to achieve this goal. In particular we explore the possibility of extending EUCalipTool, an end-user mobile tool for service compositions, with the context-aware notification capabilities offered by nimBees.]]></content>
		<excerpt><![CDATA[Service Discovery, Context-aware discovery, End-user Development]]></excerpt>
		<post_id>2111</post_id>
		<post_date><![CDATA[2016-09-06 19:01:11]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 17:01:11]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[opening-up-context-aware-services-compositions-to-end-users]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="context-aware-discovery"><![CDATA[Context-aware discovery]]></category>
		<category domain="post_tag" nicename="end-user-development"><![CDATA[End-user Development]]></category>
		<category domain="post_tag" nicename="service-discovery"><![CDATA[Service Discovery]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2112]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The interconnected world in which we live opens many possibilities to create, consume, and share knowledge and services. Even though end-users are more than ever prepared in terms of technology (e.g., by using smartphones), their specific context (i.e., personal interests, geographical location, etc.) is not yet properly considered in existing solutions to explore these possibilites. Therefore, we need to provide end-users with tools that allow them to create, consume, and share added value services by using the proper knowledge and services according to their context. In this sense this paper discusses how existing solutions could be integrated to achieve this goal. In particular we explore the possibility of extending EUCalipTool, an end-user mobile tool for service compositions, with the context-aware notification capabilities offered by nimBees.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Service Discovery, Context-aware discovery, End-user Development]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ignacio Mansanet]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València, Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[imansanet@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Victoria Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València, Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[vtorres@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pedro Valderas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València, Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pvalderas@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[José Manuel García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/009]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Construyendo Perfiles Virtuales Mediante el Procesamiento de Eventos Complejos</title>
		<link>https://biblioteca.sistedes.es/articulo/construyendo-perfiles-virtuales-mediante-el-procesamiento-de-eventos-complejos/</link>
		<pubDate>Tue, 06 Sep 2016 17:13:14 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2115</guid>
		<description></description>
		<content><![CDATA[A medida que se incrementa el número de dispositivos inteligentes, el esfuerzo requerido para adaptarlos a las necesidades de cada usuario también crece. Asimismo, el proceso de adaptación de un dispositivo al contexto de un usuario es todavía un proceso muy manual. A pesar de que en los últimos años han surgido algunas propuestas centradas en obtener la informacióon contextual de los usuarios para crear sus perfiles virtuales, se necesitan soluciones novedosas que permitan crear perfiles más completos, que sean utilizados por los dispositivos inteligentes para adaptarse automáticamente a las necesidades de sus usuarios, redundando en una mayor exactitud de la adaptación. En este artículo se propone la integración del modelo computacional People as a Service (PeaaS) con el procesamiento de eventos complejos (CEP) para la creación en tiempo real de perfiles virtuales complejos desde el propio dispositivo móvil y la compartición de estos como servicios para el resto de sistemas y dispositivos. Además, se evalúa esta integración en un caso de estudio sobre Alzheimer. Los resultados confirman que el uso de la tecnología CEP para la identificación de información contextual compleja es posible.]]></content>
		<excerpt><![CDATA[Información Contextual, CEP, PeaaS, Asper, MDD]]></excerpt>
		<post_id>2115</post_id>
		<post_date><![CDATA[2016-09-06 19:13:14]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 17:13:14]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[construyendo-perfiles-virtuales-mediante-el-procesamiento-de-eventos-complejos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="asper"><![CDATA[Asper]]></category>
		<category domain="post_tag" nicename="cep"><![CDATA[CEP]]></category>
		<category domain="post_tag" nicename="informacion-contextual"><![CDATA[Información Contextual]]></category>
		<category domain="post_tag" nicename="mdd"><![CDATA[MDD]]></category>
		<category domain="post_tag" nicename="peaas"><![CDATA[PeaaS]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2116]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A medida que se incrementa el número de dispositivos inteligentes, el esfuerzo requerido para adaptarlos a las necesidades de cada usuario también crece. Asimismo, el proceso de adaptación de un dispositivo al contexto de un usuario es todavía un proceso muy manual. A pesar de que en los últimos años han surgido algunas propuestas centradas en obtener la informacióon contextual de los usuarios para crear sus perfiles virtuales, se necesitan soluciones novedosas que permitan crear perfiles más completos, que sean utilizados por los dispositivos inteligentes para adaptarse automáticamente a las necesidades de sus usuarios, redundando en una mayor exactitud de la adaptación. En este artículo se propone la integración del modelo computacional People as a Service (PeaaS) con el procesamiento de eventos complejos (CEP) para la creación en tiempo real de perfiles virtuales complejos desde el propio dispositivo móvil y la compartición de estos como servicios para el resto de sistemas y dispositivos. Además, se evalúa esta integración en un caso de estudio sobre Alzheimer. Los resultados confirman que el uso de la tecnología CEP para la identificación de información contextual compleja es posible.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Información Contextual, CEP, PeaaS, Asper, MDD]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jose Garcia-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Juan M. Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería de Sistemas Informáticos y Telemáticos, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Dpto. de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/010]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>La Web de las Cosas se nos viene encima</title>
		<link>https://biblioteca.sistedes.es/articulo/la-web-de-las-cosas-se-nos-viene-encima/</link>
		<pubDate>Tue, 06 Sep 2016 17:18:01 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2118</guid>
		<description></description>
		<content><![CDATA[A medida que crece el interés por la denominada Web de las Cosas (WoT), deberíamos hacer disminuir las barreras de entrada para el uso de las tecnologías asociadas. Hoy en día somos capaces de desarrollar aplicaciones que adaptan su comportamiento de acuerdo a condiciones definidas de antemano, así como a las preferencias personales de sus usuarios, facilitando así su utilización. El software para la Web de las Cosas que desarrollemos en el futuro inmediato debería ser capaz de ajustar de forma automática su comportamiento también de acuerdo a situaciones no predefinidas y al contexto en el que se mueven sus usuarios. En este artículo de reflexión, discutimos el estado actual del arte y la necesidad de nuevos modelos y herramientas capaces de hacer frente a estos retos, de forma que podamos predecir el comportamiento esperado de un sistema WoT y la interacción necesaria entre los dispositivos que lo integran, con el objetivo de lograr una mejor respuesta del sistema a información contextual variable.]]></content>
		<excerpt><![CDATA[Internet de las Cosas, Web de las Cosas, Sensibilidad al contexto]]></excerpt>
		<post_id>2118</post_id>
		<post_date><![CDATA[2016-09-06 19:18:01]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 17:18:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[la-web-de-las-cosas-se-nos-viene-encima]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="internet-de-las-cosas"><![CDATA[Internet de las Cosas]]></category>
		<category domain="post_tag" nicename="sensibilidad-al-contexto"><![CDATA[Sensibilidad al contexto]]></category>
		<category domain="post_tag" nicename="web-de-las-cosas"><![CDATA[Web de las Cosas]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2119]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A medida que crece el interés por la denominada Web de las Cosas (WoT), deberíamos hacer disminuir las barreras de entrada para el uso de las tecnologías asociadas. Hoy en día somos capaces de desarrollar aplicaciones que adaptan su comportamiento de acuerdo a condiciones definidas de antemano, así como a las preferencias personales de sus usuarios, facilitando así su utilización. El software para la Web de las Cosas que desarrollemos en el futuro inmediato debería ser capaz de ajustar de forma automática su comportamiento también de acuerdo a situaciones no predefinidas y al contexto en el que se mueven sus usuarios. En este artículo de reflexión, discutimos el estado actual del arte y la necesidad de nuevos modelos y herramientas capaces de hacer frente a estos retos, de forma que podamos predecir el comportamiento esperado de un sistema WoT y la interacción necesaria entre los dispositivos que lo integran, con el objetivo de lograr una mejor respuesta del sistema a información contextual variable.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Internet de las Cosas, Web de las Cosas, Sensibilidad al contexto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/011]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Análisis inteligente de flujos de trabajo sociales</title>
		<link>https://biblioteca.sistedes.es/articulo/analisis-inteligente-de-flujos-de-trabajo-sociales/</link>
		<pubDate>Tue, 06 Sep 2016 17:30:08 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2121</guid>
		<description></description>
		<content><![CDATA[Los flujos de trabajo sociales (SOW) coordinan las actividades realizadas por un conjunto de usuarios que bien de forma individual o en cooperación tratan de alcanzar un determinado objetivo. Los SOW son flujos no estructurados en los que participan un gran número de usuarios que llevan a cabo actividades de muy diversa naturaleza que se extienden a lo largo del tiempo y que típicamente consumen pocos recursos de computación. Un ejemplo de procesos que se modelan a través de este tipo de flujos de trabajo son las campañas de marketing que tienen como objetivo motivar a los potenciales clientes en el consumo de un determinado producto o servicio. En este trabajo, se presenta el proyecto Inteligencia (Artificial) de Negocio para Flujos de Trabajo Sociales, en el que se combinan técnicas de minería de procesos, estrategias de paralelización de algoritmos, y técnicas de localización y seguimiento de usuarios, con el fin de extraer información relevante sobre SOW, como los que modelan, entre otros, el comportamiento de los usuarios en campañas de marketing desarrolladas en escenarios abiertos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2121</post_id>
		<post_date><![CDATA[2016-09-06 19:30:08]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 17:30:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analisis-inteligente-de-flujos-de-trabajo-sociales]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[11]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2122]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los flujos de trabajo sociales (SOW) coordinan las actividades realizadas por un conjunto de usuarios que bien de forma individual o en cooperación tratan de alcanzar un determinado objetivo. Los SOW son flujos no estructurados en los que participan un gran número de usuarios que llevan a cabo actividades de muy diversa naturaleza que se extienden a lo largo del tiempo y que típicamente consumen pocos recursos de computación. Un ejemplo de procesos que se modelan a través de este tipo de flujos de trabajo son las campañas de marketing que tienen como objetivo motivar a los potenciales clientes en el consumo de un determinado producto o servicio. En este trabajo, se presenta el proyecto Inteligencia (Artificial) de Negocio para Flujos de Trabajo Sociales, en el que se combinan técnicas de minería de procesos, estrategias de paralelización de algoritmos, y técnicas de localización y seguimiento de usuarios, con el fin de extraer información relevante sobre SOW, como los que modelan, entre otros, el comportamiento de los usuarios en campañas de marketing desarrolladas en escenarios abiertos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel Lama]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[manuel.lama@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pedro Álvarez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Ingenería de Aragón (I3A) Depto. de Informática e Ingenería de Sistemas, Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[alvaper@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Ocaña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Depto. de Electrónica, Escuela Politécnica Superior. Universidad de Alcalá de Henares]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mocana@depeca.uah.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel Mucientes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manuel.mucientes@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Joaquín Ezpeleta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Ingenería de Aragón (I3A) Depto. de Informática e Ingeneríaa de Sistemas, Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[ezpeleta@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Miguel Ángel Garrido]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autor_univ_6]]></meta_key>
			<meta_value><![CDATA[Depto. de Electrónica, Escuela Politécnica Superior. Universidad de Alcalá de Henares]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[garrido@depeca.uah.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Alberto Bugarín]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[alberto.bugarin.diz@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/028]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Depto. de Electrónica, Escuela Politécnica Superior. Universidad de Alcalá de Henares]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>MigraSOA: Migrando aplicaciones web legadas hacia arquitecturas orientadas a servicios (SOA)</title>
		<link>https://biblioteca.sistedes.es/articulo/migrasoa-migrando-aplicaciones-web-legadas-hacia-arquitecturas-orientadas-a-servicios-soa/</link>
		<pubDate>Tue, 06 Sep 2016 17:37:58 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2125</guid>
		<description></description>
		<content><![CDATA[La migración de aplicaciones legadas hacia arquitecturas orientadas a servicios (SOA) es un proceso relativamente habitual en la actualidad, ya que las características de flexibilidad arquitectónica que ofrece SOA permiten adaptar fácilmente las aplicaciones a los nuevos requisitos marcados por las empresas. Sin embargo, el desarrollo de esta migración hacia estas nuevas arquitecturas software se lleva a cabo normalmente de forma manual, siendo este un mecanismo tedioso y propenso a errores. MigraSOA es una propuesta de migración de aplicaciones web legadas (LWA) hacia SOA que utiliza técnicas de Desarrollo de Software Dirigido por Modelos (MDD) para abordar la complejidad de las tecnologías subyacentes (servicios web, definición de procesos de negocio o plataformas para procesos de negocio ejecutables). En este trabajo, además de presentar MigraSOA de una forma global, nos centraremos en los aspectos de alineación de los procesos de negocio definidos por la empresa con los servicios web subyacentes en la aplicación legada y en cómo extender los modelos BPMN para conseguir la sincronización entre ellos y los servicios disponibles.]]></content>
		<excerpt><![CDATA[migración de aplicaciones web, servicios web, procesos de negocio, arquitecturas orientadas a servicios]]></excerpt>
		<post_id>2125</post_id>
		<post_date><![CDATA[2016-09-06 19:37:58]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 17:37:58]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[migrasoa-migrando-aplicaciones-web-legadas-hacia-arquitecturas-orientadas-a-servicios-soa]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="arquitecturas-orientadas-a-servicios"><![CDATA[arquitecturas orientadas a servicios]]></category>
		<category domain="post_tag" nicename="migracion-de-aplicaciones-web"><![CDATA[migración de aplicaciones web]]></category>
		<category domain="post_tag" nicename="procesos-de-negocio"><![CDATA[Procesos de Negocio]]></category>
		<category domain="post_tag" nicename="servicios-web"><![CDATA[servicios web]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2126]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La migración de aplicaciones legadas hacia arquitecturas orientadas a servicios (SOA) es un proceso relativamente habitual en la actualidad, ya que las características de flexibilidad arquitectónica que ofrece SOA permiten adaptar fácilmente las aplicaciones a los nuevos requisitos marcados por las empresas. Sin embargo, el desarrollo de esta migración hacia estas nuevas arquitecturas software se lleva a cabo normalmente de forma manual, siendo este un mecanismo tedioso y propenso a errores. MigraSOA es una propuesta de migración de aplicaciones web legadas (LWA) hacia SOA que utiliza técnicas de Desarrollo de Software Dirigido por Modelos (MDD) para abordar la complejidad de las tecnologías subyacentes (servicios web, definición de procesos de negocio o plataformas para procesos de negocio ejecutables). En este trabajo, además de presentar MigraSOA de una forma global, nos centraremos en los aspectos de alineación de los procesos de negocio definidos por la empresa con los servicios web subyacentes en la aplicación legada y en cómo extender los modelos BPMN para conseguir la sincronización entre ellos y los servicios disponibles.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[migración de aplicaciones web, servicios web, procesos de negocio, arquitecturas orientadas a servicios]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Encarna Sosa-Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura. Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[esosa@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pedro J. Clemente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura. Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pjclemente@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alvaro Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura. Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aeprieto@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José M. Conejero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura. Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[chemacm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Roberto Rodríguez-Echeverría]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura. Quercus Software Engineering Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[rre@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/024]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una aproximación DevOps para el Desarrollo Dirigido por Modelos de Servicios Cloud</title>
		<link>https://biblioteca.sistedes.es/articulo/una-aproximacion-devops-para-el-desarrollo-dirigido-por-modelos-de-servicios-cloud/</link>
		<pubDate>Tue, 06 Sep 2016 19:07:45 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2132</guid>
		<description></description>
		<content><![CDATA[El desarrollo de software ágil promueve la entrega continua e incremental de software. Con cada incremento surge la necesidad de realizar una integración del nuevo código fuente con el existente para obtener una nueva versión del software. La nueva versión debe superar un conjunto de pruebas para ser desplegada en el entorno de operaciones. El tiempo que transcurre desde que el nuevo incremento pasa del entorno de desarrollo al entorno de operaciones debe ser minimizado para reducir costes económicos a las organizaciones. DevOps es un conjunto de principios y prácticas que optimizan el tiempo de entrega de un producto software, gestionan la infraestructura como código y mejoran la experiencia del usuario en base a la retroalimentación de sus comentarios. En trabajos anteriores hemos presentado DIARy como un método dirigido por modelos que soporta la reconfiguración dinámica de arquitecturas de servicios cloud producida por la integración incremental de nuevos servicios. En este trabajo presentamos una extensión del método DIARy con el fin de adoptar DevOps con una estrategia dirigida por modelos.]]></content>
		<excerpt><![CDATA[DevOps, Servicios Cloud, Integración y Reconfiguración de Servicios, Desarrollo Ágil, Desarrollo Dirigido por Modelos]]></excerpt>
		<post_id>2132</post_id>
		<post_date><![CDATA[2016-09-06 21:07:45]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:07:45]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-aproximacion-devops-para-el-desarrollo-dirigido-por-modelos-de-servicios-cloud]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="desarrollo-agil"><![CDATA[Desarrollo Ágil]]></category>
		<category domain="post_tag" nicename="desarrollo-dirigido-por-modelos"><![CDATA[Desarrollo dirigido por modelos]]></category>
		<category domain="post_tag" nicename="devops"><![CDATA[DevOps]]></category>
		<category domain="post_tag" nicename="integracion-y-reconfiguracion-de-servicios"><![CDATA[Integración y Reconfiguración de Servicios]]></category>
		<category domain="post_tag" nicename="servicios-cloud"><![CDATA[Servicios Cloud]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2133]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El desarrollo de software ágil promueve la entrega continua e incremental de software. Con cada incremento surge la necesidad de realizar una integración del nuevo código fuente con el existente para obtener una nueva versión del software. La nueva versión debe superar un conjunto de pruebas para ser desplegada en el entorno de operaciones. El tiempo que transcurre desde que el nuevo incremento pasa del entorno de desarrollo al entorno de operaciones debe ser minimizado para reducir costes económicos a las organizaciones. DevOps es un conjunto de principios y prácticas que optimizan el tiempo de entrega de un producto software, gestionan la infraestructura como código y mejoran la experiencia del usuario en base a la retroalimentación de sus comentarios. En trabajos anteriores hemos presentado DIARy como un método dirigido por modelos que soporta la reconfiguración dinámica de arquitecturas de servicios cloud producida por la integración incremental de nuevos servicios. En este trabajo presentamos una extensión del método DIARy con el fin de adoptar DevOps con una estrategia dirigida por modelos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[DevOps, Servicios Cloud, Integración y Reconfiguración de Servicios, Desarrollo Ágil, Desarrollo Dirigido por Modelos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julio Sandobalín-Guamán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València y Departamento de Informática y Ciencias de la Computación, Escuela Politécnica Nacional (Ecuador)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jsandobalin@disc.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miguel Zúñiga-Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València y Departamento de Ciencias de la Computación, Universidad de Cuenca (Ecuador)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mzuniga@disc.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Emilio Insfran]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[einsfran@disc.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Silvia Abrahão]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sabrahao@disc.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Carlos Cano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[carcage@disc.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/014]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards a general architecture for predictive monitoring of business processes</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-a-general-architecture-for-predictive-monitoring-of-business-processes/</link>
		<pubDate>Tue, 06 Sep 2016 19:15:49 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2135</guid>
		<description></description>
		<content><![CDATA[Process mining allows the extraction of useful information from event logs and historical data of business processes. This information will improve the performance of these processes and is generally obtained after they have finished. Therefore, predictive monitoring of business process running instances is needed, in order to provide proactive and corrective actions to improve the process performance and mitigate the possible risks in real time. This monitoring allows the prediction of evaluation metrics for a runtime process. In this context, this work describes a general methodology for a business process monitoring system for the prediction of process performance indicators and their stages, such as, the processing and encoding of log events, the calculation of aggregated attributes or the application of a data mining algorithm.]]></content>
		<excerpt><![CDATA[business process, process mining, predictive monitoring, business process indicator prediction]]></excerpt>
		<post_id>2135</post_id>
		<post_date><![CDATA[2016-09-06 21:15:49]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:15:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-a-general-architecture-for-predictive-monitoring-of-business-processes]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="business-process"><![CDATA[Business process]]></category>
		<category domain="post_tag" nicename="business-process-indicator-prediction"><![CDATA[business process indicator prediction]]></category>
		<category domain="post_tag" nicename="predictive-monitoring"><![CDATA[predictive monitoring]]></category>
		<category domain="post_tag" nicename="process-mining"><![CDATA[Process Mining]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2136]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Process mining allows the extraction of useful information from event logs and historical data of business processes. This information will improve the performance of these processes and is generally obtained after they have finished. Therefore, predictive monitoring of business process running instances is needed, in order to provide proactive and corrective actions to improve the process performance and mitigate the possible risks in real time. This monitoring allows the prediction of evaluation metrics for a runtime process. In this context, this work describes a general methodology for a business process monitoring system for the prediction of process performance indicators and their stages, such as, the processing and encoding of log events, the calculation of aggregated attributes or the application of a data mining algorithm.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[business process, process mining, predictive monitoring, business process indicator prediction]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alfonso E. Márquez-Chamorro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[amarquez6@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/003]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automating Correctness Verification of Artifact-Centric Business Process Models (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/automating-correctness-verification-of-artifact-centric-business-process-models-abstract/</link>
		<pubDate>Tue, 06 Sep 2016 19:20:44 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2138</guid>
		<description></description>
		<content><![CDATA[Resumen de artículo publicado como:

Automating Correctness Verification of Artifact-Centric Business Process Models. Published in Journal of Information and Software Technology. Vol. 62, Issue C, Pages 187-197, June 2015. DOI:10.1016/j.infsof.2015.02.010.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2138</post_id>
		<post_date><![CDATA[2016-09-06 21:20:44]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:20:44]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automating-correctness-verification-of-artifact-centric-business-process-models-abstract]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2139]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen de artículo publicado en:

Automating Correctness Verification of Artifact-Centric Business Process Models. Published in Journal of Information and Software Technology. Vol. 62, Issue C, Pages 187-197, June 2015. DOI:10.1016/j.infsof.2015.02.010.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Diana Borrego]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[dianabn@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Rafael M. Gasca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gasca@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[María Teresa Gómez-López]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[maytegomez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modelling Service Level Agreements for Business Process Outsourcing Services (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/modelling-service-level-agreements-for-business-process-outsourcing-services-abstract/</link>
		<pubDate>Tue, 06 Sep 2016 19:25:12 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2141</guid>
		<description></description>
		<content><![CDATA[Resumen del artículo publicado como:

A. del Río-Ortega et al.: Modelling Service Level Agreements for Business Process Outsourcing Services. In: CAiSE 2015: 485-500.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2141</post_id>
		<post_date><![CDATA[2016-09-06 21:25:12]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:25:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modelling-service-level-agreements-for-business-process-outsourcing-services-abstract]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen del artículo publicado en:

A. del Río-Ortega et al.: Modelling Service Level Agreements for Business Process Outsourcing Services. In: CAiSE 2015: 485-500.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Adela del-Río-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Manuel Gutiérrez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Amador Durán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2142]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/022]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Verification and Validation of UML Artifact-centric Business Process Models (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/verification-and-validation-of-uml-artifact-centric-business-process-models-abstract/</link>
		<pubDate>Tue, 06 Sep 2016 19:29:40 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2145</guid>
		<description></description>
		<content><![CDATA[Resumen del artículo publicado en:

27th Int. Conf. on Advanced Information Systems Engineering (CAiSE 2015).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2145</post_id>
		<post_date><![CDATA[2016-09-06 21:29:40]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:29:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[verification-and-validation-of-uml-artifact-centric-business-process-models-abstract]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2146]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen del artículo publicado en:

27th Int. Conf. on Advanced Information Systems Engineering (CAiSE 2015).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Montserrat Estañol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[estanyol@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Maria-Ribera Sancho]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya y Barcelona Supercomputing Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ribera@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ernest Teniente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[teniente@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Reconfiguration of Service Failures in DAMASCo using Dynamic Software Product Lines (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/reconfiguration-of-service-failures-in-damasco-using-dynamic-software-product-lines-abstract/</link>
		<pubDate>Tue, 06 Sep 2016 19:33:36 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2148</guid>
		<description></description>
		<content><![CDATA[<div data-canvas-width="47.34519999999999">Building service-based applications requires providing the ability to handle, maintain or upgrade the services that compose these applications. As same services may be used by a wide variability of applications, the management of the heterogeneity at runtime is required. This is crucial to reconfigure applications in case of service failures. The DAMASCo framework reduces the complexity of modeling services focusing on the discovery, composition and adaptation of context-aware services. But currently, it does not support the dynamic reconfiguration of service-based applications. In this work, we follow a Dynamic Software Product Line approach to extend DAMASCo for providing reconfiguration to support specific situations of fails at runtime. We propose a novel approach of grouping services in families facilitating the selection and usage of similar services in case of fails. We apply our approach to an intelligent transportation system case study where DAMASCo composes and reconfigure the necessary services to provide a dynamic route for a driver’srequest.</div>
&nbsp;

Resumen del artículo publicado en:

12th IEEE International Conference on Services Computing (SCC 2015).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2148</post_id>
		<post_date><![CDATA[2016-09-06 21:33:36]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:33:36]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[reconfiguration-of-service-failures-in-damasco-using-dynamic-software-product-lines-abstract]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="dsp"><![CDATA[DSP]]></category>
		<category domain="post_tag" nicename="heterogeneity"><![CDATA[Heterogeneity]]></category>
		<category domain="post_tag" nicename="service-reconfiguration"><![CDATA[Service Reconfiguration]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2149]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Building service-based applications requires providing the ability to handle, maintain or upgrade the services that compose these applications. As same services may be used by a wide variability of applications, the management of the heterogeneity at runtime is required. This is crucial to reconfigure applications in case of service failures. The DAMASCo framework reduces the complexity of modeling services focusing on the discovery, composition and adaptation of context-aware services. But currently, it does not support the dynamic reconfiguration of service-based applications. In this work, we follow a Dynamic Software Product Line approach to extend DAMASCo for providing reconfiguration to support specific situations of fails at runtime. We propose a novel approach of grouping services in families facilitating the selection and usage of similar services in case of fails. We apply our approach to an intelligent transportation system case study where DAMASCo composes and reconfigure the necessary services to provide a dynamic route for a driver’srequest.

Resumen del artículo publicado en:

12th IEEE International Conference on Services Computing (SCC 2015).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Cubo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cubo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Nadia Gamez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[nadia@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ernesto Pimentel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ernesto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Service Reconfiguration, Heterogeneity, DSP]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/007]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Reconfigurando Aplicaciones Multi-Cloud con Líneas de Producto Software Dinámicas</title>
		<link>https://biblioteca.sistedes.es/articulo/reconfigurando-aplicaciones-multi-cloud-con-lineas-de-producto-software-dinamicas/</link>
		<pubDate>Tue, 06 Sep 2016 19:39:04 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2151</guid>
		<description></description>
		<content><![CDATA[La reconfiguración dinámica de aplicaciones multi-cloud es un reto complejo aún no suficientemente explorado. En estos entornos las aplicaciones o sus módulos pueden estar desplegados en diferentes proveedores. Por lo tanto, reconfigurar en tiempo de ejecución estas aplicaciones puede requerir la modificación de la distribución en múltiples y heterogéneos proveedores. Obtener la nueva distribución para que sigan funcionando correctamente las aplicaciones no es una tarea sencilla, pues tanto los requisitos de las aplicaciones como las propiedades de los proveedores son muy diversos y variables. Además, la migración de las aplicaciones o sus módulos en tiempo real de un proveedor a otro puede conllevar problemas de compatibilidad y/o dependencias entre los módulos. Por lo tanto, el manejo de la variabilidad dinámica de las aplicaciones y proveedores, así como el de las dependencias existentes es deseable que se haga a un alto nivel de abstracción. Las Líneas de Producto Software Dinámicas (DSLP) utilizan modelos de variabilidad en tiempo de ejecución para obtener los cambios que han de llevarse a cabo durante la reconfiguración. En este trabajo, exploramos el uso del enfoque de DSPL, para que cuando ocurran problemas en los proveedores o se violen requisitos de las aplicaciones multi-cloud, las apps puedan ser reconfiguradas y seguir proporcionando los servicios adecuadamente a los usuarios.]]></content>
		<excerpt><![CDATA[Reconfiguración, Aplicaciones Cloud, Multi-Cloud, DSPL, Variabilidad]]></excerpt>
		<post_id>2151</post_id>
		<post_date><![CDATA[2016-09-06 21:39:04]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:39:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[reconfigurando-aplicaciones-multi-cloud-con-lineas-de-producto-software-dinamicas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="aplicaciones-cloud"><![CDATA[Aplicaciones Cloud]]></category>
		<category domain="post_tag" nicename="dspl"><![CDATA[DSPL]]></category>
		<category domain="post_tag" nicename="multi-cloud"><![CDATA[Multi-Cloud]]></category>
		<category domain="post_tag" nicename="reconfiguracion"><![CDATA[Reconfiguración]]></category>
		<category domain="post_tag" nicename="variabilidad"><![CDATA[Variabilidad]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2152]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La reconfiguración dinámica de aplicaciones multi-cloud es un reto complejo aún no suficientemente explorado. En estos entornos las aplicaciones o sus módulos pueden estar desplegados en diferentes proveedores. Por lo tanto, reconfigurar en tiempo de ejecución estas aplicaciones puede requerir la modificación de la distribución en múltiples y heterogéneos proveedores. Obtener la nueva distribución para que sigan funcionando correctamente las aplicaciones no es una tarea sencilla, pues tanto los requisitos de las aplicaciones como las propiedades de los proveedores son muy diversos y variables. Además, la migración de las aplicaciones o sus módulos en tiempo real de un proveedor a otro puede conllevar problemas de compatibilidad y/o dependencias entre los módulos. Por lo tanto, el manejo de la variabilidad dinámica de las aplicaciones y proveedores, así como el de las dependencias existentes es deseable que se haga a un alto nivel de abstracción. Las Líneas de Producto Software Dinámicas (DSLP) utilizan modelos de variabilidad en tiempo de ejecución para obtener los cambios que han de llevarse a cabo durante la reconfiguración. En este trabajo, exploramos el uso del enfoque de DSPL, para que cuando ocurran problemas en los proveedores o se violen requisitos de las aplicaciones multi-cloud, las apps puedan ser reconfiguradas y seguir proporcionando los servicios adecuadamente a los usuarios. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Reconfiguración, Aplicaciones Cloud, Multi-Cloud, DSPL, Variabilidad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Cubo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cubo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Nadia Gámez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[nadia@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ernesto Pimentel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ernesto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. de Lenguajes y Ciencias de la Computación, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/013]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Bidimensional Cross-Cloud Application Management with TOSCA and Brooklyn (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/bidimensional-cross-cloud-application-management-with-tosca-and-brooklyn-abstract/</link>
		<pubDate>Tue, 06 Sep 2016 19:47:45 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2154</guid>
		<description></description>
		<content><![CDATA[The diversity in the way different cloud providers offer their services, give their SLAs, present their QoS, support different technologies, etc., complicates the portability and interoperability of cloud applications, and favors vendor lock-in. Standards like TOSCA, and tools supporting them, have come to help in the provider-independent description of cloud applications. After the variety of proposed cross-cloud application management tools, we propose going one step further in the unification of cloud services with a deployment tool in which IaaS and PaaS services are integrated into a unified interface. We provide support for applications whose components are to be deployed on different providers, indistinctly using IaaS and PaaS services. The TOSCA standard is used to define a portable model describing the topology of the cloud applications and the required resources in an agnostic, and providers- and resources-independent way. We include in this paper some highlights on our implementation on Apache Brooklyn and present a non-trivial example that illustrates our approach.

Resumen del artículo publicado en:

Jose Carrasco, Javier Cubo, Francisco Durán, Ernesto Pimentel. Bidimensional Cross-Cloud Application Management with TOSCA and Brooklyn, 9th IEEE International Conference on Cloud Computing (CLOUD 2016), San Francisco, (EEUU). IEEE Computer Society, 2016.]]></content>
		<excerpt><![CDATA[Cloud applications, multi-deployment, cross-cloud, standards, TOSCA, Brooklyn, IaaS, PaaS]]></excerpt>
		<post_id>2154</post_id>
		<post_date><![CDATA[2016-09-06 21:47:45]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:47:45]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[bidimensional-cross-cloud-application-management-with-tosca-and-brooklyn-abstract]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="brooklyn"><![CDATA[Brooklyn]]></category>
		<category domain="post_tag" nicename="cloud-applications"><![CDATA[Cloud applications]]></category>
		<category domain="post_tag" nicename="cross-cloud"><![CDATA[cross-cloud]]></category>
		<category domain="post_tag" nicename="iaas"><![CDATA[IaaS]]></category>
		<category domain="post_tag" nicename="multi-deployment"><![CDATA[multi-deployment]]></category>
		<category domain="post_tag" nicename="paas"><![CDATA[PaaS]]></category>
		<category domain="post_tag" nicename="standards"><![CDATA[standards]]></category>
		<category domain="post_tag" nicename="tosca"><![CDATA[TOSCA]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2155]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The diversity in the way different cloud providers offer their services, give their SLAs, present their QoS, support different technologies, etc., complicates the portability and interoperability of cloud applications, and favors vendor lock-in. Standards like TOSCA, and tools supporting them, have come to help in the provider-independent description of cloud applications. After the variety of proposed cross-cloud application management tools, we propose going one step further in the unification of cloud services with a deployment tool in which IaaS and PaaS services are integrated into a unified interface. We provide support for applications whose components are to be deployed on different providers, indistinctly using IaaS and PaaS services. The TOSCA standard is used to define a portable model describing the topology of the cloud applications and the required resources in an agnostic, and providers- and resources-independent way. We include in this paper some highlights on our implementation on Apache Brooklyn and present a non-trivial example that illustrates our approach.

Resumen del artículo publicado en:

Jose Carrasco, Javier Cubo, Francisco Durán, Ernesto Pimentel. Bidimensional Cross-Cloud Application Management with TOSCA and Brooklyn, 9th IEEE International Conference on Cloud Computing (CLOUD 2016), San Francisco, (EEUU). IEEE Computer Society, 2016.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Cloud applications, multi-deployment, cross-cloud, standards, TOSCA, Brooklyn, IaaS, PaaS]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jose Carrasco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[josec@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Cubo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cubo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco Durán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[duran@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ernesto Pimentel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Dept. Lenguajes y Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[ernesto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/012]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Recommender System for Process Discovery (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-recommender-system-for-process-discovery-abstract/</link>
		<pubDate>Tue, 06 Sep 2016 19:54:43 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2157</guid>
		<description></description>
		<content><![CDATA[Resumen del artículo publicado como:

Joel Ribeiro, Josep Carmona, Mustafa Misir, Michle Sebag: A Recommender System for Process Discovery. 12th International Conference on Business Process Management, BPM 2014, Haifa, Israel, September 7-11, 67-83. Lecture Notes in Computer Science 8659, Springer 2014, ISBN 978-3-319-10171-2.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2157</post_id>
		<post_date><![CDATA[2016-09-06 21:54:43]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:54:43]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-recommender-system-for-process-discovery-abstract]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2158]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen del artículo publicado como:

Joel Ribeiro, Josep Carmona, Mustafa Misir, Michle Sebag: A Recommender System for Process Discovery. 12th International Conference on Business Process Management, BPM 2014, Haifa, Israel, September 7-11, 67-83. Lecture Notes in Computer Science 8659, Springer 2014, ISBN 978-3-319-10171-2.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Joel Ribeiro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jribeiro@lsi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Josep Carmona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jcarmona@lsi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Mustafa Misir]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[TAO, INRIA Saclay - CNRS - LRI, Université Paris Sud XI (France)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mustafa.misir@lri.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Michele Sebag]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[TAO, INRIA Saclay - CNRS - LRI, Université Paris Sud XI (France)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[michele.sebag@lri.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/001]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Process Mining: Past, Present and (Likely) Future</title>
		<link>https://biblioteca.sistedes.es/articulo/process-mining-past-present-and-likely-future/</link>
		<pubDate>Tue, 06 Sep 2016 19:57:45 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2160</guid>
		<description></description>
		<content><![CDATA[The process mining field came here to stay. This is demonstrated by the growing interest in the last decade, both in academia and industry. Being at the intersection of many disciplines, process mining techniques transform structured information into valuable models, which provide a fresh and formal insight into the real execution of processes within an organization. Still, there is way more to do than what has been accomplished: process discovery techniques may suffer from noisy, incomplete event logs and may fail to choose the right representational bias; conformance checking suffers from the inherent complexity of working at the state-space level, and in case of large inputs this fact prevents from enhancing process models with additional perspectives. In this paper I will provide an historical overview of the field, describe its current challenges, and vaticinate its long-term future.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2160</post_id>
		<post_date><![CDATA[2016-09-06 21:57:45]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 19:57:45]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[process-mining-past-present-and-likely-future]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2161]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The process mining field came here to stay. This is demonstrated by the growing interest in the last decade, both in academia and industry. Being at the intersection of many disciplines, process mining techniques transform structured information into valuable models, which provide a fresh and formal insight into the real execution of processes within an organization. Still, there is way more to do than what has been accomplished: process discovery techniques may suffer from noisy, incomplete event logs and may fail to choose the right representational bias; conformance checking suffers from the inherent complexity of working at the state-space level, and in case of large inputs this fact prevents from enhancing process models with additional perspectives. In this paper I will provide an historical overview of the field, describe its current challenges, and vaticinate its long-term future.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Josep Carmona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jcarmona@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/006]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>VIVACE: A framework for the systematic evaluation of variability support in process-aware information systems (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/vivace-a-framework-for-the-systematic-evaluation-of-variability-support-in-process-aware-information-systems-summary/</link>
		<pubDate>Tue, 06 Sep 2016 20:10:47 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2163</guid>
		<description></description>
		<content><![CDATA[Resumen del artículo publicado como:

Clara Ayora, Victoria Torres, Barbara Weber, Manfred Reichert, and Vicente Pelechano. VIVACE: A framework for the systematic evaluation of variability support in process-aware information systems, Information and Software Technology, Volume 57, January 2015, Pages 248–276, Elsevier, 2015.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2163</post_id>
		<post_date><![CDATA[2016-09-06 22:10:47]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 20:10:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[vivace-a-framework-for-the-systematic-evaluation-of-variability-support-in-process-aware-information-systems-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2165]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen del artículo publicado como:

Clara Ayora, Victoria Torres, Barbara Weber, Manfred Reichert, and Vicente Pelechano. VIVACE: A framework for the systematic evaluation of variability support in process-aware information systems, Information and Software Technology, Volume 57, January 2015, Pages 248–276, Elsevier, 2015.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Clara Ayora]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València y Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cayora@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Victoria Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València y Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[vtorres@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Barbara Weber]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Innsbruck (Austria)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[barbara.weber@uibk.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manfred Reichert]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Ulm (Germany)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manfred.reichert@uni-ulm.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València y Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[pele@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/016]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Monitoring the service-based system lifecycle with SALMon (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/monitoring-the-service-based-system-lifecycle-with-salmon-summary/</link>
		<pubDate>Tue, 06 Sep 2016 20:15:11 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2167</guid>
		<description></description>
		<content><![CDATA[Resumen del artículo publicado como:

Marc Oriol, Xavier Franch, Jordi Marco. Monitoring the service-based system lifecycle with SALMon, Expert Systems with Applications, 42(19), 2015.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2167</post_id>
		<post_date><![CDATA[2016-09-06 22:15:11]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 20:15:11]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[monitoring-the-service-based-system-lifecycle-with-salmon-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2168]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen del artículo publicado como:

Marc Oriol, Xavier Franch, Jordi Marco. Monitoring the service-based system lifecycle with SALMon, Expert Systems with Applications, 42(19), 2015.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Marc Oriol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya, y GESSI research group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[moriol@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Xavier Franch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya, y GESSI research group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[franch@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jordi Marco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya, y GESSI research group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jmarco@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/021]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Governing the service-chain: Challenges ahead</title>
		<link>https://biblioteca.sistedes.es/articulo/governing-the-service-chain-challenges-ahead/</link>
		<pubDate>Tue, 06 Sep 2016 20:18:08 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2170</guid>
		<description></description>
		<content><![CDATA[As Information Systems are evolving into an ecosystem of services, organizations face the persistent challenge of IT governance. In such a context, Cloud Computing shift has supported a growing service chain that has transformed the business model from industry. In this position paper we outline the dimensions of this service chain reality and the role of Service Level Agreement as a foundation to support its governance challenges.

&nbsp;]]></content>
		<excerpt><![CDATA[service-chain, governance, sla]]></excerpt>
		<post_id>2170</post_id>
		<post_date><![CDATA[2016-09-06 22:18:08]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 20:18:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[governing-the-service-chain-challenges-ahead]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="governance"><![CDATA[governance]]></category>
		<category domain="post_tag" nicename="service-chain"><![CDATA[service-chain]]></category>
		<category domain="post_tag" nicename="sla"><![CDATA[SLA]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2171]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[As Information Systems are evolving into an ecosystem of services, organizations face the persistent challenge of IT governance. In such a context, Cloud Computing shift has supported a growing service chain that has transformed the business model from industry. In this position paper we outline the dimensions of this service chain reality and the role of Service Level Agreement as a foundation to support its governance challenges.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[service-chain, governance, sla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/030]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Programming Elasticity and Commitment in Dynamic Processes (summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/programming-elasticity-and-commitment-in-dynamic-processes-summary/</link>
		<pubDate>Tue, 06 Sep 2016 20:23:39 +0000</pubDate>
		<creator><![CDATA[ccanal]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2173</guid>
		<description></description>
		<content><![CDATA[In the past, elasticity and commitment in business processes were under-explored. But as businesses increasingly exploit pay-per-use resources in the cloud for on-demand needs, elasticity and commitment have become important issues. Here, the authors discuss the value of using elastic resources and commitments to create more dynamic organizations that can easily balance the need to be adaptable and flexible, while also retaining a high level of manageability.

Resumen del artículo publicado como:

Pablo Fernandez, Hong-Linh Truong, Schahram Dustdar, and Antonio Ruiz-Cortes. Programming Elasticity and Commitment in Dynamic Processes, IEEE Internet Computing, Vol 19, 2 , 68-74, 2015.]]></content>
		<excerpt><![CDATA[elasticity, commitments, process management]]></excerpt>
		<post_id>2173</post_id>
		<post_date><![CDATA[2016-09-06 22:23:39]]></post_date>
		<post_date_gmt><![CDATA[2016-09-06 20:23:39]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[programming-elasticity-and-commitment-in-dynamic-processes-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-ccanal"><![CDATA[ccanal]]></category>
		<category domain="post_tag" nicename="commitments"><![CDATA[commitments]]></category>
		<category domain="post_tag" nicename="elasticity"><![CDATA[elasticity]]></category>
		<category domain="post_tag" nicename="process-management"><![CDATA[process management]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2174]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In the past, elasticity and commitment in business processes were under-explored. But as businesses increasingly exploit pay-per-use resources in the cloud for on-demand needs, elasticity and commitment have become important issues. Here, the authors discuss the value of using elastic resources and commitments to create more dynamic organizations that can easily balance the need to be adaptable and flexible, while also retaining a high level of manageability.

Resumen del artículo publicado como:

Pablo Fernandez, Hong-Linh Truong, Schahram Dustdar, and Antonio Ruiz-Cortes. Programming Elasticity and Commitment in Dynamic Processes, IEEE Internet Computing, Vol 19, 2 , 68-74, 2015.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[elasticity, commitments, process management]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Hong-Linh Truong]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Technical University of Vienna (Austria)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Schahram Dustdar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Technical University of Vienna (Austria)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2016/020]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Constraint-Based Testing: An Emerging Trend in Software Testing</title>
		<link>https://biblioteca.sistedes.es/articulo/constraint-based-testing-an-emerging-trend-in-software-testing/</link>
		<pubDate>Thu, 08 Sep 2016 09:25:39 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2194</guid>
		<description></description>
		<content><![CDATA[Software Testing involves the development of smart techniques to automatically find test inputs which uncover faults in programs. An emerging trend in this area, called “Constraint-Based Testing”, aims at exploiting constraint solving techniques for this goal. My talk will review different techniques including dynamic symbolic execution, path-based exploration and constraint-based exploration and will emphasize the usage of advanced Constraint Programming tools.Software Testing involves the development of smart techniques to automatically find test inputs which uncover faults in programs. An emerging trend in this area, called “Constraint-Based Testing”, aims at exploiting constraint solving techniques for this goal. My talk will review different techniques including dynamic symbolic execution, path-based exploration and constraint-based exploration and will emphasize the usage of advanced Constraint Programming tools.]]></content>
		<excerpt><![CDATA[Software Testing involves the development of smart techniques to automatically find test inputs which uncover faults in programs. An emerging trend in this area, called “Constraint-Based Testing”, aims at exploiting constraint solving techniques for this goal. My talk will review different techniques including dynamic symbolic execution, path-based exploration and constraint-based exploration and will emphasize the usage of advanced Constraint Programming tools.Software Testing involves the development of smart techniques to automatically find test inputs which uncover faults in programs. An emerging trend in this area, called “Constraint-Based Testing”, aims at exploiting constraint solving techniques for this goal. My talk will review different techniques including dynamic symbolic execution, path-based exploration and constraint-based exploration and will emphasize the usage of advanced Constraint Programming tools.]]></excerpt>
		<post_id>2194</post_id>
		<post_date><![CDATA[2016-09-08 11:25:39]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 09:25:39]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[constraint-based-testing-an-emerging-trend-in-software-testing]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[10]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2195]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Software Testing involves the development of smart techniques to automatically find test inputs which uncover faults in programs. An emerging trend in this area, called “Constraint-Based Testing”, aims at exploiting constraint solving techniques for this goal. My talk will review different techniques including dynamic symbolic execution, path-based exploration and constraint-based exploration and will emphasize the usage of advanced Constraint Programming tools.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Arnaud Gotlieb]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Simula Research Laboratory. Norway]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[arnaud@simula.no]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards Automatic Learning of Heuristics for Mechanical Transformations of Procedural Code</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-automatic-learning-of-heuristics-for-mechanical-transformations-of-procedural-code/</link>
		<pubDate>Thu, 08 Sep 2016 09:39:12 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2199</guid>
		<description></description>
		<content><![CDATA[The current trends in next-generation exascale systems go towards integrating a wide range of specialized (co-)processors into traditional supercomputers. Due to the efficiency of heterogeneous systems in terms of Watts and FLOPS per surface unit, opening the access of heterogeneous platforms to a range of users as wide as possible is an important problem to be tackled. However, the integration of heterogeneous, specialized devices increases programming complexity, restricting it to a few experts, and makes porting applications onto different computational infrastructures extremely costly. In order to bridge the gap between the programming needs of heterogeneous systems and the expertise of programmers, program transformation has been proposed elsewhere as a means to ease program generation and adaptation. This brings about several issues such as how to plan a transformation strategy which eventually generates code with increased performance. In this paper we propose a machine learning-based approach to learn heuristics for defining transformation strategies of a program transformation system. Our approach proposes a novel combination of reinforcement learning and classification methods to efficiently tackle the problems inherent to this type of systems. Preliminary results demonstrate the suitability of this approach.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2199</post_id>
		<post_date><![CDATA[2016-09-08 11:39:12]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 09:39:12]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-automatic-learning-of-heuristics-for-mechanical-transformations-of-procedural-code]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2200]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The current trends in next-generation exascale systems go towards integrating a wide range of specialized (co-)processors into traditional supercomputers. Due to the efficiency of heterogeneous systems in terms of Watts and FLOPS per surface unit, opening the access of heterogeneous platforms to a range of users as wide as possible is an important problem to be tackled. However, the integration of heterogeneous, specialized devices increases programming complexity, restricting it to a few experts, and makes porting applications onto different computational infrastructures extremely costly. In order to bridge the gap between the programming needs of heterogeneous systems and the expertise of programmers, program transformation has been proposed elsewhere as a means to ease program generation and adaptation. This brings about several issues such as how to plan a transformation strategy which eventually generates code with increased performance. In this paper we propose a machine learning-based approach to learn heuristics for defining transformation strategies of a program transformation system. Our approach proposes a novel combination of reinforcement learning and classification methods to efficiently tackle the problems inherent to this type of systems. Preliminary results demonstrate the suitability of this approach.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Program Transformation, Machine Learning, Heterogeneous Systems]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Guillermo Vigueras  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[guillermo.vigueras@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Manuel Carro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[manuel.carro@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Salvador Tamarit  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[salvador.tamarit@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Julio Mariño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[julio.marino@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/015]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards a Semantics-Aware Code Transformation Toolchain for Heterogeneous Systems</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-a-semantics-aware-code-transformation-toolchain-for-heterogeneous-systems/</link>
		<pubDate>Thu, 08 Sep 2016 09:49:31 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2203</guid>
		<description></description>
		<content><![CDATA[Obtaining good performance when programming heterogeneous computing platforms poses significant challenges. We present a program transformation environment, implemented in Haskell, where architecture-agnostic scientific C code with semantic annotations is transformed into functionally equivalent code better suited for a given platform. The transformation steps are represented as rules which can be fired when certain syntactic and semantic conditions are fulfilled. These rules are not hard-wired into the rewriting engine: they are written in a C-like language and are automatically processed and incorporated by the rewriting engine. That makes it possible for end-users to add their own rules or to provide sets of rules which are adapted to certain specific domains or purposes.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2203</post_id>
		<post_date><![CDATA[2016-09-08 11:49:31]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 09:49:31]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-a-semantics-aware-code-transformation-toolchain-for-heterogeneous-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2204]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Obtaining good performance when programming heterogeneous computing platforms poses significant challenges. We present a program transformation environment, implemented in Haskell, where architecture-agnostic scientific C code with semantic annotations is transformed into functionally equivalent code better suited for a given platform. The transformation steps are represented as rules which can be fired when certain syntactic and semantic conditions are fulfilled. These rules are not hard-wired into the rewriting engine: they are written in a C-like language and are automatically processed and incorporated by the rewriting engine. That makes it possible for end-users to add their own rules or to provide sets of rules which are adapted to certain specific domains or purposes.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Rule-based program transformation, Semantics-aware program transformation, High-performance, Heterogeneous platforms, Scientific computing, Domain-specific language, Haskell, C]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Tamarit  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[salvador.tamarit@upm.es, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Julio Mariño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[julio.marino@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Guillermo Vigueras  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[guillermo.vigueras@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel Carro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manuel.carro@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/014]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Metapredicate Optimization for Datalog Queries through Program Analysis</title>
		<link>https://biblioteca.sistedes.es/articulo/metapredicate-optimization-for-datalog-queries-through-program-analysis/</link>
		<pubDate>Thu, 08 Sep 2016 10:59:07 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2237</guid>
		<description></description>
		<content><![CDATA[Some systems extend Datalog in order to allow the use of constructions in which several queries are composed to produce the set of resulting tuples. These constructions include outer joins, aggregate and grouping predicates, as well as, to some extent, negation. Typically, the result of such
constructions depends on the subset of the tuples in the sets initially computed. In order to optimize for efficiency these compound queries, it would be interesting to determine in advance the subsets involved in the compound construct. Static analysis can be used at compile-time to infer
an over-approximation of such subsets. Very precise abstract interpretation-based static analyzers have been developed for logic languages, and in particular the use of type domains allow to infer descriptive types for the arguments of a given predicate. Using the extensional description of the
types inferred, the Datalog program can then be transformed to use the inferred subsets instead of the original queries. Here, we propose a source-to-source transformation of Datalog programs based on static analysis for optimizing queries involving outer join, negation, aggregate and grouping predicates. This approach has been tested in the DES system, using CiaoPP (a language preprocessor for Prolog) for inferring descriptive types. Some preliminary experiments show promising results.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2237</post_id>
		<post_date><![CDATA[2016-09-08 12:59:07]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 10:59:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[metapredicate-optimization-for-datalog-queries-through-program-analysis]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2238]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Some systems extend Datalog in order to allow the use of constructions in which several queries are composed to produce the set of resulting tuples. These constructions include outer joins, aggregate and grouping predicates, as well as, to some extent, negation. Typically, the result of such
constructions depends on the subset of the tuples in the sets initially computed. In order to optimize for efficiency these compound queries, it would be interesting to determine in advance the subsets involved in the compound construct. Static analysis can be used at compile-time to infer
an over-approximation of such subsets. Very precise abstract interpretation-based static analyzers have been developed for logic languages, and in particular the use of type domains allow to infer descriptive types for the arguments of a given predicate. Using the extensional description of the
types inferred, the Datalog program can then be transformed to use the inferred subsets instead of the original queries. Here, we propose a source-to-source transformation of Datalog programs based on static analysis for optimizing queries involving outer join, negation, aggregate and grouping predicates. This approach has been tested in the DES system, using CiaoPP (a language preprocessor for Prolog) for inferring descriptive types. Some preliminary experiments show promising results.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Bueno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DIA, Polytechnic University of Madrid (UPM)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[bueno@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jesús Correas  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[DSIC, Madrid, Spain Complutense University of Madrid (UCM)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jcorreas@fdi.ucm.es  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[ Fernando Sáenz-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DISIA, Madrid, Spain Complutense University of Madrid (UCM)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ fernan@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/002]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Proving termination properties of conditional rewrite systems</title>
		<link>https://biblioteca.sistedes.es/articulo/proving-termination-properties-of-conditional-rewrite-systems/</link>
		<pubDate>Thu, 08 Sep 2016 11:03:28 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2240</guid>
		<description></description>
		<content><![CDATA[Conditional Term Rewriting Systems (CTRSs) extend Term Rewriting Systems (TRSs) conditional part c to each rewrite rule l → r, thus obtaining a conditional rewrite rule l → r ⇐ c. The addition of such conditional parts c substantially increases the expressiveness of programming languages that use them and often clarifies the purpose of the rules to make programs more readable and self-explanatory. Computations with CTRSs are defined by means of an Inference System where each rewriting step s →R t requires a proof. This proof-theoretical definition of the operational semantics suggests a natural definition of the termination behavior of R as the absence of infinite proof trees. The notion of operational termination captures this idea, meaning that, given an initial goal, an interpreter will either succeed in finite time in producing a closed proof tree, or will fail in finite time, not being able to close or extend further any of the possible proof trees, after exhaustively searching all such proof trees. Besides implying termination in the usual ‘horizontal’ sense (i.e., as the absence of infinite sequences of rewrite steps), operational termination also captures a ‘vertical’ dimension of the termination behavior which is missing in the usual “without infinite reduction sequences” definition of termination. In [1] we define the notion of V-termination, which captures such a vertical dimension of the termination behavior of CTRSs. We provide a uniform definition of termination and V-termination of CTRSs as the absence of specific kinds of infinite proof trees. We prove that operational termination is just the conjunction of termination and V-termination. We use these results to develop a methodology to prove or disprove termination, V-termination, and operational termination of CTRSs by extending the Dependency Pair (DP) approach for TRSs and generalize the DP approach to all aforementioned termination properties of CTRSs.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2240</post_id>
		<post_date><![CDATA[2016-09-08 13:03:28]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 11:03:28]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[proving-termination-properties-of-conditional-rewrite-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2241]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Conditional Term Rewriting Systems (CTRSs) extend Term Rewriting Systems (TRSs) conditional part c to each rewrite rule l → r, thus obtaining a conditional rewrite rule l → r ⇐ c. The addition of such conditional parts c substantially increases the expressiveness of programming languages that use them and often clarifies the purpose of the rules to make programs more readable and self-explanatory. Computations with CTRSs are defined by means of an Inference System where each rewriting step s →R t requires a proof. This proof-theoretical definition of the operational semantics suggests a natural definition of the termination behavior of R as the absence of infinite proof trees. The notion of operational termination captures this idea, meaning that, given an initial goal, an interpreter will either succeed in finite time in producing a closed proof tree, or will fail in finite time, not being able to close or extend further any of the possible proof trees, after exhaustively searching all such proof trees. Besides implying termination in the usual ‘horizontal’ sense (i.e., as the absence of infinite sequences of rewrite steps), operational termination also captures a ‘vertical’ dimension of the termination behavior which is missing in the usual “without infinite reduction sequences” definition of termination. In [1] we define the notion of V-termination, which captures such a vertical dimension of the termination behavior of CTRSs. We provide a uniform definition of termination and V-termination of CTRSs as the absence of specific kinds of infinite proof trees. We prove that operational termination is just the conjunction of termination and V-termination. We use these results to develop a methodology to prove or disprove termination, V-termination, and operational termination of CTRSs by extending the Dependency Pair (DP) approach for TRSs and generalize the DP approach to all aforementioned termination properties of CTRSs.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Lucas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politecnica de Valencia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Meseguer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[CS Dept. at the University of Illinois at Urbana-Champaign]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/020]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Abstract analysis of universal properties for tccp</title>
		<link>https://biblioteca.sistedes.es/articulo/abstract-analysis-of-universal-properties-for-tccp/</link>
		<pubDate>Thu, 08 Sep 2016 11:07:47 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2243</guid>
		<description></description>
		<content><![CDATA[The Timed Concurrent Constraint Language (tccp) is a time extension of the concurrent constraint paradigm of Saraswat. tccp was defined to model reactive systems, where infinite behaviors arise naturally. It is well-known that modeling and analyzing concurrent systems by hand can be an extremely hard task. Thus, the development of automatic formal methods is essential. The particular characteristics of ccp languages make such task even harder, since we have to deal with technical issues due to the infinite computations (natural to reactive systems), use of negative information (particular for ccp languages) and non-determinism.
One well established technique to develop semantic-based program analysis is abstract interpretation, which relies on the definition of a specific approximated abstract semantics that captures the information needed to perform the analysis. Typically, one defines an over-approximation of the concrete semantics that includes all possible traces of the system, possibly introducing inexistent ones. This allows one to develop (correct) analysis of universal properties. It does not allow to analyze existential properties, for instance to verify that there exists a suspension trace.
This paper (originally published in [1]) defines a framework of over-approximated abstract semantics parametric w.r.t. an abstract constraint system.
Since we need to preserve the notion of time—to be able to express properties of interest like safety or time-depending properties—the abstract semantics domains are not Noetherian (even if we use finite abstract constraint systems). Thus, in order to have an effective approach we use a widening to ensure finiteness of the analysis.
The abstract semantics is correct and can be represented as a finite graph where each node represents
a hypothetical computational step of the program containing approximated information for the variables.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2243</post_id>
		<post_date><![CDATA[2016-09-08 13:07:47]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 11:07:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[abstract-analysis-of-universal-properties-for-tccp]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2244]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The Timed Concurrent Constraint Language (tccp) is a time extension of the concurrent constraint paradigm of Saraswat. tccp was defined to model reactive systems, where infinite behaviors arise naturally. It is well-known that modeling and analyzing concurrent systems by hand can be an extremely hard task. Thus, the development of automatic formal methods is essential. The particular characteristics of ccp languages make such task even harder, since we have to deal with technical issues due to the infinite computations (natural to reactive systems), use of negative information (particular for ccp languages) and non-determinism.
One well established technique to develop semantic-based program analysis is abstract interpretation, which relies on the definition of a specific approximated abstract semantics that captures the information needed to perform the analysis. Typically, one defines an over-approximation of the concrete semantics that includes all possible traces of the system, possibly introducing inexistent ones. This allows one to develop (correct) analysis of universal properties. It does not allow to analyze existential properties, for instance to verify that there exists a suspension trace.
This paper (originally published in [1]) defines a framework of over-approximated abstract semantics parametric w.r.t. an abstract constraint system.
Since we need to preserve the notion of time—to be able to express properties of interest like safety or time-depending properties—the abstract semantics domains are not Noetherian (even if we use finite abstract constraint systems). Thus, in order to have an effective approach we use a widening to ensure finiteness of the analysis.
The abstract semantics is correct and can be represented as a finite graph where each node represents
a hypothetical computational step of the program containing approximated information for the variables.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Marco Comini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DIMI, Università degli Studi di Udine  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[marco.comini@uniud.it  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ María del Mar Gallardo  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[LCC, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gallardo@lcc.uma.es  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[ Laura Titolo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[LCC, Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ laura.titolo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Alicia Villanueva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[villanue@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/017]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>River basin management with SPIN</title>
		<link>https://biblioteca.sistedes.es/articulo/river-basin-management-with-spin/</link>
		<pubDate>Thu, 08 Sep 2016 12:09:56 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2246</guid>
		<description></description>
		<content><![CDATA[This paper presents the use of the SPIN model checker as the core engine to build Decision Support Systems (DSSs) to control complex river basins during flood situations. Current DSSs in this domain are mostly based on simulators to predict the rainfall and the water flow along the river basin.
In this paper, we propose a scheme that integrates simulators in the water domain with additional logic in P ROMELA to represent basin elements, such as dams, their management rules, the evolution of dam parameters (e.g. level or discharge capacity), and user defined constraints in the whole basin over time. Then, we use the exploration capabilities of SPIN to find out which sequences of operations over the dams produce a global behaviour that mitigates the effect of floods according to user defined constraints along the river basin. Although the method is general for any river basin with dams, it has been evaluated in a real basin in the south of Spain.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2246</post_id>
		<post_date><![CDATA[2016-09-08 14:09:56]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:09:56]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[river-basin-management-with-spin]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2247]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper presents the use of the SPIN model checker as the core engine to build Decision Support Systems (DSSs) to control complex river basins during flood situations. Current DSSs in this domain are mostly based on simulators to predict the rainfall and the water flow along the river basin.
In this paper, we propose a scheme that integrates simulators in the water domain with additional logic in P ROMELA to represent basin elements, such as dams, their management rules, the evolution of dam parameters (e.g. level or discharge capacity), and user defined constraints in the whole basin over time. Then, we use the exploration capabilities of SPIN to find out which sequences of operations over the dams produce a global behaviour that mitigates the effect of floods according to user defined constraints along the river basin. Although the method is general for any river basin with dams, it has been evaluated in a real basin in the south of Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María del Mar Gallardo  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Andalucía Tech, Dept. de Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[gallardo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pedro Merino  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Andalucía Tech, Dept. de Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pedro@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Laura Panizo  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Andalucía Tech, Dept. de Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[laurapanizo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[ Alberto Salmerón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga, Andalucía Tech, Dept. de Ciencias de la Computación]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[salmeron@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/007]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automatic Grading of Programming Exercises using Property-Based Testing</title>
		<link>https://biblioteca.sistedes.es/articulo/automatic-grading-of-programming-exercises-using-property-based-testing/</link>
		<pubDate>Thu, 08 Sep 2016 12:13:04 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2249</guid>
		<description></description>
		<content><![CDATA[We present a framework for automatic grading of programming exercises using property-based testing, a form of model-based black-box testing. Models are developed to assess both the functional behaviour of programs and their algorithmic complexity. From the functional correctness model a
large number of test cases are derived automatically. Executing them on the body of exercises gives rise to a (partial) ranking of programs, so that a program A is ranked higher than program B if it fails a strict subset of the test cases failed by B. The model for algorithmic complexity is used to compute worst-case complexity bounds. The framework moreover considers code structural metrics, such as McCabe’s cyclomatic complexity, giving rise to a composite program grade that includes both functional, non-functional, and code structural aspects. The framework is evaluated in a course teaching algorithms and data structures using Java.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2249</post_id>
		<post_date><![CDATA[2016-09-08 14:13:04]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:13:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automatic-grading-of-programming-exercises-using-property-based-testing]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2250]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We present a framework for automatic grading of programming exercises using property-based testing, a form of model-based black-box testing. Models are developed to assess both the functional behaviour of programs and their algorithmic complexity. From the functional correctness model a
large number of test cases are derived automatically. Executing them on the body of exercises gives rise to a (partial) ranking of programs, so that a program A is ranked higher than program B if it fails a strict subset of the test cases failed by B. The model for algorithmic complexity is used to compute worst-case complexity bounds. The framework moreover considers code structural metrics, such as McCabe’s cyclomatic complexity, giving rise to a composite program grade that includes both functional, non-functional, and code structural aspects. The framework is evaluated in a course teaching algorithms and data structures using Java.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Clara Benac Earle  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid, Spain  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cbenac@fi.upm.es  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Lars-Ake Fredlund]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid, Spain  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[lfredlund@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[John Hughes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Chalmers University of Technology and Quviq AB, Göteborg, Sweden]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[rjmh@chalmers.se]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/023]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Fuzzy Thresholded Fixpoint Semantics</title>
		<link>https://biblioteca.sistedes.es/articulo/fuzzy-thresholded-fixpoint-semantics/</link>
		<pubDate>Thu, 08 Sep 2016 12:18:11 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2253</guid>
		<description></description>
		<content><![CDATA[This work proposes an immediate consequences operator that allows us to give a fixpoint characterization of the least Herbrand model for a powerful class of fuzzy logic programs coping with implicit/explicit truth degree annotations, a great variety of connectives and unification by similarity. The so-called FASILL language (acronym of “Fuzzy Aggregators and Similarity Into a Logic Language”) has been recently designed and implemented in our research group and it enjoys the capability for managing filters or thresholds in a natural way in order to relax some computational and
declarative aspects as revealed in the proposed fixpoint semantics.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2253</post_id>
		<post_date><![CDATA[2016-09-08 14:18:11]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:18:11]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[fuzzy-thresholded-fixpoint-semantics]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2254]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This work proposes an immediate consequences operator that allows us to give a fixpoint characterization of the least Herbrand model for a powerful class of fuzzy logic programs coping with implicit/explicit truth degree annotations, a great variety of connectives and unification by similarity. The so-called FASILL language (acronym of “Fuzzy Aggregators and Similarity Into a Logic Language”) has been recently designed and implemented in our research group and it enjoys the capability for managing filters or thresholds in a natural way in order to relax some computational and
declarative aspects as revealed in the proposed fixpoint semantics.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[ Fuzzy Logic Programming, Similarity Relation, Herbrand Model, Immediate Consequences Operator, Fixpoint Semantics]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pascual Julián-Iranzo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dep. of Technologies and Information Systems. U. of Castilla-La Mancha, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Pascual.Julian@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ginés Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dep. of Computing Systems. U. of Castilla-La Mancha, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Gines.Moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jaime Penabad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dep. of Mathematics. U. of Castilla-La Mancha, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Jaime.Penabad@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Formal Relational Languages in a Deductive Setting</title>
		<link>https://biblioteca.sistedes.es/articulo/formal-relational-languages-in-a-deductive-setting/</link>
		<pubDate>Thu, 08 Sep 2016 12:19:56 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2256</guid>
		<description></description>
		<content><![CDATA[The relational data model coincides with the deductive one and, thus, formal relational query languages can be mapped to a deductive setting. These languages include, on the one hand, Tuple Relational Calculus (TRC) and Domain Relational Calculus (DRC). It can be argued that TRC can be
seen as the formal basis of SQL, while DRC does the same for the semantic web language SPARQL and even the graphical relational language Query-by-Example (QBE). On the other hand, Relational Algebra (RA) is also used as a target language for intermediate compilations from SQL to executable query plans. As commonly acknowledged, RA allows a more formal setting for query optimizations than SQL. In this work, we describe the new support of TRC and DRC in the deductive system DES (which included already SQL and RA) with the aim to have an integrated system for learning database query (formal) languages based on logic.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2256</post_id>
		<post_date><![CDATA[2016-09-08 14:19:56]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:19:56]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[formal-relational-languages-in-a-deductive-setting]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2257]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The relational data model coincides with the deductive one and, thus, formal relational query languages can be mapped to a deductive setting. These languages include, on the one hand, Tuple Relational Calculus (TRC) and Domain Relational Calculus (DRC). It can be argued that TRC can be
seen as the formal basis of SQL, while DRC does the same for the semantic web language SPARQL and even the graphical relational language Query-by-Example (QBE). On the other hand, Relational Algebra (RA) is also used as a target language for intermediate compilations from SQL to executable query plans. As commonly acknowledged, RA allows a more formal setting for query optimizations than SQL. In this work, we describe the new support of TRC and DRC in the deductive system DES (which included already SQL and RA) with the aim to have an integrated system for learning database query (formal) languages based on logic.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Fernando Sáenz-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid (UCM), Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fernan@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/003]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Logic of Graph Conditions Extended with Paths</title>
		<link>https://biblioteca.sistedes.es/articulo/a-logic-of-graph-conditions-extended-with-paths/</link>
		<pubDate>Thu, 08 Sep 2016 12:22:55 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2259</guid>
		<description></description>
		<content><![CDATA[In this paper we tackle the problem of extending the logic of nested graph conditions with paths. This means, for instance, that we may state properties about the existence of paths between some given nodes. As a main contribution, a sound and complete tableau method is defined for reasoning about this kind of properties.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2259</post_id>
		<post_date><![CDATA[2016-09-08 14:22:55]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:22:55]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-logic-of-graph-conditions-extended-with-paths]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2260]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento – NoComercial (by-nc)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper we tackle the problem of extending the logic of nested graph conditions with paths. This means, for instance, that we may state properties about the existence of paths between some given nodes. As a main contribution, a sound and complete tableau method is defined for reasoning about this kind of properties.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Marisa Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad del País Vasco (UPV/EHU), Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[marisa.navarro@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando Orejas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[orejas@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Elvira Pino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pino@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Leen Lambers]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Hasso Plattner Institut. University of Potsdam, Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Leen.Lambers@hpi.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/009]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Polymorphic Types in Erlang Function Specifications</title>
		<link>https://biblioteca.sistedes.es/articulo/polymorphic-types-in-erlang-function-specifications/</link>
		<pubDate>Thu, 08 Sep 2016 12:26:02 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2262</guid>
		<description></description>
		<content><![CDATA[Erlang is a concurrent functional programming language developed by Ericsson, well suited for implementing distributed systems. Although Erlang is dynamically typed, the Dialyzer static analysis tool can be used to extract implicit type information from the programs, both for documentation
purposes and for finding errors that will definitively arise at program execution. Dialyzer is based on the notion of success types, that correspond to safe over-approximations for the semantics of expressions. Erlang also supports user given function specifications (or just specs), that are contracts
providing more information about the semantics of functions. Function specs are useful not only as documentation, but also can be employed by Dialyzer to improve the precision of the analysis. Even though specs can have a polymorphic shape, in practice Dialyzer is not able to exploit all their potential. One reason for that is that extending the notion of success type to a polymorphic setting is not trivial, and several interpretations are possible. In this work [1] we propose a precise formulation for a novel interpretation of function specs as polymorphic success types, and a program transformation that allows us to apply this new interpretation on the call sites of functions with a declared spec. This results on a significant improvement in the number of definite errors that Dialyzer is able to detect.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2262</post_id>
		<post_date><![CDATA[2016-09-08 14:26:02]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:26:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[polymorphic-types-in-erlang-function-specifications]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2263]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Erlang is a concurrent functional programming language developed by Ericsson, well suited for implementing distributed systems. Although Erlang is dynamically typed, the Dialyzer static analysis tool can be used to extract implicit type information from the programs, both for documentation
purposes and for finding errors that will definitively arise at program execution. Dialyzer is based on the notion of success types, that correspond to safe over-approximations for the semantics of expressions. Erlang also supports user given function specifications (or just specs), that are contracts
providing more information about the semantics of functions. Function specs are useful not only as documentation, but also can be employed by Dialyzer to improve the precision of the analysis. Even though specs can have a polymorphic shape, in practice Dialyzer is not able to exploit all their potential. One reason for that is that extending the notion of success type to a polymorphic setting is not trivial, and several interpretations are possible. In this work [1] we propose a precise formulation for a novel interpretation of function specs as polymorphic success types, and a program transformation that allows us to apply this new interpretation on the call sites of functions with a declared spec. This results on a significant improvement in the number of definite errors that Dialyzer is able to detect.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Javier López-Fraguas,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de sistemas Informáticos y Computación. Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fraguas@sip.ucm.es,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Montenegro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de sistemas Informáticos y Computación. Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[montenegro@fdi.ucm.es,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Rodríguez-Hortalá]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de sistemas Informáticos y Computación. Universidad Complutense de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanrh@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Que Ningún Término Resoluble de Lambda-Valor Se Quede Atrás (resumen)</title>
		<link>https://biblioteca.sistedes.es/articulo/que-ningun-termino-resoluble-de-lambda-valor-se-quede-atras-resumen/</link>
		<pubDate>Thu, 08 Sep 2016 12:29:39 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2265</guid>
		<description></description>
		<content><![CDATA[Este es el resumen de la ponencia en Castellano sobre el artículo titulado "No solvable lambda-value term left behind" publicado por los autores en la revista Logical Methods in Computer Science Vol. 2(2:12) 2016, págs.1–43. La ponencia forma parte del programa de las XVI Jornadas sobre Programación y Lenguajes dentro del V Congreso Español de Informática que tuvo lugar del 13 al 16 de septiembre de 2016 en Salamanca.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2265</post_id>
		<post_date><![CDATA[2016-09-08 14:29:39]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:29:39]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[que-ningun-termino-resoluble-de-lambda-valor-se-quede-atras-resumen]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2266]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este es el resumen de la ponencia en Castellano sobre el artículo titulado "No solvable lambda-value term left behind" publicado por los autores en la revista Logical Methods in Computer Science Vol. 2(2:12) 2016, págs.1–43. La ponencia forma parte del programa de las XVI Jornadas sobre Programación y Lenguajes dentro del V Congreso Español de Informática que tuvo lugar del 13 al 16 de septiembre de 2016 en Salamanca.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Álvaro García-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Reykjavík University, Islandia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alvarog@ru.is]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Nogueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto IMDEA Software Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pablo.nogueira@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/006]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Combining Runtime Checking and Slicing to improve Maude Error Diagnosis</title>
		<link>https://biblioteca.sistedes.es/articulo/combining-runtime-checking-and-slicing-to-improve-maude-error-diagnosis/</link>
		<pubDate>Thu, 08 Sep 2016 12:32:33 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2268</guid>
		<description></description>
		<content><![CDATA[This paper introduces the idea of using assertion checking for enhancing the dynamic slicing of Maude computation traces. Since trace slicing can greatly simplify the size and complexity of the analyzed traces, our methodology can be useful for improving the diagnosis of erroneous Maude
programs. The proposed methodology is based on (i) a logical notation for specifying two types of user-defined assertions that are imposed on execution runs: functional assertions and system assertions; (ii) a runtime checking technique that dynamically tests the assertions and is provably safe in the sense that all errors flagged are definite violations of the specifications; and (iii) a mechanism based on equational least general generalization that automatically derives accurate criteria for slicing from falsified assertions.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2268</post_id>
		<post_date><![CDATA[2016-09-08 14:32:33]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:32:33]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[combining-runtime-checking-and-slicing-to-improve-maude-error-diagnosis]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2269]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper introduces the idea of using assertion checking for enhancing the dynamic slicing of Maude computation traces. Since trace slicing can greatly simplify the size and complexity of the analyzed traces, our methodology can be useful for improving the diagnosis of erroneous Maude
programs. The proposed methodology is based on (i) a logical notation for specifying two types of user-defined assertions that are imposed on execution runs: functional assertions and system assertions; (ii) a runtime checking technique that dynamically tests the assertions and is provably safe in the sense that all errors flagged are definite violations of the specifications; and (iii) a mechanism based on equational least general generalization that automatically derives accurate criteria for slicing from falsified assertions.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Alpuente  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DSIC-ELP, Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alpuente@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Francisco Frechina  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[DSIC-ELP, Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ffrechina@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Julia Sapiña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DSIC-ELP, Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jsapina@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Demis Ballis]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[DIMI, University of Udine, Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[demis.ballis@uniud.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/001]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Reversible Term Rewriting</title>
		<link>https://biblioteca.sistedes.es/articulo/reversible-term-rewriting/</link>
		<pubDate>Thu, 08 Sep 2016 12:35:37 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2271</guid>
		<description></description>
		<content><![CDATA[Essentially, in a reversible programming language, for each forward computation step from state S to state S', there exists a constructive and deterministic method to go backwards from state S' to state S. Besides its theoretical interest, reversible computation is a fundamental concept which is relevant in many different areas like cellular automata, bidirectional program transformation, or quantum computing, to name a few. In this paper, we focus on term rewriting, a computation model that underlies most rule-based programming languages. In general, term rewriting is not reversible, even for injective functions; namely, given a rewrite step t1 → t2 , we do not always have a decidable and deterministic method to get t1 from t2 . Here, we introduce a conservative extension of term rewriting that becomes reversible. Furthermore, we also define a transformation to make a rewrite system reversible using standard term rewriting.
This paper has been published in Naoki Nishida, Adrián Palacios, Germán Vidal. Reversible Term Rewriting. In Delia Kesner and Brigitte Pientka, editors, Proceedings of the First International Conference on Formal Structures for Computation and Deduction, FSCD 2016, June 22-26, 2016,
Porto, Portugal. LIPIcs 52, 28:1–28:18, Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2016.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2271</post_id>
		<post_date><![CDATA[2016-09-08 14:35:37]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:35:37]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[reversible-term-rewriting]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2272]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Essentially, in a reversible programming language, for each forward computation step from state S to state S', there exists a constructive and deterministic method to go backwards from state S' to state S. Besides its theoretical interest, reversible computation is a fundamental concept which is relevant in many different areas like cellular automata, bidirectional program transformation, or quantum computing, to name a few. In this paper, we focus on term rewriting, a computation model that underlies most rule-based programming languages. In general, term rewriting is not reversible, even for injective functions; namely, given a rewrite step t1 → t2 , we do not always have a decidable and deterministic method to get t1 from t2 . Here, we introduce a conservative extension of term rewriting that becomes reversible. Furthermore, we also define a transformation to make a rewrite system reversible using standard term rewriting.
This paper has been published in Naoki Nishida, Adrián Palacios, Germán Vidal. Reversible Term Rewriting. In Delia Kesner and Brigitte Pientka, editors, Proceedings of the First International Conference on Formal Structures for Computation and Deduction, FSCD 2016, June 22-26, 2016,
Porto, Portugal. LIPIcs 52, 28:1–28:18, Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2016.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Naoki Nishida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Graduate School of Information Science, Nagoya University, Japan]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[nishida@is.nagoya-u.ac.jp]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Adrián Palacios  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[MiST, DSIC, Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[apalacios@dsic.upv.es  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Germán Vidal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[MiST, DSIC, Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gvidal@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/011]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Page-Level Webpage Menu Detection</title>
		<link>https://biblioteca.sistedes.es/articulo/page-level-webpage-menu-detection/</link>
		<pubDate>Thu, 08 Sep 2016 12:38:51 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2274</guid>
		<description></description>
		<content><![CDATA[One of the key elements of a website are Web menus, which provide fundamental information about the structure of the own website. For humans, identifying the main menu of a website is a relatively easy task. However, for computer tools identifying the menu is not trivial at all and, in fact, it is still a challenging unsolved problem. From the point of view of crawlers and indexers, menu detection is a valuable technique, because processing the menu allows these tools to immediately find out the structure of the website. Identifying the menu is also essential for website mapping tasks. With the information of the menu, it is possible to build a sitemap that includes the main pages without having to follow all the links. In this work, we propose a novel method for automatic Web menu detection that works at the level of DOM. Our implementation and experiments demonstrate the usefulness of the technique.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2274</post_id>
		<post_date><![CDATA[2016-09-08 14:38:51]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:38:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[page-level-webpage-menu-detection]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2275]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[One of the key elements of a website are Web menus, which provide fundamental information about the structure of the own website. For humans, identifying the main menu of a website is a relatively easy task. However, for computer tools identifying the menu is not trivial at all and, in fact, it is still a challenging unsolved problem. From the point of view of crawlers and indexers, menu detection is a valuable technique, because processing the menu allows these tools to immediately find out the structure of the website. Identifying the menu is also essential for website mapping tasks. With the information of the menu, it is possible to build a sitemap that includes the main pages without having to follow all the links. In this work, we propose a novel method for automatic Web menu detection that works at the level of DOM. Our implementation and experiments demonstrate the usefulness of the technique.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julián Alarte]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación. Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalarte@dsic.upv.es  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ David Insa  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación. Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ dinsa@dsic.upv.es  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[ Josep Silva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación. Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ jsilva@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/022]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Tutorial on Using Dafny to Construct Verified Software</title>
		<link>https://biblioteca.sistedes.es/articulo/a-tutorial-on-using-dafny-to-construct-verified-software/</link>
		<pubDate>Thu, 08 Sep 2016 12:40:33 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2277</guid>
		<description></description>
		<content><![CDATA[This paper is a tutorial for newcomers to the field of automated verification tools, though we assume the reader to be relatively familiar with Hoare-style verification. In this paper, besides introducing the most basic features of the language and verifier Dafny, we place special emphasis on how to use Dafny as an assistant in the development of verified programs. Our main aim is to encourage the software engineering community to make the move towards using formal verification tools.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2277</post_id>
		<post_date><![CDATA[2016-09-08 14:40:33]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:40:33]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-tutorial-on-using-dafny-to-construct-verified-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2278]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper is a tutorial for newcomers to the field of automated verification tools, though we assume the reader to be relatively familiar with Hoare-style verification. In this paper, besides introducing the most basic features of the language and verifier Dafny, we place special emphasis on how to use Dafny as an assistant in the development of verified programs. Our main aim is to encourage the software engineering community to make the move towards using formal verification tools.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Paqui Lucio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[The University of the Basque Country (UPV/EHU)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[paqui.lucio@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/010]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Introduction to Liquid Haskell</title>
		<link>https://biblioteca.sistedes.es/articulo/an-introduction-to-liquid-haskell/</link>
		<pubDate>Thu, 08 Sep 2016 12:42:13 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2280</guid>
		<description></description>
		<content><![CDATA[This paper is a tutorial introducing the underlying technology and the use of the tool Liquid Haskell, a type-checker for the functional language Haskell that can help programmers to verify non-trivial properties of their programs with a low effort.
The first sections introduce the technology of Liquid Types by explaining its principles and summarizing how its type inference algorithm manages to prove properties. The remaining sections present a selection of Haskell examples and show the kind of properties that can be proved with the
system.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2280</post_id>
		<post_date><![CDATA[2016-09-08 14:42:13]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:42:13]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-introduction-to-liquid-haskell]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2281]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper is a tutorial introducing the underlying technology and the use of the tool Liquid Haskell, a type-checker for the functional language Haskell that can help programmers to verify non-trivial properties of their programs with a low effort.
The first sections introduce the technology of Liquid Types by explaining its principles and summarizing how its type inference algorithm manages to prove properties. The remaining sections present a selection of Haskell examples and show the kind of properties that can be proved with the
system.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ricardo Peña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Complutense University of Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ricardo@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/016]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Comparing MapReduce and Pipeline implementations for Counting Triangles</title>
		<link>https://biblioteca.sistedes.es/articulo/comparing-mapreduce-and-pipeline-implementations-for-counting-triangles/</link>
		<pubDate>Thu, 08 Sep 2016 12:45:55 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2283</guid>
		<description></description>
		<content><![CDATA[A common method to define a parallel solution for a computational problem consists in finding a way to use the Divide &amp; Conquer paradigm in order to have processors acting on its own data and scheduled in a parallel fashion. MapReduce is a programming model that follows this paradigm,
and allows for the definition of efficient solutions by both decomposing a problem into steps on subsets of the input data and combining the results of each step to produce final results. Albeit used for the implementation of a wide variety of computational problems, MapReduce performance
can be negatively affected whenever the replication factor grows or the size of the input is larger than the resources available at each processor. In this paper we show an alternative approach to implement the Divide &amp; Conquer paradigm, named dynamic pipeline. The main features of pipeline
are illustrated on a parallel implementation of the well-known problem of counting triangles in a graph. This problem is especially interesting either when the input graph does not fit in memory or is dynamically generated. To evaluate the properties of pipeline, a dynamic pipeline of processes and
an ad-hoc version of MapReduce are implemented in the language Go, exploiting its ability to deal with channels and spawned processes. An empirical evaluation is conducted on graphs of different topologies, sizes, and densities. Observed results suggest that pipeline allows for the implementation of an efficient solution of the problem of counting triangles in a graph, particularly, in dense and large graphs, drastically reducing the execution time with respect to the MapReduce implementation.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2283</post_id>
		<post_date><![CDATA[2016-09-08 14:45:55]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:45:55]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[comparing-mapreduce-and-pipeline-implementations-for-counting-triangles]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[10]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2284]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A common method to define a parallel solution for a computational problem consists in finding a way to use the Divide & Conquer paradigm in order to have processors acting on its own data and scheduled in a parallel fashion. MapReduce is a programming model that follows this paradigm,
and allows for the definition of efficient solutions by both decomposing a problem into steps on subsets of the input data and combining the results of each step to produce final results. Albeit used for the implementation of a wide variety of computational problems, MapReduce performance
can be negatively affected whenever the replication factor grows or the size of the input is larger than the resources available at each processor. In this paper we show an alternative approach to implement the Divide & Conquer paradigm, named dynamic pipeline. The main features of pipeline
are illustrated on a parallel implementation of the well-known problem of counting triangles in a graph. This problem is especially interesting either when the input graph does not fit in memory or is dynamically generated. To evaluate the properties of pipeline, a dynamic pipeline of processes and
an ad-hoc version of MapReduce are implemented in the language Go, exploiting its ability to deal with channels and spawned processes. An empirical evaluation is conducted on graphs of different topologies, sizes, and densities. Observed results suggest that pipeline allows for the implementation of an efficient solution of the problem of counting triangles in a graph, particularly, in dense and large graphs, drastically reducing the execution time with respect to the MapReduce implementation.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Edelmira Pasarella]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Computer Science Department. Universitat Politècnica de Catalunya, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[edelmira@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Maria-Esther Vidal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Bonn & Fraunhofer IAIS, Germany / Universidad Simón Bolívar, Venezuela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[vidal@cs.uni-bonn.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Cristina Zoltan]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Computer Science Department. Universitat Politècnica de Catalunya, Spain / Universidad Internacional de Ciencia y Tecnología, Panamá]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[zoltan@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/013]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Synthesizing Invariants for Arrays (Work in Progress)</title>
		<link>https://biblioteca.sistedes.es/articulo/synthesizing-invariants-for-arrays-work-in-progress/</link>
		<pubDate>Thu, 08 Sep 2016 12:48:52 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2286</guid>
		<description></description>
		<content><![CDATA[Liquid types can be seen as as a computer assisted verification system. Ordinary Hindley-Milner types are qualified by predicates expressing properties. In this way, the programmer may specify the preconditions and postconditions of functions. More importantly, the system infers the types of all the intermediate variables and checks that the verification conditions proving correctness hold. The predicates are currently expressed in a quantifier free decidable logic.
Here, we extend Liquid types with quantified predicates of a decidable logic for arrays, propose a concept of an array refinement type, and provide an inference algorithm for this extension. By applying this ideas to several imperative algorithms dealing with arrays, we have been able to infer
complex invariants.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2286</post_id>
		<post_date><![CDATA[2016-09-08 14:48:52]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:48:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[synthesizing-invariants-for-arrays-work-in-progress]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2287]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Liquid types can be seen as as a computer assisted verification system. Ordinary Hindley-Milner types are qualified by predicates expressing properties. In this way, the programmer may specify the preconditions and postconditions of functions. More importantly, the system infers the types of all the intermediate variables and checks that the verification conditions proving correctness hold. The predicates are currently expressed in a quantifier free decidable logic.
Here, we extend Liquid types with quantified predicates of a decidable logic for arrays, propose a concept of an array refinement type, and provide an inference algorithm for this extension. By applying this ideas to several imperative algorithms dealing with arrays, we have been able to infer
complex invariants.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel Montenegro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Complutense University of Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[montenegro@fdi.ucm.es,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Susana Nieva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Complutense University of Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[nieva@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ricardo Peña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Complutense University of Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ricardo@sip.ucm.es,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Clara Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Complutense University of Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[csegura@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/024]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Processing an Intermediate Representation Written in Lisp</title>
		<link>https://biblioteca.sistedes.es/articulo/processing-an-intermediate-representation-written-in-lisp/</link>
		<pubDate>Thu, 08 Sep 2016 12:51:15 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2289</guid>
		<description></description>
		<content><![CDATA[In the context of designing the verification platform CAVI-ART, we arrived to the need of deciding a textual format for our intermediate representation of programs. After considering several options, we finally decided to use S-expressions for that textual representation, and Common Lisp for processing it in order to obtain the verification conditions. In this paper, we discuss the benefits of this decision. S-expressions are homoiconic, i.e. they can be both considered as data and as code. We exploit this duality, and extensively use the facilities of the Common Lisp environment to make different processing with these textual representations. In particular, using a common compilation scheme we
show that program execution, and verification condition generation, can be seen as two instantiations of the same generic process.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2289</post_id>
		<post_date><![CDATA[2016-09-08 14:51:15]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:51:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[processing-an-intermediate-representation-written-in-lisp]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2290]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In the context of designing the verification platform CAVI-ART, we arrived to the need of deciding a textual format for our intermediate representation of programs. After considering several options, we finally decided to use S-expressions for that textual representation, and Common Lisp for processing it in order to obtain the verification conditions. In this paper, we discuss the benefits of this decision. S-expressions are homoiconic, i.e. they can be both considered as data and as code. We exploit this duality, and extensively use the facilities of the Common Lisp environment to make different processing with these textual representations. In particular, using a common compilation scheme we
show that program execution, and verification condition generation, can be seen as two instantiations of the same generic process.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ricardo Peña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Complutense University of Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ricardo@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Santiago Saavedra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Complutense University of Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[s.saavedra@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[ Jaime Sánchez-Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Complutense University of Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jaime@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/019]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A tool for the automatic generation of logical models of order-sorted first-order theories</title>
		<link>https://biblioteca.sistedes.es/articulo/a-tool-for-the-automatic-generation-of-logical-models-of-order-sorted-first-order-theories/</link>
		<pubDate>Thu, 08 Sep 2016 12:53:40 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2292</guid>
		<description></description>
		<content><![CDATA[Semantics-based program analysis guarantees that the obtained knowledge about focused program features matches the real behaviour of the program. Automation of the analyses requires abstraction mechanisms to approximate the (usually undecidable) program semantics and targeted properties. In this setting, the logical notions of interpretation of a logic language and model of a theory provide an appropriate framework for abstraction in the sense that the corresponding analyses will be sound and, when relying on some decidable theory, amenable for automation. We describe a new tool, AGES, which is able to automatically generate models for order-sorted first-order theories. Such theories are very helpful in the semantic description of most programming languages. The current version of the tool systematically exploits (and relies on) the recently introduced convex domains which are well-suited for representing domains for different sorts; we use them to interpret the ranked symbols of order-sorted signatures and also the (also ranked) predicate symbols in the language by means of appropriately adapted convex matrix interpretations. The system is available as a web application and can be used to give support to users interested in checking properties of software modules provided
that they are able to describe the property as an order-sorted first-order theory whose satisfiability guarantees the property. Examples of such properties are partial correctness, program termination, etc. The paper illustrates the use of the tool by means of simple case studies.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2292</post_id>
		<post_date><![CDATA[2016-09-08 14:53:40]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:53:40]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-tool-for-the-automatic-generation-of-logical-models-of-order-sorted-first-order-theories]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<category domain="post_tag" nicename="abstraction"><![CDATA[Abstraction]]></category>
		<category domain="post_tag" nicename="logical-models"><![CDATA[Logical models]]></category>
		<category domain="post_tag" nicename="order-sorted-first-order-logic"><![CDATA[Order-sorted first-order logic]]></category>
		<category domain="post_tag" nicename="program-analysis"><![CDATA[Program analysis]]></category>
		<category domain="post_tag" nicename="termination"><![CDATA[termination]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2293]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Semantics-based program analysis guarantees that the obtained knowledge about focused program features matches the real behaviour of the program. Automation of the analyses requires abstraction mechanisms to approximate the (usually undecidable) program semantics and targeted properties. In this setting, the logical notions of interpretation of a logic language and model of a theory provide an appropriate framework for abstraction in the sense that the corresponding analyses will be sound and, when relying on some decidable theory, amenable for automation. We describe a new tool, AGES, which is able to automatically generate models for order-sorted first-order theories. Such theories are very helpful in the semantic description of most programming languages. The current version of the tool systematically exploits (and relies on) the recently introduced convex domains which are well-suited for representing domains for different sorts; we use them to interpret the ranked symbols of order-sorted signatures and also the (also ranked) predicate symbols in the language by means of appropriately adapted convex matrix interpretations. The system is available as a web application and can be used to give support to users interested in checking properties of software modules provided
that they are able to describe the property as an order-sorted first-order theory whose satisfiability guarantees the property. Examples of such properties are partial correctness, program termination, etc. The paper illustrates the use of the tool by means of simple case studies.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Raúl Gutiérrez  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Salvador Lucas  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Patricio Reinoso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DSIC, Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/018]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Abstraction, Logical models, Order-sorted first-order logic, Program analysis, Termination]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>How to construct a suite of program slices</title>
		<link>https://biblioteca.sistedes.es/articulo/how-to-construct-a-suite-of-program-slices/</link>
		<pubDate>Thu, 08 Sep 2016 12:55:48 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2295</guid>
		<description></description>
		<content><![CDATA[Program slicing is a technique to extract the part of a program (the slice) that influences or is influenced by a set of variables at a given point. Computing minimal slices is undecidable in the general case. Obtaining the minimal slice of a given program is computationally prohibitive even for very small programs. Hence, no matter what program slicer we use, in general, we cannot be sure that our slices are minimal. This is probably the fundamental reason why no benchmark collection of minimal program slices exists, even though this would be of great interest. In this work, we present the first suite of quasi-minimal slices (i.e., we cannot prove that they are minimal, but we provide technological evidences, based on different techniques, that they probably are). We explain the process of constructing the suite, the methodology and tools that were used, and the obtained results. The suite comes with a collection of Erlang benchmarks together with different slicing criteria and the associated quasi-minimal slices. This suite can be used to evaluate and compare program slicers, but it is particularly useful to develop slicers, because it contains scripts that allow for automatically validating a slicer against the whole suite. Concretely, these scripts produce reports about the impact on recall and precision of any change done during the development of the slicer.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2295</post_id>
		<post_date><![CDATA[2016-09-08 14:55:48]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:55:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[how-to-construct-a-suite-of-program-slices]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2296]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Program slicing is a technique to extract the part of a program (the slice) that influences or is influenced by a set of variables at a given point. Computing minimal slices is undecidable in the general case. Obtaining the minimal slice of a given program is computationally prohibitive even for very small programs. Hence, no matter what program slicer we use, in general, we cannot be sure that our slices are minimal. This is probably the fundamental reason why no benchmark collection of minimal program slices exists, even though this would be of great interest. In this work, we present the first suite of quasi-minimal slices (i.e., we cannot prove that they are minimal, but we provide technological evidences, based on different techniques, that they probably are). We explain the process of constructing the suite, the methodology and tools that were used, and the obtained results. The suite comes with a collection of Erlang benchmarks together with different slicing criteria and the associated quasi-minimal slices. This suite can be used to evaluate and compare program slicers, but it is particularly useful to develop slicers, because it contains scripts that allow for automatically validating a slicer against the whole suite. Concretely, these scripts produce reports about the impact on recall and precision of any change done during the development of the slicer.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Insa  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación. Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[dinsa@dsic.upv.es  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Sergio Pérez  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación. Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ serperu@dsic.upv.es  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[ Josep Silva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación. Universitat Politècnica de València, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ jsilva@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/021]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Testing of ATL programs from Randomly Generated Ecore Test Models</title>
		<link>https://biblioteca.sistedes.es/articulo/testing-of-atl-programs-from-randomly-generated-ecore-test-models/</link>
		<pubDate>Thu, 08 Sep 2016 12:58:10 +0000</pubDate>
		<creator><![CDATA[avillanueva]]></creator>
		<guid isPermaLink="false">http://biblioteca.sistedes.es/?post_type=articulo&#038;p=2298</guid>
		<description></description>
		<content><![CDATA[Model transformation testing is crucial to detect incorrect transformations. Buggy transformations can lead to incorrect target models, either violating target meta-model requirements or more complex target model properties. In this paper we present a tool for testing ATL transformations. This tool is an extension of a previously developed tool for testing XML-based languages. With this aim an Ecore to XML Schema transformation is defined which makes to automatically generate random Ecore models possible. These randomly generated Ecore models are used to test ATL transformations. Properties to be tested are specified by OCL constraints, describing input and output conditions on source and target models, respectively.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2298</post_id>
		<post_date><![CDATA[2016-09-08 14:58:10]]></post_date>
		<post_date_gmt><![CDATA[2016-09-08 12:58:10]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[testing-of-atl-programs-from-randomly-generated-ecore-test-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-avillanueva"><![CDATA[avillanueva]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2299]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Model transformation testing is crucial to detect incorrect transformations. Buggy transformations can lead to incorrect target models, either violating target meta-model requirements or more complex target model properties. In this paper we present a tool for testing ATL transformations. This tool is an extension of a previously developed tool for testing XML-based languages. With this aim an Ecore to XML Schema transformation is defined which makes to automatically generate random Ecore models possible. These randomly generated Ecore models are used to test ATL transformations. Properties to be tested are specified by OCL constraints, describing input and output conditions on source and target models, respectively.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús M. Almendros-Jiménez ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dept. of Informatics. University of Almería, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalmen@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Antonio Becerra-Terón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[￼ Dept. of Informatics. University of Almería, Spain ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[abecerra@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2016/012]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Partial Evaluation of Order-sorted Equational Programs modulo Axioms (Trabajo de alto nivel)</title>
		<link>https://biblioteca.sistedes.es/articulo/partial-evaluation-of-order-sorted-equational-programs-modulo-axioms-trabajo-de-alto-nivel/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/partial-evaluation-of-order-sorted-equational-programs-modulo-axioms-trabajo-de-alto-nivel/</guid>
		<description></description>
		<content><![CDATA[Partial evaluation (PE) is a powerful and general program optimization
technique with many successful applications. However, it has never been investigated
in the context of expressive rule-based languages like Maude, CafeOBJ,
OBJ, ASF+SDF, and ELAN, which support: rich type structures with sorts, subsorts
and overloading; and equational rewriting modulo axioms such as commutativity,
associativity–commutativity, and associativity–commutativity–identity. In
this paper, we illustrate the key concepts by showing how they apply to partial
evaluation of expressive rule-based programs written in Maude. Our partial evaluation
scheme is based on an automatic unfolding algorithm that computes term
variants and relies on equational least general generalization for ensuring global
termination. We demonstrate the use of the resulting partial evaluator for program
optimization on several examples where it shows significant speed-ups.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2454</post_id>
		<post_date><![CDATA[2017-06-30 02:55:48]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[partial-evaluation-of-order-sorted-equational-programs-modulo-axioms-trabajo-de-alto-nivel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="equational-rewriting-modulo-axioms"><![CDATA[Equational Rewriting modulo Axioms]]></category>
		<category domain="post_tag" nicename="maude"><![CDATA[Maude]]></category>
		<category domain="post_tag" nicename="partial-evaluation"><![CDATA[Partial Evaluation]]></category>
		<category domain="post_tag" nicename="rewriting-logic"><![CDATA[Rewriting Logic]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Partial evaluation (PE) is a powerful and general program optimization
technique with many successful applications. However, it has never been investigated
in the context of expressive rule-based languages like Maude, CafeOBJ,
OBJ, ASF+SDF, and ELAN, which support: rich type structures with sorts, subsorts
and overloading; and equational rewriting modulo axioms such as commutativity,
associativity–commutativity, and associativity–commutativity–identity. In
this paper, we illustrate the key concepts by showing how they apply to partial
evaluation of expressive rule-based programs written in Maude. Our partial evaluation
scheme is based on an automatic unfolding algorithm that computes term
variants and relies on equational least general generalization for ensuring global
termination. We demonstrate the use of the resulting partial evaluator for program
optimization on several examples where it shows significant speed-ups.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/007]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2856]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498591532.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Alpuente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alpuente@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Angel Cuenca-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[acuenca@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Universidad de Guayaquil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Santiago	Escobar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sescobar@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José Meseguer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[meseguer@cs.uiuc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Illinois at Urbana-Champaign]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Built-in Variant Generation and Unification, and Their Applications in Maude 2.7 (Tutorial)</title>
		<link>https://biblioteca.sistedes.es/articulo/built-in-variant-generation-and-unification-and-their-applications-in-maude-2-7-tutorial/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/built-in-variant-generation-and-unification-and-their-applications-in-maude-2-7-tutorial/</guid>
		<description></description>
		<content><![CDATA[This paper introduces some novel features of Maude 2.7. We have added support for: (i) built-in order-sorted unification modulo associativity, commutativity, and identity, (ii) built-in variant generation, (iii) built-in order-sorted unification modulo a finite variant theory, and (iv) symbolic reachability modulo a finite variant theory.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2455</post_id>
		<post_date><![CDATA[2017-06-30 02:55:49]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[built-in-variant-generation-and-unification-and-their-applications-in-maude-2-7-tutorial]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="associativity-commutativity-and-identity"><![CDATA[associativity commutativity and identity]]></category>
		<category domain="post_tag" nicename="maude"><![CDATA[Maude]]></category>
		<category domain="post_tag" nicename="narrowing"><![CDATA[narrowing]]></category>
		<category domain="post_tag" nicename="order-sorted"><![CDATA[Order-sorted]]></category>
		<category domain="post_tag" nicename="unification"><![CDATA[unification]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper introduces some novel features of Maude 2.7. We have added support for: (i) built-in order-sorted unification modulo associativity, commutativity, and identity, (ii) built-in variant generation, (iii) built-in order-sorted unification modulo a finite variant theory, and (iv) symbolic reachability modulo a finite variant theory.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/010]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2857]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498592286.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Durán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[duran@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Steven Eker]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[eker@csl.sri.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[SRI International]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Santiago	Escobar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sescobar@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Narciso Martí-Oliet]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[narciso@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[José Meseguer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[meseguer@cs.uiuc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Illinois at Urbana-Champaign]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Carolyn Talcott]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[clt@cs.stanford.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[SRI International]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Description and Evaluation of a Generic Design to Integrate CLP and Tabled Execution (Trabajo de alto nivel)</title>
		<link>https://biblioteca.sistedes.es/articulo/description-and-evaluation-of-a-generic-design-to-integrate-clp-and-tabled-execution-trabajo-de-alto-nivel/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/description-and-evaluation-of-a-generic-design-to-integrate-clp-and-tabled-execution-trabajo-de-alto-nivel/</guid>
		<description></description>
		<content><![CDATA[Logic programming systems with tabling and constraints (TCLP, tabled constraint logic
programming) have been shown to be more expressive and in some cases more efficient
than those featuring only either tabling or constraints. Previous implementations of TCLP
systems which use entailment to determine call / answer subsumption did not provide a
simple, uniform, and well-documented interface to facilitate the integration of additional
constraint solvers in existing tabling systems, which would increase the application range of
TCLP. We present the design and an experimental evaluation of Mod TCLP, a framework
which eases this integration. Mod TCLP views the constraints solver as a client of the tabling
system. The tabling system is generic w.r.t. the constraint solver and only requires a clear,
small interface from the latter. We validate our design by integrating four constraint solvers:
a re-engineered version of a previously existing constraint solver for difference constraints,
written in C; the standard versions of Holzbauer’s CLP(Q) and CLP(R), written in Prolog;
and a new constraint solver for equations over finite lattices. We evaluate the performance
of our framework in several benchmarks using the aforementioned constraint solvers. All
the development work and evaluation was done in Ciao Prolog.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2456</post_id>
		<post_date><![CDATA[2017-06-30 02:55:50]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[description-and-evaluation-of-a-generic-design-to-integrate-clp-and-tabled-execution-trabajo-de-alto-nivel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="constraints"><![CDATA[constraints]]></category>
		<category domain="post_tag" nicename="implementation"><![CDATA[Implementation]]></category>
		<category domain="post_tag" nicename="interface"><![CDATA[Interface]]></category>
		<category domain="post_tag" nicename="prolog"><![CDATA[Prolog]]></category>
		<category domain="post_tag" nicename="tabling"><![CDATA[Tabling]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Logic programming systems with tabling and constraints (TCLP, tabled constraint logic
programming) have been shown to be more expressive and in some cases more efficient
than those featuring only either tabling or constraints. Previous implementations of TCLP
systems which use entailment to determine call / answer subsumption did not provide a
simple, uniform, and well-documented interface to facilitate the integration of additional
constraint solvers in existing tabling systems, which would increase the application range of
TCLP. We present the design and an experimental evaluation of Mod TCLP, a framework
which eases this integration. Mod TCLP views the constraints solver as a client of the tabling
system. The tabling system is generic w.r.t. the constraint solver and only requires a clear,
small interface from the latter. We validate our design by integrating four constraint solvers:
a re-engineered version of a previously existing constraint solver for difference constraints,
written in C; the standard versions of Holzbauer’s CLP(Q) and CLP(R), written in Prolog;
and a new constraint solver for equations over finite lattices. We evaluate the performance
of our framework in several benchmarks using the aforementioned constraint solvers. All
the development work and evaluation was done in Ciao Prolog.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/016]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498592587.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498592587.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Joaquín Arias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[joaquin.arias@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid e IMDEA Software]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Carro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mcarro@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid e IMDEA Software]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>FuzzyDES: Fuzzifying DES (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/fuzzydes-fuzzifying-des-trabajo-en-progreso/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/fuzzydes-fuzzifying-des-trabajo-en-progreso/</guid>
		<description></description>
		<content><![CDATA[This paper describes a system implementation of a fuzzy deductive database. Concepts supporting the fuzzy logic programming system BPL are translated into the deductive database system DES. We develop a version of fuzzy Datalog as its query language, where programs and queries are compiled to the DES core Datalog language. Weak unification and weak SLD resolution are adapted to this setting, and extended to allow rules with truth degree annotations. We provide a public implementation in Prolog which is open-source, multiplatform, portable, and in-memory. A database example for a recommender system is used to illustrate some of the features of the system.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2457</post_id>
		<post_date><![CDATA[2017-06-30 02:55:50]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[fuzzydes-fuzzifying-des-trabajo-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="bousiprolog"><![CDATA[Bousi~Prolog]]></category>
		<category domain="post_tag" nicename="datalog-educational-system"><![CDATA[Datalog Educational System]]></category>
		<category domain="post_tag" nicename="fuzzy-datalog"><![CDATA[Fuzzy Datalog]]></category>
		<category domain="post_tag" nicename="fuzzy-logic-programming"><![CDATA[Fuzzy Logic Programming]]></category>
		<category domain="post_tag" nicename="fuzzydes"><![CDATA[FuzzyDES]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper describes a system implementation of a fuzzy deductive database. Concepts supporting the fuzzy logic programming system BPL are translated into the deductive database system DES. We develop a version of fuzzy Datalog as its query language, where programs and queries are compiled to the DES core Datalog language. Weak unification and weak SLD resolution are adapted to this setting, and extended to allow rules with truth degree annotations. We provide a public implementation in Prolog which is open-source, multiplatform, portable, and in-memory. A database example for a recommender system is used to illustrate some of the features of the system.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/004]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498603725.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498603725.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pascual Julián-Iranzo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Pascual.Julian@uclm.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando	Sáenz-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fernan@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Tuning Fuzzy Logic Programs with Symbolic Execution (Trabajo de alto nivel)</title>
		<link>https://biblioteca.sistedes.es/articulo/tuning-fuzzy-logic-programs-with-symbolic-execution-trabajo-de-alto-nivel/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/tuning-fuzzy-logic-programs-with-symbolic-execution-trabajo-de-alto-nivel/</guid>
		<description></description>
		<content><![CDATA[Fuzzy logic programming is a growing declarative paradigm aiming to integrate fuzzy logic into logic programming. One of the most difficult tasks when specifying a fuzzy logic program is determining the right weights for each rule, as well as the most appropriate fuzzy connectives and operators. In this paper, we introduce a symbolic extension of fuzzy logic programs in which some of these parameters can be left unknown, so that the user can easily see the impact of their possible values. Furthermore, given a number of test cases, the most appropriate values for these parameters can be automatically computed.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2458</post_id>
		<post_date><![CDATA[2017-06-30 02:55:50]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[tuning-fuzzy-logic-programs-with-symbolic-execution-trabajo-de-alto-nivel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="fuzzy-logic-programming"><![CDATA[Fuzzy Logic Programming]]></category>
		<category domain="post_tag" nicename="symbolic-execution"><![CDATA[symbolic execution]]></category>
		<category domain="post_tag" nicename="tuning"><![CDATA[tuning]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Fuzzy logic programming is a growing declarative paradigm aiming to integrate fuzzy logic into logic programming. One of the most difficult tasks when specifying a fuzzy logic program is determining the right weights for each rule, as well as the most appropriate fuzzy connectives and operators. In this paper, we introduce a symbolic extension of fuzzy logic programs in which some of these parameters can be left unknown, so that the user can easily see the impact of their possible values. Furthermore, given a number of test cases, the most appropriate values for these parameters can be automatically computed.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/005]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498593173.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498593173.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ginés Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[gines.moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jaime Penabab]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Jaime.Penabab@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Germán Vidal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gvidal@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politecnica de Valencia	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Simulation Tool for tccp Programs (Trabajo de alto nivel)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-simulation-tool-for-tccp-programs-trabajo-de-alto-nivel/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-simulation-tool-for-tccp-programs-trabajo-de-alto-nivel/</guid>
		<description></description>
		<content><![CDATA[The Timed Concurrent Constraint Language tccp is a declarative synchronous concurrent language, particularly suitable for modelling reactive systems. In tccp, agents communicate and synchronise through a global constraint store. It supports a notion of discrete time that allows all non-blocked agents to proceed with their execution simultaneously.
In this paper, we present a modular architecture for the simulation of tccp programs. The tool comprises three main components. First, a set of basic abstract instructions able to model the tccp agent behaviour, the memory model needed to manage the active agents and the state of the store during the execution. Second, the agent interpreter that executes the instructions of the current agent iteratively and calculates the new agents to be executed at the next time instant. Finally, the constraint solver components which are the modules that deal with constraints.
In this paper, we describe the implementation of these components and present an example of a real system modelled in tccp.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2459</post_id>
		<post_date><![CDATA[2017-06-30 02:55:50]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-simulation-tool-for-tccp-programs-trabajo-de-alto-nivel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="abstract-tccp-instructions"><![CDATA[Abstract tccp instructions]]></category>
		<category domain="post_tag" nicename="simulation-tool"><![CDATA[Simulation tool]]></category>
		<category domain="post_tag" nicename="timed-concurrent-constraint-language-tccp"><![CDATA[Timed Concurrent Constraint Language (tccp)]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The Timed Concurrent Constraint Language tccp is a declarative synchronous concurrent language, particularly suitable for modelling reactive systems. In tccp, agents communicate and synchronise through a global constraint store. It supports a notion of discrete time that allows all non-blocked agents to proceed with their execution simultaneously.
In this paper, we present a modular architecture for the simulation of tccp programs. The tool comprises three main components. First, a set of basic abstract instructions able to model the tccp agent behaviour, the memory model needed to manage the active agents and the state of the store during the execution. Second, the agent interpreter that executes the instructions of the current agent iteratively and calculates the new agents to be executed at the next time instant. Finally, the constraint solver components which are the modules that deal with constraints.
In this paper, we describe the implementation of these components and present an example of a real system modelled in tccp.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/009]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498593348.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498593348.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María del Mar Gallardo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[gallardo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Leticia Lavado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[leticialavmu@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Laura Panizo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[laurapanizo@lcc.uma.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Tool for Black-Box Testing in a Multilanguage Verification Platform (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-tool-for-black-box-testing-in-a-multilanguage-verification-platform-trabajo-en-progreso/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-tool-for-black-box-testing-in-a-multilanguage-verification-platform-trabajo-en-progreso/</guid>
		<description></description>
		<content><![CDATA[In the context of the multilanguage verification platform CAVI-ART, we have defined an Intermediate Representation (IR) to which all the source languages are translated. This IR contains both the code and the assertions given by the programmer. Its primary purpose was automatically generating and proving, in a source language independent way, the verification conditions ensuring the program correctness. The logical formulas are sent by the platform to an SMT solver which checks their validity.

In this paper we present a new use of the IR: we transform it into an executable language (that it turns out to be Haskell) and also transform the assertions into executable (Haskell) code. Thanks to that, tests can be run on the transformed program, and bugs can be detected either in the specification assertions or in the code. Moreover, we use the assertions to generate black-box test-cases from them, and also as test oracles. In this way, given the IR of a program, all the process ---namely, test-case generation, test running, and test correctness checking--- is completely automatic. So, thousands of tests can be run with little or none effort. The only burden for the programmer is providing the precondition and the postcondition of the code under test, which anyway should have been provided in advance, since the primary goal was to verify the program.

We discuss the problems we have encountered while implementing this idea, and how we have solved them. In particular, we report on the use of Haskell resources such as GADTs, efficient data structures, and specialized libraries.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2460</post_id>
		<post_date><![CDATA[2017-06-30 02:55:50]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-tool-for-black-box-testing-in-a-multilanguage-verification-platform-trabajo-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="black-box"><![CDATA[black box]]></category>
		<category domain="post_tag" nicename="executable-assertions"><![CDATA[executable assertions]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<category domain="post_tag" nicename="verification-platform"><![CDATA[verification platform]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In the context of the multilanguage verification platform CAVI-ART, we have defined an Intermediate Representation (IR) to which all the source languages are translated. This IR contains both the code and the assertions given by the programmer. Its primary purpose was automatically generating and proving, in a source language independent way, the verification conditions ensuring the program correctness. The logical formulas are sent by the platform to an SMT solver which checks their validity.

In this paper we present a new use of the IR: we transform it into an executable language (that it turns out to be Haskell) and also transform the assertions into executable (Haskell) code. Thanks to that, tests can be run on the transformed program, and bugs can be detected either in the specification assertions or in the code. Moreover, we use the assertions to generate black-box test-cases from them, and also as test oracles. In this way, given the IR of a program, all the process ---namely, test-case generation, test running, and test correctness checking--- is completely automatic. So, thousands of tests can be run with little or none effort. The only burden for the programmer is providing the precondition and the postcondition of the code under test, which anyway should have been provided in advance, since the primary goal was to verify the program.

We discuss the problems we have encountered while implementing this idea, and how we have solved them. In particular, we report on the use of Haskell resources such as GADTs, efficient data structures, and specialized libraries.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/001]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Marta Aracil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[maracil@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pedro García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pegarc03@ucm.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ricardo Peña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ricardo@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Termination Analysis in a Multi-language Verification Platform (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/termination-analysis-in-a-multi-language-verification-platform-trabajo-en-progreso/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/termination-analysis-in-a-multi-language-verification-platform-trabajo-en-progreso/</guid>
		<description></description>
		<content><![CDATA[One aim of the verification platform CAVI-ART is to provide as much assistance as possible to programmers in order to alleviate their verification effort. One of these aids is automatically proving termination of programs, whenever this is possible. Since CAVI-ART is a multi-language platform, the analysis is performed at the level of the platform Intermediate Representation language (IR), to which all source languages are first translated.

We have selected one of the the most successful termination tools, called RANK, and transform our IR-programs to an appropriate input for RANK. There is a fundamental mismatch between the functional, stateless, recursive flavour of our IR, and the automaton-based input of RANK, which is a tool developed for imperative, mutable-state programs. In this paper we show how we have circumvented this problem, and present an algorithm transforming the IR to an automaton. We give some examples of recursive programs that we have successfully proved terminating.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2461</post_id>
		<post_date><![CDATA[2017-06-30 02:55:50]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[termination-analysis-in-a-multi-language-verification-platform-trabajo-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="integer-automata"><![CDATA[integer automata]]></category>
		<category domain="post_tag" nicename="termination-analysis"><![CDATA[Termination analysis]]></category>
		<category domain="post_tag" nicename="verification-platform"><![CDATA[verification platform]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[One aim of the verification platform CAVI-ART is to provide as much assistance as possible to programmers in order to alleviate their verification effort. One of these aids is automatically proving termination of programs, whenever this is possible. Since CAVI-ART is a multi-language platform, the analysis is performed at the level of the platform Intermediate Representation language (IR), to which all source languages are first translated.

We have selected one of the the most successful termination tools, called RANK, and transform our IR-programs to an appropriate input for RANK. There is a fundamental mismatch between the functional, stateless, recursive flavour of our IR, and the automaton-based input of RANK, which is a tool developed for imperative, mutable-state programs. In this paper we show how we have circumvented this problem, and present an algorithm transforming the IR to an automaton. We give some examples of recursive programs that we have successfully proved terminating.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/014]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499160980.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jakub Holubanský]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jakubhol@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Álvaro Mínguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[alvaming@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ricardo Peña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ricardo@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Type Checking and Testing of SPARQL Queries (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/type-checking-and-testing-of-sparql-queries-trabajo-en-progreso/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/type-checking-and-testing-of-sparql-queries-trabajo-en-progreso/</guid>
		<description></description>
		<content><![CDATA[In this paper we describe a property-based testing tool for SPARQL. The tool randomly generates test cases in the form of instances of an ontology. The tool checks the well typed-ness of the SPARQL query as well as the consistency of the test cases with the ontology axioms. With this aim, a type system has been defined for SPARQL. Test cases are after used to execute queries. The output of the queries are tested with a Boolean property which is defined in terms of membership of ontology individuals to classes. The testing tool reports counterexamples when the Boolean property is not satisfied.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2462</post_id>
		<post_date><![CDATA[2017-06-30 02:55:50]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[type-checking-and-testing-of-sparql-queries-trabajo-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="semantic-web"><![CDATA[Semantic Web]]></category>
		<category domain="post_tag" nicename="sparql"><![CDATA[SPARQL]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<category domain="post_tag" nicename="type-systems"><![CDATA[Type Systems]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper we describe a property-based testing tool for SPARQL. The tool randomly generates test cases in the form of instances of an ontology. The tool checks the well typed-ness of the SPARQL query as well as the consistency of the test cases with the ontology axioms. With this aim, a type system has been defined for SPARQL. Test cases are after used to execute queries. The output of the queries are tested with a Boolean property which is defined in terms of membership of ontology individuals to classes. The testing tool reports counterexamples when the Boolean property is not satisfied.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/002]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498593875.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498593875.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús M. Almendros-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalmen@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Becerra-Terón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[abecerra@ual.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>FSA-SPARQL: Fuzzy Queries in SPARQL (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/fsa-sparql-fuzzy-queries-in-sparql-trabajo-en-progreso/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/fsa-sparql-fuzzy-queries-in-sparql-trabajo-en-progreso/</guid>
		<description></description>
		<content><![CDATA[SPARQL has been adopted as query language for the Semantic Web. RDF and OWL have been also established as vocabularies to describe ontologies in this setting. While RDF/OWL/SPARQL have been designed for querying crisp information, some contexts require to manage uncertainty, vagueness and imprecise knowledge. In this paper we propose a SPARQL extension, called FSA-SPARQL (Fuzzy Sets and Aggregators based SPARQL) in which queries can involve different fuzzy connectives and (aggregation) operators. The language has been implemented as an extension of the ARQ Jena SPARQL engine and it is equipped with a Web tool from which queries can be executed on-line.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2463</post_id>
		<post_date><![CDATA[2017-06-30 02:55:51]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[fsa-sparql-fuzzy-queries-in-sparql-trabajo-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="fuzzy-logic"><![CDATA[Fuzzy Logic]]></category>
		<category domain="post_tag" nicename="semantic-web"><![CDATA[Semantic Web]]></category>
		<category domain="post_tag" nicename="sparql"><![CDATA[SPARQL]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[SPARQL has been adopted as query language for the Semantic Web. RDF and OWL have been also established as vocabularies to describe ontologies in this setting. While RDF/OWL/SPARQL have been designed for querying crisp information, some contexts require to manage uncertainty, vagueness and imprecise knowledge. In this paper we propose a SPARQL extension, called FSA-SPARQL (Fuzzy Sets and Aggregators based SPARQL) in which queries can involve different fuzzy connectives and (aggregation) operators. The language has been implemented as an extension of the ARQ Jena SPARQL engine and it is equipped with a Web tool from which queries can be executed on-line.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/006]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498601637.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498601637.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús M. Almendros-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalmen@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Becerra-Terón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[abecerra@ual.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ginés Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gines.moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Use of logical models for proving operational termination in general logics (Tutorial)</title>
		<link>https://biblioteca.sistedes.es/articulo/use-of-logical-models-for-proving-operational-termination-in-general-logics-tutorial/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/use-of-logical-models-for-proving-operational-termination-in-general-logics-tutorial/</guid>
		<description></description>
		<content><![CDATA[A declarative programming language is based on some logic L and its operational semantics is given by a proof calculus which is often presented in a natural deduction style by means of inference rules. Declarative programs are theories S of L and executing a program is proving goals G in the inference system I(S) associated to S as a particularization of the inference system of the logic. The usual soundness assumption for L implies that every model M of S also satisfies G. In this setting, the operational termination of a declarative program is quite naturally defined as the absence of infinite proof trees in the inference system I(S). Proving operational termination of declarative programs often involves two main ingredients: (i) the generation of logical models M to abstract the program execution (i.e., the provability of specific goals in I(S)), and (ii) the use of well-founded relations to guarantee the absence of infinite branches in proof trees and hence of infinite proof trees, possibly taking into account the information about provability encoded by M. In this paper we show how to deal with (i) and (ii) in a uniform way. The main point is the synthesis of logical models where well-foundedness is a side requirement for some specific predicate symbols.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2464</post_id>
		<post_date><![CDATA[2017-06-30 02:55:51]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[use-of-logical-models-for-proving-operational-termination-in-general-logics-tutorial]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="abstraction"><![CDATA[Abstraction]]></category>
		<category domain="post_tag" nicename="logical-models"><![CDATA[Logical models]]></category>
		<category domain="post_tag" nicename="operational-termination"><![CDATA[Operational Termination]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A declarative programming language is based on some logic L and its operational semantics is given by a proof calculus which is often presented in a natural deduction style by means of inference rules. Declarative programs are theories S of L and executing a program is proving goals G in the inference system I(S) associated to S as a particularization of the inference system of the logic. The usual soundness assumption for L implies that every model M of S also satisfies G. In this setting, the operational termination of a declarative program is quite naturally defined as the absence of infinite proof trees in the inference system I(S). Proving operational termination of declarative programs often involves two main ingredients: (i) the generation of logical models M to abstract the program execution (i.e., the provability of specific goals in I(S)), and (ii) the use of well-founded relations to guarantee the absence of infinite branches in proof trees and hence of infinite proof trees, possibly taking into account the information about provability encoded by M. In this paper we show how to deal with (i) and (ii) in a uniform way. The main point is the synthesis of logical models where well-foundedness is a side requirement for some specific predicate symbols.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/015]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498601913.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498601913.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Lucas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[slucas@dsic.upv.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Some applications of context-sensitive rewriting (Tutorial)</title>
		<link>https://biblioteca.sistedes.es/articulo/some-applications-of-context-sensitive-rewriting-tutorial/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/some-applications-of-context-sensitive-rewriting-tutorial/</guid>
		<description></description>
		<content><![CDATA[The appropriate selection of the arguments of functions that can be evaluated in function calls improves the evaluation of such calls in a number of different ways: efficiency, speed, termination behavior, etc. This is essential in the conditional if-then-else operator. Other operators like sequencing (;) or choice (+) that are used in concurrent and/or imperative languages require a similar treatment. The (lazy) list constructor 'cons' of functional languages is another well-known example. At the syntactic level we can specify this by just associating a set mu(f) of indices of evaluable arguments to each function symbol 'f' by means of a mapping mu which we call a replacement map. For instance, we let mu(if-then-else)={1} to specify that only the boolean argument 'b' of a conditional expression (if b then e else e') is necessarily evaluated. We can write mu(;)={1} to avoid computations on S2 in a sequence S1;S2, and mu(+)={} to say that processes should not be executed as part of a choice expression. In the realm of term rewriting, context-sensitive rewriting is the restriction of rewriting that arises when these syntactic replacement restrictions are taken into account. It has been used to improve the termination behavior of reduction-based computation systems and programs. It has been shown useful as an operational notion to model or simulate the executions of various formalisms and calculi. Some computational properties of context-sensitive rewriting (remarkably termination) have been used to characterize or verify computational properties of important rewriting strategies like innermost, outermost, demand-driven, and lazy rewriting. Context-sensitive rewriting has also been shown useful to develop verification techniques and tools for variants of rewriting like order-sorted or conditional rewriting. Consequently, it is also useful for analyzing computational properties of programs written in sophisticated rewriting-based programming languages such as OBJ*, CafeOBJ, Maude, Elan, etc., where related language constructions are used. This paper provides an overview of the theory of context-sensitive rewriting and some of its applications.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2465</post_id>
		<post_date><![CDATA[2017-06-30 02:55:51]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[some-applications-of-context-sensitive-rewriting-tutorial]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="context-sensitive-rewriting"><![CDATA[context-sensitive rewriting]]></category>
		<category domain="post_tag" nicename="infinitary-normalization"><![CDATA[infinitary normalization]]></category>
		<category domain="post_tag" nicename="normalization"><![CDATA[normalization]]></category>
		<category domain="post_tag" nicename="replacement-restrictions"><![CDATA[replacement restrictions]]></category>
		<category domain="post_tag" nicename="rewriting-semantics"><![CDATA[rewriting semantics]]></category>
		<category domain="post_tag" nicename="termination"><![CDATA[termination]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The appropriate selection of the arguments of functions that can be evaluated in function calls improves the evaluation of such calls in a number of different ways: efficiency, speed, termination behavior, etc. This is essential in the conditional if-then-else operator. Other operators like sequencing (;) or choice (+) that are used in concurrent and/or imperative languages require a similar treatment. The (lazy) list constructor 'cons' of functional languages is another well-known example. At the syntactic level we can specify this by just associating a set mu(f) of indices of evaluable arguments to each function symbol 'f' by means of a mapping mu which we call a replacement map. For instance, we let mu(if-then-else)={1} to specify that only the boolean argument 'b' of a conditional expression (if b then e else e') is necessarily evaluated. We can write mu(;)={1} to avoid computations on S2 in a sequence S1;S2, and mu(+)={} to say that processes should not be executed as part of a choice expression. In the realm of term rewriting, context-sensitive rewriting is the restriction of rewriting that arises when these syntactic replacement restrictions are taken into account. It has been used to improve the termination behavior of reduction-based computation systems and programs. It has been shown useful as an operational notion to model or simulate the executions of various formalisms and calculi. Some computational properties of context-sensitive rewriting (remarkably termination) have been used to characterize or verify computational properties of important rewriting strategies like innermost, outermost, demand-driven, and lazy rewriting. Context-sensitive rewriting has also been shown useful to develop verification techniques and tools for variants of rewriting like order-sorted or conditional rewriting. Consequently, it is also useful for analyzing computational properties of programs written in sophisticated rewriting-based programming languages such as OBJ*, CafeOBJ, Maude, Elan, etc., where related language constructions are used. This paper provides an overview of the theory of context-sensitive rewriting and some of its applications.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/008]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498602104.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498602104.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Lucas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[slucas@dsic.upv.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards a formal framework for analyzing stream processing systems in Maude (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-a-formal-framework-for-analyzing-stream-processing-systems-in-maude-trabajo-en-progreso/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-a-formal-framework-for-analyzing-stream-processing-systems-in-maude-trabajo-en-progreso/</guid>
		<description></description>
		<content><![CDATA[With the rise of Big Data technologies, distributed stream processing systems (SPS) have gained popularity in the last years. Among these systems Spark Streaming stands out as a particularly attractive option, with a growing adoption in the industry, so we will consider in particular some features of SPS in Spark Streaming. Maude is a high-performance logical framework where other systems can be easily specified and executed. In this paper we show how a Maude specification of Spark Streaming would allow developers to analyze and prove properties on their programs.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2466</post_id>
		<post_date><![CDATA[2017-06-30 02:55:51]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-a-formal-framework-for-analyzing-stream-processing-systems-in-maude-trabajo-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="maude"><![CDATA[Maude]]></category>
		<category domain="post_tag" nicename="model-checking"><![CDATA[Model checking]]></category>
		<category domain="post_tag" nicename="stream-processing-systems"><![CDATA[Stream processing systems]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[With the rise of Big Data technologies, distributed stream processing systems (SPS) have gained popularity in the last years. Among these systems Spark Streaming stands out as a particularly attractive option, with a growing adoption in the industry, so we will consider in particular some features of SPS in Spark Streaming. Maude is a high-performance logical framework where other systems can be easily specified and executed. In this paper we show how a Maude specification of Spark Streaming would allow developers to analyze and prove properties on their programs.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/003]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498602286.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498602286.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Adrián Riesco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ariesco@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miguel Palomino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[miguelpt@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Narciso Martí-Oliet]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[narciso@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A type derivation system for Erlang (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-type-derivation-system-for-erlang-trabajo-en-progreso/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-type-derivation-system-for-erlang-trabajo-en-progreso/</guid>
		<description></description>
		<content><![CDATA[Erlang is a dynamically typed concurrent functional language of increasing interest in industry and academy. Official Erlang distributions come equipped with Dialyzer, a useful static analysis tool able to anticipate runtime errors by inferring so-called success types, which are overapproximations to the real semantics of expressions. However, Dialyzer exhibits two main weaknesses: on the practical side, its ability to deal with functions that are typically polymorphic is rather poor; and on the theoretical side, a fully developed theory for its underlying type system –comparable to, say, Hindley-Milner system– does not seem to exist, something that we consider a regrettable circumstance. This work in progress is the starting point of a medium-term project aiming at improving both aspects, so that at its end we should have proposed a full type system able to infer polymorphic success types for Erlang programs, accompanied by solid theoretical foundations including adequateness results for the type system. In this first step we only provide a derivation system of monomorphic success types for Erlang, along with correctness results with respect to a suitable semantics for the language.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2467</post_id>
		<post_date><![CDATA[2017-06-30 02:55:51]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-type-derivation-system-for-erlang-trabajo-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="dialyzer"><![CDATA[Dialyzer]]></category>
		<category domain="post_tag" nicename="erlang"><![CDATA[Erlang]]></category>
		<category domain="post_tag" nicename="program-semantics"><![CDATA[program semantics]]></category>
		<category domain="post_tag" nicename="success-types"><![CDATA[Success types]]></category>
		<category domain="post_tag" nicename="type-systems"><![CDATA[Type Systems]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Erlang is a dynamically typed concurrent functional language of increasing interest in industry and academy. Official Erlang distributions come equipped with Dialyzer a useful static analysis tool able to anticipate runtime errors by inferring so-called success types, which are overapproximations to the real semantics of expressions. However, Dialyzer exhibits two main weaknesses: on the practical side, its ability to deal with functions that are typically polymorphic is rather poor; and on the theoretical side, a fully developed theory for its underlying type system –comparable to, say, Hindley-Milner system– does not seem to exist, something that we consider a regrettable circumstance. This work in progress is the starting point of a medium-term project aiming at improving both aspects, so that at its end we should have proposed a full type system able to infer polymorphic success types for Erlang programs, accompanied by solid theoretical foundations including adequateness results for the type system. In this first step we only provide a derivation system of monomorphic success types for Erlang, along with correctness results with respect to a suitable semantics for the language.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/018]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498602481.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498602481.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Javier López-Fraguas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fraguas@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Montenegro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[montenegro@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Gorka Suárez-García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gorka.suarez@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evaluación de Requisitos de Seguridad con MBASafe conforme a la norma EN 50128 (Trabajo de alto nivel)</title>
		<link>https://biblioteca.sistedes.es/articulo/evaluacion-de-requisitos-de-seguridad-con-mbasafe-conforme-a-la-norma-en-50128-trabajo-de-alto-nivel/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/evaluacion-de-requisitos-de-seguridad-con-mbasafe-conforme-a-la-norma-en-50128-trabajo-de-alto-nivel/</guid>
		<description></description>
		<content><![CDATA[According to EN 50129, manufacturers of rail vehicles shall justify via a safety case that their vehicles are adequately safe for their intended applications. MBASafe is a recently proposed and potentially innovative design and verification process. In the presence of compelling arguments concerning its adequacy as process evidence, MBASafe could support the safety claims within the required safety cases.
In this paper, we contribute to partially justify the adequacy of MBASafe to act as process evidence. To do that, we first manually check if MBASafe includes EN 50128-compliant process elements, then we model MBASafe in compliance with Software Process Engineering Meta-model 2.0, then, we derive process-based arguments from the MBASafe process model by using MDSafeCer, the recently introduced Model Driven Safety Certification method. By doing so, we provide a twofold contribution: we further validate MDSafeCer in the rail domain and we strengthen MBASafe.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2468</post_id>
		<post_date><![CDATA[2017-06-30 02:55:51]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evaluacion-de-requisitos-de-seguridad-con-mbasafe-conforme-a-la-norma-en-50128-trabajo-de-alto-nivel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="en-5012x"><![CDATA[EN 5012x]]></category>
		<category domain="post_tag" nicename="model-driven-safety-certication"><![CDATA[model-driven safety certication]]></category>
		<category domain="post_tag" nicename="process-assessment"><![CDATA[process assessment]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[According to EN 50129, manufacturers of rail vehicles shall justify via a safety case that their vehicles are adequately safe for their intended applications. MBASafe is a recently proposed and potentially innovative design and verification process. In the presence of compelling arguments concerning its adequacy as process evidence, MBASafe could support the safety claims within the required safety cases.
In this paper, we contribute to partially justify the adequacy of MBASafe to act as process evidence. To do that, we first manually check if MBASafe includes EN 50128-compliant process elements, then we model MBASafe in compliance with Software Process Engineering Meta-model 2.0, then, we derive process-based arguments from the MBASafe process model by using MDSafeCer, the recently introduced Model Driven Safety Certification method. By doing so, we provide a twofold contribution: we further validate MDSafeCer in the rail domain and we strengthen MBASafe. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/013]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498603878.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498603878.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Barbara Gallina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[barbara.gallina@mdh.se]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Malardalen University]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Elena Gómez-Martínez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[egomez@babel.ls.fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Clara Benac Earle]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[cbenac@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards the model-based predictive performance analysis of Cloud adaptive systems with e-Motions (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-the-model-based-predictive-performance-analysis-of-cloud-adaptive-systems-with-e-motions-trabajo-en-progreso/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-the-model-based-predictive-performance-analysis-of-cloud-adaptive-systems-with-e-motions-trabajo-en-progreso/</guid>
		<description></description>
		<content><![CDATA[We use graph transformation to define an adaptive component model, what allows us to carry on predictive analyses on dynamic architectures through simulations. Specifically, we build on the e-Motions definition of the Palladio component model, and then specify adaptation mechanisms as generic adaptation rules. We illustrate our approach with rules modelling the increase in the number of CPU replicas used by a component, and the distribution of works between processors, reacting, respectively, to saturated queues or response time constraints violations. We evaluate alternative scenarios by analysing their performance, and discuss on its consequences in practice.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2469</post_id>
		<post_date><![CDATA[2017-06-30 02:55:51]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-the-model-based-predictive-performance-analysis-of-cloud-adaptive-systems-with-e-motions-trabajo-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="domain-specific-languages"><![CDATA[Domain Specific Languages]]></category>
		<category domain="post_tag" nicename="e-motions"><![CDATA[e-Motions]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<category domain="post_tag" nicename="performance-analysis"><![CDATA[performance analysis]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We use graph transformation to define an adaptive component model, what allows us to carry on predictive analyses on dynamic architectures through simulations. Specifically, we build on the e-Motions definition of the Palladio component model, and then specify adaptation mechanisms as generic adaptation rules. We illustrate our approach with rules modelling the increase in the number of CPU replicas used by a component, and the distribution of works between processors, reacting, respectively, to saturated queues or response time constraints violations. We evaluate alternative scenarios by analysing their performance, and discuss on its consequences in practice.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/012]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498602918.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498602918.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Patricia de Oliveira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[patricia@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francisco Durán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[duran@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ernesto Pimentel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ernesto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards the Automatic Verification of QCSP tractability results (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-the-automatic-verication-of-qcsp-tractability-results-trabajo-en-progreso/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-the-automatic-verication-of-qcsp-tractability-results-trabajo-en-progreso/</guid>
		<description></description>
		<content><![CDATA[We deal with the quantied constraint satisfaction problem (QCSP) which consists in deciding, given an structure and a first-order sentence built from atoms, with conjunction and quantication, whether or not the sentence is true on the structure. We study a known proof system which has been used to derive QCSP tractability results. Our contribution is to formalize this proof system into an automatically veried theory, so that it can be used (in a near future) as a basis for automatically verify tractability results.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2470</post_id>
		<post_date><![CDATA[2017-06-30 02:55:51]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-the-automatic-verication-of-qcsp-tractability-results-trabajo-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="automatic-verification"><![CDATA[Automatic verification]]></category>
		<category domain="post_tag" nicename="dafny"><![CDATA[Dafny]]></category>
		<category domain="post_tag" nicename="inductive-predicate"><![CDATA[inductive predicate]]></category>
		<category domain="post_tag" nicename="proof-system"><![CDATA[proof system]]></category>
		<category domain="post_tag" nicename="tractability-results"><![CDATA[tractability results]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We deal with the quantied constraint satisfaction problem (QCSP) which consists in deciding, given an structure and a rst-order sentence built from atoms, with conjunction and quantication, whether or not the sentence is true on the structure. We study a known proof system which has been used to derive QCSP tractability results. Our contribution is to formalize this proof system into an automatically veried theory, so that it can be used (in a near future) as a basis for automatically verify tractability results.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/017]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498603120.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498603120.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alex Abuin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aabuin@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Ik4-Ikerlan Research Center	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Hubie Chen]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[hubie.chen@ehu.eus	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad del País Vasco and IKERBASQUE Basque Foundation for Science]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Montserrat Hermo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[montserrat.hermo@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad del País Vasco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Paqui Lucio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[paqui.lucio@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad del País Vasco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A characterisation of reliability tools for Software Defined Networks (Trabajo original)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-characterisation-of-reliability-tools-for-software-defined-networks-trabajo-original/</link>
		<pubDate>Fri, 30 Jun 2017 00:55:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-characterisation-of-reliability-tools-for-software-defined-networks-trabajo-original/</guid>
		<description></description>
		<content><![CDATA[Software Defined Network (SDN) is a new paradigm in networking that introduces great flexibility, allowing the dynamic configuration of parts of the network through centralised programming. SDN has been successfully applied in field networks, and is now being applied to wireless and mobile networks, generating Software Defined Mobile/Wireless networks (SDWNs). SDN can be also combined with Network Function Virtualization (NFV) producing a software network in which the specific hardware is replaced by general purpose computing equipment running SDN and NFV software solutions. This highly programmable and flexible network introduces many challenges from the point of view of reliability (or robustness), and operators need to ensure the same level of confidence as in previous, less flexible deployments. This paper provides a first study of the current tools used to analyse the reliability of SDNs before deployment and/or during the exploitation of the network. Most of these tools offer some kind of automatic verification, supported by algorithms based on formal methods, but they do not differentiate between fixed and mobile/wireless networks. In the paper we provide a number of classifications of the tools to make this selection easier for potential users, and we also identify promising research areas where more effort needs to be made.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2471</post_id>
		<post_date><![CDATA[2017-06-30 02:55:51]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:55:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-characterisation-of-reliability-tools-for-software-defined-networks-trabajo-original]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="communication-networks"><![CDATA[Communication Networks]]></category>
		<category domain="post_tag" nicename="model-checking"><![CDATA[Model checking]]></category>
		<category domain="post_tag" nicename="reliability"><![CDATA[Reliability]]></category>
		<category domain="post_tag" nicename="runtime"><![CDATA[Runtime]]></category>
		<category domain="post_tag" nicename="software-defined-network"><![CDATA[Software Defined Network]]></category>
		<category domain="post_tag" nicename="verification"><![CDATA[Verification]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Software Defined Network (SDN) is a new paradigm in networking that introduces great flexibility, allowing the dynamic configuration of parts of the network through centralised programming. SDN has been successfully applied in field networks, and is now being applied to wireless and mobile networks, generating Software Defined Mobile/Wireless networks (SDWNs). SDN can be also combined with Network Function Virtualization (NFV) producing a software network in which the specific hardware is replaced by general purpose computing equipment running SDN and NFV software solutions. This highly programmable and flexible network introduces many challenges from the point of view of reliability (or robustness), and operators need to ensure the same level of confidence as in previous, less flexible deployments. This paper provides a first study of the current tools used to analyse the reliability of SDNs before deployment and/or during the exploitation of the network. Most of these tools offer some kind of automatic verification, supported by algorithms based on formal methods, but they do not differentiate between fixed and mobile/wireless networks. In the paper we provide a number of classifications of the tools to make this selection easier for potential users, and we also identify promising research areas where more effort needs to be made.
]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2017/011]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498603312.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1498603312.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Leticia Lavado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[leticialavmu@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Laura Panizo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[laurapanizo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[María del Mar Gallardo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gallardo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Pedro Merino]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[pedro@lcc.uma.es	]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards a Social End-user Composition of Services</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-a-social-end-user-composition-of-services/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:00 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-a-social-end-user-composition-of-services/</guid>
		<description></description>
		<content><![CDATA[Nowadays, end-users’ environment is plenty of services that support their life style, and involving them in the process of service creation can allows them to benefit from a cheaper, faster, and better service provisioning. There are already tools targeted to the authoring and
consumption of services. However these tools consider end-users as isolated individuals, missing the potential that their social environment can bring to them. In this paper, we investigate how social networks can be used to improve the authoring and consumption of services by end-users. We propose a social network of service compositions as a valuable
mechanism to share knowledge among end-users in order to improve their skills in composing new services. In addition, we analyse the underlying relationships created among service compositions in order to provide end-users with an intuitive way of browsing them.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2472</post_id>
		<post_date><![CDATA[2017-06-30 02:56:00]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:00]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-a-social-end-user-composition-of-services]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Nowadays, end-users’ environment is plenty of services that support their life style, and involving them in the process of service creation can allows them to benefit from a cheaper, faster, and better service provisioning. There are already tools targeted to the authoring and
consumption of services. However these tools consider end-users as isolated individuals, missing the potential that their social environment can bring to them. In this paper, we investigate how social networks can be used to improve the authoring and consumption of services by end-users. We propose a social network of service compositions as a valuable
mechanism to share knowledge among end-users in order to improve their skills in composing new services. In addition, we analyse the underlying relationships created among service compositions in order to provide end-users with an intuitive way of browsing them.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/001]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496868434.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496868434.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Valderas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pvalderas@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Victoria Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[vtorres@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pele@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Kopernik: Modeling Business Processes for Digital Customers</title>
		<link>https://biblioteca.sistedes.es/articulo/kopernik-modeling-business-processes-for-digital-customers/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:00 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/kopernik-modeling-business-processes-for-digital-customers/</guid>
		<description></description>
		<content><![CDATA[This paper presents the Kopernik approach for modeling business processes for digital customers. These processes require a high degree of flexibility in the execution of their tasks or actions. We achieve this by using an artifact-centric approach to process modeling and the
use of condition-action rules. The processes modeled following Kopernik can then be implemented in an existing commercial tool, Balandra.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2473</post_id>
		<post_date><![CDATA[2017-06-30 02:56:00]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:00]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[kopernik-modeling-business-processes-for-digital-customers]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>1</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper presents the Kopernik approach for modeling business processes for digital customers. These processes require a high degree of flexibility in the execution of their tasks or actions. We achieve this by using an artifact-centric approach to process modeling and the
use of condition-action rules. The processes modeled following Kopernik can then be implemented in an existing commercial tool, Balandra.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/002]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496924157.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496924157.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Montserrat Estañol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[estanyol@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya, Barcelona - SIRIS Lab, Research Division of SIRIS Academic, Barcelona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[manuel.castro@leelo.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Léelo - Process as a service, Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Silvia Díaz-Montenegro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sylvia.diazm@leelo.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Léelo - Process as a service, Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ernest Teniente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[teniente@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya, Barcelona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>M-eRoDes: una plataforma de servicios para la creación y evaluación automática de actividades de aprendizaje colaborativo</title>
		<link>https://biblioteca.sistedes.es/articulo/m-erodes-una-plataforma-de-servicios-para-la-creacion-y-evaluacion-automatica-de-actividades-de-aprendizaje-colaborativo/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:00 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/m-erodes-una-plataforma-de-servicios-para-la-creacion-y-evaluacion-automatica-de-actividades-de-aprendizaje-colaborativo/</guid>
		<description></description>
		<content><![CDATA[En este trabajo se presenta una plataforma de servicios de e-learning, llamada M-eRoDes, que ofrece funcionalidad para crear y evaluar automáticamente actividades de enseñanza-aprendizaje basadas en metodologías activas. La plataforma facilita que los estudiantes
aprendan creando sus propios recursos (audiovisuales) de aprendizaje y a su vez enseñen con estos mismos recursos a sus compañeros. Además, M-eRoDes integra un novedoso sistema de evaluación basado en modelos de conocimiento y semántica.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2474</post_id>
		<post_date><![CDATA[2017-06-30 02:56:00]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:00]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[m-erodes-una-plataforma-de-servicios-para-la-creacion-y-evaluacion-automatica-de-actividades-de-aprendizaje-colaborativo]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>2</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="aprendizaje-online"><![CDATA[aprendizaje online]]></category>
		<category domain="post_tag" nicename="metodologias-activas"><![CDATA[metodologías activas]]></category>
		<category domain="post_tag" nicename="representacion-del-conocimiento"><![CDATA[representación del conocimiento]]></category>
		<category domain="post_tag" nicename="serviciosaplicaciones-web"><![CDATA[Servicios/aplicaciones Web]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este trabajo se presenta una plataforma de servicios de e-learning, llamada M-eRoDes, que ofrece funcionalidad para crear y evaluar automáticamente actividades de enseñanza-aprendizaje basadas en metodologías activas. La plataforma facilita que los estudiantes
aprendan creando sus propios recursos (audiovisuales) de aprendizaje y a su vez ense~nen con estos mismos recursos a sus compa~neros. Además, M-eRoDes integra un novedoso sistema de evaluación basado en modelos de conocimiento y semántica.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/003]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496924527.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496924527.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Álvarez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alvaper@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sandra Baldassarri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sandra@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza, Españaa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Predicciones en Procesos de Negocio Declarativos</title>
		<link>https://biblioteca.sistedes.es/articulo/predicciones-en-procesos-de-negocio-declarativos/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/predicciones-en-procesos-de-negocio-declarativos/</guid>
		<description></description>
		<content><![CDATA[La generación de predicciones sobre instancias de procesos de negocio permite anticipar problemas, evitar el incumplimiento de restricciones de una manera proactiva, y tomar decisiones sobre prioridades y restricciones al enfrentarse a eventos inesperados, e.g., retrasos. Sin embargo, elaborar una predicción es una tarea compleja en la mayoría de los casos ya que se deben tener en cuenta múltiples instancias y recursos, es necesario adaptar dichas predicciones a circunstancias cambiantes, y hay que tener en cuenta distintas dimensiones, no sólo el tiempo. En este contexto, el presente trabajo propone una propuesta novedosa para generar predicciones sobre un conjunto de instancias en ejecución relacionadas con un modelo declarativo de un proceso de negocio. Dicha propuesta consiste en generar un plan de ejecución optimizado a partir del modelo declarativo y del estado de las instancias en ejecución. Tras ello, la predicción se genera evaluando la función que se desea predecir sobre el plan de ejecución generado. La presente propuesta ha sido evaluada utilizando un modelo de proceso de un escenario real que incluye restricciones temporales, de datos, de recursos y de control-flow que lo dotan de una alta complejidad. Los prometedores resultados obtenidos alientan a continuar los trabajos en escenarios con características diferentes que permitan extender la validez de la propuesta.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2475</post_id>
		<post_date><![CDATA[2017-06-30 02:56:01]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[predicciones-en-procesos-de-negocio-declarativos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>1</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="constraint-programming"><![CDATA[Constraint programming]]></category>
		<category domain="post_tag" nicename="constraint-based-process-models"><![CDATA[Constraint-based process models]]></category>
		<category domain="post_tag" nicename="flexible-process-aware-information-systems"><![CDATA[Flexible process-aware information systems]]></category>
		<category domain="post_tag" nicename="planning-and-scheduling"><![CDATA[Planning and scheduling]]></category>
		<category domain="post_tag" nicename="time-prediction"><![CDATA[Time prediction]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La generación de predicciones sobre instancias de procesos de negocio permite anticipar problemas, evitar el incumplimiento de restricciones de una manera proactiva, y tomar decisiones sobre prioridades y restricciones al enfrentarse a eventos inesperados, e.g., retrasos. Sin embargo, elaborar una predicción es una tarea compleja en la mayoría de los casos ya que se deben tener en cuenta múltiples instancias y recursos, es necesario adaptar dichas predicciones a circunstancias cambiantes, y hay que tener en cuenta distintas dimensiones, no sólo el tiempo. En este contexto, el presente trabajo propone una propuesta novedosa para generar predicciones sobre un conjunto de instancias en ejecución relacionadas con un modelo declarativo de un proceso de negocio. Dicha propuesta consiste en generar un plan de ejecución optimizado a partir del modelo declarativo y del estado de las instancias en ejecución. Tras ello, la predicción se genera evaluando la función que se desea predecir sobre el plan de ejecución generado. La presente propuesta ha sido evaluada utilizando un modelo de proceso de un escenario real que incluye restricciones temporales, de datos, de recursos y de control-flow que lo dotan de una alta complejidad. Los prometedores resultados obtenidos alientan a continuar los trabajos en escenarios con características diferentes que permitan extender la validez de la propuesta. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/005]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496924921.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496924921.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Andrés Jiménez-Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ajramirez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Irene Barba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[irenebr@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Fernández-Olivares]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[faro@decsai.ugr.esg]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Granada, Granada, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Carmelo del Valle]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[carmelo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Barbara Weber]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[bweber@dtu.dk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Technical University of Denmark, Kongens Lyngby, Denmark]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards the Extraction of Frequent Patterns in Complex Process Models</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-the-extraction-of-frequent-patterns-in-complex-process-models/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-the-extraction-of-frequent-patterns-in-complex-process-models/</guid>
		<description></description>
		<content><![CDATA[In this paper, we present WoMine, an algorithm to retrieve frequent behavioural patterns from the model. Our approach searches in process models extracting structures with sequences, selections, parallels and loops, which are frequently executed in the logs. This proposal has been validated with a set of process models, and compared with the state of the art techniques. Experiments have validated that WoMine can find all types of patterns, extracting information that cannot be mined with the state of the art techniques.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2476</post_id>
		<post_date><![CDATA[2017-06-30 02:56:01]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-the-extraction-of-frequent-patterns-in-complex-process-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>2</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="frequent-pattern-mining"><![CDATA[frequent pattern mining]]></category>
		<category domain="post_tag" nicename="process-discovery"><![CDATA[process discovery]]></category>
		<category domain="post_tag" nicename="process-mining"><![CDATA[Process Mining]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper, we present WoMine, an algorithm to retrieve frequent behavioural patterns from the model. Our approach searches in process models extracting structures with sequences, selections, parallels and loops, which are frequently executed in the logs. This proposal has been validated with a set of process models, and compared with the state of the art techniques. Experiments have validated that WoMine can find all types of patterns, extracting information that cannot be mined with the state of the art techniques.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/006]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496925629.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496925629.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Chapela-Campa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[david.chapela@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Mucientes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[manuel.mucientes@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Lama]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuel.lama@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Monitorización predictiva de procesos de negocio basada en modelos de predicción actualizables</title>
		<link>https://biblioteca.sistedes.es/articulo/monitorizacion-predictiva-de-procesos-de-negocio-basada-en-modelos-de-prediccion-actualizables/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/monitorizacion-predictiva-de-procesos-de-negocio-basada-en-modelos-de-prediccion-actualizables/</guid>
		<description></description>
		<content><![CDATA[La monitorización predictiva de instancias de procesos de negocio en ejecución propociona acciones proactivas y correctivas para mejorar el rendimiento de los procesos y mitigar los posibles riesgos en tiempo real. Dicha monitorización permite la predicción de métricas de evaluación o indicadores del rendimiento de un proceso en ejecución. En este contexto, este trabajo define una arquitectura para el proceso de predicción de indicadores que, asimismo, contempla la posibilidad de la actualización del modelo predictivo a lo largo del tiempo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2477</post_id>
		<post_date><![CDATA[2017-06-30 02:56:01]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[monitorizacion-predictiva-de-procesos-de-negocio-basada-en-modelos-de-prediccion-actualizables]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>3</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mineria-de-procesos"><![CDATA[minería de procesos]]></category>
		<category domain="post_tag" nicename="monitorizacion-predictiva"><![CDATA[monitorización predictiva]]></category>
		<category domain="post_tag" nicename="prediccion-de-indicadores"><![CDATA[predicción de indicadores.]]></category>
		<category domain="post_tag" nicename="procesos-de-negocio"><![CDATA[Procesos de Negocio]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La monitorización predictiva de instancias de procesos de negocio en ejecución propociona acciones proactivas y correctivas para mejorar el rendimiento de los procesos y mitigar los posibles riesgos en tiempo real. Dicha monitorización permite la predicción de métricas de evaluación o indicadores del rendimiento de un proceso en ejecución. En este contexto, este trabajo define una arquitectura para el proceso de predicción de indicadores que, asimismo, contempla la posibilidad de la actualización del modelo predictivo a lo largo del tiempo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/007]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alfonso E. Márquez-Chamorro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[amarquez6@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Analyzer4BPEL: Una herramienta de análisis de composiciones WS-BPEL para su aplicación en la etapa de prueba del software</title>
		<link>https://biblioteca.sistedes.es/articulo/analyzer4bpel-una-herramienta-de-analisis-de-composiciones-ws-bpel-para-su-aplicacion-en-la-etapa-de-prueba-del-software/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/analyzer4bpel-una-herramienta-de-analisis-de-composiciones-ws-bpel-para-su-aplicacion-en-la-etapa-de-prueba-del-software/</guid>
		<description></description>
		<content><![CDATA[Toda herramienta de prueba de software requiere en algún momento de su proceso realizar un análisis, o bien como primer paso, para extraer la información necesaria para aplicar una determinada técnica, o bien, una vez procesado el software para estudiar los resultados y evaluarlos. Existen en la actualidad herramientas capaces de analizar la mayoría de los lenguajes de programación. Sin embargo, no abundan los analizadores de lenguajes para composiciones de servicios. En este trabajo se presenta una aplicación que realiza un análisis de composiciones en lenguaje WS-BPEL y de sus casos de prueba para extraer información útil para diversos objetivos. Así mismo, se describe su utilización particular, en una de las etapas de la aplicación de una técnica de prueba de software: la prueba metamórfica.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2478</post_id>
		<post_date><![CDATA[2017-06-30 02:56:01]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analyzer4bpel-una-herramienta-de-analisis-de-composiciones-ws-bpel-para-su-aplicacion-en-la-etapa-de-prueba-del-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>1</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="analisis"><![CDATA[análisis]]></category>
		<category domain="post_tag" nicename="bpts"><![CDATA[BPTS]]></category>
		<category domain="post_tag" nicename="casos-de-prueba"><![CDATA[casos de prueba]]></category>
		<category domain="post_tag" nicename="prueba-del-software"><![CDATA[prueba del software]]></category>
		<category domain="post_tag" nicename="prueba-metamorfica"><![CDATA[prueba metamórfica]]></category>
		<category domain="post_tag" nicename="relaciones-metamorfircas"><![CDATA[relaciones metamórfircas]]></category>
		<category domain="post_tag" nicename="servicios-web"><![CDATA[servicios web]]></category>
		<category domain="post_tag" nicename="ws-bpel"><![CDATA[WS-BPEL]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Toda herramienta de prueba de software requiere en algún momento de su proceso realizar un análisis, o bien como primer paso, para extraer la información necesaria para aplicar una determinada técnica, o bien, una vez procesado el software para estudiar los resultados y evaluarlos. Existen en la actualidad herramientas capaces de analizar la mayoría de los lenguajes de programación. Sin embargo, no abundan los analizadores de lenguajes para composiciones de servicios. En este trabajo se presenta una aplicación que realiza un análisis de composiciones en lenguaje WS-BPEL y de sus casos de prueba para extraer información útil para diversos objetivos. Así mismo, se describe su utilización particular, en una de las etapas de la aplicación de una técnica de prueba de software: la prueba metamórfica.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/009]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496926419.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496926419.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Kevin J. Valle-Gómez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[kevin.vallegomez@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[M. Carmen de Castro-Cabrera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[maricarmen.decastro@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards SLA modeling for RESTful APIs</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-sla-modeling-for-restful-apis/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-sla-modeling-for-restful-apis/</guid>
		<description></description>
		<content><![CDATA[The term of API Economy is becoming increasingly used to describe the change of vision in how APIs can add value to the organizations. Furthermore, a greater automation of RESTful APIs management can suppose a competitive advantage for the company. New proposals are emerging in order to automatize some API governance tasks and increase the ease of use (e.g. generation of code and documentation). Despite that, the non-functional aspects are often addressed in a highly specific manner or even there not exists any solution for an automatic governance. Nevertheless, these properties are already defined in natural language at the Service Level Agreement (SLA) that both customer and provided have established. In this paper, we carry out a study on the *aaS industry and analyze the current both API modeling and SLA modeling proposals in order to identify the open challenges for an automatic RESTful API governance.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2479</post_id>
		<post_date><![CDATA[2017-06-30 02:56:01]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-sla-modeling-for-restful-apis]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>2</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The term of API Economy is becoming increasingly used to describe the change of vision in how APIs can add value to the organizations. Furthermore, a greater automation of RESTful APIs management can suppose a competitive advantage for the company. New proposals are emerging in order to automatize some API governance tasks and increase the ease of use (e.g. generation of code and documentation). Despite that, the non-functional aspects are often addressed in a highly specific manner or even there not exists any solution for an automatic governance. Nevertheless, these properties are already defined in natural language at the Service Level Agreement (SLA) that both customer and provided have established. In this paper, we carry out a study on the *aaS industry and analyze the current both API modeling and SLA modeling proposals in order to identify the open challenges for an automatic RESTful API governance.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/010]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2783]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Gámez-Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[agamez2@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modelling Citizen Letters for Public Services automation</title>
		<link>https://biblioteca.sistedes.es/articulo/modelling-citizen-letters-for-public-services-automation/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/modelling-citizen-letters-for-public-services-automation/</guid>
		<description></description>
		<content><![CDATA[The publication and, when it is possible, automation of public services on Internet provides advantages for citizens and governance. The former because promotes the transparency and control over governance actions and avoids unneeded presencial inquiries and the latter because information systems help to decrease human resources costs. A number of efforts have been performed by public administrations to provide precise service information online. As this service information is incrementally published, manual interaction to navigate and query these services becomes a difficult task that automated mechanisms could support based on service catalogs. In this paper we introduce an ongoing work proposing the use of ontologies to enable the automated processing -i.e. search and validation- of these service catalogs.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2480</post_id>
		<post_date><![CDATA[2017-06-30 02:56:01]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modelling-citizen-letters-for-public-services-automation]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>3</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The publication and, when it is possible, automation of public services on Internet provides advantages for citizens and governance. The former because promotes the transparency and control over governance actions and avoids unneeded presencial inquiries and the latter because information systems help to decrease human resources costs. A number of efforts have been performed by public administrations to provide precise service information online. As this service information is incrementally published, manual interaction to navigate and query these services becomes a difficult task that automated mechanisms could support based on service catalogs. In this paper we introduce an ongoing work proposing the use of ontologies to enable the automated processing -i.e. search and validation- of these service catalogs.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/011]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496926934.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496926934.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Manuel Gutiérrez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[amgutierrez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernanda Massena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fmmassena@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidade Federal do Estado do Rio de Janeiro, Brazil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Claudia Cappelli]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[claudia.cappelli@uniriotec.br]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidade Federal do Estado do Rio de Janeiro, Brazil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Flavia Santoro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[flavia.santoro@uniriotec.br]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidade Federal do Estado do Rio de Janeiro, Brazil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Detección de Abandono de una Zona Segura mediante la Integración de CEP y SOA 2.0</title>
		<link>https://biblioteca.sistedes.es/articulo/deteccion-de-abandono-de-una-zona-segura-mediante-la-integracion-de-cep-y-soa-2-0/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/deteccion-de-abandono-de-una-zona-segura-mediante-la-integracion-de-cep-y-soa-2-0/</guid>
		<description></description>
		<content><![CDATA[Existe una gran problemática alrededor de personas enfermas de Alzheimer. Estas personas viven en el pasado y no son conscientes de la reali-dad en la que viven. Gran parte de ellas llegan a perderse provocando un gran dolor en familia y amigos. Por consiguiente, el ser informado en el instante jus-to que dicha persona abandona su hogar, la residencia o lugar de recreo evitaría muchas situaciones trágicas para estas familias. En este artículo desarrollamos un sistema que integra SOA 2.0 con un motor de procesamiento de eventos complejos y un sensor GPS con el fin de avisar a los familiares en el momento en que el enfermo salga de una zona determinada. Los resultados obtenidos de-muestran que el procesamiento de eventos complejos es la tecnología acertada para detectar en tiempo real cuándo una persona abandona una zona establecida y ser informados de su posición, pudiendo emprender su búsqueda inmediata-mente y evitar la fatal pérdida.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2481</post_id>
		<post_date><![CDATA[2017-06-30 02:56:01]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[deteccion-de-abandono-de-una-zona-segura-mediante-la-integracion-de-cep-y-soa-2-0]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="arquitectura-dirigida-por-eventos"><![CDATA[Arquitectura Dirigida por Eventos]]></category>
		<category domain="post_tag" nicename="arquitectura-orientada-a-servicios"><![CDATA[Arquitectura Orientada a Servicios]]></category>
		<category domain="post_tag" nicename="bus-de-servicios-empresaria-les"><![CDATA[Bus de Servicios Empresaria-les]]></category>
		<category domain="post_tag" nicename="gps"><![CDATA[GPS.]]></category>
		<category domain="post_tag" nicename="procesamiento-de-eventos-complejos"><![CDATA[procesamiento de eventos complejos]]></category>
		<category domain="post_tag" nicename="rest"><![CDATA[REST]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Existe una gran problemática alrededor de personas enfermas de Alzheimer. Estas personas viven en el pasado y no son conscientes de la reali-dad en la que viven. Gran parte de ellas llegan a perderse provocando un gran dolor en familia y amigos. Por consiguiente, el ser informado en el instante jus-to que dicha persona abandona su hogar, la residencia o lugar de recreo evitaría muchas situaciones trágicas para estas familias. En este artículo desarrollamos un sistema que integra SOA 2.0 con un motor de procesamiento de eventos complejos y un sensor GPS con el fin de avisar a los familiares en el momento en que el enfermo salga de una zona determinada. Los resultados obtenidos de-muestran que el procesamiento de eventos complejos es la tecnología acertada para detectar en tiempo real cuándo una persona abandona una zona establecida y ser informados de su posición, pudiendo emprender su búsqueda inmediata-mente y evitar la fatal pérdida.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/012]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2787]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496929227.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carmen Marchena-Tinoco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carmen.marchenatinoco@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Escuela Superior de Ingeniería, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carmen Moreno-Muñoz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[carmen.morenomunoz@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Escuela Superior de Ingeniería, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>QSS: una experiencia en la industria 4.0 en seguridad y prevención de riesgos</title>
		<link>https://biblioteca.sistedes.es/articulo/qss-una-experiencia-en-la-industria-4-0-en-seguridad-y-prevencion-de-riesgos/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/qss-una-experiencia-en-la-industria-4-0-en-seguridad-y-prevencion-de-riesgos/</guid>
		<description></description>
		<content><![CDATA[En los últimos años, la Industria 4.0 se está convirtiendo en una gran apuesta de los gobiernos industrializados y donde las fábricas renuevan sus procesos industriales interconectándolos entre sí. Los principales desafíos a los que ha de hacer frente esta Industria 4.0 se encuentran en el desarrollo de software donde, entre otros, la ciberseguridad y el control de riesgos son aspectos claves en la innovación hacia esta industria 4.0. Este artículo presenta nuestra experiencia práctica en el desarrollo e implantación de una arquitectura SOA 2.0 para la monitorización en tiempo real de escenarios de trabajo de alta peligrosidad que, haciendo uso de los principios de la industria 4.0, permiten realizar una rápida toma de decisiones orientadas a la seguridad y prevención de riesgos de los trabajadores de una empresa de explosivos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2482</post_id>
		<post_date><![CDATA[2017-06-30 02:56:01]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[qss-una-experiencia-en-la-industria-4-0-en-seguridad-y-prevencion-de-riesgos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>1</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="entornos-de-alta-peligrosidad"><![CDATA[Entornos de alta peligrosidad]]></category>
		<category domain="post_tag" nicename="industria-4-0"><![CDATA[Industria 4.0]]></category>
		<category domain="post_tag" nicename="soa-2-0"><![CDATA[SOA 2.0]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años, la Industria 4.0 se está convirtiendo en una gran apuesta de los gobiernos industrializados y donde las fábricas renuevan sus procesos industriales interconectándolos entre sí. Los principales desafíos a los que ha de hacer frente esta Industria 4.0 se encuentran en el desarrollo de software donde, entre otros, la ciberseguridad y el control de riesgos son aspectos claves en la innovación hacia esta industria 4.0. Este artículo presenta nuestra experiencia práctica en el desarrollo e implantación de una arquitectura SOA 2.0 para la monitorización en tiempo real de escenarios de trabajo de alta peligrosidad que, haciendo uso de los principios de la industria 4.0, permiten realizar una rápida toma de decisiones orientadas a la seguridad y prevención de riesgos de los trabajadores de una empresa de explosivos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/013]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2782]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JCIS_2017_paper_8.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Guillermo Barco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanher@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[QSEG, Escuela Politécnica de Cáceres, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Enrique Moguel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[enrique@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[QSEG, Escuela Politécnica de Cáceres, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jorge Perianez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Industria 4.0, SOA 2.0, Entornos de alta peligrosidad]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>El papel de los ciudadanos en las ciudades inteligentes: un escenario de movilidad urbana</title>
		<link>https://biblioteca.sistedes.es/articulo/el-papel-de-los-ciudadanos-en-las-ciudades-inteligentes-un-escenario-de-movilidad-urbana/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/el-papel-de-los-ciudadanos-en-las-ciudades-inteligentes-un-escenario-de-movilidad-urbana/</guid>
		<description></description>
		<content><![CDATA[Gran parte de los esfuerzos dedicados al desarrollo de las llamadas ciudades inteligentes se centran en el campo del Internet of Things (IoT). Las instituciones ofrecen habitualmente
la información recolectada mediante IoT en forma de datos abiertos y estadísticas, a partir de las cuales se pueden realizar análisis y obtener conclusiones que ayuden a mejorar la gestión de las ciudades, haciéndolas más eficientes y habitables. No obstante, sin el concurso de los ciudadanos en la generación y recogida de información, no es posible ofrecer una imagen completa de las ciudades. El análisis de la información recopilada no tendrá en
cuenta el contexto de las personas, ni podrá adaptarse a las necesidades de las mismas. Para resolver este problema, proponemos el uso de un nuevo modelo capaz de convivir con el de IoT actual y que cubra estas necesidades respecto a los ciudadanos. Se trata de Internet of People (IoP), un modelo de computación social y móvil que permite recopilar información a partir de los smartphones y del uso que hacen de ellos sus propietarios. Mediante
un motor de inferencia, dicha información se transforma en conocimiento de los hábitos del usuario del teléfono, conocimiento que puede ser ofrecido a su vez como un servicio. La
combinación de los datos recogidos por ambas partes, IoT e IoP, procurará realmente el adjetivo inteligente a la ciudad, permitiendo que los servicios que el IoT ofrece puedan adaptarse a cada persona, y convirtiendo a estas últimas en el objetivo central
de la ciudad inteligente.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2483</post_id>
		<post_date><![CDATA[2017-06-30 02:56:02]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[el-papel-de-los-ciudadanos-en-las-ciudades-inteligentes-un-escenario-de-movilidad-urbana]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>2</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Gran parte de los esfuerzos dedicados al desarrollo de las llamadas ciudades inteligentes se centran en el campo del Internet of Things (IoT). Las instituciones ofrecen habitualmente
la información recolectada mediante IoT en forma de datos abiertos y estadísticas, a partir de las cuales se pueden realizar análisis y obtener conclusiones que ayuden a mejorar la gestión de las ciudades, haciéndolas más eficientes y habitables. No obstante, sin el concurso de los ciudadanos en la generación y recogida de información, no es posible ofrecer una imagen completa de las ciudades. El análisis de la información recopilada no tendrá en
cuenta el contexto de las personas, ni podrá adaptarse a las necesidades de las mismas. Para resolver este problema, proponemos el uso de un nuevo modelo capaz de convivir con el de IoT actual y que cubra estas necesidades respecto a los ciudadanos. Se trata de Internet of People (IoP), un modelo de computación social y móvil que permite recopilar información a partir de los smartphones y del uso que hacen de ellos sus propietarios. Mediante
un motor de inferencia, dicha información se transforma en conocimiento de los hábitos del usuario del teléfono, conocimiento que puede ser ofrecido a su vez como un servicio. La
combinación de los datos recogidos por ambas partes, IoT e IoP, procurará realmente el adjetivo inteligente a la ciudad, permitiendo que los servicios que el IoT ofrece puedan adaptarse a cada persona, y convirtiendo a estas últimas en el objetivo central
de la ciudad inteligente.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/014]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496930266.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496930266.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alejandro Pérez-Vereda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[apvereda@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José Garcia-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Juan M. Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia la mejora de las mediciones topográficas de campo a través de una arquitectura orientada a servicios dirigida por eventos</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-la-mejora-de-las-mediciones-topograficas-de-campo-a-traves-de-una-arquitectura-orientada-a-servicios-dirigida-por-eventos/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/hacia-la-mejora-de-las-mediciones-topograficas-de-campo-a-traves-de-una-arquitectura-orientada-a-servicios-dirigida-por-eventos/</guid>
		<description></description>
		<content><![CDATA[Las tecnologías para las mediciones topográficas y el software para calcular y representar la elevación del terreno han evolucionado considerablemente en los últimos años. Sin embargo, las empresas de topografía, especialmente las pymes, aún sufren grandes costes por datos erróneos o incompletos en las mediciones realizadas por los operarios. En este artículo se esboza una propuesta para la reducción de dichos costes –en tiempo y en dinero– a través de una arquitectura orientada a servicios y dirigida por eventos que emita la recepción
instantánea de los datos tomados por los operarios, la detección de mediciones erróneas o incompletas y la inmediata notificación a los operarios para solventar la incidencia.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2484</post_id>
		<post_date><![CDATA[2017-06-30 02:56:02]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-la-mejora-de-las-mediciones-topograficas-de-campo-a-traves-de-una-arquitectura-orientada-a-servicios-dirigida-por-eventos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>3</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="arquitecturas-dirigidas-por-eventos"><![CDATA[Arquitecturas Dirigidas por Eventos]]></category>
		<category domain="post_tag" nicename="arquitecturas-orientadas-a-servicios"><![CDATA[arquitecturas orientadas a servicios]]></category>
		<category domain="post_tag" nicename="bus-de-servicios-empresariales"><![CDATA[Bus de Servicios Empresariales]]></category>
		<category domain="post_tag" nicename="procesamiento-de-eventos-complejos"><![CDATA[procesamiento de eventos complejos]]></category>
		<category domain="post_tag" nicename="topografia"><![CDATA[Topografía]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las tecnologías para las mediciones topográficas y el software para calcular y representar la elevación del terreno han evolucionado considerablemente en los últimos años. Sin embargo, las empresas de topografía, especialmente las pymes, aún sufren grandes costes por datos erróneos o incompletos en las mediciones realizadas por los operarios. En este artículo se esboza una propuesta para la reducción de dichos costes –en tiempo y en dinero– a través de una arquitectura orientada a servicios y dirigida por eventos que emita la recepción
instantánea de los datos tomados por los operarios, la detección de mediciones erróneas o incompletas y la inmediata notificación a los operarios para solventar la incidencia.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/015]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2788]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496930401.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alfonso García de Prado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alfonso.garciadeprado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francisco Gámez Lázaro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[francisco@georamasc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Georama S.C.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Coordinating heterogeneous IoT devices by means of the centralized vision of the SDN controller</title>
		<link>https://biblioteca.sistedes.es/articulo/coordinating-heterogeneous-iot-devices-by-means-of-the-centralized-vision-of-the-sdn-controller/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/coordinating-heterogeneous-iot-devices-by-means-of-the-centralized-vision-of-the-sdn-controller/</guid>
		<description></description>
		<content><![CDATA[The IoT (Internet of Things) has become a reality during recent years. The desire of having everything connected to the Internet results in clearly identified benefits that will impact on socio economic development. However, the exponential growth in the number of IoT devices and their heterogeneity open new challenges that must be carefully studied. Coordination among devices to adapt them to their users' context usually requires high volumes of data to be exchanged with the cloud. In order to reduce unnecessary communications and network overhead, this paper proposes a novel network architecture based on the Software-Defined Networking paradigm that allows IoT devices coordinate and adapt them within the scope of a particular context.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2485</post_id>
		<post_date><![CDATA[2017-06-30 02:56:02]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[coordinating-heterogeneous-iot-devices-by-means-of-the-centralized-vision-of-the-sdn-controller]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="internet-of-things"><![CDATA[Internet of Things]]></category>
		<category domain="post_tag" nicename="situational-context"><![CDATA[Situational-Context]]></category>
		<category domain="post_tag" nicename="software-defined-networking"><![CDATA[Software-Defined Networking]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The IoT (Internet of Things) has become a reality during recent years. The desire of having everything connected to the Internet results in clearly identified benefits that will impact on socio economic development. However, the exponential growth in the number of IoT devices and their heterogeneity open new challenges that must be carefully studied. Coordination among devices to adapt them to their users' context usually requires high volumes of data to be exchanged with the cloud. In order to reduce unnecessary communications and network overhead, this paper proposes a novel network architecture based on the Software-Defined Networking paradigm that allows IoT devices coordinate and adapt them within the scope of a particular context.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/016]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496950553.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496950553.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jaime Galán-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jaime@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose Garcia-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Juan M. Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automatización del Aprovisionamiento de Infraestructura en la Nube</title>
		<link>https://biblioteca.sistedes.es/articulo/automatizacion-del-aprovisionamiento-de-infraestructura-en-la-nube/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/automatizacion-del-aprovisionamiento-de-infraestructura-en-la-nube/</guid>
		<description></description>
		<content><![CDATA[DevOps es un paradigma que aporta prácticas y herramientas que optimizan el tiempo de entrega del software. En particular, la Infraestructura como Código es la capacidad principal de DevOps para automatizar la gestión de la infraestructura basada en actividades de desarrollo de software. Existe una gran variedad de herramientas que gestionan el aprovisionamiento de infraestructura y utilizan scripts para definir el estado final del hardware. Sin embargo, aún existen retos técnicos para gestionar las herramientas en actividades como la integración, despliegue y entrega continua de aplicaciones. Para abordar este problema, en trabajos previos, presentamos una extensión de un método de reconfiguración dinámica de arquitecturas de servicios en la nube (DIARy) con el fin de adoptar las prácticas de DevOps. En este trabajo presentamos una herramienta para modelar el aprovisionamiento de infraestructura en la nube basado en el concepto de Infraestructura como Código.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2486</post_id>
		<post_date><![CDATA[2017-06-30 02:56:02]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automatizacion-del-aprovisionamiento-de-infraestructura-en-la-nube]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>2</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="aprovisionamiento-de-infraestructura"><![CDATA[Aprovisionamiento de Infraestructura]]></category>
		<category domain="post_tag" nicename="desarrollo-dirigido-por-modelos"><![CDATA[Desarrollo dirigido por modelos]]></category>
		<category domain="post_tag" nicename="devops"><![CDATA[DevOps]]></category>
		<category domain="post_tag" nicename="infraestructura-como-codigo"><![CDATA[Infraestructura como Código]]></category>
		<category domain="post_tag" nicename="servicios-en-la-nube"><![CDATA[Servicios en la Nube]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[DevOps es un paradigma que aporta prácticas y herramientas que optimizan el tiempo de entrega del software. En particular, la Infraestructura como Código es la capacidad principal de DevOps para automatizar la gestión de la infraestructura basada en actividades de desarrollo de software. Existe una gran variedad de herramientas que gestionan el aprovisionamiento de infraestructura y utilizan scripts para definir el estado final del hardware. Sin embargo, aún existen retos técnicos para gestionar las herramientas en actividades como la integración, despliegue y entrega continua de aplicaciones. Para abordar este problema, en trabajos previos, presentamos una extensión de un método de reconfiguración dinámica de arquitecturas de servicios en la nube (DIARy) con el fin de adoptar las prácticas de DevOps. En este trabajo presentamos una herramienta para modelar el aprovisionamiento de infraestructura en la nube basado en el concepto de Infraestructura como Código.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/018]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496952434.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496952434.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julio Sandobalín]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[julio.sandobalin@epn.edu.ec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática y Ciencias de la Computación, Escuela Politécnica Nacional de Ecuador]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Emilio Insfran]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[einsfran@disc.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Silvia Abrahão]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sabrahao@disc.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Mejorando la arquitectura de la infraestructura de datos y metadatos estadísticos de Canarias (eDatos)</title>
		<link>https://biblioteca.sistedes.es/articulo/mejorando-la-arquitectura-de-la-infraestructura-de-datos-y-metadatos-estadisticos-de-canarias-edatos/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/mejorando-la-arquitectura-de-la-infraestructura-de-datos-y-metadatos-estadisticos-de-canarias-edatos/</guid>
		<description></description>
		<content><![CDATA[La integración de datos entre distintos sistemas es un problema típico al que se enfrentan los responsables de las organizaciones. En este artículo se detalla la solución propuesta a un caso real del Instituto Canario de Estadística (ISTAC) haciendo uso de una aproximación orientada a servicios, basada en eventos (EDSOA) y utilizando como software base Apache Kafka.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2487</post_id>
		<post_date><![CDATA[2017-06-30 02:56:02]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mejorando-la-arquitectura-de-la-infraestructura-de-datos-y-metadatos-estadisticos-de-canarias-edatos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>3</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La integración de datos entre distintos sistemas es un problema típico al que se enfrentan los responsables de las organizaciones. En este artículo se detalla la solución propuesta a un caso real del Instituto Canario de Estadística (ISTAC) haciendo uso de una aproximación orientada a servicios, basada en eventos (EDSOA) y utilizando como software base Apache Kafka.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/019]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496952572.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496952572.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Peña Dorta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carlos@arte-consultores.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Arte Consultores Tecnológicos, S.L., Canarias, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Rita Díaz Adán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[rdiaada@arte-consultores.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Arte Consultores Tecnológicos, S.L., Canarias, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alberto González Yanes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jgonyanp@gobiernodecanarias.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto Canario de Estadísticas, Canarias, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Optimización de indicadores técnicos utilizando un conjunto de Algoritmos Evolutivos Multiobjetivo</title>
		<link>https://biblioteca.sistedes.es/articulo/optimizacion-de-indicadores-tecnicos-utilizando-un-conjunto-de-algoritmos-evolutivos-multiobjetivo-2/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/optimizacion-de-indicadores-tecnicos-utilizando-un-conjunto-de-algoritmos-evolutivos-multiobjetivo-2/</guid>
		<description></description>
		<content><![CDATA[Los indicadores técnicos, mediante la aplicación de un conjunto de fórmulas matemáticas, representan de forma gráfica la serie de precios de un activo. Estas fórmulas comprenden un conjunto de reglas y parámetros cuyos valores son desconocidos y dependen de factores, como el mercado en el que opera, o el tamaño de la ventana de tiempo. Este trabajo se centra en la realización de una aplicación software que optimiza, en tiempo real, el valor de los parámetros para dichos indicadores técnicos mediante el uso de algoritmos evolutivos multiobjetivos (AEMOs). A diferencia de otros enfoques, en este documento se aplica un conjunto de AEMOs diferentes que compiten entre sí, con el fin de lograr mejores rendimientos con un riesgo mínimo. El proceso de optimización es continuo y tiene lugar al final de cada intervalo de tiempo. Esta técnica permite aplicar soluciones no dominadas, obtenidas con diferentes AEMOs y puede mejorar considerablemente los resultados de la estrategia Buy &amp; Hold, incluso operando diariamente. Esta afirmación se demostrará comparando los resultados con los presentados previamente en la literatura. Para realizar esta operativa se ha empleado una arquitectura basada en servicios, donde las distintas partes del software han sido implementadas como servicios.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2489</post_id>
		<post_date><![CDATA[2017-06-30 02:56:02]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[optimizacion-de-indicadores-tecnicos-utilizando-un-conjunto-de-algoritmos-evolutivos-multiobjetivo-2]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="algoritmos-evolutivos"><![CDATA[algoritmos evolutivos]]></category>
		<category domain="post_tag" nicename="indicadores-tecnicos"><![CDATA[Indicadores Técnicos]]></category>
		<category domain="post_tag" nicename="optimizacion-multiobjetivo"><![CDATA[Optimización Multiobjetivo]]></category>
		<category domain="post_tag" nicename="servicios"><![CDATA[Servicios]]></category>
		<category domain="post_tag" nicename="trading-automatizado"><![CDATA[Trading automatizado]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los indicadores técnicos, mediante la aplicación de un conjunto de fórmulas matemáticas, representan de forma gráfica la serie de precios de un activo. Estas fórmulas comprenden un conjunto de reglas y parámetros cuyos valores son desconocidos y dependen de factores, como el mercado en el que opera, o el tamaño de la ventana de tiempo. Este trabajo se centra en la realización de una aplicación software que optimiza, en tiempo real, el valor de los parámetros para dichos indicadores técnicos mediante el uso de algoritmos evolutivos multiobjetivos (AEMOs). A diferencia de otros enfoques, en este documento se aplica un conjunto de AEMOs diferentes que compiten entre sí, con el fin de lograr mejores rendimientos con un riesgo mínimo. El proceso de optimización es continuo y tiene lugar al final de cada intervalo de tiempo. Esta técnica permite aplicar soluciones no dominadas, obtenidas con diferentes AEMOs y puede mejorar considerablemente los resultados de la estrategia Buy & Hold, incluso operando diariamente. Esta afirmación se demostrará comparando los resultados con los presentados previamente en la literatura. Para realizar esta operativa se ha empleado una arquitectura basada en servicios, donde las distintas partes del software han sido implementadas como servicios.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/020]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Soltero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[franciscojose.soltero@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[david.granada@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Marcos López]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[marcos.lopez@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Juan M. Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>On the feasibility of measuring performance using PPINOT in CMMN</title>
		<link>https://biblioteca.sistedes.es/articulo/on-the-feasibility-of-measuring-performance-using-ppinot-in-cmmn/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/on-the-feasibility-of-measuring-performance-using-ppinot-in-cmmn/</guid>
		<description></description>
		<content><![CDATA[Monitoring and measuring the performance of business processes are valuable tasks that facilitate the identification of possible improvement areas within the organisation according to the fulfillment of its strategic and business goals. A large number of techniques and tools have been developed with the aim of measuring process performance, but most of those processes are structured processes, usually defined using BPMN. The object of this paper is to identify and to analyse the feasibility of using an existing mechanism for the definition and modelling of process performance indicators (PPINOT) in a different context to structured BPMN processes; such as Cases, usually modelled using CMMN. This analysis is based on the similarities between CMMN and BPMN, and on characteristics and attributes used by PPINOT to get values from the process.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2490</post_id>
		<post_date><![CDATA[2017-06-30 02:56:02]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[on-the-feasibility-of-measuring-performance-using-ppinot-in-cmmn]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>1</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="business-processes"><![CDATA[business processes]]></category>
		<category domain="post_tag" nicename="cmmn"><![CDATA[CMMN]]></category>
		<category domain="post_tag" nicename="performance-indicators"><![CDATA[performance indicators]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Monitoring and measuring the performance of business processes are valuable tasks that facilitate the identification of possible improvement areas within the organisation according to the fulfillment of its strategic and business goals. A large number of techniques and tools have been developed with the aim of measuring process performance, but most of those processes are structured processes, usually defined using BPMN. The object of this paper is to identify and to analyse the feasibility of using an existing mechanism for the definition and modelling of process performance indicators (PPINOT) in a different context to structured BPMN processes; such as Cases, usually modelled using CMMN. This analysis is based on the similarities between CMMN and BPMN, and on characteristics and attributes used by PPINOT to get values from the process.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/021]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496953559.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496953559.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Bedilia Estrada-Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[iestrada@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Adela del-Río-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[adeladelrio@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Depto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Depto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Depto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Devising an SLA-Aware Methodology to Improve Process Performance</title>
		<link>https://biblioteca.sistedes.es/articulo/devising-an-sla-aware-methodology-to-improve-process-performance/</link>
		<pubDate>Fri, 30 Jun 2017 00:56:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/devising-an-sla-aware-methodology-to-improve-process-performance/</guid>
		<description></description>
		<content><![CDATA[Aiming to be as competitive as possible, organisations are always pursuing to improve their business processes applying corrective actions when needed. However, the actual analysis and decision making for those actions is typically a challenging task relying on extensive human-in-the-loop expertise. Specifically, this improvement process usually involves: (i) to analyse evidences to understand the current behavior; (ii) to decide the actual objectives (usually defined in Service Level Agreements -SLAs- based on intuition) and (iii) to establish the improvement plan. In this ongoing work, we aim to propose a data-driven and intuition-free methodology to define an SLA as a governance element that specifies the service level objectives in an explicit way. Such a methodology considers process performance indicators that are analysed by means of inference, optimization, and simulation techniques. In order to motivate and exemplify our work we address a Healthcare scenario.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2491</post_id>
		<post_date><![CDATA[2017-06-30 02:56:02]]></post_date>
		<post_date_gmt><![CDATA[2017-06-30 00:56:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[devising-an-sla-aware-methodology-to-improve-process-performance]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>3</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Aiming to be as competitive as possible, organisations are always pursuing to improve their business processes applying corrective actions when needed. However, the actual analysis and decision making for those actions is typically a challenging task relying on extensive human-in-the-loop expertise. Specifically, this improvement process usually involves: (i) to analyse evidences to understand the current behavior; (ii) to decide the actual objectives (usually defined in Service Level Agreements -SLAs- based on intuition) and (iii) to establish the improvement plan. In this ongoing work, we aim to propose a data-driven and intuition-free methodology to define an SLA as a governance element that specifies the service level objectives in an explicit way. Such a methodology considers process performance indicators that are analysed by means of inference, optimization, and simulation techniques. In order to motivate and exemplify our work we address a Healthcare scenario.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/023]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496954008.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1496954008.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Müller]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Minsu Cho]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Pohang University of Science and Technology, Pohang, Korea.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Minseok Song]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Pohang University of Science and Technology, Pohang, Kore]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Seville, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Seville, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Actualización reactiva de bases de datos usando cadenas de procesadores de flujo de datos</title>
		<link>https://biblioteca.sistedes.es/articulo/actualizacion-reactiva-de-bases-de-datos-usando-cadenas-de-procesadores-de-flujo-de-datos/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:03 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/actualizacion-reactiva-de-bases-de-datos-usando-cadenas-de-procesadores-de-flujo-de-datos/</guid>
		<description></description>
		<content><![CDATA[Este trabajo en curso explora el uso de cadenas de procesadores de flujos de datos como medio para proporcionar a aplicaciones con requisitos de tiempo real (TR) un acceso a la información del entorno bajo una perspectiva de base de datos (consultas continuas consistentes). En este trabajo se formulan las características que han de ofrecer las cadenas de procesadores de flujos de datos para este caso de uso, se define la arquitectura de procesado a utilizar y se asig-nan responsabilidades a cada uno de los elementos de la arquitectura.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2550</post_id>
		<post_date><![CDATA[2017-07-02 04:47:03]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:03]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[actualizacion-reactiva-de-bases-de-datos-usando-cadenas-de-procesadores-de-flujo-de-datos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="base-de-datos-en-memoria"><![CDATA[Base de datos en memoria]]></category>
		<category domain="post_tag" nicename="consultas-sobre-flujos-de-datos"><![CDATA[Consultas sobre flujos de datos]]></category>
		<category domain="post_tag" nicename="flujos-de-datos"><![CDATA[Flujos de datos]]></category>
		<category domain="post_tag" nicename="tiempo-real"><![CDATA[Tiempo real]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este trabajo en curso explora el uso de cadenas de procesadores de flujos de datos como medio para proporcionar a aplicaciones con requisitos de tiempo real (TR) un acceso a la información del entorno bajo una perspectiva de base de datos (consultas continuas consistentes). En este trabajo se formulan las características que han de ofrecer las cadenas de procesadores de flujos de datos para este caso de uso, se define la arquitectura de procesado a utilizar y se asig-nan responsabilidades a cada uno de los elementos de la arquitectura.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/011]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_2.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_2.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel Algorri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[miguel.algorri@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José María Drake]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jose.drake@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Marta Zorrilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[marta.zorrilla@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Linda-based Platform for the Parallel Execution of Out-place Model Transformations</title>
		<link>https://biblioteca.sistedes.es/articulo/a-linda-based-platform-for-the-parallel-execution-of-out-place-model-transformations/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:04 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-linda-based-platform-for-the-parallel-execution-of-out-place-model-transformations/</guid>
		<description></description>
		<content><![CDATA[Context: The performance and scalability of model transformations is gaining interest as industry is progressively adopting model-driven techniques and multicore computers are becoming commonplace. However, existing model transformation engines are mostly based on sequential and in-memory execution strategies, and thus their capabilities to transform large models in parallel and distributed environments are limited. Objective: This paper presents a solution that provides concurrency and distribution to model transformations. Method: Inspired by the concepts and principles of the Linda coordination language, and the use of data parallelism to achieve parallelization, a novel Java-based execution platform is introduced. It offers a set of core features for the parallel execution of out-place transformations that can be used as a target for high-level transformation language compilers. Results: Significant gains in performance and scalability of this platform are reported with regard to existing model transformation solutions. These results are demonstrated by running a model transformation test suite, and by its comparison against several state-of-the-art model transformation engines. Conclusion: Our Linda-based approach to the concurrent execution of model transformations can serve as a platform for their scalable and efficient implementation in parallel and distributed environments.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2551</post_id>
		<post_date><![CDATA[2017-07-02 04:47:04]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-linda-based-platform-for-the-parallel-execution-of-out-place-model-transformations]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="model-transformation"><![CDATA[Model Transformation]]></category>
		<category domain="post_tag" nicename="parallelization"><![CDATA[Parallelization]]></category>
		<category domain="post_tag" nicename="performance"><![CDATA[Performance]]></category>
		<category domain="post_tag" nicename="scalability"><![CDATA[Scalability]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Context: The performance and scalability of model transformations is gaining interest as industry is progressively adopting model-driven techniques and multicore computers are becoming commonplace. However, existing model transformation engines are mostly based on sequential and in-memory execution strategies, and thus their capabilities to transform large models in parallel and distributed environments are limited.  Objective: This paper presents a solution that provides concurrency and distribution to model transformations.  Method: Inspired by the concepts and principles of the Linda coordination language, and the use of data parallelism to achieve parallelization, a novel Java-based execution platform is introduced. It offers a set of core features for the parallel execution of out-place transformations that can be used as a target for high-level transformation language compilers.  Results: Significant gains in performance and scalability of this platform are reported with regard to existing model transformation solutions. These results are demonstrated by running a model transformation test suite, and by its comparison against several state-of-the-art model transformation engines.  Conclusion: Our Linda-based approach to the concurrent execution of model transformations can serve as a platform for their scalable and efficient implementation in parallel and distributed environments.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/075]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_3.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_3.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Loli Burgueño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[loli@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Málaga,  GISUM/Atenea Research Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Wimmer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[wimmer@big.tuwien.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Christian Doppler Laboratory for Model-Integrated Smart Production,  TU Wien]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Vallecillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[av@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga,  GISUM/Atenea Research Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Requirement-driven Evolution in Software Product Lines: A Systematic Mapping Study</title>
		<link>https://biblioteca.sistedes.es/articulo/requirement-driven-evolution-in-software-product-lines-a-systematic-mapping-study/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:04 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/requirement-driven-evolution-in-software-product-lines-a-systematic-mapping-study/</guid>
		<description></description>
		<content><![CDATA[Artículo relevante. Leticia Montalvillo, Oscar Díaz: Requirement-driven evolution in software product lines: A systematic mapping study. Journal of Systems and Software Volume 122, December 2016, Pages 110-143, COMPUTER SCIENCE, SOFTWARE ENGINEERING, IF: 1,424, Posición: (24/106), Cuartil: Q1. DOI http://dx.doi.org/10.1016/j.jss.2016.08.053]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2552</post_id>
		<post_date><![CDATA[2017-07-02 04:47:04]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[requirement-driven-evolution-in-software-product-lines-a-systematic-mapping-study]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="evolution"><![CDATA[Evolution]]></category>
		<category domain="post_tag" nicename="software-product-lines"><![CDATA[software product lines]]></category>
		<category domain="post_tag" nicename="systematic-mapping-study"><![CDATA[Systematic Mapping Study]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Artículo relevante.  Leticia Montalvillo, Oscar Díaz: Requirement-driven evolution in software product lines: A systematic mapping study. Journal of Systems and Software Volume 122, December 2016, Pages 110-143, COMPUTER SCIENCE, SOFTWARE ENGINEERING, IF: 1,424, Posición: (24/106), Cuartil: Q1. DOI http://dx.doi.org/10.1016/j.jss.2016.08.053]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/007]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_4.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_4.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Leticia Montalvillo Mendizabal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[leticia.montalvillo@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of The Basque Country (UPV/EHU)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Oscar Diaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[oscar.diaz@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Survey on Metamorphic Testing</title>
		<link>https://biblioteca.sistedes.es/articulo/a-survey-on-metamorphic-testing/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:04 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-survey-on-metamorphic-testing/</guid>
		<description></description>
		<content><![CDATA[S. Segura, G. Fraser, A. B. Sanchez and A. Ruiz-Cortés, A Survey on Metamorphic Testing, in IEEE Transactions on Software Engineering, vol. 42, no. 9, pp. 805-824, Sept. 1 2016. https://doi.org/10.1109/TSE.2016.2532875 Indicadores de calidad: - Revista de referencia en el área de Ingeniería del Software (CS-SE: 20/106). - Ha recibido 9 citas desde su publicación en febrero de 2016 (más otras 5-7 citas por aparecer en las actas del segundo workshop internacional de pruebas metamórficas [1]). - Hemos sido invitados a presentar el trabajo en ICSE17 como parte de la iniciativa journal-first (ver programa de la conferencia [2]). - Colaboración internacional con el profesor Gordon Fraser. [1] https://www.cs.montana.edu/met17/ [2] http://icse2017.gatech.edu/?q=technical-research-accepted]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2553</post_id>
		<post_date><![CDATA[2017-07-02 04:47:04]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-survey-on-metamorphic-testing]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="metamorphic-testing"><![CDATA[metamorphic testing]]></category>
		<category domain="post_tag" nicename="oracle-problem"><![CDATA[oracle problem]]></category>
		<category domain="post_tag" nicename="survey"><![CDATA[survey]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[S. Segura, G. Fraser, A. B. Sanchez and A. Ruiz-Cortés, A Survey on Metamorphic Testing, in IEEE Transactions on Software Engineering, vol. 42, no. 9, pp. 805-824, Sept. 1 2016. https://doi.org/10.1109/TSE.2016.2532875  Indicadores de calidad:  - Revista de referencia en el área de Ingeniería del Software (CS-SE: 20/106).  - Ha recibido 9 citas desde su publicación en febrero de 2016 (más otras 5-7 citas por aparecer en las actas del segundo workshop internacional de pruebas metamórficas [1]).  - Hemos sido invitados a presentar el trabajo en ICSE17 como parte de la iniciativa journal-first (ver programa de la conferencia [2]).  - Colaboración internacional con el profesor Gordon Fraser.  [1] https://www.cs.montana.edu/met17/ [2] http://icse2017.gatech.edu/?q=technical-research-accepted ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/066]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_6.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_6.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Gordon Fraser]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gordon.fraser@sheffield.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Sheffield]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ana B. Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[anabsanchez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Assessment of class mutation operators for C++ with the MuCPP mutation system</title>
		<link>https://biblioteca.sistedes.es/articulo/assessment-of-class-mutation-operators-for-c-with-the-mucpp-mutation-system/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:04 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/assessment-of-class-mutation-operators-for-c-with-the-mucpp-mutation-system/</guid>
		<description></description>
		<content><![CDATA[Context: Mutation testing has been mainly analyzed regarding traditional mutation operators involving structured programming constructs common in mainstream languages, but mutations at the class level have not been assessed to the same extent. This fact is noteworthy in the case of C++ , despite being one of the most relevant languages including object-oriented features. Objective: This paper provides a complete evaluation of class operators for the C++ programming language. MuCPP, a new system devoted to the application of mutation testing to this language, was developed to this end. This mutation system implements class mutation operators in a robust way, dealing with the inherent complexity of the language. Method: MuCPP generates the mutants by traversing the abstract syntax tree of each translation unit with the Clang API, and stores mutants as branches in the Git version control system. The tool is able to detect duplicate mutants, avoid system headers, and drive the compilation process. Then, MuCPP is used to conduct experiments with several open-source C++ programs. Results: The improvement rules listed in this paper to reduce unproductive class mutants have a significant impact in the computational cost of the technique. We also calculate the quantity and distribution of mutants generated with class operators, which generate far fewer mutants than their traditional counterparts. Conclusions: We show that the tests accompanying these programs cannot detect faults related to particular object-oriented features of C++ . In order to increase the mutation score, we create new test scenarios to kill the surviving class mutants for all the applications. The results confirm that, while traditional mutation operators are still needed, class operators can complement them and help testers further improve the test suite. Autores: Pedro Delgado-Pérez, Inmaculada Medina-Bulo, Francisco Palomo-Lozano, Antonio García-Domínguez, Juan José Domínguez-Jiménez Revista: Information and Software Technology, Volume 81, January 2017, Pages 169-184, http://dx.doi.org/10.1016/j.infsof.2016.07.002 Factor de impacto: 1.569 - Q1 (listado JCR 2015)]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2554</post_id>
		<post_date><![CDATA[2017-07-02 04:47:04]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:04]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[assessment-of-class-mutation-operators-for-c-with-the-mucpp-mutation-system]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="c"><![CDATA[C++]]></category>
		<category domain="post_tag" nicename="class-mutation-operators"><![CDATA[Class mutation operators]]></category>
		<category domain="post_tag" nicename="mutation-system"><![CDATA[Mutation system]]></category>
		<category domain="post_tag" nicename="mutation-testing"><![CDATA[Mutation testing]]></category>
		<category domain="post_tag" nicename="object-oriented-programming"><![CDATA[Object-oriented programming]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Context: Mutation testing has been mainly analyzed regarding traditional mutation operators involving structured programming constructs common in mainstream languages, but mutations at the class level have not been assessed to the same extent. This fact is noteworthy in the case of C++ , despite being one of the most relevant languages including object-oriented features. Objective: This paper provides a complete evaluation of class operators for the C++ programming language. MuCPP, a new system devoted to the application of mutation testing to this language, was developed to this end. This mutation system implements class mutation operators in a robust way, dealing with the inherent complexity of the language. Method: MuCPP generates the mutants by traversing the abstract syntax tree of each translation unit with the Clang API, and stores mutants as branches in the Git version control system. The tool is able to detect duplicate mutants, avoid system headers, and drive the compilation process. Then, MuCPP is used to conduct experiments with several open-source C++ programs. Results: The improvement rules listed in this paper to reduce unproductive class mutants have a significant impact in the computational cost of the technique. We also calculate the quantity and distribution of mutants generated with class operators, which generate far fewer mutants than their traditional counterparts. Conclusions: We show that the tests accompanying these programs cannot detect faults related to particular object-oriented features of C++ . In order to increase the mutation score, we create new test scenarios to kill the surviving class mutants for all the applications. The results confirm that, while traditional mutation operators are still needed, class operators can complement them and help testers further improve the test suite.   Autores: Pedro Delgado-Pérez, Inmaculada Medina-Bulo, Francisco Palomo-Lozano, Antonio García-Domínguez, Juan José Domínguez-Jiménez  Revista: Information and Software Technology, Volume 81, January 2017, Pages 169-184, http://dx.doi.org/10.1016/j.infsof.2016.07.002  Factor de impacto: 1.569 - Q1 (listado JCR 2015)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/067]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_7.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_7.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Delgado-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pedro.delgado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco Palomo-Lozano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[francisco.palomo@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Garcia-Dominguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[a.garcia-dominguez@aston.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science,  Aston University]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Juan José Domínguez-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[juanjose.dominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>tESA: using semantics of scientific articles to approximate semantic relatedness</title>
		<link>https://biblioteca.sistedes.es/articulo/tesa-using-semantics-of-scientific-articles-to-approximate-semantic-relatedness/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/tesa-using-semantics-of-scientific-articles-to-approximate-semantic-relatedness/</guid>
		<description></description>
		<content><![CDATA[Short abstract Semantic relatedness is a measure that quantifies the strength of a semantic link between two concepts. Often, it can be efficiently approximated with methods that operate on words, which represent these concepts. Approximating semantic relatedness between texts is an important part of many text and knowledge processing tasks of crucial importance in the ever growing domain of biomedical informatics. In this paper we present tESA, an extension to a well known Explicit Semantic Relatedness (ESA) method, which leverages the semantics of a corpus of scientific documents to improve the quality of the relatedness approximation for biomedical domain. In our extension we use two separate sets of vectors, corresponding to different sections of the articles from the underlying corpus of documents, as opposed to the original method, which only uses a single vector space. Our findings suggest that extending the original ESA methodology with the use of title vectors of the documents of scientific corpora may be used to enhance the performance of a distributional semantic relatedness measures. Background Semantic relatedness is a measure that quantifies the strength of a semantic link between two concepts. Often, it can be efficiently approximated with methods that operate on words, which represent these concepts. Approximating semantic relatedness between texts and concepts represented by these texts is an important part of many text and knowledge processing tasks of crucial importance in the ever growing domain of biomedical informatics. The problem of most state-of-the-art methods for calculating semantic relatedness is their dependence on highly specialized, structured knowledge resources, which makes these methods poorly adaptable for many usage scenarios. On the other hand, the domain knowledge in the Life Sciences has become more and more accessible, but mostly in its unstructured form - as texts in large document collections, which makes its use more challenging for automated processing. In this paper we present tESA, an extension to a well known Explicit Semantic Relatedness (ESA) method. Results In our extension we use two separate sets of vectors, corresponding to different sections of the articles from the underlying corpus of documents, as opposed to the original method, which only uses a single vector space. We present an evaluation of Life Sciences domain-focused applicability of both tESA and domain-adapted Explicit Semantic Analysis. The methods are tested against a set of standard benchmarks established for the evaluation of biomedical semantic relatedness quality. Our experiments show that the propsed method achieves results comparable with or superior to the current state-of-the-art methods. Additionally, a comparative discussion of the results obtained with tESA and ESA is presented, together with a study of the adaptability of the methods to different corpora and their performance with different input parameters. Conclusions Our findings suggest that combined use of the semantics from different sections (i.e. extending the original ESA methodology with the use of title vectors) of the documents of scientific corpora may be used to enhance the performance of a distributional semantic relatedness measures, which can be observed in the largest reference datasets. We also present the impact of the proposed extension on the size of distributional representations. Publication details The original paper tESA: a distributional measure for calculating semantic relatedness (DOI: 10.1186/s13326-016-0109-6), authored by Maciej Rybinski and José Francisco Aldana-Montes, was published online in the Journal of Biomedical Semantics on 28th of December 2016. The Journal of Biomedical Semantics currently holds (according to the latest JCR for 2015) an impact factor of 1.62, with a five-year impact factor of 2.511. The main impact factor places the Journal in the second cuartile (Q2) of its JCR-SCI category MATHEMATICAL &amp; COMPUTATIONAL BIOLOGY. Acknowledgments Work presented here was partially supported by grants TIN2014-58304-R (Ministerio de Ciencia e Innovación), P11-TIC-7529 and P12-TIC-1519 (Plan Andaluz de Investigación, Desarrollo e Innovación) and EU FP7-KBBE-289126 (the EU 7th Framework Programme, BIOLEDGE).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2555</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[tesa-using-semantics-of-scientific-articles-to-approximate-semantic-relatedness]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="bioinformatics"><![CDATA[Bioinformatics]]></category>
		<category domain="post_tag" nicename="biomedical-semantics"><![CDATA[Biomedical semantics]]></category>
		<category domain="post_tag" nicename="distributional-linguistics"><![CDATA[Distributional linguistics]]></category>
		<category domain="post_tag" nicename="explicit-semantic-analysis"><![CDATA[Explicit semantic analysis]]></category>
		<category domain="post_tag" nicename="knowledge-extraction"><![CDATA[Knowledge extraction]]></category>
		<category domain="post_tag" nicename="semantic-relatedness"><![CDATA[Semantic relatedness]]></category>
		<category domain="post_tag" nicename="semantic-similarity"><![CDATA[Semantic similarity]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Short abstract  Semantic relatedness is a measure that quantifies the strength of a semantic link between two concepts. Often, it can be efficiently approximated with methods that operate on words, which represent these concepts. Approximating semantic relatedness between texts is an important part of many text and knowledge processing tasks of crucial importance in the ever growing domain of biomedical informatics.   In this paper we present tESA, an extension to a well known Explicit Semantic Relatedness (ESA) method, which leverages the semantics of a corpus of scientific documents to improve the quality of the relatedness approximation for biomedical domain. In our extension we use two separate sets of vectors, corresponding to different sections of the articles from the underlying corpus of documents, as opposed to the original method, which only uses a single vector space.  Our findings suggest that extending the original ESA methodology with the use of title vectors of the documents of scientific corpora may be used to enhance the performance of a distributional semantic relatedness measures.  Background  Semantic relatedness is a measure that quantifies the strength of a semantic link between two concepts. Often, it can be efficiently approximated with methods that operate on words, which represent these concepts. Approximating semantic relatedness between texts and concepts represented by these texts is an important part of many text and knowledge processing tasks of crucial importance in the ever growing domain of biomedical informatics. The problem of most state-of-the-art methods for calculating semantic relatedness is their dependence on highly specialized, structured knowledge resources, which makes these methods poorly adaptable for many usage scenarios. On the other hand, the domain knowledge in the Life Sciences has become more and more accessible, but mostly in its unstructured form - as texts in large document collections, which makes its use more challenging for automated processing. In this paper we present tESA, an extension to a well known Explicit Semantic Relatedness (ESA) method.   Results  In our extension we use two separate sets of vectors, corresponding to different sections of the articles from the underlying corpus of documents, as opposed to the original method, which only uses a single vector space. We present an evaluation of Life Sciences domain-focused applicability of both tESA and domain-adapted Explicit Semantic Analysis. The methods are tested against a set of standard benchmarks established for the evaluation of biomedical semantic relatedness quality. Our experiments show that the propsed method achieves results comparable with or superior to the current state-of-the-art methods. Additionally, a comparative discussion of the results obtained with tESA and ESA is presented, together with a study of the adaptability of the methods to different corpora and their performance with different input parameters.   Conclusions  Our findings suggest that combined use of the semantics from different sections (i.e. extending the original ESA methodology with the use of title vectors) of the documents of scientific corpora may be used to enhance the performance of a distributional semantic relatedness measures, which can be observed in the largest reference datasets. We also present the impact of the proposed extension on the size of distributional representations.  Publication details  The original paper tESA: a distributional measure for calculating semantic relatedness (DOI: 10.1186/s13326-016-0109-6), authored by Maciej Rybinski and José Francisco Aldana-Montes, was published online in the Journal of Biomedical Semantics on 28th of December 2016. The Journal of Biomedical Semantics currently holds (according to the latest JCR for 2015) an impact factor of 1.62, with a five-year impact factor of 2.511. The main impact factor places the Journal in the second cuartile (Q2) of its JCR-SCI category MATHEMATICAL & COMPUTATIONAL BIOLOGY.   Acknowledgments  Work presented here was partially supported by grants TIN2014-58304-R (Ministerio de Ciencia e Innovación), P11-TIC-7529 and P12-TIC-1519 (Plan Andaluz de Investigación, Desarrollo e Innovación) and EU FP7-KBBE-289126 (the EU 7th Framework Programme, BIOLEDGE).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/022]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_8.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_8.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Maciej Rybinski]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[maciek.rybinski@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Malaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose F Aldana Montes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jfam@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Malaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Rich contextual information for monitoring the elderly in an early stage of cognitive impairment</title>
		<link>https://biblioteca.sistedes.es/articulo/rich-contextual-information-for-monitoring-the-elderly-in-an-early-stage-of-cognitive-impairment/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/rich-contextual-information-for-monitoring-the-elderly-in-an-early-stage-of-cognitive-impairment/</guid>
		<description></description>
		<content><![CDATA[Artículo relevante ya publicado. Revista de publicación: Pervasive and Mobile Computing Available online : 24 May 2016 Numero: 34 Páginas: 106 - 125 DOI: http://dx.doi.org/10.1016/j.pmcj.2016.05.001 Factor de impacto: JCR 2.079, SJR 0.872, IPP 2.289, SNIP 2.051 Abstract: With the increase in the elderly population, there is a concomitant growth in the number of cases of cognitive impairment. The early stages of these disorders can cause the elderly difficulties in performing their daily activities. To improve their independence while keeping their caregivers informed, this paper presents a monitoring system that focuses on the use of rich contextual information to detect a wide variety of a cognitively impaired persons routines and deviations from those routines. A detailed architecture of the system is presented together with an in-depth description of the algorithms for the identification of routines and deviations. In an experimental test with students, the algorithms identified some 91% of the routines and some 96% of the deviations.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2556</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[rich-contextual-information-for-monitoring-the-elderly-in-an-early-stage-of-cognitive-impairment]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="contextual-information"><![CDATA[Contextual information]]></category>
		<category domain="post_tag" nicename="eldercare"><![CDATA[Eldercare]]></category>
		<category domain="post_tag" nicename="identification-of-routines"><![CDATA[Identification of routines]]></category>
		<category domain="post_tag" nicename="sociological-profiles"><![CDATA[Sociological Profiles]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Artículo relevante ya publicado. Revista de publicación: Pervasive and Mobile Computing Available online : 24 May 2016 Numero: 34 Páginas: 106 - 125 DOI: http://dx.doi.org/10.1016/j.pmcj.2016.05.001 Factor de impacto: JCR 2.079, SJR 0.872, IPP 2.289, SNIP 2.051  Abstract:  With the increase in the elderly population, there is a concomitant growth in the number of cases of cognitive impairment. The early stages of these disorders can cause the elderly difficulties in performing their daily activities. To improve their independence while keeping their caregivers informed, this paper presents a monitoring system that focuses on the use of rich contextual information to detect a wide variety of a cognitively impaired persons routines and deviations from those routines. A detailed architecture of the system is presented together with an in-depth description of the algorithms for the identification of routines and deviations. In an experimental test with students, the algorithms identified some 91% of the routines and some 96% of the deviations.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/064]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_9.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_9.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose García-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Murillo Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards Mutation Testing of Configurable Simulink Models: a Product Line Engineering Perspective</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-mutation-testing-of-configurable-simulink-models-a-product-line-engineering-perspective/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-mutation-testing-of-configurable-simulink-models-a-product-line-engineering-perspective/</guid>
		<description></description>
		<content><![CDATA[Mutation testing has been found to be an efficient technique in order to assess the quality of a test suite. The use of Simulink models is increasing in both industry and academia to model and simulate complex systems such as Cyber-Physical Systems (CPSs). An advantage of Simulink is its ease to integrate software and control algorithms with complex mathematical models that typically represent continuous dynamic behaviors. In addition to that, the increasing trend of industry in adopting product line engineering methods to efficiently support the variability that their products demand is resulting in configurable Simulink models. Consequently, many configurations can be employed to test the configurable system. Each of these configurations will have a set of mutants, which will be in accordance with the configuration characteristics (i.e., features). However, manually generating and configuring mutants for each of the configurations is a time-consuming and non-systematic process. To deal with this problem, we propose a methodology supported by a tool that automatically generates mutants for configurable Simulink models.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2557</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-mutation-testing-of-configurable-simulink-models-a-product-line-engineering-perspective]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cyber-physical-systems"><![CDATA[Cyber-Physical Systems]]></category>
		<category domain="post_tag" nicename="feature-modeling"><![CDATA[Feature Modeling]]></category>
		<category domain="post_tag" nicename="matlabsimulink"><![CDATA[MATLAB/Simulink]]></category>
		<category domain="post_tag" nicename="mutation-testing"><![CDATA[Mutation testing]]></category>
		<category domain="post_tag" nicename="product-line-engineering"><![CDATA[Product Line Engineering]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Mutation testing has been found to be an efficient technique in order to assess the quality of a test suite. The use of Simulink models is increasing in both industry and academia to model and simulate complex systems such as Cyber-Physical Systems (CPSs). An advantage of Simulink is its ease to integrate software and control algorithms with complex mathematical models that typically represent continuous dynamic behaviors. In addition to that, the increasing trend of industry in adopting product line engineering methods to efficiently support the variability that their products demand is resulting in configurable Simulink models. Consequently, many configurations can be employed to test the configurable system. Each of these configurations will have a set of mutants, which will be in accordance with the configuration characteristics (i.e., features). However, manually generating and configuring mutants for each of the configurations is a time-consuming and non-systematic process. To deal with this problem, we propose a methodology supported by a tool that automatically generates mutants for configurable Simulink models.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/008]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_11.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_11.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aitor Arrieta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aarrieta@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Urtzi Markiegi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[umarkiegi@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Leire Etxeberria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[letxeberria@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Test Case Prioritization of Configurable Cyber-Physical Systems with Weight-Based Search Algorithms</title>
		<link>https://biblioteca.sistedes.es/articulo/test-case-prioritization-of-configurable-cyber-physical-systems-with-weight-based-search-algorithms/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/test-case-prioritization-of-configurable-cyber-physical-systems-with-weight-based-search-algorithms/</guid>
		<description></description>
		<content><![CDATA[El paper fue publicado en julio de 2016 en la conferencia GECCO (The Genetic and Evolutionary Computation Conference), que es un congreso de clase 2 del ranking SCIE de congresos relevantes. Hasta la fecha, según google scholar, ha recibido un total de dos citas. Cyber-Physical Systems (CPSs) can be found in many sectors (e.g., automotive and aerospace). These systems are usually configurable to give solutions based on different needs. The variability of these systems is large, which implies they can be set into millions of configurations. As a result, different testing processes are needed to efficiently test these systems: the appropriate configurations must be selected and relevant test cases for each configuration must be chosen as well as prioritized. Prioritizing the order in which the test cases are executed reduces the time for detecting faults in these kinds of systems. However, the test suite size is often large and exploring all the possible test case orders is infeasible. Search algorithms can help find optimal solutions from a large solution space. This paper presents an approach based on weight-based search algorithms for prioritizing the test cases for configurable CPSs. We empirically evaluate the performance of the following algorithms with two case studies: Weight-Based Genetic Algorithms, Random Weighted Genetic Algorithms, Greedy, Alternating Variable Method and Random Search (RS). Our results suggest that all the search algorithms outperform RS, which is taken as a baseline. Local search algorithms have shown better performance than global search algorithms.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2558</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[test-case-prioritization-of-configurable-cyber-physical-systems-with-weight-based-search-algorithms]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="configurable-cyber-physical-systems"><![CDATA[Configurable Cyber-Physical Systems]]></category>
		<category domain="post_tag" nicename="search-algorithms"><![CDATA[Search Algorithms]]></category>
		<category domain="post_tag" nicename="test-case-prioritization"><![CDATA[Test Case Prioritization]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El paper fue publicado en julio de 2016 en la conferencia GECCO (The Genetic and Evolutionary Computation Conference), que es un congreso de clase 2 del ranking SCIE de congresos relevantes.  Hasta la fecha, según google scholar, ha recibido un total de dos citas.    Cyber-Physical Systems (CPSs) can be found in many sectors (e.g., automotive and aerospace). These systems are usually configurable to give solutions based on different needs. The variability of these systems is large, which implies they can be set into millions of configurations. As a result, different testing processes are needed to efficiently test these systems: the appropriate configurations must be selected and relevant test cases for each configuration must be chosen as well as prioritized. Prioritizing the order in which the test cases are executed reduces the time for detecting faults in these kinds of systems. However, the test suite size is often large and exploring all the possible test case orders is infeasible. Search algorithms can help find optimal solutions from a large solution space. This paper presents an approach based on weight-based search algorithms for prioritizing the test cases for configurable CPSs. We empirically evaluate the performance of the following algorithms with two case studies: Weight-Based Genetic Algorithms, Random Weighted Genetic Algorithms, Greedy, Alternating Variable Method and Random Search (RS). Our results suggest that all the search algorithms outperform RS, which is taken as a baseline. Local search algorithms have shown better performance than global search algorithms.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/043]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_12.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_12.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aitor Arrieta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aarrieta@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Shuai Wang]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[shuai@simula.no]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Simula Research Laboratory]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Goiuria Sagardui]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gsagardui@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Mondragon]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Leire Etxeberria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[letxeberria@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Compact and queryable representation of raster datasets</title>
		<link>https://biblioteca.sistedes.es/articulo/compact-and-queryable-representation-of-raster-datasets/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/compact-and-queryable-representation-of-raster-datasets/</guid>
		<description></description>
		<content><![CDATA[Titulo: Compact and queryable representation of raster datasets Autores: Susana Ladra, José R. Paramá, Fernando Silva-Coira Congreso: INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATA BASE MANAGEMENT (SSDBM) 2016 Clasificación Ranking SCIE. Clase 2 (A-) Clasidicación CORE: A Citas: 2 DOI: http://dx.doi.org/10.1145/2949689.2949710]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2559</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[compact-and-queryable-representation-of-raster-datasets]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="compresion-de-datos"><![CDATA[Compresión de datos]]></category>
		<category domain="post_tag" nicename="raster"><![CDATA[Ráster]]></category>
		<category domain="post_tag" nicename="sistemas-de-informacion-geografica"><![CDATA[Sistemas de Informacíon Geográfica]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Titulo: Compact and queryable representation of raster datasets Autores: Susana Ladra, José R. Paramá, Fernando Silva-Coira  Congreso: INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATA BASE MANAGEMENT (SSDBM) 2016  Clasificación Ranking SCIE. Clase 2 (A-) Clasidicación CORE: A  Citas: 2  DOI: http://dx.doi.org/10.1145/2949689.2949710]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/012]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_13.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_13.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Susana Ladra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[susana.ladra@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José R. Paramá]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jose.parama@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Fernando Silva-Coira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fernando.silva@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Multi-Objective Test Case Prioritization in Highly Configurable Systems: A Case Study</title>
		<link>https://biblioteca.sistedes.es/articulo/multi-objective-test-case-prioritization-in-highly-configurable-systems-a-case-study/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/multi-objective-test-case-prioritization-in-highly-configurable-systems-a-case-study/</guid>
		<description></description>
		<content><![CDATA[Test case prioritization schedules test cases for execution in an order that attempts to accelerate the detection of faults. The order of test cases is determined by prioritization objectives such as covering code or critical components as rapidly as possible. The importance of this technique has been recognized in the context of Highly-Configurable Systems (HCSs), where the potentially huge number of configurations makes testing extremely challenging. However, current approaches for test case prioritization in HCSs suffer from two main limitations. First, the prioritization is usually driven by a single objective which neglects the potential benefits of combining multiple criteria to guide the detection of faults. Second, instead of using industry-strength case studies, evaluations are conducted using synthetic data, which provides no information about the effectiveness of different prioritization objectives. In this paper, we address both limitations by studying 63 combinations of up to three prioritization objectives in accelerating the detection of faults in the Drupal framework. Results show that non-functional properties such as the number of changes in the features are more effective than functional metrics extracted from the configuration model. Results also suggest that multi-objective prioritization typically results in faster fault detection than mono-objective prioritization. Indicios de calidad de la revista: Journal of Systems and Software (Elsevier) ISSN: 0164-1212 Factor de impacto 2015: 1,424 Factor de impacto a 5 años: 1,767 Indexada en dos categorías: Computer Science / Theory &amp; Methods: 31/105 (Q2) Computer Science / Software Engineering: 24/106 (Q1) Otros datos: CiteScore: 2.93 Source Normalized Impact per Paper (SNIP): 2.415 SCImago Journal Rank (SJR): 0.897 Indicios de calidad del propio paper: Número de Citas según Google Scholar: 3 Número de lecturas según Research Gate: 73]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2560</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[multi-objective-test-case-prioritization-in-highly-configurable-systems-a-case-study]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="optimizacion-multi-objetivo"><![CDATA[optimización multi-objetivo]]></category>
		<category domain="post_tag" nicename="priorizacion-de-pruebas"><![CDATA[priorización de pruebas]]></category>
		<category domain="post_tag" nicename="sistemas-altamente-configurables"><![CDATA[sistemas altamente configurables]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Test case prioritization schedules test cases for execution in an order that attempts to accelerate the detection of faults. The order of test cases is determined by prioritization objectives such as covering code or critical components as rapidly as possible. The importance of this technique has been recognized in the context of Highly-Configurable Systems (HCSs), where the potentially huge number of configurations makes testing extremely challenging. However, current approaches for test case prioritization in HCSs suffer from two main limitations. First, the prioritization is usually driven by a single objective which neglects the potential benefits of combining multiple criteria to guide the detection of faults. Second, instead of using industry-strength case studies, evaluations are conducted using synthetic data, which provides no information about the effectiveness of different prioritization objectives. In this paper, we address both limitations by studying 63 combinations of up to three prioritization objectives in accelerating the detection of faults in the Drupal framework. Results show that non-functional properties such as the number of changes in the features are more effective than functional metrics extracted from the configuration model. Results also suggest that multi-objective prioritization typically results in faster fault detection than mono-objective prioritization.  Indicios de calidad de la revista: Journal of Systems and Software (Elsevier) ISSN: 0164-1212  Factor de impacto 2015: 1,424  Factor de impacto a 5 años: 1,767  Indexada en dos categorías:  Computer Science / Theory & Methods: 31/105 (Q2)  Computer Science / Software Engineering: 24/106 (Q1)  Otros datos:  CiteScore: 2.93  Source Normalized Impact per Paper (SNIP): 2.415  SCImago Journal Rank (SJR): 0.897  Indicios de calidad del propio paper: Número de Citas según Google Scholar: 3 Número de lecturas según Research Gate: 73]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/040]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_14.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_14.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Antonio Parejo Maestre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[japarejo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ana Belén Sánchez Jerez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[anabsanchez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Roberto Erick Lopez-Herrejón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[Roberto.Lopez@etsmtl.ca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Department of Software Engineering and Information Technology of the École de Technologie Supérieure of the University of Quebec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Alexander Egyed]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[alexander.egyed@jku.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Institute for Software Systems Engineering,  Johannes Kepler University]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evaluación de la Mejora de Conjuntos de Casos de Prueba mediante la Prueba de Mutación Evolutiva</title>
		<link>https://biblioteca.sistedes.es/articulo/evaluacion-de-la-mejora-de-conjuntos-de-casos-de-prueba-mediante-la-prueba-de-mutacion-evolutiva/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/evaluacion-de-la-mejora-de-conjuntos-de-casos-de-prueba-mediante-la-prueba-de-mutacion-evolutiva/</guid>
		<description></description>
		<content><![CDATA[La Prueba de Mutación Evolutiva (PME) es una técnica surgida recientemente para reducir el número de mutantes a generar en la prueba de mutaciones y, por consiguiente, su alto coste computacional. Esto se logra a través de un algoritmo genético, el cual trata de localizar la mayor cantidad posible de los mutantes con potencial para guiar a la mejora del conjunto de casos de prueba (denominados mutantes fuertes) en ese subconjunto de mutantes generado. La técnica ha sido evaluada precisamente respecto a esa capacidad de encontrar mutantes fuertes, pero tal análisis omite el hecho de que parte de esos mutantes fuertes puede no aportar a la mejora de las pruebas ya que son mutantes equivalentes. Por esa razón, en este artículo se propone una nueva metodología para la evaluación de la PME. Esta realiza una estimación del refinamiento conseguido del conjunto de pruebas a través de los mutantes seleccionados por el algoritmo genético. Esta metodología se emplea sobre cuatro programas en C++ que aplican orientación a objetos, mostrando que la PME es capaz de aumentar el conjunto de pruebas generando un porcentaje menor de mutantes que la selección aleatoria.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2561</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evaluacion-de-la-mejora-de-conjuntos-de-casos-de-prueba-mediante-la-prueba-de-mutacion-evolutiva]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="algoritmos-geneticos"><![CDATA[Algoritmos genéticos]]></category>
		<category domain="post_tag" nicename="prueba-de-mutaciones"><![CDATA[prueba de mutaciones]]></category>
		<category domain="post_tag" nicename="prueba-de-software"><![CDATA[Prueba de software]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La Prueba de Mutación Evolutiva (PME) es una técnica surgida recientemente para reducir el número de mutantes a generar en la prueba de mutaciones y, por consiguiente, su alto coste computacional. Esto se logra a través de un algoritmo genético, el cual trata de localizar la mayor cantidad posible de los mutantes con potencial para guiar a la mejora del conjunto de casos de prueba (denominados mutantes fuertes) en ese subconjunto de mutantes generado. La técnica ha sido evaluada precisamente respecto a esa capacidad de encontrar mutantes fuertes, pero tal análisis omite el hecho de que parte de esos mutantes fuertes puede no aportar a la mejora de las pruebas ya que son mutantes equivalentes. Por esa razón, en este artículo se propone una nueva metodología para la evaluación de la PME. Esta realiza una estimación del refinamiento conseguido del conjunto de pruebas a través de los mutantes seleccionados por el algoritmo genético. Esta metodología se emplea sobre cuatro programas en C++ que aplican orientación a objetos, mostrando que la PME es capaz de aumentar el conjunto de pruebas generando un porcentaje menor de mutantes que la selección aleatoria.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/036]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_15.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_15.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Delgado-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pedro.delgado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Mejora del Rendimiento de la Prueba de Mutación Evolutiva mediante la Reducción de Mutantes Equivalentes</title>
		<link>https://biblioteca.sistedes.es/articulo/mejora-del-rendimiento-de-la-prueba-de-mutacion-evolutiva-mediante-la-reduccion-de-mutantes-equivalentes/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/mejora-del-rendimiento-de-la-prueba-de-mutacion-evolutiva-mediante-la-reduccion-de-mutantes-equivalentes/</guid>
		<description></description>
		<content><![CDATA[La Prueba de Mutación Evolutiva (PME) busca la generación de un subconjunto de mutantes mediante un algoritmo genético con el objetivo de mejorar el conjunto de casos de prueba a un menor coste. A pesar de los resultados positivos obtenidos hasta el momento empleando esta técnica, otros avances paralelos en la prueba de mutaciones pueden aumentar la eficiencia de la PME. En este artículo se propone la incorporación en herramientas que aplican la PME de nuevas técnicas para ayudar a detectar mutantes que son equivalentes al programa original, exponiendo los beneficios de esta fusión.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2562</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mejora-del-rendimiento-de-la-prueba-de-mutacion-evolutiva-mediante-la-reduccion-de-mutantes-equivalentes]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="algoritmos-geneticos"><![CDATA[Algoritmos genéticos]]></category>
		<category domain="post_tag" nicename="prueba-de-mutaciones"><![CDATA[prueba de mutaciones]]></category>
		<category domain="post_tag" nicename="prueba-de-software"><![CDATA[Prueba de software]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La Prueba de Mutación Evolutiva (PME) busca la generación de un subconjunto de mutantes mediante un algoritmo genético con el objetivo de mejorar el conjunto de casos de prueba a un menor coste. A pesar de los resultados positivos obtenidos hasta el momento empleando esta técnica, otros avances paralelos en la prueba de mutaciones pueden aumentar la eficiencia de la PME. En este artículo se propone la incorporación en herramientas que aplican la PME de nuevas técnicas para ayudar a detectar mutantes que son equivalentes al programa original, exponiendo los beneficios de esta fusión.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/039]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_16.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_16.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Delgado-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pedro.delgado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Requirements reuse and requirement patterns: a state of the practice survey</title>
		<link>https://biblioteca.sistedes.es/articulo/requirements-reuse-and-requirement-patterns-a-state-of-the-practice-survey/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/requirements-reuse-and-requirement-patterns-a-state-of-the-practice-survey/</guid>
		<description></description>
		<content><![CDATA[Autores: Cristina Palomares, Carme Quer, Xavier Franch Revista: Empirical Software Engineering (Springer), in press DOI: http://dx.doi.org/10.1007/s10664-016-9485-x JCR IF 2015: 1.393 (27/106 de la categoría de ingeniería del software)]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2563</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[requirements-reuse-and-requirement-patterns-a-state-of-the-practice-survey]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="exploratory-survey"><![CDATA[exploratory survey]]></category>
		<category domain="post_tag" nicename="online-questionnaire"><![CDATA[online questionnaire]]></category>
		<category domain="post_tag" nicename="requirements-engineering"><![CDATA[requirements engineering]]></category>
		<category domain="post_tag" nicename="software-rerquirement-patterns"><![CDATA[software rerquirement patterns]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Autores: Cristina Palomares, Carme Quer, Xavier Franch  Revista: Empirical Software Engineering (Springer), in press  DOI: http://dx.doi.org/10.1007/s10664-016-9485-x  JCR IF 2015: 1.393 (27/106 de la categoría de ingeniería del software) ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/051]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_17.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_17.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cristina Palomares]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cpalomares@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carme Quer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cquer@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Xavier Franch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[franch@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>On the use of developers context for automatic refactoring of software anti-patterns</title>
		<link>https://biblioteca.sistedes.es/articulo/on-the-use-of-developers-context-for-automatic-refactoring-of-software-anti-patterns/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/on-the-use-of-developers-context-for-automatic-refactoring-of-software-anti-patterns/</guid>
		<description></description>
		<content><![CDATA[Publication: Journal of Systems and Software Number: Available On-line Month and Year: May 2016 DOI: 10.1016/j.jss.2016.05.042 Quality indicators of the journal: ISI JCR IF=1.424 (Q1 in CS/SE, Q2 in CS/TM), 5-year IF=1.767, SNIP=2.415, SJR=0.897, CiteScore=2.93 Citations (according to Google Scholar): 4]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2564</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[on-the-use-of-developers-context-for-automatic-refactoring-of-software-anti-patterns]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="anti-patterns"><![CDATA[Anti-patterns]]></category>
		<category domain="post_tag" nicename="automatic-refactoring"><![CDATA[Automatic refactoring]]></category>
		<category domain="post_tag" nicename="interaction-traces"><![CDATA[Interaction traces]]></category>
		<category domain="post_tag" nicename="metaheuristics"><![CDATA[Metaheuristics]]></category>
		<category domain="post_tag" nicename="software-maintenance"><![CDATA[Software maintenance]]></category>
		<category domain="post_tag" nicename="task-context"><![CDATA[Task context]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Publication: Journal of Systems and Software Number: Available On-line Month and Year: May 2016 DOI: 10.1016/j.jss.2016.05.042 Quality indicators of the journal: ISI JCR IF=1.424 (Q1 in CS/SE, Q2 in CS/TM), 5-year IF=1.767, SNIP=2.415, SJR=0.897, CiteScore=2.93 Citations (according to Google Scholar): 4]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/041]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_19.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_19.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rodrigo Morales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rodrigo.morales@polymtl.ca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Polytechnique Montréal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Zéphyrin Soh]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[zephyrin.soh@polymtl.ca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Polytechnique Montréal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Foutse Khomh]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[foutse.khomh@polymtl.ca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Polytechnique Montréal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Giuliano Antoniol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[giuliano.antoniol@polymtl.ca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Polytechnique Montréal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Francisco Chicano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[chicano@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Configuración Eco-Eficiente de Atributos de Calidad Funcionales</title>
		<link>https://biblioteca.sistedes.es/articulo/configuracion-eco-eficiente-de-atributos-de-calidad-funcionales/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/configuracion-eco-eficiente-de-atributos-de-calidad-funcionales/</guid>
		<description></description>
		<content><![CDATA[Los atributos de calidad funcionales (FQAs) son aquellos que para satisfacerlos se necesita incorporar funcionalidad adicional a la arquitectura de las aplicación (e.g., seguridad). La nueva funcionalidad incorporada por estos FQAs (e.g., encriptación) afecta a otro atributo de calidad como es el consumo de energía de la aplicación. Hasta el momento no se han explorado suficientemente las interdependencias entre, por ejemplo diferentes niveles de seguridad y su incidencia en el consumo de energía. En este artículo se propone una solución para ayudar al arquitecto software a generar la configuración de los FQAs que optimiza la eficiencia energética de la aplicación. Para ello se define un modelo de uso para cada FQA, teniendo en cuenta las variables que influyen en el consumo de energía y como el valor de estas variables cambia en función del punto de la aplicación donde se requiere ese FQA. Se extiende una Línea de Productos Software que modela una familia de FQAs para incorporar la variabilidad del modelo de uso y los frameworks existentes que implementan los FQAs. Generamos la configuración más eco-eficiente seleccionando el framework y las características más adecuadas para cada FQA y configurándolo según los requisitos de la aplicación.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2565</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[configuracion-eco-eficiente-de-atributos-de-calidad-funcionales]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="atributos-de-calidad"><![CDATA[Atributos de Calidad]]></category>
		<category domain="post_tag" nicename="eco-eficiente"><![CDATA[Eco-Eficiente]]></category>
		<category domain="post_tag" nicename="energia"><![CDATA[Energía]]></category>
		<category domain="post_tag" nicename="fqa"><![CDATA[FQA]]></category>
		<category domain="post_tag" nicename="linea-de-productos-software"><![CDATA[Línea de Productos Software]]></category>
		<category domain="post_tag" nicename="variabilidad"><![CDATA[Variabilidad]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los atributos de calidad funcionales (FQAs) son aquellos que para satisfacerlos se necesita incorporar funcionalidad adicional a la arquitectura de las aplicación (e.g., seguridad). La nueva funcionalidad incorporada por estos FQAs (e.g., encriptación) afecta a otro atributo de calidad como es el consumo de energía de la aplicación. Hasta el momento no se han explorado suficientemente las interdependencias entre, por ejemplo diferentes niveles de seguridad y su incidencia en el consumo de energía. En este artículo se propone una solución para ayudar al arquitecto software a generar la configuración de los FQAs que optimiza la eficiencia energética de la aplicación. Para ello se define un modelo de uso para cada FQA, teniendo en cuenta las variables que influyen en el consumo de energía y como el valor de estas variables cambia en función del punto de la aplicación donde se requiere ese FQA. Se extiende una Línea de Productos Software que modela una familia de FQAs para incorporar la variabilidad del modelo de uso y los frameworks existentes que implementan los FQAs. Generamos la configuración más eco-eficiente seleccionando el framework y las características más adecuadas para cada FQA y configurándolo según los requisitos de la aplicación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/003]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_22.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_22.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Miguel Horcas Aguilera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[horcas@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mónica Pinto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pinto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Universal indexes for highly repetitive document collections</title>
		<link>https://biblioteca.sistedes.es/articulo/universal-indexes-for-highly-repetitive-document-collections/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/universal-indexes-for-highly-repetitive-document-collections/</guid>
		<description></description>
		<content><![CDATA[Abstract ======== Indexing highly repetitive collections has become a relevant problem with the emergence of large repositories of versioned documents, among other applications. These collections may reach huge sizes, but are formed mostly of documents that are near-copies of others. Traditional techniques for indexing these collections fail to properly exploit their regularities in order to reduce space. We introduce new techniques for compressing inverted indexes that exploit this near-copy regularity. They are based on run-length, Lempel-Ziv, or grammar compression of the differential inverted lists, instead of the usual practice of gap-encoding them. We show that, in this highly repetitive setting, our compression methods significantly reduce the space obtained with classical techniques, at the price of moderate slowdowns. Moreover, our best methods are universal, that is, they do not need to know the versioning structure of the collection, nor that a clear versioning structure even exists. We also introduce compressed self-indexes in the comparison. These are designed for general strings (not only natural language texts) and represent the text collection plus the index structure (not an inverted index) in integrated form. We show that these techniques can compress much further, using a small fraction of the space required by our new inverted indexes. Yet, they are orders of magnitude slower. Publication Details =================== Francisco Claude, Antonio Fariña, Miguel A. Martínez-Prieto, Gonzalo Navarro. Universal indexes for highly repetitive document collections Information Systems, 61, pp. 1-23, 2016, DOI: http://dx.doi.org/10.1016/j.is.2016.04.002 Citations Google Scholar: 3 (2 self-citations)]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2566</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[universal-indexes-for-highly-repetitive-document-collections]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="inverted-index"><![CDATA[Inverted index]]></category>
		<category domain="post_tag" nicename="repetitive-collections"><![CDATA[Repetitive collections]]></category>
		<category domain="post_tag" nicename="self-index"><![CDATA[Self-index]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Abstract ======== Indexing highly repetitive collections has become a relevant problem with the emergence of large repositories of versioned documents, among other applications. These collections may reach huge sizes, but are formed mostly of documents that are near-copies of others. Traditional techniques for indexing these collections fail to properly exploit their regularities in order to reduce space.  We introduce new techniques for compressing inverted indexes that exploit this near-copy regularity. They are based on run-length, Lempel-Ziv, or grammar compression of the differential inverted lists, instead of the usual practice of gap-encoding them. We show that, in this highly repetitive setting, our compression methods significantly reduce the space obtained with classical techniques, at the price of moderate slowdowns. Moreover, our best methods are universal, that is, they do not need to know the versioning structure of the collection, nor that a clear versioning structure even exists.  We also introduce compressed self-indexes in the comparison. These are designed for general strings (not only natural language texts) and represent the text collection plus the index structure (not an inverted index) in integrated form. We show that these techniques can compress much further, using a small fraction of the space required by our new inverted indexes. Yet, they are orders of magnitude slower.  Publication Details =================== Francisco Claude, Antonio Fariña, Miguel A. Martínez-Prieto, Gonzalo Navarro. Universal indexes for highly repetitive document collections Information Systems, 61, pp. 1-23, 2016,  DOI: http://dx.doi.org/10.1016/j.is.2016.04.002  Citations Google Scholar: 3 (2 self-citations)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/024]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_24.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_24.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Claude]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fclaude@recoded.cl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Diego Portales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Fariña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fari@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of A Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Miguel A. Martinez-Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[migumar2@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[DataWeb Research,  Department of Computer Science,  University of Valladolid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Gonzalo Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[gnavarro@dcc.uchile.cl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Chile]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Interactive Fuzzy Inference System for Teletherapy of Older People</title>
		<link>https://biblioteca.sistedes.es/articulo/an-interactive-fuzzy-inference-system-for-teletherapy-of-older-people/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:05 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-interactive-fuzzy-inference-system-for-teletherapy-of-older-people/</guid>
		<description></description>
		<content><![CDATA[The progressive aging of the population in developed countries is becoming a problem for healthcare systems, which must invest ever higher sums in caring for their older citizens. One of the most important issues in this area involves the physical and cognitive problems associated with growing old. In order to reduce the effect of these problems, gerontechnology has emerged as one of the most promising alternatives, especially in the field of the telerehabilitation systems developed to date. However, most of these systems do not offer therapists the facilities to design therapies adapted to individual patients. This paper proposes a novel system that supplies this need and enables therapists to create bespoke motor therapies as state diagrams and manage them efficiently in a collaborative setting. The proposed system is equipped with a fuzzy-based decision-making component that therapists can use to control transitioning between states according to variables such as fatigue and performance. Therefore, the system makes it feasible to provide older patients with the treatment they need in their own homes while its effectiveness is controlled by a Fuzzy Inference System. Cogn Comput (2016) 8:318-335 DOI 10.1007/s12559-015-9356-6 Ã?ndice de calidad: ------------------------ índice de impacto: 1.993 Posición relativa: 41/130]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2567</post_id>
		<post_date><![CDATA[2017-07-02 04:47:05]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:05]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-interactive-fuzzy-inference-system-for-teletherapy-of-older-people]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="bespoke-therapy-editor"><![CDATA[Bespoke therapy editor]]></category>
		<category domain="post_tag" nicename="fuzzy-inference-system"><![CDATA[Fuzzy Inference System]]></category>
		<category domain="post_tag" nicename="gerontechnology"><![CDATA[Gerontechnology]]></category>
		<category domain="post_tag" nicename="telerehabilitation"><![CDATA[Telerehabilitation]]></category>
		<category domain="post_tag" nicename="teletherapy"><![CDATA[Teletherapy]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The progressive aging of the population in developed countries is becoming a problem for healthcare systems, which must invest ever higher sums in caring for their older citizens. One of the most important issues in this area involves the physical and cognitive problems associated with growing old. In order to reduce the effect of these problems, gerontechnology has emerged as one of the most promising alternatives, especially in the field of the telerehabilitation systems developed to date. However, most of these systems do not offer therapists the facilities to design therapies adapted to individual patients. This paper proposes a novel system that supplies this need and enables therapists to create bespoke motor therapies as state diagrams and manage them efficiently in a collaborative setting. The proposed system is equipped with a fuzzy-based decision-making component that therapists can use to control transitioning between states according to variables such as fatigue and performance. Therefore, the system makes it feasible to provide older patients with the treatment they need in their own homes while its effectiveness is controlled by a Fuzzy Inference System.  Cogn Comput (2016) 8:318-335 DOI 10.1007/s12559-015-9356-6  Ã?ndice de calidad:  ------------------------ índice de impacto: 1.993 Posición relativa: 41/130]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/060]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_26.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_26.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel A. Teruel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[miguel@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Elena Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[elena.navarro@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pascual Gonzalez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pgonzalez@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Víctor López-Jaquero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[victor@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Francisco Montero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[fmontero@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An ACO-based personalized learning technique in support of people with acquired brain injury</title>
		<link>https://biblioteca.sistedes.es/articulo/an-aco-based-personalized-learning-technique-in-support-of-people-with-acquired-brain-injury/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-aco-based-personalized-learning-technique-in-support-of-people-with-acquired-brain-injury/</guid>
		<description></description>
		<content><![CDATA[The ever-increasing cases of acquired brain injury (ABI), especially among young people, have prompted a rapid progress in research involving neurological disorders. One important path is the concept of relearning, which attempts to help people regain basic motor and cognitive skills lost due to illness or accident. The goals of relearning are twofold. First, there must exist a way to properly assess the necessities of an affected person, leading to a diagnosis, followed by a recommendation regarding the exercises, tests and tasks to perform, and second, there must be a way to confirm the results obtained from these recommendations in order to fine-tune and personalize the relearning process. This presents a challenge, as there is a deeply-rooted duality between the personalized and the generalized approach. In this work we propose a personalization algorithm based on the ant colony optimization (ACO), which is a bio-inspired meta-heuristic. As we show, the stochastic nature of ants has certain similarities to the human learning process. Applied Soft Computing 47 (2016) 316-331 http://dx.doi.org/10.1016/j.asoc.2016.04.039 21/130 (Q1) We combine the adaptive and exploratory capabilities of ACO systems to respond to rapidly changing environments and the ubiquitous human factor. Finally, we test the proposed solution extensively in various scenarios, achieving high quality results.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2568</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-aco-based-personalized-learning-technique-in-support-of-people-with-acquired-brain-injury]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="abi"><![CDATA[ABI]]></category>
		<category domain="post_tag" nicename="aco"><![CDATA[ACO]]></category>
		<category domain="post_tag" nicename="acquired-brain-injury"><![CDATA[Acquired brain injury]]></category>
		<category domain="post_tag" nicename="recommendation-system"><![CDATA[Recommendation system]]></category>
		<category domain="post_tag" nicename="relearning-process"><![CDATA[Relearning process]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The ever-increasing cases of acquired brain injury (ABI), especially among young people, have prompted a rapid progress in research involving neurological disorders. One important path is the concept of relearning, which attempts to help people regain basic motor and cognitive skills lost due to illness or accident. The goals of relearning are twofold. First, there must exist a way to properly assess the necessities of an affected person, leading to a diagnosis, followed by a recommendation regarding the exercises, tests and tasks to perform, and second, there must be a way to confirm the results obtained from these recommendations in order to fine-tune and personalize the relearning process.  This presents a challenge, as there is a deeply-rooted duality between the personalized and the generalized approach. In this work we propose a personalization algorithm based on the ant colony optimization (ACO), which is a bio-inspired meta-heuristic. As we show, the stochastic nature of ants has certain similarities to the human learning process.  Applied Soft Computing 47 (2016) 316-331 http://dx.doi.org/10.1016/j.asoc.2016.04.039  21/130 (Q1)    We combine the adaptive and exploratory capabilities of ACO systems to respond to rapidly changing environments and the ubiquitous human factor. Finally, we test the proposed solution extensively in various scenarios, achieving high quality results.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/059]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_27.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_27.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Kamil Krynicki]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[kkrynicki@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Jaen]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fjaen@upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Elena Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Elena.Navarro@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Applying thematic analysis to define an awareness interpretation for collaborative computer games</title>
		<link>https://biblioteca.sistedes.es/articulo/applying-thematic-analysis-to-define-an-awareness-interpretation-for-collaborative-computer-games/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/applying-thematic-analysis-to-define-an-awareness-interpretation-for-collaborative-computer-games/</guid>
		<description></description>
		<content><![CDATA[Indices de calidad: Índice de impacto: 1.569, Q1 Posición que ocupa la revista en la categoría: 16/106 Número de citas: 3 Context Collaborative computer games have evolved from single-player to massively multiplayer awareness-demanding games, usually involving collaboration to achieve team goals. As a consequence of such evolution, these players should be provided with awareness information that enables them to perform collaborative tasks with other team members. Objective The objective of this work is the analysis of current awareness interpretations in order to develop an awareness interpretation that collects the awareness needs of such games. Method This analysis has been conducted by means of a step-by-step Thematic Analysis of current interpretations that led us to extract the most relevant awareness elements defined in existing interpretations. The developed awareness interpretation was empirically evaluated by means of several surveys aimed at assessing whether the implementation of the interpretation elements in a game would improve the players enjoyment. Results The Thematic Synthesis Analysis concluded that none of the current awareness interpretations can deal properly with collaborative computer games, specifically due to collaboration and social &amp; group dynamics. This Thematic Synthesis Analysis led us to coin Gamespace Awareness, a new awareness interpretation based on a combination of the previously analyzed awareness interpretations, which is suitable for collaborative computer games. The interpretation was positively evaluated for two games, namely a first person shooter and a real-time strategy game. Conclusions Gamespace Awareness combines the potential awareness elements needed for collaborative computer games, making it possible to identify the awareness requirements of these games from the very beginning.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2569</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[applying-thematic-analysis-to-define-an-awareness-interpretation-for-collaborative-computer-games]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="awareness"><![CDATA[Awareness]]></category>
		<category domain="post_tag" nicename="collaborative-computer-games"><![CDATA[Collaborative computer games]]></category>
		<category domain="post_tag" nicename="empirical-evaluation"><![CDATA[Empirical evaluation]]></category>
		<category domain="post_tag" nicename="game-development"><![CDATA[Game development]]></category>
		<category domain="post_tag" nicename="gamespace-awareness"><![CDATA[Gamespace awareness]]></category>
		<category domain="post_tag" nicename="thematic-synthesis"><![CDATA[Thematic synthesis]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Indices de calidad: Ã?ndice de impacto: 1.569, Q1 Posición que ocupa la revista en la categoría: 16/106 Número de citas: 3   Context Collaborative computer games have evolved from single-player to massively multiplayer awareness-demanding games, usually involving collaboration to achieve team goals. As a consequence of such evolution, these players should be provided with awareness information that enables them to perform collaborative tasks with other team members.  Objective  The objective of this work is the analysis of current awareness interpretations in order to develop an awareness interpretation that collects the awareness needs of such games.  Method  This analysis has been conducted by means of a step-by-step Thematic Analysis of current interpretations that led us to extract the most relevant awareness elements defined in existing interpretations. The developed awareness interpretation was empirically evaluated by means of several surveys aimed at assessing whether the implementation of the interpretation elements in a game would improve the players enjoyment.  Results  The Thematic Synthesis Analysis concluded that none of the current awareness interpretations can deal properly with collaborative computer games, specifically due to collaboration and social & group dynamics. This Thematic Synthesis Analysis led us to coin Gamespace Awareness, a new awareness interpretation based on a combination of the previously analyzed awareness interpretations, which is suitable for collaborative computer games. The interpretation was positively evaluated for two games, namely a first person shooter and a real-time strategy game.  Conclusions  Gamespace Awareness combines the potential awareness elements needed for collaborative computer games, making it possible to identify the awareness requirements of these games from the very beginning.   ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/046]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_28.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_28.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel A. Teruel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[miguel@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Elena Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Elena.Navarro@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pascual Gonzalez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pgonzalez@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Víctor López-Jaquero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[victor@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Francisco Montero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[fmontero@dsi.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[LoUISE Research Group, University of Castilla – La Mancha, Albacete, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>DScaffolding: una Herramienta de Apoyo en el Aprendizaje y la Ejecución de Investigación Científica Basada en Diseño</title>
		<link>https://biblioteca.sistedes.es/articulo/dscaffolding-una-herramienta-de-apoyo-en-el-aprendizaje-y-la-ejecucion-de-investigacion-cientifica-basada-en-diseno/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/dscaffolding-una-herramienta-de-apoyo-en-el-aprendizaje-y-la-ejecucion-de-investigacion-cientifica-basada-en-diseno/</guid>
		<description></description>
		<content><![CDATA[El aprendizaje y la práctica de Investigación Científica Basada en Diseño (ICBD) son tareas complejas para las que no existe asistencia más allá de publicaciones. Estas dos tareas abarcan numerosas actividades que deben ser dominadas y coordinadas. Este artículo describe una nueva herramienta, DScaffolding, desarrollada con el fin de asistir a los investigadores principiantes en la ejecución de proyectos de ICBD. Las actividades de ICBD se integran dentro un popular editor de mapas mentales (MindMeister). Se ha realizado una evaluación formativa sobre una versión inicial de DScaffolding. El prototipo está disponible en forma de extensión en la tienda web de Google Chrome.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2570</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[dscaffolding-una-herramienta-de-apoyo-en-el-aprendizaje-y-la-ejecucion-de-investigacion-cientifica-basada-en-diseno]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="analisis-de-causa-raiz"><![CDATA[Análisis de Causa Raíz]]></category>
		<category domain="post_tag" nicename="investigacion-cientifica-basada-en-diseno"><![CDATA[Investigación Científica Basada en Diseño]]></category>
		<category domain="post_tag" nicename="mapas-mentales"><![CDATA[Mapas Mentales]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El aprendizaje y la práctica de Investigación Científica Basada en Diseño (ICBD) son tareas complejas para las que no existe asistencia más allá de publicaciones. Estas dos tareas abarcan numerosas actividades que deben ser dominadas y coordinadas. Este artículo describe una nueva herramienta, DScaffolding, desarrollada con el fin de asistir a los investigadores principiantes en la ejecución de proyectos de ICBD. Las actividades de ICBD se integran dentro un popular editor de mapas mentales (MindMeister). Se ha realizado una evaluación formativa sobre una versión inicial de DScaffolding. El prototipo está disponible en forma de extensión en la tienda web de Google Chrome.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/048]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_29.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_29.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Oscar Diaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[oscar.diaz@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad del País Vasco (UPV/EHU), San Sebastián, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jeremías P. Contell]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jeremias.perez@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad del País Vasco (UPV/EHU), San Sebastián, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[John Venable]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[j.venable@curtin.edu.au]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[School of Information Systems, Curtin University of Technology, Perth, Western Australia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Incremental Consolidation of Data-Intensive Multi-Flows</title>
		<link>https://biblioteca.sistedes.es/articulo/incremental-consolidation-of-data-intensive-multi-flows/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/incremental-consolidation-of-data-intensive-multi-flows/</guid>
		<description></description>
		<content><![CDATA[En Transactions on Knowledge and Data Engineering, 28(5). IEEE Press, May 2016. Páginas 1203-1216. ISSN: 1041-4347. DOI: 10.1109/TKDE.2016.2515609 Ã?ndice de impacto: JCR-Science Edition 2015, 2.476 Quartil i área: Q1, COMPUTER SCIENCE, INFORMATION SYSTEMS, 17/143 Business intelligence (BI) systems depend on efficient integration of disparate and often heterogeneous data. The integration of data is governed by data-intensive flows and is driven by a set of information requirements. Designing such flows is in general a complex process, which due to the complexity of business environments is hard to be done manually. In this paper, we deal with the challenge of efficient design and maintenance of data-intensive flows and propose an incremental approach, namely CoAl , for semi-automatically consolidating data-intensive flows satisfying a given set of information requirements. CoAl works at the logical level and consolidates data flows from either high-level information requirements or platform-specific programs. As CoAl integrates a new data flow, it opts for maximal reuse of existing flows and applies a customizable cost model tuned for minimizing the overall cost of a unified solution. We demonstrate the efficiency and effectiveness of our approach through an experimental evaluation using our implemented prototype.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2571</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[incremental-consolidation-of-data-intensive-multi-flows]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="business-intelligence"><![CDATA[Business Intelligence]]></category>
		<category domain="post_tag" nicename="data-warehousing"><![CDATA[Data warehousing]]></category>
		<category domain="post_tag" nicename="data-intensive-flows"><![CDATA[Data-intensive flows]]></category>
		<category domain="post_tag" nicename="workflow-management"><![CDATA[Workflow management]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En Transactions on Knowledge and Data Engineering, 28(5). IEEE Press, May 2016. Páginas 1203-1216.  ISSN: 1041-4347.  DOI: 10.1109/TKDE.2016.2515609 Ã?ndice de impacto: JCR-Science Edition 2015, 2.476 Quartil i área: Q1, COMPUTER SCIENCE, INFORMATION SYSTEMS, 17/143  Business intelligence (BI) systems depend on efficient integration of disparate and often heterogeneous data. The integration of data is governed by data-intensive flows and is driven by a set of information requirements. Designing such flows is in general a complex process, which due to the complexity of business environments is hard to be done manually. In this paper, we deal with the challenge of efficient design and maintenance of data-intensive flows and propose an incremental approach, namely CoAl , for semi-automatically consolidating data-intensive flows satisfying a given set of information requirements. CoAl works at the logical level and consolidates data flows from either high-level information requirements or platform-specific programs. As CoAl integrates a new data flow, it opts for maximal reuse of existing flows and applies a customizable cost model tuned for minimizing the overall cost of a unified solution. We demonstrate the efficiency and effectiveness of our approach through an experimental evaluation using our implemented prototype.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/019]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_30.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_30.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Petar Jovanovic]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[petar@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica De Catalunya - Barcelona Tech]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Oscar Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[oromero@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alkis Simitsis]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[alkis@hpe.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[HP Labs]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Alberto Abello]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aabello@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Mejorando el Conocimiento de los Estudiantes sobre Desarrollo Global del Software mediante un Juego Serio</title>
		<link>https://biblioteca.sistedes.es/articulo/mejorando-el-conocimiento-de-los-estudiantes-sobre-desarrollo-global-del-software-mediante-un-juego-serio/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/mejorando-el-conocimiento-de-los-estudiantes-sobre-desarrollo-global-del-software-mediante-un-juego-serio/</guid>
		<description></description>
		<content><![CDATA[La globalización ha llevado a muchas empresas a realizar el desarrollo de sus productos de una manera distribuida, llevándose a cabo por diferentes equipos e incluso desde diferentes países. Este nuevo paradigma de desarrollo se conoce como Desarrollo Global del Software - DGS. Para realizar esta práctica las empresas requieren desarrolladores que posean conocimientos y habilidades para solventar los problemas que surgen a causa de la distancia geográfica, temporal y cultural. Por eso, es muy importante que las asignaturas de Ingeniería del Software traten el DGS para que los alumnos conozcan este paradigma y sean conscientes de los desafíos que implica. Lo ideal sería que los alumnos pudieran trabajar en proyectos globales, pero somos conscientes de que esta actividad no siempre es posible. Por ello, en este artículo se evalúa la eficiencia de utilizar, como alternativa, un juego serio diseñado para que los alumnos descubran los problemas que conlleva el DGS.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2572</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mejorando-el-conocimiento-de-los-estudiantes-sobre-desarrollo-global-del-software-mediante-un-juego-serio]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="desarrollo-global-de-software"><![CDATA[Desarrollo Global de Software]]></category>
		<category domain="post_tag" nicename="experimento"><![CDATA[Experimento]]></category>
		<category domain="post_tag" nicename="juego-serio"><![CDATA[Juego serio]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La globalización ha llevado a muchas empresas a realizar el desarrollo de sus productos de una manera distribuida, llevándose a cabo por diferentes equipos e incluso desde diferentes países. Este nuevo paradigma de desarrollo se conoce como Desarrollo Global del Software - DGS. Para realizar esta práctica las empresas requieren desarrolladores que posean conocimientos y habilidades para solventar los problemas que surgen a causa de la distancia geográfica, temporal y cultural. Por eso, es muy importante que las asignaturas de Ingeniería del Software traten el DGS para que los alumnos conozcan este paradigma y sean conscientes de los desafíos que implica. Lo ideal sería que los alumnos pudieran trabajar en proyectos globales, pero somos conscientes de que esta actividad no siempre es posible. Por ello, en este artículo se evalúa la eficiencia de utilizar, como alternativa, un juego serio diseñado para que los alumnos descubran los problemas que conlleva el DGS. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/057]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_31.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_31.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aurora Vizcaíno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[Aurora.Vizcaino@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Félix García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[felix.garcia@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[David Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[david.valencia@avanttic.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[avanticc Consultorí­a Tecnológica,  S.L.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ignacio García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Ignacio.GRodriguez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Ma ángeles Moraga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[Mariangeles.Moraga@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Approach for Debugging Model Transformations Applying Spectrum-Based Fault Localization</title>
		<link>https://biblioteca.sistedes.es/articulo/an-approach-for-debugging-model-transformations-applying-spectrum-based-fault-localization/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-approach-for-debugging-model-transformations-applying-spectrum-based-fault-localization/</guid>
		<description></description>
		<content><![CDATA[Model transformations play a cornerstone role in Model-Driven Engineering as they provide the essential mechanisms for manipulating and transforming models. The use of assertions for checking their correctness has been proposed in several works. However, it is still challenging and error prone to locate the faulty rules, and the situation gets more critical as the size and complexity of model transformations grow, where manual debugging is no longer possible. Spectrum-Based Fault Localization (SBFL) is a technique for software debugging that uses the results of test cases and their corresponding code coverage information to estimate the likelihood of each program component (e.g., statements) of being faulty. This paper describes a proposal for applying SBFL for locating the faulty rules in ATL model transformations. The approach aims at automatically detecting the transformation rule that makes an assertion fail.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2573</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-approach-for-debugging-model-transformations-applying-spectrum-based-fault-localization]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="debugging"><![CDATA[Debugging]]></category>
		<category domain="post_tag" nicename="fault-localization"><![CDATA[Fault Localization]]></category>
		<category domain="post_tag" nicename="model-transformation"><![CDATA[Model Transformation]]></category>
		<category domain="post_tag" nicename="spectrum"><![CDATA[Spectrum]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Model transformations play a cornerstone role in Model-Driven Engineering as they provide the essential mechanisms for manipulating and transforming models. The use of assertions for checking their correctness has been proposed in several works. However, it is still challenging and error prone to locate the faulty rules, and the situation gets more critical as the size and complexity of model transformations grow, where manual debugging is no longer possible. Spectrum-Based Fault Localization (SBFL) is a technique for software debugging that uses the results of test cases and their corresponding code coverage information to estimate the likelihood of each program component (e.g., statements) of being faulty. This paper describes a proposal for applying SBFL for locating the faulty rules in ATL model transformations. The approach aims at automatically detecting the transformation rule that makes an assertion fail.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/026]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_32.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_32.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Troya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jtroya@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José Antonio Parejo Maestre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[japarejo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Creating datasets for data analysis through a cloud microservice-based architecture</title>
		<link>https://biblioteca.sistedes.es/articulo/creating-datasets-for-data-analysis-through-a-cloud-microservice-based-architecture/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/creating-datasets-for-data-analysis-through-a-cloud-microservice-based-architecture/</guid>
		<description></description>
		<content><![CDATA[Data analysis is a trending technique due to the tendency of analyzing patterns or generating knowledge in different domains. However, it is difficult to know at design time what raw data should be collected, how it is going to be analyzed or which analysis techniques will be applied to data. Service-oriented architectures can be applied to solve these problems by providing flexible and reliable architectures. In this paper, we present a microservice-based software architecture in the cloud with the aim of generating datasets to carry out data analysis. This architecture facilitates acquiring data, which may be located in a data center, distributed, or even on different devices (ubiquitous computing) due to the rise of the IoT. It provides an infrastructure over which multiple developer' groups can work in parallel on the microservices. These microservices also provide a reliable and affordable adaptability to the lack of specific requirements in some functionalities and the fast evolution and variability of them, due to the fast changing of client needs.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2574</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[creating-datasets-for-data-analysis-through-a-cloud-microservice-based-architecture]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="architectures"><![CDATA[architectures]]></category>
		<category domain="post_tag" nicename="datasets"><![CDATA[datasets]]></category>
		<category domain="post_tag" nicename="microservices"><![CDATA[microservices]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Data analysis is a trending technique due to the tendency of analyzing patterns or generating knowledge in different domains. However, it is difficult to know at design time what raw data should be collected, how it is going to be analyzed or which analysis techniques will be applied to data. Service-oriented architectures can be applied to solve these problems by providing flexible and reliable architectures. In this paper, we present a microservice-based software architecture in the cloud with the aim of generating datasets to carry out data analysis. This architecture facilitates acquiring data, which may be located in a data center, distributed, or even on different devices (ubiquitous computing) due to the rise of the IoT. It provides an infrastructure over which multiple developer' groups can work in parallel on the microservices. These microservices also provide a reliable and affordable adaptability to the lack of specific requirements in some functionalities and the fast evolution and variability of them, due to the fast changing of client needs.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/004]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_33.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_33.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Jesús Fernández-García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ajfernandez@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Almeria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Criado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[javi.criado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Almerí­a]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Corral]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[acorral@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Almeria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Luis Iribarne]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[luis.iribarne@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Almerí­a]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia un Marco de Desarrollo para Apps Móviles</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-un-marco-de-desarrollo-para-apps-moviles/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/hacia-un-marco-de-desarrollo-para-apps-moviles/</guid>
		<description></description>
		<content><![CDATA[En los últimos años el desarrollo de aplicaciones móviles ha ido ganando adeptos a gran velocidad debido a la popularidad que han adquirido los dispositivos móviles. El establecimiento de un marco de procesos adecuado para desarrollar este tipo de aplicaciones resulta vital a la hora de garantizar que los productos se desarrollan y se validan siguiendo un método sistemático y coherente. En este artículo se presenta una iniciativa de diseño y validación de un marco de procesos específico para el desarrollo de aplicaciones móviles. El marco propuesto ha sido diseñado en base a los fundamentos básicos de ingeniería del software y considerando modelos de desarrollo existentes que han sido adaptados a las características particulares del contexto. La propuesta ha sido validada en un proyecto real obteniendo unos resultados que nos han servido como punto de partida para iniciar una mejora del proceso de desarrollo que seguimos en nuestro grupo de investigación.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2575</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-un-marco-de-desarrollo-para-apps-moviles]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="aplicaciones-moviles"><![CDATA[aplicaciones móviles]]></category>
		<category domain="post_tag" nicename="apps"><![CDATA[apps]]></category>
		<category domain="post_tag" nicename="desarrollo-de-softare"><![CDATA[desarrollo de softare]]></category>
		<category domain="post_tag" nicename="marco-de-desarrollo"><![CDATA[marco de desarrollo]]></category>
		<category domain="post_tag" nicename="proceso-software"><![CDATA[Proceso Software]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años el desarrollo de aplicaciones móviles ha ido ganando adeptos a gran velocidad debido a la popularidad que han adquirido los dispositivos móviles. El establecimiento de un marco de procesos adecuado para desarrollar este tipo de aplicaciones resulta vital a la hora de garantizar que los productos se desarrollan y se validan siguiendo un método sistemático y coherente. En este artículo se presenta una iniciativa de diseño y validación de un marco de procesos específico para el desarrollo de aplicaciones móviles. El marco propuesto ha sido diseñado en base a los fundamentos básicos de ingeniería del software y considerando modelos de desarrollo existentes que han sido adaptados a las características particulares del contexto. La propuesta ha sido validada en un proyecto real obteniendo unos resultados que nos han servido como punto de partida para iniciar una mejora del proceso de desarrollo que seguimos en nuestro grupo de investigación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/055]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_34.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_34.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Esperança Amengual]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[eamengual@uib.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat de les Illes Balears]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antoni Bibiloni Coll]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[antoni.bibiloni@uib.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat de les Illes Balears]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Miguel Mascaró]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mascport@uib.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat de les Illes Balears]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Pere Palmer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[pere.palmer@uib.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat de les Illes Balears]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>iHDT++: un Autoíndice Semántico para la Resolución de Patrones de Consulta SPARQL</title>
		<link>https://biblioteca.sistedes.es/articulo/ihdt-un-autoindice-semantico-para-la-resolucion-de-patrones-de-consulta-sparql/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/ihdt-un-autoindice-semantico-para-la-resolucion-de-patrones-de-consulta-sparql/</guid>
		<description></description>
		<content><![CDATA[La publicación de colecciones RDF, y el volumen de las mismas, ha crecido exponencialmente en los últimos años, abriendo nuevos retos de investigación relacionados con el almacenamiento, el procesamiento y la consulta de Big Semantic Data. Los auto-índices RDF son una de las soluciones más innovadoras en este escenario, ya que no sólo comprimen las colecciones, sino que además proveen acceso eficiente a los datos sin descomprimirlos previamente. En este escenario, HDT es una de las soluciones de referencia y su uso ha sido validado por diferentes herramientas semánticas. Sin embargo, la efectividad de HDT está limitada por la sencillez de su diseño y sus ratios de compresión han sido recientemente mejorados por HDT++. Sin embargo, HDT++ no soporta directamente la resolución de consultas SPARQL. En este artículo extendemos HDT++ para dar soporte a la resolución de todos los triple patterns SPARQL. Esta nueva propuesta (iHDT++) mejora los resultados de compresión obtenidos por HDT y garantiza un rendimiento comparable para la resolución de consultas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2576</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[ihdt-un-autoindice-semantico-para-la-resolucion-de-patrones-de-consulta-sparql]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="compresion"><![CDATA[Compresión]]></category>
		<category domain="post_tag" nicename="hdt"><![CDATA[HDT]]></category>
		<category domain="post_tag" nicename="rdf"><![CDATA[RDF]]></category>
		<category domain="post_tag" nicename="sparql"><![CDATA[SPARQL]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La publicación de colecciones RDF, y el volumen de las mismas, ha crecido exponencialmente en los últimos años, abriendo nuevos retos de investigación relacionados con el almacenamiento, el procesamiento y la consulta de Big Semantic Data. Los auto-índices RDF son una de las soluciones más innovadoras en este escenario, ya que no sólo comprimen las colecciones, sino que además proveen acceso eficiente a los datos sin descomprimirlos previamente. En este escenario, HDT es una de las soluciones de referencia y su uso ha sido validado por diferentes herramientas semánticas. Sin embargo, la efectividad de HDT está limitada por la sencillez de su diseño y sus ratios de compresión han sido recientemente mejorados por HDT++. Sin embargo, HDT++ no soporta directamente la resolución de consultas SPARQL. En este artículo extendemos HDT++ para dar soporte a la resolución de todos los triple patterns SPARQL. Esta nueva propuesta (iHDT++) mejora los resultados de compresión obtenidos por HDT y garantiza un rendimiento comparable para la resolución de consultas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/018]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_35.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_35.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Hernández Illera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[antonio.hi@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[DataWeb Research,  Department of Computer Science,  University of Valladolid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miguel A. Martinez-Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[migumar2@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[DataWeb Research,  Department of Computer Science,  University of Valladolid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier D. Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jfernand@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Computer Science Department. University of Valladolid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Impacto de las métricas CK en la refactorización</title>
		<link>https://biblioteca.sistedes.es/articulo/impacto-de-las-metricas-ck-en-la-refactorizacion/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/impacto-de-las-metricas-ck-en-la-refactorizacion/</guid>
		<description></description>
		<content><![CDATA[Las métricas CK son las que alcanzan un mayor consenso, a nivel de diseño orientado a objetos, sobre la idenficación de la necesidad de una refactorización. Para estimar el impacto de estas métricas de calidad en la refactorización en este trabajo nos basamos en la reducción de la entropía. Para medir este impacto empleamos datos validados de refactorizaciones y métricas de código de varios proyectos open source. Las valoraciones obtenidas se combinan para ordenar las métricas y proponemos un método para medir su influencia incluso en aquellas situaciones en las que no todas las métricas puedan ser valoradas o cuando esta valoración no alcance unos tasas suficientemente representativas. Los resultados obtenidos con el enfoque aplicado están en la misma línea de trabajos previos de otros autores.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2577</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[impacto-de-las-metricas-ck-en-la-refactorizacion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="evolucion-del-software"><![CDATA[evolución del software]]></category>
		<category domain="post_tag" nicename="metricas-de-codigo"><![CDATA[métricas de código]]></category>
		<category domain="post_tag" nicename="refactorizacion"><![CDATA[Refactorización]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las métricas CK son las que alcanzan un mayor consenso, a nivel de diseño orientado a objetos, sobre la idenficación de la necesidad de una refactorización. Para estimar el impacto de estas métricas de calidad en la refactorización en este trabajo nos basamos en la reducción de la entropía. Para medir este impacto empleamos datos validados de refactorizaciones y métricas de código de varios proyectos open source. Las valoraciones obtenidas se combinan para ordenar las métricas y proponemos un método para medir su influencia incluso en aquellas situaciones en las que no todas las métricas puedan ser  valoradas o cuando esta valoración no alcance unos tasas suficientemente representativas. Los resultados obtenidos con el enfoque aplicado están en la misma línea de trabajos previos de otros autores.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/038]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_37.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_37.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Del Sagrado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jsagrado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Informatics,  University of Almerí­a]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Isabel María Del águila]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[imaguila@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Almería]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Alfonso J. Bosch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[abosch@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Almerí­a]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Francisco Chicano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[chicano@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Propuesta de Marco para el Gobierno de la Seguridad en Entornos Big Data</title>
		<link>https://biblioteca.sistedes.es/articulo/propuesta-de-marco-para-el-gobierno-de-la-seguridad-en-entornos-big-data/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/propuesta-de-marco-para-el-gobierno-de-la-seguridad-en-entornos-big-data/</guid>
		<description></description>
		<content><![CDATA[Big Data ya es una realidad en el día a día de muchas compañías. Cuando se implanta un entorno Big Data en una organización, este se debe adaptar a las características de la misma. Para poder alcanzar una garantía de seguridad mientras se respetan las características inherentes de la organización se re-quiere una adecuada función de gobierno. Para lograr este objetivo hemos creado una propuesta de marco para el gobierno de la seguridad en entornos Big Data denominada marco GSB. Este marco de gobierno toma como base los estándares internacionales relacionados con el gobierno de las TI, como por ejemplo COBIT, y lo adapta a las necesidades específicas de un entorno de Big Data. El objetivo final del marco GSB es cubrir todo su ciclo de vida de forma segura.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2578</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[propuesta-de-marco-para-el-gobierno-de-la-seguridad-en-entornos-big-data]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="gobierno-de-las-ti"><![CDATA[Gobierno de las TI]]></category>
		<category domain="post_tag" nicename="seguridad-de-la-informacion"><![CDATA[Seguridad de la información]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Big Data ya es una realidad en el día a día de muchas compañías. Cuando se implanta un entorno Big Data en una organización, este se debe adaptar a las características de la misma. Para poder alcanzar una garantía de seguridad mientras se respetan las características inherentes de la organización se re-quiere una adecuada función de gobierno. Para lograr este objetivo hemos creado una propuesta de marco para el gobierno de la seguridad en entornos Big Data denominada marco GSB. Este marco de gobierno toma como base los estándares internacionales relacionados con el gobierno de las TI, como por ejemplo COBIT, y lo adapta a las necesidades específicas de un entorno de Big Data. El objetivo final del marco GSB es cubrir todo su ciclo de vida de forma segura.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/020]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_38.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_38.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julio Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[julio.moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ALARCOS Research Group. UCLM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Serrano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Manuel.Serrano@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ALARCOS Research Group. UCLM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Eduardo Fernandez-Medina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[eduardo.fdezmedina@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ALARCOS Research Group. UCLM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modelos de Madurez de Usabilidad: Evolución y Situación Actual</title>
		<link>https://biblioteca.sistedes.es/articulo/modelos-de-madurez-de-usabilidad-evolucion-y-situacion-actual/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/modelos-de-madurez-de-usabilidad-evolucion-y-situacion-actual/</guid>
		<description></description>
		<content><![CDATA[Los beneficios de incorporar la usabilidad en el desarrollo del software han sido ampliamente documentados tanto desde el punto de vista del usuario como para la propia organización de desarrollo. Los modelos de madurez de usabilidad (MMUs) se usan para evaluar cómo una organización integra buenas prácticas de usabilidad en su proceso de desarrollo de software, por lo tanto, los MMUs son, así mismo, un vehículo eficaz para promover dicha integración. El objetivo de este trabajo es proporcionar información actualizada y detallada sobre los MMUs utilizados en la última década. Para ello hemos realizado un mapeo siste-mático de los MMUs objeto de publicación en los últimos 10 años. Como resul-tado, hemos identificado once modelos desde 2006. Para cada uno de ellos se han analizado en detalle distintas características de diseño y aplicación. El análisis ex-haustivo de dichos modelos, confirma la falta de evidencia empírica y de docu-mentación de soporte para su aplicación objetiva, carencias ya predichas por tra-bajos anteriores. Nuestro estudio identifica además otras carencias como son el grado de prescriptividad o mutabilidad de dichos modelos. Este estudio justifica así la necesidad de seguir trabajando en mejorar la madurez de los MMUs para potenciar su eficacia en la integración de prácticas de usabilidad en el desarrollo de software.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2579</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modelos-de-madurez-de-usabilidad-evolucion-y-situacion-actual]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mapeo-sistematico"><![CDATA[mapeo sistemático]]></category>
		<category domain="post_tag" nicename="modelos-de-madurez"><![CDATA[modelos de madurez]]></category>
		<category domain="post_tag" nicename="modelos-de-madurez-de-usabilidad"><![CDATA[Modelos de madurez de usabilidad]]></category>
		<category domain="post_tag" nicename="usabilidad"><![CDATA[usabilidad]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los beneficios de incorporar la usabilidad en el desarrollo del software han sido ampliamente documentados tanto desde el punto de vista del usuario como para la propia organización de desarrollo. Los modelos de madurez de usabilidad (MMUs) se  usan para evaluar cómo una organización integra buenas prácticas de usabilidad en su proceso de desarrollo de software, por lo tanto, los MMUs son, así mismo, un vehículo eficaz para promover dicha integración. El objetivo de este trabajo es proporcionar información actualizada y detallada sobre los MMUs utilizados en la última década. Para ello hemos realizado un mapeo siste-mático de los MMUs objeto de publicación en los últimos 10 años. Como resul-tado, hemos identificado once modelos desde 2006. Para cada uno de ellos se han analizado en detalle distintas características de diseño y aplicación. El análisis ex-haustivo de dichos modelos, confirma la falta de evidencia empírica y de docu-mentación de soporte para su aplicación objetiva, carencias ya predichas por tra-bajos anteriores. Nuestro estudio identifica además otras carencias como son el grado de prescriptividad o mutabilidad de dichos modelos. Este estudio justifica así la necesidad de seguir trabajando en mejorar la madurez de los MMUs para potenciar su eficacia en la integración de prácticas de usabilidad en el desarrollo de software.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/058]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_39.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_39.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carmen L. Carvajal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carmen.carvajal07@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ana M. Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ammoreno@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Coverage-Aware Test Database Reduction</title>
		<link>https://biblioteca.sistedes.es/articulo/coverage-aware-test-database-reduction/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:06 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/coverage-aware-test-database-reduction/</guid>
		<description></description>
		<content><![CDATA[Functional testing of applications that process the information stored in databases often requires a careful design of the test database. The larger the test database, the more difficult it is to develop and maintain tests as well as to load and reset the test data. This paper presents an approach to reduce a database with respect to a set of SQL queries and a coverage criterion. The reduction procedures search the rows in the initial database that contribute to the coverage in order to find a representative subset that satisfies the same coverage as the initial database. The approach is automated and efficiently executed against large databases and complex queries. The evaluation is carried out over two real life applications and a well-known database benchmark. The results show a very large degree of reduction as well as scalability in relation to the size of the initial database and the time needed to perform the reduction. --- Datos del artículo --- Autores: Javier Tuya, Claudio de la Riva, María José Suárez-Cabal, Raquel Blanco Revista: IEEE Transactions on Software Engineering Year: 2016, Volume: 42, Issue: 10 Pages: 941 - 959, DOI: 10.1109/TSE.2016.2519032 Factor de impacto (JCR 2005): 1,516, Q1 in Computer Science, Software engineering --- Nota --- Artículo para track Requisitos, Calidad y Pruebas, enviado a otros por conflicto de interés]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2580</post_id>
		<post_date><![CDATA[2017-07-02 04:47:06]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:06]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[coverage-aware-test-database-reduction]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="test-coverage-of-code"><![CDATA[Test coverage of code]]></category>
		<category domain="post_tag" nicename="test-database-reduction"><![CDATA[Test database reduction]]></category>
		<category domain="post_tag" nicename="test-design"><![CDATA[Test design]]></category>
		<category domain="post_tag" nicename="testing-tools"><![CDATA[Testing tools]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Functional testing of applications that process the information stored in databases often requires a careful design of the test database. The larger the test database, the more difficult it is to develop and maintain tests as well as to load and reset the test data. This paper presents an approach to reduce a database with respect to a set of SQL queries and a coverage criterion. The reduction procedures search the rows in the initial database that contribute to the coverage in order to find a representative subset that satisfies the same coverage as the initial database. The approach is automated and efficiently executed against large databases and complex queries. The evaluation is carried out over two real life applications and a well-known database benchmark. The results show a very large degree of reduction as well as scalability in relation to the size of the initial database and the time needed to perform the reduction.  --- Datos del artículo --- Autores: Javier Tuya, Claudio de la Riva, María José Suárez-Cabal, Raquel Blanco Revista: IEEE Transactions on Software Engineering Year: 2016, Volume: 42, Issue: 10  Pages: 941 - 959,  DOI: 10.1109/TSE.2016.2519032  Factor de impacto (JCR 2005): 1,516, Q1 in Computer Science, Software engineering  --- Nota --- Artículo para track Requisitos, Calidad y Pruebas, enviado a otros por conflicto de interés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/068]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_40.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_40.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Claudio de La Riva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[claudio@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de  Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[María José Suárez-Cabal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[cabal@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Raquel Blanco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[rblanco@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modeling Systems Variability with Delta Rhapsody</title>
		<link>https://biblioteca.sistedes.es/articulo/modeling-systems-variability-with-delta-rhapsody/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/modeling-systems-variability-with-delta-rhapsody/</guid>
		<description></description>
		<content><![CDATA[Variability modeling is demanded by industrial companies to support customization of their products. However, not all the software tools include variability modeling mechanisms. IBM Rhapsody is one of the leading environments for modeling complex industrial systems. In this paper we present Delta Rhapsody, a tool for modeling variability in IBM Rhapsody models employing the delta modeling paradigm.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2581</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modeling-systems-variability-with-delta-rhapsody]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="delta-modelling"><![CDATA[Delta Modelling]]></category>
		<category domain="post_tag" nicename="rhapsody"><![CDATA[Rhapsody]]></category>
		<category domain="post_tag" nicename="variability"><![CDATA[Variability]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Variability modeling is demanded by industrial companies to support customization of their products. However, not all the software tools include variability modeling mechanisms. IBM Rhapsody is one of the leading environments for modeling complex industrial systems. In this paper we present Delta Rhapsody, a tool for modeling variability in IBM Rhapsody models employing the delta modeling paradigm.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/006]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_41.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_41.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Xabier Perez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[xabier.perezb@alumni.mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Mondragon Unibertsitatea]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Oskar Berreteaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[oberreteaga@ulmaembedded.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ULMA Embedded Solutions]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Leire Etxeberria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[letxeberria@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Aitor Arrieta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aarrieta@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Urtzi Markiegi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[umarkiegi@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Soportando el modelado de procesos  de negocio con Process Chain Network</title>
		<link>https://biblioteca.sistedes.es/articulo/soportando-el-modelado-de-procesos-de-negocio-con-process-chain-network/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/soportando-el-modelado-de-procesos-de-negocio-con-process-chain-network/</guid>
		<description></description>
		<content><![CDATA[En la actualidad, los modelos de negocio se han convertido en un activo fundamental para cualquier tipo de organización. De hecho, son varias las notaciones que gozan de cierto nivel de aceptación para la representación de modelos de negocio. Sin embargo, no existe a día de hoy un entorno que permita gestionar eficazmente modelos de negocio elaborados con diferentes notaciones, debiendo recurrir a diferentes herramientas o incluso en algunos casos, a simples editores de imágenes o diagramadores genéricos. Este último es el caso de Process Chain Network (PCN), una técnica para la representación visual de procesos de negocio, utilizada habitualmente en el área de operaciones de servicio. Por todo ello, en este trabajo se presenta un DSL gráfico que soporta la notación PCN y se integra en un entorno de modelado para el diseño de servicios, con la intención de soportar a medio plazo la gestión integrada de modelos de negocio elaborados con diferentes notaciones.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2582</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[soportando-el-modelado-de-procesos-de-negocio-con-process-chain-network]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="bpmn"><![CDATA[BPMN]]></category>
		<category domain="post_tag" nicename="modelo-de-negocio"><![CDATA[Modelo de Negocio]]></category>
		<category domain="post_tag" nicename="proceso-de-negocio"><![CDATA[Proceso de Negocio]]></category>
		<category domain="post_tag" nicename="process-chain-network"><![CDATA[Process Chain Network]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En la actualidad, los modelos de negocio se han convertido en un activo fundamental para cualquier tipo de organización. De hecho, son varias las notaciones que gozan de cierto nivel de aceptación para la representación de modelos de negocio. Sin embargo, no existe a día de hoy un entorno que permita gestionar eficazmente modelos de negocio elaborados con diferentes notaciones, debiendo recurrir a diferentes herramientas o incluso en algunos casos, a simples editores de imágenes o diagramadores genéricos. Este último es el caso de Process Chain Network (PCN), una técnica para la representación visual de procesos de negocio, utilizada habitualmente en el área de operaciones de servicio. Por todo ello, en este trabajo se presenta un DSL gráfico que soporta la notación PCN y se integra en un entorno de modelado para el diseño de servicios, con la intención de soportar a medio plazo la gestión integrada de modelos de negocio elaborados con diferentes notaciones. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/030]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_42.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_42.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Javier Pérez Blanco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[francisco.perez@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group,  University Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[María Valeria De Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[valeria.decastro@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group. University Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[David Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[david.granada@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Cómo gestionan la variabilidad las empresas que no conocen de líneas de producto software: hacia una evaluación real</title>
		<link>https://biblioteca.sistedes.es/articulo/como-gestionan-la-variabilidad-las-empresas-que-no-conocen-de-lineas-de-producto-software-hacia-una-evaluacion-real/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/como-gestionan-la-variabilidad-las-empresas-que-no-conocen-de-lineas-de-producto-software-hacia-una-evaluacion-real/</guid>
		<description></description>
		<content><![CDATA[Las líneas de producto software tienen como prioridad alcanzar la reutilización sistemática dentro de una organización permitiendo la reducción de coste, esfuerzo, tiempo de desarrollo, y numero promedio de defectos por producto. Sin embargo, existen desafíos al ejecutar un proyecto de emph{líneas de producto software (SPLs)} y pocas veces estos han sido reportados, reduciendo la posibilidad de comprobación entre la teoría y la praxis. Esto implica dificultades para el fortalecimiento o elaboración de ajustes o mejoras a los frameworks de SPL. Asimismo, hay nuevos conceptos novedosos como los ecosistemas software software ecosystems'', que hacen necesario revisar el concepto de SPL y adaptarlo a los tiempos actuales. En este artículo, presentamos el diseño de un emph{estudio de caso} para la reducir esta brecha, permitiendo conocer el contexto de dos medianas empresas que no saben de líneas de producto software emph{gestionan la variabilidad}. También, nos permitirá identificar oportunidades y debilidades descubiertas en los frameworks de adopción de SPL con el objetivo de mejorarlos. Además de presentar un fragmento metodológico que indique el camino a seguir para que una empresa pueda transicionar hacia el paradigma de SPLs.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2583</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[como-gestionan-la-variabilidad-las-empresas-que-no-conocen-de-lineas-de-producto-software-hacia-una-evaluacion-real]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="estudio-de-casos"><![CDATA[estudio de casos]]></category>
		<category domain="post_tag" nicename="gestion-de-variabilidad"><![CDATA[gestión de variabilidad]]></category>
		<category domain="post_tag" nicename="lineas-de-producto-software"><![CDATA[Líneas de Producto Software]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las líneas de producto software tienen como prioridad alcanzar la reutilización sistemática dentro de una organización permitiendo la reducción de coste, esfuerzo, tiempo de desarrollo, y numero promedio de defectos por producto. Sin embargo, existen desafíos al ejecutar un proyecto de emph{líneas de producto software (SPLs)} y pocas veces estos han sido reportados, reduciendo la posibilidad de comprobación entre la teoría y la praxis. Esto implica dificultades para el fortalecimiento o elaboración de ajustes o mejoras a los frameworks de SPL. Asimismo, hay nuevos conceptos novedosos como los ecosistemas software software ecosystems'', que hacen necesario revisar el concepto de SPL y adaptarlo a los tiempos actuales. En este artículo, presentamos el diseño de un emph{estudio de caso} para la reducir esta brecha, permitiendo conocer el contexto de dos medianas empresas que no saben de líneas de producto software emph{gestionan la variabilidad}. También, nos permitirá identificar oportunidades y debilidades descubiertas en los frameworks de adopción de SPL con el objetivo de mejorarlos. Además de presentar un fragmento metodológico que indique el camino a seguir para que una empresa pueda transicionar hacia el paradigma de SPLs.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/002]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_43.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_43.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana E. Chacón-Luna]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[achaconl1@unemi.edu.ec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad estatal de Milagro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José A. Galindo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jagalindo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[David Benavides]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[benavides@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Localización de defectos en aplicaciones MapReduce</title>
		<link>https://biblioteca.sistedes.es/articulo/localizacion-de-defectos-en-aplicaciones-mapreduce/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/localizacion-de-defectos-en-aplicaciones-mapreduce/</guid>
		<description></description>
		<content><![CDATA[Los programas que analizan grandes cantidades de datos suelen ejecutarse en entornos distribuidos, tal y como ocurre con las aplicaciones MapReduce. Estos programas se desarrollan independientemente de la infraestructura sobre que la que se ejecutan, ya que un framework gestiona automáticamente la asignación de recursos y gestión de fallos, entre otros. Detectar y localizar defectos en estos programas suele ser una tarea compleja ya que diversas funciones se ejecutan simultáneamente en una infraestructura distribuida, difícil de controlar y que cambia continuamente. En este artículo se describe una técnica que, a partir de un fallo detectado en las pruebas, localiza defectos de diseño analizando dinámicamente los parámetros que lo causan.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2584</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[localizacion-de-defectos-en-aplicaciones-mapreduce]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="big-data-engineering"><![CDATA[Big Data Engineering]]></category>
		<category domain="post_tag" nicename="localizacion-de-defectos"><![CDATA[Localización de defectos]]></category>
		<category domain="post_tag" nicename="mapreduce"><![CDATA[MapReduce]]></category>
		<category domain="post_tag" nicename="pruebas-del-software"><![CDATA[Pruebas del software]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los programas que analizan grandes cantidades de datos suelen ejecutarse en entornos distribuidos, tal y como ocurre con las aplicaciones MapReduce. Estos programas se desarrollan independientemente de la infraestructura sobre que la que se ejecutan, ya que un framework gestiona automáticamente la asignación de recursos y gestión de fallos, entre otros. Detectar y localizar defectos en estos programas suele ser una tarea compleja ya que diversas funciones se ejecutan simultáneamente en una infraestructura distribuida, difícil de controlar y que cambia continuamente. En este artículo se describe una técnica que, a partir de un fallo detectado en las pruebas, localiza defectos de diseño analizando dinámicamente los parámetros que lo causan.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/070]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_44.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_44.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús Morán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[moranjesus@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Claudio De La Riva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[claudio@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Bibiano Rivas García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Bibiano.Rivas@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Mantenimiento de la Consistencia Lógica en Cassandra</title>
		<link>https://biblioteca.sistedes.es/articulo/mantenimiento-de-la-consistencia-logica-en-cassandra/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/mantenimiento-de-la-consistencia-logica-en-cassandra/</guid>
		<description></description>
		<content><![CDATA[A diferencia de las bases de datos relacionales, en bases de datos NoSQL como Cassandra es muy común que exista duplicidad de los datos en diferentes tablas. Esto es debido a que, normalmente, las tablas son diseñadas en base a las consul-tas y a la ausencia de relaciones entre ellas para primar el rendimiento en las con-sultas. Por tanto, si los datos no se actualizan convenientemente, se pueden pro-ducir inconsistencias en la información almacenada. Es relativamente fácil intro-ducir defectos que originan inconsistencia de datos en Cassandra, sobre todo du-rante la evolución de un sistema en el que se crean nuevas tablas, y éstos son difí-ciles de detectar utilizando técnicas convencionales de pruebas dinámicas. El desarrollador es quien debe preocuparse de mantener esta consistencia incluyendo y actualizando los procedimientos adecuados. Este trabajo propone un enfoque preventivo a estos problemas, estableciendo los procesos necesarios para asegu-rar la calidad de los datos desde el punto de vista de su consistencia, facilitando así las tareas del desarrollador. Estos procesos incluyen: (1) un análisis estático considerando el modelo conceptual, las consultas y el modelo lógico de la aplica-ción, para identificar qué elementos (tablas o columnas) de la base de datos se ven afectados por un cambio, y (2) la determinación y ejecución de las operaciones que aseguren la consistencia de la información.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2585</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mantenimiento-de-la-consistencia-logica-en-cassandra]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="apache-cassandra"><![CDATA[Apache Cassandra]]></category>
		<category domain="post_tag" nicename="consistencia-logica"><![CDATA[Consistencia Lógica]]></category>
		<category domain="post_tag" nicename="pruebas-estaticas"><![CDATA[Pruebas Estáticas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A diferencia de las bases de datos relacionales, en bases de datos NoSQL como Cassandra es muy común que exista duplicidad de los datos en diferentes tablas. Esto es debido a que, normalmente, las tablas son diseñadas en base a las consul-tas y a la ausencia de relaciones entre ellas para primar el rendimiento en las con-sultas. Por tanto, si los datos no se actualizan convenientemente, se pueden pro-ducir inconsistencias en la información almacenada. Es relativamente fácil intro-ducir defectos que originan inconsistencia de datos en Cassandra, sobre todo du-rante la evolución de un sistema en el que se crean nuevas tablas, y éstos son difí-ciles de detectar utilizando técnicas convencionales de pruebas dinámicas. El desarrollador es quien debe preocuparse de mantener esta consistencia incluyendo y actualizando los procedimientos adecuados. Este trabajo propone un enfoque preventivo a estos problemas, estableciendo los procesos necesarios para asegu-rar la calidad de los datos desde el punto de vista de su consistencia, facilitando así las tareas del desarrollador. Estos procesos incluyen: (1) un análisis estático considerando el modelo conceptual, las consultas y el modelo lógico de la aplica-ción, para identificar qué elementos (tablas o columnas) de la base de datos se ven afectados por un cambio, y (2) la determinación y ejecución de las operaciones que aseguren la consistencia de la información.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/071]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_45.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_45.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Suárez-Otero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[suarezgpablo@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Gutierrez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[javierj@lsi.us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de  Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Claudio de La Riva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[claudio@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An exploratory study in communication in Agile Global Software Development</title>
		<link>https://biblioteca.sistedes.es/articulo/an-exploratory-study-in-communication-in-agile-global-software-development/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-exploratory-study-in-communication-in-agile-global-software-development/</guid>
		<description></description>
		<content><![CDATA[Global software development (GSD) is gaining ever more relevance. Although communication is key in the exchange of information between team members, multi-site software development has introduced additional obstacles (different time-zones and cultures, IT infrastructure, etc.) and delays into the act of communication, which is already problematic. Communication is even more critical in the case of Agile Global Software Development (AGSD) in which communication plays a primary role. This paper reports an exploratory study of the effects of tools supporting communication in AGSD. More precisely, this paper analyses the perception of team members about communication infrastructures in AGSD. The research question to which this study responds concerns how development teams perceive the communication infrastructure while developing products using agile methodologies. Most previous studies have dealt with communication support from a highly technological media tool perspective. In this research work, instead, observations were obtained from three perspectives: communication among team members, communication of the status of the development process, and communication of the status of the progress of the product under development. It has been possible to show that team members perceive advantages to using media tools that make them feel in practice that teams are co-located, such as smartboards supported by efficient video-tools, and combining media tools with centralized repository tools, with information from the process development and product characteristics, that allow distributed teams to effectively share information about the status of the project/process/product during the development process in order to overcome some of the still existing problems in communication in AGSD. COMPUTER STANDARDS &amp; INTERFACES Volumen: 48 Páginas: 184-197 Número especial: SI DOI: 10.1016/j.csi.2016.06.002 Impacto de la revista 2015 Computer Science: 171/393 Q2 2015 Computer Svience/Software Engineering 35/106 Q2]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2586</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-exploratory-study-in-communication-in-agile-global-software-development]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="agile"><![CDATA[Agile]]></category>
		<category domain="post_tag" nicename="development-project"><![CDATA[Development project]]></category>
		<category domain="post_tag" nicename="exploratory-research"><![CDATA[Exploratory research]]></category>
		<category domain="post_tag" nicename="global-distributed-software-development"><![CDATA[Global Distributed Software Development]]></category>
		<category domain="post_tag" nicename="infrastructure"><![CDATA[Infrastructure]]></category>
		<category domain="post_tag" nicename="mangement"><![CDATA[Mangement]]></category>
		<category domain="post_tag" nicename="teams"><![CDATA[Teams]]></category>
		<category domain="post_tag" nicename="tools-and-technologies"><![CDATA[Tools and technologies]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Global software development (GSD) is gaining ever more relevance. Although communication is key in the exchange of information between team members, multi-site software development has introduced additional obstacles (different time-zones and cultures, IT infrastructure, etc.) and delays into the act of communication, which is already problematic. Communication is even more critical in the case of Agile Global Software Development (AGSD) in which communication plays a primary role. This paper reports an exploratory study of the effects of tools supporting communication in AGSD. More precisely, this paper analyses the perception of team members about communication infrastructures in AGSD. The research question to which this study responds concerns how development teams perceive the communication infrastructure while developing products using agile methodologies. Most previous studies have dealt with communication support from a highly technological media tool perspective. In this research work, instead, observations were obtained from three perspectives: communication among team members, communication of the status of the development process, and communication of the status of the progress of the product under development. It has been possible to show that team members perceive advantages to using media tools that make them feel in practice that teams are co-located, such as smartboards supported by efficient video-tools, and combining media tools with centralized repository tools, with information from the process development and product characteristics, that allow distributed teams to effectively share information about the status of the project/process/product during the development process in order to overcome some of the still existing problems in communication in AGSD.   COMPUTER STANDARDS & INTERFACES  Volumen: 48  Páginas: 184-197  Número especial: SI  DOI: 10.1016/j.csi.2016.06.002   Impacto de la revista  2015 Computer Science: 171/393 Q2 2015 Computer Svience/Software Engineering 35/106 Q2 ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/045]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_46.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_46.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Agustin Yague]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[agustin.yague@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Garbajosa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jgs@etsisi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politecnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jessica Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[idiaz@etsisi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Eloy Gonzalez Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[egonzalezort@indra.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Indra Software Labs]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A model-based proposal for integrating the measures lifecycle within the process lifecycle</title>
		<link>https://biblioteca.sistedes.es/articulo/a-model-based-proposal-for-integrating-the-measures-lifecycle-within-the-process-lifecycle/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-model-based-proposal-for-integrating-the-measures-lifecycle-within-the-process-lifecycle/</guid>
		<description></description>
		<content><![CDATA[Software development process (SDP) is a complex and long endeavor, the quality and management of this process affect the quality of its results. Measuring the SDP is essential to gain insight on its performance and to discover improvements. This work proposes to use Model-Driven Engineering (MDE) paradigm to integrate the measures lifecycle within the process lifecycle in order to explicitly and operationally model measures during the process modeling. Also defines transformation rules to derive executable code to run these measures into enterprise tools in order to support the measures lifecycle.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2587</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-model-based-proposal-for-integrating-the-measures-lifecycle-within-the-process-lifecycle]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="measurement"><![CDATA[Measurement.]]></category>
		<category domain="post_tag" nicename="modeling"><![CDATA[Modeling.]]></category>
		<category domain="post_tag" nicename="software-development-process"><![CDATA[Software development process.]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Software development process (SDP) is a complex and long endeavor, the quality and management of this process affect the quality of its results. Measuring the SDP is essential to gain insight on its performance and to discover improvements. This work proposes to use Model-Driven Engineering (MDE) paradigm to integrate the measures lifecycle within the process lifecycle in order to explicitly and operationally model measures during the process modeling. Also defines transformation rules to derive executable code to run these measures into enterprise tools in order to support the measures lifecycle.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/053]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_47.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_47.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ayman Meidan]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ayman.meidan@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Julian Alberto García García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[julian.garcia@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Isabel Ramos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[iramos@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Maria Jose Escalona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mjescalona@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Carlos Arevalo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[carlosarevalo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia una propuesta de estimación de costes de producción desde etapas tempranas del desarrollo Web</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-una-propuesta-de-estimacion-de-costes-de-produccion-desde-etapas-tempranas-del-desarrollo-web/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/hacia-una-propuesta-de-estimacion-de-costes-de-produccion-desde-etapas-tempranas-del-desarrollo-web/</guid>
		<description></description>
		<content><![CDATA[Actualmente, el coste de producción de aplicaciones en infraestructuras cloud se calcula prácticamente en las fases finales de despliegue y produccion. Por otro lado, la creciente consolidación de la Ingeniería Web Dirigida por Modelos ofrece ventajas como la generación de código a partir de la etapa de diseño. Con ambas ideas en mente, en este trabajo presentamos los primeros pasos encaminados a disponer de una propuesta de estimación de los costes de producción en un entorno cloud a partir de la etapa de diseño, anticipando así la toma de decisiones al respecto.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2588</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-una-propuesta-de-estimacion-de-costes-de-produccion-desde-etapas-tempranas-del-desarrollo-web]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="crud"><![CDATA[CRUD.]]></category>
		<category domain="post_tag" nicename="diseno"><![CDATA[Diseño.]]></category>
		<category domain="post_tag" nicename="ingenieria-web"><![CDATA[Ingeniería Web]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Actualmente, el coste de producción de aplicaciones en infraestructuras cloud se calcula prácticamente en las fases nales de despliegue y produccion. Por otro lado, la creciente consolidación de la Ingeniería Web Dirigida por Modelos ofrece ventajas como la generación de código a partir de la etapa de dise~no. Con ambas ideas en mente, en este trabajo presentamos los primeros pasos encaminados a disponer de una propuesta de estimación de los costes de producción en un entorno cloud a partir de la etapa de diseño, anticipando así la toma de decisiones al respecto.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/063]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_48.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_48.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rubén Martín]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rubenms@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Carlos Preciado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jcpreciado@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose Maria Conejero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[chemacm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Roberto Rodriguez-Echeverria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[rre@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Fernando Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[fernando@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Diseñando la Participación del Humano en los Sistemas Autónomos</title>
		<link>https://biblioteca.sistedes.es/articulo/disenando-la-participacion-del-humano-en-los-sistemas-autonomos/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/disenando-la-participacion-del-humano-en-los-sistemas-autonomos/</guid>
		<description></description>
		<content><![CDATA[Estamos entrando gradualmente en la era de los sistemas que pretenden dotar de capacidades de computación autónoma a servicios cotidianos. La búsqueda de la autonomía completa es un reto que se está persiguiendo en diversos ámbitos de aplicación y sectores industriales. Sin embargo, la realidad es que la variedad de sistemas, dominios, entornos y contextos de ejecución, restricciones legales y sociales, hace vislumbrar un mundo donde esta autonomía completa será una utopía a corto y medio plazo. En los escenarios en que el sistema autónomo no pueda automatizar completamente sus tareas, se requerirá pues de la participación humana. Desde un punto de vista ingenieril la colaboración entre el humano y estos sistemas (Human in the Loop) introduce un considerable número de retos y problemas a resolver. En este trabajo se identifican los retos tecnológicos que introduce esta colaboración humano-sistema, y se define un marco conceptual que identifica los aspectos a considerar desde un punto de vista abstracto e ingenieril.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2589</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[disenando-la-participacion-del-humano-en-los-sistemas-autonomos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="human-in-the-loop"><![CDATA[Human in the Loop]]></category>
		<category domain="post_tag" nicename="interaccion-hombre-maquina"><![CDATA[Interacción Hombre-Máquina]]></category>
		<category domain="post_tag" nicename="marco-conceptual"><![CDATA[Marco Conceptual]]></category>
		<category domain="post_tag" nicename="sensibilidad-al-contexto"><![CDATA[Sensibilidad al contexto]]></category>
		<category domain="post_tag" nicename="sistemas-autonomos"><![CDATA[Sistemas Autónomos]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Estamos entrando gradualmente en la era de los sistemas que pretenden dotar de capacidades de computación autónoma a servicios cotidianos. La búsqueda de la autonomía completa es un reto que se está persiguiendo en diversos ámbitos de aplicación y sectores industriales. Sin embargo, la realidad es que la variedad de sistemas, dominios, entornos y contextos de ejecución, restricciones legales y sociales, hace vislumbrar un mundo donde esta autonomía completa será una utopía a corto y medio plazo. En los escenarios en que el sistema autónomo no pueda automatizar completamente sus tareas, se requerirá pues de la participación humana. Desde un punto de vista ingenieril la colaboración entre el humano y estos sistemas (Human in the Loop) introduce un considerable número de retos y problemas a resolver. En este trabajo se identifican los retos tecnológicos que introduce esta colaboración humano-sistema, y se define un marco conceptual que identifica los aspectos a considerar desde un punto de vista abstracto e ingenieril. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/062]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_49.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_49.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pele@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miriam Gil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mgil@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Joan Fons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jjfons@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manoli Albert]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[malbert@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Definiendo un Caso de Estudio para Recomendaciones Dinámicas Móviles</title>
		<link>https://biblioteca.sistedes.es/articulo/definiendo-un-caso-de-estudio-para-recomendaciones-dinamicas-moviles/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/definiendo-un-caso-de-estudio-para-recomendaciones-dinamicas-moviles/</guid>
		<description></description>
		<content><![CDATA[Los denominados sistemas de recomendación permiten aliviar la sobrecarga de información de los usuarios, al ofrecer sugerencias específicas acerca de ítems concretos (películas, libros, actividades, puntos de interés, etc.) que pueden resultar de interés para el usuario. En los últimos años se está realizando una intensa investigación en el desarrollo de sistemas de recomendación sensibles al contexto, ya que tener en cuenta el contexto del usuario (posición geográfica, tiempo atmosférico, estado de ánimo, etc.) permite ofrecer recomendaciones más apropiadas. En entornos de computación móvil uno de los elementos clave del contexto del usuario es su localización, siendo relevante ofrecer sugerencias al usuario de forma proactiva (sin peticiones expresas por parte del usuario) y teniendo en cuenta su trayectoria. En este artículo, describimos nuestro trabajo en progreso relacionado con las recomendaciones dinámicas sensibles al contexto en entornos móviles. Debido a la dificultad de evaluación de estos sistemas de recomendación en el mundo real, nos centramos en el desarrollo de un caso de estudio que simulará un escenario para recomendaciones dinámicas para los visitantes de un museo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2590</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[definiendo-un-caso-de-estudio-para-recomendaciones-dinamicas-moviles]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="computacion-movil"><![CDATA[computación móvil]]></category>
		<category domain="post_tag" nicename="contexto"><![CDATA[Contexto]]></category>
		<category domain="post_tag" nicename="recomendaciones-dinamicas"><![CDATA[recomendaciones dinámicas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los denominados sistemas de recomendación permiten aliviar la sobrecarga de información de los usuarios, al ofrecer sugerencias específicas acerca de ítems concretos (películas, libros, actividades, puntos de interés, etc.) que pueden resultar de interés para el usuario. En los últimos años se está realizando una intensa investigación en el desarrollo de sistemas de recomendación sensibles al contexto, ya que tener en cuenta el contexto del usuario (posición geográfica, tiempo atmosférico, estado de ánimo, etc.) permite ofrecer recomendaciones más apropiadas.  En entornos de computación móvil uno de los elementos clave del contexto del usuario es su localización, siendo relevante ofrecer sugerencias al usuario de forma proactiva (sin peticiones expresas por parte del usuario) y teniendo en cuenta su trayectoria. En este artículo, describimos nuestro trabajo en progreso relacionado con las recomendaciones dinámicas sensibles al contexto en entornos móviles. Debido a la dificultad de evaluación de estos sistemas de recomendación en el mundo real, nos centramos en el desarrollo de un caso de estudio que simulará un escenario para recomendaciones dinámicas para los visitantes de un museo. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/013]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_50.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_50.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Del Carmen Rodríguez-Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[692383@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Ilarri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[silarri@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ramon Hermoso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[rhermoso@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Raquel Trillo-Lado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[raqueltl@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una Aproximación MDA para la Construcción de Componentes COTSgets en Aplicaciones Web</title>
		<link>https://biblioteca.sistedes.es/articulo/una-aproximacion-mda-para-la-construccion-de-componentes-cotsgets-en-aplicaciones-web/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/una-aproximacion-mda-para-la-construccion-de-componentes-cotsgets-en-aplicaciones-web/</guid>
		<description></description>
		<content><![CDATA[Actualmente, existe una tendencia al desarrollo de aplicaciones web. Muchas de estas aplicaciones se construyen en base a componentes reutilizables, lo que influye considerablemente en el tiempo de desarrollo. En este contexto se enmarca nuestra propuesta. El artículo presenta una solución basada en la ingeniería dirigida por modelos (MDE) para agilizar y facilitar a los desarrolladores la implementación de un tipo de componentes web (llamados COTSgets). Nuestra propuesta consiste en la generación automática de la implementación de estos componentes, en lo que a su estructura y funcionalidad básica se refiere, a partir de un modelo que describe su especificación y mediante la utilización de una transformación modelo-a-texto (M2T). Para dicha implementación se ha seleccionado la incipiente tecnología Polymer.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2591</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-aproximacion-mda-para-la-construccion-de-componentes-cotsgets-en-aplicaciones-web]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="componentes-cotsgets"><![CDATA[Componentes COTSgets]]></category>
		<category domain="post_tag" nicename="coscore"><![CDATA[COScore]]></category>
		<category domain="post_tag" nicename="ingenieria-dirigida-por-modelos-mde"><![CDATA[Ingeniería Dirigida por Modelos (MDE)]]></category>
		<category domain="post_tag" nicename="polymer"><![CDATA[Polymer]]></category>
		<category domain="post_tag" nicename="transformacion-de-modelo-a-texto-m2t"><![CDATA[Transformación de Modelo a Texto (M2T)]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Actualmente, existe una tendencia al desarrollo de aplicaciones web. Muchas de estas aplicaciones se construyen en base a componentes reutilizables, lo que influye considerablemente en el tiempo de desarrollo. En este contexto se enmarca nuestra propuesta. El artículo presenta una solución basada en la ingeniería dirigida por modelos (MDE) para agilizar y facilitar a los desarrolladores la implementación de un tipo de componentes web (llamados COTSgets). Nuestra propuesta consiste en la generación automática de la implementación de estos componentes, en lo que a su estructura y funcionalidad básica se refiere, a partir de un modelo que describe su especificación y mediante la utilización de una transformación modelo-a-texto (M2T). Para dicha implementación se ha seleccionado la incipiente tecnología Polymer.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/032]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_53.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_53.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jose A. Asensio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jacortes@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group. University of Almerí­a]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Nicolás Padilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[npadilla@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group. University of Almerí­a]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Criado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[javi.criado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Almerí­a]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Luis Iribarne]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[luis.iribarne@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Almerí­a]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Does the level of detail of UML diagrams affect the maintainability of source code?: a family of experiments</title>
		<link>https://biblioteca.sistedes.es/articulo/does-the-level-of-detail-of-uml-diagrams-affect-the-maintainability-of-source-code-a-family-of-experiments/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/does-the-level-of-detail-of-uml-diagrams-affect-the-maintainability-of-source-code-a-family-of-experiments/</guid>
		<description></description>
		<content><![CDATA[Although the UML is considered to be the de facto standard notation with which to model software, there is still resistance to model-based development. UML modeling is perceived to be expensive and not necessarily cost-effective. It is therefore important to collect empirical evidence concerning the conditions under which the use of UML makes a practical difference. The focus of this paper is to investigate whether and how the Level of Detail (LoD) of UML diagrams impacts on the performance of maintenance tasks in a model-centric approach. A family of experiments consisting of one controlled experiment and three replications has therefore been carried out with 81 students with different abilities and levels of experience from 3 countries (The Netherlands, Spain, and Italy). The analysis of the results of the experiments indicates that there isno strong statistical evidence as to the influence of different LoDs. The analysis suggests a slight tendency toward better results when using low LoD UML diagrams, especially if used for the modification of the source code, while a high LoD would appear to be helpful in understanding the system. The participants in our study also favored low LoD diagrams because they were perceived as easier to read. Although the participants expressed a preference for low LoD diagrams, no statistically significant conclusions can be drawn from the set of experiments. One important finding attained from this family of experiments was that the participants minimized or avoided the use of UML diagrams, regardless of their LoD. This effect was probably the result of using small software systems from well-known domains as experimental materials.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2592</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[does-the-level-of-detail-of-uml-diagrams-affect-the-maintainability-of-source-code-a-family-of-experiments]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="controlled-experiment"><![CDATA[Controlled Experiment]]></category>
		<category domain="post_tag" nicename="family-of-experiments"><![CDATA[Family of experiments]]></category>
		<category domain="post_tag" nicename="level-of-detail"><![CDATA[Level of detail]]></category>
		<category domain="post_tag" nicename="replication"><![CDATA[Replication]]></category>
		<category domain="post_tag" nicename="software-maintenance"><![CDATA[Software maintenance]]></category>
		<category domain="post_tag" nicename="uml-diagrams"><![CDATA[UML diagrams]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Although the UML is considered to be the de facto standard notation with which to model software, there is still resistance to model-based development. UML modeling is perceived to be expensive and not necessarily cost-effective. It is therefore important to collect empirical evidence concerning the conditions under which the use of UML makes a practical difference. The focus of this paper is to investigate whether and how the Level of Detail (LoD) of UML diagrams impacts on the performance of maintenance tasks in a model-centric approach. A family of experiments consisting of one controlled experiment and three replications has therefore been carried out with 81 students with different abilities and levels of experience from 3 countries (The Netherlands, Spain, and Italy). The analysis of the results of the experiments indicates that there isno strong statistical evidence as to the influence of different LoDs. The analysis suggests a slight tendency toward better results when using low LoD UML diagrams, especially if used for the modification of the source code, while a high LoD would appear to be helpful in understanding the system. The participants in our study also favored low LoD diagrams because they were perceived as easier to read. Although the participants expressed a preference for low LoD diagrams, no statistically significant conclusions can be drawn from the set of experiments. One important finding attained from this family of experiments was that the participants minimized or avoided the use of UML diagrams, regardless of their LoD. This effect was probably the result of using small software systems from well-known domains as experimental materials.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/047]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_54.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_54.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana Maria Fernández-Sáez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ana.fernandez@alarcosqualitycenter.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha/ Leiden University]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Marcela Genero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[marcela.genero@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Danilo Caivano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[danilo.caivano@searandp.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Bari]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Michel Chaudron]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[chaudron@chalmers.se]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Chalmers]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A workflow management system to feed digital libraries: proposal and case study</title>
		<link>https://biblioteca.sistedes.es/articulo/a-workflow-management-system-to-feed-digital-libraries-proposal-and-case-study/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-workflow-management-system-to-feed-digital-libraries-proposal-and-case-study/</guid>
		<description></description>
		<content><![CDATA[Articulo publicado en: Multimedia Tools and Applications, 75(7), Springer US, Estados Unidos, 2016, pp. 3843-3877. DOI: 10.1007/s11042-014-2155-3 Multimedia Tools and Applications tiene factor de impacto 1.331, y está clasificada como Q2 en COMPUTER SCIENCE, INFORMATION SYSTEMS]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2593</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-workflow-management-system-to-feed-digital-libraries-proposal-and-case-study]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="digital-libraries"><![CDATA[Digital libraries]]></category>
		<category domain="post_tag" nicename="text-retrieval"><![CDATA[Text retrieval]]></category>
		<category domain="post_tag" nicename="workflow-management-system"><![CDATA[Workflow management system]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Articulo publicado en:  Multimedia Tools and Applications, 75(7), Springer US, Estados Unidos, 2016, pp. 3843-3877.  DOI: 10.1007/s11042-014-2155-3  Multimedia Tools and Applications tiene factor de impacto 1.331, y está clasificada como Q2 en COMPUTER SCIENCE, INFORMATION SYSTEMS]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/010]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_57.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_57.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ángeles S. Places]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[asplaces@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Fariña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fari@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of A Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Miguel R. Luaces]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[luaces@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of A Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Oscar Pedreira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[opedreira@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruna]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Diego Seco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[dseco@udec.cl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Concepción]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Trayectorias semánticas en aplicaciones de Mobile Workforce Management</title>
		<link>https://biblioteca.sistedes.es/articulo/trayectorias-semanticas-en-aplicaciones-de-mobile-workforce-management/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:07 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/trayectorias-semanticas-en-aplicaciones-de-mobile-workforce-management/</guid>
		<description></description>
		<content><![CDATA[Los smartphones actuales presentan continuamente mejoras en sus características y en la actualidad incluyen diversos sensores que capturan información de muy diversos tipos (localización, aceleración lineal, etc.). Un proceso industrial que podría beneficiarse mucho de esta información es el de Mobile Workforce Management (MWM). Sin embargo, existen varios problemas que lo impiden: i) hoy en día el nivel de abstracción de las actividades que son identificadas es demasiado bajo (por ejemplo, moviéndose en vez de realizando una inspección en un cliente, o parado en vez de cargando un camión en la instalación de un cliente), ii) los trabajos de investigación se centran en el uso de algoritmos que contrastan la información geográfica con los datos del GPS, o en algoritmos de aprendizaje aplicados a los datos de los sensores, pero existen pocos resultados de investigación que combinen ambos tipos de datos, y iii) la información contextual procedente de los repositorios de información geográfica o del software MWM es raramente usada. En este artículo se presenta una nueva metodología que convierte los datos crudos capturados por los sensores de los dispositivos móviles en trayectorias anotadas con actividades semánticas en un alto nivel de abstracción. La metodología está basada en la definición de taxonomías de actividades que pueden ser adaptadas fácilmente a las necesidades de cualquier empresa. Estas taxonomías describen los valores esperados para cada una de las variables que son recogidas en el sistema usando predicados definidos mediante un lenguaje de especificación de patrones.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2594</post_id>
		<post_date><![CDATA[2017-07-02 04:47:07]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:07]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[trayectorias-semanticas-en-aplicaciones-de-mobile-workforce-management]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="datos-de-sensores"><![CDATA[datos de sensores]]></category>
		<category domain="post_tag" nicename="mobile-workforce-management"><![CDATA[mobile workforce management]]></category>
		<category domain="post_tag" nicename="sistemas-de-informacion-geografica"><![CDATA[Sistemas de Informacíon Geográfica]]></category>
		<category domain="post_tag" nicename="trayectorias-semanticas"><![CDATA[trayectorias semánticas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los smartphones actuales presentan continuamente mejoras en sus características y en la actualidad incluyen diversos sensores que capturan información de muy diversos tipos (localización, aceleración lineal, etc.). Un proceso industrial que podría beneficiarse mucho de esta información es el de Mobile Workforce Management (MWM). Sin embargo, existen varios problemas que lo impiden: i) hoy en día el nivel de abstracción de las actividades que son identificadas es demasiado bajo (por ejemplo, moviéndose en vez de realizando una inspección en un cliente, o parado en vez de cargando un camión en la instalación de un cliente), ii) los trabajos de investigación se centran en el uso de algoritmos que contrastan la información geográfica con los datos del GPS, o en algoritmos de aprendizaje aplicados a los datos de los sensores, pero existen pocos resultados de investigación que combinen ambos tipos de datos, y iii) la información contextual procedente de los repositorios de información geográfica o del software MWM es raramente usada.  En este artículo se presenta una nueva metodología que convierte los datos crudos capturados por los sensores de los dispositivos móviles en trayectorias anotadas con actividades semánticas en un alto nivel de abstracción. La metodología está basada en la definición de taxonomías de actividades que pueden ser adaptadas fácilmente a las necesidades de cualquier empresa. Estas taxonomías describen los valores esperados para cada una de las variables que son recogidas en el sistema usando predicados definidos mediante un lenguaje de especificación de patrones. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/023]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_58.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_58.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Nieves R. Brisaboa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[brisaboa@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miguel R. Luaces]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[luaces@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of A Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Cristina Martínez Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[cristina.martinez@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ángeles S. Places]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[asplaces@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una aplicación práctica del método Delphi para la validación de una propuesta de Ingeniería Web</title>
		<link>https://biblioteca.sistedes.es/articulo/una-aplicacion-practica-del-metodo-delphi-para-la-validacion-de-una-propuesta-de-ingenieria-web/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/una-aplicacion-practica-del-metodo-delphi-para-la-validacion-de-una-propuesta-de-ingenieria-web/</guid>
		<description></description>
		<content><![CDATA[Las organizaciones que trabajan en el desarrollo de Sistemas de Información son reacias muchas veces a implantar nuevas metodologías de trabajo sin disponer previamente de ciertas garantías de éxito. Esta reacción es comprensible, ya que el éxito o el fracaso de ciertos proyectos puede suponer graves pérdidas económicas o reputacionales para las misma. En este trabajo vamos a presentar una aplicación práctica del uso de una técnica de juicio de expertos, el método Delphi, para la validación de una propuesta metodológica en el ámbito de la Ingeniería Web. El uso de las técnicas basadas en juicios de expertos puede suponer un buen compromiso en términos de inversión requerida y rápido retorno de la misma, obteniendo un juicio objetivo sobre una determinada propuesta sin tener que realizar una elevada inversión económica o arriesgar determinados proyectos que pueden ser clave para las organizaciones.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2595</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-aplicacion-practica-del-metodo-delphi-para-la-validacion-de-una-propuesta-de-ingenieria-web]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="delphi"><![CDATA[Delphi]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software"><![CDATA[Ingeniería del Software]]></category>
		<category domain="post_tag" nicename="ingenieria-web"><![CDATA[Ingeniería Web]]></category>
		<category domain="post_tag" nicename="juicio-de-expertos"><![CDATA[juicio de expertos]]></category>
		<category domain="post_tag" nicename="metodologias-agiles"><![CDATA[Metodologías Ágiles]]></category>
		<category domain="post_tag" nicename="scrum"><![CDATA[Scrum]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las organizaciones que trabajan en el desarrollo de Sistemas de Información son reacias muchas veces a implantar nuevas metodologías de trabajo sin disponer previamente de ciertas garantías de éxito. Esta reacción es comprensible, ya que el éxito o el fracaso de ciertos proyectos puede suponer graves pérdidas económicas o reputacionales para las misma. En este trabajo vamos a presentar una aplicación práctica del uso de una técnica de juicio de expertos, el método Delphi, para la validación de una propuesta metodológica en el ámbito de la Ingeniería Web. El uso de las técnicas basadas en juicios de expertos puede suponer un buen compromiso en términos de inversión requerida y rápido retorno de la misma, obteniendo un juicio objetivo sobre una determinada propuesta sin tener que realizar una elevada inversión económica o arriesgar determinados proyectos que pueden ser clave para las organizaciones. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/052]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_59.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_59.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Torrecilla-Salinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carlos.torrecilla@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Olga De Troyer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[Olga.DeTroyer@vub.ac.be]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science. Vrije Universiteit Brussel (VUB). Belgium]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[M.J. Escalona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mjescalona@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel Mejías]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[risoto@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo IWT2, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evaluación de un Método de Monitorización de Calidad de Servicios Cloud: Una Replicación Interna</title>
		<link>https://biblioteca.sistedes.es/articulo/evaluacion-de-un-metodo-de-monitorizacion-de-calidad-de-servicios-cloud-una-replicacion-interna/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/evaluacion-de-un-metodo-de-monitorizacion-de-calidad-de-servicios-cloud-una-replicacion-interna/</guid>
		<description></description>
		<content><![CDATA[Contexto: El modelo de negocio que ofrece la computación en la nube tiene un gran número de ventajas tanto para proveedores como para consumidores. Sin embargo, es imprescindible controlar la calidad de los servicios provistos, lo que se puede alcanzar a través de soluciones de monitorización. Sin embargo, se ha prestado poca atención a las percepciones de los usuarios que las utilizan. En un trabajo previo, hemos realizado un cuasi-experimento para evaluar las percepciones de un grupo de estudiantes en el uso un método de monitorización (Cloud MoS@RT) de calidad de servicios cloud en tiempo de ejecución. Objetivo: Proporcionar mayor evidencia sobre la facilidad de uso percibida, utilidad percibida e intención de uso de un grupo de profesionales utilizando el método Cloud MoS@RT. Método: Hemos ejecutado una replicación interna del cuasi-experimento base con un grupo de profesionales. La tarea experimental consistió en utilizar Cloud MoS@RT para configurar la monitorización de la calidad de un servicio en la plataforma Microsoft Azure. Los participantes también rellenaron un cuestionario que nos ha permitido evaluar su percepción sobre la utilidad del método. Resultados: Los resultados indican que los participantes han percibido el método como fácil de usar y útil, y han manifestado su intención de uso futuro. Conclusiones: Los resultados están alineados con el cuasi-experimento base y confirman que Cloud MoS@RT puede ser utilizado de manera efectiva tanto por estudiantes como profesionales sin la necesidad de un extensivo entrena-miento y conocimiento de la plataforma cloud.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2596</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evaluacion-de-un-metodo-de-monitorizacion-de-calidad-de-servicios-cloud-una-replicacion-interna]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="calidad-de-servicios"><![CDATA[Calidad de Servicios]]></category>
		<category domain="post_tag" nicename="cloud-computing"><![CDATA[Cloud Computing]]></category>
		<category domain="post_tag" nicename="cuasi-experimento"><![CDATA[Cuasi-Experimento]]></category>
		<category domain="post_tag" nicename="monitorizacion"><![CDATA[Monitorización]]></category>
		<category domain="post_tag" nicename="replicacion"><![CDATA[Replicación]]></category>
		<category domain="post_tag" nicename="software-as-a-service"><![CDATA[Software as a Service]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Contexto: El modelo de negocio que ofrece la computación en la nube tiene un gran número de ventajas tanto para proveedores como para consumidores. Sin embargo, es imprescindible controlar la calidad de los servicios provistos, lo que se puede alcanzar a través de soluciones de monitorización. Sin embargo, se ha prestado poca atención a las percepciones de los usuarios que las utilizan. En un trabajo previo, hemos realizado un cuasi-experimento para evaluar las percepciones de un grupo de estudiantes en el uso un método de monitorización (Cloud MoS@RT) de calidad de servicios cloud en tiempo de ejecución. Objetivo: Proporcionar mayor evidencia sobre la facilidad de uso percibida, utilidad percibida e intención de uso de un grupo de profesionales utilizando el método Cloud MoS@RT.  Método: Hemos ejecutado una replicación interna del cuasi-experimento base con un grupo de profesionales. La tarea experimental consistió en utilizar Cloud MoS@RT para configurar la monitorización de la calidad de un servicio en la plataforma Microsoft Azure. Los participantes también rellenaron un cuestionario que nos ha permitido evaluar su percepción sobre la utilidad del método. Resultados: Los resultados indican que los participantes han percibido el método como fácil de usar y útil, y han manifestado su intención de uso futuro. Conclusiones: Los resultados están alineados con el cuasi-experimento base y confirman que Cloud MoS@RT puede ser utilizado de manera efectiva tanto por estudiantes como profesionales sin la necesidad de un extensivo entrena-miento y conocimiento de la plataforma cloud.  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/050]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_60.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_60.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Priscila Cedillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[icedillo@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Emilio Insfran]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[einsfran@disc.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Silvia Abrahao]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sabrahao@disc.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un Editor Textual para el Modelado y la Generación de Código de Patrones de Eventos</title>
		<link>https://biblioteca.sistedes.es/articulo/un-editor-textual-para-el-modelado-y-la-generacion-de-codigo-de-patrones-de-eventos/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/un-editor-textual-para-el-modelado-y-la-generacion-de-codigo-de-patrones-de-eventos/</guid>
		<description></description>
		<content><![CDATA[El procesamiento de eventos complejos (CEP) es una tecnología que permite analizar y correlacionar grandes cantidades de datos con el propósito de detectar situaciones de interés en tiempo real. Para ello se requiere implementar patrones de eventos, especificando las condiciones que deben cumplirse para detectar dichas situaciones, con los lenguajes de procesamiento de eventos (EPL). A pesar de que los usuarios suelen tener un vasto conocimiento en el dominio para el que se necesitan definir ciertos patrones de eventos, suelen ser inexpertos tanto en EPL como en el lenguaje requerido para implementar las acciones a llevar a cabo tras la detección de los patrones. En este artículo presentamos un editor textual para el modelado y la generación de código de los patrones de eventos que se necesiten detectar en un dominio de aplicación. Gracias a este editor, el usuario solo tendrá que conocer un lenguaje textual para definir patrones de eventos, que podrán ser posteriormente transformados automáticamente al EPL soportado por el motor CEP en cuestión. Este editor complementa a MEdit4CEP, un editor que permite la definición gráfica e intuitiva de patrones sin necesidad de conocer ningún lenguaje de programación en particular.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2597</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-editor-textual-para-el-modelado-y-la-generacion-de-codigo-de-patrones-de-eventos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cep"><![CDATA[CEP]]></category>
		<category domain="post_tag" nicename="editor-de-modelado-textual"><![CDATA[Editor de Modelado Textual]]></category>
		<category domain="post_tag" nicename="epl"><![CDATA[EPL]]></category>
		<category domain="post_tag" nicename="mdd"><![CDATA[MDD]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El procesamiento de eventos complejos (CEP) es una tecnología que permite analizar y correlacionar grandes cantidades de datos con el propósito de detectar situaciones de interés en tiempo real. Para ello se requiere implementar patrones de eventos, especificando las condiciones que deben cumplirse para detectar dichas situaciones, con los lenguajes de procesamiento de eventos (EPL). A pesar de que los usuarios suelen tener un vasto conocimiento en el dominio para el que se necesitan definir ciertos patrones de eventos, suelen ser inexpertos tanto en EPL como en el lenguaje requerido para implementar las acciones a llevar a cabo tras la detección de los patrones. En este artículo presentamos un editor textual para el modelado y la generación de código de los patrones de eventos que se necesiten detectar en un dominio de aplicación. Gracias a este editor, el usuario solo tendrá que conocer un lenguaje textual para definir patrones de eventos, que podrán ser posteriormente transformados automáticamente al EPL soportado por el motor CEP en cuestión. Este editor complementa a MEdit4CEP, un editor que permite la definición gráfica e intuitiva de patrones sin necesidad de conocer ningún lenguaje de programación en particular.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/031]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_61.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_61.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ramón Ramírez-González]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[rrgonzalez1992@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Escuela Superior de Ingeniería. Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Design Patterns for Software Evolution Requirements</title>
		<link>https://biblioteca.sistedes.es/articulo/design-patterns-for-software-evolution-requirements/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/design-patterns-for-software-evolution-requirements/</guid>
		<description></description>
		<content><![CDATA[The software Engineering term known as Software Evolution can be understood in two senses. First, as the changes that software experiences over its develop-ment cycle, second, as changes that software goes through in its lifetime. In both cases, software architectures should lead, support and ease any software modifications, reconfiguration or adaptation to a changing environment. At moment, it is widely acknowledged that design and architectural patterns must be used for carrying out any software development focused on quality. We present here the analysis of several design and architectural patterns for sustaining software systems evolution according to two complementary perspectives, one connected with maintainability and the other with dynamicity of any software design.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2598</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[design-patterns-for-software-evolution-requirements]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="architectural-patterns"><![CDATA[Architectural Patterns]]></category>
		<category domain="post_tag" nicename="design-patterns"><![CDATA[Design Patterns]]></category>
		<category domain="post_tag" nicename="software-architecture"><![CDATA[Software Architecture]]></category>
		<category domain="post_tag" nicename="software-quality-factors"><![CDATA[Software Quality Factors]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The software Engineering term known as Software Evolution can be understood in two senses. First, as the changes that software experiences over its develop-ment cycle, second, as changes that software goes through in its lifetime. In both cases, software architectures should lead, support and ease any software modifications, reconfiguration or adaptation to a changing environment. At moment, it is widely acknowledged that design and architectural patterns must be used for carrying out any software development focused on quality. We present here the analysis of several design and architectural patterns for sustaining software systems evolution according to two complementary perspectives, one connected with maintainability and the other with dynamicity of any software design.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/069]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_63.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_63.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel I. Capel Tuñón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[manuelcapel@ugr.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Anna C. Gramán Padua]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[acgriman@usb.ve]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Simón Bolí­var]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Eladio Garví García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[egarvi@ugr.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>HADAS: Asistente de eco-eficiencia con repositorio de consumo energético</title>
		<link>https://biblioteca.sistedes.es/articulo/hadas-asistente-de-eco-eficiencia-con-repositorio-de-consumo-energetico/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/hadas-asistente-de-eco-eficiencia-con-repositorio-de-consumo-energetico/</guid>
		<description></description>
		<content><![CDATA[El interés por la Ingeniería del Software verde, o sea, sensible al consumo de energía, es relativamente reciente. Su objetivo es concienciar a los desarrolladores de software de la influencia que tienen sus decisiones de diseño e implementación en el gasto energético del producto final. Hasta el momento se han publicado muchos resultados experimentales que comparan el consumo de energía de varias soluciones alternativas, y que demuestran que se puede reducir dicho consumo hasta en un 70 %. Aunque estos resultados sean de libre disposición, no es sencillo que un desarrollador aplique este conocimiento a sus aplicaciones. En consecuencia, en este artículo presentamos el eco-asistente HADAS cuya utilidad es: (i) los investigadores almacenarán sus resultados en un repositorio de libre disposición, (ii) los desarrolladores podrán razonar y obtener las configuraciones que menos energía consuman y que satisfaga sus requisitos. Nos centraremos en mostrar los elementos principales de nuestra propuesta y cómo se aplica a casos de estudio reales.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2599</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hadas-asistente-de-eco-eficiencia-con-repositorio-de-consumo-energetico]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cvl"><![CDATA[CVL]]></category>
		<category domain="post_tag" nicename="energia"><![CDATA[Energía]]></category>
		<category domain="post_tag" nicename="java"><![CDATA[Java]]></category>
		<category domain="post_tag" nicename="linea-de-productos-software"><![CDATA[Línea de Productos Software]]></category>
		<category domain="post_tag" nicename="servidor"><![CDATA[Servidor]]></category>
		<category domain="post_tag" nicename="variabilidad"><![CDATA[Variabilidad]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El interés por la Ingeniería del Software verde, o sea, sensible al consumo de energía, es relativamente reciente. Su objetivo es concienciar a los desarrolladores de software de la influencia que tienen sus decisiones de diseño e implementación en el gasto energético del producto final. Hasta el momento se han publicado muchos resultados experimentales que comparan el consumo de energía de varias soluciones alternativas, y que demuestran que se puede reducir dicho consumo hasta en un 70 %. Aunque estos resultados sean de libre disposición, no es sencillo que un desarrollador aplique este conocimiento a sus aplicaciones. En consecuencia, en este artículo presentamos el eco-asistente HADAS cuya utilidad es: (i) los investigadores almacenarán sus resultados en un repositorio de libre disposición, (ii) los desarrolladores podrán razonar y obtener las configuraciones que menos energía consuman y que satisfaga sus requisitos. Nos centraremos en mostrar los elementos principales de nuestra propuesta y cómo se aplica a casos de estudio reales.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/005]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_64.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_64.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Daniel Jesus Munoz Guerra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[danimg@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Malaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Monica Pinto Alarcon]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pinto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Malaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Malaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Impacto de las notaciones en la productividad de creación de modelos de dominio: Un estudio empírico</title>
		<link>https://biblioteca.sistedes.es/articulo/impacto-de-las-notaciones-en-la-productividad-de-creacion-de-modelos-de-dominio-un-estudio-empirico/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/impacto-de-las-notaciones-en-la-productividad-de-creacion-de-modelos-de-dominio-un-estudio-empirico/</guid>
		<description></description>
		<content><![CDATA[El uso intensivo de modelos en el paradigma MDE es una de las piedras angulares para la consecución de mejoras de productividad en el desarrollo software. Sin embargo, con el fin de maximizar dicha mejora, es importante realizar una selección adecuada de las notaciones. Desafortunadamente, la comunidad de MDE todavía adolece de una falta de datos empíricos que soporten dicha selección. El objetivo del estudio empírico presentado en este artículo ha sido comparar dos notaciones, una gráfica y otra textual, con respecto a la eficiencia y eficacia mostrada por desarrolladores software noveles a la hora de desarrollar modelos de dominio de dos aplicaciones distintas. Para ello, se ha diseñado un quasi-experimento con 127 alumnos del grado de Ingeniería Informática de la Universidad de Alicante. Los sujetos se clasificaron de manera aleatoria en cuatro grupos, y a cada grupo se le asignó una combinación de Notación y Sistema. Los datos recogidos muestran que, mientras que el sistema desarrollado no influye de manera significativa en las medidas analizadas, la notación sí lo hace de manera significativa en todas ellas, siendo la notación gráfica la que mejores resultados arroja tanto en cuanto a eficiencia como eficacia. Con el fin de generalizar estos resultados, se hace necesario realizar nuevas réplicas con distintos perfiles de sujetos, distintas notaciones y distintos tipos de aplicación.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2600</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[impacto-de-las-notaciones-en-la-productividad-de-creacion-de-modelos-de-dominio-un-estudio-empirico]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="domain-model"><![CDATA[Domain Model]]></category>
		<category domain="post_tag" nicename="empirical-software-engineering"><![CDATA[Empírical Software Engineering]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="notation"><![CDATA[Notation]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El uso intensivo de modelos en el paradigma MDE es una de las piedras angulares para la consecución de mejoras de productividad en el desarrollo software. Sin embargo, con el fin de maximizar dicha mejora, es importante realizar una selección adecuada de las notaciones. Desafortunadamente, la comunidad de MDE todavía adolece de una falta de datos empíricos que soporten dicha selección. El objetivo del estudio empírico presentado en este artículo ha sido comparar dos notaciones, una gráfica y otra textual, con respecto a la eficiencia y eficacia mostrada por desarrolladores software noveles a la hora de desarrollar modelos de dominio de dos aplicaciones distintas. Para ello, se ha diseñado un quasi-experimento con 127 alumnos del grado de Ingeniería Informática de la Universidad de Alicante. Los sujetos se clasificaron de manera aleatoria en cuatro grupos, y a cada grupo se le asignó una combinación de Notación y Sistema. Los datos recogidos muestran que, mientras que el sistema desarrollado no influye de manera significativa en las medidas analizadas, la notación sí lo hace de manera significativa en todas ellas, siendo la notación gráfica la que mejores resultados arroja tanto en cuanto a eficiencia como eficacia. Con el fin de generalizar estos resultados, se hace necesario realizar nuevas réplicas con distintos perfiles de sujetos, distintas notaciones y distintos tipos de aplicación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/028]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_65.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_65.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cristina Cachero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ccachero@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Santiago Meliá]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[santi@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesús María Hermida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jesus.hermida@jrc.ec.europa.eu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[European Comission Joint Research Centre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Identificadores Persistentes para Objetos Espaciales</title>
		<link>https://biblioteca.sistedes.es/articulo/identificadores-persistentes-para-objetos-espaciales/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/identificadores-persistentes-para-objetos-espaciales/</guid>
		<description></description>
		<content><![CDATA[Resumen. Un gran volumen de la información almacenada en los sistemas de información está georreferenciada mediante direcciones, códigos y conjuntos de coordenadas. Un mecanismo para garantizar un uso consistente es asignar identificadores persistentes y resolubles a la información espacial. Dada la explosión en el volumen de la información espacial es necesario que exista una arquitectura que provea y resuelva dichos identificadores persistentes de la forma más automática posible. Este artículo propone una arquitectura para la recolección, registro, resolución, catalogación y difusión de identificadores persistentes de datos espaciales. También propone un algoritmo para facilitar la recolección de identificadores persistentes mediante la automatización de la extracción de datos espaciales publicados en servicios geoespaciales estándar con recursos limitados. Esta arquitectura ha sido llevada a la práctica para dar soporte a la implementación de la Directiva Europea INSPIRE.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2601</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[identificadores-persistentes-para-objetos-espaciales]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="informacion-geografica"><![CDATA[Información Geográfica]]></category>
		<category domain="post_tag" nicename="inspire"><![CDATA[INSPIRE]]></category>
		<category domain="post_tag" nicename="pid"><![CDATA[PID]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen. Un gran volumen de la información almacenada en los sistemas de información está georreferenciada mediante direcciones, códigos y conjuntos de coordenadas. Un mecanismo para garantizar un uso consistente es asignar identificadores persistentes y resolubles a la información espacial. Dada la explosión en el volumen de la información espacial es necesario que exista una arquitectura que provea y resuelva dichos identificadores persistentes de la forma más automática posible. Este artículo propone una arquitectura para la recolección, registro, resolución, catalogación y difusión de identificadores persistentes de datos espaciales. También propone un algoritmo para facilitar la recolección de identificadores persistentes mediante la automatización de la extracción de datos espaciales publicados en servicios geoespaciales estándar con recursos limitados. Esta arquitectura ha sido llevada a la práctica para dar soporte a la implementación de la Directiva Europea INSPIRE.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/017]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_67.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_67.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco J. Lopez-Pellicer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fjlopez@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Rubén Béjar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[rbejar@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Miguel Á. Latre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[latre@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Javier Nogueras-Iso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jnog@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[F.Javier Zarazaga-Soria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[javy@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Descubrimiento de patrones de diseño basado en buenas prácticas: modelo y discusión</title>
		<link>https://biblioteca.sistedes.es/articulo/descubrimiento-de-patrones-de-diseno-basado-en-buenas-practicas-modelo-y-discusion/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/descubrimiento-de-patrones-de-diseno-basado-en-buenas-practicas-modelo-y-discusion/</guid>
		<description></description>
		<content><![CDATA[La complejidad de los sistemas actuales obliga a los ingenieros software a aprender de las buenas prácticas empleadas en proyectos previos como, por ejemplo, el uso de patrones de diseño. Dichos patrones tienen una gran importancia durante la fase de diseño y su posterior implementación genera varias ventajas. En este contexto, se propone el uso de técnicas de minería de datos que ayuden a comprender como otros ingenieros software han implementado dichos patrones. Con la representación adecuada, este conocimiento se podrá utilizar para identificar fragmentos de código susceptibles de ser convertidos en un determinado patrón. Además del modelo, se discuten ventajas y retos asociados.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2602</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[descubrimiento-de-patrones-de-diseno-basado-en-buenas-practicas-modelo-y-discusion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="buenas-practicas"><![CDATA[buenas prácticas]]></category>
		<category domain="post_tag" nicename="mineria-de-repositorios-software"><![CDATA[Minería de repositorios software]]></category>
		<category domain="post_tag" nicename="patrones-de-diseno"><![CDATA[patrones de diseño]]></category>
		<category domain="post_tag" nicename="programacion-genetica-gramatical"><![CDATA[programación genética gramatical]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La complejidad de los sistemas actuales obliga a los ingenieros software a aprender de las buenas prácticas empleadas en proyectos previos como, por ejemplo, el uso de patrones de diseño. Dichos patrones tienen una gran importancia durante la fase de diseño y su posterior implementación genera varias ventajas. En este contexto, se propone el uso de técnicas de minería de datos que ayuden a comprender como otros ingenieros software han implementado dichos patrones. Con la representación adecuada, este conocimiento se podrá utilizar para identificar fragmentos de código susceptibles de ser convertidos en un determinado patrón. Además del modelo, se discuten ventajas y retos asociados.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/035]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_68.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_68.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rafael Barbudo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rbarbudo@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Aurora Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[aramirez@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José Raúl Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Sebastián Ventura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sventura@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Búsqueda coevolutiva interactiva aplicada al diseño de software</title>
		<link>https://biblioteca.sistedes.es/articulo/busqueda-coevolutiva-interactiva-aplicada-al-diseno-de-software/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/busqueda-coevolutiva-interactiva-aplicada-al-diseno-de-software/</guid>
		<description></description>
		<content><![CDATA[La resolución de tareas de diseño software mediante técnicas de búsqueda plantea dificultades como la exploración efectiva de un gran conjunto de alternativas, cuya calidad no puede ser evaluada sólo en base a medidas software. Con el fin de solventarlas, es necesario considerar técnicas más avanzadas que se aproximen más a cómo los ingenieros diseñan en la realidad. Los modelos coevolutivos permiten descomponer el problema original en varias partes diferenciadas que se resuelven simultáneamente, mientras que la optimización interactiva permite incorporar el conocimiento del ingeniero. Este trabajo propone un modelo que combina ambas técnicas y plantea los retos que conlleva su desarrollo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2603</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[busqueda-coevolutiva-interactiva-aplicada-al-diseno-de-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="algoritmos-coevolutivos"><![CDATA[algoritmos coevolutivos]]></category>
		<category domain="post_tag" nicename="diseno-software"><![CDATA[diseño software]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software-basada-en-busqueda"><![CDATA[ingeniería del software basada en búsqueda]]></category>
		<category domain="post_tag" nicename="optimizacion-interactiva"><![CDATA[optimización interactiva]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La resolución de tareas de diseño software mediante técnicas de búsqueda plantea dificultades como la exploración efectiva de un gran conjunto de alternativas, cuya calidad no puede ser evaluada sólo en base a medidas software. Con el fin de solventarlas, es necesario considerar técnicas más avanzadas que se aproximen más a cómo los ingenieros diseñan en la realidad. Los modelos coevolutivos permiten descomponer el problema original en varias partes diferenciadas que se resuelven simultáneamente, mientras que la optimización interactiva permite incorporar el conocimiento del ingeniero. Este trabajo propone un modelo que combina ambas técnicas y plantea los retos que conlleva su desarrollo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/034]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_69.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_69.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aurora Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aramirez@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Raúl Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sebastián Ventura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sventura@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Visualización de Esquemas en Bases de Datos NoSQL basadas en documentos</title>
		<link>https://biblioteca.sistedes.es/articulo/visualizacion-de-esquemas-en-bases-de-datos-nosql-basadas-en-documentos/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/visualizacion-de-esquemas-en-bases-de-datos-nosql-basadas-en-documentos/</guid>
		<description></description>
		<content><![CDATA[La ausencia de esquema (schemaless) es una de las características más atractivas de las bases de datos NoSQL debido a la flexibilidad que ofrece. Por ejemplo, datos no uniformes pueden ser almacenados y se facilita la evolución. Sin embargo, los desarrolladores siempre tienen en mente un esquema cuando escriben código para bases de datos NoSQL y muchas utilidades de bases de datos también requieren el conocimiento del esquema para implementar su funcionalidad. Por esta razón, recientemente se han propuesto diferentes enfoques para inferir el esquema ímplicito en los datos NoSQL almacenados. En este trabajo se presenta una herramienta para la visualización de esquemas NoSQL representados como modelos que son obtenidos por medio de un proceso de ingeniería inversa definido por los autores en un trabajo previo. Estos modelos conforman a un metamodelo Ecore que representa esquemas versionados NoSQL. La herramienta es capaz de mostrar diferentes vistas o diagramas de los esquemas que han sido ideados para favorecer la comprensión de algún aspecto del esquema, por ejemplo mostrar un esquema global con todas las versiones de entidades y las relaciones entre ellas. Se trata de una de las primeras soluciones de visualización de esquemas NoSQL.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2604</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[visualizacion-de-esquemas-en-bases-de-datos-nosql-basadas-en-documentos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="nosql-databases"><![CDATA[NoSQL Databases]]></category>
		<category domain="post_tag" nicename="nosql-schema"><![CDATA[NoSQL schema]]></category>
		<category domain="post_tag" nicename="schema-visualization"><![CDATA[Schema Visualization]]></category>
		<category domain="post_tag" nicename="sirius"><![CDATA[Sirius]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La ausencia de esquema (schemaless) es una de las características  más atractivas de las bases de datos NoSQL debido a la flexibilidad que ofrece. Por ejemplo, datos no uniformes pueden ser almacenados y se facilita la evolución. Sin embargo, los desarrolladores siempre tienen en mente un esquema cuando escriben código para bases de datos NoSQL y muchas utilidades de bases de datos también requieren el conocimiento del esquema para implementar su funcionalidad. Por esta razón,  recientemente se han propuesto diferentes enfoques para inferir el esquema ímplicito en los datos NoSQL almacenados. En este trabajo se presenta una herramienta para la visualización de esquemas NoSQL representados como modelos que son obtenidos por medio de un proceso de ingeniería inversa definido por los autores en un trabajo previo. Estos modelos conforman a un metamodelo Ecore que representa esquemas versionados NoSQL. La herramienta es capaz de mostrar diferentes vistas o diagramas de los esquemas que han sido ideados para favorecer la comprensión de algún aspecto del esquema, por ejemplo mostrar un esquema global con todas las versiones de entidades y las relaciones entre ellas. Se trata de una de las primeras soluciones de visualización de esquemas NoSQL.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/025]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_71.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_71.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alberto Hernández Chillón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alberto.hernandez1@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Cátedra SAES - Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Severino Feliciano Morales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[severino.feliciano@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesus Garcia-Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jmolina@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Diego Sevilla Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[dsevilla@ditec.um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una experiencia en la implementación del método AFP</title>
		<link>https://biblioteca.sistedes.es/articulo/una-experiencia-en-la-implementacion-del-metodo-afp/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/una-experiencia-en-la-implementacion-del-metodo-afp/</guid>
		<description></description>
		<content><![CDATA[OMG lanzó en 2014 la propuesta Automated Function Point (AFP) para automatizar el conteo de puntos de función de una aplicación legacy en procesos de modernización a partir de modelos KDM. En el contexto de una colaboración entre el grupo Modelum (Universidad de Murcia) y la empresa Open Canarias se ha desarrollado una implementación de AFP que se está evaluando para código Oracle Forms. En este trabajo se describe la experiencia de implementación: motivación, arquitectura y desafíos para completarla.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2605</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-experiencia-en-la-implementacion-del-metodo-afp]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="automated-function-points"><![CDATA[Automated Function Points]]></category>
		<category domain="post_tag" nicename="kdm"><![CDATA[KDM]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="oracle-forms"><![CDATA[Oracle Forms]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[OMG lanzó en 2014 la propuesta Automated Function Point (AFP) para automatizar el conteo de puntos de función de una aplicación legacy en procesos de modernización a partir de modelos KDM. En el contexto de una colaboración entre el grupo Modelum (Universidad de Murcia) y la empresa Open Canarias se ha desarrollado una implementación de AFP que se está evaluando para código Oracle Forms. En este trabajo se describe la experiencia de implementación: motivación, arquitectura y desafíos para completarla.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/033]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_72.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_72.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos J. Fernández Candel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carlosjavier.fernandez1@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose Ramon Hoyos Barceló]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jose.hoyos@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesus Garcia-Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jmolina@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Francisco Javier Bermúdez Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[fjavier@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Benito J. Cuesta Viera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[bcuesta@opencanarias.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Open Canarias S.L.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Predicción de módulos defectuosos como un problema de optimización multiobjetivo</title>
		<link>https://biblioteca.sistedes.es/articulo/prediccion-de-modulos-defectuosos-como-un-problema-de-optimizacion-multiobjetivo/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/prediccion-de-modulos-defectuosos-como-un-problema-de-optimizacion-multiobjetivo/</guid>
		<description></description>
		<content><![CDATA[<div class="page" title="Page 1">
<div class="layoutArea">
<div class="column">

La dificultad de aplicar técnicas de análisis de datos al problema de la calidad del software radica principalmente en dos razones: la ausencia de datos generalistas y de herramientas específicas. En este trabajo exponemos los primeros pasos de una iniciativa para paliar estos inconvenientes. Con respecto al primero, hemos trabajado con dos conjuntos de datos públicos que han sido tratados de forma conjunta para poder lograr modelos más generales. Para el segundo propósito se ha aplicado un algoritmo multiobjetivo que mediante reglas cuantitativas establezca cuáles son los íımites empíricos de los atributos que miden la complejidad a partir de los cuales la probabilidad de error aumenta significativamente e incluso la posibilidad de medir ese aumento.

</div>
</div>
</div>]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2606</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[prediccion-de-modulos-defectuosos-como-un-problema-de-optimizacion-multiobjetivo]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="multiobjetivo"><![CDATA[Multiobjetivo]]></category>
		<category domain="post_tag" nicename="prediccion-defectos-software"><![CDATA[Predicción defectos software]]></category>
		<category domain="post_tag" nicename="reglas"><![CDATA[Reglas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La dificultad de aplicar técnicas de análisis de datos al problema de la calidad del software radica principalmente en dos razones: la ausencia de datos generalistas y de herramientas específicas. En este trabajo exponemos los primeros pasos de una iniciativa para paliar estos inconvenientes. Con respecto al primero, hemos trabajado con dos conjuntos de datos públicos que han sido tratados de forma conjunta para poder lograr modelos más generales. Para el segundo propósito se ha aplicado un algoritmo multiobjetivo que mediante reglas cuantitativas establezca cuáles son los íımites empíricos de los atributos que miden la complejidad a partir de los cuales la probabilidad de error aumenta significativamente e incluso la posibilidad de medir ese aumento.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/042]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_74.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_74.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Martínez Ballesteros]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mariamartinez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José C. Riquelme Santos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[riquelme@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Roberto Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[robertoruiz@upo.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Pablo de Olavide]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Daniel Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[daniel.rodriguez@uah.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Alcalá]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia un Algoritmo Exacto para Resolver el Problema de Agrupamiento de Módulos Software</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-un-algoritmo-exacto-para-resolver-el-problema-de-agrupamiento-de-modulos-software/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/hacia-un-algoritmo-exacto-para-resolver-el-problema-de-agrupamiento-de-modulos-software/</guid>
		<description></description>
		<content><![CDATA[El problema de agrupamiento de módulos software consiste en encontrar una partición del conjunto de módulos de un determinado software de tal forma que se maximice la cohesión entre módulos pertenecientes al mismo componente de la partición a la vez que se minimiza el acoplamiento entre módulos pertenecientes a distintos componentes. El objetivo es estructurar el software de una manera que mejore el desarrollo y la mantenibilidad del sistema. Este problema, conocido como emph{Software Module Clustering}, ha sido abordado en el pasado usando principalmente algoritmos heurísticos y metaheurísticas. En este trabajo describimos un algoritmo exacto basado en ramificación y poda.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2607</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-un-algoritmo-exacto-para-resolver-el-problema-de-agrupamiento-de-modulos-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="agrupamiento-de-modulos-software"><![CDATA[Agrupamiento de módulos software]]></category>
		<category domain="post_tag" nicename="algoritmos-exactos"><![CDATA[Algoritmos exactos]]></category>
		<category domain="post_tag" nicename="ramificacion-y-poda"><![CDATA[Ramificación y poda]]></category>
		<category domain="post_tag" nicename="search-based-software-engineering"><![CDATA[Search-Based Software Engineering]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El problema de agrupamiento de módulos software consiste en encontrar una partición del conjunto de módulos de un determinado software de tal forma que se maximice la cohesión entre módulos pertenecientes al mismo componente de la partición a la vez que se minimiza el acoplamiento entre módulos pertenecientes a distintos componentes. El objetivo es estructurar el software de una manera que mejore el desarrollo y la mantenibilidad del sistema. Este problema, conocido como emph{Software Module Clustering}, ha sido abordado en el pasado usando principalmente algoritmos heurísticos y metaheurísticas. En este trabajo describimos un algoritmo exacto basado en ramificación y poda.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/037]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_75.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_75.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel Ángel Domínguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[miguel.angel.dominguez.rios@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francisco Chicano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[chicano@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Enrique Alba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[eat@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Desarrollando una arquitectura de microservicios mediante MDE</title>
		<link>https://biblioteca.sistedes.es/articulo/desarrollando-una-arquitectura-de-microservicios-mediante-mde/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/desarrollando-una-arquitectura-de-microservicios-mediante-mde/</guid>
		<description></description>
		<content><![CDATA[En los últimos años, la industria del software ha apostado por la migración hacia las aplicaciones basadas en servicios y su despliegue en la nube por su promesa de obtener alta disponibilidad y escalabilidad. Tanto las aplicaciones Web como las móviles utilizan partes servidoras basadas en fachadas REST o SOA que en muchas ocasiones crecen tanto a nivel de servicios como de datos lo que complica su mantenibilidad. En este sentido, ha aparecido recientemente un estilo arquitectónico denominado microservicios que propone la división horizontal de la funcionalidad de una aplicación en una colección de servicios que gestionan separadamente su propia lógica y sus datos. Esta división permite explotar la escalabilidad de la nube a nivel de servicio y abordar los cambios más rápidamente. A pesar de sus beneficios, este estilo arquitectónico presenta algunas desventajas como la dificultad de agregar datos de diferentes microservicios y el mantenimiento de la consistencia entre las diferentes orígenes de datos. Para abordar estos dos retos, este trabajo presenta una solución MDE basada en una evolución del modelo de servicios de OOH4RIA. Este modelo permite tanto acelerar la creación de microservicios como facilitar el mantenimiento en la comunicación y la composición de datos de diferentes orígenes.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2608</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[desarrollando-una-arquitectura-de-microservicios-mediante-mde]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="microservices"><![CDATA[microservices]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<category domain="post_tag" nicename="rest"><![CDATA[REST]]></category>
		<category domain="post_tag" nicename="soa"><![CDATA[SOA]]></category>
		<category domain="post_tag" nicename="web-services"><![CDATA[web services]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años, la industria del software ha apostado por la migración hacia las aplicaciones basadas en servicios y su despliegue en la nube por su promesa de obtener alta disponibilidad y escalabilidad. Tanto las aplicaciones Web como las móviles utilizan partes servidoras basadas en fachadas REST o SOA que en muchas ocasiones crecen tanto a nivel de servicios como de datos lo que complica su mantenibilidad. En este sentido, ha aparecido recientemente un estilo arquitectónico denominado microservicios que propone la división horizontal de la funcionalidad de una aplicación en una colección de servicios que gestionan separadamente su propia lógica y sus datos. Esta división permite explotar la escalabilidad de la nube a nivel de servicio y abordar los cambios más rápidamente. A pesar de sus beneficios, este estilo arquitectónico presenta algunas desventajas como la dificultad de agregar datos de diferentes microservicios y el mantenimiento de la consistencia entre las diferentes orígenes de datos. Para abordar estos dos retos, este trabajo presenta una solución MDE basada en una evolución del modelo de servicios de OOH4RIA. Este modelo permite tanto acelerar la creación de microservicios como facilitar el mantenimiento en la comunicación y la composición de datos de diferentes orígenes.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/061]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_76.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_76.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Santiago Meliá]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[santi@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jesús M. Hermida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jesus.hermida@ec.europa.eu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[European Commission Joint Research Centre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Cristina Cachero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ccachero@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jaume Aragonés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jaume@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SmartPoliTech: un experimento en inmótica social</title>
		<link>https://biblioteca.sistedes.es/articulo/smartpolitech-un-experimento-en-inmotica-social/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/smartpolitech-un-experimento-en-inmotica-social/</guid>
		<description></description>
		<content><![CDATA[La optimización energética en edificios públicos terciarios en España es un reto insoslayable. La realidad actual de despilfarro energético, falta de confort, infrautilización de los espacios o deficiente disposición de los mismos respecto a los usos sobre los que fueron proyectados, es un hecho que repercute directamente en la eficiencia de las actividades realizadas en ellos, así como en las emisiones de $CO_{2}$ que se generan actualmente y que suponen una seria amenaza para la sostenibilidad de estos edificios. La inmótica, como disciplina que apunta a la automatización de los procesos y actividades que se generan en el edificio, surge como elemento capaz de proporcionar soluciones a este grave problema de optimización energética. En este artículo se describen las generalidades del proyecto SmartPolitech, una iniciativa experimental de bajo coste que utiliza la inmótica como medio para abordar una problemática generalizada de ineficiencia energética en la inmensa mayoría de edificios públicos españoles.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2609</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[smartpolitech-un-experimento-en-inmotica-social]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="inmotica"><![CDATA[Inmótica]]></category>
		<category domain="post_tag" nicename="internet-de-las-cosas"><![CDATA[Internet de las Cosas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La optimización energética en edificios públicos terciarios en España es un reto insoslayable. La realidad actual de despilfarro energético, falta de confort, infrautilización de los espacios o deficiente disposición de los mismos respecto a los usos sobre los que fueron proyectados, es un hecho que repercute directamente en la eficiencia de las actividades realizadas en ellos, así como en las emisiones de $CO_{2}$ que se generan actualmente y que suponen una seria amenaza para la sostenibilidad de estos edificios. La inmótica, como disciplina que apunta a la automatización de los procesos y actividades que se generan en el edificio, surge como elemento capaz de proporcionar soluciones a este grave problema de optimización energética. En este artículo se describen las generalidades del proyecto SmartPolitech, una iniciativa experimental de bajo coste que utiliza la inmótica como medio para abordar una problemática generalizada de ineficiencia energética en la inmensa mayoría de edificios públicos españoles.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/021]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_79.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_79.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Agustín Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[agustin.robolab@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Barrena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[barrena@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pablo García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pablogr@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Beatriz Montalbán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[bmpozas@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Pablo Bustos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[pbustos@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Visual CPS: Sistemas Ciber-Físicos en la Nube con Soporte a la Variabilidad y Multitenencia</title>
		<link>https://biblioteca.sistedes.es/articulo/visual-cps-sistemas-ciber-fisicos-en-la-nube-con-soporte-a-la-variabilidad-y-multitenencia/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:08 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/visual-cps-sistemas-ciber-fisicos-en-la-nube-con-soporte-a-la-variabilidad-y-multitenencia/</guid>
		<description></description>
		<content><![CDATA[En los últimos años, nuestra sociedad está cambiando a gran velocidad. Cada vez son más los dispositivos que interactúan con nosotros y el entorno para ofrecernos servicios ampliados respecto a los servicios de información tradicionales. Esta nueva era de Internet de las Cosas (Internet of Things - IoT) y de servicios al ciudadano a través de internet, con la nueva concepción de los sistemas inteligentes (smart buildings, grids, cities y spaces), necesitan cada vez de más recursos computacionales y software. En este sentido, Cloud Computing ofrece una serie de características en cuanto escalabilidad y flexibilidad, acceso a recursos a través de Internet (off-premises) sin necesidad de ser instalados y gestionados localmente (on-premises) [1] que son fundamentales para soportar tales sistemas. Los servicios proporcionados por la nube son infraestructura (IaaS), plataforma de desarrollo (PaaS) y software (SaaS). Una de las características más significativas de SaaS (Software as a Service) es la multitenencia, la cual promueve las economías de escala mediante la compartición de una serie de recursos entre múltiples usuarios o grupos de usuarios denominados tenants. Cada tenant podría personalizar ciertas partes del software para satisfacer requisitos individuales. Este concepto no es nuevo, y ha sido abordado ampliamente por la ingeniería de líneas de producto [8] y la gestión de la variabilidad. La variabilidad de un producto software se puede definir como la capacidad de este para cambiar y ser utilizado en múltiples contextos. Resulta de gran importancia el dotar al software de mecanismos para soportar distintos grados de variabilidad para poder ofrecer una personalización ajustada a las necesidades específicas de los usuarios. En este artículo se presenta una herramienta para la creación y gestión de sistemas ciber-físicos en la nube con soporte a múltiples tenants y variabilidad entre los tenants llamada Visual CPS. Un sistema ciber-físico es aquel sistema en el que se embebe o integra capacidad de cómputo con el objetivo de interactuar el software con el mundo físico, obteniendo una comunicación bidireccional entre estos dos. Para soportar dichas características la herramienta se basa en el concepto de multitenencia de la plataforma de nube GPaaS [7] y en el diseño arquitectónico basado en el estilo de microservicios [2] que se define como una aplicación compuesta por componentes independientes, ligeros y muy especializados orquestados para proporcionar la funcionalidad de la aplicación global.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2610</post_id>
		<post_date><![CDATA[2017-07-02 04:47:08]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:08]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[visual-cps-sistemas-ciber-fisicos-en-la-nube-con-soporte-a-la-variabilidad-y-multitenencia]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="ciber-physical-system"><![CDATA[Ciber physical system]]></category>
		<category domain="post_tag" nicename="cloud-computing"><![CDATA[Cloud Computing]]></category>
		<category domain="post_tag" nicename="microservices"><![CDATA[microservices]]></category>
		<category domain="post_tag" nicename="multitenancy"><![CDATA[Multitenancy]]></category>
		<category domain="post_tag" nicename="variability"><![CDATA[Variability]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años, nuestra sociedad está cambiando a gran velocidad. Cada vez son más los dispositivos que interactúan con nosotros y el entorno para ofrecernos servicios ampliados respecto a los servicios de información tradicionales. Esta nueva era de Internet de las Cosas (Internet of Things - IoT) y de servicios al ciudadano a través de internet, con la nueva concepción de los sistemas inteligentes (smart buildings, grids, cities y spaces), necesitan cada vez de más recursos computacionales y software. En este sentido, Cloud Computing ofrece una serie de características en cuanto escalabilidad y flexibilidad, acceso a recursos a través de Internet (off-premises) sin necesidad de ser instalados y gestionados localmente (on-premises) [1] que son fundamentales para soportar tales sistemas. Los servicios proporcionados por la nube son infraestructura (IaaS), plataforma de desarrollo (PaaS) y software (SaaS).    Una de las características más significativas de SaaS (Software as a Service) es la multitenencia, la cual promueve las economías de escala mediante la compartición de una serie de recursos entre múltiples usuarios o grupos de usuarios denominados tenants. Cada tenant podría personalizar ciertas partes del software para satisfacer requisitos individuales. Este concepto no es nuevo, y ha sido abordado ampliamente por la ingeniería de líneas de producto [8] y la gestión de la variabilidad. La variabilidad de un producto software se puede definir como la capacidad de este para cambiar y ser utilizado en múltiples contextos. Resulta de gran importancia el dotar al software de mecanismos para soportar distintos grados de variabilidad para poder ofrecer una personalización ajustada a las necesidades específicas de los usuarios.  En este artículo se presenta una herramienta para la creación y gestión de sistemas ciber-físicos en la nube con soporte a múltiples tenants y variabilidad entre los tenants llamada Visual CPS. Un sistema ciber-físico es aquel sistema en el que se embebe o integra capacidad de cómputo con el objetivo de interactuar el software con el mundo físico, obteniendo una comunicación bidireccional entre estos dos. Para soportar dichas características la herramienta se basa en el concepto de multitenencia de la plataforma de nube GPaaS [7] y en el diseño arquitectónico basado en  el estilo de microservicios [2] que se define como una aplicación compuesta por componentes independientes, ligeros y muy especializados orquestados para proporcionar la funcionalidad de la aplicación global.  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/009]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_80.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_80.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Héctor Humanes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[h.humanes@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[SYST Research Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jessica Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[yesica.diaz@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[SYST Research Group ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Carlos Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[carlos.fernandez@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[SYST Research Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Agustín Yagüe]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[agustin.yague@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[SYST Research Group]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Mapas de navegación para la automatización de pruebas de aceptación en aplicaciones móviles</title>
		<link>https://biblioteca.sistedes.es/articulo/mapas-de-navegacion-para-la-automatizacion-de-pruebas-de-aceptacion-en-aplicaciones-moviles/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/mapas-de-navegacion-para-la-automatizacion-de-pruebas-de-aceptacion-en-aplicaciones-moviles/</guid>
		<description></description>
		<content><![CDATA[Para que el proceso de pruebas del software resulte eficaz es habitual que tanto la parte proveedora como la parte aceptante colaboren. Esto es especialmente cierto en el nivel de las pruebas de aceptación, donde la responsabilidad principal recae en la parte aceptante. Aunque se ha avanzado mucho en herramientas que facilitan de forma automática la generación de casos de prueba y la ejecución de los mismos, estas están normalmente pensadas para desarrolladores con avanzados conocimientos en programación. Este trabajo presenta un componente, denominado Graph2Test, que pretende facilitar la comunicación entre la parte aceptante y la parte desarrolladora en base a la representación mediante un diagrama de estados de los mapas de navegación de la aplicación objeto de las pruebas. A partir de este mapa de navegación se generan casos de prueba en texto plano (lenguaje Gherkin), que posteriormente se transforman en scripts de prueba utilizando la tecnología Cucumber. El componente está especializado en la prueba de aplicaciones móviles Android y autocompleta parcialmente estos scripts de prueba con instrucciones del entorno de automatización Espresso.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2611</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mapas-de-navegacion-para-la-automatizacion-de-pruebas-de-aceptacion-en-aplicaciones-moviles]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="android"><![CDATA[Android]]></category>
		<category domain="post_tag" nicename="automatizacion-de-pruebas"><![CDATA[Automatización de pruebas]]></category>
		<category domain="post_tag" nicename="cucumber"><![CDATA[Cucumber]]></category>
		<category domain="post_tag" nicename="espresso"><![CDATA[Espresso]]></category>
		<category domain="post_tag" nicename="pruebas-de-aceptacion"><![CDATA[Pruebas de aceptación]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Para que el proceso de pruebas del software resulte eficaz es habitual que tanto la parte proveedora como la parte aceptante colaboren. Esto es especialmente cierto en el nivel de las pruebas de aceptación, donde la responsabilidad principal recae en la parte aceptante. Aunque se ha avanzado mucho en herramientas que facilitan de forma automática la generación de casos de prueba y la ejecución de los mismos, estas están normalmente pensadas para desarrolladores con avanzados conocimientos en programación. Este trabajo presenta un componente, denominado Graph2Test, que pretende facilitar la comunicación entre la parte aceptante y la parte desarrolladora en base a la representación mediante un diagrama de estados de los mapas de navegación de la aplicación objeto de las pruebas. A partir de este mapa de navegación se generan casos de prueba en texto plano (lenguaje Gherkin), que posteriormente se transforman en scripts de prueba utilizando la tecnología Cucumber. El componente está especializado en la prueba de aplicaciones móviles Android y autocompleta parcialmente estos scripts de prueba con instrucciones del entorno de automatización Espresso.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/072]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_81.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_81.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ginger Janet Valencia-Vásconez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[neyitagin@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miguel Ángel Latre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[latre@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco Javier López-Pellicer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fjlopez@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Javier Nogueras-Iso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jnog@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación, almacenamiento y consulta de datos espaciales masivos</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-almacenamiento-y-consulta-de-datos-espaciales-masivos/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/generacion-almacenamiento-y-consulta-de-datos-espaciales-masivos/</guid>
		<description></description>
		<content><![CDATA[En este artículo presentamos resultados preliminares para dos problemas que surgen en el ámbito del almacenamiento, consulta y visualización de conjuntos masivos de objetos móviles: una herramienta para la generación de conjuntos de datos masivos de objetos móviles en una red de carreteras y su posterior almacenamiento en diferentes sistemas de almacenamiento, y una serie de experimentos de visualización de 40 millones de datos geolocalizados en los que enfrentamos una solución tradicional con una alternativa Big Data actual.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2612</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-almacenamiento-y-consulta-de-datos-espaciales-masivos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="big-data-geografico"><![CDATA[big data geográfico]]></category>
		<category domain="post_tag" nicename="generacion-de-datos"><![CDATA[generación de datos]]></category>
		<category domain="post_tag" nicename="sistemas-de-informacion-geografica"><![CDATA[Sistemas de Informacíon Geográfica]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este artículo presentamos resultados preliminares para dos problemas que surgen en el ámbito del almacenamiento, consulta y visualización de conjuntos masivos de objetos móviles: una herramienta para la generación de conjuntos de datos masivos de objetos móviles en una red de carreteras y su posterior almacenamiento en diferentes sistemas de almacenamiento, y una serie de experimentos de visualización de 40 millones de datos geolocalizados en los que enfrentamos una solución tradicional con una alternativa Big Data actual.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/016]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_82.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_82.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alejandro Cortiñas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alejandro.cortinas@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miguel R. Luaces]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[luaces@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of A Coruña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Ecological Debt: outlining a measure to evaluate software greenability</title>
		<link>https://biblioteca.sistedes.es/articulo/ecological-debt-outlining-a-measure-to-evaluate-software-greenability/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/ecological-debt-outlining-a-measure-to-evaluate-software-greenability/</guid>
		<description></description>
		<content><![CDATA[Developing low quality software (with design flaws, poor quality code, etc) lead to a product with an inner cost that could be measured by using technical debt, that could be consider as the economical effort to solve all the existing design problems of a given software. As time goes on, software quality is acquiring new dimensions, and one of the most important one in the recent years (required by our society) is Software Sustainability, that could be understood as the degree of environmental-friendliness of a soft-ware system. So, following the idea of technical debt, we propose the concept of Ecological Debt which purpose is to measure the economical effort to develop a sustainable software following the Green-in principles.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2613</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[ecological-debt-outlining-a-measure-to-evaluate-software-greenability]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="ecological-debt"><![CDATA[ecological debt]]></category>
		<category domain="post_tag" nicename="greenability"><![CDATA[greenability]]></category>
		<category domain="post_tag" nicename="software-sustainability"><![CDATA[software sustainability]]></category>
		<category domain="post_tag" nicename="technical-debt"><![CDATA[technical debt]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Developing low quality software (with design flaws, poor quality code, etc) lead to a product with an inner cost that could be measured by using technical debt, that could be consider as the economical effort to solve all the existing design problems of a given software. As time goes on, software quality is acquiring new dimensions, and one of the most important one in the recent years (required by our society) is Software Sustainability, that could be understood as the degree of environmental-friendliness of a soft-ware system. So, following the idea of technical debt, we propose the concept of Ecological Debt which purpose is to measure the economical effort to develop a sustainable software following the Green-in principles.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/054]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_83.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_83.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ignacio García-Rodríguez de Guzmán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ignacio.rodriguez@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universida de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Felix Oscar García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[felix.garcia@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[María Ángeles Moraga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mariangeles.moraga@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mario.piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Castilla-La Mancha]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SemHabitApp: Diseño de un Entorno de Observación Biológica para Pacientes Pediátricos Basado en Interacción Tangible y Repositorios Semánticos</title>
		<link>https://biblioteca.sistedes.es/articulo/semhabitapp-diseno-de-un-entorno-de-observacion-biologica-para-pacientes-pediatricos-basado-en-interaccion-tangible-y-repositorios-semanticos/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/semhabitapp-diseno-de-un-entorno-de-observacion-biologica-para-pacientes-pediatricos-basado-en-interaccion-tangible-y-repositorios-semanticos/</guid>
		<description></description>
		<content><![CDATA[Los pacientes pediátricos están sometidos a altas cargas de estrés emocional que repercuten en su bienestar psicológico y social. Estudios previos muestran la efectividad de mezclar terapias tecnológicas de observación de especies animales, aun no contando con la presencia física de éstas en el hospital. En este trabajo se presenta una herramienta de observación de ecosistemas biológicos y un meca-nismo de consultas basado en elementos tangibles que permita a usuarios en edad infantil hospitalizados realizar tareas de exploración biológica de forma autónoma. El mecanismo de consulta desarrollado está basado en definiciones ontológicas utilizando el lenguaje de modelado OWL y en el uso de razonadores semánticos que permiten la inferencia de información no explícita. Por otro lado, el uso de elementos de interacción tangible y de lenguajes icónicos pretende reducir el es-fuerzo cognitivo requerido a usuarios en edad infantil durante el proceso de defi-nición de consultas sobre los repositorios semánticos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2614</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[semhabitapp-diseno-de-un-entorno-de-observacion-biologica-para-pacientes-pediatricos-basado-en-interaccion-tangible-y-repositorios-semanticos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="bases-de-datos-ontologicas"><![CDATA[Bases de datos ontológicas]]></category>
		<category domain="post_tag" nicename="hospitalizacion"><![CDATA[Hospitalización]]></category>
		<category domain="post_tag" nicename="interfaces-tangibles-de-usuario-tui"><![CDATA[Interfaces Tangibles de Usuario (TUI)]]></category>
		<category domain="post_tag" nicename="marcadores-fiduciales"><![CDATA[Marcadores fiduciales]]></category>
		<category domain="post_tag" nicename="owl"><![CDATA[OWL]]></category>
		<category domain="post_tag" nicename="rfid"><![CDATA[RFID]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los pacientes pediátricos están sometidos a altas cargas de estrés emocional que repercuten en su bienestar psicológico y social. Estudios previos muestran la efectividad de mezclar terapias tecnológicas de observación de especies animales, aun no contando con la presencia física de éstas en el hospital. En este trabajo se presenta una herramienta de observación de ecosistemas biológicos y un meca-nismo de consultas basado en elementos tangibles que permita a usuarios en edad infantil hospitalizados realizar tareas de exploración biológica de forma autónoma. El mecanismo de consulta desarrollado está basado en definiciones ontológicas utilizando el lenguaje de modelado OWL y en el uso de razonadores semánticos que permiten la inferencia de información no explícita. Por otro lado, el uso de elementos de interacción tangible y de lenguajes icónicos pretende reducir el es-fuerzo cognitivo requerido a usuarios en edad infantil durante el proceso de defi-nición de consultas sobre los repositorios semánticos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/065]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_84.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_84.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana Seguí]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ansegil@upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando Garcia-Sanjuan]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fegarcia@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Jaen]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fjaen@upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valencia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>FABIOLA: Arquitectura para la Optimización de Problemas en entornos de Big Data</title>
		<link>https://biblioteca.sistedes.es/articulo/fabiola-arquitectura-para-la-optimizacion-de-problemas-en-entornos-de-big-data/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/fabiola-arquitectura-para-la-optimizacion-de-problemas-en-entornos-de-big-data/</guid>
		<description></description>
		<content><![CDATA[Dentro de las organizaciones, los problemas de optimización pueden encontrarse en numerosos ejemplos, tales como minimizar los costes de producción, los errores producidos, o maximizar la fidelidad de los clientes. La resolución de estos problemas es un reto que conlleva un esfuerzo extra. Hoy en día, los problemas de Big Data se suman a estos problems de optimización en dichas empresas. Desafortunadamente, afrontar estos problemas en la pequeña y mediana empresa es extremadamente difícil o incluso imposible. En este artículo, proponemos la arquitectura llamada Fabiola, que permite describir los datos distribuidos y estructurados en problemas de optimización que pueden ser paralelizados. Además, Fabiola aplica las técnicas de Programación con Restricciones para poder devolver la solución a dichos problemas de optimización.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2615</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[fabiola-arquitectura-para-la-optimizacion-de-problemas-en-entornos-de-big-data]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="estructura-de-datos"><![CDATA[Estructura de Datos]]></category>
		<category domain="post_tag" nicename="problemas-de-optimizacion"><![CDATA[Problemas de Optimización]]></category>
		<category domain="post_tag" nicename="programacion-con-restricciones"><![CDATA[Programación con Restricciones]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Dentro de las organizaciones, los problemas de optimización pueden encontrarse en numerosos ejemplos, tales como minimizar los costes de producción, los errores producidos, o maximizar la fidelidad de los clientes. La resolución de estos problemas es un reto que conlleva un esfuerzo extra. Hoy en día, los problemas de Big Data se suman a estos problems de optimización en dichas empresas. Desafortunadamente, afrontar estos problemas en la pequeña y mediana empresa es extremadamente difícil o incluso imposible. En este artículo, proponemos la arquitectura llamada Fabiola, que permite describir los datos distribuidos y estructurados en problemas de optimización que pueden ser paralelizados. Además, Fabiola aplica las técnicas de Programación con Restricciones para poder devolver la solución a dichos problemas de optimización.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/014]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_85.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_85.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Luisa Parody]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[lparody@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Angel Jesus Varela Vaca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ajvarela@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Rafael M. Gasca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gasca@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems,  University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Framework for modelling and implementing secure NoSQL document databases</title>
		<link>https://biblioteca.sistedes.es/articulo/framework-for-modelling-and-implementing-secure-nosql-document-databases/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/framework-for-modelling-and-implementing-secure-nosql-document-databases/</guid>
		<description></description>
		<content><![CDATA[The great amount of data managed by Big Data technologies have to be correctly assured in order to protect critical enterprise and personal information. Nevertheless, current security solutions for Big Data technologies such as NoSQL databases do not take into account the special characteristics of these technologies. In this paper, we focus on assuring NoSQL document databases proposing a framework composed of three stages: (1) the source data set is analysed by using Natural Language Processing techniques and ontological resources in order to detect sensitive data. (2) we define a metamodel for document NoSQL databases that allows designer to specify both structural and security aspects. (3) this model is implemented into a specific document database tool, MongoDB. Finally, we apply the framework proposed to a case study with a dataset of medical domain.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2616</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[framework-for-modelling-and-implementing-secure-nosql-document-databases]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="model"><![CDATA[model]]></category>
		<category domain="post_tag" nicename="natural-language-processing"><![CDATA[Natural Language Processing]]></category>
		<category domain="post_tag" nicename="no-sql"><![CDATA[No SQL]]></category>
		<category domain="post_tag" nicename="security"><![CDATA[security]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The great amount of data managed by Big Data technologies have to be correctly assured in order to protect critical enterprise and personal information. Nevertheless, current security solutions for Big Data technologies such as NoSQL databases do not take into account the special characteristics of these technologies.  In this paper, we focus on assuring NoSQL document databases proposing a framework composed of three stages: (1) the source data set is analysed by using Natural Language Processing techniques and ontological resources in order to detect sensitive data. (2) we define a metamodel for document NoSQL databases that allows designer to specify both structural and security aspects. (3) this model is implemented into a specific document database tool, MongoDB. Finally, we apply the framework proposed to a case study with a dataset of medical domain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/015]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_87.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_87.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Blanco Bueno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carlos.blanco@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cantabria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jesus Peral]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jperal@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Trujillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jtrujillo@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Alicante]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Eduardo Fernandez-Medina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[eduardo.fdezmedina@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[ALARCOS Research Group. UCLM]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Ingeniería inversa basada en modelos de código PL/SQL en aplicaciones Oracle Forms</title>
		<link>https://biblioteca.sistedes.es/articulo/ingenieria-inversa-basada-en-modelos-de-codigo-plsql-en-aplicaciones-oracle-forms/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/ingenieria-inversa-basada-en-modelos-de-codigo-plsql-en-aplicaciones-oracle-forms/</guid>
		<description></description>
		<content><![CDATA[El alto coste de mantenimiento de las aplicaciones legacy promueve en las empresas iniciativas de modernización a nuevas plataformas y tecnologías. La modernización de software, en especial la ingeniería inversa, es uno de los escenarios de aplicación de las técnicas de la In- geniería del Software Dirigida por Modelos (MDE), con el fin de automatizar las tareas manuales y reducir costes. En este trabajo se presenta una solución MDE para la extracción de modelos del código PL/SQL de aplicaciones Oracle Forms. En concreto, se ha implementado un enfoque propuesto en un trabajo previo del grupo Modelum dentro de una colaboración con la empresa Open Canarias en el marco de un proyecto CDTI destinado a la automatización de aplicaciones Oracle Forms a Java. Los principales retos que se han debido afrontar han sido el uso extensivo del metamodelo KDM, la implementación de transformaciones modelo a modelo complicadas y la validación de estas transformaciones que gen- eran modelos grandes y complejos. A lo largo del trabajo se discutirá sobre estas cuestiones.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2617</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[ingenieria-inversa-basada-en-modelos-de-codigo-plsql-en-aplicaciones-oracle-forms]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software-dirigida-por-modelos"><![CDATA[Ingeniería del Software Dirigida por Modelos]]></category>
		<category domain="post_tag" nicename="ingenieria-inversa"><![CDATA[Ingeniería Inversa]]></category>
		<category domain="post_tag" nicename="kdm"><![CDATA[KDM]]></category>
		<category domain="post_tag" nicename="modernizacion-de-software"><![CDATA[Modernizacion de software]]></category>
		<category domain="post_tag" nicename="oracle-forms"><![CDATA[Oracle Forms]]></category>
		<category domain="post_tag" nicename="plsql"><![CDATA[PL/SQL]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El alto coste de mantenimiento de las aplicaciones legacy promueve en las empresas iniciativas de modernización a nuevas plataformas y tecnologías. La modernización de software, en especial la ingeniería inversa, es uno de los escenarios de aplicación de las técnicas de la In- geniería del Software Dirigida por Modelos (MDE), con el fin de automatizar las tareas manuales y reducir costes. En este trabajo se presenta una solución MDE para la extracción de modelos del código PL/SQL de aplicaciones Oracle Forms. En concreto, se ha implementado un enfoque propuesto en un trabajo previo del grupo Modelum dentro de  una colaboración con la empresa Open Canarias en el marco de un proyecto CDTI destinado a la automatización de aplicaciones Oracle Forms a Java. Los principales retos que se han debido afrontar han sido el uso extensivo del metamodelo KDM, la implementación de transformaciones modelo a modelo complicadas y la validación de estas transformaciones que gen- eran modelos grandes y complejos. A lo largo del trabajo se discutirá sobre estas cuestiones.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/029]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_89.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_89.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Javier Fernández Candel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carlosjavier.fernandez1@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francisco Javier Bermúdez Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fjavier@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesus Garcia-Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jmolina@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jose Ramon Hoyos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jose.hoyos@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Diego Sevilla Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[dsevilla@ditec.um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Benito J. Cuesta Viera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[bcuesta@opencanarias.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Open Canarias S.L.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Adaptación Dinámica de Calidades de Servicio en Middleware DDS: Un Enfoque Dirigido por Modelos</title>
		<link>https://biblioteca.sistedes.es/articulo/adaptacion-dinamica-de-calidades-de-servicio-en-middleware-dds-un-enfoque-dirigido-por-modelos/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/adaptacion-dinamica-de-calidades-de-servicio-en-middleware-dds-un-enfoque-dirigido-por-modelos/</guid>
		<description></description>
		<content><![CDATA[Los sistemas distribuidos, en particular los utilizados en aplicaciones críticas, deben garantizar determinados requisitos de seguridad y rendimiento en tiempo de ejecución. En este sentido, los middleware basados en el estándar DDS permiten el desarrollo de aplicaciones distribuidas en las que es posible configurar una amplia variedad de parámetros relacionados con la calidad de servicio (QoS). Sin embargo, la configuración de estos parámetros en aplica-ciones cuyo contexto de ejecución es altamente dinámico e impredecible supone un gran reto, ya que los recursos disponibles y la carga de trabajo de estos sistemas pueden fluctuar sensiblemente a lo largo de la ejecución. En este artículo proponemos un enfoque dirigido por modelos para la adaptación automática, segura, transparente y en tiempo de ejecución de los atributos de QoS en middleware basado en DDS, que permite optimizar el rendimiento del sistema en función de los recursos disponibles en cada momento.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2618</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[adaptacion-dinamica-de-calidades-de-servicio-en-middleware-dds-un-enfoque-dirigido-por-modelos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="calidad-de-servicio"><![CDATA[Calidad de Servicio]]></category>
		<category domain="post_tag" nicename="dds"><![CDATA[DDS]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="middleware"><![CDATA[Middleware]]></category>
		<category domain="post_tag" nicename="software-adaptativo"><![CDATA[Software Adaptativo]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los sistemas distribuidos, en particular los utilizados en aplicaciones críticas, deben garantizar determinados requisitos de seguridad y rendimiento en tiempo de ejecución. En este sentido, los middleware basados en el estándar DDS permiten el desarrollo de aplicaciones distribuidas en las que es posible configurar una amplia variedad de parámetros relacionados con la calidad de servicio (QoS). Sin embargo, la configuración de estos parámetros en aplica-ciones cuyo contexto de ejecución es altamente dinámico e impredecible supone un gran reto, ya que los recursos disponibles y la carga de trabajo de estos sistemas pueden fluctuar sensiblemente a lo largo de la ejecución. En este artículo proponemos un enfoque dirigido por modelos para la adaptación automática, segura, transparente y en tiempo de ejecución de los atributos de QoS en middleware basado en DDS, que permite optimizar el rendimiento del sistema en función de los recursos disponibles en cada momento.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/001]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_91.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_91.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Juan F. Ingles-Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[juanfran.ingles@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Cartagena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Adrián Romero-Garcés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[adrigtl@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Cristina Vicente-Chicote]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[cristinav@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jesús Martínez Cruz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jmcruz@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Integrating risk management in IT settings from ISO standards and management systems perspectives</title>
		<link>https://biblioteca.sistedes.es/articulo/integrating-risk-management-in-it-settings-from-iso-standards-and-management-systems-perspectives/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/integrating-risk-management-in-it-settings-from-iso-standards-and-management-systems-perspectives/</guid>
		<description></description>
		<content><![CDATA[Este artículo analiza las actividades de gestión de riesgos recogidas en varios estándares ISO para así proporcionar una base para mejorar, coordinar e interoperar las actividades de gestión de riesgos en entornos de TI. Tomando como base el estándar internacional ISO 31000 para la gestión de riesgos, se realiza un análisis comparativo de las siguientes normas con el objetivo de identificar las actividades relacionadas con la gestión de riesgos: ISO high level structure for management system standards, ISO 9001 Requisitos de un sistema de gestión de la calidad, ISO 21500 Guía para la gestión de proyectos, ISO/IEC 20000-1 Requisitos de un sistema de gestión de servicios de TI e ISO/IEC 27001 Sistema de gestión de la seguridad de la información de TI. Estas normas facilitan la integración de todas las actividades basadas en procesos, así como la implementación de mecanismos para alinear a todas las entidades de la organización, con el objetivo de hacer frente a los desafíos relacionados con la gestión de riesgos. Se presentan diferentes perspectivas de integración como pueden ser la comprensión de la organización y su contexto, el pensamiento basado en el riesgo, el liderazgo y el compromiso, el enfoque basado en procesos y la estructura PDCA. Indicios de calidad: Publicación: Computer Standards &amp; Interfaces Q2 (35/106) COMPUTER SCIENCE, SOFTWARE ENGINEERING Fecha de publicación: Available online 30 November 2016 DOI: http://dx.doi.org/10.1016/j.csi.2016.11.010]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2619</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[integrating-risk-management-in-it-settings-from-iso-standards-and-management-systems-perspectives]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="entornos-de-ti"><![CDATA[Entornos de TI]]></category>
		<category domain="post_tag" nicename="estandares-iso"><![CDATA[Estándares ISO]]></category>
		<category domain="post_tag" nicename="gestion-integrada-de-riesgos"><![CDATA[Gestión integrada de riesgos]]></category>
		<category domain="post_tag" nicename="sistema-de-gestion-integrado"><![CDATA[Sistema de gestión integrado]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo analiza las actividades de gestión de riesgos recogidas en varios estándares ISO para así proporcionar una base para mejorar, coordinar e interoperar las actividades de gestión de riesgos en entornos de TI. Tomando como base el estándar internacional ISO 31000 para la gestión de riesgos, se realiza un análisis comparativo de las siguientes normas con el objetivo de identificar las actividades relacionadas con la gestión de riesgos: ISO high level structure for management system standards, ISO 9001 Requisitos de un sistema de gestión de la calidad, ISO 21500 Guía para la gestión de proyectos, ISO/IEC 20000-1 Requisitos de un sistema de gestión de servicios de TI e ISO/IEC 27001 Sistema de gestión de la seguridad de la información de TI. Estas normas facilitan la integración de todas las actividades basadas en procesos, así como la implementación de mecanismos para alinear a todas las entidades de la organización, con el objetivo de hacer frente a los desafíos relacionados con la gestión de riesgos. Se presentan diferentes perspectivas de integración como pueden ser la comprensión de la organización y su contexto, el pensamiento basado en el riesgo, el liderazgo y el compromiso, el enfoque basado en procesos y la estructura PDCA.   Indicios de calidad:  Publicación: Computer Standards & Interfaces  Q2 (35/106) COMPUTER SCIENCE, SOFTWARE ENGINEERING  Fecha de publicación: Available online 30 November 2016 DOI: http://dx.doi.org/10.1016/j.csi.2016.11.010]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/056]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_94.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_94.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Beátrix Barafort]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[beatrix.barafort@list.lu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Luxembourg Institute of Science and Technology]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antoni Lluís Mesquida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[antoni.mesquida@uib.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat de les Illes Balears]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonia Mas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[antonia.mas@uib.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat de les Illes Balears]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Docencia sobre Desarrollo de Software dirigido por Modelos en títulos de Grado: fortalezas y debilidades</title>
		<link>https://biblioteca.sistedes.es/articulo/docencia-sobre-desarrollo-de-software-dirigido-por-modelos-en-titulos-de-grado-fortalezas-y-debilidades/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/docencia-sobre-desarrollo-de-software-dirigido-por-modelos-en-titulos-de-grado-fortalezas-y-debilidades/</guid>
		<description></description>
		<content><![CDATA[El Desarrollo de Software Dirigido por Modelos (DSDM) es un área de la Ingeniería del software prometedora, la cual permite el desarrollo de software a partir de artefactos conocidos como modelos, los cuales se definen a partir de los conceptos y relaciones de cada dominio. Posteriormente, y mediante transformaciones bien a otros modelos o bien a texto, es capaz de manejar la complejidad de las actuales tecnologías de desarrollo de software (frameworks, patrones de diseño, versiones de una misma tecnología, integración de múltiples tecnologías, etc.). La inclusión de contenidos sobre DSDM en los títulos de Grado y Máster de Ingeniería Informática es en la actualidad una asignatura pendiente en muchas de estas titulaciones. Probablemente la novedad de la materia y la complejidad de diseñar los nuevos títulos dejo a esta disciplina fuera de los mismos. No obstante, existen algunas universidades donde se han incorporado estos conocimientos y habilidades en Grados (por ejemplo, UPV, UCA o UEx), Másteres (por ejemplo, UMA, UPC, UOC, UAM, U. de Murcia, U. de Oviedo o U. de Almera entre otras). Así, durante el diseño del título de Grado en Ingeniería Informática en Ingeniería del Software de la Universidad de Extremadaura se incluyó una asignatura denominada Diseñoo y Modelado de Sistemas Software (DMSS) que aborda los conceptos esenciales sobre DSDM. En este trabajo se comparte la experiencia docente en esta asignatura durante los ultimos años, justificando la inclusión de los contenidos de DSDM y revisando tanto los aspectos positivos como las principales debilidades.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2620</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[docencia-sobre-desarrollo-de-software-dirigido-por-modelos-en-titulos-de-grado-fortalezas-y-debilidades]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="desarrollo-de-software-dirigido-por-modelos"><![CDATA[Desarrollo de Software Dirigido por Modelos]]></category>
		<category domain="post_tag" nicename="docencia"><![CDATA[Docencia]]></category>
		<category domain="post_tag" nicename="titulos-de-ingenieria-informatica"><![CDATA[Títulos de ingeniería informática]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El Desarrollo de Software Dirigido por Modelos (DSDM) es un área de la Ingeniería del software prometedora, la cual permite el desarrollo de software a partir de artefactos conocidos como modelos, los cuales se definen a partir de los conceptos y relaciones de cada dominio. Posteriormente, y mediante transformaciones bien a otros modelos o bien a texto, es capaz de manejar la complejidad de las actuales tecnologías de desarrollo de software (frameworks, patrones de diseño, versiones de una misma tecnología, integración de múltiples tecnologías, etc.). La inclusión de contenidos sobre DSDM en los títulos de Grado y Máster de Ingeniería Informática es en la actualidad una asignatura pendiente en muchas de estas titulaciones. Probablemente la novedad de la materia y la complejidad de diseñar los nuevos títulos dejo a esta disciplina fuera de los mismos. No obstante, existen algunas universidades donde se han incorporado estos conocimientos y habilidades en Grados (por ejemplo, UPV, UCA o UEx), Másteres (por ejemplo, UMA, UPC, UOC, UAM, U. de Murcia, U. de Oviedo o U. de Almera entre otras). Así, durante el diseño del título de Grado en Ingeniería Informática en Ingeniería del Software de la Universidad de Extremadaura se incluyó una asignatura denominada Diseñoo y Modelado de Sistemas Software (DMSS) que aborda los conceptos esenciales sobre DSDM. En este trabajo se comparte la experiencia docente en esta asignatura durante los ultimos años, justificando la inclusión de los contenidos de DSDM y revisando tanto los aspectos positivos como las principales debilidades.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/027]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_95.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_95.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro J. Clemente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pjclemente@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Effect of Domain Knowledge on Elicitation Effectiveness: An Internally Replicated Controlled Experiment</title>
		<link>https://biblioteca.sistedes.es/articulo/effect-of-domain-knowledge-on-elicitation-effectiveness-an-internally-replicated-controlled-experiment/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/effect-of-domain-knowledge-on-elicitation-effectiveness-an-internally-replicated-controlled-experiment/</guid>
		<description></description>
		<content><![CDATA[IEEE TRANSACTIONS ON SOFTWARE ENGINEERING, VOL. 42, NO. 5, MAY 2016 DOI: https://doi.org/10.1109/TSE.2015.2494588 Factor de impacto: 1.516 Posición: 20/106 (Software Engineering) - Q1]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2621</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[effect-of-domain-knowledge-on-elicitation-effectiveness-an-internally-replicated-controlled-experiment]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="controlled-experiment"><![CDATA[Controlled Experiment]]></category>
		<category domain="post_tag" nicename="domain-knowledge"><![CDATA[domain knowledge]]></category>
		<category domain="post_tag" nicename="internal-replication"><![CDATA[internal replication]]></category>
		<category domain="post_tag" nicename="requirements-elicitation"><![CDATA[requirements elicitation]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[IEEE TRANSACTIONS ON SOFTWARE ENGINEERING, VOL. 42, NO. 5, MAY 2016  DOI: https://doi.org/10.1109/TSE.2015.2494588 Factor de impacto: 1.516 Posición: 20/106 (Software Engineering) - Q1  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/049]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_96.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_96.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alejandrina M. Aranda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alearanda@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Oscar Dieste]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[odieste@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Natalia Juristo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[natalia@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad PolitíƒÂ©cnica de Madrid]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An experimental replication on the effect of the practice of mindfulness in conceptual modeling performance</title>
		<link>https://biblioteca.sistedes.es/articulo/an-experimental-replication-on-the-effect-of-the-practice-of-mindfulness-in-conceptual-modeling-performance/</link>
		<pubDate>Sun, 02 Jul 2017 02:47:09 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-experimental-replication-on-the-effect-of-the-practice-of-mindfulness-in-conceptual-modeling-performance/</guid>
		<description></description>
		<content><![CDATA[Beatriz Bernárdez, Amador Durán , JoséA. Parejo , Antonio Ruiz-Cortés The Journal of Systems and Software 0 0 0 (2016) 1-20, In Press (Available online 30 June 2016) Indicios de Calidad: Journal of Systems and Software (Elsevier) ISSN: 0164-1212 Factor de impacto 2015: 1,424 Factor de impacto a 5 años: 1,767 Está indexada en dos categorías: Computer Science / Theory &amp; Methods: 31/105 (Q2) Computer Science / Software Engineering: 24/106 (Q1) Otros datos (sacados de la web de la revista): CiteScore: 2.93 Source Normalized Impact per Paper (SNIP): 2.415 SCImago Journal Rank (SJR): 0.897]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2622</post_id>
		<post_date><![CDATA[2017-07-02 04:47:09]]></post_date>
		<post_date_gmt><![CDATA[2017-07-02 02:47:09]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-experimental-replication-on-the-effect-of-the-practice-of-mindfulness-in-conceptual-modeling-performance]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="conceptual-modeling"><![CDATA[Conceptual modeling]]></category>
		<category domain="post_tag" nicename="mindfulness"><![CDATA[Mindfulness]]></category>
		<category domain="post_tag" nicename="replication"><![CDATA[Replication]]></category>
		<category domain="post_tag" nicename="software-psychology"><![CDATA[Software psychology]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Beatriz Bernárdez, Amador Durán , JoséA. Parejo , Antonio Ruiz-Cortés The Journal of Systems and Software 0 0 0 (2016) 1-20, In Press (Available online 30 June 2016)  Indicios de Calidad:  Journal of Systems and Software (Elsevier) ISSN: 0164-1212 Factor de impacto 2015: 1,424 Factor de impacto a 5 años: 1,767   Está indexada en dos categorías:   Computer Science / Theory & Methods: 31/105 (Q2)  Computer Science / Software Engineering: 24/106 (Q1)   Otros datos (sacados de la web de la revista): CiteScore: 2.93 Source Normalized Impact per Paper (SNIP): 2.415 SCImago Journal Rank (SJR): 0.897 ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/044]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_97.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/JISBD_2017_paper_97.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Beatriz Bernárdez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[beat@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Amador Durán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[amador@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José A. Parejo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[japarejo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Early analysis of resource consumption patterns in mobile applications (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/early-analysis-of-resource-consumption-patterns-in-mobile-applications-summary/</link>
		<pubDate>Sat, 08 Jul 2017 02:35:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/early-analysis-of-resource-consumption-patterns-in-mobile-applications-summary/</guid>
		<description></description>
		<content><![CDATA[The success or failure of a mobile application largely depends on the resources it consumes. A resource-intensive application will quickly be rejected by its users. One of the most important aspects that determines this consumption is the software architecture applied in its development. However, which architecture is the most efficient depends on the application's behaviour.

With the aim of providing mobile developers information on what architectural style consumes fewer resources for each application, in this work we analysed the resources consumed by two applications, each of them built with two different architectures (a server-centric architecture and a mobile-centric architecture) in order to identify under which situation each architecture is more efficient. We observed that, for these cases, as the number of interactions with external entities grows, the more efficient becomes a server-centric architecture. Instead, a mobile-centric architecture is more efficient if the data to be shared has to be updated frequently or if there are few external entities involved.

In addition, by generalizing the analysis of the two applications, a conceptual framework was created with which to analyse the consumption pattern of any applications in their early development phases. This framework can be used to estimate a particular application's consumption with different architectures, or to predict its consumption under future evolution of the app.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2710</post_id>
		<post_date><![CDATA[2017-07-08 04:35:15]]></post_date>
		<post_date_gmt><![CDATA[2017-07-08 02:35:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[early-analysis-of-resource-consumption-patterns-in-mobile-applications-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>2</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The success or failure of a mobile application largely depends on the resources it consumes. A resource-intensive application will quickly be rejected by its users. One of the most important aspects that determines this consumption is the software architecture applied in its development. However, which architecture is the most efficient depends on the application's behaviour.

With the aim of providing mobile developers information on what architectural style consumes fewer resources for each application, in this work we analysed the resources consumed by two applications, each of them built with two different architectures (a server-centric architecture and a mobile-centric architecture) in order to identify under which situation each architecture is more efficient. We observed that, for these cases, as the number of interactions with external entities grows, the more efficient becomes a server-centric architecture. Instead, a mobile-centric architecture is more efficient if the data to be shared has to be updated frequently or if there are few external entities involved.

In addition, by generalizing the analysis of the two applications, a conceptual framework was created with which to analyse the consumption pattern of any applications in their early development phases. This framework can be used to estimate a particular application's consumption with different architectures, or to predict its consumption under future evolution of the app.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/031]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499279592.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499279592.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose Garcia-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Cristina Vicente-Chicote]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[cristinav@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juanher@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Tommi Mikkonen]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[tjm@cs.tut.fi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Tampere University of Technology, Finland]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Juan M. Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Framework for Efficiently Mining the Organisational Perspective of Business Processes (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-framework-for-efficiently-mining-the-organisational-perspective-of-business-processes-summary/</link>
		<pubDate>Sat, 08 Jul 2017 02:35:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-framework-for-efficiently-mining-the-organisational-perspective-of-business-processes-summary/</guid>
		<description></description>
		<content><![CDATA[Actual process executions may constitute a valuable input for improving process design. Process mining provides methods for automatic process analysis, among others for discovering processes by extracting knowledge from event logs in the form of a process model. Various algorithms are available to discover models capturing the control flow of a process, related to the behavioural perspective of the process.For perspectives like the organisational perspective, which manages the involvement of human resources in processes, only partial solutions for mining had been developed despite the importance of resource information not only for performance but also for compliance analysis.

Prior work on mining resource information focused on discovering specific aspects of the organisational perspective such as role models, separation of duty or social networks. However, comprehensive and integrated support for the wellestablished workflow resource patterns, and specifically in this context for the socalled creation patterns, was missing. Furthermore, the close interplay between the organisational and the behavioural perspectives (cross-perspective patterns) was disregarded.

The research reported in this paper presented an efficient and effective framework for mining the organisational perspective of business processes that is divided into an event log pre-processing phase, a phase for integrated resource mining including cross-perspective patterns, and a model post-processing phase. We evaluated our approach with an implementation of the three phases, with simulation experiments for measuring performance, and with the application of the approach on a real-life event log for checking its effectiveness.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2711</post_id>
		<post_date><![CDATA[2017-07-08 04:35:15]]></post_date>
		<post_date_gmt><![CDATA[2017-07-08 02:35:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-framework-for-efficiently-mining-the-organisational-perspective-of-business-processes-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Actual process executions may constitute a valuable input for improving process design. Process mining provides methods for automatic process analysis, among others for discovering processes by extracting knowledge from event logs in the form of a process model. Various algorithms are available to discover models capturing the control flow of a process, related to the behavioural perspective of the process.For perspectives like the organisational perspective, which manages the involvement of human resources in processes, only partial solutions for mining had been developed despite the importance of resource information not only for performance but also for compliance analysis.

Prior work on mining resource information focused on discovering specific aspects of the organisational perspective such as role models, separation of duty or social networks. However, comprehensive and integrated support for the wellestablished workflow resource patterns, and specifically in this context for the socalled creation patterns, was missing. Furthermore, the close interplay between the organisational and the behavioural perspectives (cross-perspective patterns) was disregarded.

The research reported in this paper presented an efficient and effective framework for mining the organisational perspective of business processes that is divided into an event log pre-processing phase, a phase for integrated resource mining including cross-perspective patterns, and a model post-processing phase. We evaluated our approach with an implementation of the three phases, with simulation experiments for measuring performance, and with the application of the approach on a real-life event log for checking its effectiveness.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/029]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499280233.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499280233.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Stefan Schönig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[stefan.schoenig@uni-bayreuth.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Bayreuth, Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Cristina Cabanillas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cristina.cabanillas@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Vienna University of Economics and Business, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Stefan Jablonski]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[stefan.jablonski@uni-bayreuth.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Bayreuth, Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jan Mendling]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jan.mendling@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Vienna University of Economics and Business, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Narrowing the Business-IT Gap in Process Performance Measurement (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/narrowing-the-business-it-gap-in-process-performance-measurement-summary/</link>
		<pubDate>Sat, 08 Jul 2017 02:35:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/narrowing-the-business-it-gap-in-process-performance-measurement-summary/</guid>
		<description></description>
		<content><![CDATA[Process Performance indicators (PPIs) play an important role in monitoring the performance of operational procedures. Both defining and measuring suitable PPIs are key tasks for aligning strategic business objectives with the operational implementation of a process. A major challenge in this regard is that perspectives on the same real-world phenomenon differ among the stakeholders that are involved in these tasks. Since the formulation of PPIs is typically a managerial concern, there is a risk that these do not match with the exact operational and technical characteristics of business processes. To bridge this gap, the concepts described in PPIs must first be linked to their corresponding process elements. Establishing these links is paramount for the monitoring of process performance.
Without them, the values of PPIs cannot be computed automatically. However, the necessary links must currently be established manually. A task which is tedious and error-prone, due to the aforementioned incoherence between the different perspectives. The goal of our work is to overcome the efforts involved in the manual creation of links by automating this step. To achieve this, we developed an approach that automatically aligns textual PPI descriptions to the relevant parts of a process model. The approach takes a textual PPI description and a process model to which the PPI relates as input. Given this input, the approach generates an alignment in three steps. (1) Type classification: We make use of a decision tree classifier to identify the type of a given PPI, which is important because it affects the number and kinds of process model elements that should be aligned to a PPI. (2) PPI parsing: We parse the textual PPI description to extract those phrases that relate to specific parts of a process, making use of natural language processing techniques. (3) Alignment to process model: Finally, given the identified measure type and the extracted phrases, we compute an alignment between the phrases and the process model. A quantitative evaluation with a set of 173 PPIs obtained from industry and reference frameworks, demonstrates that our automated approach produces satisfying results.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2712</post_id>
		<post_date><![CDATA[2017-07-08 04:35:15]]></post_date>
		<post_date_gmt><![CDATA[2017-07-08 02:35:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[narrowing-the-business-it-gap-in-process-performance-measurement-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Process Performance indicators (PPIs) play an important role in monitoring the performance of operational procedures. Both defining and measuring suitable PPIs are key tasks for aligning strategic business objectives with the operational implementation of a process. A major challenge in this regard is that perspectives on the same real-world phenomenon differ among the stakeholders that are involved in these tasks. Since the formulation of PPIs is typically a managerial concern, there is a risk that these do not match with the exact operational and technical characteristics of business processes. To bridge this gap, the concepts described in PPIs must first be linked to their corresponding process elements. Establishing these links is paramount for the monitoring of process performance. Without them, the values of PPIs cannot be computed automatically. However, the necessary links must currently be established manually. A task which is tedious and error-prone, due to the aforementioned incoherence between the different perspectives. The goal of our work is to overcome the efforts involved in the manual creation of links by automating this step. To achieve this, we developed an approach that automatically aligns textual PPI descriptions to the relevant parts of a process model. The approach takes a textual PPI description and a process model to which the PPI relates as input. Given this input, the approach generates an alignment in three steps. (1) Type classification: We make use of a decision tree classifier to identify the type of a given PPI, which is important because it affects the number and kinds of process model elements that should be aligned to a PPI. (2) PPI parsing: We parse the textual PPI description to extract those phrases that relate to specific parts of a process, making use of natural language processing techniques. (3) Alignment to process model: Finally, given the identified measure type and the extracted phrases, we compute an alignment between the phrases and the process model. A quantitative evaluation with a set of 173 PPIs obtained from industry and reference frameworks, demonstrates that our automated approach produces satisfying results.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/028]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499280822.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499280822.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Han van der Aa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[j.h.vander.aa@vu.nl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[VU University Amsterdam, The Netherlands]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Adela del-Río-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[adeladelrio@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Henrik Leopold]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[h.leopold@vu.nl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[VU University Amsterdam, The Netherlands]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Jan Mendling]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[jan.mendling@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Vienna University of Economics and Business, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Hajo Reijers]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[a.reijers@vu.nl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[VU University Amsterdam, The Netherlands & Eindhoven University of Technology, The Netherlands]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Complex Event Processing Modeling by Prioritized Colored Petri Nets (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/complex-event-processing-modeling-by-prioritized-colored-petri-nets-summary/</link>
		<pubDate>Sat, 08 Jul 2017 02:35:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/complex-event-processing-modeling-by-prioritized-colored-petri-nets-summary/</guid>
		<description></description>
		<content><![CDATA[Complex Event Processing (CEP) is a technology that allows us to process and correlate large volumes of data by using event patterns, aiming at promptly detecting specific situations that could require special treatment. The event types and event patterns for a particular application domain are implemented by using an Event Processing Language (EPL). Although some current model-driven tools allow end users to easily define these patterns, which are then transformed automatically into a particular EPL, the generated code is syntactically but not semantically validated. To deal with this problem, a Prioritized Colored Petri Net model (PCPN) for CEP is proposed and conducted in this paper.

Thus, we have not only an event pattern graphical representation, but also the capability to perform formal analysis, and therefore semantic analysis, by means of the PCPN model obtained and the CPN Tools. This formal analysis is twofold. On the one hand, users can interact with the model itself by performing a step by step debugging, since the tool allows to simulate the model. With this in mind, users can specify a concrete scenario by providing the initial marking to check whether the model works as expected. By doing this, users can observe the results of the individual steps of the simulation, which represent the different EPL operators, as we can observe at the end of the case study where a user can detect whether the preferred operator has been used, that is, if the specified pattern behaves as expected. On the other hand, there are certain advantages of performing automatic simulations. An automatic simulation allows us to actually execute the EPL code and compare the obtained output, that is, we can compare whether the results obtained from a given input are the same when we execute the EPL code in the Esper EPL online tool and in CPN Tools.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2713</post_id>
		<post_date><![CDATA[2017-07-08 04:35:15]]></post_date>
		<post_date_gmt><![CDATA[2017-07-08 02:35:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[complex-event-processing-modeling-by-prioritized-colored-petri-nets-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Complex Event Processing (CEP) is a technology that allows us to process and correlate large volumes of data by using event patterns, aiming at promptly detecting specific situations that could require special treatment. The event types and event patterns for a particular application domain are implemented by using an Event Processing Language (EPL). Although some current model-driven tools allow end users to easily define these patterns, which are then transformed automatically into a particular EPL, the generated code is syntactically but not semantically validated. To deal with this problem, a Prioritized Colored Petri Net model (PCPN) for CEP is proposed and conducted in this paper.

Thus, we have not only an event pattern graphical representation, but also the capability to perform formal analysis, and therefore semantic analysis, by means of the PCPN model obtained and the CPN Tools. This formal analysis is twofold. On the one hand, users can interact with the model itself by performing a step by step debugging, since the tool allows to simulate the model. With this in mind, users can specify a concrete scenario by providing the initial marking to check whether the model works as expected. By doing this, users can observe the results of the individual steps of the simulation, which represent the different EPL operators, as we can observe at the end of the case study where a user can detect whether the preferred operator has been used, that is, if the specified pattern behaves as expected. On the other hand, there are certain advantages of performing automatic simulations. An automatic simulation allows us to actually execute the EPL code and compare the obtained output, that is, we can compare whether the results obtained from a given input are the same when we execute the EPL code in the Esper EPL online tool and in CPN Tools.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/027]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499281447.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499281447.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Hermenegilda Macià]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[hermenegilda.macia@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[School of Computer Science, University of Castilla-La Mancha, Albacete]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Valentín Valero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[valentin.valero@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[School of Computer Science, University of Castilla-La Mancha, Albacete]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Gregorio Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gregorio.diaz@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[School of Computer Science, University of Castilla-La Mancha, Albacete]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science and Engineering, University of Cádiz, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Department of Computer Science and Engineering, University of Cádiz, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modeling Service Level Agreements with Linked USDL Agreement (Resumen)</title>
		<link>https://biblioteca.sistedes.es/articulo/modeling-service-level-agreements-with-linked-usdl-agreement-resumen/</link>
		<pubDate>Sat, 08 Jul 2017 02:35:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/modeling-service-level-agreements-with-linked-usdl-agreement-resumen/</guid>
		<description></description>
		<content><![CDATA[A pesar de la importancia de los servicios en la economía, las tareas como la búsqueda, análisis de alternativas, y contratación de servicios en virtud de acuerdos de nivel de servicio (ANS), siguen realizándose manualmente. En la denominada Web de los servicios existen alternativas para facilitar  la automatización  de estas tareas basadas en diversos modelos conceptuales: genéricos como Linked USDL, o centrados en algún aspecto concreto, como
WS-Agreement con los ANS. Sin embargo,  estos últimos contemplan principalmente sólo aspectos técnicos, sin proporcionar una semántica explícita a los términos del ANS ni cumplir los principios de la Web, dificultando su adopción y análisis automático.

En este artículo presentamos Linked USDL Agreement, una extensión de la familia de ontologías Linked USDL que proporciona facilidades para especificar, gestionar y compartir descripciones de ANS en la Web. Este modelo semántico evita los problemas de interoperabilidad y heterogeneidad de las especificaciones de ANS actuales. Además, dado que nuestro modelo sigue los principios de la Web de los datos, las descripciones de ANS generadas son fácilmente publicables, compartibles y analizables, sirviendo como soporte del ciclo de vida de los servicios.

Nuestra propuesta ha sido validada tanto sobre servicios Web tradicionales (e.g. computación en la nube), como sobre servicios no-computacionales  (e.g. outsourcing de procesos de negocio). La comparación realizada con otras alternativas existentes, así como la implementación de una herramienta que facilita la creación, publicación, y análisis automático de documentos en Linked USDL Agreement, nos permite afirmar que nuestra propuesta  es capaz de soportar
completamente la gestión del ciclo de vida de los ANS.
]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2714</post_id>
		<post_date><![CDATA[2017-07-08 04:35:15]]></post_date>
		<post_date_gmt><![CDATA[2017-07-08 02:35:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modeling-service-level-agreements-with-linked-usdl-agreement-resumen]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>1</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A pesar de la importancia de los servicios en la economía, las tareas como la búsqueda, análisis de alternativas, y contratación de servicios en virtud de acuerdos de nivel de servicio (ANS), siguen realizándose manualmente. En la denominada Web de los servicios existen alternativas para facilitar  la automatización  de estas tareas basadas en diversos modelos conceptuales: genéricos como Linked USDL, o centrados en algún aspecto concreto, como
WS-Agreement con los ANS. Sin embargo,  estos últimos contemplan principalmente sólo aspectos técnicos, sin proporcionar una semántica explícita a los términos del ANS ni cumplir los principios de la Web, dificultando su adopción y análisis automático.

En este artículo presentamos Linked USDL Agreement, una extensión de la familia de ontologías Linked USDL que proporciona facilidades para especificar, gestionar y compartir descripciones de ANS en la Web. Este modelo semántico evita los problemas de interoperabilidad y heterogeneidad de las especificaciones de ANS actuales. Además, dado que nuestro modelo sigue los principios de la Web de los datos, las descripciones de ANS generadas son fácilmente publicables, compartibles y analizables, sirviendo como soporte del ciclo de vida de los servicios.

Nuestra propuesta ha sido validada tanto sobre servicios Web tradicionales (e.g. computación en la nube), como sobre servicios no-computacionales  (e.g. outsourcing de procesos de negocio). La comparación realizada con otras alternativas existentes, así como la implementación de una herramienta que facilita la creación, publicación, y análisis automático de documentos en Linked USDL Agreement, nos permite afirmar que nuestra propuesta  es capaz de soportar
completamente la gestión del ciclo de vida de los ANS.
]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/026]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499282110.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499282110.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José María García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[josemgarcia@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Carlos Pedrinaci]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[c.pedrinaci@open.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[The Open University, United Kingdom]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Jorge S. Cardoso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[jcardoso@dei.uc.pt]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[CISUC/Department of Informatics Engineering, University of Coimbra, Portugal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards an MDE-Based Approach to Test Entity Reconciliation Applications (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-an-mde-based-approach-to-test-entity-reconciliation-applications-summary/</link>
		<pubDate>Sat, 08 Jul 2017 02:35:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-an-mde-based-approach-to-test-entity-reconciliation-applications-summary/</guid>
		<description></description>
		<content><![CDATA[The management of large volumes of data has given rise to significant challenges to the entity reconciliation problem (which refers to combining data from different sources for a unified vision) due to the fact that the data are becoming more un-structured, un-clean and incomplete, need to be more linked, etc. Testing the applications that implement the entity reconciliation problem is crucial to ensure both the correctness of the reconciliation process and the quality of the reconciled data.

In this paper, we have presented a work-in-progress that aims to test applications that implement an entity reconciliation problem to ensure the quality of both the applications and the reconciled data. The approach allows the creation of test models for integration testing, taking into account the problem specification and the data models of the data sources and the solution. These test models are composed of several business rules, called integration rules, which can be used to automatically derive the test requirements. Besides, as the integration rules also describe the business logic of the entity reconciliation process, they can be used to partially derive the implementation of the application.

The proposal is based on two main pillars: MDE and virtual graph. The support of automation of the MDE paradigm allows us to build very scalable solutions at a low cost, whilst the virtual graphs allow us to dynamically build the entity reconciliation solution at runtime.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2715</post_id>
		<post_date><![CDATA[2017-07-08 04:35:15]]></post_date>
		<post_date_gmt><![CDATA[2017-07-08 02:35:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-an-mde-based-approach-to-test-entity-reconciliation-applications-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>2</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The management of large volumes of data has given rise to significant challenges to the entity reconciliation problem (which refers to combining data from different sources for a unified vision) due to the fact that the data are becoming more un-structured, un-clean and incomplete, need to be more linked, etc. Testing the applications that implement the entity reconciliation problem is crucial to ensure both the correctness of the reconciliation process and the quality of the reconciled data.

In this paper, we have presented a work-in-progress that aims to test applications that implement an entity reconciliation problem to ensure the quality of both the applications and the reconciled data. The approach allows the creation of test models for integration testing, taking into account the problem specification and the data models of the data sources and the solution. These test models are composed of several business rules, called integration rules, which can be used to automatically derive the test requirements. Besides, as the integration rules also describe the business logic of the entity reconciliation process, they can be used to partially derive the implementation of the application.

The proposal is based on two main pillars: MDE and virtual graph. The support of automation of the MDE paradigm allows us to build very scalable solutions at a low cost, whilst the virtual graphs allow us to dynamically build the entity reconciliation solution at runtime.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/025]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499282605.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499282605.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[J.G. Enríquez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jose.gonzalez@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Computer and Language Systems, University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Raquel Blanco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[rblanco@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computing, University of Oviedo, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[F.J. Domínguez-Mayo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fjdominguez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer and Language Systems, University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computing, University of Oviedo, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[M.J. Escalona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[mjescalona@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Department of Computer and Language Systems, University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Continuous Space Estimation: Increasing WiFi-Based Indoor Localization Resolution without Increasing the Site-Survery Effort (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/continuous-space-estimation-increasing-wifi-based-indoor-localization-resolution-without-increasing-the-site-survery-effort-summary/</link>
		<pubDate>Sat, 08 Jul 2017 02:35:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/continuous-space-estimation-increasing-wifi-based-indoor-localization-resolution-without-increasing-the-site-survery-effort-summary/</guid>
		<description></description>
		<content><![CDATA[This work is part of the BAI4SOW ("Inteligencia (Artificial) de Negocio para Flujos de Trabajo Sociales”) project, previously introduced in JCIS 2016, that deals with the study of the social workflows of consumers inside an open mall.

One key objective inside our sub-project is to localize and track the consumers by means of using the on board phone sensors (GPS in outdoors and WiFi, combined with other sensors, in indoors). This user localization represents the base of the activity recognition system that feeds the database. Using this
user positioning database and applying data mining processes the most frequent patterns of activity will be detected.

The objective of our proposal was to improve the resolution of fingerprint-based indoor WiFi localization systems without increasing the site survey effort. This way, WiFi indoor localization systems could be used to locate users in large environments (such as malls) reducing the effort of constructing the WiFi database. To do so, we proposed an approach, based on Support Vector Regression, to estimate the received signal strength at non-site-surveyed positions of
the environment. Experiments, performed in a real environment, showed that the number and distribution of the positions needed to train the system can be
reduced to almost half without significantly increasing the mean distance error.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2716</post_id>
		<post_date><![CDATA[2017-07-08 04:35:15]]></post_date>
		<post_date_gmt><![CDATA[2017-07-08 02:35:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[continuous-space-estimation-increasing-wifi-based-indoor-localization-resolution-without-increasing-the-site-survery-effort-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>1</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This work is part of the BAI4SOW ("Inteligencia (Artificial) de Negocio para Flujos de Trabajo Sociales”) project, previously introduced in JCIS 2016, that deals with the study of the social workflows of consumers inside an open mall.

One key objective inside our sub-project is to localize and track the consumers by means of using the on board phone sensors (GPS in outdoors and WiFi, combined with other sensors, in indoors). This user localization represents the base of the activity recognition system that feeds the database. Using this
user positioning database and applying data mining processes the most frequent patterns of activity will be detected.

The objective of our proposal was to improve the resolution of fingerprint-based indoor WiFi localization systems without increasing the site survey effort. This way, WiFi indoor localization systems could be used to locate users in large environments (such as malls) reducing the effort of constructing the WiFi database. To do so, we proposed an approach, based on Support Vector Regression, to estimate the received signal strength at non-site-surveyed positions of
the environment. Experiments, performed in a real environment, showed that the number and distribution of the positions needed to train the system can be
reduced to almost half without significantly increasing the mean distance error.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/024]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499282950.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499282950.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Noelia Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[noelia.hernandez@uc3m.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Carlos III de Madrid, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Ocaña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mocana@depeca.uah.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Alcalá, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose M. Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[josemaria.alonso.moral@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidade de Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Euntai Kim]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[etkim@yonsei.ac.kr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Yonsei University, Republic of Korea]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hybrid business process modeling for the optimization of outcome data (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/hybrid-business-process-modeling-for-the-optimization-of-outcome-data-summary/</link>
		<pubDate>Sat, 08 Jul 2017 02:35:15 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/hybrid-business-process-modeling-for-the-optimization-of-outcome-data-summary/</guid>
		<description></description>
		<content><![CDATA[Declarative business processes are commonly used to describe permitted and prohibited actions in a BP. However, most current proposals of declarative languages fail in three aspects: (1) they tend to be oriented only towards the execution order of the activities; (2) the optimization is oriented only towards the minimization of the execution time or the resources used in the business process; and (3) there is an absence of capacity of execution of declarative models in commercial Business Process Management Systems.

Therefore, this contribution aims at taking into account these three aspects, by means of: (1) the formalization of a hybrid model oriented towards obtaining the outcome data optimization by combining a data-oriented declarative specification and a control-flow-oriented imperative specification; and (2) the automatic creation from this hybrid model to an imperative model that is executable in a standard Business Process Management System.

An approach, based on the definition of a hybrid business process, which uses a constraint programming paradigm, is presented. This approach enables the optimized outcome data to be obtained at runtime for the various instances. In order to work out our approach, a language capable of defining a hybrid model is provided, and applied to a case study. Likewise, the automatic creation of an executable constraint satisfaction problem is addressed, whose resolution allows us to attain the optimized outcome data. A brief computational study is also shown.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2717</post_id>
		<post_date><![CDATA[2017-07-08 04:35:15]]></post_date>
		<post_date_gmt><![CDATA[2017-07-08 02:35:15]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hybrid-business-process-modeling-for-the-optimization-of-outcome-data-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>3</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Declarative business processes are commonly used to describe permitted and prohibited actions in a BP. However, most current proposals of declarative languages fail in three aspects: (1) they tend to be oriented only towards the execution order of the activities; (2) the optimization is oriented only towards the minimization of the execution time or the resources used in the business process; and (3) there is an absence of capacity of execution of declarative models in commercial Business Process Management Systems.

Therefore, this contribution aims at taking into account these three aspects, by means of: (1) the formalization of a hybrid model oriented towards obtaining the outcome data optimization by combining a data-oriented declarative specification and a control-flow-oriented imperative specification; and (2) the automatic creation from this hybrid model to an imperative model that is executable in a standard Business Process Management System.

An approach, based on the definition of a hybrid business process, which uses a constraint programming paradigm, is presented. This approach enables the optimized outcome data to be obtained at runtime for the various instances. In order to work out our approach, a language capable of defining a hybrid model is provided, and applied to a case study. Likewise, the automatic creation of an executable constraint satisfaction problem is addressed, whose resolution allows us to attain the optimized outcome data. A brief computational study is also shown.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2017/030]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499283276.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[uploaded-files/1499283276.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Luisa Parody]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[lparody@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[María Teresa Gómez-López]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[maytegomez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Rafael M. Gasca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gasca@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>ACon: A learning-based approach to deal with uncertainty in contextual requirements at runtime</title>
		<link>https://biblioteca.sistedes.es/articulo/acon-a-learning-based-approach-to-deal-with-uncertainty-in-contextual-requirements-at-runtime/</link>
		<pubDate>Tue, 11 Jul 2017 03:25:23 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/?post_type=articulo&#038;p=2744</guid>
		<description></description>
		<content><![CDATA[Autores: Alessia Knauss, Daniela Damian, Xavier Franch, Angela Rook, Hausi A. Müller, Alex Thomo Revista: Informacion &amp; Software Technology 70: 85-99 (2016) DOI: http://dx.doi.org/10.1016/j.infsof.2015.10.001 JCR IF 2015: 1.569 (primer cuartil de la categoría de ingeniería del software) 3 citas (excluyendo self-citations)]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2744</post_id>
		<post_date><![CDATA[2017-07-11 05:25:23]]></post_date>
		<post_date_gmt><![CDATA[2017-07-11 03:25:23]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[acon-a-learning-based-approach-to-deal-with-uncertainty-in-contextual-requirements-at-runtime]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="contextual-requirements"><![CDATA[Contextual requirements]]></category>
		<category domain="post_tag" nicename="requirements-engineering"><![CDATA[requirements engineering]]></category>
		<category domain="post_tag" nicename="self-adaptive-systems"><![CDATA[Self-adaptive systems]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2745]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/080]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[Requirements engineering,Self-adaptive systems,Contextual requirements]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alessia Knauss]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Daniela Damian]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Xavier Franch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Angela Rook]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Hausi A. Müller]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Alex Thomo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Catalunya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[franch@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Victoria, Victoria, BC, Canada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Victoria, Victoria, BC, Canada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Victoria, Victoria, BC, Canada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Victoria, Victoria, BC, Canada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Victoria, Victoria, BC, Canada]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>SIP: Optimal Product Selection from Feature Models Using Many-Objective Evolutionary Optimization</title>
		<link>https://biblioteca.sistedes.es/articulo/sip-optimal-product-selection-from-feature-models-using-many-objective-evolutionary-optimization/</link>
		<pubDate>Tue, 11 Jul 2017 03:32:42 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/?post_type=articulo&#038;p=2747</guid>
		<description></description>
		<content><![CDATA[Robert M. Hierons, Miqing Li, Xiaohui Liu, Sergio Segura, and Wei Zheng. 2016. SIP: Optimal Product Selection from Feature Models Using Many-Objective Evolutionary Optimization. ACM Trans. Softw. Eng. Methodol. 25, 2, Article 17 (April 2016), 39 pages. DOI: http://dx.doi.org/10.1145/2897760  Indicadores de calidad:   - Revista de referencia en el área de Ingeniería del Software (CS-SE: 21/106).   - Colaboración internacional con los profesores Robert Hierons [1] y XiaoHui Liu [2].  - Hemos sido invitados a presentar el trabajo en FSE16 e ICSE17 como parte de la iniciativa journal-first (ver programa de la conferencia [3]).   - Ha recibido 6 citas desde su publicación en abril de 2016 [4].   [1] http://dblp.uni-trier.de/pers/hd/h/Hierons:Robert_M= [2] http://dblp.uni-trier.de/pers/hd/l/Liu:Xiaohui [2] http://icse2017.gatech.edu/?q=technical-research-accepted [4] https://goo.gl/XyTmQR
]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2747</post_id>
		<post_date><![CDATA[2017-07-11 05:32:42]]></post_date>
		<post_date_gmt><![CDATA[2017-07-11 03:32:42]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[sip-optimal-product-selection-from-feature-models-using-many-objective-evolutionary-optimization]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>1</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="optimization"><![CDATA[Optimization]]></category>
		<category domain="post_tag" nicename="search-based-software-engineering"><![CDATA[Search-Based Software Engineering]]></category>
		<category domain="post_tag" nicename="software-product-lines"><![CDATA[software product lines]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2748]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/081]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[search-based software engineering,optimization,software product lines]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rob Hierons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Brunel University]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rob.hierons@brunel.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miqing Li]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Birmingham]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[limitsing@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Xiaohui Liu Liu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Birmingham]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[XiaoHui.Liu@brunel.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Seville]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Wei Zheng]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Northwestern Polytechnical University]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[wzheng@nwpu.edu.cn]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An approach driven by mobile agents for data management in vehicular networks</title>
		<link>https://biblioteca.sistedes.es/articulo/an-approach-driven-by-mobile-agents-for-data-management-in-vehicular-networks/</link>
		<pubDate>Tue, 11 Jul 2017 03:38:19 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/?post_type=articulo&#038;p=2750</guid>
		<description></description>
		<content><![CDATA[In the last years, and thanks to improvements on computing and communications technologies, wireless networks formed by vehicles (called vehicular networks) have emerged as a key topic of interest. In these networks, the vehicles can exchange data by using short-range radio signals in order to get useful information related to traffic conditions, road safety, and other aspects. The availability of different types of sensors can be exploited by the vehicles to measure many parameters from their surroundings. These data can then be shared with other drivers who, on the other side, could also explicitly submit queries to retrieve information available in the network. This can be a challenging task, since the data is scattered among the vehicles belonging to the network and the communication links among them have usually a short life due to their constant movement.   In this paper, we use mobile agent technology to help to accomplish these tasks, since mobile agents have a number of features that are very well suited for mobile environments, such as autonomy, mobility, and intelligence. Specifically, we analyze the benefits that mobile agents can bring to vehicular networks and the potential difficulties for their adoption. Moreover, we describe a query processing approach based on the use of mobile agents. We focus on range queries that retrieve interesting information from the vehicles located within a geographic area, and perform an extensive experimental evaluation that shows the feasibility and the interest of the proposal.
]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2750</post_id>
		<post_date><![CDATA[2017-07-11 05:38:19]]></post_date>
		<post_date_gmt><![CDATA[2017-07-11 03:38:19]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-approach-driven-by-mobile-agents-for-data-management-in-vehicular-networks]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>2</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="data-management"><![CDATA[data management]]></category>
		<category domain="post_tag" nicename="mobile-agents"><![CDATA[mobile agents]]></category>
		<category domain="post_tag" nicename="query-processing"><![CDATA[query processing]]></category>
		<category domain="post_tag" nicename="vehicular-ad-hoc-networks"><![CDATA[vehicular ad hoc networks]]></category>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[2751]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2017/082]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[keywords]]></meta_key>
			<meta_value><![CDATA[vehicular ad hoc networks,mobile agents,data management,query processing]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Oscar Urra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ourra@itainnova.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Ilarri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[silarri@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Raquel Trillo-Lado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[raqueltl@unizar.es]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>QL: Object-oriented Queries on Relational Data (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/ql-object-oriented-queries-on-relational-data-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:47 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/ql-object-oriented-queries-on-relational-data-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Paper already published at: European Conference on Object-Oriented Programming (ECOOP) 2016 This paper describes QL, a language for querying complex, potentially recursive data structures. QL compiles to Datalog and runs on a standard relational database, yet it provides familiar-looking object-oriented features such as classes and methods, reinterpreted in logical terms: classes are logical properties describing sets of values, subclassing is implication, and virtual calls are dispatched dynamically by considering the most specific classes containing the receiver. Furthermore, types in QL are prescriptive and actively influence program evaluation rather than just describing it. In combination, these features enable the development of concise queries based on reusable libraries, which are written in a purely declarative style, yet can be efficiently executed even on very large data sets. In particular, we have used QL to implement static analyses for various programming languages, which scale to millions of lines of code.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2903</post_id>
		<post_date><![CDATA[2018-07-26 06:17:47]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[ql-object-oriented-queries-on-relational-data-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="code-exploration"><![CDATA[Code-exploration]]></category>
		<category domain="post_tag" nicename="databases"><![CDATA[Databases]]></category>
		<category domain="post_tag" nicename="datalog"><![CDATA[Datalog]]></category>
		<category domain="post_tag" nicename="logic-programming"><![CDATA[Logic Programming]]></category>
		<category domain="post_tag" nicename="object-oriented-programming"><![CDATA[Object-oriented programming]]></category>
		<category domain="post_tag" nicename="queries"><![CDATA[Queries]]></category>
		<category domain="post_tag" nicename="relational-algebra"><![CDATA[Relational Algebra]]></category>
		<category domain="post_tag" nicename="static-analysis"><![CDATA[Static Analysis]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Paper already published at: European Conference on Object-Oriented Programming (ECOOP) 2016                                                                          This paper describes QL, a language for querying complex, potentially recursive data structures. QL compiles to Datalog and runs on a standard relational database, yet it provides familiar-looking object-oriented features such as classes and methods, reinterpreted in logical terms: classes are logical properties describing sets of values, subclassing is implication, and virtual calls are dispatched dynamically by considering the most specific classes containing the receiver. Furthermore, types in QL are prescriptive and actively influence program evaluation rather than just describing it. In combination, these features enable the development of concise queries based on reusable libraries, which are written in a purely declarative style, yet can be efficiently executed even on very large data sets. In particular, we have used QL to implement static analyses for various programming languages, which scale to millions of lines of code.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-002.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-002.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pavel Avgustinov]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[publications@semmle.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Semmle Ltd - United Kingdom]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Oege de Moor]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[publications@semmle.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Semmle Ltd - United Kingdom]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Michael Peyton Jones]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[publications@semmle.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Semmle Ltd - United Kingdom]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Max Schäfer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[max@semmle.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Semmle Ltd - United Kingdom]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/001]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Correct Compiler from Mini-ML to a Big-Step Machine Verified Using Natural Semantics in Coq (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-correct-compiler-from-mini-ml-to-a-big-step-machine-verified-using-natural-semantics-in-coq-en-progreso/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:47 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-correct-compiler-from-mini-ml-to-a-big-step-machine-verified-using-natural-semantics-in-coq-en-progreso/</guid>
		<description></description>
		<content><![CDATA[This work has the objective to present a simple, clear and intuitive framework for compilers verification of functional languages in the proof assistant Coq, that, as a final product, can obtain a standalone verified compiler capable of being used in real life. With this in mind, we propose to use natural semantics as unifying framework, that is to say, to use this formalism to define each of the compiler's components in order to perform this task. To show this method, we present a correct compiler of the small functional language with call by value Mini-ML, formalized in Coq. As a result of following this approach, we introduce a new big-step  machine inspired by Landin's SECD and Leroy's Modern SECD as target machine. To the best of the authors' knowledge, this is the first correct compiler that is verified by using natural semantics as unifying framework in Coq from which we can obtain a verified compiler capable of being used in real life.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2904</post_id>
		<post_date><![CDATA[2018-07-26 06:17:47]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-correct-compiler-from-mini-ml-to-a-big-step-machine-verified-using-natural-semantics-in-coq-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="abstract-machine"><![CDATA[abstract machine]]></category>
		<category domain="post_tag" nicename="big-step-machine"><![CDATA[Big-step machine]]></category>
		<category domain="post_tag" nicename="compiler-verification"><![CDATA[compiler verification]]></category>
		<category domain="post_tag" nicename="coq"><![CDATA[Coq]]></category>
		<category domain="post_tag" nicename="de-bruijn-indices"><![CDATA[de Bruijn indices]]></category>
		<category domain="post_tag" nicename="mini-ml"><![CDATA[Mini-ML]]></category>
		<category domain="post_tag" nicename="natural-semantics"><![CDATA[natural semantics]]></category>
		<category domain="post_tag" nicename="secd"><![CDATA[SECD]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper presents a correct compiler of a small functional language, Mini-ML, formalized in Coq. The literature of functional compiler verification in proof assistants usually reports the use of ad hoc formalizations. This work emphasized the use of natural semantics as uniform and unifying framework for this task. As a result of following this approach, a new big-step semantics machine with call by value is introduced, inspired by the SECD of Landin and the MSECD of Leroy. Since this machine uses de Bruijn indices, as first step is giving a (correct verified) translation from named Mini-ML to de Bruijn notation Mini-ML in the natural semantics setting. To the best of the author's knowledge, this is the first mechanization of a correct compiler of a functional language, using natural semantics as verifying framework in a proof assistant, such as, a working compiler capable to be used in real life can be obtained from it.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-003.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-003.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ángel Zúñiga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[zuniga@ciencias.unam.mx]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[UNAM - Mexico]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Gemma Bel-Enguix]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gbele@iingen.unam.mx]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[UNAM - Mexico]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/002]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Constraint Answer Set Programming without Grounding (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/constraint-answer-set-programming-without-grounding-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:47 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/constraint-answer-set-programming-without-grounding-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Extending ASP with constraints (CASP) enhances its expressiveness and performance. This extension is not straightforward as the grounding phase, present in most ASP systems, removes variables and the links among them, and also causes a combinatorial explosion in the size of the program. This has led CASP systems to devise several methods to overcome this issue: restricting the constraint domains (e.g., discrete instead of dense), where constraints can appear, or the type (or number) of models that can be returned. In this paper we propose to incorporate constraints into s(ASP), a goal-directed, top-down execution model which implements ASP while retaining logical variables both during execution and in the answer sets. The resulting model, s(CASP), can constrain variables that (as in CLP) are kept during the execution and in the answer sets. s(CASP) inherits and generalizes the execution model of s(ASP) while parameterizing the constraint solver. We describe this novel execution model and show, through several examples, the enhanced expressiveness of s(CASP) w.r.t. ASP, CLP, and other ASP systems with constraints. We also report improved performance w.r.t. other very mature, highly optimized ASP systems in some benchmarks.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2905</post_id>
		<post_date><![CDATA[2018-07-26 06:17:47]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[constraint-answer-set-programming-without-grounding-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="constraints"><![CDATA[constraints]]></category>
		<category domain="post_tag" nicename="goal-directed-evaluation"><![CDATA[goal-directed evaluation]]></category>
		<category domain="post_tag" nicename="predicate"><![CDATA[predicate]]></category>
		<category domain="post_tag" nicename="stable-model"><![CDATA[stable model]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Extending ASP with constraints (CASP) enhances its expressiveness and performance. This extension is not straightforward as the grounding phase, present in most ASP systems, removes variables and the links among them, and also causes a combinatorial explosion in the size of the program. This has led CASP systems to devise several methods to overcome this issue: restricting the constraint domains (e.g., discrete instead of dense), where constraints can appear, or the type (or number) of models that can be returned. In this paper we propose to incorporate constraints into s(ASP), a goal-directed, top-down execution model which implements ASP while retaining logical variables both during execution and in the answer sets. The resulting model, s(CASP), can constrain variables that (as in CLP) are kept during the execution and in the answer sets. s(CASP) inherits and generalizes the execution model of s(ASP) while parameterizing the constraint solver. We describe this novel execution model and show, through several examples, the enhanced expressiveness of s(CASP) w.r.t. ASP, CLP, and other ASP systems with constraints. We also report improved performance w.r.t. other very mature, highly optimized ASP systems in some benchmarks.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-004.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-004.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Joaquín Arias]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[joaquin.arias@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Carro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mcarro@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Technical University of Madrid (UPM) and IMDEA Software Institute - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Kyle Marple]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[kmarple1@utdallas.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[The University of Texas at Dallas - United States]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Elmer Salazar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[ees101020@utdallas.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[The University of Texas at Dallas - United States]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Gopal Gupta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[guptag@utdallas.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[The University of Texas at Dallas - United States]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/003]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Online Tool for Unfolding Symbolic Fuzzy Logic Programs (Demostración)</title>
		<link>https://biblioteca.sistedes.es/articulo/an-online-tool-for-unfolding-symbolic-fuzzy-logic-programs-demo/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:47 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-online-tool-for-unfolding-symbolic-fuzzy-logic-programs-demo/</guid>
		<description></description>
		<content><![CDATA[In many declarative frameworks, unfolding is a very well-known semantics-preserving transformation technique based on the application of computational steps on the bodies of program rules for improving efficiency. In this paper we describe an online tool which allows us to unfold a symbolic extension of a modern fuzzy logic language where program rules can embed concrete and/or symbolic fuzzy connectives and truth degrees on their bodies. The system offers a comfortable interaction with users for unfolding symbolic programs and it also provides useful options to navigate along the sequence of unfolded programs. Finally, the symbolic unfolding transformation is connected with some fuzzy tuning techniques that we previously implemented on the same tool.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2906</post_id>
		<post_date><![CDATA[2018-07-26 06:17:47]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:47]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-online-tool-for-unfolding-symbolic-fuzzy-logic-programs-demo]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="fuzzy-logic-programming"><![CDATA[Fuzzy Logic Programming]]></category>
		<category domain="post_tag" nicename="software-tools"><![CDATA[Software Tools]]></category>
		<category domain="post_tag" nicename="symbolic-execution"><![CDATA[symbolic execution]]></category>
		<category domain="post_tag" nicename="unfolding"><![CDATA[Unfolding]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In many declarative frameworks, unfolding is a very well-known semantics-preserving transformation technique based on the application of computational steps on the bodies of program rules for improving efficiency. In this paper we describe an online tool which allows us to unfold a symbolic extension of a modern fuzzy logic language where program rules can embed concrete and/or symbolic fuzzy connectives and truth degrees on their bodies. The system offers a comfortable interaction with users for unfolding symbolic programs and it also provides useful options to navigate along the sequence of unfolded programs. Finally, the symbolic unfolding transformation is connected with some fuzzy tuning techniques that we previously implemented on the same tool.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-005.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-005.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ginés Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[gines.moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Antonio Riaza Valverde]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[JoseAntonio.Riaza@alu.uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/004]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Rule formats for nominal process calculi (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/rule-formats-for-nominal-process-calculi-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/rule-formats-for-nominal-process-calculi-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Artículo publicado en CONCUR 2017. The nominal transition systems (NTSs) of Parrow et al. describe the operational semantics of nominal process calculi. We study NTSs in terms of the nominal residual transition systems (NRTSs) that we introduce. We provide rule formats for the specifications of NRTSs that ensure that the associated NRTS is an NTS and apply them to the operational specification of the early pi-calculus. Our study stems from the recent Nominal SOS of Cimini et al. and from earlier works in nominal sets and nominal logic by Gabbay, Pitts and their collaborators.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2907</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[rule-formats-for-nominal-process-calculi-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="nominal-sets"><![CDATA[nominal sets]]></category>
		<category domain="post_tag" nicename="nominal-structural-operational-semantics"><![CDATA[nominal structural operational semantics]]></category>
		<category domain="post_tag" nicename="nominal-transition-systems"><![CDATA[nominal transition systems]]></category>
		<category domain="post_tag" nicename="process-algebra"><![CDATA[process algebra]]></category>
		<category domain="post_tag" nicename="rule-formats"><![CDATA[rule formats]]></category>
		<category domain="post_tag" nicename="scope-opening"><![CDATA[scope opening]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Artículo publicado en CONCUR 2017.

The nominal transition systems (NTSs) of Parrow et al. describe the operational semantics of nominal process calculi. We study NTSs in terms of the nominal residual transition systems (NRTSs) that we introduce. We provide rule formats for the specifications of NRTSs that ensure that the associated NRTS is an NTS and apply them to the operational specification of the early pi-calculus. Our study stems from the recent Nominal SOS of Cimini et al. and from earlier works in nominal sets and nominal logic by Gabbay, Pitts and their collaborators.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-006.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-006.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Luca Aceto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[luca@ru.is]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ICE-TCS, School of Computer Science, Reykjavik University - Iceland]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ignacio Fábregas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ignacio.fabregas@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Álvaro García Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[alvaro.garcia.perez@imdea.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[IMDEA Software Institute - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Anna Ingólfsdóttir]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[annai@ru.is]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[ICE-TCS, School of Computer Science, Reykjavik University - Iceland]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Yolanda Ortega Mallén]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[yolanda@ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/005]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Semantic Analysis of SQL Statements in DES (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/semantic-analysis-of-sql-statements-in-des-en-progreso/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/semantic-analysis-of-sql-statements-in-des-en-progreso/</guid>
		<description></description>
		<content><![CDATA[This paper presents an on-going work that includes semantic analysis of SQL statements in the database system DES. Following Brass&amp;Goldberg, SQL statements, while syntactically correct, can exhibit symptoms of bad design. By warning users about such symptoms, both the learning curve of students as well as productivity of SQL practitioners can be enhanced. Some errors include inconsistent conditions, lack of correlations in joins, unused tuple variables and the like. Here, we describe the semantic checker developed for DES, which applies several techniques. In particular, it applies abstraction with CLP solving, and specific algorithms for the different kind of errors. This proposal has been implemented in the deductive system DES and available at des.sourceforge.net.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2908</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[semantic-analysis-of-sql-statements-in-des-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="constraint-logic-programming"><![CDATA[Constraint Logic Programming]]></category>
		<category domain="post_tag" nicename="datalog"><![CDATA[Datalog]]></category>
		<category domain="post_tag" nicename="semantic-analysis"><![CDATA[Semantic Analysis]]></category>
		<category domain="post_tag" nicename="sql"><![CDATA[SQL]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper presents an on-going work that includes semantic analysis of SQL statements in the database system DES. Following Brass&Goldberg, SQL statements, while syntactically correct, can exhibit symptoms of bad design. By warning users about such symptoms, both the learning curve of students as well as productivity of SQL practitioners can be enhanced. Some errors include inconsistent conditions, lack of correlations in joins, unused tuple variables and the like. Here, we describe the semantic checker developed for DES, which applies several techniques. In particular, it applies abstraction with CLP solving, and specific algorithms for the different kind of errors. This proposal has been implemented in the deductive system DES and available at des.sourceforge.net.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-007.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-007.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Fernando Sáenz Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fernan@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/006]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Analysis of Rewriting-Based Systems as First-Order Theories (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/analysis-of-rewriting-based-systems-as-first-order-theories-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/analysis-of-rewriting-based-systems-as-first-order-theories-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Computational systems based on a first-order language that can be given a *canonical model* which captures provability in the corresponding calculus can often be seen as first-order theories S, and computational properties of such systems can be formulated as first-order sentences F that hold in such a canonical model of S. In this setting, standard results regarding the *preservation* of satisfiability of different classes of first-order sentences yield a number of interesting applications in program analysis. In particular, properties expressed as existentially quantified boolean combinations of atoms (for instance, a set of *unification problems*) can then be *disproved* by just finding an *arbitrary* model of the considered theory plus the *negation* of such a sentence. We show that rewriting-based systems fit into this approach. Many computational properties (e.g., infeasibility and non-joinability of critical pairs in (conditional) rewriting, non-loopingness, or the secure access to protected pages of a web site) can be investigated in this way. Interestingly, this semantic approach succeeds when specific techniques developed to deal with the aforementioned problems fail.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2909</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analysis-of-rewriting-based-systems-as-first-order-theories-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="logical-models"><![CDATA[Logical models]]></category>
		<category domain="post_tag" nicename="program-analysis"><![CDATA[Program analysis]]></category>
		<category domain="post_tag" nicename="rewriting-based-systems"><![CDATA[Rewriting-based systems]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Computational systems based on a first-order language that can be given a *canonical model* which captures provability in the corresponding calculus can often be seen as first-order theories S, and computational properties of such systems can be formulated as first-order sentences F that hold in such a canonical model of S. In this setting, standard results regarding the *preservation* of satisfiability of different classes of first-order sentences yield a number of interesting applications in program analysis. In particular, properties expressed as existentially quantified boolean combinations of atoms (for instance, a set of *unification problems*) can then be *disproved* by just finding an *arbitrary* model of the considered theory plus the *negation* of such a sentence. We show that rewriting-based systems fit into this approach. Many computational properties (e.g., infeasibility and non-joinability of critical pairs in (conditional) rewriting, non-loopingness, or the secure access to protected pages of a web site) can be investigated in this way. Interestingly, this semantic approach succeeds when specific techniques developed to deal with the aforementioned problems fail.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-008.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-008.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Lucas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[slucas@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/007]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Exercise in Proving Red-Black Trees Correct (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/an-exercise-in-proving-red-black-trees-correct-en-progreso/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-exercise-in-proving-red-black-trees-correct-en-progreso/</guid>
		<description></description>
		<content><![CDATA[Red-black trees are an efficient data structure that constitutes the basis for implementing maps, multimaps, sets and multisets, in the standard libraries of many programming languages. It achieves logarithmic costs for searching, inserting, and deleting keys, but keeping them balanced frequently requires to deal with a high number of cases. However, a variant called "Left-Leaning", due to Robert Sedgewick, reduces the number of cases to a few ones. We present here a functional version of these red-black trees and prove them correct with respect to a model-based specification, being the model of a red-black tree a set of elements. We have used the Dafny verification platform, which provides the programming language, the assertion language, and the verifier. The latter is an up-to-date SMT solver (Satisfiability Modulo Theories), which can deal with a rather large decidable fragment of the first-order logic.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2910</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-exercise-in-proving-red-black-trees-correct-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="balanced-trees"><![CDATA[Balanced Trees]]></category>
		<category domain="post_tag" nicename="data-structures"><![CDATA[Data Structures]]></category>
		<category domain="post_tag" nicename="formal-verification"><![CDATA[Formal Verification]]></category>
		<category domain="post_tag" nicename="verification-platforms"><![CDATA[verification platforms]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Red-black trees are an efficient data structure that constitutes the basis for implementing maps, multimaps, sets and multisets, in the standard libraries of many programming languages. It achieves logarithmic costs for searching, inserting, and deleting keys, but keeping them balanced frequently requires to deal with a high number of cases. However, a variant called "Left-Leaning", due to Robert Sedgewick, reduces the number of cases to a few ones. We present here a functional version of these red-black trees and prove them correct with respect to a model-based specification, being the model of a red-black tree a set of elements.

We have used the Dafny verification platform, which provides the programming language, the assertion language, and the verifier. The latter is an up-to-date SMT solver (Satisfiability Modulo Theories), which can deal with a rather large decidable fragment of the first-order logic.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-009.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-009.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ricardo Peña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ricardo@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/008]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Directions of Operational Termination (Trabajo original)</title>
		<link>https://biblioteca.sistedes.es/articulo/directions-of-operational-termination-original/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/directions-of-operational-termination-original/</guid>
		<description></description>
		<content><![CDATA[A theory S in a logic supplied with an inference system is operationally terminating if no goal has an infinite well-formed proof tree. Well-formed proof trees are those which an interpreter would incrementally build when trying to solve a condition at a time from left to right. For this reason, infinite well-formed proof trees have a unique infinite branch which is called the spine. This paper introduces the notion of a directed proof tree for S and a set of formulas Δ, which we call a direction. Intuitively, a direction Δ is intended to collect formulas that are infinitely often used in the spine of an infinite well-formed proof tree (which is then called Δ-directed) due to the repeated use of some specific inference rules. Then we introduce the notion of Δ-directed operational termination of a theory as the absence of Δ-directed proof trees. This new notion permits the definition of different termination properties which can be useful to distinguish different computational behaviors. It also gives a new characterization of operational termination of a (finite) theory S as the conjunction of the Δ-directed operational termination of S for each direction Δ in a (finite) set of directions.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2911</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[directions-of-operational-termination-original]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="general-logics"><![CDATA[General Logics]]></category>
		<category domain="post_tag" nicename="operational-termination"><![CDATA[Operational Termination]]></category>
		<category domain="post_tag" nicename="program-termination"><![CDATA[Program Termination]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A theory S in a logic supplied with an inference system is operationally terminating if no goal has an infinite well-formed proof tree. Well-formed proof trees are those which an interpreter would incrementally build when trying to solve a condition at a time from left to right. For this reason, infinite well-formed proof trees have a unique infinite branch which is called the spine. This paper introduces the notion of a directed proof tree for S and a set of formulas ?, which we call a direction. Intuitively, a direction ? is intended to collect formulas that are infinitely often used in the spine of an infinite well-formed proof tree (which is then called ?-directed) due to the repeated use of some specific inference rules. Then we introduce the notion of ?-directed operational termination of a theory as the absence of ?-directed proof trees. This new notion permits the definition of different termination properties which can be useful to distinguish different computational behaviors. It also gives a new characterization of operational termination of a (finite) theory S as the conjunction of the ?-directed operational termination of S for each direction ? in a (finite) set of directions.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-010.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-010.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Lucas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[slucas@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/009]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Event-driven Interval Temporal Logic for Hybrid Systems (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/an-event-driven-interval-temporal-logic-for-hybrid-systems-en-progreso/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-event-driven-interval-temporal-logic-for-hybrid-systems-en-progreso/</guid>
		<description></description>
		<content><![CDATA[Nowadays, hybrid systems are present in many crucial tasks of our daily life. The hybrid character derives from the merge of continuous and discrete dynamics that are intrinsically related. The verification of critical properties of hybrid systems is of special importance, but sometimes it is not feasible due to their inherent complexity. In the last few years, several model-based testing and runtime verification techniques have been proposed to support the verification and validation of hybrid systems. In this paper, we present an interval logic that is suitable for specifying properties of event-driven hybrid systems. We introduce the syntax and semantics of the logic, and propose an automatic mechanism to transform each logic formula into a network of timed automata that can act as observers of the property in each test case using the UPPAAL tool.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2912</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-event-driven-interval-temporal-logic-for-hybrid-systems-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="interval-temporal-logic"><![CDATA[interval temporal logic]]></category>
		<category domain="post_tag" nicename="timed-automata"><![CDATA[Timed automata]]></category>
		<category domain="post_tag" nicename="uppaal"><![CDATA[uppaal]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Nowadays, hybrid systems are present in many crucial tasks of our daily life. The hybrid character derives from the merge of continuous and discrete dynamics that are intrinsically related. The verification of critical properties of hybrid systems is of special importance, but sometimes it is not feasible due to their inherent complexity. In the last few years, several model-based testing and
runtime verification techniques have been proposed to support the verification and validation of hybrid systems. In this paper, we present an interval logic that is suitable for specifying properties of event-driven hybrid systems. We introduce the syntax and semantics of the logic, and propose an automatic mechanism to transform each logic formula into a network of timed automata that can act as observers of the property in each test case using the UPPAAL tool.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-011.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-011.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Maria del Mar Gallardo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[gallardo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Laura Panizo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[laurapanizo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/010]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Datalog Framework for Modeling Relationship-based Access Control Policies (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-datalog-framework-for-modeling-relationship-based-access-control-policies-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-datalog-framework-for-modeling-relationship-based-access-control-policies-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Relationships like friendship to limit access to resources have been part of social network applications since their beginnings. Describing access control policies in terms of relationships is not particular to social networks and it arises naturally in many situations. Hence, we have recently seen several proposals formalizing different Relationship-based Access Control (ReBAC) models. In this paper, we introduce a class of Datalog programs suitable for modeling ReBAC and argue that this class of programs, that we called ReBAC Datalog policies, provides a very general framework to specify and implement ReBAC policies. To support our claim, we first formalize the merging of two recent proposals for modeling ReBAC, one based on hybrid logic and the other one based on path regular expressions. We present extensions to handle negative authorizations and temporal policies. We describe mechanism for policy analysis, and then discuss the feasibility of using Datalog-based systems as implementations.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2913</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-datalog-framework-for-modeling-relationship-based-access-control-policies-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="datalog"><![CDATA[Datalog]]></category>
		<category domain="post_tag" nicename="relationship-based-access-control"><![CDATA[Relationship-based Access Control]]></category>
		<category domain="post_tag" nicename="security-and-privacy-policies"><![CDATA[Security and privacy policies]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Relationships like friendship to limit access to resources have been part of social network applications since their beginnings. Describing access control policies in terms of relationships is not particular to social networks and it arises naturally in many situations. Hence, we have recently seen several proposals formalizing different Relationship-based Access Control (ReBAC) models. In this paper, we introduce a class of Datalog programs suitable for modeling
ReBAC and argue that this class of programs, that we called ReBAC Datalog policies, provides a very general framework to specify and implement ReBAC policies. To support our claim, we first formalize the merging of two recent proposals for modeling ReBAC, one based on hybrid logic and the other one based on path regular expressions. We present extensions to handle negative authorizations and temporal policies. We describe mechanism for policy analysis, and then discuss the feasibility of using Datalog-based systems as implementations.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-012.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-012.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Edelmira Pasarella]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[edelmira@lsi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jorge Lobo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jorge.lobo@upf.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Institució Catalana de Recerca i Estudis Avançats (ICREA)-Universitat Pompeu Fabra, Barcelona, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/011]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>The 2D Dependency Pair Framework for conditional rewrite systems (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/the-2d-dependency-pair-framework-for-conditional-rewrite-systems-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/the-2d-dependency-pair-framework-for-conditional-rewrite-systems-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Different termination properties of conditional term rewriting systems have been recently described emphasizing the bidimensional nature of the termination behavior of conditional rewriting. The absence of infinite sequences of rewriting steps (termination in the usual sense), provides the horizontal dimension. The absence of infinitely many attempts to launch the subsidiary processes that are required to check the rule’s condition and perform a single rewriting step has been called V-termination and provides the vertical dimension. We have characterized these properties by means of appropriate notions of dependency pairs and dependency chains. In this paper we introduce a 2D Dependency Pair Framework for automatically proving and disproving all these termination properties. Our implementation of the framework as part of the termination tool MU-TERM and the benchmarks obtained so far suggest that the 2D Dependency Pair Framework is currently the most powerful technique for proving operational termination of conditional term rewriting systems.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2914</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[the-2d-dependency-pair-framework-for-conditional-rewrite-systems-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="conditional-term-rewriting"><![CDATA[Conditional term rewriting]]></category>
		<category domain="post_tag" nicename="dependency-pairs"><![CDATA[dependency pairs]]></category>
		<category domain="post_tag" nicename="operational-termination"><![CDATA[Operational Termination]]></category>
		<category domain="post_tag" nicename="program-analysis"><![CDATA[Program analysis]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Different termination properties of conditional term rewriting systems have been recently described emphasizing the bidimensional nature of the termination behavior of conditional rewriting. The absence of infinite sequences of rewriting steps (termination in the usual sense), provides the horizontal dimension. The absence of infinitely many attempts to launch the subsidiary processes that are required to check the rule’s condition and perform a single rewriting step has been called V-termination and provides the vertical dimension. We have characterized these properties by means of appropriate notions of dependency pairs and dependency chains. In this paper we introduce a 2D Dependency Pair Framework for automatically proving and disproving all these termination properties. Our implementation of the framework as part of the termination tool MU-TERM and the benchmarks obtained so far suggest that the 2D Dependency Pair Framework is currently the most powerful technique for proving operational termination of conditional term rewriting systems.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-013.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-013.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Salvador Lucas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[slucas@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Meseguer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[meseguer@cs.uiuc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Illinois at Urbana-Champaign - United States]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Raúl Gutiérrez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[rgutierrez11@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/012]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Efficient Proximity-based Unification Algorithm (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/an-efficient-proximity-based-unification-algorithm-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-efficient-proximity-based-unification-algorithm-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Unification is a central concept in deductive systems based on the resolution principle. Recently, we introduced a new weak unification algorithm based on proximity relations (i.e., reflexive, symmetric, fuzzy binary relations). Proximity relations are able to manage vague or imprecise information and, in combination with the unification algorithm, allow certain forms of approximate reasoning in a logic programming framework. In this paper, we present a reformulation of the weak unification algorithm and an elaborated method to implement it efficiently. [This work has been accepted for its presentation at the 27th IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2018)]]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2915</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-efficient-proximity-based-unification-algorithm-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="fuzzy-logic-programming"><![CDATA[Fuzzy Logic Programming]]></category>
		<category domain="post_tag" nicename="fuzzy-prolog"><![CDATA[Fuzzy Prolog]]></category>
		<category domain="post_tag" nicename="proximity-relations"><![CDATA[Proximity Relations]]></category>
		<category domain="post_tag" nicename="weak-unification"><![CDATA[Weak Unification]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Unification is a central concept in deductive systems based on the resolution principle. Recently, we introduced a new weak unification algorithm based on proximity relations (i.e., reflexive, symmetric, fuzzy binary relations). Proximity relations are able to manage vague or imprecise information and, in combination with the unification algorithm, allow certain forms of approximate reasoning in a logic programming framework. In this paper, we present a reformulation of the weak unification algorithm and an elaborated method to implement it efficiently.

[This work has been accepted for its presentation at the 27th IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2018)]]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-014.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-014.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pascual Julián Iranzo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pascual.julian@uclm.es ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando Sáenz Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fernan@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/013]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Institutions for navigational logics for graphical structures (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/institutions-for-navigational-logics-for-graphical-structures-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/institutions-for-navigational-logics-for-graphical-structures-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[We show that a Navigational Logic, i.e., a logic to express properties about graphs and about paths in graphs is a semi-exact institution. In this way, we can use a number of operations to structure and modularize our specifications. Moreover, using the properties of our institution, we also show how to structure single formulas, which in our formalism could be quite complex. Article in press in Theoretical Computer Science (2018) https://doi.org/10.1016/j.tcs.2018.02.031]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2916</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[institutions-for-navigational-logics-for-graphical-structures-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="graph-logics"><![CDATA[Graph logics]]></category>
		<category domain="post_tag" nicename="institutions"><![CDATA[Institutions]]></category>
		<category domain="post_tag" nicename="navigational-logics"><![CDATA[Navigational logics]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We show that a Navigational Logic, i.e., a logic to express properties about graphs and about paths in graphs is a semi-exact institution. In this way, we can use a number of operations to structure and modularize our specifications. Moreover, using the properties of our institution, we also show how to structure single formulas, which in our formalism could be quite complex.

Article in press in Theoretical Computer Science (2018)
https://doi.org/10.1016/j.tcs.2018.02.031]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-015.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-015.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Fernando Orejas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[orejas@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Elvira Pino ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pino@cs.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Marisa Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[marisa.navarro@ehu.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU) - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Leen Lambers]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Leen.Lambers@hpi.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Hasso Plattner Institut, University of Potsdam - Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/014]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Behaviour Preservation across Code Versions in Erlang (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/behaviour-preservation-across-code-versions-in-erlang-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/behaviour-preservation-across-code-versions-in-erlang-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[In any alive and non-trivial program, the source code naturally evolves along the lifecycle for many reasons such as the implementation of new functionality, the optimisation of a bottle-neck, the refactoring of an obscure function, etc. Frequently, these code changes affect various different functions and modules, so it can be difficult to know whether the correct behaviour of the previous version has been preserved in the new version. In this paper, we face this problem in the context of the Erlang language, where most developers rely on a previously defined test suite to check the behaviour preservation. We propose an alternative approach to automatically obtain a test suite that specifically focusses on comparing the old and new versions of the code. Our test case generation is directed by a sophisticated combination of several already existing tools such as TypEr, CutEr, and PropEr; and it introduces novel ideas such as allowing the programmer to choose one or more expressions of interest that must preserve the behaviour, or the recording of the sequences of values to which those expressions are evaluated. All the presented work has been implemented in an open-source tool that is publicly available on GitHub.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2917</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[behaviour-preservation-across-code-versions-in-erlang-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="automated-regression-testing"><![CDATA[Automated regression testing]]></category>
		<category domain="post_tag" nicename="code-evolution-control"><![CDATA[Code evolution control]]></category>
		<category domain="post_tag" nicename="tracing"><![CDATA[Tracing]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In any alive and non-trivial program, the source code naturally evolves along the lifecycle for many reasons such as the implementation of new functionality, the optimisation of a bottle-neck, the refactoring of an obscure function, etc. Frequently, these code changes affect various different functions and modules, so it can be difficult to know whether the correct behaviour of the previous version has been preserved in the new version. In this paper, we face this problem in the context of the Erlang language, where most developers rely on a previously defined test suite to check the behaviour preservation. We propose an alternative approach to automatically obtain a test suite that specifically focusses on comparing the old and new versions of the code. Our test case generation is directed by a sophisticated combination of several already existing tools such as TypEr, CutEr, and PropEr; and it introduces novel ideas such as allowing the programmer to choose one or more expressions of interest that must preserve the behaviour, or the recording of the sequences of values to which those expressions are evaluated. All the presented work has been implemented in an open-source tool that is publicly available on GitHub.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-016.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-016.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Insa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[dinsa@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València  - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Pérez Rubio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sergio.perez.rubio@hotmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València  - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Josep Silva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jsilva@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València  - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Salvador Tamarit]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[stamarit@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València  - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/015]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Modeling Systems and Proving their Correctness with Event-B and Rodin (Tutorial)</title>
		<link>https://biblioteca.sistedes.es/articulo/modeling-systems-and-proving-their-correctness-with-event-b-and-rodin-tutorial/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/modeling-systems-and-proving-their-correctness-with-event-b-and-rodin-tutorial/</guid>
		<description></description>
		<content><![CDATA[Event-B is a formal development method. It can be used to model and verify correctness of sequential, concurrent, and reactive systems. It uses (infinite) discrete transition systems to capture how the model evolves and first-order logic and typed set theory to express the desirable properties of the system. The proofs that these properties hold are performed using sequent calculus. There are deduction rules specific for useful theories. Event-B is however is not restricted to classical set-theoretical notations and the sequent calculus: it includes notations for defining transitions over states of the model which resembles a programming language, and a rich mathematical toolkit (including operations and relations on sets and functions) to build complex models easily.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2918</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[modeling-systems-and-proving-their-correctness-with-event-b-and-rodin-tutorial]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="correctness-by-construction"><![CDATA[Correctness by Construction]]></category>
		<category domain="post_tag" nicename="formal-proofs"><![CDATA[Formal proofs]]></category>
		<category domain="post_tag" nicename="rigorous-software-development"><![CDATA[Rigorous software development]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Event-B is a formal development method. It can be used to model and verify correctness of sequential, concurrent, and reactive systems. It uses (infinite) discrete transition systems to capture how the model evolves and first-order logic and typed set theory to express the desirable properties of the system. The proofs that these properties hold are performed using sequent calculus. There are deduction rules specific for useful theories. Event-B is however is
not restricted to classical set-theoretical notations and the sequent calculus: it includes notations for defining transitions over states of the model which resembles a programming language, and a rich mathematical toolkit (including operations and relations on sets and functions) to build complex models easily.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-017.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-017.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel Carro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mcarro@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Technical University of Madrid (UPM) and IMDEA Software Institute - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/016]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Efficient Characterization of Petri Net Solvable Binary Words (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/an-efficient-characterization-of-petri-net-solvable-binary-words-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-efficient-characterization-of-petri-net-solvable-binary-words-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[We present a simple characterization of the set of Petri net solvable binary words. It states that they are exactly the extensions of the prefixes of Petri net cyclic solvable words, by some prefix x^k, where x is any letter of the binary alphabet being considered, and k is any natural number. We derive several consequences of this characterization which, in a way, shows that the set of solvable words is smaller than expected. Therefore, the existing conjecture that all of them can be generated by quite simple net is not only confirmed, but indeed reinforced. As a byproduct of the characterization, we also present a linear time algorithm for deciding whether a binary word is solvable. The key idea is that the connection with the cyclic solvable words induces certain structural regularity. Therefore, one just needs to look for possible irregularities, which can be done in a structural way, resulting in a rather surprising linearity of the decision algorithm. Finally, we employ the obtained results to provide a characterization of reversible binary transition systems. Artículo aceptado para su presentación en Petri Nets 2018 - The 39th International Conference on Applications and Theory of Petri Nets and Concurrency. Bratislava, Slovakia, June 24-29, 2018. Los "proceedings" serán publicados en el Volumen 10877 de la serie LNCS de Springer.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2919</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-efficient-characterization-of-petri-net-solvable-binary-words-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="binary-transition-systems"><![CDATA[Binary transition systems]]></category>
		<category domain="post_tag" nicename="binary-words"><![CDATA[Binary words]]></category>
		<category domain="post_tag" nicename="petri-nets"><![CDATA[Petri nets]]></category>
		<category domain="post_tag" nicename="reversibility"><![CDATA[Reversibility]]></category>
		<category domain="post_tag" nicename="word-solvability"><![CDATA[Word solvability]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[We present a simple characterization of the set of Petri net solvable binary words. It states that they are exactly the extensions of the prefixes of Petri net cyclic solvable words, by some prefix x^k, where x is any letter of the binary alphabet being considered, and k is any natural number. We derive several consequences of this characterization which, in a way, shows that the set of solvable words is smaller than expected. Therefore, the existing conjecture that all of them can be generated by quite simple net is not only confirmed, but indeed reinforced. As a byproduct of the characterization, we also present a linear time algorithm for deciding whether a binary word is solvable. The key
idea is that the connection with the cyclic solvable words induces certain
structural regularity. Therefore, one just needs to look for possible irregularities, which can be done in a structural way, resulting in a rather surprising linearity of the decision algorithm. Finally, we employ the obtained results to provide a characterization of reversible binary transition systems.

Artículo aceptado para su presentación en Petri Nets 2018 - The 39th International Conference on Applications and Theory of Petri Nets and Concurrency. Bratislava, Slovakia, June 24-29, 2018.

Los "proceedings" serán publicados en el Volumen 10877 de la serie LNCS de Springer.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-018.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-018.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David de Frutos Escrig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[defrutos@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Maciej Koutny]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[maciej.koutny@ncl.ac.uk]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Newcastle University - United Kingdom]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Lukasz Mikulski]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lukasz.mikulski@mat.umk.pl]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Nicolaus Copernicus University - Torun - Poland]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/017]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una librería para inteligencia de enjambre basada en la programación funcional (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/una-libreria-para-inteligencia-de-enjambre-basada-en-la-programacion-funcional-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/una-libreria-para-inteligencia-de-enjambre-basada-en-la-programacion-funcional-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[En este trabajo presentamos una librerÌa de esqueletos paralelos para manejar metaheurÌsticas basadas en inteligencia de enjambre. La librerÌa está implementada utilizando el lenguaje de programación funcional paralelo Eden, una extensión del lenguaje funcional Haskell. Gracias al orden superior presente en el lenguaje funcional, se simplifican las tareas de desarrollar código genérico, facilitando también la comparación entre distintas metaheurÌsticas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2920</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-libreria-para-inteligencia-de-enjambre-basada-en-la-programacion-funcional-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="functional-programming"><![CDATA[functional programming]]></category>
		<category domain="post_tag" nicename="metaheuristics"><![CDATA[Metaheuristics]]></category>
		<category domain="post_tag" nicename="parallel-programming"><![CDATA[Parallel programming]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[IIn this paper we present a library of parallel skeletons to deal with swarm intelligence metaheuristics. The library is implemented using the parallel functional language Eden, an extension of the sequential functional language Haskell. Due to the higher-order nature of functional languages, we simplify the task of writing generic code, and also the task of comparing different strategies. The paper illustrates how to develop new skeletons and presents empirical results.

The complete version of the paper was accepted for publication in IWANN 2017. The paper can be obtained at
https://link.springer.com/chapter/10.1007%2F978-3-319-59153-7_1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-019.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-019.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Fernando Rubio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fernando@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alberto de la Encina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[albertoe@sip.ucm.es ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pablo Rabanal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[prabanal@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Ismael Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[isrodrig@sip.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/018]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Context-based Model Checking using SMT-solvers (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/context-based-model-checking-using-smt-solvers-en-progreso/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/context-based-model-checking-using-smt-solvers-en-progreso/</guid>
		<description></description>
		<content><![CDATA[In this paper we propose a new idea for the implementation of symbolic model checking. Our pro- posal takes advantage of two technologies. First, SMT-solvers as efficient auxiliary tools to perform a large proportion of the computational task. Second, the context-based tableau that is especially well suited for providing certificates of proved properties, as well as counterexamples of disproved properties. We mainly introduce the algorithm to be implemented, along with illustrative examples.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2921</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[context-based-model-checking-using-smt-solvers-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="model-checking"><![CDATA[Model checking]]></category>
		<category domain="post_tag" nicename="sat"><![CDATA[SAT]]></category>
		<category domain="post_tag" nicename="smt"><![CDATA[SMT]]></category>
		<category domain="post_tag" nicename="solvers"><![CDATA[Solvers]]></category>
		<category domain="post_tag" nicename="tableux"><![CDATA[Tableux]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper we propose a new idea for the implementation of symbolic model checking. Our pro- posal takes advantage of two technologies. First, SMT-solvers as efficient auxiliary tools to perform a large proportion of the computational task. Second, the context-based tableau that is especially well suited for providing certificates of proved properties, as well as counterexamples of disproved properties. We mainly introduce the algorithm to be implemented, along with illustrative examples.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-020.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-020.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alex Abuin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aabuin@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Ik4-Ikerlan - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Unai Díaz de Cerio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[udiazcerio@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Ik4-Ikerlan - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Montserrat Hermo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[montserrat.hermo@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU) - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Paqui Lucio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[paqui.lucio@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU) - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/019]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Constrained Dynamic Partial Order Reduction (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/constrained-dynamic-partial-order-reduction-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/constrained-dynamic-partial-order-reduction-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[The cornerstone of dynamic partial order reduction (DPOR) is the notion of independence that is used to decide whether each pair of concurrent events p and t are in a race and thus both p·t and t·p must be explored. We present constrained dynamic partial order reduction (CDPOR), an extension of the DPOR framework which is able to avoid redundant explorations based on the notion of conditional independence —the execution of p and t commutes only when certain independence constraints (ICs) are satisfied. ICs can be declared by the programmer, but importantly, we present a novel SMT-based approach to automatically synthesize ICs in a static pre-analysis. A unique feature of our approach is that we have succeeded to exploit ICs within the state-of-the-art DPOR algorithm, achieving exponential reductions over existing implementations.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2922</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[constrained-dynamic-partial-order-reduction-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="conditional-independence"><![CDATA[Conditional Independence]]></category>
		<category domain="post_tag" nicename="dynamic-partial-order-reduction"><![CDATA[Dynamic Partial Order Reduction]]></category>
		<category domain="post_tag" nicename="model-checking"><![CDATA[Model checking]]></category>
		<category domain="post_tag" nicename="smt"><![CDATA[SMT]]></category>
		<category domain="post_tag" nicename="static-analysis"><![CDATA[Static Analysis]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The cornerstone of dynamic partial order reduction (DPOR) is the notion of independence that is used to decide whether each pair of concurrent events p and t are in a race and thus both p·t and t·p must be explored. We present constrained dynamic partial order reduction (CDPOR), an extension of the DPOR framework which is able to avoid redundant explorations based on the notion of conditional independence —the execution of p and t commutes only when certain independence constraints (ICs) are satisfied. ICs can be declared by the programmer, but importantly, we present a novel SMT-based approach to automatically synthesize ICs in a static pre-analysis. A unique feature of our
approach is that we have succeeded to exploit ICs within the state-of-the-art DPOR algorithm, achieving exponential reductions over existing implementations.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-021.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-021.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/020]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Fuzzy Queries of Social Networks involving Sentiment Analysis and Topic Detection (Trabajo en progreso)</title>
		<link>https://biblioteca.sistedes.es/articulo/fuzzy-queries-of-social-networks-involving-sentiment-analysis-and-topic-detection-en-progreso/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:48 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/fuzzy-queries-of-social-networks-involving-sentiment-analysis-and-topic-detection-en-progreso/</guid>
		<description></description>
		<content><![CDATA[Social networks have become a source of data which are of interest in all areas, and their querying and analysis is a hot topic in computer science. Our research group has developed a fuzzy extension of the Semantic Web query language SPARQL, called FSA-SPARQL (Fuzzy Sets and Aggregators based SPARQL). This extension provides mechanisms to express fuzzy queries against RDF data. FSA-SPARQL works with social networks. With this aim, FSA-SPARQL enables the transformation and fuzzification of social network API data. Fuzzification of social networks data is automatic and user-defined enabling a wide range of mechanisms for ranking and categorization, including sentiment analysis and topic detection. As case study, FSA-SPARQL has been used to query three well-known social networks: Twitter, Foursquare and TMDb.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2923</post_id>
		<post_date><![CDATA[2018-07-26 06:17:48]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:48]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[fuzzy-queries-of-social-networks-involving-sentiment-analysis-and-topic-detection-en-progreso]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="fuzzy-logic"><![CDATA[Fuzzy Logic]]></category>
		<category domain="post_tag" nicename="semantic-web"><![CDATA[Semantic Web]]></category>
		<category domain="post_tag" nicename="social-networks"><![CDATA[Social Networks]]></category>
		<category domain="post_tag" nicename="sparql"><![CDATA[SPARQL]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Social networks have become a source of data which are of interest in all areas, and their querying and analysis is a hot topic in computer science. Our research group has developed a fuzzy extension of the Semantic Web query language SPARQL, called FSA-SPARQL (Fuzzy Sets and Aggregators based SPARQL). This extension provides mechanisms to express fuzzy queries against RDF data. FSA-SPARQL works with social networks. With this aim, FSA-SPARQL enables the transformation and fuzzification of social network API data. Fuzzification of social networks data is automatic and user-defined enabling a wide range of mechanisms for ranking and categorization, including sentiment analysis and topic detection. As case study, FSA-SPARQL has been used to query three well-known social networks: Twitter, Foursquare and TMDb.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-022.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-022.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús M. Almendros Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jalmen@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Almeria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Becerra Terón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[abecerra@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Almeria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ginés Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[gines.moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/021]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An extension of TRIANGLE testbed with model-based testing (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/an-extension-of-triangle-testbed-with-model-based-testing-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-extension-of-triangle-testbed-with-model-based-testing-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Traditional testing methods for mobile apps focus on detecting execution errors. However, the evolution of mobile networks towards 5G will require additional support for app developers to ensure also the performance and user-experience. Manual testing in a number of scenarios is not enough to satisfy the expectations of the apps final users. This paper presents the testing framework developed in the TRIANGLE project1 that integrates a complete mobile network testbed and a model-based testing approach, which is based on model checking, to automatically evaluate the apps performance in different network scenarios.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2924</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-extension-of-triangle-testbed-with-model-based-testing-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mobile-network-testbed"><![CDATA[mobile network testbed]]></category>
		<category domain="post_tag" nicename="model-checking"><![CDATA[Model checking]]></category>
		<category domain="post_tag" nicename="model-based-testing"><![CDATA[model-based testing]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Traditional testing methods for mobile apps focus on detecting execution errors. However, the evolution of mobile networks towards 5G will require additional support for app developers to ensure also the performance and user-experience. Manual testing in a number of scenarios is not enough to satisfy the expectations of the apps final users. This paper presents the testing framework developed in the TRIANGLE project1 that integrates a complete mobile network testbed and a model-based testing approach, which is based on model checking, to automatically evaluate the apps performance in different network scenarios.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-024.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-024.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Laura Panizo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[laurapanizo@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Almudena Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[almudiaz@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Bruno García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[bgarcia@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/022]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Tool Demonstration: Testing JSON Web Services Using Jsongen (Demostración)</title>
		<link>https://biblioteca.sistedes.es/articulo/tool-demonstration-testing-json-web-services-using-jsongen-demo/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/tool-demonstration-testing-json-web-services-using-jsongen-demo/</guid>
		<description></description>
		<content><![CDATA[This article describes a tool, jsongen, which permits testing behavioural aspects of Web Services that communicate using the JSON data format. Provided a characterisation of the JSON data as a JSON schema, the jsongen tool will:(i) automatically derive a QuickCheck (the property-based testing tool)generator which can generate an infinite number of JSON values that validate against the schema, and (ii) provides a generic QuickCheck state machine which is capable of following the (hyper)links documented in the JSON schema, to automatically explore the web service. The default behaviour of the state machine can be easily customized to include web service specific checks. The approach is demonstrated by applying it to the task of testing a simplified web service for banking.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2925</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[tool-demonstration-testing-json-web-services-using-jsongen-demo]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="analysis-tools"><![CDATA[Analysis tools]]></category>
		<category domain="post_tag" nicename="json"><![CDATA[JSON]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<category domain="post_tag" nicename="web-services"><![CDATA[web services]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This article describes a tool, jsongen, which permits testing behavioural aspects of Web Services that communicate using the JSON data format. Provided a characterisation of the JSON data as a JSON schema, the jsongen tool will:
(i) automatically derive a QuickCheck (the property-based testing tool)
generator which can generate an infinite number of JSON values that validate against the schema, and (ii) provides a generic QuickCheck state machine which is capable of following the (hyper)links documented in the JSON schema, to automatically explore the web service. The default behaviour of the state machine can be easily customized to include web service specific checks. The approach is demonstrated by applying it to the task of testing a simplified web service for banking.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-025.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-025.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ignacio Ballesteros]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ignacioballesterosgonzalez@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Luis Eduardo Bueso de Barrio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[luiseduardo.bueso.debarrio@alumnos.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Lars-Ake Fredlund]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lfredlund@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Julio Mariño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jmarino@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/023]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Webpage Menu Detection Based on DOM (Trabajo ya publicado)</title>
		<link>https://biblioteca.sistedes.es/articulo/webpage-menu-detection-based-on-dom-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/webpage-menu-detection-based-on-dom-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[One of the key elements of a website is Web menus, which provide fundamental information about the topology of the own website. Menu detection is useful for humans, but also for crawlers and indexers because the menu provides essential information about the structure and contents of a website. For humans, identifying the main menu of a website is a relatively easy task. However, for computer tools identifying the menu is not trivial at all and, in fact, it is still a challenging unsolved problem. In this work, we propose a novel method for automatic Web menu detection that works at the level of DOM.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2926</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[webpage-menu-detection-based-on-dom-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="information-retrieval"><![CDATA[Information retrieval]]></category>
		<category domain="post_tag" nicename="menu-detection"><![CDATA[Menu detection]]></category>
		<category domain="post_tag" nicename="web-template-detection"><![CDATA[Web template detection]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[One of the key elements of a website is Web menus, which provide fundamental information about the topology of the own website. Menu detection is useful for humans, but also for crawlers and indexers because the menu provides essential information about the structure and contents of a website. For humans, identifying the main menu of a website is a relatively easy task. However, for computer tools identifying the menu is not trivial at all and, in fact, it is still a challenging unsolved problem. In this work, we propose a novel method for automatic Web menu detection that works at the level of DOM.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-026.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/PROLE/2018-PROLE-026.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julián Alarte Aleixandre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[julianalarte@gmail.com ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València  - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[David Insa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[dinsa@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València  - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Josep Silva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jsilva@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València  - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/PROLE/2018/024]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Smart Bound Selection for the Verification of UML/OCL Class Diagrams (YA PUBLICADO)</title>
		<link>https://biblioteca.sistedes.es/articulo/smart-bound-selection-for-the-verification-of-uml-ocl-class-diagrams-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/smart-bound-selection-for-the-verification-of-uml-ocl-class-diagrams-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Correctness of UML class diagrams annotated with OCL constraints can be checked using bounded verification techniques, e.g., SAT or constraint programming (CP) solvers. Bounded verification detects faults efficiently but, on the other hand, the absence of faults does not guarantee a correct behavior outside the bounded domain. Hence, choosing suitable bounds is a non-trivial process as there is a trade-off between the verification time (faster for smaller domains) and the confidence in the result (better for larger domains). Unfortunately, bounded verification tools provide little support in the bound selection process.In this paper, we present a technique that can be used to (i) automatically infer verification bounds whenever possible, (ii) tighten a set of bounds proposed by the user and (iii) guide the user in the bound selection process. This approach may increase the usability of UML/OCL bounded verification tools and improve the efficiency of the verification process.This paper has been published in IEEE Transactions on Software Engineering[http://dx.doi.org/10.1109/TSE.2017.2777830]]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2927</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[smart-bound-selection-for-the-verification-of-uml-ocl-class-diagrams-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="class-diagram"><![CDATA[Class Diagram]]></category>
		<category domain="post_tag" nicename="constraint-propagation"><![CDATA[Constraint Propagation]]></category>
		<category domain="post_tag" nicename="formal-verification"><![CDATA[Formal Verification]]></category>
		<category domain="post_tag" nicename="ocl"><![CDATA[OCL]]></category>
		<category domain="post_tag" nicename="sat"><![CDATA[SAT]]></category>
		<category domain="post_tag" nicename="uml"><![CDATA[UML]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Correctness of UML class diagrams annotated with OCL constraints can be checked using bounded verification techniques, e.g., SAT or constraint programming (CP) solvers. Bounded verification detects faults efficiently but, on the other hand, the absence of faults does not guarantee a correct behavior outside the bounded domain. Hence, choosing suitable bounds is a non-trivial process as there is a trade-off between the verification time (faster for smaller domains) and the confidence in the result (better for larger domains). Unfortunately, bounded verification tools provide little support in the bound selection process.

In this paper, we present a technique that can be used to (i) automatically infer verification bounds whenever possible, (ii) tighten a set of bounds proposed by the user and (iii) guide the user in the bound selection process. This approach may increase the usability of UML/OCL bounded verification tools and improve the efficiency of the verification process.

This paper has been published in IEEE Transactions on Software Engineering
[http://dx.doi.org/10.1109/TSE.2017.2777830]]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-001.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-001.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Robert Clarisó]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rclariso@uoc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Oberta de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carlos A. González]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[carlos.gonzalez@uni.lu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[SnT Centre for Security, Reliability and Trust - Luxembourg]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jordi Cabot]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jordi.cabot@icrea.cat]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ICREA - UOC (Internet interdisciplinary institute) - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/001]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>ARTICULO RELEVANTE:IoT–TEG: Test event generator system</title>
		<link>https://biblioteca.sistedes.es/articulo/articulo-relevanteiot-teg-test-event-generator-system/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/articulo-relevanteiot-teg-test-event-generator-system/</guid>
		<description></description>
		<content><![CDATA[Internet of Things (IoT) has been paid increasingly attention by the government, academe and industry all over the world. One of the main drawbacks of the IoT systems is the amount of information they have to handle. This information arrives as events that need to be processed in real time in order to make correct decisions. Given that processing the data is crucial, testing the IoT systems that will manage that information is required. In order to test IoT systems, it is necessary to generate a huge number of events with specific structures and values to test the functionalities required by these systems. As this task is very hard and very prone to error if done by hand, this paper addresses the automated generation of appropriate events for testing. For this purpose, a general specification to define event types and its representation are proposed and an event generator is developed based on this definition. Thanks to the adaptability of the proposed specification, the event generator can generate events of an event type, or events which combine the relevant attributes of several event types. Results from experiments and real-world tests show that the developed system meets the demanded requirements.Journal of Systems and Software, JSS Special Issue on Software Reliability EngineeringImpact factor: 2,444 (Q1)Available online 20 June 2017DOI: https://doi.org/10.1016/j.jss.2017.06.037]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2928</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[articulo-relevanteiot-teg-test-event-generator-system]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="complex-event-processing"><![CDATA[Complex Event Processing]]></category>
		<category domain="post_tag" nicename="event-generator"><![CDATA[Event generator]]></category>
		<category domain="post_tag" nicename="event-type-definition"><![CDATA[Event type definition]]></category>
		<category domain="post_tag" nicename="internet-of-things"><![CDATA[Internet of Things]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Internet of Things (IoT) has been paid increasingly attention by the government, academe and industry all over the world. One of the main drawbacks of the IoT systems is the amount of information they have to handle. This information arrives as events that need to be processed in real time in order to make correct decisions. Given that processing the data is crucial, testing the IoT systems that will manage that information is required. In order to test IoT systems, it is necessary to generate a huge number of events with specific structures and values to test the functionalities required by these systems. As this task is very hard and very prone to error if done by hand, this paper addresses the automated generation of appropriate events for testing. For this purpose, a general specification to define event types and its representation are proposed and an event generator is developed based on this definition. Thanks to the adaptability of the proposed specification, the event generator can generate events of an event type, or events which combine the relevant attributes of several event types. Results from experiments and real-world tests show that the developed system meets the demanded requirements.

Journal of Systems and Software, JSS Special Issue on Software Reliability Engineering
Impact factor: 2,444 (Q1)
Available online 20 June 2017
DOI: https://doi.org/10.1016/j.jss.2017.06.037]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-002.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-002.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Lorena Gutiérrez-Madroñal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[lorena.gutierrez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Cadiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan José Domínguez-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanjose.dominguez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Cadiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/002]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Practical Update Management in Ontology-based Data Access (YA PUBLICADO)</title>
		<link>https://biblioteca.sistedes.es/articulo/practical-update-management-in-ontology-based-data-access-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/practical-update-management-in-ontology-based-data-access-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Ontology-based Data Access (OBDA) is gaining importance both scientifically and practically. However, little attention has been paid so far to the problem of updating OBDA systems. This is an essential issue if we want to be able to cope with modifications of data both at the ontology and at the source level, while maintaining the independence of the data sources. In this paper, we propose mechanisms to properly handle updates in this context. We show that updating data both at the ontology and source level is first-order rewritable. We also provide a practical implementation of such updating mechanisms based on non-recursive Datalog.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2929</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[practical-update-management-in-ontology-based-data-access-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="dl-lite"><![CDATA[DL-Lite]]></category>
		<category domain="post_tag" nicename="obda"><![CDATA[OBDA]]></category>
		<category domain="post_tag" nicename="updates"><![CDATA[updates]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Ontology-based Data Access (OBDA) is gaining importance both scientifically and practically. However, little attention has been paid so far to the problem of updating OBDA systems. This is an essential issue if we want to be able to cope with modifications of data both at the ontology and at the source level, while maintaining the independence of the data sources. In this paper, we propose mechanisms to properly handle updates in this context. We show that updating data both at the ontology and source level is first-order rewritable. We also provide a practical implementation of such updating mechanisms based on non-recursive Datalog.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-003.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-003.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Giuseppe De Giacomo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[degiacomo@dis.uniroma1.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Sapienza University of Rome - Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Domenico Lembo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[lembo@dis.uniroma1.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Sapienza University of Rome - Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Xavier Oriol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[xoriol@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Domenico Fabio Savo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[savo@dis.uniroma1.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Sapienza University of Rome - Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Ernest Teniente]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[teniente@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/003]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>ARTICULO RELEVANTE: Metamorphic Testing of RESTful Web APIs</title>
		<link>https://biblioteca.sistedes.es/articulo/articulo-relevante-metamorphic-testing-of-restful-web-apis/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/articulo-relevante-metamorphic-testing-of-restful-web-apis/</guid>
		<description></description>
		<content><![CDATA[S. Segura, J. A. Parejo, J. Troya and A. Ruiz-Cortés, "Metamorphic Testing of RESTful Web APIs" in IEEE Transactions on Software Engineering, Oct 2017 (online) vol. PP, no. 99, pp. 1-1. https://doi.org/10.1109/TSE.2017.2764464Aceptado para ser presentado en ICSE 2018 en la categoría de journal-first: https://www.icse2018.org/track/icse-2018-Journal-first-papers#event-overview166 lecturas en ResearchGate desde su publicación (118 en IEEE Xplore).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2930</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[articulo-relevante-metamorphic-testing-of-restful-web-apis]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="metamorphic-testing"><![CDATA[metamorphic testing]]></category>
		<category domain="post_tag" nicename="oracle-problem"><![CDATA[oracle problem]]></category>
		<category domain="post_tag" nicename="web-apis"><![CDATA[Web APIs]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[S. Segura, J. A. Parejo, J. Troya and A. Ruiz-Cortés, "Metamorphic Testing of RESTful Web APIs" in IEEE Transactions on Software Engineering, Oct 2017 (online) vol. PP, no. 99, pp. 1-1. https://doi.org/10.1109/TSE.2017.2764464

Aceptado para ser presentado en ICSE 2018 en la categoría de journal-first: https://www.icse2018.org/track/icse-2018-Journal-first-papers#event-overview

166 lecturas en ResearchGate desde su publicación (118 en IEEE Xplore).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-004.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-004.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Antonio Parejo Maestre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[japarejo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Troya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jtroya@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/004]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Identification and analysis of the elements required to manage technical debt by means of a systematic mapping study (Artículo relevante)</title>
		<link>https://biblioteca.sistedes.es/articulo/identification-and-analysis-of-the-elements-required-to-manage-technical-debt-by-means-of-a-systematic-mapping-study-articulo-relevante/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/identification-and-analysis-of-the-elements-required-to-manage-technical-debt-by-means-of-a-systematic-mapping-study-articulo-relevante/</guid>
		<description></description>
		<content><![CDATA[Artículo publicado en Journal of Systems and Software (JSS). JSS es clasificada como Q1 en JCR 2017. @article{FERNANDEZSANCHEZ201722,title = "Identification and analysis of the elements required to manage technical debt by means of a systematic mapping study",journal = "Journal of Systems and Software",volume = "124",pages = "22 - 38",year = "2017",issn = "0164-1212",doi = "https://doi.org/10.1016/j.jss.2016.10.018",url = "http://www.sciencedirect.com/science/article/pii/S0164121216302138",author = "Carlos FernÃ¡ndez-SÃ¡nchez and Juan Garbajosa and AgustÃ­n YagÃŒe and Jennifer Perez",keywords = "Technical debt, Technical debt management, Systematic mapping, Decision making, Basic decision-making factors, Cost estimation techniques, Practices and techniques for decision-making, Stakeholdersâ?? points of view, Engineering, Engineering management, Business-organizational management, Framework",abstract = "Technical debt, a metaphor for the long-term consequences of weak software development, must be managed to keep it under control. The main goal of this article is to identify and analyze the elements required to manage technical debt. The research method used to identify the elements is a systematic mapping, including a synthesis step to synthesize the elements definitions. Our perspective differs from previous literature reviews because it focused on the elements required to manage technical debt and not on the phenomenon of technical debt or the activities used in performing technical debt management. Additionally, the rigor and relevance for industry of the current techniques used to manage technical debt are studied. The elements were classified into three groups (basic decision-making factors, cost estimation techniques, practices and techniques for decision-making) and mapped according three stakeholdersâ?? points of view (engineering, engineering management, and business-organizational management). The definitions, classification, and analysis of the elements provide a framework that can be deployed to help in the development of models that are adapted to the specific stakeholdersâ?? interests to assist the decision-making required in technical debt management and to assess existing models and methods. The analysis indicated that technical debt management is context dependent."}]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2931</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[identification-and-analysis-of-the-elements-required-to-manage-technical-debt-by-means-of-a-systematic-mapping-study-articulo-relevante]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="basic-decision-making-factors"><![CDATA[Basic decision-making factors]]></category>
		<category domain="post_tag" nicename="business-orga"><![CDATA[Business-orga]]></category>
		<category domain="post_tag" nicename="cost-estimation-techniques"><![CDATA[Cost estimation techniques]]></category>
		<category domain="post_tag" nicename="decision-making"><![CDATA[Decision Making]]></category>
		<category domain="post_tag" nicename="engineering"><![CDATA[Engineering]]></category>
		<category domain="post_tag" nicename="engineering-management"><![CDATA[Engineering management]]></category>
		<category domain="post_tag" nicename="practices-and-techniques-for-decision-making"><![CDATA[Practices and techniques for decision-making]]></category>
		<category domain="post_tag" nicename="stakeholders-points-of-view"><![CDATA[Stakeholders’ points of view]]></category>
		<category domain="post_tag" nicename="systematic-mapping"><![CDATA[Systematic mapping]]></category>
		<category domain="post_tag" nicename="technical-debt"><![CDATA[technical debt]]></category>
		<category domain="post_tag" nicename="technical-debt-management"><![CDATA[Technical debt management]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Artículo publicado en Journal of Systems and Software (JSS). JSS es clasificada como Q1 en JCR 2017.

@article{FERNANDEZSANCHEZ201722,
title = "Identification and analysis of the elements required to manage technical debt by means of a systematic mapping study",
journal = "Journal of Systems and Software",
volume = "124",
pages = "22 - 38",
year = "2017",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2016.10.018",
url = "http://www.sciencedirect.com/science/article/pii/S0164121216302138",
author = "Carlos FernÃ¡ndez-SÃ¡nchez and Juan Garbajosa and AgustÃ­n YagÃŒe and Jennifer Perez",
keywords = "Technical debt, Technical debt management, Systematic mapping, Decision making, Basic decision-making factors, Cost estimation techniques, Practices and techniques for decision-making, Stakeholdersâ?? points of view, Engineering, Engineering management, Business-organizational management, Framework",
abstract = "Technical debt, a metaphor for the long-term consequences of weak software development, must be managed to keep it under control. The main goal of this article is to identify and analyze the elements required to manage technical debt. The research method used to identify the elements is a systematic mapping, including a synthesis step to synthesize the elements definitions. Our perspective differs from previous literature reviews because it focused on the elements required to manage technical debt and not on the phenomenon of technical debt or the activities used in performing technical debt management. Additionally, the rigor and relevance for industry of the current techniques used to manage technical debt are studied. The elements were classified into three groups (basic decision-making factors, cost estimation techniques, practices and techniques for decision-making) and mapped according three stakeholdersâ?? points of view (engineering, engineering management, and business-organizational management). The definitions, classification, and analysis of the elements provide a framework that can be deployed to help in the development of models that are adapted to the specific stakeholdersâ?? interests to assist the decision-making required in technical debt management and to assess existing models and methods. The analysis indicated that technical debt management is context dependent."
}]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-006.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-006.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Fernández-Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[nandez3@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Garbajosa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jgs@etsisi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Agustín Yagüe]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[ayague@etsisi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jennifer Perez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jperez@etsisi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/005]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Improving feature location in long-living model-based product families designed with sustainability goals (YA PUBLICADO)</title>
		<link>https://biblioteca.sistedes.es/articulo/improving-feature-location-in-long-living-model-based-product-families-designed-with-sustainability-goals-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/improving-feature-location-in-long-living-model-based-product-families-designed-with-sustainability-goals-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[The benefits of Software Product Lines (SPL) are very appealing: software development becomes better, faster, and cheaper. Unfortunately, these benefits come at the expense of a migration from a family of products to a SPL. Feature Location could be useful in achieving the transition to SPLs. This work presents our FeLLaCaM approach for Feature Location. Our approach calculates similarity to a description of the feature to locate, occurrences where the candidate features remain unchanged, and changes performed to the candidate features throughout the retrospective of the product family. We evaluated our approach in two long-living industrial domains: a model-based family of firmwares for induction hobs that was developed over more than 15 years, and a model-based family of PLC software to control trains that was developed over more than 25 years. In our evaluation, we compare our FeLLaCaM approach with two other approaches for Feature Location: (1) FLL (Feature Location through Latent Semantic Analysis) and (2) FLC (Feature Location through Comparisons). We measure the performance of FeLLaCaM, FLL, and FLC in terms of recall, precision, Matthews Correlation Coefficient, and Area Under the Receiver Operating Characteristics curve. The results show that FeLLaCaM outperforms FLL and FLC.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2932</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[improving-feature-location-in-long-living-model-based-product-families-designed-with-sustainability-goals-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="architecture-sustainability"><![CDATA[Architecture sustainability]]></category>
		<category domain="post_tag" nicename="feature-location"><![CDATA[Feature location]]></category>
		<category domain="post_tag" nicename="long-living-software-systems"><![CDATA[Long-Living software systems]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<category domain="post_tag" nicename="software-product-lines"><![CDATA[software product lines]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The benefits of Software Product Lines (SPL) are very appealing: software development becomes better, faster, and cheaper. Unfortunately, these benefits come at the expense of a migration from a family of products to a SPL. Feature Location could be useful in achieving the transition to SPLs. This work presents our FeLLaCaM approach for Feature Location. Our approach calculates similarity to a description of the feature to locate, occurrences where the candidate features remain unchanged, and changes performed to the candidate features throughout the retrospective of the product family. We evaluated our approach in two long-living industrial domains: a model-based family of firmwares for induction hobs that was developed over more than 15 years, and a model-based family of PLC software to control trains that was developed over more than 25 years. In our evaluation, we compare our FeLLaCaM approach with two other approaches for Feature Location: (1) FLL (Feature Location through Latent Semantic Analysis) and (2) FLC (Feature Location through Comparisons). We measure the performance of FeLLaCaM, FLL, and FLC in terms of recall, precision, Matthews Correlation Coefficient, and Area Under the Receiver Operating Characteristics curve. The results show that FeLLaCaM outperforms FLL and FLC.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-007.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-007.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Cetina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ccetina@usj.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad San Jorge - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jaime Font]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jfont@usj.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad San Jorge - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Lorena Arcega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[larcega@usj.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad San Jorge - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Francisca Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mfperez@usj.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad San Jorge - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/006]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Artículo Relevante: Reverse engineering language product lines from existing DSL variants.</title>
		<link>https://biblioteca.sistedes.es/articulo/articulo-relevante-reverse-engineering-language-product-lines-from-existing-dsl-variants/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/articulo-relevante-reverse-engineering-language-product-lines-from-existing-dsl-variants/</guid>
		<description></description>
		<content><![CDATA[-Título: Reverse engineering language product lines from existing DSL variants.-Autores: David Méndez-Acuña, José A. Galindo, Benoît Combemale, Arnaud Blouin, Benoit Baudry-Revista de publicación: Journal of Systems and Software-Volumen 133. Noviembre de 2017. Páginas 145-158-DOI: 10.1016/j.jss.2017.05.042Indicios de calidad: JCR-IF: 2,444(22/106).JCR-Q: Q1. JCR-T: T1. JCR-Category/year: COMPUTER SCIENCE, SOFTWARE ENGINEERING - 2016. 9 citas según gscholar]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2933</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[articulo-relevante-reverse-engineering-language-product-lines-from-existing-dsl-variants]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="dsl"><![CDATA[DSL]]></category>
		<category domain="post_tag" nicename="models"><![CDATA[models]]></category>
		<category domain="post_tag" nicename="software-product-lines"><![CDATA[software product lines]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[-Título: Reverse engineering language product lines from existing DSL variants.
-Autores: David Méndez-Acuña, José A. Galindo, Benoît Combemale, Arnaud Blouin, Benoit Baudry
-Revista de publicación: Journal of Systems and Software
-Volumen 133. Noviembre de 2017. Páginas 145-158
-DOI: 10.1016/j.jss.2017.05.042

Indicios de calidad: JCR-IF: 2,444(22/106).JCR-Q: Q1. JCR-T: T1. JCR-Category/year: COMPUTER SCIENCE, SOFTWARE ENGINEERING - 2016. 9 citas según gscholar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-008.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-008.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Méndez-Acuña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[damenac@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[INRIA - France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José A. Galindo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jagalindo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/007]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación de eventos de prueba para un sistema IoT de detección de caídas</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-de-eventos-de-prueba-para-un-sistema-iot-de-deteccion-de-caidas/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/generacion-de-eventos-de-prueba-para-un-sistema-iot-de-deteccion-de-caidas/</guid>
		<description></description>
		<content><![CDATA[El Internet de las Cosas (IoT) se ha ido aplicando en diferentes áreas; como smartcyties , medicina, procesos de negocio, etc, convirtiéndolo en un paradigma muy popular. Uno de los inconvenientes de los sistemas IoT es la toma de decisiones en tiempo real según la gran cantidad de información, eventos, que manejan. Realizar pruebas en estos sistemas es crucial para la toma de decisiones, ya que si no se filtra la información correcta no se llevarán a cabo las acciones esperadas. En diversas ocasiones es difícil obtener los eventos con valores específicos para realizar pruebas: condiciones ambientales adversas, subida o bajada de la tensión arterial, paro cardíaco, caídas... Este trabajo está enfocado en analizar caídas y en generar los eventos de prueba que las simulen utilizando la herramienta IoT-TEG. Este análisis ha permitido detectar el comportamiento de los eventos durante las mismas y ampliar las funcionalidades de IoT-TEG: los eventos de prueba a generar siguen las reglas de comportamiento que el usuario defina.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2934</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-de-eventos-de-prueba-para-un-sistema-iot-de-deteccion-de-caidas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="deteccion-de-caidas"><![CDATA[Detección de caídas]]></category>
		<category domain="post_tag" nicename="eventos-de-prueba"><![CDATA[Eventos de prueba]]></category>
		<category domain="post_tag" nicename="iot-teg"><![CDATA[IoT-TEG]]></category>
		<category domain="post_tag" nicename="pruebas-en-sistemas-iot"><![CDATA[Pruebas en sistemas IoT]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El Internet de las Cosas (IoT) se ha ido aplicando en diferentes áreas; como smartcyties , medicina, procesos de negocio, etc, convirtiéndolo en un paradigma muy popular. Uno de los inconvenientes de los sistemas IoT es la toma de decisiones en tiempo real según la gran cantidad de información, eventos, que manejan. Realizar pruebas en estos sistemas es crucial para la toma de decisiones, ya que si no se filtra la información correcta no se llevarán a cabo las acciones esperadas. En diversas ocasiones es difícil obtener los eventos con valores específicos para realizar pruebas: condiciones ambientales adversas, subida o bajada de la tensión arterial, paro cardíaco, caídas... Este trabajo está enfocado en analizar caídas y en generar los eventos de prueba que las simulen utilizando la herramienta IoT-TEG. Este análisis ha permitido detectar el comportamiento de los eventos durante las mismas y ampliar las funcionalidades de IoT-TEG: los eventos de prueba a generar siguen las reglas de comportamiento que el usuario defina.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-009.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-009.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Lorena Gutiérrez-Madroñal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[lorena.gutierrez@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Luigi La Blunda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[l.lablunda@fb2.fra-uas.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Frankfurt University of Applied Sciences - Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Matthias F. Wagner]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mfwagner@fb2.fra-uas.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Frankfurt University of Applied Sciences - Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Cadiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/008]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A tool to support the definition and enactment of model-driven migration processes (YA PUBLICADO)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-tool-to-support-the-definition-and-enactment-of-model-driven-migration-processes-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-tool-to-support-the-definition-and-enactment-of-model-driven-migration-processes-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[The Journal of Systems and Software, num. 128 (March 2017) pages: 106–129DOI: http://dx.doi.org/10.1016/j.jss.2017.03.0092016 Impact Factor: 2.444  (Q1 - rank 22/106)5-year Impact Factor: 2.619ABSTRACTOne of the main challenges to achieve the industrial adoption of Model-Driven Engineering (MDE) paradigm is building tools able to support model-driven software processes. We present a tool for the definition and enactment of model-driven migration processes. We have created a SPEM-based language for defining Abstract Migration models that represent an MDE migration solution for a particular pair of source and target technologies. For each legacy application to be migrated, the Abstract Migration model is transformed into a Concrete Migration model which contains all the information needed for the enactment. Then, these models are enacted by means of a process interpreter which generates Trac tickets for executing automated tasks by means of Ant scripts and managing manual tasks with the Mylyn tool. Our work has therefore two main contributions: i) it proposes a novel solution for the enactment that integrates the execution of the automated tasks with the generation of tickets to support the manual tasks, and ii) it describes how MDE techniques can be used to implement process engineering tools, in particular migration processes. The article presents the approach and describes in detail the essential aspects of our tool.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2935</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-tool-to-support-the-definition-and-enactment-of-model-driven-migration-processes-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<category domain="post_tag" nicename="process-enactment"><![CDATA[Process enactment]]></category>
		<category domain="post_tag" nicename="software-migrations"><![CDATA[Software migrations]]></category>
		<category domain="post_tag" nicename="software-processes"><![CDATA[Software processes]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The Journal of Systems and Software, num. 128 (March 2017) pages: 106–129
DOI: http://dx.doi.org/10.1016/j.jss.2017.03.009
2016 Impact Factor: 2.444  (Q1 - rank 22/106)
5-year Impact Factor: 2.619

ABSTRACT
One of the main challenges to achieve the industrial adoption of Model-Driven Engineering (MDE) paradigm is building tools able to support model-driven software processes. We present a tool for the definition and enactment of model-driven migration processes. We have created a SPEM-based language for defining Abstract Migration models that represent an MDE migration solution for a particular pair of source and target technologies. For each legacy application to be migrated, the Abstract Migration model is transformed into a Concrete Migration model which contains all the information needed for the enactment. Then, these models are enacted by means of a process interpreter which generates Trac tickets for executing automated tasks by means of Ant scripts and managing manual tasks with the Mylyn tool. Our work has therefore two main contributions: i) it proposes a novel solution for the enactment that integrates the execution of the automated tasks with the generation of tickets to support the manual tasks, and ii) it describes how MDE techniques can be used to implement process engineering tools, in particular migration processes. The article presents the approach and describes in detail the essential aspects of our tool.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-010.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-010.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Javier Bermúdez Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[fjavier@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Óscar Sánchez Ramón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[osanchez@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesús Joaquín García Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jmolina@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/009]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>ARTICULO RELEVANTE:Incremental test data generation for database queries</title>
		<link>https://biblioteca.sistedes.es/articulo/articulo-relevanteincremental-test-data-generation-for-database-queries/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/articulo-relevanteincremental-test-data-generation-for-database-queries/</guid>
		<description></description>
		<content><![CDATA[Título: Incremental test data generation for database queriesAutores: María José Suárez-Cabal, Claudio de la Riva, Javier Tuya, Raquel BlancoRevista de publicación: Automated Software EngineeringNúmero, mes y año de la publicación: 24(4), Diciembre 2017Páginas: 719-755DOI: 10.1007/s10515-017-0212-7Indicios de calidad:  Factor de impacto: 2.625 (JCR, 2016)  Número de citas: 2      [1] R. Blanco and J. Tuya, "Modelling Test Views for Graph Database Applications", IEEE Latin America Transactions, vol. 15, no. 7, pp. 1312-1317, 2017. doi: 10.1109/TLA.2017.7959352       [2] W. Castelein, M. Aniche, M. Soltani, A. Panichella, A. Deursen, "Search-Based Test Data Generation for SQL Queries", Proceedings of the 40th International Conference on Software Engineering (ICSE 2018)]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2936</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[articulo-relevanteincremental-test-data-generation-for-database-queries]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="constraint-satisfaction-problem-csp"><![CDATA[Constraint satisfaction problem (CSP)]]></category>
		<category domain="post_tag" nicename="database-testing"><![CDATA[Database testing]]></category>
		<category domain="post_tag" nicename="software-testing"><![CDATA[Software Testing]]></category>
		<category domain="post_tag" nicename="test-coverage"><![CDATA[Test coverage]]></category>
		<category domain="post_tag" nicename="test-database-generation"><![CDATA[Test database generation]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Título: Incremental test data generation for database queries

Autores: María José Suárez-Cabal, Claudio de la Riva, Javier Tuya, Raquel Blanco

Revista de publicación: Automated Software Engineering

Número, mes y año de la publicación: 24(4), Diciembre 2017

Páginas: 719-755

DOI: 10.1007/s10515-017-0212-7

Indicios de calidad:
  Factor de impacto: 2.625 (JCR, 2016)
  Número de citas: 2
      [1] R. Blanco and J. Tuya, "Modelling Test Views for Graph Database Applications", IEEE Latin America Transactions, vol. 15, no. 7, pp. 1312-1317, 2017. doi: 10.1109/TLA.2017.7959352

      [2] W. Castelein, M. Aniche, M. Soltani, A. Panichella, A. Deursen, "Search-Based Test Data Generation for SQL Queries", Proceedings of the 40th International Conference on Software Engineering (ICSE 2018)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-011.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-011.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María José Suárez-Cabal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cabal@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Claudio De La Riva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[claudio@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Raquel Blanco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[rblanco@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/010]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Highlight&amp;Go: una extensión para automatizar la extracción de datos en revisiones sistemáticas de la literatura utilizando Google Sheets</title>
		<link>https://biblioteca.sistedes.es/articulo/highlightgo-una-extension-para-automatizar-la-extraccion-de-datos-en-revisiones-sistematicas-de-la-literatura-utilizando-google-sheets/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:49 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/highlightgo-una-extension-para-automatizar-la-extraccion-de-datos-en-revisiones-sistematicas-de-la-literatura-utilizando-google-sheets/</guid>
		<description></description>
		<content><![CDATA[Una revisión sistemática de la literatura no es tarea baladí. Conlleva almacenar, gestionar, validar y analizar una gran cantidad de datos. Extraer estos datos implica identificar los párrafos de los estudios primarios que justifican su clasificación en base a las dimensiones del estudio. Esto conlleva mover datos desde el entorno donde se ha realizado la lectura (p.e. Mendeley) al lugar dónde se recogen estos datos (p.e. Excel). Si estas actividades se mueven a la Web, este flujo de datos se puede automatizar. Este trabajo aborda este objetivo mediante la utilización de extensiones para navegadores. En concreto, hemos desarrollado Highlight&Go, una extensión de Google Chrome, donde el investigador subraya ("highlight") los estudios primarios, y se va ("go"): la hoja de cálculo se puebla sola a partir de las anotaciones realizadas. Los beneficios esperados incluyen: (1) mejoras en la eficiencia al eliminar el copiar&pegar; (2) mejoras en la fiabilidad al reducir los errores de la intervención manual; y (3) mejoras en la trazabilidad al recoger no sólo la clasificación sino también los párrafos que sustentan esta clasificación.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2937</post_id>
		<post_date><![CDATA[2018-07-26 06:17:49]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:49]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[highlightgo-una-extension-para-automatizar-la-extraccion-de-datos-en-revisiones-sistematicas-de-la-literatura-utilizando-google-sheets]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="automatization"><![CDATA[Automatization]]></category>
		<category domain="post_tag" nicename="color-coding-annotation"><![CDATA[Color-Coding Annotation]]></category>
		<category domain="post_tag" nicename="data-extraction"><![CDATA[Data Extraction]]></category>
		<category domain="post_tag" nicename="mapping-studies"><![CDATA[Mapping Studies]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Una revisión sistemática de la literatura no es tarea baladí. Conlleva almacenar, gestionar, validar y analizar una gran cantidad de datos. Extraer estos datos implica identificar los párrafos de los estudios primarios que justifican su clasificación en base a las dimensiones del estudio. Esto conlleva mover datos desde el entorno donde se ha realizado la lectura (p.e. Mendeley) al lugar dónde se recogen estos datos (p.e. Excel). Si estas actividades se mueven a la Web, este flujo de datos se puede automatizar. Este trabajo aborda este objetivo mediante la utilización de extensiones para navegadores. En concreto, hemos desarrollado Highlight&Go, una extensión de Google Chrome, donde el investigador subraya ("highlight") los estudios primarios, y se va ("go"): la hoja de cálculo se puebla sola a partir de las anotaciones realizadas. Los beneficios esperados incluyen: (1) mejoras en la eficiencia al eliminar el copiar&pegar; (2) mejoras en la fiabilidad al reducir los errores de la intervención manual; y (3) mejoras en la trazabilidad al recoger no sólo la clasificación sino también los párrafos que sustentan esta clasificación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-012.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-012.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Haritz Medina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[haritz.medina@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU) - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Oscar Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[oscar.diaz@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU) - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Felipe I. Anfurrutia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[felipe.anfurrutia@ehu.eus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of the Basque Country (UPV/EHU) - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/011]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Aggregation-based information retrieval system for geospatial data catalogs</title>
		<link>https://biblioteca.sistedes.es/articulo/aggregation-based-information-retrieval-system-for-geospatial-data-catalogs/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/aggregation-based-information-retrieval-system-for-geospatial-data-catalogs/</guid>
		<description></description>
		<content><![CDATA[Tipo de contribución: Artículo relevanteAutores: Lacasta, Javier; Lopez-Pellicer, F. Javier; Espejo-García, Borja; Nogueras-Iso, Javier; Zarazaga-Soria, F. Javier.Título: Aggregation-based information retrieval system for geospatial data catalogs.Publicación: INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE. 31 - 8, pp. 1583 - 1605. 2017. ISSN 1365-8816DOI: 10.1080/13658816.2017.1319949Indicios de Calidad - Factor de impacto:JCR-SCI 2016 impact factor: 2.502. Rank: Q2 (46/146) in Computer Science, Information Systems ; Q2 (19/49) in Geography, Physical]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2939</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[aggregation-based-information-retrieval-system-for-geospatial-data-catalogs]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="catalog-service-for-the-web"><![CDATA[Catalog Service for the Web]]></category>
		<category domain="post_tag" nicename="geospatial-data-catalog"><![CDATA[Geospatial Data Catalog]]></category>
		<category domain="post_tag" nicename="information-retrieval"><![CDATA[Information retrieval]]></category>
		<category domain="post_tag" nicename="spatial-data-infrastructure"><![CDATA[Spatial Data Infrastructure]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Tipo de contribución: Artículo relevante

Autores: Lacasta, Javier; Lopez-Pellicer, F. Javier; Espejo-García, Borja; Nogueras-Iso, Javier; Zarazaga-Soria, F. Javier.

Título: Aggregation-based information retrieval system for geospatial data catalogs.

Publicación: INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE. 31 - 8, pp. 1583 - 1605. 2017. ISSN 1365-8816
DOI: 10.1080/13658816.2017.1319949

Indicios de Calidad - Factor de impacto:
JCR-SCI 2016 impact factor: 2.502. Rank: Q2 (46/146) in Computer Science, Information Systems ; Q2 (19/49) in Geography, Physical]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-014.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-014.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Lacasta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jlacasta@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Francisco J. Lopez-Pellicer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fjlopez@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Borja Espejo García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[borjaeg@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Javier Nogueras Iso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jnog@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[F.Javier Zarazaga-Soria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[javy@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universiad de Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/013]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A systematic mapping study about socio-technical congruence (Artículo relevante)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-systematic-mapping-study-about-socio-technical-congruence-articulo-relevante/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-systematic-mapping-study-about-socio-technical-congruence-articulo-relevante/</guid>
		<description></description>
		<content><![CDATA[Artículo Relevante ya publicado:Título: A systematic mapping study about socio-technical congruenceAutores: José María Sierra, Aurora Vizcaíno, Marcela Genero, Mario PiattiniNombre de la conferencia o revista de publicación: Information and Software Technology Número: Volume 94Mes: Februaro Año de la publicación: 2018 (Es importante resaltar que se aceptó el  6 de Octubre de 2017 por lo cual cumple los requisitos)Páginas: 111-129 DOI: https://doi.org/10.1016/j.infsof.2017.10.004Indicios de calidad (factor de impacto, número de citas, etc): ( posición de la revista: 16/106, factor de impacto: 2.694, puesto que se publicó en febrero de 2018 todavía no tiene citas)]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2940</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-systematic-mapping-study-about-socio-technical-congruence-articulo-relevante]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="coordination"><![CDATA[Coordination]]></category>
		<category domain="post_tag" nicename="distributed-and-global-software-development"><![CDATA[Distributed and Global Software Development]]></category>
		<category domain="post_tag" nicename="socio-technical-congruence"><![CDATA[Socio-technical Congruence]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Artículo Relevante ya publicado:

Título: A systematic mapping study about socio-technical congruence
Autores: José María Sierra, Aurora Vizcaíno, Marcela Genero, Mario Piattini
Nombre de la conferencia o revista de publicación: Information and Software Technology
Número: Volume 94
Mes: Februaro
Año de la publicación: 2018 (Es importante resaltar que se aceptó el  6 de Octubre de 2017 por lo cual cumple los requisitos)
Páginas: 111-129
DOI: https://doi.org/10.1016/j.infsof.2017.10.004
Indicios de calidad (factor de impacto, número de citas, etc): ( posición de la revista: 16/106, factor de impacto: 2.694, puesto que se publicó en febrero de 2018 todavía no tiene citas)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-015.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-015.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José María Sierra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jose.sierra@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Aurora Vizcaíno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[aurora.vizcaino@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla - La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Marcela Genero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[marcela.genero@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Mario Piattini]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mario.piattini@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/014]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>ARTICULO RELEVANTE:Assessment of C++ object-oriented mutation operators: A selective mutation approach</title>
		<link>https://biblioteca.sistedes.es/articulo/articulo-relevanteassessment-of-c-object-oriented-mutation-operators-a-selective-mutation-approach/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/articulo-relevanteassessment-of-c-object-oriented-mutation-operators-a-selective-mutation-approach/</guid>
		<description></description>
		<content><![CDATA[La prueba de mutaciones está considerada como una técnicaefectiva, pero que es costosa en contrapartida. Varios estudios han pues-to de manifiesto que pueden existir mutantes redundantes y que, unavez eliminados, no suponen pérdida de la efectividad de la técnica. De lamisma manera, algunos mutantes pueden ser más efectivos que otros ala hora de guiarnos en la generación de nuevos casos de pruebas de altacalidad. En base a estos dos hallazgos, en este artículo presentamos unaevaluación de los operadores de mutación definidos para C++ en la queclasificamos dichos operadores en dos rankings diferentes tras estudiar losmutantes que cada uno de los operadores genera. La primera clasificaciónordena los operadores según el grado de redundancia de sus mutantes yla segunda en base a la calidad de las pruebas que ayudan a diseñar. Unavez establecidos ambos rankings, llevamos a cabo un proceso de mutaciónselectiva en el que seleccionamos subconjuntos de operadores desechandolos menos valorados. El objetivo es determinar qué relación existe entrela reducción que se obtendría al eliminar estos operadores y la pérdidade efectividad. Los resultados experimentales muestran de una maneraconsistente que al seleccionar los operadores que están en la parte altadel ranking podemos obtener una reducción significativa en el númerode mutantes con una mínima pérdida de efectividad. Esto se produce enambas clasificaciones a pesar de que los operadores se ordenan de for-ma distinta, lo cual valida el planteamiento de valorar los operadores demutación de una manera diferente según nuestro objetivo sea evaluar orefinar el conjunto de pruebas.P. Delgado-Pérez, S. Segura and I. Medina-Bulo, “Assessment of C++ object-oriented mutation operators: A selective mutation approach,” Software Testing,Verification and Reliability, vol. 27, num. 4–5, pp. e1630, 2017. http://dx.doi.org/10.1002/stvr.1630Factor de impacto revista: 1.588]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2941</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[articulo-relevanteassessment-of-c-object-oriented-mutation-operators-a-selective-mutation-approach]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="c"><![CDATA[C++]]></category>
		<category domain="post_tag" nicename="calidad-de-operadores-de-mutacion"><![CDATA[calidad de operadores de mutación]]></category>
		<category domain="post_tag" nicename="mutacion-selectiva"><![CDATA[mutación selectiva]]></category>
		<category domain="post_tag" nicename="operadores-de-mutacion-de-clase"><![CDATA[operadores de mutación de clase]]></category>
		<category domain="post_tag" nicename="prueba-de-mutaciones"><![CDATA[prueba de mutaciones]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La prueba de mutaciones está considerada como una técnica
efectiva, pero que es costosa en contrapartida. Varios estudios han pues-
to de manifiesto que pueden existir mutantes redundantes y que, una
vez eliminados, no suponen pérdida de la efectividad de la técnica. De la
misma manera, algunos mutantes pueden ser más efectivos que otros a
la hora de guiarnos en la generación de nuevos casos de pruebas de alta
calidad. En base a estos dos hallazgos, en este artículo presentamos una
evaluación de los operadores de mutación definidos para C++ en la que
clasificamos dichos operadores en dos rankings diferentes tras estudiar los
mutantes que cada uno de los operadores genera. La primera clasificación
ordena los operadores según el grado de redundancia de sus mutantes y
la segunda en base a la calidad de las pruebas que ayudan a diseñar. Una
vez establecidos ambos rankings, llevamos a cabo un proceso de mutación
selectiva en el que seleccionamos subconjuntos de operadores desechando
los menos valorados. El objetivo es determinar qué relación existe entre
la reducción que se obtendría al eliminar estos operadores y la pérdida
de efectividad. Los resultados experimentales muestran de una manera
consistente que al seleccionar los operadores que están en la parte alta
del ranking podemos obtener una reducción significativa en el número
de mutantes con una mínima pérdida de efectividad. Esto se produce en
ambas clasificaciones a pesar de que los operadores se ordenan de for-
ma distinta, lo cual valida el planteamiento de valorar los operadores de
mutación de una manera diferente según nuestro objetivo sea evaluar o
refinar el conjunto de pruebas.

P. Delgado-Pérez, S. Segura and I. Medina-Bulo, “Assessment of C++ object-
oriented mutation operators: A selective mutation approach,” Software Testing,
Verification and Reliability, vol. 27, num. 4–5, pp. e1630, 2017.
http://dx.doi.org/10.1002/stvr.1630

Factor de impacto revista: 1.588]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-016.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-016.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Delgado-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pedro.delgado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/015]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>ARTICULO RELEVANTE:Evaluating Software Project Managers: A Multidimensional Perspective</title>
		<link>https://biblioteca.sistedes.es/articulo/articulo-relevanteevaluating-software-project-managers-a-multidimensional-perspective/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/articulo-relevanteevaluating-software-project-managers-a-multidimensional-perspective/</guid>
		<description></description>
		<content><![CDATA[Lawrence Peters, Ana M. Moreno. Evaluating Software Project Managers: A multidimensional perspective. IEEE Software, Nov-Dec. 2017, Vol 34 (6), pp 104-109. IEEE Software –  JCR Impact Factor (2016): 2,547 – Rank Computer Science, Software Engineering 26/106 - Q1Qualified and motivated software project managers are key contributors in software organizations. According to literature and supported by authors experience one of the most effective motivators for software practitioners is the recognition of their work. Feedback and recognition of the work done implies the evaluation of professionals and their work. Evaluating software project managers should go beyond a hasty analysis determining if their projects finished on time, under budget and met requirements. Software project managers develop their practice in an organizational context and their work directly impacts different groups within the organization. Each group has its own value system regarding what the software project should accomplish and what an effective software project manager is. This paper discuss a holistic approach for evaluating software project managers having in mind the value system of those groups.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2942</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[articulo-relevanteevaluating-software-project-managers-a-multidimensional-perspective]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="evaluating-software-project-managers"><![CDATA[Evaluating software project managers]]></category>
		<category domain="post_tag" nicename="motivating-software-engineers"><![CDATA[Motivating Software Engineers]]></category>
		<category domain="post_tag" nicename="software-project-management"><![CDATA[Software project management]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Lawrence Peters, Ana M. Moreno. Evaluating Software Project Managers: A multidimensional perspective. IEEE Software, Nov-Dec. 2017, Vol 34 (6), pp 104-109.
IEEE Software –  JCR Impact Factor (2016): 2,547 – Rank Computer Science, Software Engineering 26/106 - Q1

Qualified and motivated software project managers are key contributors in software organizations. According to literature and supported by authors experience one of the most effective motivators for software practitioners is the recognition of their work. Feedback and recognition of the work done implies the evaluation of professionals and their work. Evaluating software project managers should go beyond a hasty analysis determining if their projects finished on time, under budget and met requirements. Software project managers develop their practice in an organizational context and their work directly impacts different groups within the organization. Each group has its own value system regarding what the software project should accomplish and what an effective software project manager is. This paper discuss a holistic approach for evaluating software project managers having in mind the value system of those groups.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-018.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-018.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Lawrence Peters]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ljpeters42@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Consultant - United States]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ana M Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ammoreno@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/016]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A software reference architecture for semantic-aware Big Data systems</title>
		<link>https://biblioteca.sistedes.es/articulo/a-software-reference-architecture-for-semantic-aware-big-data-systems/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-software-reference-architecture-for-semantic-aware-big-data-systems/</guid>
		<description></description>
		<content><![CDATA[Information & Software Technology 90: 75-92 (2017)Impact Factor JCR 2017: 2.694https://doi.org/10.1016/j.infsof.2017.06.001Citas recibidas en 2017 (Google Scholar, 2-3-2018): 3https://scholar.google.es/scholar?oi=bibs&hl=en&cites=13041754256225380312&as_sdt=5---------------------------------- Abstract --------------------------------------Context: Big Data systems are a class of software systems that ingest, store, process and serve massive amounts of heterogeneous data, from multiple sources. Despite their undisputed impact in current society, their engineering is still in its infancy and companies find it difficult to adopt them due to their inherent complexity. Existing attempts to provide architectural guidelines for their engineering fail to take into account important Big Data characteristics, such as the management, evolution and quality of the data.Objective: In this paper, we follow software engineering principles to refine the ?-architecture, a reference model for Big Data systems, and use it as seed to create Bolster, a software reference architecture (SRA) for semantic-aware Big Data systems.Method: By including a new layer into the ?-architecture, the Semantic Layer, Bolster is capable of handling the most representative Big Data characteristics (i.e., Volume, Velocity, Variety, Variability and Veracity).Results: We present the successful implementation of Bolster in three industrial projects, involving five organizations. The validation results show high level of agreement among practitioners from all organizations with respect to standard quality factors.Conclusion: As an SRA, Bolster allows organizations to design concrete architectures tailored to their specific needs. A distinguishing feature is that it provides semantic-awareness in Big Data Systems. These are Big Data system implementations that have components to simplify data definition and exploitation. In particular, they leverage metadata (i.e., data describing data) to enable (partial) automation of data exploitation and to aid the user in their decision making processes. This simplification supports the differentiation of responsibilities into cohesive roles enhancing data governance.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2943</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-software-reference-architecture-for-semantic-aware-big-data-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="data-analysis"><![CDATA[Data analysis]]></category>
		<category domain="post_tag" nicename="data-management"><![CDATA[data management]]></category>
		<category domain="post_tag" nicename="semantic-aware"><![CDATA[Semantic-aware]]></category>
		<category domain="post_tag" nicename="software-reference-architecture"><![CDATA[Software reference architecture]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Information & Software Technology 90: 75-92 (2017)
Impact Factor JCR 2017: 2.694
https://doi.org/10.1016/j.infsof.2017.06.001
Citas recibidas en 2017 (Google Scholar, 2-3-2018): 3
https://scholar.google.es/scholar?oi=bibs&hl=en&cites=13041754256225380312&as_sdt=5

---------------------------------- Abstract --------------------------------------

Context: Big Data systems are a class of software systems that ingest, store, process and serve massive amounts of heterogeneous data, from multiple sources. Despite their undisputed impact in current society, their engineering is still in its infancy and companies find it difficult to adopt them due to their inherent complexity. Existing attempts to provide architectural guidelines for their engineering fail to take into account important Big Data characteristics, such as the management, evolution and quality of the data.

Objective: In this paper, we follow software engineering principles to refine the ?-architecture, a reference model for Big Data systems, and use it as seed to create Bolster, a software reference architecture (SRA) for semantic-aware Big Data systems.

Method: By including a new layer into the ?-architecture, the Semantic Layer, Bolster is capable of handling the most representative Big Data characteristics (i.e., Volume, Velocity, Variety, Variability and Veracity).

Results: We present the successful implementation of Bolster in three industrial projects, involving five organizations. The validation results show high level of agreement among practitioners from all organizations with respect to standard quality factors.

Conclusion: As an SRA, Bolster allows organizations to design concrete architectures tailored to their specific needs. A distinguishing feature is that it provides semantic-awareness in Big Data Systems. These are Big Data system implementations that have components to simplify data definition and exploitation. In particular, they leverage metadata (i.e., data describing data) to enable (partial) automation of data exploitation and to aid the user in their decision making processes. This simplification supports the differentiation of responsibilities into cohesive roles enhancing data governance.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-019.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-019.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Sergi Nadal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[sergi.nadal.francesch@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Víctor Herrero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[vherrero@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Oscar Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[oromero@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Alberto Abello]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aabello@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Xavi Franch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[franch@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Stijn Vansummeren]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[stijn.vansummeren@ulb.ac.be]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Université Libre de Bruxelles - Belgium]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Danilo Valerio]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[danilo.valerio@siemens.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[SIEMENS - Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/017]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Consulta eficiente de datos moleculares: Situación actual y retos futuros</title>
		<link>https://biblioteca.sistedes.es/articulo/consulta-eficiente-de-datos-moleculares-situacion-actual-y-retos-futuros/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/consulta-eficiente-de-datos-moleculares-situacion-actual-y-retos-futuros/</guid>
		<description></description>
		<content><![CDATA[En los últimos años, sectores industriales como el químico o elfarmacéutico vienen demandando la gestión eficiente de datos analíticostales como espectros NMR, o estructuras moleculares. En la actualidadexisten varias bibliotecas quimioinformáticas que pueden ser incorporadasdentro de los SGBDs relacionales. Sin embargo, estas soluciones noson eficaces para todos los tipos de consultas necesarias (datos espectroscópicosy cromatográficos por ejemplo) y no son eficientes para trabajarcon el volumen de datos requerido en la actualidad. En este artículo sedescribe el problema de la búsqueda de datos moleculares y se proporcionauna breve introducción a las soluciones iniciales y retos futuros eneste campo dentro del marco del proyecto NEXTCHROM.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2944</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[consulta-eficiente-de-datos-moleculares-situacion-actual-y-retos-futuros]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="bases-de-datos-de-grafos"><![CDATA[Bases de datos de grafos]]></category>
		<category domain="post_tag" nicename="bases-de-datos-quimicas"><![CDATA[Bases de datos químicas]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="datos-moleculares"><![CDATA[Datos moleculares]]></category>
		<category domain="post_tag" nicename="quimioinformatica"><![CDATA[Quimioinformática]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años, sectores industriales como el químico o el
farmacéutico vienen demandando la gestión eficiente de datos analíticos
tales como espectros NMR, o estructuras moleculares. En la actualidad
existen varias bibliotecas quimioinformáticas que pueden ser incorporadas
dentro de los SGBDs relacionales. Sin embargo, estas soluciones no
son eficaces para todos los tipos de consultas necesarias (datos espectroscópicos
y cromatográficos por ejemplo) y no son eficientes para trabajar
con el volumen de datos requerido en la actualidad. En este artículo se
describe el problema de la búsqueda de datos moleculares y se proporciona
una breve introducción a las soluciones iniciales y retos futuros en
este campo dentro del marco del proyecto NEXTCHROM.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-020.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-020.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Luaces Cachaza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[david.luaces@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[COGRADE - CiTIUS - Universidade de Santiago de Compostela - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Michael Goebel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[michael@metrelab.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Mestrelab Research S.L. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José R.R. Viqueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jrr.viqueira@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Santiago de Compostela - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José Antonio García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jose@mestrelab.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Mestrelab Research S.L. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Tomás F. Pena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[tf.pena@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[CITIUS, University of Santiago de Compostela - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Carlos Cobas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[carlos@mestrelab.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Mestrelab Research S.L. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/018]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Semantic mediation of observation datasets through Sensor Observation Services</title>
		<link>https://biblioteca.sistedes.es/articulo/semantic-mediation-of-observation-datasets-through-sensor-observation-services/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/semantic-mediation-of-observation-datasets-through-sensor-observation-services/</guid>
		<description></description>
		<content><![CDATA[This paper describes a first effort for the semantic mediation between heterogeneous environmental observation datasets through the Sensor Observation Service (SOS) standard proposed by the Open Geospatial Consortium. The solution enables application domain experts to provide an ontology with semantic data integration knowledge, which is next combined with data source knowledge during the evaluation of global SOS GetObservation requests. This enables the development of a more general purpose solution that may be adapted to different application domains by just changing the ontology. Besides, users without specific application domain skills and knowledge may now develop new semantically enabled applications.Finally, the design of the framework is based on the well-known Mediator/Wrapper architecture and follows a Local As View data integration approach, which simplifies the incorporation of new datasets without having to change the existing data integration knowledge.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2945</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[semantic-mediation-of-observation-datasets-through-sensor-observation-services]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="environmental-data"><![CDATA[Environmental data]]></category>
		<category domain="post_tag" nicename="observation-data"><![CDATA[Observation data]]></category>
		<category domain="post_tag" nicename="semantic-mediation"><![CDATA[Semantic mediation]]></category>
		<category domain="post_tag" nicename="semantic-web"><![CDATA[Semantic Web]]></category>
		<category domain="post_tag" nicename="sensor-data"><![CDATA[Sensor data]]></category>
		<category domain="post_tag" nicename="web-service"><![CDATA[Web service]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[This paper describes a first effort for the semantic mediation between heterogeneous environmental observation datasets through the Sensor Observation Service (SOS) standard proposed by the Open Geospatial Consortium. The solution enables application domain experts to provide an ontology with semantic data integration knowledge, which is next combined with data source knowledge during the evaluation of global SOS GetObservation requests. This enables the development of a more general purpose solution that may be adapted to different application domains by just changing the ontology. Besides, users without specific application domain skills and knowledge may now develop new semantically enabled applications.
Finally, the design of the framework is based on the well-known Mediator/Wrapper architecture and follows a Local As View data integration approach, which simplifies the incorporation of new datasets without having to change the existing data integration knowledge.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-021.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-021.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manuel A. Regueiro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[manuelantonio.regueiro@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Santiago de Compostela - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José R.R. Viqueira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrr.viqueira@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Santiago de Compostela - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Christoph Stasch]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[staschc@uni-muenster.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Institute for Geoinformatics; University of Muenster - Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jose Angel Taboada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[Joseangel.taboada@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[USC - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/019]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evaluación y mejora de pruebas de rendimiento utilizando mutación del software: Un enfoque evolutivo</title>
		<link>https://biblioteca.sistedes.es/articulo/evaluacion-y-mejora-de-pruebas-de-rendimiento-utilizando-mutacion-del-software-un-enfoque-evolutivo/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/evaluacion-y-mejora-de-pruebas-de-rendimiento-utilizando-mutacion-del-software-un-enfoque-evolutivo/</guid>
		<description></description>
		<content><![CDATA[Los errores de rendimiento del software pueden causar una importante degradación en la experiencia de usuario y dar lugar a problemas muy costosos de detectar y resolver. Las pruebas de rendimiento persiguen detectar y reducir el impacto de estos errores. Sin embargo, no existen mecanismos para evaluar la calidad de las pruebas de rendimiento, causando en muchos casos, que estos errores pasen desapercibidos. La prueba de mutación es una técnica para evaluar y mejorar las pruebas funcionales a través de la introducción de errores artificiales en el programa bajo prueba. En este artículo, exploramos la aplicabilidad de la prueba de mutación junto con el empleo de un algoritmo evolutivo para buscar mutantes que simulen errores de rendimiento. Esta propuesta noPrueba de mutación, errores de rendimiento, pruebas de rendimiento, algoritmos evolutivos.vedosa contribuye a mejorar la confianza en las pruebas de rendimiento al mismo tiempo que reduce el coste de la prueba de mutación.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2947</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evaluacion-y-mejora-de-pruebas-de-rendimiento-utilizando-mutacion-del-software-un-enfoque-evolutivo]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="algoritmos-evolutivos"><![CDATA[algoritmos evolutivos]]></category>
		<category domain="post_tag" nicename="errores-de-rendimiento"><![CDATA[errores de rendimiento]]></category>
		<category domain="post_tag" nicename="prueba-de-mutacion"><![CDATA[prueba de mutación]]></category>
		<category domain="post_tag" nicename="pruebas-de-rendimiento"><![CDATA[Pruebas de Rendimiento]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los errores de rendimiento del software pueden causar una importante degradación en la experiencia de usuario y dar lugar a problemas muy costosos de detectar y resolver. Las pruebas de rendimiento persiguen detectar y reducir el impacto de estos errores. Sin embargo, no existen mecanismos para evaluar la calidad de las pruebas de rendimiento, causando en muchos casos, que estos errores pasen desapercibidos. La prueba de mutación es una técnica para evaluar y mejorar las pruebas funcionales a través de la introducción de errores artificiales en el programa bajo prueba. En este artículo, exploramos la aplicabilidad de la prueba de mutación junto con el empleo de un algoritmo evolutivo para buscar mutantes que simulen errores de rendimiento. Esta propuesta noPrueba de mutación, errores de rendimiento, pruebas de rendimiento, algoritmos evolutivos.vedosa contribuye a mejorar la confianza en las pruebas de rendimiento al mismo tiempo que reduce el coste de la prueba de mutación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-023.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-023.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ana B. Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[anabsanchez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pedro Delgado-Pérez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pedro.delgado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/021]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación de Interfaces de Usuario a partir de Modelos BPMN con Estereotipos</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-de-interfaces-de-usuario-a-partir-de-modelos-bpmn-con-estereotipos/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/generacion-de-interfaces-de-usuario-a-partir-de-modelos-bpmn-con-estereotipos/</guid>
		<description></description>
		<content><![CDATA[La notación de modelo de procesos de negocio (BPMN – Business Process Model Notation) proporciona a las organizaciones un estándar que facilita una mayor compresión del proceso empresarial. BPMN se centra en los procesos funcionales, dejando el desarrollo de las interfaces a un lado. De este modo, el diseño de la interfaz generalmente depende de la experiencia subjetiva del analista y no existe un procedimiento para extraer la interfaz de los procesos. Este artículo propone un nuevo método para generar interfaces de usuario a partir de modelos BPMN y Diagramas de Clases. La propuesta se basa en la identificación de reglas de generación de procesos a interfaces. Se han definido estereotipos para extender la notación BPMN en aquellas reglas donde haya más de una posible transformación. Estos estereotipos permiten aplicar la regla de forma inequívoca. Las reglas se extrajeron de cinco proyectos, tres existentes en el repositorio de Bizagi y dos de empresas reales. Específicamente, la propuesta se basa en la extracción de reglas para generar interfaces de usuario basadas en tres patrones, Patrón de Secuencia, Patrón de Decisión Implícita y Patrón de Ejecución Intercalada. Como resultado de nuestra propuesta, se han agregado catorce nuevos estereotipos a la notación BPMN. Para ilustrar la propuesta, los estereotipos se aplicaron a un ejemplo ilustrativo. Los resultados muestran que este trabajo es un "paso adelante" para la generación automática de códigos a partir modelos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2948</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-de-interfaces-de-usuario-a-partir-de-modelos-bpmn-con-estereotipos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="bpmn"><![CDATA[BPMN]]></category>
		<category domain="post_tag" nicename="estereotipos"><![CDATA[Estereotipos]]></category>
		<category domain="post_tag" nicename="interfaces-de-usuario"><![CDATA[Interfaces de usuario]]></category>
		<category domain="post_tag" nicename="metodo"><![CDATA[Método]]></category>
		<category domain="post_tag" nicename="reglas"><![CDATA[Reglas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La notación de modelo de procesos de negocio (BPMN – Business Process Model Notation) proporciona a las organizaciones un estándar que facilita una mayor compresión del proceso empresarial. BPMN se centra en los procesos funcionales, dejando el desarrollo de las interfaces a un lado. De este modo, el diseño de la interfaz generalmente depende de la experiencia subjetiva del analista y no existe un procedimiento para extraer la interfaz de los procesos. Este artículo propone un nuevo método para generar interfaces de usuario a partir de modelos BPMN y Diagramas de Clases. La propuesta se basa en la identificación de reglas de generación de procesos a interfaces. Se han definido estereotipos para extender la notación BPMN en aquellas reglas donde haya más de una posible transformación. Estos estereotipos permiten aplicar la regla de forma inequívoca. Las reglas se extrajeron de cinco proyectos, tres existentes en el repositorio de Bizagi y dos de empresas reales. Específicamente, la propuesta se basa en la extracción de reglas para generar interfaces de usuario basadas en tres patrones, Patrón de Secuencia, Patrón de Decisión Implícita y Patrón de Ejecución Intercalada. Como resultado de nuestra propuesta, se han agregado catorce nuevos estereotipos a la notación BPMN. Para ilustrar la propuesta, los estereotipos se aplicaron a un ejemplo ilustrativo. Los resultados muestran que este trabajo es un "paso adelante" para la generación automática de códigos a partir modelos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-024.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-024.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Eduardo Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[diazsua@alumni.uv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Valencia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Ignacio Panach]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[joigpana@uv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Valencia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Silvia Rueda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[silvia.rueda@uv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Valencia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Oscar Pastor]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[opastor@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Centro de Investigación en Métodos de Producción de Software, Universidad Politécnica de Valencia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/022]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>The MegaM@Rt2 ECSEL Project: MegaModelling at Runtime -- Scalable Model-based Framework for Continuous Development and Runtime Validation of Complex Systems</title>
		<link>https://biblioteca.sistedes.es/articulo/the-megamrt2-ecsel-project-megamodelling-at-runtime-scalable-model-based-framework-for-continuous-development-and-runtime-validation-of-complex-systems/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/the-megamrt2-ecsel-project-megamodelling-at-runtime-scalable-model-based-framework-for-continuous-development-and-runtime-validation-of-complex-systems/</guid>
		<description></description>
		<content><![CDATA[A major challenge for the European electronic components and systems (ECS) industry is to increase productivity and reduce costs while ensuring safety and quality. Model-Driven Engineering (MDE) principles have already shown valuable capabilities for the development of ECSs but still need to scale to support real-world scenarios implied by the full deployment and use of complex electronic systems, such as Cyber-Physical Systems, and real-time systems. Moreover, maintaining efficient traceability, integration and communication between fundamental stages of the development lifecycle (i.e., design time and runtime) is another challenge to the scalability of MDE tools and techniques. This paper presents "MegaModelling at runtime -- Scalable model-based framework for continuous development and runtime validation of complex systems" (MegaM@Rt2), an ECSEL--JU project whose main goal is to address the above mentioned challenges. Driven by both large and small industrial enterprises, with the support of research partners and technology providers, MegaM@Rt2 aims to deliver a framework of tools and methods for: (i) system engineering/design and continuous development,(ii) related runtime analysis, and (iii) global model and traceability management.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2949</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[the-megamrt2-ecsel-project-megamodelling-at-runtime-scalable-model-based-framework-for-continuous-development-and-runtime-validation-of-complex-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="megamodelling"><![CDATA[megamodelling]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<category domain="post_tag" nicename="runtime"><![CDATA[Runtime]]></category>
		<category domain="post_tag" nicename="system-design"><![CDATA[system design]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A major challenge for the European electronic components and systems (ECS) industry is to increase productivity and reduce costs while ensuring safety and quality. Model-Driven Engineering (MDE) principles have already shown valuable capabilities for the development of ECSs but still need to scale to support real-world scenarios implied by the full deployment and use of complex electronic systems, such as Cyber-Physical Systems, and real-time systems. Moreover, maintaining efficient traceability, integration and communication between fundamental stages of the development lifecycle (i.e., design time and runtime) is another challenge to the scalability of MDE tools and techniques. This paper presents "MegaModelling at runtime -- Scalable model-based framework for continuous development and runtime validation of complex systems" (MegaM@Rt2), an ECSEL--JU project whose main goal is to address the above mentioned challenges. Driven by both large and small industrial enterprises, with the support of research partners and technology providers, MegaM@Rt2 aims to deliver a framework of tools and methods for: (i) system engineering/design and continuous development,(ii) related runtime analysis, and (iii) global model and traceability management.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-025.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-025.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Abel Gómez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[agomezlla@uoc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Oberta de Catalunya - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Orlando Ávila-García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[orlando.avila@atos.net]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Atos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jordi Cabot]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jordi.cabot@icrea.cat]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ICREA - UOC (Internet interdisciplinary institute) - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José Ramón Juárez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jrjuarez@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[IK4-IKERLAN Research Center - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Aitor Urbieta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aurbieta@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[IK4-IKERLAN Research Center - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Eugenio Villar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[villar@teisa.unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad de Cantabria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/023]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[8]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evaluación automática de modelos aplicando técnicas de MBE</title>
		<link>https://biblioteca.sistedes.es/articulo/evaluacion-automatica-de-modelos-aplicando-tecnicas-de-mbe/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/evaluacion-automatica-de-modelos-aplicando-tecnicas-de-mbe/</guid>
		<description></description>
		<content><![CDATA[La construcción de modelos, como proceso de abstracción para definir una solución software, es una tarea que requiere ingenieros con cierta experiencia. Por un lado, modelos diferentes pueden ser igual de válidos para describir una misma solución y, por otro lado, disponer de una guía durante el aprendizaje de tareas de modelado puede ayudar a optimizar el proceso de desarrollo. Este artículo describe una propuesta para dar soporte a la evaluación de modelos utilizados durante las fases de análisis y diseño de un desarrollo de software. En particular, nuestro trabajo se aplica en la evaluación de modelos de casos de uso, clases y secuencias, como artefactos principales en la captura de requisitos, la descomposición modular y la descripción de comportamientos, respectivamente. Para evaluar dichos modelos, se ejecuta un conjunto de pruebas unitarias que son creadas automáticamente a partir de modelos de pruebas definidos conforme a un lenguaje específico de dominio.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2950</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evaluacion-automatica-de-modelos-aplicando-tecnicas-de-mbe]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="evaluacion"><![CDATA[Evaluación]]></category>
		<category domain="post_tag" nicename="generacion-automatica-de-pruebas"><![CDATA[Generación automática de pruebas]]></category>
		<category domain="post_tag" nicename="ingenieria-basada-en-modelos-mbe"><![CDATA[Ingeniería Basada en Modelos (MBE)]]></category>
		<category domain="post_tag" nicename="transformacion-modelo-a-texto-m2t"><![CDATA[Transformación Modelo-a-Texto (M2T)]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La construcción de modelos, como proceso de abstracción para definir una solución software, es una tarea que requiere ingenieros con cierta experiencia. Por un lado, modelos diferentes pueden ser igual de válidos para describir una misma solución y, por otro lado, disponer de una guía durante el aprendizaje de tareas de modelado puede ayudar a optimizar el proceso de desarrollo. Este artículo describe una propuesta para dar soporte a la evaluación de modelos utilizados durante las fases de análisis y diseño de un desarrollo de software. En particular, nuestro trabajo se aplica en la evaluación de modelos de casos de uso, clases y secuencias, como artefactos principales en la captura de requisitos, la descomposición modular y la descripción de comportamientos, respectivamente. Para evaluar dichos modelos, se ejecuta un conjunto de pruebas unitarias que son creadas automáticamente a partir de modelos de pruebas definidos conforme a un lenguaje específico de dominio.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-026.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-026.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Criado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[javi.criado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Informática Aplicada, Universidad de Almería - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Joaquín Cañadas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jjcanada@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Almería - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Luis Iribarne]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[luis.iribarne@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Informática Aplicada, Universidad de Almería - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/024]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Formally Modeling, Executing, and Testing Service-Oriented Systems with UML and OCL (YA PUBLICADO)</title>
		<link>https://biblioteca.sistedes.es/articulo/formally-modeling-executing-and-testing-service-oriented-systems-with-uml-and-ocl-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/formally-modeling-executing-and-testing-service-oriented-systems-with-uml-and-ocl-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[One of the issues that developers of service-oriented systems currently discuss is the lack of practical, but formal modeling notations and tools that can address the many different, important aspects. This paper presents an approach to model structural and behavioral properties of service-oriented systems with UML and OCL models. Essential service-oriented concepts as service request, service provision or orchestration are formally represented by UML concepts. The models can be executed, tested and analyzed. Feedback is given to the developer in terms of the UML and OCL model.Our approach supports the automatic generation of test scenarios in which, for example, the availability of services can be checked. Furthermore, the consistency of the service model can be proved by constructing test scenarios.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2951</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[formally-modeling-executing-and-testing-service-oriented-systems-with-uml-and-ocl-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="formal-modeling"><![CDATA[Formal modeling]]></category>
		<category domain="post_tag" nicename="service-oriented-systems"><![CDATA[Service-oriented systems]]></category>
		<category domain="post_tag" nicename="uml-ocl"><![CDATA[UML/OCL]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[One of the issues that developers of service-oriented systems currently discuss is the lack of practical, but formal modeling notations and tools that can address the many different, important aspects. This paper presents an approach to model structural and behavioral properties of service-oriented systems with UML and OCL models. Essential service-oriented concepts as service request, service provision or orchestration are formally represented by UML concepts. The models can be executed, tested and analyzed. Feedback is given to the developer in terms of the UML and OCL model.
Our approach supports the automatic generation of test scenarios in which, for example, the availability of services can be checked. Furthermore, the consistency of the service model can be proved by constructing test scenarios.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-027.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-027.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Loli Burgueño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[loli@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Málaga, GISUM/Atenea Research Group - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Martin Gogolla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gogolla@informatik.uni-bremen.de]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Database Systems Group, University of Bremen - Germany]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/025]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia la integración de lenguajes de modelado para el diseño de servicios</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-la-integracion-de-lenguajes-de-modelado-para-el-diseno-de-servicios/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/hacia-la-integracion-de-lenguajes-de-modelado-para-el-diseno-de-servicios/</guid>
		<description></description>
		<content><![CDATA[A día de hoy existen diversas técnicas o notaciones para el modelado de negocio y/o procesos de negocio que permiten, con mayor o menor nivel de detalle, comprender, conceptualizar y representar la forma en que una organización es capaz de generar valor. Estas técnicas presentan similitudes y diferencias, pero en la mayoría de los casos la información que proporcionan es complementaria. Sin embargo, en la actualidad no existe un entorno tecnológico que permita trabajar eficazmente con varias de estas notaciones. Para afrontar este problema, en trabajos anteriores abordamos el desarrollo de un entorno de modelado que integrase un conjunto de DSLs visuales para dar soporte a la gestión integrada de diferentes notaciones para el modelado de negocio, como Canvas, e3value, Service Blueprint, PCN o BPMN. Una vez que disponemos de una primera versión funcional de este entorno, el siguiente paso que pretendemos abordar es el que se expone en este trabajo: el análisis de las correspondencias entre esas notaciones, y la consecuente automatización de las tareas o actividades que pueden derivarse de la identificación de esas relaciones.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2952</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-la-integracion-de-lenguajes-de-modelado-para-el-diseno-de-servicios]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="business-modeling"><![CDATA[Business Modeling]]></category>
		<category domain="post_tag" nicename="business-process-modeling"><![CDATA[Business Process Modeling]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<category domain="post_tag" nicename="service-design"><![CDATA[Service Design]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[A día de hoy existen diversas técnicas o notaciones para el modelado de negocio y/o procesos de negocio que permiten, con mayor o menor nivel de detalle, comprender, conceptualizar y representar la forma en que una organización es capaz de generar valor. Estas técnicas presentan similitudes y diferencias, pero en la mayoría de los casos la información que proporcionan es complementaria. Sin embargo, en la actualidad no existe un entorno tecnológico que permita trabajar eficazmente con varias de estas notaciones. Para afrontar este problema, en trabajos anteriores abordamos el desarrollo de un entorno de modelado que integrase un conjunto de DSLs visuales para dar soporte a la gestión integrada de diferentes notaciones para el modelado de negocio, como Canvas, e3value, Service Blueprint, PCN o BPMN. Una vez que disponemos de una primera versión funcional de este entorno, el siguiente paso que pretendemos abordar es el que se expone en este trabajo: el análisis de las correspondencias entre esas notaciones, y la consecuente automatización de las tareas o actividades que pueden derivarse de la identificación de esas relaciones.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-028.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-028.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Francisco Javier Pérez Blanco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[francisco.perez@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group, University Rey Juan Carlos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group, University Rey Juan Carlos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[María Valeria De Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[valeria.decastro@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group, University Rey Juan Carlos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[David Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[david.granada@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group, University Rey Juan Carlos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group, University Rey Juan Carlos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/026]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evolutionary composition of QoS-aware web services: A many-objective perspective</title>
		<link>https://biblioteca.sistedes.es/articulo/evolutionary-composition-of-qos-aware-web-services-a-many-objective-perspective/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/evolutionary-composition-of-qos-aware-web-services-a-many-objective-perspective/</guid>
		<description></description>
		<content><![CDATA[Web service based applications often invoke services provided by third-parties in their workflow. The Quality of Service (QoS) provided by the invoked supplier can be expressed in terms of the Service Level Agreement specifying the values contracted for particular aspects like cost or throughput, among others. In this scenario, intelligent systems can support the engineer to scrutinise the service market in order to select those candidates that best fit with the expected composition focusing on different QoS aspects. This search problem, also known as QoS-aware web service composition, is characterised by the presence of many diverse QoS properties to be simultaneously optimised from a multi-objective perspective. Nevertheless, as the number of QoS properties considered during the design phase increases and a larger number of decision factors come into play, it becomes more difficult to find the most suitable candidate solutions, so more sophisticated techniques are required to explore and return diverse, competitive alternatives. With this aim, this paper explores the suitability of many objective evolutionary algorithms for addressing the binding problem of web services on the basis of a real-world benchmark with 9 QoS properties. A complete comparative study demonstrates that these techniques, never before applied to this problem, can achieve a better trade-off between all the QoS properties, or even promote specific QoS properties while keeping high values for the rest. In addition, this search process can be performed within a reasonable computational cost, enabling its adoption by intelligent and decision-support systems in the field of service oriented computation.Publicado en: Expert Systems with Applications, vol. 72, pp.357-370. 2017. DOI: http://dx.doi.org/10.1016/j.eswa.2016.10.047.IF(2016): 3,928 [18/133 Artificial Intelligence] (Q1).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2953</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evolutionary-composition-of-qos-aware-web-services-a-many-objective-perspective]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="many-objective-evolutionary-algorithms"><![CDATA[many-objective evolutionary algorithms]]></category>
		<category domain="post_tag" nicename="multi-objective-optimization"><![CDATA[multi-objective optimization]]></category>
		<category domain="post_tag" nicename="qos-aware-web-service-composition"><![CDATA[QoS-aware web service composition]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Web service based applications often invoke services provided by third-parties in their workflow. The Quality of Service (QoS) provided by the invoked supplier can be expressed in terms of the Service Level Agreement specifying the values contracted for particular aspects like cost or throughput, among others. In this scenario, intelligent systems can support the engineer to scrutinise the service market in order to select those candidates that best fit with the expected composition focusing on different QoS aspects. This search problem, also known as QoS-aware web service composition, is characterised by the presence of many diverse QoS properties to be simultaneously optimised from a multi-objective perspective. Nevertheless, as the number of QoS properties considered during the design phase increases and a larger number of decision factors come into play, it becomes more difficult to find the most suitable candidate solutions, so more sophisticated techniques are required to explore and return diverse, competitive alternatives. With this aim, this paper explores the suitability of many objective evolutionary algorithms for addressing the binding problem of web services on the basis of a real-world benchmark with 9 QoS properties. A complete comparative study demonstrates that these techniques, never before applied to this problem, can achieve a better trade-off between all the QoS properties, or even promote specific QoS properties while keeping high values for the rest. In addition, this search process can be performed within a reasonable computational cost, enabling its adoption by intelligent and decision-support systems in the field of service oriented computation.

Publicado en: Expert Systems with Applications, vol. 72, pp.357-370. 2017. DOI: http://dx.doi.org/10.1016/j.eswa.2016.10.047.

IF(2016): 3,928 [18/133 Artificial Intelligence] (Q1).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-029.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-029.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aurora Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aramirez@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Antonio Parejo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[japarejo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José Raúl Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/027]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Diseño de un marco de trabajo dirigido por modelos y soportado por herramientas para mejorar la gestión de guías clínicas y procesos asistenciales</title>
		<link>https://biblioteca.sistedes.es/articulo/diseno-de-un-marco-de-trabajo-dirigido-por-modelos-y-soportado-por-herramientas-para-mejorar-la-gestion-de-guias-clinicas-y-procesos-asistenciales/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/diseno-de-un-marco-de-trabajo-dirigido-por-modelos-y-soportado-por-herramientas-para-mejorar-la-gestion-de-guias-clinicas-y-procesos-asistenciales/</guid>
		<description></description>
		<content><![CDATA[El Proyecto IDE4ICDS se mueve en el contexto médico para dar solu-ción a la gestión del ciclo de vida de guías clínicas. Actualmente, las guías clíni-cas están definidas de forma textual, lo que las hace difíciles de seguir en el día a día. Esto provoca, entre otros factores, variabilidad en la práctica clínica. En este proyecto se presenta una metodología guiada por modelos que permite auto-matizar la gestión de guías clínicas, así como una plataforma software que le de soporte, permitiendo definir, ejecutar y monitorizar guías clínicas. Dicha plata-forma ha sido validada con profesionales sanitarios del Hospital Virgen del Rocío (Sevilla), obteniendo resultados prometedores. Actualmente se encuentra en fase de pilotaje en Atención Primaria con pacientes que sufren Diabetes Mellitus Tipo 2.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2954</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[diseno-de-un-marco-de-trabajo-dirigido-por-modelos-y-soportado-por-herramientas-para-mejorar-la-gestion-de-guias-clinicas-y-procesos-asistenciales]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="clinical-decision-support"><![CDATA[Clinical Decision Support]]></category>
		<category domain="post_tag" nicename="clinical-practices-guidelines"><![CDATA[Clinical Practices Guidelines]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El Proyecto IDE4ICDS se mueve en el contexto médico para dar solu-ción a la gestión del ciclo de vida de guías clínicas. Actualmente, las guías clíni-cas están definidas de forma textual, lo que las hace difíciles de seguir en el día a día. Esto provoca, entre otros factores, variabilidad en la práctica clínica. En este proyecto se presenta una metodología guiada por modelos que permite auto-matizar la gestión de guías clínicas, así como una plataforma software que le de soporte, permitiendo definir, ejecutar y monitorizar guías clínicas. Dicha plata-forma ha sido validada con profesionales sanitarios del Hospital Virgen del Rocío (Sevilla), obteniendo resultados prometedores. Actualmente se encuentra en fase de pilotaje en Atención Primaria con pacientes que sufren Diabetes Mellitus Tipo 2.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-030.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-030.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Virginia Cid De La Paz Furest]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[virginia.cid@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[IWT2 Group. University of Seville. Spain. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Julián Alberto García García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[julian.garcia@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[IWT2 Group. University of Seville. Spain. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Ramos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanmanuel.ramos@soltel.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Soltel S.A - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[M.J. Escalona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mjescalona@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/028]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Expansión cuantitativa del método MoSCoW para la priorización de requisitos</title>
		<link>https://biblioteca.sistedes.es/articulo/expansion-cuantitativa-del-metodo-moscow-para-la-priorizacion-de-requisitos/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/expansion-cuantitativa-del-metodo-moscow-para-la-priorizacion-de-requisitos/</guid>
		<description></description>
		<content><![CDATA[La priorización de los requisitos a ser incluidos en el producto ?nal es un complejo proceso de decisión multicriterio que suele implicar llegar al equilibrio entre el bene?cio para el negocio de cada requisito y el consumo de recursos. Existen distintos factores y dimensiones a considerar en la priorización de requisitos, muchos de ellos de carácter cualitativo. Sin embargo, algunos métodos también han utilizado las propiedades cuantitativas estimadas, siendo muchas de estas soluciones del ámbito de las técnicas de optimización. En este trabajo se propone y estudia la validez de un algoritmo de agrupamiento muy conocido, k-medias, junto con el método subjetivo más ampliamente utilizado, el método MoSCoW, para la priorización de requisitos. Los resultados experimentales, sobre dos casos de 20 y 100 requisitos respectivamente, muestran la validez de la propuesta en la identi?cación de los requisitos que dan mayor valor al sistema a construir y que aseguran el mayor bene?cio en el proyecto.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2955</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[expansion-cuantitativa-del-metodo-moscow-para-la-priorizacion-de-requisitos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="ingenieria-de-requisitos"><![CDATA[ingeniería de requisitos]]></category>
		<category domain="post_tag" nicename="k-medias"><![CDATA[k-medias]]></category>
		<category domain="post_tag" nicename="moscow"><![CDATA[MoSCoW]]></category>
		<category domain="post_tag" nicename="priorizacion-de-requisitos"><![CDATA[Priorización de requisitos]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La priorización de los requisitos a ser incluidos en el producto ?nal es un complejo proceso de decisión multicriterio que suele implicar llegar al equilibrio entre el bene?cio para el negocio de cada requisito y el consumo de recursos. Existen distintos factores y dimensiones a considerar en la priorización de requisitos, muchos de ellos de carácter cualitativo. Sin embargo, algunos métodos también han utilizado las propiedades cuantitativas estimadas, siendo muchas de estas soluciones del ámbito de las técnicas de optimización. En este trabajo se propone y estudia la validez de un algoritmo de agrupamiento muy conocido, k-medias, junto con el método subjetivo más ampliamente utilizado, el método MoSCoW, para la priorización de requisitos. Los resultados experimentales, sobre dos casos de 20 y 100 requisitos respectivamente, muestran la validez de la propuesta en la identi?cación de los requisitos que dan mayor valor al sistema a construir y que aseguran el mayor bene?cio en el proyecto.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-031.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-031.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Del Sagrado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jsagrado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Informatics, University of Almería - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Isabel María Del Águila]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[imaguila@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Almería - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/029]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Obtención de diagramas de objetivos para sistemas Teleo-Reactivos: una aproximación metodológica</title>
		<link>https://biblioteca.sistedes.es/articulo/obtencion-de-diagramas-de-objetivos-para-sistemas-teleo-reactivos-una-aproximacion-metodologica/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:50 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/obtencion-de-diagramas-de-objetivos-para-sistemas-teleo-reactivos-una-aproximacion-metodologica/</guid>
		<description></description>
		<content><![CDATA[Este artículo presenta un método para obtener un diagrama TRiStar partiendo de la descripción textual de un sistema Teleo-Reactivo. El método se ilustra con un ejemplo clásico en la literatura de sistemas Teleo-Reactivos: el recolector de latas. El uso de este método permitirá facilitar la especificación y la reutilización de sistemas Teleo-Reactivos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2956</post_id>
		<post_date><![CDATA[2018-07-26 06:17:50]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:50]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[obtencion-de-diagramas-de-objetivos-para-sistemas-teleo-reactivos-una-aproximacion-metodologica]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="metodologia"><![CDATA[Metodología]]></category>
		<category domain="post_tag" nicename="teleo-reactivo"><![CDATA[Teleo-Reactivo]]></category>
		<category domain="post_tag" nicename="tristar"><![CDATA[TRiStar]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo presenta un método para obtener un diagrama TRiStar partiendo de la descripción textual de un sistema Teleo-Reactivo. El método se ilustra con un ejemplo clásico en la literatura de sistemas Teleo-Reactivos: el recolector de latas. El uso de este método permitirá facilitar la especificación y la reutilización de sistemas Teleo-Reactivos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-032.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-032.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José M Morales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[josemiguel.morales@upct.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[UPCT - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pedro Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pedro.sanchez@upct.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[UPCT - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Bárbara Álvarez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[balvarez@upct.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[UPCT - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Sanchez Garcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[a.sanchez@electronica-submarina.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[SAES - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Elena Navarro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[Elena.Navarro@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/030]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>MOTIV: selección de pruebas para algoritmos de detección de movimiento en vídeos usando técnicas de líneas de productos software</title>
		<link>https://biblioteca.sistedes.es/articulo/motiv-seleccion-de-pruebas-para-algoritmos-de-deteccion-de-movimiento-en-videos-usando-tecnicas-de-lineas-de-productos-software/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/motiv-seleccion-de-pruebas-para-algoritmos-de-deteccion-de-movimiento-en-videos-usando-tecnicas-de-lineas-de-productos-software/</guid>
		<description></description>
		<content><![CDATA[Las líneas de producto software se usan para gestionar la producción de sistemas software con un alto grado de variabilidad lo que puede permitir tener un mejor tiempo de respuesta para poder configurar un producto de acuerdo a sus especificaciones concretas en un escenario de uso determinado. La investigación en líneas de producto software se ha centrado en las últimas décadas en proponer procesos, técnicas, herramientas y métodos para gestionar la variabilidad a todos los niveles: desde los requisitos, hasta la generación de código. En este sentido, se han desarrollado distintas técnicas que pueden ser utilizadas en distintos escenarios  más allá de la gestión de líneas de producto software. Es el caso del conocido como análisis automático de modelos de características. En este proyecto se usaron técnicas que provienen de este área para afrontar un reto tecnológico en un consorcio con empresas que usaban distintos algoritmos para detectar movimientos en sistemas de vídeo vigilancia. En concreto, se usaron técnicas de modelado y selección de casos de prueba usando modelos de características. La aportación tecnológica permitió una reducción considerable de los costes en la producción de algoritmos de detección de movimientos y la mejora en la detección de fallos en los sistemas. El consorcio estuvo formado por dos empresas francesas e INRIA donde trabajaban varios de los autores del trabajo en el momento de la ejecución del proyecto. Además, se contó con el asesoramiento de la Universidad de Sevilla.   keywords{líneas de producto software, modelos de características, selección de pruebas]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2957</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[motiv-seleccion-de-pruebas-para-algoritmos-de-deteccion-de-movimiento-en-videos-usando-tecnicas-de-lineas-de-productos-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="lineas-de-producto-software"><![CDATA[Líneas de Producto Software]]></category>
		<category domain="post_tag" nicename="modelos-de-caracteristicas"><![CDATA[modelos de características]]></category>
		<category domain="post_tag" nicename="seleccion-de-pruebas"><![CDATA[selección de pruebas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las líneas de producto software se usan para gestionar la producción de sistemas software con un alto grado de variabilidad lo que puede permitir tener un mejor tiempo de respuesta para poder configurar un producto de acuerdo a sus especificaciones concretas en un escenario de uso determinado. La investigación en líneas de producto software se ha centrado en las últimas décadas en proponer procesos, técnicas, herramientas y métodos para gestionar la variabilidad a todos los niveles: desde los requisitos, hasta la generación de código. En este sentido, se han desarrollado distintas técnicas que pueden ser utilizadas en distintos escenarios  más allá de la gestión de líneas de producto software. Es el caso del conocido como análisis automático de modelos de características. En este proyecto se usaron técnicas que provienen de este área para afrontar un reto tecnológico en un consorcio con empresas que usaban distintos algoritmos para detectar movimientos en sistemas de vídeo vigilancia. En concreto, se usaron técnicas de modelado y selección de casos de prueba usando modelos de características. La aportación tecnológica permitió una reducción considerable de los costes en la producción de algoritmos de detección de movimientos y la mejora en la detección de fallos en los sistemas. El consorcio estuvo formado por dos empresas francesas e INRIA donde trabajaban varios de los autores del trabajo en el momento de la ejecución del proyecto. Además, se contó con el asesoramiento de la Universidad de Sevilla.
keywords{líneas de producto software, modelos de características, selección de pruebas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-033.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-033.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José A. Galindo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jagalindo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mauricio Alférez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[alferez@svv.lu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Luxembourg - Luxembourg]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Mathieu Acher]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mathieu.acher@irisa.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[INRIA - France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Benoit Baudry]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[baudry@kth.se]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[KTH Royal Institute of Technology - Sweden]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[David Benavides]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[benavides@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/031]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Usabilidad de Software: Una Apuesta Corporativa</title>
		<link>https://biblioteca.sistedes.es/articulo/usabilidad-de-software-una-apuesta-corporativa/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/usabilidad-de-software-una-apuesta-corporativa/</guid>
		<description></description>
		<content><![CDATA[Este trabajo presenta los resultados de una síntesis cualitativa de la literatura orientada a identificar pautas y recomendaciones que ayuden a integrar la usabilidad en una organización software desde el punto de vista corporativo. Los resultados constituyen el primer paso para definir un conjunto de guías y prácticas que puedan usar los gestores o responsables de calidad de las organizaciones software para crear una cultura de usabilidad que ayude a integrar dicho atributo de calidad de manera sostenible en los distintos proyectos de la organización. La metodología utilizada es la síntesis temática, con la que se han sintetizado 44 artículos dando como resultado la identificación de cinco prácticas generales que agrupan otras 13 prácticas más concretas para abordar este fin. Finalmente, se presenta un modelo de interrelaciones entre las distintas prácticas identificadas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2958</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[usabilidad-de-software-una-apuesta-corporativa]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="experiencia-de-usuarios"><![CDATA[experiencia de usuarios]]></category>
		<category domain="post_tag" nicename="sintesis-tematica"><![CDATA[síntesis temática]]></category>
		<category domain="post_tag" nicename="usabilidad"><![CDATA[usabilidad]]></category>
		<category domain="post_tag" nicename="usabilidad-a-nivel-organizativo"><![CDATA[usabilidad a nivel organizativo]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este trabajo presenta los resultados de una síntesis cualitativa de la literatura orientada a identificar pautas y recomendaciones que ayuden a integrar la usabilidad en una organización software desde el punto de vista corporativo. Los resultados constituyen el primer paso para definir un conjunto de guías y prácticas que puedan usar los gestores o responsables de calidad de las organizaciones software para crear una cultura de usabilidad que ayude a integrar dicho atributo de calidad de manera sostenible en los distintos proyectos de la organización. La metodología utilizada es la síntesis temática, con la que se han sintetizado 44 artículos dando como resultado la identificación de cinco prácticas generales que agrupan otras 13 prácticas más concretas para abordar este fin. Finalmente, se presenta un modelo de interrelaciones entre las distintas prácticas identificadas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-034.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-034.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carmen L. Carvajal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carmen.carvajal07@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Ana M. Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ammoreno@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/032]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automated inference of likely metamorphic relations for model transformations (YA PUBLICADO)</title>
		<link>https://biblioteca.sistedes.es/articulo/automated-inference-of-likely-metamorphic-relations-for-model-transformations-ya-publicado/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/automated-inference-of-likely-metamorphic-relations-for-model-transformations-ya-publicado/</guid>
		<description></description>
		<content><![CDATA[Model transformations play a cornerstone role in Model-Driven Engineering (MDE) as they provide the essential mechanisms for manipulating and transforming models. Checking whether the output of a model transformation is correct is a manual and errorprone task, referred to as the oracle problem. Metamorphic testing alleviates the oracle problem by exploiting the relations among different inputs and outputs of the program under test, so-called metamorphic relations (MRs). One of the main challenges in metamorphic testing is the automated inference of likely MRs. This paper proposes an approach to automatically infer likely MRs for ATL model transformations, where the tester does not need to have any knowledge of the transformation. The inferred MRs aim at detecting faults in model transformations in three application scenarios, namely regression testing, incremental transformations and migrations among transformation languages. In the experiments performed, the inferred likely MRs have proved to be quite accurate, with a precision of 96.4% from a total of 4101 true positives out of 4254 MRs inferred. Furthermore, they have been useful for identifying mutants in regression testing scenarios, with a mutation score of 93.3%. Finally, our approach can be used in conjunction with current approaches for the automatic generation of test cases. Artículo publicado en The Journal of Systems and Software, Vol 136, pp 188-208 (Available Online May 2017; Final Published Version February 2018) - Q1. http://dx.doi.org/10.1016/j.jss.2017.05.043]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2959</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automated-inference-of-likely-metamorphic-relations-for-model-transformations-ya-publicado]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="automatic-inference"><![CDATA[Automatic inference]]></category>
		<category domain="post_tag" nicename="generic-approach"><![CDATA[Generic approach]]></category>
		<category domain="post_tag" nicename="metamorphic-relations"><![CDATA[Metamorphic relations]]></category>
		<category domain="post_tag" nicename="metamorphic-testing"><![CDATA[metamorphic testing]]></category>
		<category domain="post_tag" nicename="model-transformations"><![CDATA[model transformations]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Model transformations play a cornerstone role in Model-Driven Engineering (MDE) as they provide the essential mechanisms for manipulating and transforming models. Checking whether the output of a model transformation is correct is a manual and errorprone task, referred to as the oracle problem. Metamorphic testing alleviates the oracle problem by exploiting the relations among different inputs and outputs of the program under test, so-called metamorphic relations (MRs). One of the main challenges in metamorphic testing is the automated inference of likely MRs.

This paper proposes an approach to automatically infer likely MRs for ATL model transformations, where the tester does not need to have any knowledge of the transformation. The inferred MRs aim at detecting faults in model transformations in three application scenarios, namely regression testing, incremental transformations and migrations among transformation languages. In the experiments performed, the inferred likely MRs have proved to be quite accurate, with a precision of 96.4% from a total of 4101 true positives out of 4254 MRs inferred. Furthermore, they have been useful for identifying mutants in regression testing scenarios, with a mutation score of 93.3%. Finally, our approach can be used in conjunction with current approaches for the automatic
generation of test cases.

Artículo publicado en The Journal of Systems and Software, Vol 136, pp 188-208 (Available Online May 2017; Final Published Version February 2018) - Q1.
http://dx.doi.org/10.1016/j.jss.2017.05.043]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-036.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-036.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Troya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jtroya@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Segura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[sergiosegura@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/033]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación de datos NoSQL usando esquemas de bases de datos inferidos</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-de-datos-nosql-usando-esquemas-de-bases-de-datos-inferidos/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/generacion-de-datos-nosql-usando-esquemas-de-bases-de-datos-inferidos/</guid>
		<description></description>
		<content><![CDATA[La generación automática de datos resulta muy adecuada para realizar pruebas sobre bases de datos. Para sistemas relacionales se han definido diferentes enfoques y existe un buen número de herramientas. Sin embargo, todavía se ha prestado escasa atención a este problema para sistemas NoSQL. En este trabajo se presenta un primer prototipo de una herramienta desarrollada para generar datos NoSQL a partir de esquemas inferidos y representados como modelos conformes al metamodelo NoSQLSchema. Se describe el proceso de generación y la validación realizados, y se comenta el trabajo futuro.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2960</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-de-datos-nosql-usando-esquemas-de-bases-de-datos-inferidos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="generacion-de-bases-de-datos"><![CDATA[Generación de bases de datos]]></category>
		<category domain="post_tag" nicename="mongodb"><![CDATA[MongoDB]]></category>
		<category domain="post_tag" nicename="sistemas-nosql"><![CDATA[Sistemas NoSQL]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La generación automática de datos resulta muy adecuada para realizar pruebas sobre bases de datos. Para sistemas relacionales se han definido diferentes enfoques y existe un buen número de herramientas. Sin embargo, todavía se ha prestado escasa atención a este problema para sistemas NoSQL. En este trabajo se presenta un primer prototipo de una herramienta desarrollada para generar datos NoSQL a partir de esquemas inferidos y representados como modelos conformes al metamodelo NoSQLSchema. Se describe el proceso de generación y la validación realizados, y se comenta el trabajo futuro.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-037.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-037.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alberto Hernández Chillón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alberto.hernandez1@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia, Cátedra SAES-UMU - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Diego Sevilla Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[dsevilla@ditec.um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesus Garcia-Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jmolina@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/034]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evaluación del mantenimiento de la consistencia lógica en Cassandra</title>
		<link>https://biblioteca.sistedes.es/articulo/evaluacion-del-mantenimiento-de-la-consistencia-logica-en-cassandra/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/evaluacion-del-mantenimiento-de-la-consistencia-logica-en-cassandra/</guid>
		<description></description>
		<content><![CDATA[En las bases de datos NoSQL como Cassandra es común que exista duplicidad de los datos entre las tablas, a diferencia de los modelos relacionales normalizados. Esto se debe a que las tablas son diseñadas en base a consultas y a la ausencia de relaciones entre ellas. Por tanto, si los datos no son modificados convenientemente se pueden producir inconsistencias en la información almace-nada. A su vez, es relativamente fácil que se introduzcan defectos que ocasionen inconsistencias en Cassandra, siendo éstos difíciles de detectar utilizando técnicas convencionales de pruebas dinámicas. Con el objetivo de ayudar al desarro-llador a evitar la producción de inconsistencias, proponemos un nuevo método que, usando un modelo conceptual, es capaz de establecer los procesos necesarios para asegurar la calidad de los datos desde el punto de vista de su consistencia a través de pruebas estáticas. En este trabajo evaluamos la eficiencia de este método ante un caso de estudio en el que insertamos tuplas en entidades y relaciones del modelo conceptual y extraemos qué es necesario para mantener la consistencia en el modelo lógico. Los resultados muestran como la desnormalización de los datos puede aumentar la complejidad del mantenimiento de la consistencia, no solo necesitando saber dónde se debe mantener la consistencia sino también cómo hay que mantenerla.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2961</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evaluacion-del-mantenimiento-de-la-consistencia-logica-en-cassandra]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="cassandra"><![CDATA[Cassandra]]></category>
		<category domain="post_tag" nicename="consistencia-logica"><![CDATA[Consistencia Lógica]]></category>
		<category domain="post_tag" nicename="evaluacion"><![CDATA[Evaluación]]></category>
		<category domain="post_tag" nicename="pruebas-estaticas"><![CDATA[Pruebas Estáticas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En las bases de datos NoSQL como Cassandra es común que exista duplicidad de los datos entre las tablas, a diferencia de los modelos relacionales normalizados. Esto se debe a que las tablas son diseñadas en base a consultas y a la ausencia de relaciones entre ellas. Por tanto, si los datos no son modificados convenientemente se pueden producir inconsistencias en la información almace-nada. A su vez, es relativamente fácil que se introduzcan defectos que ocasionen inconsistencias en Cassandra, siendo éstos difíciles de detectar utilizando técnicas convencionales de pruebas dinámicas. Con el objetivo de ayudar al desarro-llador a evitar la producción de inconsistencias, proponemos un nuevo método que, usando un modelo conceptual, es capaz de establecer los procesos necesarios para asegurar la calidad de los datos desde el punto de vista de su consistencia a través de pruebas estáticas. En este trabajo evaluamos la eficiencia de este método ante un caso de estudio en el que insertamos tuplas en entidades y relaciones del modelo conceptual y extraemos qué es necesario para mantener la consistencia en el modelo lógico. Los resultados muestran como la desnormalización de los datos puede aumentar la complejidad del mantenimiento de la consistencia, no solo necesitando saber dónde se debe mantener la consistencia sino también cómo hay que mantenerla.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-038.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-038.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Suárez-Otero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[suarezgpablo@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Maria José Suárez-Cabal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cabal@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/035]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Gestión de Proyectos con PMBOK y LEGO(R) SERIOUD PLAY(R)</title>
		<link>https://biblioteca.sistedes.es/articulo/gestion-de-proyectos-con-pmbok-y-legor-serioud-playr/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/gestion-de-proyectos-con-pmbok-y-legor-serioud-playr/</guid>
		<description></description>
		<content><![CDATA[La comunicación es una de las técnicas más importantes en la gestión de proyectos. La técnica más utilizada en A Guide to the Project Management Body of Knowledge (PMBOK) son los juicios de experto junto contras di-námicas de trabajo en grupo como reuniones. Sin embargo, las reuniones ha-bituales en las que una persona habla y el resto escucha presentan un por-centaje de actividad mental y de implicación muy bajo. Por tanto una mejora en la manera de trabajar en grupo supone una mejora en la gestión de un proyecto. En este trabajo, se explora el uso de la metodología de trabajo en grupo LEGO® SERIOUS PLAY® en la gestión de proyectos. Para ello, este trabajo propone 11 talleres utilizando esta metodología que dan soporte a los procesos basados en comunicación y trabajo en grupo de PMBOK. Las eva-luaciones preliminares de estos talleres por parte de sus asistentes muestran un alto grado de satisfacción y participación en los mismos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2962</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[gestion-de-proyectos-con-pmbok-y-legor-serioud-playr]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="comunicacion"><![CDATA[comunicación]]></category>
		<category domain="post_tag" nicename="gestion-de-proyectos"><![CDATA[gestión de proyectos]]></category>
		<category domain="post_tag" nicename="lego-serious-play"><![CDATA[LEGO SERIOUS PLAY]]></category>
		<category domain="post_tag" nicename="pmbok"><![CDATA[PMBOK]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La comunicación es una de las técnicas más importantes en la gestión de proyectos. La técnica más utilizada en A Guide to the Project Management Body of Knowledge (PMBOK) son los juicios de experto junto contras di-námicas de trabajo en grupo como reuniones. Sin embargo, las reuniones ha-bituales en las que una persona habla y el resto escucha presentan un por-centaje de actividad mental y de implicación muy bajo. Por tanto una mejora en la manera de trabajar en grupo supone una mejora en la gestión de un proyecto. En este trabajo, se explora el uso de la metodología de trabajo en grupo LEGO® SERIOUS PLAY® en la gestión de proyectos. Para ello, este trabajo propone 11 talleres utilizando esta metodología que dan soporte a los procesos basados en comunicación y trabajo en grupo de PMBOK. Las eva-luaciones preliminares de estos talleres por parte de sus asistentes muestran un alto grado de satisfacción y participación en los mismos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-039.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-039.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Gutierrez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[javierj@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[María José Escalona]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mjescalona@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/036]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[ Pablo Suárez-Otero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[suarezgpablo@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[moranjesus@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesús Morán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>vEXgine: Extendiendo el Motor de Ejecución de CVL</title>
		<link>https://biblioteca.sistedes.es/articulo/vexgine-extendiendo-el-motor-de-ejecucion-de-cvl/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/vexgine-extendiendo-el-motor-de-ejecucion-de-cvl/</guid>
		<description></description>
		<content><![CDATA[El Lenguaje CVL (textit{Common Variability Language}) carece de una herramienta flexible que permita poner en práctica las necesidades industriales del modelado de la variabilidad en Líneas de Producto Software. Las herramientas existentes que proporcionan soporte para CVL son prototipos incompletos, o se centran principalmente en la especificación de la variabilidad, sin llegar a resolverla sobre modelos reales. Además, no existe una API que permita la interacción directa con el motor CVL para extenderlo o usarlo en una aplicación independiente. Este artículo presenta vEXgine, una implementación adaptable y extensible del motor de ejecución de la variabilidad de CVL.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2963</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[vexgine-extendiendo-el-motor-de-ejecucion-de-cvl]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="cvl"><![CDATA[CVL]]></category>
		<category domain="post_tag" nicename="linea-de-producto-software"><![CDATA[Línea de Producto Software]]></category>
		<category domain="post_tag" nicename="variabilidad"><![CDATA[Variabilidad]]></category>
		<category domain="post_tag" nicename="vexgine"><![CDATA[vEXgine]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El Lenguaje CVL (textit{Common Variability Language}) carece de una herramienta flexible que permita poner en práctica las necesidades industriales del modelado de la variabilidad en Líneas de Producto Software. Las herramientas existentes que proporcionan soporte para CVL son prototipos incompletos, o se centran principalmente en la especificación de la variabilidad, sin llegar a resolverla sobre modelos reales. Además, no existe una API que permita la interacción directa con el motor CVL para extenderlo o usarlo en una aplicación independiente. Este artículo presenta vEXgine, una implementación adaptable y extensible del motor de ejecución de la variabilidad de CVL.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-040.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-040.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Miguel Horcas Aguilera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[horcas@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Mónica Pinto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pinto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Mlaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/037]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A First Approach towards Storage and Query Processing of Big Spatial Networks in Scalable and Distributed Systems</title>
		<link>https://biblioteca.sistedes.es/articulo/a-first-approach-towards-storage-and-query-processing-of-big-spatial-networks-in-scalable-and-distributed-systems/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-first-approach-towards-storage-and-query-processing-of-big-spatial-networks-in-scalable-and-distributed-systems/</guid>
		<description></description>
		<content><![CDATA[Due to the ubiquitous use of spatial data applications and the large amounts of spatial data that these applications generate, the processing of large-scale queries in distributed systems is becoming increasingly popular. Complex spatial systems are very often organized under the form of Spatial Networks, a type of graph where nodes and edges are embedded in space. Examples of these spatial networks are transportation and mobility networks, mobile phone networks, social and contact networks, etc. When these spatial networks are big enough that exceed the capacity of commonly-used spatial computing technologies, we have Big Spatial Networks, and to manage them is necessary the use of distributed graph-parallel systems. In this paper, we describe our emerging work concerning the design of new storage methods and query processing algorithms over big spatial networks in scalable and distributed systems, which is a very active research area in the past years.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2964</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-first-approach-towards-storage-and-query-processing-of-big-spatial-networks-in-scalable-and-distributed-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="distributed-systems"><![CDATA[Distributed Systems]]></category>
		<category domain="post_tag" nicename="query-processing"><![CDATA[query processing]]></category>
		<category domain="post_tag" nicename="spatial-networks"><![CDATA[Spatial Networks]]></category>
		<category domain="post_tag" nicename="storage-methods"><![CDATA[Storage Methods]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Due to the ubiquitous use of spatial data applications and the large amounts of spatial data that these applications generate, the processing of large-scale queries in distributed systems is becoming increasingly popular. Complex spatial systems are very often organized under the form of Spatial Networks, a type of graph where nodes and edges are embedded in space. Examples of these spatial networks are transportation and mobility networks, mobile phone networks, social and contact networks, etc. When these spatial networks are big enough that exceed the capacity of commonly-used spatial computing technologies, we have Big Spatial Networks, and to manage them is necessary the use of distributed graph-parallel systems. In this paper, we describe our emerging work concerning the design of new storage methods and query processing algorithms over big spatial networks in scalable and distributed systems, which is a very active research area in the past years.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-041.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-041.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Manel Mena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[manel.mena@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Almeria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Corral]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[acorral@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Almeria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Luis Iribarne]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[luis.iribarne@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Almeria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/038]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una experiencia con transformaciones modelo-modelo en un proyecto de modernización</title>
		<link>https://biblioteca.sistedes.es/articulo/una-experiencia-con-transformaciones-modelo-modelo-en-un-proyecto-de-modernizacion/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/una-experiencia-con-transformaciones-modelo-modelo-en-un-proyecto-de-modernizacion/</guid>
		<description></description>
		<content><![CDATA[Las transformaciones modelo-modelo en procesos de reingeniería, en especial en la etapa de ingeniería inversa, suelen ser complejas e implican la escritura de mucho código imperativo. Este hecho junto a la falta de madurez de los lenguajes y entornos para el desarrollo de este tipo de transformaciones fueron los principales factores que influyeron en la decisión de usar Java y el API EMF dentro de un proyecto de migración de aplicaciones Oracle Forms a Java. En este artículo se presentan los resultados iniciales de una comparación entre diferentes soluciones para escribir transformaciones modelo-modelo a partir de las transformaciones implementadas en ese proyecto.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2965</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-experiencia-con-transformaciones-modelo-modelo-en-un-proyecto-de-modernizacion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="atl"><![CDATA[ATL]]></category>
		<category domain="post_tag" nicename="comparacion"><![CDATA[comparación]]></category>
		<category domain="post_tag" nicename="ingenieria-inversa"><![CDATA[Ingeniería Inversa]]></category>
		<category domain="post_tag" nicename="java"><![CDATA[Java]]></category>
		<category domain="post_tag" nicename="lenguajes-de-transformacion-modelo-modelo"><![CDATA[lenguajes de transformación modelo-modelo]]></category>
		<category domain="post_tag" nicename="migracion"><![CDATA[migración]]></category>
		<category domain="post_tag" nicename="qvt"><![CDATA[QVT]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las transformaciones modelo-modelo en procesos de reingeniería, en especial en la etapa de ingeniería inversa, suelen ser complejas e implican la escritura de mucho código imperativo. Este hecho junto a la falta de madurez de los lenguajes y entornos para el desarrollo de este tipo de transformaciones fueron los principales factores que influyeron en la decisión de usar Java y el API EMF dentro de un proyecto de migración de aplicaciones Oracle Forms a Java. En este artículo se presentan los resultados iniciales de una comparación entre diferentes soluciones para escribir transformaciones modelo-modelo a partir de las transformaciones implementadas en ese proyecto.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-042.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-042.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Javier Fernández Candel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cjferna@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jesús García-Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jmolina@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco Javier Bermúdez Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fjavier@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Diego Sevilla Ruiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[dsevilla@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/039]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Confianza e Incertidumbre en Modelos y Transformaciones de Modelos</title>
		<link>https://biblioteca.sistedes.es/articulo/confianza-e-incertidumbre-en-modelos-y-transformaciones-de-modelos/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/confianza-e-incertidumbre-en-modelos-y-transformaciones-de-modelos/</guid>
		<description></description>
		<content><![CDATA[La incertidumbre, tanto en los datos como en los mecanismos que manipulan y operan sobre ellos, es un tema crucial en sistemas que trabajan con entornos físicos. Una incertidumbre que puede ser debida a diversos factores, como fuentes de datos poco fiables, tolerancia en las mediciones o la incapacidad para determinar si un determinado evento ha sucedido realmente o no. En este trabajo proponemos el uso de modelos con confianza, donde los objetos pueden llevar asociadas probabilidades. Al igual que en los modelos, la incertidumbre puede trasladarse a las transformaciones de modelos,  donde las reglas también pueden estar sujetas a incertidumbre.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2966</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[confianza-e-incertidumbre-en-modelos-y-transformaciones-de-modelos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="confianza"><![CDATA[Confianza]]></category>
		<category domain="post_tag" nicename="incertidumbre"><![CDATA[Incertidumbre]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="modelos"><![CDATA[Modelos]]></category>
		<category domain="post_tag" nicename="transformaciones-de-modelos"><![CDATA[Transformaciones de Modelos]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La incertidumbre, tanto en los datos como en los mecanismos que manipulan y operan sobre ellos, es un tema crucial en sistemas que trabajan con entornos físicos. Una incertidumbre que puede ser debida a diversos factores, como fuentes de datos poco fiables, tolerancia en las mediciones o la incapacidad para determinar si un determinado evento ha sucedido realmente o no. En este trabajo proponemos el uso de modelos con confianza, donde los objetos pueden llevar asociadas probabilidades. Al igual que en los modelos, la incertidumbre puede trasladarse a las transformaciones de modelos,  donde las reglas también pueden estar sujetas a incertidumbre.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-043.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-043.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Loli Burgueño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[loli@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Gala Barquero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[gala@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Nathalie Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[moreno@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Manuel F. Bertoa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[bertoa@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Antonio Vallecillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[av@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/040]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Enhancing semantic consistency in anti-fraud rule-based expert systems</title>
		<link>https://biblioteca.sistedes.es/articulo/enhancing-semantic-consistency-in-anti-fraud-rule-based-expert-systems/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/enhancing-semantic-consistency-in-anti-fraud-rule-based-expert-systems/</guid>
		<description></description>
		<content><![CDATA[En este estudio, se propone un servicio guiado por ontología para la detección y clasificación de problemas de incoherencia semántica en sistemas expertos con bases de reglas de decisión. Se centra en el caso crítico de repositorios de reglas antifraude para la inspección de transacciones en entornos de comercio electrónico. La motivación principal consiste en examinar y seleccionar los conjuntos de datos de reglas antifraude para evitar conflictos semánticos que podrían llevar al sistema experto subyacente a funcionar incorrectamente, e. g., al aceptar transacciones fraudulentas y/o descartando las inofensivas. Se ha desarrollado una ontología OWL específica y una serie de reglas semánticas (SWRL) de razonamiento para evaluar dichas bases de reglas antifraude. Las tres principales contribuciones de este trabajo son: primero, la creación de un modelo de conocimiento conceptual para describir las reglas antifraude y sus relaciones; segundo, el desarrollo de reglas semánticas como métodos de detección de conflictos para sistemas expertos contra el fraude; en tercer lugar, se recopilan datos experimentales para evaluar y validar el modelo propuesto. Se utiliza un caso de uso real de la industria de comercio electrónico (e-Turismo) para explicar el diseño de la ontología y su uso. Los experimentos muestran que los enfoques ontológicos pueden descubrir y clasificar efectivamente conflictos en sistemas expertos basados en reglas para detección de fraude. La propuesta también se puede aplicar en otros dominios donde se trabaje con bases de reglas de conocimiento.Este trabajo se presenta como artículo relevante, con referencia: María del Mar Roldán-García, José García-Nieto, José F. Aldana-Montes. Enhancing semantic consistency in anti-fraud rule-based expert systems. Expert Systems with Applications, Volume 90, 2017, Pages 332-343, ISSN 0957-4174, https://doi.org/10.1016/j.eswa.2017.08.036.La revista Expert Systems with Applications está indexada en JCR-ISI en categorías: COMPUTER SCIENCE, ARTIFICIAL INTELLIGENCE - SCIE; ENGINEERING, ELECTRICAL & ELECTRONIC - SCIE; OPERATIONS RESEARCH & MANAGEMENT SCIENCE - SCIE; con ranking Q1 en todas ellas y cuenta con un factor de impacto 2016 de 3.928.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2967</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[enhancing-semantic-consistency-in-anti-fraud-rule-based-expert-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="modelo-semantico"><![CDATA[Modelo Semántico]]></category>
		<category domain="post_tag" nicename="ontologia"><![CDATA[Ontología]]></category>
		<category domain="post_tag" nicename="razonamiento"><![CDATA[Razonamiento]]></category>
		<category domain="post_tag" nicename="reglas-antifraude"><![CDATA[Reglas Antifraude]]></category>
		<category domain="post_tag" nicename="reglas-swrl"><![CDATA[Reglas SWRL]]></category>
		<category domain="post_tag" nicename="sistemas-expertos-de-base-de-reglas"><![CDATA[Sistemas Expertos de Base de Reglas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este estudio, se propone un servicio guiado por ontología para la detección y clasificación de problemas de incoherencia semántica en sistemas expertos con bases de reglas de decisión. Se centra en el caso crítico de repositorios de reglas antifraude para la inspección de transacciones en entornos de comercio electrónico. La motivación principal consiste en examinar y seleccionar los conjuntos de datos de reglas antifraude para evitar conflictos semánticos que podrían llevar al sistema experto subyacente a funcionar incorrectamente, e. g., al aceptar transacciones fraudulentas y/o descartando las inofensivas. Se ha desarrollado una ontología OWL específica y una serie de reglas semánticas (SWRL) de razonamiento para evaluar dichas bases de reglas antifraude. Las tres principales contribuciones de este trabajo son: primero, la creación de un modelo de conocimiento conceptual para describir las reglas antifraude y sus relaciones; segundo, el desarrollo de reglas semánticas como métodos de detección de conflictos para sistemas expertos contra el fraude; en tercer lugar, se recopilan datos experimentales para evaluar y validar el modelo propuesto. Se utiliza un caso de uso real de la industria de comercio electrónico (e-Turismo) para explicar el diseño de la ontología y su uso. Los experimentos muestran que los enfoques ontológicos pueden descubrir y clasificar efectivamente conflictos en sistemas expertos basados en reglas para detección de fraude. La propuesta también se puede aplicar en otros dominios donde se trabaje con bases de reglas de conocimiento.

Este trabajo se presenta como artículo relevante, con referencia:

María del Mar Roldán-García, José García-Nieto, José F. Aldana-Montes. Enhancing semantic consistency in anti-fraud rule-based expert systems. Expert Systems with Applications, Volume 90, 2017, Pages 332-343, ISSN 0957-4174, https://doi.org/10.1016/j.eswa.2017.08.036.

La revista Expert Systems with Applications está indexada en JCR-ISI en categorías: COMPUTER SCIENCE, ARTIFICIAL INTELLIGENCE - SCIE; ENGINEERING, ELECTRICAL & ELECTRONIC - SCIE; OPERATIONS RESEARCH & MANAGEMENT SCIENCE - SCIE; con ranking Q1 en todas ellas y cuenta con un factor de impacto 2016 de 3.928.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-044.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-044.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Maria Del Mar Roldan-Garcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mmar@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Manuel García-Nieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jnieto@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of  Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose F Aldana Montes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jfam@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/041]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una propuesta de editor gráfico para el desarrollo de aplicaciones multiplaforma</title>
		<link>https://biblioteca.sistedes.es/articulo/una-propuesta-de-editor-grafico-para-el-desarrollo-de-aplicaciones-multiplaforma/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/una-propuesta-de-editor-grafico-para-el-desarrollo-de-aplicaciones-multiplaforma/</guid>
		<description></description>
		<content><![CDATA[El Internet de las Cosas (IoT) cubre una gran variedad de dispositivos y tecnologías. Esto permite que se puedan crear aplicaciones muy diversas de IoT, como por ejemplo en el ámbito de las Smart Cities, Smart Agro, Smart Buildings, Smart Home, y Smart Health. Cada uno de estos escenarios requiere que personas y  objetos se interconecten. Para llevar a cabo esta tarea, los desarrolladores deben tener un alto grado de conocimiento de los lenguajes de programación que se emplean en cada plataforma y las tecnologías sobre las cuales se ejecutan. El artículo presenta una solución basada en MDE para facilitar a los desarrolladores la implementación de aplicaciones para el IoT, sin necesidad de conocer en profundidad todas las características de los escenarios, ni los lenguajes de programación de cada una de las plataformas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2968</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-propuesta-de-editor-grafico-para-el-desarrollo-de-aplicaciones-multiplaforma]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="ingenieria-dirigida-por-modelos-mde"><![CDATA[Ingeniería Dirigida por Modelos (MDE)]]></category>
		<category domain="post_tag" nicename="internet-de-las-cosas-iot"><![CDATA[Internet de las cosas (IoT)]]></category>
		<category domain="post_tag" nicename="lenguaje-especifico-de-dominio-dsl"><![CDATA[Lenguaje específico de dominio (DSL)]]></category>
		<category domain="post_tag" nicename="sirius"><![CDATA[Sirius]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El Internet de las Cosas (IoT) cubre una gran variedad de dispositivos y tecnologías. Esto permite que se puedan crear aplicaciones muy diversas de IoT, como por ejemplo en el ámbito de las Smart Cities, Smart Agro, Smart Buildings, Smart Home, y Smart Health. Cada uno de estos escenarios requiere que personas y  objetos se interconecten. Para llevar a cabo esta tarea, los desarrolladores deben tener un alto grado de conocimiento de los lenguajes de programación que se emplean en cada plataforma y las tecnologías sobre las cuales se ejecutan. El artículo presenta una solución basada en MDE para facilitar a los desarrolladores la implementación de aplicaciones para el IoT, sin necesidad de conocer en profundidad todas las características de los escenarios, ni los lenguajes de programación de cada una de las plataformas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-045.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-045.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Darwin Alulema]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[doalulema@espe.edu.ec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de las Fuerzas Armadas ESPE, Sangolquí, Ecuador - Ecuador]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Criado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[javi.criado@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, University of Almería, Spain - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Luis Iribarne]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[luis.iribarne@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Applied Computing Group, University of Almería, Spain - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/042]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Efficient query processing on large spatial databases: A performance study</title>
		<link>https://biblioteca.sistedes.es/articulo/efficient-query-processing-on-large-spatial-databases-a-performance-study/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/efficient-query-processing-on-large-spatial-databases-a-performance-study/</guid>
		<description></description>
		<content><![CDATA[Processing of spatial queries has been studied extensively in the literature. In most cases, it is accomplished by indexing spatial data using spatial access methods. Spatial indexes, such as those based on the Quadtree, are important in spatial databases for efficient execution of queries involving spatial constraints and objects. In this paper, we study a recent balanced disk-based index structure for point data, called xBR+-tree, that belongs to the Quadtree family and hierarchically decomposes space in a regular manner. For the most common spatial queries, like Point Location, Window, Distance Range, Nearest Neighbor and Distance-based Join, the R-tree family is a very popular choice of spatial index, due to its excellent query performance. For this reason, we compare the performance of the xBR+-tree with respect to the R?-tree and the R+-tree for tree building and processing the most studied spatial queries. To perform this comparison, we utilize existing algorithms and present new ones. We demonstrate through extensive experimental performance results (I/O efficiency and execution time), based on medium and large real and synthetic datasets, that the xBR+-tree is a big winner in execution time in all cases and a winner in I/O in most cases.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2969</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[efficient-query-processing-on-large-spatial-databases-a-performance-study]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="performance-evaluation"><![CDATA[Performance evaluation]]></category>
		<category domain="post_tag" nicename="quadtrees"><![CDATA[Quadtrees]]></category>
		<category domain="post_tag" nicename="query-processing"><![CDATA[query processing]]></category>
		<category domain="post_tag" nicename="r-trees"><![CDATA[R-trees]]></category>
		<category domain="post_tag" nicename="spatial-access-methods"><![CDATA[Spatial access methods]]></category>
		<category domain="post_tag" nicename="spatial-databases"><![CDATA[Spatial databases]]></category>
		<category domain="post_tag" nicename="xbr-trees"><![CDATA[xBR-trees]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Processing of spatial queries has been studied extensively in the literature. In most cases, it is accomplished by indexing spatial data using spatial access methods. Spatial indexes, such as those based on the Quadtree, are important in spatial databases for efficient execution of queries involving spatial constraints and objects. In this paper, we study a recent balanced disk-based index structure for point data, called xBR+-tree, that belongs to the Quadtree family and hierarchically decomposes space in a regular manner. For the most common spatial queries, like Point Location, Window, Distance Range, Nearest Neighbor and Distance-based Join, the R-tree family is a very popular choice of spatial index, due to its excellent query performance. For this reason, we compare the performance of the xBR+-tree with respect to the R?-tree and the R+-tree for tree building and processing the most studied spatial queries. To perform this comparison, we utilize existing algorithms and present new ones. We demonstrate through extensive experimental performance results (I/O efficiency and execution time), based on medium and large real and synthetic datasets, that the xBR+-tree is a big winner in execution time in all cases and a winner in I/O in most cases.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-046.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-046.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[George Roumelis]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[groumeli@csd.auth.gr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Aristotle University of Thessaloniki - Greece]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Michael Vassilakopoulos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[mvasilako@uth.gr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Thessaly - Greece]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Corral]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[acorral@ual.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Almeria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Yannis Manolopoulos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[manolopo@csd.auth.gr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Aristotle University of Thessaloniki - Greece]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/043]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>(Trabajo relevante) Handling location uncertainty in probabilistic location-dependent queries</title>
		<link>https://biblioteca.sistedes.es/articulo/trabajo-relevante-handling-location-uncertainty-in-probabilistic-location-dependent-queries/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/trabajo-relevante-handling-location-uncertainty-in-probabilistic-location-dependent-queries/</guid>
		<description></description>
		<content><![CDATA[Este artículo se presenta a JISBD como trabajo relevante y ha sido publicado en la revista Information Sciences en el año 2017.Los datos del artículo son: - Autores: Jorge Bernad, Carlos Bobed, Sergio Ilarri, Eduardo Mena - Título: Handling location uncertainty in probabilistic location-dependent queries - Revista: Information Sciences  - Volumen: 388-389 - Páginas: 154-171 - Año: 2017 - DOI: http://dx.doi.org/10.1016/j.ins.2017.01.029Indicios de calidad: la revista tiene un JCR en el año 2016 de 4.832. Dentro la categoría "Computer Science, Information Systems" está situada dentro 5% de las mejores revistas (7/146), y pertenece al cuartil Q1.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2970</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[trabajo-relevante-handling-location-uncertainty-in-probabilistic-location-dependent-queries]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="location-dependent-queries"><![CDATA[Location-dependent queries]]></category>
		<category domain="post_tag" nicename="probabilistic-range-queries"><![CDATA[Probabilistic range queries]]></category>
		<category domain="post_tag" nicename="uncertainty-management"><![CDATA[Uncertainty management]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo se presenta a JISBD como trabajo relevante y ha sido publicado en la revista Information Sciences en el año 2017.

Los datos del artículo son:
 - Autores: Jorge Bernad, Carlos Bobed, Sergio Ilarri, Eduardo Mena
 - Título: Handling location uncertainty in probabilistic location-dependent queries
 - Revista: Information Sciences
 - Volumen: 388-389
 - Páginas: 154-171
 - Año: 2017
 - DOI: http://dx.doi.org/10.1016/j.ins.2017.01.029

Indicios de calidad: la revista tiene un JCR en el año 2016 de 4.832. Dentro la categoría "Computer Science, Information Systems" está situada dentro 5% de las mejores revistas (7/146), y pertenece al cuartil Q1.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-047.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-047.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jorge Bernad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jbernad@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Carlos Bobed]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cbobed@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Rennes 1 - France]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sergio Ilarri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[silarri@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Eduardo Mena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[emena@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/044]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Dynamic SLOD-BI: Infraestructura Dinamica de Inteligencia de Negocio Social</title>
		<link>https://biblioteca.sistedes.es/articulo/dynamic-slod-bi-infraestructura-dinamica-de-inteligencia-de-negocio-social/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:51 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/dynamic-slod-bi-infraestructura-dinamica-de-inteligencia-de-negocio-social/</guid>
		<description></description>
		<content><![CDATA[Este proyecto plantea nuevas perspectivas de analisis y nuevasextensiones en la funcionalidad de la infraestructura de datos desarrolladaen el proyecto SLOD-BI (Social Linked Open Data for BusinessIntelligence). SLOD-BI plantea una infraestructura de datos enlazados yabiertos (Linked Open Data -LOD-) orientada a capturar y publicar hechosextrados de las redes sociales que son relevantes para los objetivosestrategicos de empresas PYME. La principal limitacion de estas infraestructurases su naturaleza estatica, ya que los datos son generados ypublicados cada cierto tiempo como conjuntos de datos RDF. Sin embargo,los hechos generados en las redes sociales son altamente dinamicos,y muchas veces requieren ser analizados casi en tiempo real (right time).En el proyecto Dynamic SLOD-BI se aborda principalmente la generacion dinamica de hechos para el calculo a demanda de indicadores deredes sociales. El sistema planteado en el proyecto descansa en el modeloconceptual de SLOD-BI, y plantea nuevos desafos de investigacion talescomo la generacion dinamica de conocimiento y el mantenimiento de sucoherencia.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2971</post_id>
		<post_date><![CDATA[2018-07-26 06:17:51]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:51]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[dynamic-slod-bi-infraestructura-dinamica-de-inteligencia-de-negocio-social]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="indicadores-clave-de-desempeno"><![CDATA[Indicadores Clave de Desempeño]]></category>
		<category domain="post_tag" nicename="inteligencia-de-negocio"><![CDATA[Inteligencia de negocio]]></category>
		<category domain="post_tag" nicename="modelos-cognitivos"><![CDATA[Modelos Cognitivos]]></category>
		<category domain="post_tag" nicename="redes-sociales"><![CDATA[Redes sociales]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este proyecto plantea nuevas perspectivas de analisis y nuevas
extensiones en la funcionalidad de la infraestructura de datos desarrollada
en el proyecto SLOD-BI (Social Linked Open Data for Business
Intelligence). SLOD-BI plantea una infraestructura de datos enlazados y
abiertos (Linked Open Data -LOD-) orientada a capturar y publicar hechos
extrados de las redes sociales que son relevantes para los objetivos
estrategicos de empresas PYME. La principal limitacion de estas infraestructuras
es su naturaleza estatica, ya que los datos son generados y
publicados cada cierto tiempo como conjuntos de datos RDF. Sin embargo,
los hechos generados en las redes sociales son altamente dinamicos,
y muchas veces requieren ser analizados casi en tiempo real (right time).
En el proyecto Dynamic SLOD-BI se aborda principalmente la generaci
on dinamica de hechos para el calculo a demanda de indicadores de
redes sociales. El sistema planteado en el proyecto descansa en el modelo
conceptual de SLOD-BI, y plantea nuevos desafos de investigacion tales
como la generacion dinamica de conocimiento y el mantenimiento de su
coherencia.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-048.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-048.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Rafael Berlanga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[berlanga@uji.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Jaume I - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Maria Jose Aramburu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[aramburu@icc.uji.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Jaume I - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Indira Lanza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lanza@uji.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Jaume I - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Dolores Mª Llidó]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[dllido@uji.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Jaume I - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Lledó Museros]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[museros@uji.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universitat Jaume I - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Ismael Sanz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[isanz@uji.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Universitat Jaume I - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/045]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Plataforma Escalable para el Almacenamiento y Procesamiento de Imágenes Multi e Hiperespectrales con Propiedades de Acceso Espacio-Temporal</title>
		<link>https://biblioteca.sistedes.es/articulo/plataforma-escalable-para-el-almacenamiento-y-procesamiento-de-imagenes-multi-e-hiperespectrales-con-propiedades-de-acceso-espacio-temporal/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/plataforma-escalable-para-el-almacenamiento-y-procesamiento-de-imagenes-multi-e-hiperespectrales-con-propiedades-de-acceso-espacio-temporal/</guid>
		<description></description>
		<content><![CDATA[Este artículo describe el desarrollo de una plataforma escalable y eficiente para el almacenamiento y gestión masiva de imágenes multi e hiperespectrales a diferente escala; imágenes de satélite a gran altura e imágenes a media y baja altura procedentes de vuelos con vehículos aéreos no tripulados, con propiedades de acceso espacio-temporal, que sea capaz de ofrecer una mejora en los procesos de gestión y productividad de explotaciones agrarias. Esta información se combina con el uso de tecnologías actuales como bases de datos NoSQL para la gestión del almacenamiento, así como el diseño de los modelos de datos necesarios que sean capaces de soportar la variabilidad de la característica espacio-tiempo de los datos citados, y de aquellas fuentes externas que necesitan ser analizadas y procesadas antes de incorporarse al sistema. Ofreciendo mediante esta integración de datos y tecnología una infraestructura digital que logre facilitar, dentro del ámbito agrícola, los procesos de toma de decisión y la optimización de la gestión de las zonas de cultivo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2972</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[plataforma-escalable-para-el-almacenamiento-y-procesamiento-de-imagenes-multi-e-hiperespectrales-con-propiedades-de-acceso-espacio-temporal]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="agricultura-de-precision"><![CDATA[Agricultura de Precisión]]></category>
		<category domain="post_tag" nicename="datos-espaciales"><![CDATA[Datos Espaciales]]></category>
		<category domain="post_tag" nicename="georreferenciacion"><![CDATA[Georreferenciación]]></category>
		<category domain="post_tag" nicename="imagenes-hiperespectrales"><![CDATA[Imágenes Hiperespectrales]]></category>
		<category domain="post_tag" nicename="imagenes-multiespectrales"><![CDATA[Imágenes Multiespectrales]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo describe el desarrollo de una plataforma escalable y eficiente para el almacenamiento y gestión masiva de imágenes multi e hiperespectrales a diferente escala; imágenes de satélite a gran altura e imágenes a media y baja altura procedentes de vuelos con vehículos aéreos no tripulados, con propiedades de acceso espacio-temporal, que sea capaz de ofrecer una mejora en los procesos de gestión y productividad de explotaciones agrarias. Esta información se combina con el uso de tecnologías actuales como bases de datos NoSQL para la gestión del almacenamiento, así como el diseño de los modelos de datos necesarios que sean capaces de soportar la variabilidad de la característica espacio-tiempo de los datos citados, y de aquellas fuentes externas que necesitan ser analizadas y procesadas antes de incorporarse al sistema. Ofreciendo mediante esta integración de datos y tecnología una infraestructura digital que logre facilitar, dentro del ámbito agrícola, los procesos de toma de decisión y la optimización de la gestión de las zonas de cultivo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-049.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-049.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miguel Sánchez Cabrera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mscabrera@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Barrena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[barrena@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Aurora Cuartero Sáez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[acuartero@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/046]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>RoQME: Dealing with Non-Functional Properties through Global Robot QoS Metrics</title>
		<link>https://biblioteca.sistedes.es/articulo/roqme-dealing-with-non-functional-properties-through-global-robot-qos-metrics/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/roqme-dealing-with-non-functional-properties-through-global-robot-qos-metrics/</guid>
		<description></description>
		<content><![CDATA[Non-functional properties are an essential part of any software solution. There is a lot of literature on what non-functional properties are but, unfortunately, there is also a lot of disagreement and different points of view on how to deal with them. Non-functional properties, such as safety or dependability, become particularly relevant in the context of robotics. In the EU H2020 RobMoSys Project, non-functional properties are treated as first-class citizens and considered key added-value services. In this vein, the RoQME Integrated Technical Project, funded by RobMoSys, aims at contributing a model-driven tool-chain for dealing with system-level non-functional properties, enabling the specification of global robot Quality of Service (QoS) metrics. The estimation of these metrics at runtime, in terms of the contextual information available, can then be used for different purposes, such as robot behavior adaptation or benchmarking.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2973</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[roqme-dealing-with-non-functional-properties-through-global-robot-qos-metrics]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="non-functional-properties"><![CDATA[Non-functional Properties]]></category>
		<category domain="post_tag" nicename="qos-metrics"><![CDATA[QoS metrics]]></category>
		<category domain="post_tag" nicename="service-robotics"><![CDATA[Service Robotics]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Non-functional properties are an essential part of any software solution. There is a lot of literature on what non-functional properties are but, unfortunately, there is also a lot of disagreement and different points of view on how to deal with them. Non-functional properties, such as safety or dependability, become particularly relevant in the context of robotics. In the EU H2020 RobMoSys Project, non-functional properties are treated as first-class citizens and considered key added-value services. In this vein, the RoQME Integrated Technical Project, funded by RobMoSys, aims at contributing a model-driven tool-chain for dealing with system-level non-functional properties, enabling the specification of global robot Quality of Service (QoS) metrics. The estimation of these metrics at runtime, in terms of the contextual information available, can then be used for different purposes, such as robot behavior adaptation or benchmarking.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-050.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-050.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cristina Vicente-Chicote]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cristinav@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José Manuel García-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juanher@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Antonio Bandera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[ajbandera@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Jesús Martínez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[jmcruz@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Adrián Romero-Garcés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[adrigtl@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_8]]></meta_key>
			<meta_value><![CDATA[Roberto Font]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_8]]></meta_key>
			<meta_value><![CDATA[roberto.font@biometricvox.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_8]]></meta_key>
			<meta_value><![CDATA[Biometric Vox S.L. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_9]]></meta_key>
			<meta_value><![CDATA[Juan Francisco Inglés-Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_9]]></meta_key>
			<meta_value><![CDATA[juanfran.ingles@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_9]]></meta_key>
			<meta_value><![CDATA[Biometric Vox, S.L. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/047]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Instituto Internacional de Investigacion e Innovacion del Envejecimiento</title>
		<link>https://biblioteca.sistedes.es/articulo/instituto-internacional-de-investigacion-e-innovacion-del-envejecimiento/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/instituto-internacional-de-investigacion-e-innovacion-del-envejecimiento/</guid>
		<description></description>
		<content><![CDATA[El Instituto Internacional de Investigacion e Innovacion del Envejecimiento es un proyecto transfronterizo y multidisciplinar centrado en la mejora de la calidad de vida de los ancianos mediante el uso de la tecnologia. En este proyecto colaboran la Universidad de Evora, el Instituto Politecnico de Porto Alegre, el Instituto Politecnico de Beja, la Administracion Regional de Salud de Alentejo y la Universidad de Extremadura. Los objetivos del proyecto se centran en comprender los aspectos biomedicos, funcionales y psicologicos del envejecimiento; generar nuevos modelos y procesos de cuidado a ancianos y desarrollar soluciones tecnologicas que contribuyan a la salud y calidad de vida de los ancianos y a la sostenibilidad de los servicios.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2975</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[instituto-internacional-de-investigacion-e-innovacion-del-envejecimiento]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="ambient-assisted-living"><![CDATA[Ambient Assisted Living]]></category>
		<category domain="post_tag" nicename="envejecimiento"><![CDATA[Envejecimiento]]></category>
		<category domain="post_tag" nicename="mobile-computing"><![CDATA[mobile computing]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El Instituto Internacional de Investigacion e Innovacion del Envejecimiento es un proyecto transfronterizo y multidisciplinar centrado en la mejora de la calidad de vida de los ancianos mediante el uso de la tecnologia. En este proyecto colaboran la Universidad de Evora, el Instituto Politecnico de Porto Alegre, el Instituto Politecnico de Beja, la Administracion Regional de Salud de Alentejo y la Universidad de Extremadura. Los objetivos del proyecto se centran en comprender los aspectos biomedicos, funcionales y psicologicos del envejecimiento; generar nuevos modelos y procesos de cuidado a ancianos y desarrollar soluciones tecnologicas que contribuyan a la salud y calidad de vida de los ancianos y a la sostenibilidad de los servicios.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-052.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-052.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jose García-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Borja Rivero Jimenez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[brivero@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[David Conde Caballero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[dcondecab@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Lorenzo Mariano Juárez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[lorenmariano@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Murillo Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[David Mendes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[diverzulu@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Universidade de Évora - Portugal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_8]]></meta_key>
			<meta_value><![CDATA[Cesar Fonseca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_8]]></meta_key>
			<meta_value><![CDATA[cfonseca@uevora.pt]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_8]]></meta_key>
			<meta_value><![CDATA[University of Evora - Portugal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_9]]></meta_key>
			<meta_value><![CDATA[Manuel Lopes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_9]]></meta_key>
			<meta_value><![CDATA[mjl@uevora.pt]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_9]]></meta_key>
			<meta_value><![CDATA[Universidade de Évora - Escola Superior de Enfermagem de S. João de Deus - Portugal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_10]]></meta_key>
			<meta_value><![CDATA[Alejandro Pérez Vereda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_10]]></meta_key>
			<meta_value><![CDATA[apvereda@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_10]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_11]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_11]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_11]]></meta_key>
			<meta_value><![CDATA[University of Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/049]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Benchmarking real-time vehicle data streaming models for a smart city</title>
		<link>https://biblioteca.sistedes.es/articulo/benchmarking-real-time-vehicle-data-streaming-models-for-a-smart-city/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/benchmarking-real-time-vehicle-data-streaming-models-for-a-smart-city/</guid>
		<description></description>
		<content><![CDATA[Artículo ya publicadoInformation Systems, Volume 72, December 2017, Pages 62-76https://doi.org/10.1016/j.is.2017.09.002Q2, (COMPUTER SCIENCE, INFORMATION SYSTEMS)---The information systems of smart cities offer project developers, institutions, industry and experts the possibility to handle massive incoming data from diverse information sources in order to produce new information services for citizens. Much of this information has to be processed as it arrives because a real-time response is often needed. Stream processing architectures solve this kind of problems, but sometimes it is not easy to benchmark the load capacity or the efficiency of a proposed architecture. This work presents a real case project in which an infrastructure was needed for gathering information from drivers in a big city, analyzing that information and sending real-time recommendations to improve driving efficiency and safety on roads. The challenge was to support the real-time recommendation service in a city with thousands of simultaneous drivers at the lowest possible cost. In addition, in order to estimate the ability of an infrastructure to handle load, a simulator that emulates the data produced by a given amount of simultaneous drivers was also developed. Experiments with the simulator show how recent stream processing platforms like Apache Kafka could replace custom-made streaming servers in a smart city to achieve a higher scalability and faster responses, together with cost reduction.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2976</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[benchmarking-real-time-vehicle-data-streaming-models-for-a-smart-city]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="data-streaming"><![CDATA[Data streaming]]></category>
		<category domain="post_tag" nicename="distributed-systems"><![CDATA[Distributed Systems]]></category>
		<category domain="post_tag" nicename="simulator"><![CDATA[Simulator]]></category>
		<category domain="post_tag" nicename="smart-city"><![CDATA[Smart city]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Artículo ya publicado
Information Systems, Volume 72, December 2017, Pages 62-76
https://doi.org/10.1016/j.is.2017.09.002
Q2, (COMPUTER SCIENCE, INFORMATION SYSTEMS)

---
The information systems of smart cities offer project developers, institutions, industry and experts the possibility to handle massive incoming data from diverse information sources in order to produce new information services for citizens. Much of this information has to be processed as it arrives because a real-time response is often needed. Stream processing architectures solve this kind of problems, but sometimes it is not easy to benchmark the load capacity or the efficiency of a proposed architecture. This work presents a real case project in which an infrastructure was needed for gathering information from drivers in a big city, analyzing that information and sending real-time recommendations to improve driving efficiency and safety on roads. The challenge was to support the real-time recommendation service in a city with thousands of simultaneous drivers at the lowest possible cost. In addition, in order to estimate the ability of an infrastructure to handle load, a simulator that emulates the data produced by a given amount of simultaneous drivers was also developed. Experiments with the simulator show how recent stream processing platforms like Apache Kafka could replace custom-made streaming servers in a smart city to achieve a higher scalability and faster responses, together with cost reduction.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-053.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-053.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jorge Y. Fernández-Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jorgeyago@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan A. Álvarez-García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jaalvarez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jesús Arias Fisteus]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jesus.arias@uc3m.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Carlos III de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Miguel R. Luaces]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[luaces@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of A Coruña - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Víctor Corcoba Magaña]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[corcobavictor@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/050]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Designing a Tool for Linking Genetic Variations to Diseases</title>
		<link>https://biblioteca.sistedes.es/articulo/designing-a-tool-for-linking-genetic-variations-to-diseases/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/designing-a-tool-for-linking-genetic-variations-to-diseases/</guid>
		<description></description>
		<content><![CDATA[The technological advance in biomedicine field has led to the creation of large and dispersed heterogeneous data silos. The researchers manually explore the information from these silos to find the relationship between DNA alterations and diseases. This task is tedious and time-consuming due to a large number of dispersed data sources, the volume of information to analyze and the heterogeneity of the content format. In this article, we report the design of a tool based on mashups and interactions to identify the cause-effect relationship between diseases and alterations in the human genome considering the challenges of data integration and the support to different formats of content. The proposed tool is not limited to the genetic domain, rather it can be applied to several domains characterized by dispersed data sources and heterogeneous data formats.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2977</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[designing-a-tool-for-linking-genetic-variations-to-diseases]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="data-exploration"><![CDATA[Data Exploration]]></category>
		<category domain="post_tag" nicename="data-integration"><![CDATA[Data Integration]]></category>
		<category domain="post_tag" nicename="diseases"><![CDATA[Diseases.]]></category>
		<category domain="post_tag" nicename="genetic-variations"><![CDATA[Genetic Variations]]></category>
		<category domain="post_tag" nicename="user-interaction"><![CDATA[User Interaction]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[The technological advance in biomedicine field has led to the creation of large and dispersed heterogeneous data silos. The researchers manually explore the information from these silos to find the relationship between DNA alterations and diseases. This task is tedious and time-consuming due to a large number of dispersed data sources, the volume of information to analyze and the heterogeneity of the content format. In this article, we report the design of a tool based on mashups and interactions to identify the cause-effect relationship between diseases and alterations in the human genome considering the challenges of data integration and the support to different formats of content. The proposed tool is not limited to the genetic domain, rather it can be applied to several domains characterized by dispersed data sources and heterogeneous data formats.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-054.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-054.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Carlos Iñiguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[carlos.iniguez@epn.edu.ec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Escuela Politécnica Nacional - Ecuador]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Oscar Pastor]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[opastor@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/051]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards a model-driven engineering solution for language independent mutation testing</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-a-model-driven-engineering-solution-for-language-independent-mutation-testing/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-a-model-driven-engineering-solution-for-language-independent-mutation-testing/</guid>
		<description></description>
		<content><![CDATA[Mutation testing is a technique to assess test suite adequacy to distinguish between correct and incorrect programs. Mutation testing applies one or more small changes to a program to obtain variants called mutants. The adequacy of a test suite is measured by determining how many of the mutants it distinguishes from the original program. There are many works about mutation testing, but the existing approaches focus on a specific programming language, and usually, it is not easy to customize the set of mutation operators. In this paper, we present Wodel-Test, an extension of the Wodel tool that implements a language-independent mutation testing framework based on model-driven engineering principles.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2978</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-a-model-driven-engineering-solution-for-language-independent-mutation-testing]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="domain-specific-languages"><![CDATA[Domain Specific Languages]]></category>
		<category domain="post_tag" nicename="model-mutation"><![CDATA[model mutation]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<category domain="post_tag" nicename="mutation-testing"><![CDATA[Mutation testing]]></category>
		<category domain="post_tag" nicename="reverse-engineering"><![CDATA[reverse engineering]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Mutation testing is a technique to assess test suite adequacy to distinguish between correct and incorrect programs. Mutation testing applies one or more small changes to a program to obtain variants called mutants. The adequacy of a test suite is measured by determining how many of the mutants it distinguishes from the original program. There are many works about mutation testing, but the existing approaches focus on a specific programming language, and usually, it is not easy to customize the set of mutation operators. In this paper, we present Wodel-Test, an extension of the Wodel tool that implements a language-independent mutation testing framework based on model-driven engineering principles.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-055.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-055.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pablo Gómez-Abajo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pablo.gomeza@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Autónoma de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Esther Guerra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[esther.guerra@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Autónoma de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan de Lara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juan.delara@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Autónoma de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Mercedes G. Merayo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[mgmerayo@fdi.ucm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Complutense de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/052]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generating Test Systems in Simulink Models for Testing Product Lines with ASTERYSCO</title>
		<link>https://biblioteca.sistedes.es/articulo/generating-test-systems-in-simulink-models-for-testing-product-lines-with-asterysco/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/generating-test-systems-in-simulink-models-for-testing-product-lines-with-asterysco/</guid>
		<description></description>
		<content><![CDATA[Simulink models are commonly employed to simulate and test complex systems such as Cyber-Physical Systems (CPSs). These systems are becoming highly configurable, and techniques from the product line engineering context (e.g., feature models) are being acquired by industrial practitioners to model the variability. Having variability in these systems means that there might be several configurations to test. Selecting relevant configurations by considering feature models following combinatorial techniques has been widely investigated by the software engineering community. However, efficiently testing each configuration has attracted little attention, which is not that trivial. One important aspect when testing such systems is automation. This tool paper presents ASTERYSCO, which aims at automatically generating test system instances in Simulink for testing specific configurations of configurable CPSs.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2979</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generating-test-systems-in-simulink-models-for-testing-product-lines-with-asterysco]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="cyber-physical-systems"><![CDATA[Cyber-Physical Systems]]></category>
		<category domain="post_tag" nicename="feature-modeling"><![CDATA[Feature Modeling]]></category>
		<category domain="post_tag" nicename="matlabsimulink"><![CDATA[MATLAB/Simulink]]></category>
		<category domain="post_tag" nicename="product-line-engineering"><![CDATA[Product Line Engineering]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Simulink models are commonly employed to simulate and test complex systems such as Cyber-Physical Systems (CPSs). These systems are becoming highly configurable, and techniques from the product line engineering context (e.g., feature models) are being acquired by industrial practitioners to model the variability. Having variability in these systems means that there might be several configurations to test. Selecting relevant configurations by considering feature models following combinatorial techniques has been widely investigated by the software engineering community. However, efficiently testing each configuration has attracted little attention, which is not that trivial. One important aspect when testing such systems is automation. This tool paper presents ASTERYSCO, which aims at automatically generating test system instances in Simulink for testing specific configurations of configurable CPSs.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-056.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-056.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aitor Arrieta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aarrieta@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Leire Etxeberria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[letxeberria@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Mondragon Uniberstitatea - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Justyna Zander]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[justyna.zander@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[NVIDIA - United States]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/053]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A continuous deployment-based approach for the collaborative creation, maintenance, testing and deployment of CityGML models</title>
		<link>https://biblioteca.sistedes.es/articulo/a-continuous-deployment-based-approach-for-the-collaborative-creation-maintenance-testing-and-deployment-of-citygml-models/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-continuous-deployment-based-approach-for-the-collaborative-creation-maintenance-testing-and-deployment-of-citygml-models/</guid>
		<description></description>
		<content><![CDATA[Publicado en: International Journal of Geographical Information ScienceVolume 32, 2018 - Issue 2, pp. 282-301 (ya publicado online el 26 Oct 2017)https://doi.org/10.1080/13658816.2017.1393543La revista está 46/146 en COMPUTER SCIENCE, INFORMATION SYSTEMS en el JCR (Q2)Abstract:Georeferenced 3D models are an increasingly common choice to store and display urban data in many application areas. CityGML is an open and standardized data model, and exchange format that provides common semantics for 3D city entities and their relations and one of the most common options for this kind of information.Currently, creating and maintaining CityGML models is costly and difficult. This is in part because both the creation of the geometries and the semantic annotation can be complex processes that require at least some manual work. In fact, many publicly available CityGML models have errors. This paper proposes a method to facilitate the regular maintenance of correct city models in CityGML. This method is based on the continuous deployment strategy and tools used in software development, but adapted to the problem of creating,maintaining and deploying CityGML models, even when several people are working on them at the same time. The method requires designing and implementing CityGML deployment pipelines. These pipelines are automatic implementations of the process of building, testing and deploying CityGML models. These pipelines must berun by the maintainers of the models when they make changes that are intended to be shared with others. The pipelines execute increasingly complex automatic tests in order to detect errors as soon as possible, and can even automate the deployment step, where the CityGML models are made available to their end users. In order to demonstrate the feasibility of this method, and as an example of its application, a CityGML deployment pipeline has been developed for an example scenario where three actors maintain the same city model. This scenario is representative of the kind of problems that this method intends to solve, and it is based on real work in progress. The main bene fits of this method are the automation of model testing, every change to the model is tested in a repeatable way; the automation of the model deployment,every change to the model can reach its end users as fast as possible; the systematic approach to integrating changes made by different people working together on the models, including the possibility of keeping parallel versions with a common core; anautomatic record of every change made to the models (who did what and when) and the possibility of undoing some of those changes at any time.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2980</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-continuous-deployment-based-approach-for-the-collaborative-creation-maintenance-testing-and-deployment-of-citygml-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="3d-city-model"><![CDATA[3D City Model]]></category>
		<category domain="post_tag" nicename="automated-testing"><![CDATA[Automated Testing]]></category>
		<category domain="post_tag" nicename="citygml"><![CDATA[CityGML]]></category>
		<category domain="post_tag" nicename="collaborative-edition"><![CDATA[Collaborative Edition]]></category>
		<category domain="post_tag" nicename="continuous-deployment"><![CDATA[Continuous Deployment]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Publicado en: International Journal of Geographical Information Science
Volume 32, 2018 - Issue 2, pp. 282-301 (ya publicado online el 26 Oct 2017)

https://doi.org/10.1080/13658816.2017.1393543

La revista está 46/146 en COMPUTER SCIENCE, INFORMATION SYSTEMS en el JCR (Q2)

Abstract:

Georeferenced 3D models are an increasingly common choice to store and display urban data in many application areas. CityGML is an open and standardized data model, and exchange format that provides common semantics for 3D city entities and their relations and one of the most common options for this kind of information.

Currently, creating and maintaining CityGML models is costly and difficult. This is in part because both the creation of the geometries and the semantic annotation can be complex processes that require at least some manual work. In fact, many publicly available CityGML models have errors.

This paper proposes a method to facilitate the regular maintenance of correct city models in CityGML. This method is based on the continuous deployment strategy and tools used in software development, but adapted to the problem of creating,
maintaining and deploying CityGML models, even when several people are working on them at the same time. The method requires designing and implementing CityGML deployment pipelines. These pipelines are automatic implementations of the process of building, testing and deploying CityGML models. These pipelines must be
run by the maintainers of the models when they make changes that are intended to be shared with others. The pipelines execute increasingly complex automatic tests in order to detect errors as soon as possible, and can even automate the deployment step, where the CityGML models are made available to their end users.

In order to demonstrate the feasibility of this method, and as an example of its application, a CityGML deployment pipeline has been developed for an example scenario where three actors maintain the same city model. This scenario is representative of the kind of problems that this method intends to solve, and it is based on real work in progress.

The main bene fits of this method are the automation of model testing, every change to the model is tested in a repeatable way; the automation of the model deployment,
every change to the model can reach its end users as fast as possible; the systematic approach to integrating changes made by different people working together on the models, including the possibility of keeping parallel versions with a common core; anautomatic record of every change made to the models (who did what and when) and the possibility of undoing some of those changes at any time.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-057.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-057.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Iñaki Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Sustainable Construction Division, Tecnalia Research & Innovation - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose Luis Izkara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Sustainable Construction Division, Tecnalia Research & Innovation - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Rubén Béjar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[rbejar@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/054]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una propuesta para componer APIs orientadas a datos</title>
		<link>https://biblioteca.sistedes.es/articulo/una-propuesta-para-componer-apis-orientadas-a-datos/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/una-propuesta-para-componer-apis-orientadas-a-datos/</guid>
		<description></description>
		<content><![CDATA[En los últimos años un gran número de compañías y entidades públicas han liberado sus datos vía APIs REST. Esto ha provocado un incremento en el número de APIs REST, motivando la creación de mashups para combinar y reutilizar datos provenientes de diferentes fuentes. Sin embargo, la creación de este tipo de aplicaciones es tediosa y propensa a errores ya que hay que invertir un gran esfuerzo en analizar y explicitar el modelo de datos de cada API, definir una estrategia de composición y, finalmente, implementar la aplicación de tipo mashup. En este artículo presentamos una propuesta para la composición de APIs REST orientadas a datos. Dado un conjunto de APIs REST iniciales, nuestra propuesta es capaz de descubrir su modelo de datos, crear un modelo de datos global y publicarlo como una API REST.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2981</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-propuesta-para-componer-apis-orientadas-a-datos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="odata"><![CDATA[OData]]></category>
		<category domain="post_tag" nicename="openapi"><![CDATA[OpenAPI]]></category>
		<category domain="post_tag" nicename="rest-api"><![CDATA[REST API]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años un gran número de compañías y entidades públicas han liberado sus datos vía APIs REST. Esto ha provocado un incremento en el número de APIs REST, motivando la creación de mashups para combinar y reutilizar datos provenientes de diferentes fuentes. Sin embargo, la creación de este tipo de aplicaciones es tediosa y propensa a errores ya que hay que invertir un gran esfuerzo en analizar y explicitar el modelo de datos de cada API, definir una estrategia de composición y, finalmente, implementar la aplicación de tipo mashup. En este artículo presentamos una propuesta para la composición de APIs REST orientadas a datos. Dado un conjunto de APIs REST iniciales, nuestra propuesta es capaz de descubrir su modelo de datos, crear un modelo de datos global y publicarlo como una API REST.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-058.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-058.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Hamza Ed-Douibi]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[hed-douibi@uoc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[IN3 - UOC - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Luis Canovas Izquierdo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jcanovasi@uoc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[IN3 - UOC - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jordi Cabot]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jordi.cabot@icrea.cat]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ICREA - UOC (Internet interdisciplinary institute) - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/055]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Restricción de coetaneidad: cómo detectar y neutralizar inconsistencias temporales</title>
		<link>https://biblioteca.sistedes.es/articulo/restriccion-de-coetaneidad-como-detectar-y-neutralizar-inconsistencias-temporales/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/restriccion-de-coetaneidad-como-detectar-y-neutralizar-inconsistencias-temporales/</guid>
		<description></description>
		<content><![CDATA[La preocupación por la propagación de información falsa crece y el análisis de grandes volúmenes de datos correctos se hace imprescindible en los procesos de toma de decisiones de las organizaciones. Pese a ello, no se han extendido mecanismos automáticos que aseguren la consistencia de los datos relativos al tiempo cronológico, que abundan en los grandes sistemas de información.En este artículo se define y formaliza la restricción de coetaneidad, un mecanismo para la detección y el marcado masivos de datos inconsistentes gracias a la comparación cruzada de valores de tiempo con el consiguiente incremento en la calidad de la información en diferentes contextos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2982</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[restriccion-de-coetaneidad-como-detectar-y-neutralizar-inconsistencias-temporales]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="calidad-de-datos"><![CDATA[Calidad de Datos]]></category>
		<category domain="post_tag" nicename="coetaniedad"><![CDATA[coetaniedad]]></category>
		<category domain="post_tag" nicename="consistencia-de-datos"><![CDATA[consistencia de datos]]></category>
		<category domain="post_tag" nicename="curacion-de-contenidos"><![CDATA[curación de contenidos]]></category>
		<category domain="post_tag" nicename="limpieza-de-datos"><![CDATA[limpieza de datos]]></category>
		<category domain="post_tag" nicename="restricciones-temporales"><![CDATA[restricciones temporales]]></category>
		<category domain="post_tag" nicename="wikidata"><![CDATA[Wikidata]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La preocupación por la propagación de información falsa crece y el análisis de grandes volúmenes de datos correctos se hace imprescindible en los procesos de toma de decisiones de las organizaciones. Pese a ello, no se han extendido mecanismos automáticos que aseguren la consistencia de los datos relativos al tiempo cronológico, que abundan en los grandes sistemas de información.
En este artículo se define y formaliza la restricción de coetaneidad, un mecanismo para la detección y el marcado masivos de datos inconsistentes gracias a la comparación cruzada de valores de tiempo con el consiguiente incremento en la calidad de la información en diferentes contextos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-059.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-059.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Abián]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[da@davidabian.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jorge Bernad]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jbernad@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Raquel Trillo-Lado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[raqueltl@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/056]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un primer enfoque para medir la calidad de FIWARE</title>
		<link>https://biblioteca.sistedes.es/articulo/un-primer-enfoque-para-medir-la-calidad-de-fiware/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/un-primer-enfoque-para-medir-la-calidad-de-fiware/</guid>
		<description></description>
		<content><![CDATA[FIWARE es un ecosistema tecnológico abierto que pretendeconvertirse en la plataforma de referencia para los servicios y aplicaciones del Internet del Futuro. Para ello, primero se necesita solventar lasdudas existentes en cuanto a la calidad de FIWARE, ya que la plata-forma manejará datos sensibles tanto personales como esenciales parala correcta gestión de las ciudades inteligentes. Hay muchas formas deestudiar la calidad de un middleware complejo como este. En nuestrocaso seguimos las pautas de un estándar ISO usando herramientas existentes en una primera fase de identicación de problemas. Tras estudiar26 habilitadores genéricos de referencia de FIWARE, hemos detectadonumerosos puntos de mejora. En el caso de la conconfiabilidad y seguridadse podrán solventar en poco tiempo, mientras que los defectos relativosa mantenibilidad requeriran del orden de meses de trabajo. Esto posiblemente es debido al carácter tan heterogéneo del equipo de desarrolladode FIWARE (miembros de diversas empresas), que afecta directamentea la mantenibilidad del código.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2983</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-primer-enfoque-para-medir-la-calidad-de-fiware]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="calidad"><![CDATA[Calidad]]></category>
		<category domain="post_tag" nicename="ciudades-inteligentes"><![CDATA[Ciudades Inteligentes]]></category>
		<category domain="post_tag" nicename="confiabilidad"><![CDATA[Confiabilidad]]></category>
		<category domain="post_tag" nicename="fiware"><![CDATA[FIWARE]]></category>
		<category domain="post_tag" nicename="mantenibilidad"><![CDATA[mantenibilidad]]></category>
		<category domain="post_tag" nicename="metricas"><![CDATA[métricas]]></category>
		<category domain="post_tag" nicename="seguridad"><![CDATA[seguridad]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[FIWARE es un ecosistema tecnológico abierto que pretende
convertirse en la plataforma de referencia para los servicios y aplicaciones del Internet del Futuro. Para ello, primero se necesita solventar las
dudas existentes en cuanto a la calidad de FIWARE, ya que la plata-
forma manejará datos sensibles tanto personales como esenciales para
la correcta gestión de las ciudades inteligentes. Hay muchas formas de
estudiar la calidad de un middleware complejo como este. En nuestro
caso seguimos las pautas de un estándar ISO usando herramientas existentes en una primera fase de identicación de problemas. Tras estudiar
26 habilitadores genéricos de referencia de FIWARE, hemos detectado
numerosos puntos de mejora. En el caso de la conconfiabilidad y seguridad
se podrán solventar en poco tiempo, mientras que los defectos relativos
a mantenibilidad requeriran del orden de meses de trabajo. Esto posiblemente es debido al carácter tan heterogéneo del equipo de desarrollado
de FIWARE (miembros de diversas empresas), que afecta directamente
a la mantenibilidad del código.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-060.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-060.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ignacio Villalobos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[nacho@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Ferrer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ferrer@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Enrique Alba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[eat@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/057]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>FEETINGS: Un Marco para la Sostenibilidad del Software</title>
		<link>https://biblioteca.sistedes.es/articulo/feetings-un-marco-para-la-sostenibilidad-del-software/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/feetings-un-marco-para-la-sostenibilidad-del-software/</guid>
		<description></description>
		<content><![CDATA[El desarrollo del software no debe de permanecer indiferente a la necesidad de construir productos que sean sostenibles y respetuosos con el medioambiente a lo largo de su ciclo de vida. Sin embargo, uno de los principales problemas actuales, es la falta de herramientas que permitan medir el consumo de energía cuando un software es ejecutado, y detectar, por ejemplo, cuáles son las partes del software que tienen un consumo de energía excesivo. Por esta razón, se ha propuesto FEETINGS (Framework for Energy Efficiency Testing to Improve eNviromental Goals of the Software), un marco que permite medir la eficiencia energética del software y así mejorar la sostenibilidad del mismo. En este trabajo, nos hemos centrado en el núcleo del marco, EET (Energy Efficiency Tester). EET es un dispositivo hardware de medición dedicado a recopilar los datos de consumo específicos del software que se está evaluando. A lo largo del documento se presenta las principales funciones de EET, y un caso de estudio usando el dispositivo de medición EET, donde se pretende observar si existe una correlación entre los requisitos de usabilidad de un software determinado con el consumo de ener-gía que conlleva al ser ejecutado.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2984</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[feetings-un-marco-para-la-sostenibilidad-del-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="dispositivo-de-medicion"><![CDATA[Dispositivo de medición]]></category>
		<category domain="post_tag" nicename="green-software"><![CDATA[Green Software]]></category>
		<category domain="post_tag" nicename="medicion-del-consumo-del-software"><![CDATA[Medición del consumo del software]]></category>
		<category domain="post_tag" nicename="phr"><![CDATA[PHR]]></category>
		<category domain="post_tag" nicename="software-sostenible"><![CDATA[Software sostenible]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El desarrollo del software no debe de permanecer indiferente a la necesidad de construir productos que sean sostenibles y respetuosos con el medioambiente a lo largo de su ciclo de vida. Sin embargo, uno de los principales problemas actuales, es la falta de herramientas que permitan medir el consumo de energía cuando un software es ejecutado, y detectar, por ejemplo, cuáles son las partes del software que tienen un consumo de energía excesivo. Por esta razón, se ha propuesto FEETINGS (Framework for Energy Efficiency Testing to Improve eNviromental Goals of the Software), un marco que permite medir la eficiencia energética del software y así mejorar la sostenibilidad del mismo. En este trabajo, nos hemos centrado en el núcleo del marco, EET (Energy Efficiency Tester). EET es un dispositivo hardware de medición dedicado a recopilar los datos de consumo específicos del software que se está evaluando. A lo largo del documento se presenta las principales funciones de EET, y un caso de estudio usando el dispositivo de medición EET, donde se pretende observar si existe una correlación entre los requisitos de usabilidad de un software determinado con el consumo de ener-gía que conlleva al ser ejecutado.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-061.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-061.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Mancebo Pavón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[javier.mancebo@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Felix Garcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[felix.garcia@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Coral Calero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[coral.calero@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Instituto de Tecnologías y Sistemas de Información, Universidad de Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José Alberto García-Berna]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[JoseAlberto.Garcia1@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática y Sistemas, Universidad de Murcia, Murcia, España - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[José Luis Fenández-Alemán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aleman@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática y Sistemas, Universidad de Murcia, Murcia, España - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Ambrosio Toval]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[AToval@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática y Sistemas, Universidad de Murcia, Murcia, España - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/058]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Análisis de los datos del acelerómetro para detección de actividades</title>
		<link>https://biblioteca.sistedes.es/articulo/analisis-de-los-datos-del-acelerometro-para-deteccion-de-actividades/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:52 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/analisis-de-los-datos-del-acelerometro-para-deteccion-de-actividades/</guid>
		<description></description>
		<content><![CDATA[Las enfermedades cardiovasculares son la principal causa de muerte en España, siendo necesaria la prevención de factores de riesgos como la obesidad o los altos niveles de colesterol. La actividad física previene estos problemas, y su seguimiento usando pulseras de actividad permite tomar decisiones para su corrección. En este trabajo se presenta un experimento para evaluar la viabilidad de detección automática de ciertas actividades a través de algoritmos supervisados de Deep Learning]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2985</post_id>
		<post_date><![CDATA[2018-07-26 06:17:52]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:52]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analisis-de-los-datos-del-acelerometro-para-deteccion-de-actividades]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="classification"><![CDATA[classification]]></category>
		<category domain="post_tag" nicename="deep-learning"><![CDATA[Deep Learning]]></category>
		<category domain="post_tag" nicename="har"><![CDATA[HAR]]></category>
		<category domain="post_tag" nicename="wearable-sensors"><![CDATA[wearable sensors]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Las enfermedades cardiovasculares son la principal causa de muerte en España, siendo necesaria la prevención de factores de riesgos como la obesidad o los altos niveles de colesterol. La actividad física previene estos problemas, y su seguimiento usando pulseras de actividad permite tomar decisiones para su corrección. En este trabajo se presenta un experimento para evaluar la viabilidad de detección automática de ciertas actividades a través de algoritmos supervisados de Deep Learning]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-062.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-062.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Sandro Hurtado-Requena]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[sandrohurtadorequena@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Cristobal Barba-Gonzalez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[cbarba@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Maciej Rybinski]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[maciek.rybinski@lcc.umaes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Francisco J Baron-Lopez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[fjbaron@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Julia Warnberg]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[jwarnberg@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Ismael Navas-Delgado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[ismael@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Jose F Aldana-Montes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[jfam@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/059]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>AIRPORTS: Análisis de Eficiencia Operacional basado en Trayectorias de Vuelo</title>
		<link>https://biblioteca.sistedes.es/articulo/airports-analisis-de-eficiencia-operacional-basado-en-trayectorias-de-vuelo/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/airports-analisis-de-eficiencia-operacional-basado-en-trayectorias-de-vuelo/</guid>
		<description></description>
		<content><![CDATA[AIRPORTS es un proyecto liderado por Boeing Research & Technology Europe (BR&T-E) en el que se coordinan varias líneas de investigación centradas en mejorar la eficiencia del sistema de transporte aéreo futuro. En particular, nuestro trabajo en AIRPORTS aborda la explotación de los datos que describen las trayectorias de vuelo para caracterizar la eficiencia de las operaciones realizadas en el entorno aeroportuario. Este documento introduce las particularidades básicas del contexto en el que estamos desarrollando nuestra investigación y presenta, brevemente, tanto el entorno tecnológico en el que se está realizando el proyecto, como los resultados que se esperan del mismo.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2986</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[airports-analisis-de-eficiencia-operacional-basado-en-trayectorias-de-vuelo]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="ads-b"><![CDATA[ADS-B]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="integracion-de-datos"><![CDATA[Integración de datos]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[AIRPORTS es un proyecto liderado por Boeing Research & Technology Europe (BR&T-E) en el que se coordinan varias líneas de investigación centradas en mejorar la eficiencia del sistema de transporte aéreo futuro. En particular, nuestro trabajo en AIRPORTS aborda la explotación de los datos que describen las trayectorias de vuelo para caracterizar la eficiencia de las operaciones realizadas en el entorno aeroportuario. Este documento introduce las particularidades básicas del contexto en el que estamos desarrollando nuestra investigación y presenta, brevemente, tanto el entorno tecnológico en el que se está realizando el proyecto, como los resultados que se esperan del mismo.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-063.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-063.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Álvaro Alonso-Isla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alvaro.alonso.isla@uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Matemáticas (IMUVA), Universidad de Valladolid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pedro C. Álvarez-Esteban]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pedroc@eio.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Matemáticas (IMUVA), Universidad de Valladolid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Aníbal Bregón]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[anibal@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Valladolid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Luís D'Alto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[luis.p.dalto@boeing.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Boeing Research & Technology Europe - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Fernando Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[fdiaz@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Valladolid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Iván García-Miranda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[ivangmasir@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Matemáticas (IMUVA), Universidad de Valladolid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Paula Gordaliza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[Paula.Gordaliza@math.univ-toulouse.fr]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Instituto de Investigación en Matemáticas (IMUVA), Universidad de Valladolid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_8]]></meta_key>
			<meta_value><![CDATA[Javier López-Leonés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_8]]></meta_key>
			<meta_value><![CDATA[javier.lopezleones@boeing.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_8]]></meta_key>
			<meta_value><![CDATA[Boeing Research & Technology Europe - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_9]]></meta_key>
			<meta_value><![CDATA[Miguel A. Martinez-Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_9]]></meta_key>
			<meta_value><![CDATA[migumar2@infor.uva.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_9]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática, Universidad de Valladolid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_10]]></meta_key>
			<meta_value><![CDATA[David Scarlatti]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_10]]></meta_key>
			<meta_value><![CDATA[david.scarlatti@boeing.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_10]]></meta_key>
			<meta_value><![CDATA[Boeing Research & Technology Europe - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_11]]></meta_key>
			<meta_value><![CDATA[Miguel Vilaplana]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_11]]></meta_key>
			<meta_value><![CDATA[miguel.vilaplana@boeing.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_11]]></meta_key>
			<meta_value><![CDATA[Boeing Research & Technology Europe - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/060]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Aplicabilidad de la Caracterización de Benchmarks a Modelos de Variabilidad</title>
		<link>https://biblioteca.sistedes.es/articulo/aplicabilidad-de-la-caracterizacion-de-benchmarks-a-modelos-de-variabilidad/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/aplicabilidad-de-la-caracterizacion-de-benchmarks-a-modelos-de-variabilidad/</guid>
		<description></description>
		<content><![CDATA[Los Benchmarks utilizados para comparar el rendimiento de diferentes sistemas presentan una alta variabilidad que puede ser representada en modelos de variabilidad como los feature models. En este artículo presentamos las ventajas de la caracterización de Benchmarks (dada por sus cargas de trabajo), junto a los problemas de escalabilidad y complejidad de selección por objetivos de los Feature Models. Para solucionar esos problemas, formalizamos un modelo de caracterización de paquetes de cargas de trabajo para Feature Models, basándonos en ocho atributos abstractos (operaciones matemáticas, memoria, ...). Este modelo y sus ventajas son evaluados en el eco-asistente HADAS, junto a un Benchmark PHP, y al Benchmark de sistemas empotrados BEEBS, obteniendo una capacidad de selección más intuitiva, y un decremento en el tiempo de obtención de configuraciones válidas y sus métricas en HADAS, con respecto a la representación estándar.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2987</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[aplicabilidad-de-la-caracterizacion-de-benchmarks-a-modelos-de-variabilidad]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="atributos"><![CDATA[Atributos]]></category>
		<category domain="post_tag" nicename="benchmarking"><![CDATA[Benchmarking]]></category>
		<category domain="post_tag" nicename="caracterizacion"><![CDATA[Caracterización]]></category>
		<category domain="post_tag" nicename="eficiencia"><![CDATA[Eficiencia]]></category>
		<category domain="post_tag" nicename="escalabilidad"><![CDATA[escalabilidad]]></category>
		<category domain="post_tag" nicename="features"><![CDATA[Features]]></category>
		<category domain="post_tag" nicename="software"><![CDATA[Software]]></category>
		<category domain="post_tag" nicename="variabilidad"><![CDATA[Variabilidad]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los Benchmarks utilizados para comparar el rendimiento de diferentes sistemas presentan una alta variabilidad que puede ser representada en modelos de variabilidad como los feature models. En este artículo presentamos las ventajas de la caracterización de Benchmarks (dada por sus cargas de trabajo), junto a los problemas de escalabilidad y complejidad de selección por objetivos de los Feature Models. Para solucionar esos problemas, formalizamos un modelo de caracterización de paquetes de cargas de trabajo para Feature Models, basándonos en ocho atributos abstractos (operaciones matemáticas, memoria, ...). Este modelo y sus ventajas son evaluados en el eco-asistente HADAS, junto a un Benchmark PHP, y al Benchmark de sistemas empotrados BEEBS, obteniendo una capacidad de selección más intuitiva, y un decremento en el tiempo de obtención de configuraciones válidas y sus métricas en HADAS, con respecto a la representación estándar.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-064.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-064.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Daniel Jesus Munoz Guerra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[danimg@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/061]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una Propuesta para Especificar Cambios de Replicaciones de Experimentos en Ingeniería del Software</title>
		<link>https://biblioteca.sistedes.es/articulo/una-propuesta-para-especificar-cambios-de-replicaciones-de-experimentos-en-ingenieria-del-software/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/una-propuesta-para-especicar-cambios-de-replicaciones-de-experimentos-en-ingenieria-del-software/</guid>
		<description></description>
		<content><![CDATA[Contexto: La replicación de estudios empíricos en Ingeniería del Software es necesaria para consolidar el conocimiento adquirido. No obstante, para incrementar el conocimiento que se genera mediante la replicación, es necesario que la información se publique de forma que permita una comprensión profunda del estudio. Objetivo: Al diseñar una replicación, habitualmente surge la necesidad de introducir cambios. El objetivo de este trabajo es facilitar la especificación de dichos cambios proponiendo una plantilla que permita definirlos sistemáticamente y documentarlos de forma homogénea. Método: Se ha definido el metamodelo para formalizar la información sobre replicaciones y cambios que son relevantes para la plantilla propuesta. Posteriormente, se ha detallado la plantilla y se ha aplicado a una replicación concreta. Resultados y Conclusiones: La aplicación de la plantilla a una replicación concreta ha sido satisfactoria pero se debe aplicar a otras replicaciones o familias de experimentos para su validación y mejora a través de la retroalimentación obtenida.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2988</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-propuesta-para-especificar-cambios-de-replicaciones-de-experimentos-en-ingenieria-del-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="estudio-empirico"><![CDATA[estudio empírico]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software-empirica"><![CDATA[Ingeniería del Software empírica]]></category>
		<category domain="post_tag" nicename="patrones-linguisticos"><![CDATA[patrones lingüísticos]]></category>
		<category domain="post_tag" nicename="plantilla"><![CDATA[plantilla]]></category>
		<category domain="post_tag" nicename="replicacion"><![CDATA[Replicación]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Contexto: La replicación de estudios empíricos en Ingeniería del Software es necesaria para consolidar el conocimiento adquirido. No obstante, para incrementar el conocimiento que se genera mediante la replicación, es necesario que la información se publique de forma que permita una comprensión profunda del estudio. Objetivo: Al diseñar una replicación, habitualmente surge la necesidad de introducir cambios. El objetivo de este trabajo es facilitar la especi?cación de dichos cambios proponiendo una plantilla que permita de?nirlos sistemáticamente y documentarlos de forma homogénea. Método: Se ha de?nido el metamodelo para formalizar la información sobre replicaciones y cambios que son relevantes para la plantilla propuesta. Posteriormente, se ha detallado la plantilla y se ha aplicado a una replicación concreta. Resultados y Conclusiones: La aplicación de la plantilla a una replicación concreta ha sido satisfactoria pero se debe aplicar a otras replicaciones o familias de experimentos para su validación y mejora a través de la retroalimentación obtenida.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-065.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-065.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Margarita Cruz Risco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cruz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Beatriz Bernárdez Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[beat@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Amador Durán Toro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[amador@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/062]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_wp_old_slug]]></meta_key>
			<meta_value><![CDATA[una-propuesta-para-especicar-cambios-de-replicaciones-de-experimentos-en-ingenieria-del-software]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Analizando la Integración Humano-Sistema en Sistemas Autónomos</title>
		<link>https://biblioteca.sistedes.es/articulo/analizando-la-integracion-humano-sistema-en-sistemas-autonomos/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/analizando-la-integracion-humano-sistema-en-sistemas-autonomos/</guid>
		<description></description>
		<content><![CDATA[Los sistemas autónomos (SA) están diseñados para actuar de forma autónoma en gran parte de su trabajo; sin embargo, la autonomía completa es una utopía a medio y corto plazo. Este hecho hace necesario que el humano ayude a completar su funcionalidad (‘human-in-the-loop’). Este tipo de sistemas deben garantizar en todo momento un correcto funcionamiento autónomo, a la vez que de-be ceder, bajo ciertas condiciones, total o parcialmente el control al humano para la realización de algunas tareas. Esto requiere analizar y diseñar los siste-mas para que involucren al humano de forma adecuada ante situaciones donde no es posible alcanzar la autonomía, procurando garantizar una correcta integración humano-sistema. En este trabajo se proporcionan las bases para analizar y diseñar las interacciones humano-sistema. En este artículo se presenta un análisis que permite identificar los aspectos esenciales de la participación del humano en el SA y se propone una técnica para especificar como integrar el humano y el sistema en las primeras fases de desarrollo. Los coches autónomos se toman como ejemplo para ilustrar la propuesta mediante escenarios reales.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2989</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analizando-la-integracion-humano-sistema-en-sistemas-autonomos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="coches-autonomos"><![CDATA[Coches Autónomos]]></category>
		<category domain="post_tag" nicename="human-in-the-loop"><![CDATA[Human in the Loop]]></category>
		<category domain="post_tag" nicename="interaccion-humano-sistema"><![CDATA[Interacción Humano-Sistema]]></category>
		<category domain="post_tag" nicename="sistemas-autonomos"><![CDATA[Sistemas Autónomos]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los sistemas autónomos (SA) están diseñados para actuar de forma autónoma en gran parte de su trabajo; sin embargo, la autonomía completa es una utopía a medio y corto plazo. Este hecho hace necesario que el humano ayude a completar su funcionalidad (‘human-in-the-loop’). Este tipo de sistemas deben garantizar en todo momento un correcto funcionamiento autónomo, a la vez que de-be ceder, bajo ciertas condiciones, total o parcialmente el control al humano para la realización de algunas tareas. Esto requiere analizar y diseñar los siste-mas para que involucren al humano de forma adecuada ante situaciones donde no es posible alcanzar la autonomía, procurando garantizar una correcta integración humano-sistema. En este trabajo se proporcionan las bases para analizar y diseñar las interacciones humano-sistema. En este artículo se presenta un análisis que permite identificar los aspectos esenciales de la participación del humano en el SA y se propone una técnica para especificar como integrar el humano y el sistema en las primeras fases de desarrollo. Los coches autónomos se toman como ejemplo para ilustrar la propuesta mediante escenarios reales.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-066.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-066.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Miriam Gil]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mgil@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manoli Albert]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[malbert@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Joan Fons]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jjfons@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[pele@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de València - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/063]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Técnicas creativas para la captura de requisitos en el desarrollo ágil: una revisión sistemática de la literatura</title>
		<link>https://biblioteca.sistedes.es/articulo/tecnicas-creativas-para-la-captura-de-requisitos-en-el-desarrollo-agil-una-revision-sistematica-de-la-literatura/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/tecnicas-creativas-para-la-captura-de-requisitos-en-el-desarrollo-agil-una-revision-sistematica-de-la-literatura/</guid>
		<description></description>
		<content><![CDATA[Si bien uno de los objetivos de las metodologías ágiles es proporcionar un contexto que facilite la innovación, el afán de las técnicas tradicionales para la captura de requisitos por conseguir una especificación completa y pormenorizada de requisitos que guíe el proceso de desarrollo, parece no encajar a priori con el carácter innovador de las metodologías ágiles. Aplicar el pensamiento creativo a la captura de requisitos, permitiría en principio seguir contemplando la captura de requisitos como una fase más del desarrollo ágil, sin penalizar el carácter innovador de estas metodologías. Para evaluar las iniciativas al respecto que existen hasta la fecha, este trabajo presenta una revisión sistemática que identifica y analiza los trabajos que proponen alguna forma de combinar la utilización de técnicas creativas para la toma de requisitos con el desarrollo ágil. El estudio revela que hasta el momento las metodologías ágiles  basadas en modelado rápido son las más populares como forma de introducir la creatividad en la toma de de requisitos. Asimismo, el estudio muestra que la creatividad en la toma de requisitos debe venir acompañada de un alto nivel de compromiso por parte del usuario y de un contexto que favorezca la flexibilidad, si queremos favorecer la innovación en el desarrollo de software.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2990</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[tecnicas-creativas-para-la-captura-de-requisitos-en-el-desarrollo-agil-una-revision-sistematica-de-la-literatura]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="captura-de-requisitos"><![CDATA[Captura de requisitos]]></category>
		<category domain="post_tag" nicename="desarrollo-de-software"><![CDATA[Desarrollo de software]]></category>
		<category domain="post_tag" nicename="gestion-de-proyectos-de-software"><![CDATA[Gestión de proyectos de software]]></category>
		<category domain="post_tag" nicename="metodologias-agiles"><![CDATA[Metodologías Ágiles]]></category>
		<category domain="post_tag" nicename="pensamiento-creativo"><![CDATA[Pensamiento creativo]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Si bien uno de los objetivos de las metodologías ágiles es proporcionar un contexto que facilite la innovación, el afán de las técnicas tradicionales para la captura de requisitos por conseguir una especificación completa y pormenorizada de requisitos que guíe el proceso de desarrollo, parece no encajar a priori con el carácter innovador de las metodologías ágiles. Aplicar el pensamiento creativo a la captura de requisitos, permitiría en principio seguir contemplando la captura de requisitos como una fase más del desarrollo ágil, sin penalizar el carácter innovador de estas metodologías. Para evaluar las iniciativas al respecto que existen hasta la fecha, este trabajo presenta una revisión sistemática que identifica y analiza los trabajos que proponen alguna forma de combinar la utilización de técnicas creativas para la toma de requisitos con el desarrollo ágil. El estudio revela que hasta el momento las metodologías ágiles  basadas en modelado rápido son las más populares como forma de introducir la creatividad en la toma de de requisitos. Asimismo, el estudio muestra que la creatividad en la toma de requisitos debe venir acompañada de un alto nivel de compromiso por parte del usuario y de un contexto que favorezca la flexibilidad, si queremos favorecer la innovación en el desarrollo de software.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-067.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-067.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Ainhoa Aldave]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[a.aparicioa@alumnos.urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group, University Rey Juan Carlos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Vara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group, University Rey Juan Carlos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[David Granada]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[david.granada@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group, University Rey Juan Carlos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[david.gr4n4d4@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Kybele Research Group, University Rey Juan Carlos - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/064]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Scalable and queryable compressed storage structure for raster data</title>
		<link>https://biblioteca.sistedes.es/articulo/scalable-and-queryable-compressed-storage-structure-for-raster-data/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/scalable-and-queryable-compressed-storage-structure-for-raster-data/</guid>
		<description></description>
		<content><![CDATA[Titulo: Scalable and queryable compressed storage structure for raster data Autores: Susana Ladra, José R. Paramá, Fernando Silva-Coira Revista: Information Systems Volume 72, December 2017, Pages 179-204Factor de impacto: 2.777Ranking JCR: Q2Citas: 1 DOI: https://doi.org/10.1016/j.is.2017.10.007]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2991</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[scalable-and-queryable-compressed-storage-structure-for-raster-data]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="compresion-de-datos"><![CDATA[Compresión de datos]]></category>
		<category domain="post_tag" nicename="raster"><![CDATA[Ráster]]></category>
		<category domain="post_tag" nicename="sistemas-de-informacion-geografica"><![CDATA[Sistemas de Informacíon Geográfica]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Titulo: Scalable and queryable compressed storage structure for raster data
Autores: Susana Ladra, José R. Paramá, Fernando Silva-Coira

Revista: Information Systems Volume 72, December 2017, Pages 179-204

Factor de impacto: 2.777
Ranking JCR: Q2
Citas: 1

DOI: https://doi.org/10.1016/j.is.2017.10.007]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-068.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-068.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Susana Ladra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[susana.ladra@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose R. Parama]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[parama@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Fernando Silva-Coira]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[fernando.silva@udc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidade da Coruña - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/065]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>DataGenCARS: A generator of synthetic data for the evaluation of context-aware recommendation systems</title>
		<link>https://biblioteca.sistedes.es/articulo/trabajo-relevante-datagencars-a-generator-of-synthetic-data-for-the-evaluation-of-context-aware-recommendation-systems/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/trabajo-relevante-datagencars-a-generator-of-synthetic-data-for-the-evaluation-of-context-aware-recommendation-systems/</guid>
		<description></description>
		<content><![CDATA[Este artículo se presenta a JISBD como trabajo relevante y ha sido publicado en la revista Pervasive and Mobile Computing en el año 2017.María del Carmen Rodríguez-Hernández, Sergio Ilarri, Ramón Hermoso, Raquel Trillo-Lado, "DataGenCARS: A Generator of Synthetic Data for the Evaluation of Context-Aware Recommendation Systems", Pervasive and Mobile Computing, ISSN 1574-1192, volume 38, part 2, pp. 516-541, Elsevier, July 2017. Special Issue on Context-aware Mobile Recommender Systems.DOI: 10.1016/j.pmcj.2016.09.020.JCR 2016 (última edición del JCR publicada): factor de impacto: 2,349; 53/146 en Computer Science, Information Systems (Q2, T2); 34/89 en Telecommunications (Q2, T2). Revista en el top 36,3% (considerando la mejor categoría del JCR).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2992</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[trabajo-relevante-datagencars-a-generator-of-synthetic-data-for-the-evaluation-of-context-aware-recommendation-systems]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="context-aware-recommendation-systems"><![CDATA[Context-aware recommendation systems]]></category>
		<category domain="post_tag" nicename="dataset-generation"><![CDATA[Dataset generation]]></category>
		<category domain="post_tag" nicename="evaluation"><![CDATA[Evaluation]]></category>
		<category domain="post_tag" nicename="mobile-recommendations"><![CDATA[Mobile recommendations]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo se presenta a JISBD como trabajo relevante y ha sido publicado en la revista Pervasive and Mobile Computing en el año 2017.

María del Carmen Rodríguez-Hernández, Sergio Ilarri, Ramón Hermoso, Raquel Trillo-Lado, "DataGenCARS: A Generator of Synthetic Data for the Evaluation of Context-Aware Recommendation Systems", Pervasive and Mobile Computing, ISSN 1574-1192, volume 38, part 2, pp. 516-541, Elsevier, July 2017. Special Issue on Context-aware Mobile Recommender Systems.
DOI: 10.1016/j.pmcj.2016.09.020.

JCR 2016 (última edición del JCR publicada): factor de impacto: 2,349; 53/146 en Computer Science, Information Systems (Q2, T2); 34/89 en Telecommunications (Q2, T2).
Revista en el top 36,3% (considerando la mejor categoría del JCR).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-069.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-069.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Del Carmen Rodríguez Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mary0485@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[UNIZAR - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Sergio Ilarri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[silarri@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Ramon Hermoso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[rhermoso@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Raquel Trillo-Lado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[raqueltl@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Zaragoza - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/066]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Quid: A web-based DSL for defining User Interfaces applied to Web Components</title>
		<link>https://biblioteca.sistedes.es/articulo/quid-a-web-based-dsl-for-defining-user-interfaces-applied-to-web-components/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/quid-a-web-based-dsl-for-defining-user-interfaces-applied-to-web-components/</guid>
		<description></description>
		<content><![CDATA[User Interface construction is a recurrent topic in Software Engineering: multiples tools ranging from textual, graphical design tools exists to help in this task.On the other hand, the fast pace of front-end industrial frameworks makes such editors tools obsolete as soon as new technology emerges.The work presented here, introduces Quid, a web based DSL with focus on minimal accidental complexity, removing accessory markup and a WUYIWYG environment to provide real-time feedback to users.Moreover, the UI specification built in this way is catalog neutral: in the way its primitives can be extended, and target platform agnostic: using model transformations and code generation for generating software artifacts like Native Web Components or Angular Elements code.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2993</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[quid-a-web-based-dsl-for-defining-user-interfaces-applied-to-web-components]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="code-generation"><![CDATA[code generation]]></category>
		<category domain="post_tag" nicename="dsl"><![CDATA[DSL]]></category>
		<category domain="post_tag" nicename="mde"><![CDATA[MDE]]></category>
		<category domain="post_tag" nicename="user-interface-design"><![CDATA[User Interface Design]]></category>
		<category domain="post_tag" nicename="web-components"><![CDATA[Web Components]]></category>
		<category domain="post_tag" nicename="web-dsl"><![CDATA[Web DSL]]></category>
		<category domain="post_tag" nicename="wysiwygw"><![CDATA[WYSIWYGW]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[User Interface construction is a recurrent topic in Software Engineering: multiples tools ranging from textual, graphical design tools exists to help in this task.
On the other hand, the fast pace of front-end industrial frameworks makes such editors tools obsolete as soon as new technology emerges.
The work presented here, introduces <<Quid>>, a web based DSL with focus on minimal accidental complexity, removing accessory markup and a WUYIWYG environment to provide real-time feedback to users.
Moreover, the UI specification built in this way is catalog neutral: in the way its primitives can be extended, and target platform agnostic: using model transformations and code generation for generating software artifacts like Native Web Components or Angular Elements code.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-070.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-070.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro J. Molina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pjmolina@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Metadev S.L. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/067]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Mecanismos de Reconfiguración Eco-eficiente de Código en Aplicaciones Móviles Android</title>
		<link>https://biblioteca.sistedes.es/articulo/mecanismos-de-reconfiguracion-eco-eficiente-de-codigo-en-aplicaciones-moviles-android/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/mecanismos-de-reconfiguracion-eco-eficiente-de-codigo-en-aplicaciones-moviles-android/</guid>
		<description></description>
		<content><![CDATA[Los dispositivos móviles ofrecen cada vez mayores prestaciones a costa de un mayor consumo energético. La energía consumida por un móvil no sólo depende de las aplicaciones en sí, sino también de las interacciones del usuario con la aplicación. Si un recurso no está siendo utilizado por la aplicación, no debería estar consumiendo energía. En este artículo se presenta un modelo de adaptación de aplicaciones móviles al contexto del usuario con el objetivo de reducir el consumo energético de las aplicaciones. Se desarrollan y evalúan cuatro implementaciones diferentes de la propuesta en busca del mecanismo de reconfiguración más eficiente energéticamente.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2994</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mecanismos-de-reconfiguracion-eco-eficiente-de-codigo-en-aplicaciones-moviles-android]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="adaptabilidad"><![CDATA[Adaptabilidad]]></category>
		<category domain="post_tag" nicename="android"><![CDATA[Android]]></category>
		<category domain="post_tag" nicename="dispositivos-moviles"><![CDATA[Dispositivos móviles]]></category>
		<category domain="post_tag" nicename="eco-eficiente"><![CDATA[Eco-Eficiente]]></category>
		<category domain="post_tag" nicename="energia"><![CDATA[Energía]]></category>
		<category domain="post_tag" nicename="reconfiguracion-dinamica"><![CDATA[reconfiguración dinámica]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los dispositivos móviles ofrecen cada vez mayores prestaciones a costa de un mayor consumo energético. La energía consumida por un móvil no sólo depende de las aplicaciones en sí, sino también de las interacciones del usuario con la aplicación. Si un recurso no está siendo utilizado por la aplicación, no debería estar consumiendo energía. En este artículo se presenta un modelo de adaptación de aplicaciones móviles al contexto del usuario con el objetivo de reducir el consumo energético de las aplicaciones. Se desarrollan y evalúan cuatro implementaciones diferentes de la propuesta en busca del mecanismo de reconfiguración más eficiente energéticamente.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-071.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-071.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Angel Canete]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[angelcv@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Miguel Horcas Aguilera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[horcas@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Lidia Fuentes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[lff@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Mlaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/068]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>MRG4BPEL: herramienta para generar relaciones metamórficas candidatas en composiciones WS-BPEL</title>
		<link>https://biblioteca.sistedes.es/articulo/mrg4bpel-herramienta-para-generar-relaciones-metamorficas-candidatas-en-composiciones-ws-bpel/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/mrg4bpel-herramienta-para-generar-relaciones-metamorficas-candidatas-en-composiciones-ws-bpel/</guid>
		<description></description>
		<content><![CDATA[En el contexto de la prueba de software, existen diversas técnicas que permiten probar las composiciones de servicios web. Una de ellas, que va adquiriendo importancia y visibilidad en este campo es la Prueba Metamórfica (PM).Dentro los aspectos que esta técnica requiere considerar, está la obtención y generación de Relaciones Metamórficas (RM), parte esencial y la más compleja de automatizar. En este trabajo se abordan las mejoras  tanto en la arquitectura inicialmente propuesta (que representa un framework para probar composiciones de servicios web en el lenguaje WS-BPEL), como en los módulos que la componen. Es decir, se describen los avances en la herramienta de análisis (Analyzer4BPEL) y se presenta una nueva  aplicación para generar RM candidatas, MRG4BPEL. Se muestra un caso de uso, donde, a partir de una composición, se obtienen y aplican RM utilizando estas herramientas, así como las conclusiones obtenidas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2995</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[mrg4bpel-herramienta-para-generar-relaciones-metamorficas-candidatas-en-composiciones-ws-bpel]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="casos-de-prueba-siguientes"><![CDATA[casos de prueba siguientes]]></category>
		<category domain="post_tag" nicename="prueba-metamorfica"><![CDATA[prueba metamórfica]]></category>
		<category domain="post_tag" nicename="relaciones-metamorficas"><![CDATA[relaciones metamórficas]]></category>
		<category domain="post_tag" nicename="ws-bpel"><![CDATA[WS-BPEL]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En el contexto de la prueba de software, existen diversas técnicas que permiten probar las composiciones de servicios web. Una de ellas, que va adquiriendo importancia y visibilidad en este campo es la Prueba Metamórfica (PM).
Dentro los aspectos que esta técnica requiere considerar, está la obtención y generación de Relaciones Metamórficas (RM), parte esencial y la más compleja de automatizar. En este trabajo se abordan las mejoras  tanto en la arquitectura inicialmente propuesta (que representa un framework para probar composiciones de servicios web en el lenguaje WS-BPEL), como en los módulos que la componen. Es decir, se describen los avances en la herramienta de análisis (Analyzer4BPEL) y se presenta una nueva  aplicación para generar RM candidatas, MRG4BPEL. Se muestra un caso de uso, donde, a partir de una composición, se obtienen y aplican RM utilizando estas herramientas, así como las conclusiones obtenidas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-072.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-072.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[M.Carmen De Castro-Cabrera]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[maricarmen.decastro@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Cadiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Kevin J. Valle-Gómez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[kevin.valle@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Department of Computer Languages and Systems, University of Cadiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Pablo Tena-Sánchez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[pablo.tenasanchez@alum.uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Cádiz - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/069]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Evaluación de la Sobrecarga en Pruebas de Transformaciones de Modelos</title>
		<link>https://biblioteca.sistedes.es/articulo/evaluacion-de-la-sobrecarga-en-pruebas-de-transformaciones-de-modelos/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/evaluacion-de-la-sobrecarga-en-pruebas-de-transformaciones-de-modelos/</guid>
		<description></description>
		<content><![CDATA[En el Desarrollo Software Dirigido por Modelos, el desarrollo y mantenimiento de transformaciones entre modelos conlleva grandes costes. La definición de pruebas permite mejorar la calidad y reducir los costes de estos procesos. Sin embargo, hasta ahora no se ha considerado la sobrecarga introducida por las actuales propuestas de pruebas. En este trabajo, se identifican las principales fuentes de sobrecarga en propuestas de pruebas basadas en contratos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2996</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[evaluacion-de-la-sobrecarga-en-pruebas-de-transformaciones-de-modelos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="desarrollo-software-dirigido-por-modelos"><![CDATA[Desarrollo Software Dirigido por Modelos]]></category>
		<category domain="post_tag" nicename="especificacion-basada-en-contratos"><![CDATA[Especificación basada en contratos]]></category>
		<category domain="post_tag" nicename="pruebas-de-transformaciones-de-modelos"><![CDATA[Pruebas de Transformaciones de Modelos]]></category>
		<category domain="post_tag" nicename="sobrecarga"><![CDATA[Sobrecarga]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En el Desarrollo Software Dirigido por Modelos, el desarrollo y mantenimiento de transformaciones entre modelos conlleva grandes costes. La definición de pruebas permite mejorar la calidad y reducir los costes de estos procesos. Sin embargo, hasta ahora no se ha considerado la sobrecarga introducida por las actuales propuestas de pruebas. En este trabajo, se identifican las principales fuentes de sobrecarga en propuestas de pruebas basadas en contratos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-073.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-073.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Roberto Rodriguez-Echeverria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[rre@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Fernando Macías]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[fmac@hvl.no]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Western Norway University of Applied Sciences - Norway]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jose Maria Conejero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[chemacm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Carlos Preciado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jcpreciado@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Alvaro Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aeprieto@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Adrian Rutle]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[aru@hib.no]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Faculty of Engineering and Business Administration - Norway]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/070]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generacio?n de pruebas del sistema en el desarrollo del proyecto ADAGIO mediante la aplicacio?n de NDT</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-de-pruebas-del-sistema-en-el-desarrollo-del-proyecto-adagio-mediante-la-aplicacion-de-ndt/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/generacion-de-pruebas-del-sistema-en-el-desarrollo-del-proyecto-adagio-mediante-la-aplicacion-de-ndt/</guid>
		<description></description>
		<content><![CDATA[La ingenieri?a guiada por modelos (MDE) se ha utilizado en los u?ltimos an?os para promover mejores resultados en el desarrollo de aplicaciones web, en el campo que se ha denominado ingenieri?a web guiada por modelos (MDWE). Una de las ventajas de aplicar MDWE es que ofrece una solucio?n para reducir el coste de las pruebas sin afectar su ejecucio?n ni la calidad de las mismas. Navigational Development Techinques (NDT), es una metodologi?a que proporciona soporte para todas las fases del ciclo de vida del desarrollo de un proyecto de software, proponiendo transformaciones automa?ticas entre dichas fases, sin embargo, en este trabajo, aunque se describe brevemente co?mo se ha hecho uso de NDT para la definicio?n de las fases de requisitos y ana?lisis, se hace hincapie? en el uso de la metodologi?a para la definicio?n de la fase de pruebas de un proyecto real denominado ADAGIO. La aplicacio?n de esta metodologi?a, proporciona un mayor i?ndice de cobertura de pruebas del sistema, y, consecuentemente, un incremento en la calidad del producto.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2997</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-de-pruebas-del-sistema-en-el-desarrollo-del-proyecto-adagio-mediante-la-aplicacion-de-ndt]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="ingenieria-web-guiada-por-modelos"><![CDATA[Ingenieri?a web guiada por modelos]]></category>
		<category domain="post_tag" nicename="metodologia"><![CDATA[Metodología]]></category>
		<category domain="post_tag" nicename="ndt"><![CDATA[NDT]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La ingenieri?a guiada por modelos (MDE) se ha utilizado en los u?ltimos an?os para promover mejores resultados en el desarrollo de aplicaciones web, en el campo que se ha denominado ingenieri?a web guiada por modelos (MDWE). Una de las ventajas de aplicar MDWE es que ofrece una solucio?n para reducir el coste de las pruebas sin afectar su ejecucio?n ni la calidad de las mismas. Navigational Development Techinques (NDT), es una metodologi?a que proporciona soporte para todas las fases del ciclo de vida del desarrollo de un proyecto de software, proponiendo transformaciones automa?ticas entre dichas fases, sin embargo, en este trabajo, aunque se describe brevemente co?mo se ha hecho uso de NDT para la definicio?n de las fases de requisitos y ana?lisis, se hace hincapie? en el uso de la metodologi?a para la definicio?n de la fase de pruebas de un proyecto real denominado ADAGIO. La aplicacio?n de esta metodologi?a, proporciona un mayor i?ndice de cobertura de pruebas del sistema, y, consecuentemente, un incremento en la calidad del producto.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-074.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-074.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[S. Moreno-Leonardo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[sara.moreno@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[J.G. Enríquez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jose.gonzalez@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[L. Morales]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[leticia.morales@iwt2.org]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[F.J. Dominguez-Mayo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[fjdominguez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/071]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>API para el desarrollo de algoritmos interactivos en ingeniería del software basada en búsqueda</title>
		<link>https://biblioteca.sistedes.es/articulo/api-para-el-desarrollo-de-algoritmos-interactivos-en-ingenieria-del-software-basada-en-busqueda/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/api-para-el-desarrollo-de-algoritmos-interactivos-en-ingenieria-del-software-basada-en-busqueda/</guid>
		<description></description>
		<content><![CDATA[La experiencia y la intuición son factores clave a la hora de dar solución a los complejos problemas que plantea la ingeniería del software. Sin embargo, este tipo de criterios no suelen ser considerados cuando su resolución se aborda por medio de técnicas de búsqueda automática. La ingeniería del software basada en búsqueda (SBSE) no puede ni debe obviar la opinión del ingeniero, razón por la que cada vez es más frecuente encontrar propuestas que le invitan a participar en el proceso. Diseñar e implementar un mecanismo de interacción efectivo, a la par que atractivo para el ingeniero, puede resultar complejo. Por ello, este trabajo presenta una API para dar soporte al desarrollo de algoritmos interactivos en SBSE. En base a los enfoques interactivos actuales en SBSE, esta API expone cuáles son los requisitos propios de la interactividad que deben programarse como, por ejemplo, la forma de evaluar las soluciones y las acciones que el ingeniero puede realizar sobre ellas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>2999</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[api-para-el-desarrollo-de-algoritmos-interactivos-en-ingenieria-del-software-basada-en-busqueda]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="application-programming-interface"><![CDATA[Application Programming Interface]]></category>
		<category domain="post_tag" nicename="ingenieria-del-software-basada-en-busqueda"><![CDATA[ingeniería del software basada en búsqueda]]></category>
		<category domain="post_tag" nicename="interactividad"><![CDATA[interactividad]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La experiencia y la intuición son factores clave a la hora de dar solución a los complejos problemas que plantea la ingeniería del software. Sin embargo, este tipo de criterios no suelen ser considerados cuando su resolución se aborda por medio de técnicas de búsqueda automática. La ingeniería del software basada en búsqueda (SBSE) no puede ni debe obviar la opinión del ingeniero, razón por la que cada vez es más frecuente encontrar propuestas que le invitan a participar en el proceso. Diseñar e implementar un mecanismo de interacción efectivo, a la par que atractivo para el ingeniero, puede resultar complejo. Por ello, este trabajo presenta una API para dar soporte al desarrollo de algoritmos interactivos en SBSE. En base a los enfoques interactivos actuales en SBSE, esta API expone cuáles son los requisitos propios de la interactividad que deben programarse como, por ejemplo, la forma de evaluar las soluciones y las acciones que el ingeniero puede realizar sobre ellas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-076.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-076.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Aurora Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aramirez@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Raúl Romero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jrromero@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Sebastián Ventura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sventura@uco.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Córdoba - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/073]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un Repositorio RDF para la Integración y Consulta de Datos de Pacientes Hepáticos</title>
		<link>https://biblioteca.sistedes.es/articulo/un-repositorio-rdf-para-la-integracion-y-consulta-de-datos-de-pacientes-hepaticos/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/un-repositorio-rdf-para-la-integracion-y-consulta-de-datos-de-pacientes-hepaticos/</guid>
		<description></description>
		<content><![CDATA[Los casos médicos pasados, y por lo tanto, la experiencia clínica, son recursos de valor incalculable para apoyar la práctica clínica, la investigación y la formación. Los profesionales médicos deben poder intercambiar información sobre casos médicos de pacientes y explorarlos desde distintas perspectivas subjetivas. Esto requiere de una metodología sistemática y flexible para la representación de los casos médicos que soporte el intercambio de información procesable del paciente. En este artículo presentamos un enfoque basado en ontologías para modelar casos médicos de pacientes que utiliza pacientes con enfermedades hepáticas como ejemplo. Para este fin, se propone una nueva ontología, LiCO, que utiliza estándares médicos bien conocidos para representar casos de pacientes con enfermedades hepáticas. La utilidad del enfoque propuesto se demuestra con consultas semánticas y razonamiento utilizando datos recopilados de pacientes reales. Los resultados preliminares son prometedores con respecto al potencial de la representación de casos médicos basada en ontologías para la construcción de sistemas de búsqueda y recuperación de información de casos médicos, allanando el camino hacia una plataforma de intercambio de experiencias clínicas para comparar diagnósticos, para investigación y para formación.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3000</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-repositorio-rdf-para-la-integracion-y-consulta-de-datos-de-pacientes-hepaticos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="integracion-de-datos"><![CDATA[Integración de datos]]></category>
		<category domain="post_tag" nicename="ontologias"><![CDATA[Ontologías]]></category>
		<category domain="post_tag" nicename="rdf"><![CDATA[RDF]]></category>
		<category domain="post_tag" nicename="representacion-de-casos-medicos"><![CDATA[Representación de casos médicos]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los casos médicos pasados, y por lo tanto, la experiencia clínica, son recursos de valor incalculable para apoyar la práctica clínica, la investigación y la formación. Los profesionales médicos deben poder intercambiar información sobre casos médicos de pacientes y explorarlos desde distintas perspectivas subjetivas. Esto requiere de una metodología sistemática y flexible para la representación de los casos médicos que soporte el intercambio de información procesable del paciente. En este artículo presentamos un enfoque basado en ontologías para modelar casos médicos de pacientes que utiliza pacientes con enfermedades hepáticas como ejemplo. Para este fin, se propone una nueva ontología, LiCO, que utiliza estándares médicos bien conocidos para representar casos de pacientes con enfermedades hepáticas. La utilidad del enfoque propuesto se demuestra con consultas semánticas y razonamiento utilizando datos recopilados de pacientes reales. Los resultados preliminares son prometedores con respecto al potencial de la representación de casos médicos basada en ontologías para la construcción de sistemas de búsqueda y recuperación de información de casos médicos, allanando el camino hacia una plataforma de intercambio de experiencias clínicas para comparar diagnósticos, para investigación y para formación.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-077.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-077.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Maria Del Mar Roldan-Garcia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mmar@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Jose F. Aldana-Montes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jfam@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/074]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>An Infrastructure Modelling Tool for Cloud Provisioning</title>
		<link>https://biblioteca.sistedes.es/articulo/an-infrastructure-modelling-tool-for-cloud-provisioning/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/an-infrastructure-modelling-tool-for-cloud-provisioning/</guid>
		<description></description>
		<content><![CDATA[Autores: Julio Sandobalin, Emilio Insfran, Silvia Abrahao(Universitat Politècnica de València y Escuela Politécnica NacionalQuito, Ecuador)Conferencia: The 14th IEEE International Conference on Services ComputingJun 25, 2017 - Jun 30, 2017 Honolulu, Hawaii, USAPáginas: 8Editorial: IEEEElectronic ISSN: 2474-2473DOI: 10.1109/SCC.2017.52Indicios de calidad de acuerdo al GII-GRIN-SCIE (GGS) Conference Rating: GGS Class 2; GGS Rating A; Qualified Classes CORE:A, LiveSHINE:A; Collected Classes A, A.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3001</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[an-infrastructure-modelling-tool-for-cloud-provisioning]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cloud-services"><![CDATA[Cloud Services]]></category>
		<category domain="post_tag" nicename="devops"><![CDATA[DevOps]]></category>
		<category domain="post_tag" nicename="infrastructure-provisioning"><![CDATA[Infrastructure Provisioning]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Autores: Julio Sandobalin, Emilio Insfran, Silvia Abrahao
(Universitat Politècnica de València y Escuela Politécnica Nacional
Quito, Ecuador)
Conferencia: The 14th IEEE International Conference on Services Computing
Jun 25, 2017 - Jun 30, 2017 Honolulu, Hawaii, USA
Páginas: 8
Editorial: IEEE
Electronic ISSN: 2474-2473
DOI: 10.1109/SCC.2017.52

Indicios de calidad de acuerdo al GII-GRIN-SCIE (GGS) Conference Rating: GGS Class 2; GGS Rating A; Qualified Classes CORE:A, LiveSHINE:A; Collected Classes A, A.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-078.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-078.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julio Sandobalin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[julio.sandobalin@epn.edu.ec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática y Ciencias de la Computación, Escuela Politécnica Nacional, Ecuador]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Emilio Insfran]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[einsfran@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Silvia Abrahao]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sabrahao@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/075]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Coordinación de dispositivos IoT mediante Web Semántica y Ontologías en Situational-Context</title>
		<link>https://biblioteca.sistedes.es/articulo/coordinacion-de-dispositivos-iot-mediante-web-semantica-y-ontologias-en-situational-context/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/coordinacion-de-dispositivos-iot-mediante-web-semantica-y-ontologias-en-situational-context/</guid>
		<description></description>
		<content><![CDATA[El ritmo al que crece Internet de las Cosas (IoT) es imparable. Existen multitud de fabricantes que desarrollan dispositivos IoT, siguiendo sus propias especificaciones y sin atender a un estándar que todavía no existe como tal. Esto nos lleva a una situación donde la gran heterogeneidad de dispositivos que podemos encontrar en el mercado, provoca que esta interconexión sea compleja o incluso no sea posible, impidiendo así que los dispositivos puedan coordinarse para desarrollar tareas colaborativas. Esta interconexión además depende del contexto, pues los dispositivos IoT deben adaptar su comportamiento dependiendo de las características de las personas que les rodean. Con nuestra propuesta, abordamos esta situación proponiendo un sistema que permita identificar una interconexión dinámica de dispositivos IoT que surja de situaciones cambiantes. Gracias a nuestro trabajo conseguimos que esta interconexión sea dependiente del contexto, creando un entorno colaborativo entre personas y dispositivos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3002</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[coordinacion-de-dispositivos-iot-mediante-web-semantica-y-ontologias-en-situational-context]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="contexto"><![CDATA[Contexto]]></category>
		<category domain="post_tag" nicename="interconexion"><![CDATA[Interconexión]]></category>
		<category domain="post_tag" nicename="internet-de-las-cosas"><![CDATA[Internet de las Cosas]]></category>
		<category domain="post_tag" nicename="personas"><![CDATA[Personas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El ritmo al que crece Internet de las Cosas (IoT) es imparable. Existen multitud de fabricantes que desarrollan dispositivos IoT, siguiendo sus propias especificaciones y sin atender a un estándar que todavía no existe como tal. Esto nos lleva a una situación donde la gran heterogeneidad de dispositivos que podemos encontrar en el mercado, provoca que esta interconexión sea compleja o incluso no sea posible, impidiendo así que los dispositivos puedan coordinarse para desarrollar tareas colaborativas. Esta interconexión además depende del contexto, pues los dispositivos IoT deben adaptar su comportamiento dependiendo de las características de las personas que les rodean. Con nuestra propuesta, abordamos esta situación proponiendo un sistema que permita identificar una interconexión dinámica de dispositivos IoT que surja de situaciones cambiantes. Gracias a nuestro trabajo conseguimos que esta interconexión sea dependiente del contexto, creando un entorno colaborativo entre personas y dispositivos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-079.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-079.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Daniel Flores-Martin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[dfloresm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alejandro Pérez Vereda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[apvereda@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Juan Manuel Murillo Rodríguez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/076]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Application of Data Mining techniques to identify relevant Key Performance Indicators</title>
		<link>https://biblioteca.sistedes.es/articulo/application-of-data-mining-techniques-to-identify-relevant-key-performance-indicators/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:53 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/application-of-data-mining-techniques-to-identify-relevant-key-performance-indicators/</guid>
		<description></description>
		<content><![CDATA[Datos:Revista: Computer Standards & Interfaces (CSI)Volumen, páginas y fecha: Vol. 54(2), pp 76-85, Noviembre de 2017DOI: https://doi.org/10.1016/j.csi.2016.11.006Indicios de calidad:- Revista en Ranking: Q2, 40/106 COMPUTER SCIENCE, SOFTWARE ENGINEERING- Factor de Impacto: 1.633- Citas: 2 (Scopus)]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3003</post_id>
		<post_date><![CDATA[2018-07-26 06:17:53]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:53]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[application-of-data-mining-techniques-to-identify-relevant-key-performance-indicators]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="data-mining"><![CDATA[Data Mining]]></category>
		<category domain="post_tag" nicename="kpis"><![CDATA[KPIs]]></category>
		<category domain="post_tag" nicename="open-data"><![CDATA[Open Data]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Datos:

Revista: Computer Standards & Interfaces (CSI)
Volumen, páginas y fecha: Vol. 54(2), pp 76-85, Noviembre de 2017
DOI: https://doi.org/10.1016/j.csi.2016.11.006

Indicios de calidad:
- Revista en Ranking: Q2, 40/106 COMPUTER SCIENCE, SOFTWARE ENGINEERING
- Factor de Impacto: 1.633
- Citas: 2 (Scopus)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-080.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-080.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesus Peral]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jperal@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Alicante - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Alejandro Maté]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[amate@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Alicante - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manolo Marco]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[marco@dlsi.ua.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Alicante - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/077]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>RESDEC: Un prototipo de herramienta para la selección de configuraciones de despliegue basada en Sistemas de Recomendación</title>
		<link>https://biblioteca.sistedes.es/articulo/resdec-un-prototipo-de-herramienta-para-la-seleccion-de-configuraciones-de-despliegue-basada-en-sistemas-de-recomendacion/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/resdec-un-prototipo-de-herramienta-para-la-seleccion-de-configuraciones-de-despliegue-basada-en-sistemas-de-recomendacion/</guid>
		<description></description>
		<content><![CDATA[Los sistemas de alta variabilidad son sistemas que representan cientos de configuraciones distintas. En un contexto particular, estas configuraciones pueden ser desplegadas en distintos entornos de despliegue lo cual es una decisión crítica para el correcto funcionamiento de la misma. Por ejemplo, determinar en qué dispositivo móvil se va a ejecutar correctamente nuestra app, es una tarea difícil de resolver. En este artículo presentamos RESDEC, un prototipo de herramienta para asistir al ingeniero de software en la toma de decisiones para el despliegue. Concretamente RESDEC provee algoritmos de recomendación para tres escenarios de despliegue distintos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3006</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[resdec-un-prototipo-de-herramienta-para-la-seleccion-de-configuraciones-de-despliegue-basada-en-sistemas-de-recomendacion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="configuraciones"><![CDATA[Configuraciones]]></category>
		<category domain="post_tag" nicename="sistemas-de-alta-variabilidad"><![CDATA[Sistemas de alta variabilidad]]></category>
		<category domain="post_tag" nicename="sistemas-de-recomendacion"><![CDATA[Sistemas de recomendación]]></category>
		<category domain="post_tag" nicename="valoraciones"><![CDATA[Valoraciones]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los sistemas de alta variabilidad son sistemas que representan cientos de configuraciones distintas. En un contexto particular, estas configuraciones pueden ser desplegadas en distintos entornos de despliegue lo cual es una decisión crítica para el correcto funcionamiento de la misma. Por ejemplo, determinar en qué dispositivo móvil se va a ejecutar correctamente nuestra app, es una tarea difícil de resolver. En este artículo presentamos RESDEC, un prototipo de herramienta para asistir al ingeniero de software en la toma de decisiones para el despliegue. Concretamente RESDEC provee algoritmos de recomendación para tres escenarios de despliegue distintos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-083.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-083.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jorge Rodas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jorge.rodass@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Milagro - Ecuador]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José A. Galindo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jagalindo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[David Benavides]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[benavides@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/080]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Entorno de Validación Configurable para Software Embebido Refactorizado y su Aplicación en Ascensores</title>
		<link>https://biblioteca.sistedes.es/articulo/entorno-de-validacion-configurable-para-software-embebido-refactorizado-y-su-aplicacion-en-ascensores/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/entorno-de-validacion-configurable-para-software-embebido-refactorizado-y-su-aplicacion-en-ascensores/</guid>
		<description></description>
		<content><![CDATA[Los ascensores son sistemas complejos que integran ademásde software, componentes eléctricos, mecánicos, etc. La complejidad deestos sistemas es aumentada además al tener en cuenta la variabilidad:un ascensor puede ser instalado en edificios de más o menos pisos, puedetener diferente puertas, los actuadores y sensores pueden variar, etc.La validación del software de estos sistemas es compleja en diferentesaspectos. Este artículo presenta un trabajo industrial para la validaciónde software embebido congurable refactorizado en el contexto del sectordel transporte vertical.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3007</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[entorno-de-validacion-configurable-para-software-embebido-refactorizado-y-su-aplicacion-en-ascensores]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="ascensores"><![CDATA[Ascensores]]></category>
		<category domain="post_tag" nicename="test"><![CDATA[Test]]></category>
		<category domain="post_tag" nicename="validacion"><![CDATA[Validación]]></category>
		<category domain="post_tag" nicename="variabilidad"><![CDATA[Variabilidad]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los ascensores son sistemas complejos que integran además
de software, componentes eléctricos, mecánicos, etc. La complejidad de
estos sistemas es aumentada además al tener en cuenta la variabilidad:
un ascensor puede ser instalado en edificios de más o menos pisos, puede
tener diferente puertas, los actuadores y sensores pueden variar, etc.
La validación del software de estos sistemas es compleja en diferentes
aspectos. Este artículo presenta un trabajo industrial para la validación
de software embebido congurable refactorizado en el contexto del sector
del transporte vertical.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-084.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-084.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Goiuria Sagardui]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[gsagardui@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Mondragon - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Leire Etxeberria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[letxeberria@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Mondragon Uniberstitatea - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Joseba Andoni Agirre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jaagirre@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Mondragon - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Aitor Arrieta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aarrieta@mondragon.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Mondragon Goi Eskola Politeknikoa - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Carlos F. Nicolas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[cfnicolas@ikerlan.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Ikerlan - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Jose Maria Martin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[jmmartinc@orona-group.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Orona EIC - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/081]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Patrón de seguridad para la autorización de bases de datos NoSQL (par clave-valor)</title>
		<link>https://biblioteca.sistedes.es/articulo/patron-de-seguridad-para-la-autorizacion-de-bases-de-datos-nosql-par-clave-valor/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/patron-de-seguridad-para-la-autorizacion-de-bases-de-datos-nosql-par-clave-valor/</guid>
		<description></description>
		<content><![CDATA[Aunque las bases de datos de tipo NoSQL surgieron hace unos años, son cada vez más usadas en diversos contextos, debido al crecimiento de los sistemas web y su uso en sistemas analíticos como Big Data. Sin embargo, generalmente este tipo de sistemas de almacenamiento no ha sido concebido con la seguridad en mente, pues se centran en resolver otros problemas como la velocidad de acceso o su uso en entornos distribuidos. Uno de los principales problemas de seguridad que se pueden identificar en estos entornos es la falta de un mecanismo de control de acceso nativo. Aunque existen numerosas propuestas hechas por investigadores que solucionan esta problemática para una tecnología concreta, faltan propuestas con un mayor nivel de abstracción que propongan soluciones más generales. En este sentido, una solución para este tipo de problemas generales es la creación de un patrón de seguridad. En este artículo proponemos un patrón de seguridad específico para realizar el control de acceso de bases de datos NoSQL de tipo clave-valor y se definen los diferentes elementos que lo conforman.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3008</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[patron-de-seguridad-para-la-autorizacion-de-bases-de-datos-nosql-par-clave-valor]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="nosql"><![CDATA[NoSQL]]></category>
		<category domain="post_tag" nicename="patrones-de-seguridad"><![CDATA[Patrones de Seguridad]]></category>
		<category domain="post_tag" nicename="seguridad-de-la-informacion"><![CDATA[Seguridad de la información]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Aunque las bases de datos de tipo NoSQL surgieron hace unos años, son cada vez más usadas en diversos contextos, debido al crecimiento de los sistemas web y su uso en sistemas analíticos como Big Data. Sin embargo, generalmente este tipo de sistemas de almacenamiento no ha sido concebido con la seguridad en mente, pues se centran en resolver otros problemas como la velocidad de acceso o su uso en entornos distribuidos. Uno de los principales problemas de seguridad que se pueden identificar en estos entornos es la falta de un mecanismo de control de acceso nativo. Aunque existen numerosas propuestas hechas por investigadores que solucionan esta problemática para una tecnología concreta, faltan propuestas con un mayor nivel de abstracción que propongan soluciones más generales. En este sentido, una solución para este tipo de problemas generales es la creación de un patrón de seguridad. En este artículo proponemos un patrón de seguridad específico para realizar el control de acceso de bases de datos NoSQL de tipo clave-valor y se definen los diferentes elementos que lo conforman.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-085.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-085.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julio Moreno]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[julio.moreno@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de investigación GSyA. Universidad de Castilla La-Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Eduardo B. Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ed@cse.fau.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Florida Atlantic University - United States]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Serrano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[Manuel.Serrano@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de investigación Alarcos. Universidad de Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Eduardo Fernandez-Medina]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[eduardo.fdezmedina@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de investigación GSyA. Universidad de Castilla La-Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/082]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Descripción de pruebas de benchmark para plataformas de tercera generación</title>
		<link>https://biblioteca.sistedes.es/articulo/descripcion-de-pruebas-de-benchmark-para-plataformas-de-tercera-generacion/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/descripcion-de-pruebas-de-benchmark-para-plataformas-de-tercera-generacion/</guid>
		<description></description>
		<content><![CDATA[La irrupción del big data y la computación en la nube ha impulsado un cambio de paradigma en la construcción de nuevos sistemas basados en plataformas distribuidas escalables y orientadas al dato como servicio. La existencia de diversas tecnologías y la necesidad de evaluar el rendimiento de las aplicaciones construidas con ellas tanto en fase de prototipo como ya una vez implementadas y desplegadas en el entorno operativo, nos ha llevado a proponer un modelo de datos para describir pruebas de benchmark destinadas a la comparación de estas plataformas de tercera generación. El modelo incorpora información sobre todos los aspectos de la prueba: recursos, fuentes de datos, cargas de trabajo y métricas; cubre varios casos de uso y permite adaptar la información que contiene a las diferentes fases del ciclo de desarrollo del sistema. En las fases iniciales de desarrollo de prototipos, el modelo describe estimaciones de la carga de trabajo, de las prestaciones previstas para los recursos y componentes del sistema y de las métricas que se quieren valorar; mientras que en las fases finales de validación, el modelo sólo ha de incluir la identificación de las fuentes que generan las cargas de trabajo, de los recursos utilizados y de los componente desplegados, a fin de evaluar las métricas de interés.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3009</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[descripcion-de-pruebas-de-benchmark-para-plataformas-de-tercera-generacion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="benchmark"><![CDATA[Benchmark]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="distributed-system"><![CDATA[Distributed System]]></category>
		<category domain="post_tag" nicename="performance-metric"><![CDATA[Performance Metric]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La irrupción del big data y la computación en la nube ha impulsado un cambio de paradigma en la construcción de nuevos sistemas basados en plataformas distribuidas escalables y orientadas al dato como servicio. La existencia de diversas tecnologías y la necesidad de evaluar el rendimiento de las aplicaciones construidas con ellas tanto en fase de prototipo como ya una vez implementadas y desplegadas en el entorno operativo, nos ha llevado a proponer un modelo de datos para describir pruebas de benchmark destinadas a la comparación de estas plataformas de tercera generación. El modelo incorpora información sobre todos los aspectos de la prueba: recursos, fuentes de datos, cargas de trabajo y métricas; cubre varios casos de uso y permite adaptar la información que contiene a las diferentes fases del ciclo de desarrollo del sistema. En las fases iniciales de desarrollo de prototipos, el modelo describe estimaciones de la carga de trabajo, de las prestaciones previstas para los recursos y componentes del sistema y de las métricas que se quieren valorar; mientras que en las fases finales de validación, el modelo sólo ha de incluir la identificación de las fuentes que generan las cargas de trabajo, de los recursos utilizados y de los componente desplegados, a fin de evaluar las métricas de interés.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-086.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-086.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Luis Martin de La Rubia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[luis.martind@alumnos.unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[ISTR-Universidad de Cantabria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Miguel Algorri]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[miguel.algorria@alumnos.unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[ISTR-Universidad de Cantabria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Marta Elena Zorrilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[marta.zorrilla@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[ISTR-Universidad de Cantabria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[José María Drake]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[drakej@unican.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[ISTR-Universidad de Cantabria - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/083]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Building Scalable Graphical Modelling Environments with EMFSplitter (tool demo)</title>
		<link>https://biblioteca.sistedes.es/articulo/building-scalable-graphical-modelling-environments-with-emfsplitter-tool-demo/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/building-scalable-graphical-modelling-environments-with-emfsplitter-tool-demo/</guid>
		<description></description>
		<content><![CDATA[In Model-Driven Engineering the creation of Domain-Specific Modelling Languages (DSMLs) is a recurrent demanding task. Usually DSMLs are built in an ad-hoc manner and the generated environments do not scale well to face scenarios with complex systems. To improve this situation, we propose an approach to facilitate the engineering of DSMLs through a catalogue of patterns and a set of wizards to reduce the implementation time of such environments. Our approach is supported by a tool called EMFSplitter, which proposes a Modularity pattern to fragment the models and a Graphical Representation pattern, for the definition of graphical and tabular syntax.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3010</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[building-scalable-graphical-modelling-environments-with-emfsplitter-tool-demo]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="domain-specific-modelling-languages"><![CDATA[Domain-Specific Modelling Languages]]></category>
		<category domain="post_tag" nicename="graphical-modelling-environments"><![CDATA[Graphical Modelling Environments]]></category>
		<category domain="post_tag" nicename="meta-modelling"><![CDATA[Meta-modelling]]></category>
		<category domain="post_tag" nicename="modularity"><![CDATA[Modularity]]></category>
		<category domain="post_tag" nicename="scalable-modelling"><![CDATA[Scalable Modelling]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In Model-Driven Engineering the creation of Domain-Specific Modelling Languages (DSMLs) is a recurrent demanding task. Usually DSMLs are built in an ad-hoc manner and the generated environments do not scale well to face scenarios with complex systems. To improve this situation, we propose an approach to facilitate the engineering of DSMLs through a catalogue of patterns and a set of wizards to reduce the implementation time of such environments. Our approach is supported by a tool called EMFSplitter, which proposes a Modularity pattern to fragment the models and a Graphical Representation pattern, for the definition of graphical and tabular syntax.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-087.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-087.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Garmendia]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[antonio.garmendia@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[UAM - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Esther Guerra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[esther.guerra@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Autónoma de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan De Lara]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juan.delara@uam.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Autonoma de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/084]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Data-Interoperability Aware Software Architecture</title>
		<link>https://biblioteca.sistedes.es/articulo/a-data-interoperability-aware-software-architecture/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-data-interoperability-aware-software-architecture/</guid>
		<description></description>
		<content><![CDATA[Making heterogeneous data sources homogeneous manually and off-line can become a high time-consuming task. This paper presents a software architecture that extends the standardized-based architectures for heterogeneous sensors with components to also support devices and data that are not compliant with standards. The defined architecture is based on Internet of Things (IoT) layered architectures that establish perception, network, middleware, application, and business as main layers. To define the architecture, an architectural framework was used; this framework supports the identification of non-compliant data, providing then a different processing path. This proposed architecture covers a wide spectrum of data interoperability addressing the IoT challenge of ``Interoperability and Standardization''. The implemented solution proved that the processing time between data acquisition and the feeding of analysis algorithms can be reduced from 100% to approximately to 1% with systems based on the proposed architecture compared with those that manage data manually and off-line.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3011</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-data-interoperability-aware-software-architecture]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="interoperability"><![CDATA[interoperability]]></category>
		<category domain="post_tag" nicename="iot"><![CDATA[IoT]]></category>
		<category domain="post_tag" nicename="software-architecture"><![CDATA[Software Architecture]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Making heterogeneous data sources homogeneous manually and off-line can become a high time-consuming task. This paper presents a software architecture that extends the standardized-based architectures for heterogeneous sensors with components to also support devices and data that are not compliant with standards. The defined architecture is based on Internet of Things (IoT) layered architectures that establish perception, network, middleware, application, and business as main layers. To define the architecture, an architectural framework was used; this framework supports the identification of non-compliant data, providing then a different processing path. This proposed architecture covers a wide spectrum of data interoperability addressing the IoT challenge of ``Interoperability and Standardization''. The implemented solution proved that the processing time between data acquisition and the feeding of analysis algorithms can be reduced from 100% to approximately to 1% with systems based on the proposed architecture compared with those that manage data manually and off-line.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-088.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-088.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Hector Humanes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[h.humanes@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Agustin Yague]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[agustin.yague@upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Jennifer Perez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jenifer.perez@etsisi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Garbajosa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jgs@etsisi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Llorenç Burgas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[llorenc.burgas@udg.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universitat de Girona - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Joan Colomer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[joan.colomer@udg.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Universitat de Girona - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Joaquim Melendez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[joaquim.melendez@udg.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Universitat de Girona - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_8]]></meta_key>
			<meta_value><![CDATA[Carles Pous]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_8]]></meta_key>
			<meta_value><![CDATA[carles.pous@udg.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_8]]></meta_key>
			<meta_value><![CDATA[Universitat de Girona - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/085]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automatización de la localización de defectos en el diseño de aplicaciones MapReduce</title>
		<link>https://biblioteca.sistedes.es/articulo/automatizacion-de-la-localizacion-de-defectos-en-el-diseno-de-aplicaciones-mapreduce/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/automatizacion-de-la-localizacion-de-defectos-en-el-diseno-de-aplicaciones-mapreduce/</guid>
		<description></description>
		<content><![CDATA[Los programas MapReduce analizan grandes cantidades de datos sobre una infraestructura distribuida. En cambio, estos programas pueden desarrollarse independientemente de la infraestructura ya que un framework gestiona automáticamente la asignación de recursos y la gestión de fallos. Una vez que se detecta un defecto, suele ser complicado localizar su causa raíz ya que diversas funciones se ejecutan simultáneamente en una infraestructura distribuida que cambia continuamente y que es difícil tanto de controlar como depurar. En este artículo se describe una técnica que, a partir de un caso de prueba que produce fallo, localiza su causa raíz analizando dinámicamente las características del diseño que se cubren cuando se produce fallo y aquellas que no.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3013</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automatizacion-de-la-localizacion-de-defectos-en-el-diseno-de-aplicaciones-mapreduce]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="localizacion-de-defectos"><![CDATA[Localización de defectos]]></category>
		<category domain="post_tag" nicename="mapreduce"><![CDATA[MapReduce]]></category>
		<category domain="post_tag" nicename="pruebas-del-software"><![CDATA[Pruebas del software]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los programas MapReduce analizan grandes cantidades de datos sobre una infraestructura distribuida. En cambio, estos programas pueden desarrollarse independientemente de la infraestructura ya que un framework gestiona automáticamente la asignación de recursos y la gestión de fallos. Una vez que se detecta un defecto, suele ser complicado localizar su causa raíz ya que diversas funciones se ejecutan simultáneamente en una infraestructura distribuida que cambia continuamente y que es difícil tanto de controlar como depurar. En este artículo se describe una técnica que, a partir de un caso de prueba que produce fallo, localiza su causa raíz analizando dinámicamente las características del diseño que se cubren cuando se produce fallo y aquellas que no.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-090.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-090.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Jesús Morán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[moranjesus@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Claudio De La Riva]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[claudio@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Javier Tuya]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[tuya@uniovi.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Oviedo - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/087]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia la automatización de pruebas funcionales y de rendimiento en Android con algoritmos basados en búsqueda</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-la-automatizacion-de-pruebas-funcionales-y-de-rendimiento-en-android-con-algoritmos-basados-en-busqueda/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/hacia-la-automatizacion-de-pruebas-funcionales-y-de-rendimiento-en-android-con-algoritmos-basados-en-busqueda/</guid>
		<description></description>
		<content><![CDATA[Actualmente existen millones de aplicaciones para smartphone que deben ejecutarse correctamente en entornos software, hardware y de conectividad muy variados y cambiantes. El testing de dichas aplicaciones es por tanto un reto importante, para el que ligeras mejoras de la productividad suponen grandes beneficios para usuarios y desarrolladores. Este artículo presenta una primera aproximación de trabajo en curso para la  la automatización de pruebas funcionales y de rendimiento en aplicaciones android usando algoritmos basados en búsqueda. La viabilidad de la propuesta se ha validado aplicándola a dos aplicaciones simples. Generando casos de pruebas que detectan cierres abruptos en la aplicación y maximizan el tiempo de ejecución.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3014</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-la-automatizacion-de-pruebas-funcionales-y-de-rendimiento-en-android-con-algoritmos-basados-en-busqueda]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="android"><![CDATA[Android]]></category>
		<category domain="post_tag" nicename="automation"><![CDATA[automation]]></category>
		<category domain="post_tag" nicename="search-based-algorithms"><![CDATA[search based algorithms]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Actualmente existen millones de aplicaciones para smartphone que deben ejecutarse correctamente en entornos software, hardware y de conectividad muy variados y cambiantes. El testing de dichas aplicaciones es por tanto un reto importante, para el que ligeras mejoras de la productividad suponen grandes beneficios para usuarios y desarrolladores. Este artículo presenta una primera aproximación de trabajo en curso para la  la automatización de pruebas funcionales y de rendimiento en aplicaciones android usando algoritmos basados en búsqueda. La viabilidad de la propuesta se ha validado aplicándola a dos aplicaciones simples. Generando casos de pruebas que detectan cierres abruptos en la aplicación y maximizan el tiempo de ejecución.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-091.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-091.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Antonio Parejo Maestre]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[japarejo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville. - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/088]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Enriquecimiento Automático de Ontologías Biomédicas mediante el uso de Mappings</title>
		<link>https://biblioteca.sistedes.es/articulo/enriquecimiento-automatico-de-ontologias-biomedicas-mediante-el-uso-de-mappings/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/enriquecimiento-automatico-de-ontologias-biomedicas-mediante-el-uso-de-mappings/</guid>
		<description></description>
		<content><![CDATA[Dione es una representación en OWL del ICD-10-CM, consistente lógicamente, cuyos axiomas definen las inclusiones y exclusiones del ICD-10-CM mediante una metodología basada en los mappings ICD-10-CM/SNOMED-CT, proporcionados por UMLS y BioPortal, y que han sido validados por una comunidad de expertos en el ámbito biomédico. En este artículo se presenta una metodología automática que permite la población con axiomas en Dione a partir de los mappings establecidos entre ICD-10-CM y otra ontología biomédica que hayan sido proporcionados por BioPortal. Para mostrar el funcionamiento de esta metodología, se han utilizado los mappings entre Dione y ORDO. Esta última es una ontología que incluye el conjunto de enfermedades raras, genes y otras características para la población de nuevos axiomas en Dione. Una vez que estos axiomas se incluyeron en Dione, se comprobó su consistencia utilizando el razonador ELK y se mostró con un caso de uso que las clases equivalentes entre las ontologías DIONE-ORDO permitían la inferencia de axiomas que definen una clase ICD-10-CM en DIONE a una clase que representa una enfermedad rara en ORDO y, viceversa. Esta nueva metodología se puede aplicar a dos ontologías biomédicas cualquiera cuyos mappings estén previamente definidos en BioPortal.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3016</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[enriquecimiento-automatico-de-ontologias-biomedicas-mediante-el-uso-de-mappings]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="enfermedades-raras"><![CDATA[Enfermedades Raras]]></category>
		<category domain="post_tag" nicename="icd-10-cm"><![CDATA[ICD-10-CM]]></category>
		<category domain="post_tag" nicename="mappings"><![CDATA[Mappings]]></category>
		<category domain="post_tag" nicename="ontologias-biomedicas"><![CDATA[Ontologías Biomédicas]]></category>
		<category domain="post_tag" nicename="razonamiento"><![CDATA[Razonamiento]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Dione es una representación en OWL del ICD-10-CM, consistente lógicamente, cuyos axiomas definen las inclusiones y exclusiones del ICD-10-CM mediante una metodología basada en los mappings ICD-10-CM/SNOMED-CT, proporcionados por UMLS y BioPortal, y que han sido validados por una comunidad de expertos en el ámbito biomédico. En este artículo se presenta una metodología automática que permite la población con axiomas en Dione a partir de los mappings establecidos entre ICD-10-CM y otra ontología biomédica que hayan sido proporcionados por BioPortal. Para mostrar el funcionamiento de esta metodología, se han utilizado los mappings entre Dione y ORDO. Esta última es una ontología que incluye el conjunto de enfermedades raras, genes y otras características para la población de nuevos axiomas en Dione. Una vez que estos axiomas se incluyeron en Dione, se comprobó su consistencia utilizando el razonador ELK y se mostró con un caso de uso que las clases equivalentes entre las ontologías DIONE-ORDO permitían la inferencia de axiomas que definen una clase ICD-10-CM en DIONE a una clase que representa una enfermedad rara en ORDO y, viceversa. Esta nueva metodología se puede aplicar a dos ontologías biomédicas cualquiera cuyos mappings estén previamente definidos en BioPortal.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-093.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-093.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[María Jesús García Godoy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[mjgarciag@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Esteban López-Camacho]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[esteban@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[María Del Mar Roldán-García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mmar@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jose F Aldana Montes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jfam@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/090]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>CMSA para el problema de la generación de casos de prueba priorizados en líneas de productos software</title>
		<link>https://biblioteca.sistedes.es/articulo/cmsa-para-el-problema-de-la-generacion-de-casos-de-prueba-priorizados-en-lineas-de-productos-software/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/cmsa-para-el-problema-de-la-generacion-de-casos-de-prueba-priorizados-en-lineas-de-productos-software/</guid>
		<description></description>
		<content><![CDATA[En las líneas de producto software puede ser difícil o incluso imposible probar todos los productos de la familia debido al gran número de combinaciones de características que pueden existir. Esto conlleva la necesidad de buscar un subconjunto de productos de la familia que nos permita probar todas las posibles combinaciones. Los algoritmos del estado del arte basados en heurísticos junto con programación lineal entera (ILP) son lo bastante rápidos para instancias de tamaño pequeño o mediano. Sin embargo, existen algunas instancias del mundo real que son demasiado grandes para obtener una respuesta en un tiempo razonable, debido al crecimiento exponencial del espacio de búsqueda. Por otro lado, estos heurísticos no siempre conducen a las mejores soluciones. En este trabajo proponemos un nuevo enfoque basado en un algoritmo metaheurístico híbrido llamado Construct, Merge, Solve & Adapt (CMSA). Comparamos este enfoque con un algoritmo del estado del arte basado en ILP y en algoritmos híbridos. El análisis muestra que el algoritmo propuesto conduce a soluciones de mayor calidad.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3017</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[cmsa-para-el-problema-de-la-generacion-de-casos-de-prueba-priorizados-en-lineas-de-productos-software]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="aleatorizacion"><![CDATA[Aleatorización]]></category>
		<category domain="post_tag" nicename="hibridos-exactos-heuristicos"><![CDATA[Híbridos exactos/heurísticos]]></category>
		<category domain="post_tag" nicename="lineas-de-productos-software"><![CDATA[Líneas de Productos Software]]></category>
		<category domain="post_tag" nicename="modelos-de-caracteristicas"><![CDATA[modelos de características]]></category>
		<category domain="post_tag" nicename="optimizacion-combinatoria"><![CDATA[Optimización Combinatoria]]></category>
		<category domain="post_tag" nicename="testeo-por-pares"><![CDATA[Testeo por pares]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En las líneas de producto software puede ser difícil o incluso imposible probar todos los productos de la familia debido al gran número de combinaciones de características que pueden existir. Esto conlleva la necesidad de buscar un subconjunto de productos de la familia que nos permita probar todas las posibles combinaciones. Los algoritmos del estado del arte basados en heurísticos junto con programación lineal entera (ILP) son lo bastante rápidos para instancias de tamaño pequeño o mediano. Sin embargo, existen algunas instancias del mundo real que son demasiado grandes para obtener una respuesta en un tiempo razonable, debido al crecimiento exponencial del espacio de búsqueda. Por otro lado, estos heurísticos no siempre conducen a las mejores soluciones. En este trabajo proponemos un nuevo enfoque basado en un algoritmo metaheurístico híbrido llamado Construct, Merge, Solve & Adapt (CMSA). Comparamos este enfoque con un algoritmo del estado del arte basado en ILP y en algoritmos híbridos. El análisis muestra que el algoritmo propuesto conduce a soluciones de mayor calidad.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-094.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-094.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José Antonio Ortega-Toro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[joseaortegatoro@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[CERN - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Javier Ferrer]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ferrer@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Malaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Francisco Chicano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[chicano@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Málaga - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/091]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>GREEN-BANNER: Una propuesta para mejorar la responsabilidad energética de los usuarios en las organizaciones</title>
		<link>https://biblioteca.sistedes.es/articulo/green-banner-una-propuesta-para-mejorar-la-responsabilidad-energetica-de-los-usuarios-en-las-organizaciones/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/green-banner-una-propuesta-para-mejorar-la-responsabilidad-energetica-de-los-usuarios-en-las-organizaciones/</guid>
		<description></description>
		<content><![CDATA[La sostenibilidad en su sentido más amplio y desde el punto de vista de la ecología comprende todo aquello que se puede mantener durante largo tiempo sin agotarlo o causar un daño grave al medio ambiente. Desde su descubrimiento en la revolución industrial hasta la actualidad no se ha prestado una atención especial a las consecuencias que supone para el medio ambiente la producción y uso de la energía eléctrica. Es en la actualidad, con la indiscutible supremacía de demanda de este recurso, cuando se destaca que el gasto de cantidades ingentes de energía supone un daño para el planeta. Con el firme propósito de que los usuarios de los ordenadores de las Aulas de Libre Acceso (ALAs) de la Universidad de Murcia (UMU) sean conscientes de la importancia que tiene para el medio ambiente el buen uso de este recurso, pretendemos realizar un experimento de concienciación para estudiar si mediante mensajes mostrados en la pantalla o con pegatinas adheridas a la carcasa del ordenador es posible modificar los hábitos de uso de estos dispositivos. Trataremos de conseguir que los usuarios suspendan los equipos cuando terminen de utilizarlos en lugar de solamente cerrar la sesión, evitando que se queden encendidos desperdiciando energía. En este trabajo proponemos el diseño y la infraestructura para llevar a cabo el experimento propuesto y detallaremos el estudio estadístico a seguir con los datos que recabemos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3019</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[green-banner-una-propuesta-para-mejorar-la-responsabilidad-energetica-de-los-usuarios-en-las-organizaciones]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="aulas-informaticas"><![CDATA[Aulas Informáticas]]></category>
		<category domain="post_tag" nicename="concienciacion-energetica"><![CDATA[Concienciación Energética]]></category>
		<category domain="post_tag" nicename="experimento"><![CDATA[Experimento]]></category>
		<category domain="post_tag" nicename="sostenibilidad"><![CDATA[Sostenibilidad]]></category>
		<category domain="post_tag" nicename="universidad"><![CDATA[Universidad]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La sostenibilidad en su sentido más amplio y desde el punto de vista de la ecología comprende todo aquello que se puede mantener durante largo tiempo sin agotarlo o causar un daño grave al medio ambiente. Desde su descubrimiento en la revolución industrial hasta la actualidad no se ha prestado una atención especial a las consecuencias que supone para el medio ambiente la producción y uso de la energía eléctrica. Es en la actualidad, con la indiscutible supremacía de demanda de este recurso, cuando se destaca que el gasto de cantidades ingentes de energía supone un daño para el planeta. Con el firme propósito de que los usuarios de los ordenadores de las Aulas de Libre Acceso (ALAs) de la Universidad de Murcia (UMU) sean conscientes de la importancia que tiene para el medio ambiente el buen uso de este recurso, pretendemos realizar un experimento de concienciación para estudiar si mediante mensajes mostrados en la pantalla o con pegatinas adheridas a la carcasa del ordenador es posible modificar los hábitos de uso de estos dispositivos. Trataremos de conseguir que los usuarios suspendan los equipos cuando terminen de utilizarlos en lugar de solamente cerrar la sesión, evitando que se queden encendidos desperdiciando energía. En este trabajo proponemos el diseño y la infraestructura para llevar a cabo el experimento propuesto y detallaremos el estudio estadístico a seguir con los datos que recabemos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-096.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-096.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José A. García-Berná]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[josealberto.garcia1@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan M. Carrillo de Gea]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jmcdg1@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[José L. Fernández Alemán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aleman@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Joaquín Nicolás]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jnr@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Begoña Moros]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[bmoros@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Ambrosio Toval]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[atoval@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[José María Abellán Perpiñán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[dionisos@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_8]]></meta_key>
			<meta_value><![CDATA[Francisco Maeso Fernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_8]]></meta_key>
			<meta_value><![CDATA[fmaeso@um.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_8]]></meta_key>
			<meta_value><![CDATA[Universidad de Murcia - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/093]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Diseño de operadores de mutación para características de sensibilidad al contexto en aplicaciones móviles</title>
		<link>https://biblioteca.sistedes.es/articulo/diseno-de-operadores-de-mutacion-para-caracteristicas-de-sensibilidad-al-contexto-en-aplicaciones-moviles/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:54 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/diseno-de-operadores-de-mutacion-para-caracteristicas-de-sensibilidad-al-contexto-en-aplicaciones-moviles/</guid>
		<description></description>
		<content><![CDATA[Este artículo presenta el diseño arquitectónico de un conjunto de operadores de mutación. Este diseño mejora el tiempo y coste de implementación de nuevos operadores respecto de la experiencia previa de los autores en el desarrollo de otras herramientas de mutación. El diseño, además, se está utilizando para la creación de operadores específicamente diseñados para reproducir artificialmente errores sobre las características de sensibilidad al contexto de aplicaciones móviles.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3020</post_id>
		<post_date><![CDATA[2018-07-26 06:17:54]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:54]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[diseno-de-operadores-de-mutacion-para-caracteristicas-de-sensibilidad-al-contexto-en-aplicaciones-moviles]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="operadores-de-mutacion"><![CDATA[operadores de mutación]]></category>
		<category domain="post_tag" nicename="tecnologia-movil"><![CDATA[Tecnología móvil]]></category>
		<category domain="post_tag" nicename="testing"><![CDATA[Testing]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Este artículo presenta el diseño arquitectónico de un conjunto de operadores de mutación. Este diseño mejora el tiempo y coste de implementación de nuevos operadores respecto de la experiencia previa de los autores en el desarrollo de otras herramientas de mutación. El diseño, además, se está utilizando para la creación de operadores específicamente diseñados para reproducir artificialmente errores sobre las características de sensibilidad al contexto de aplicaciones móviles.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-098.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-098.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Macario Polo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[macario.polo@uclm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Castilla-La Mancha - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Isyed De La Caridad Rodriguez Trujillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[isyedcrt@gmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Concepcion - Chile]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/094]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Empirical Evaluation of the Effects of Experience on Code Quality and Programmer Productivity: An Exploratory Study (Artículo Relevante)</title>
		<link>https://biblioteca.sistedes.es/articulo/empirical-evaluation-of-the-effects-of-experience-on-code-quality-and-programmer-productivity-an-exploratory-study-articulo-relevante/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:55 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/empirical-evaluation-of-the-effects-of-experience-on-code-quality-and-programmer-productivity-an-exploratory-study-articulo-relevante/</guid>
		<description></description>
		<content><![CDATA[Context. There is a widespread belief in both SE and other branches of science that experience helps professionals to improve their performance. However, cases have been reported where experience not only does not have a positive influence but sometimes even degrades the performance of professionals. Aim. Determinewhether years of experience influence programmer performance. Method. We have analysed 10 quasi-experiments executed both in academia with graduate and postgraduate students and in industry with professionals. The experimental task was to apply ITLD on two experimental problems and then measure external code quality and programmer productivity. Results. Programming experience gained in industry does not appear to have any effect whatsoever on quality and productivity. Overall programming experience gained in academia does tend to have a positive influence on programmer performance. These two findings may be related to the fact that, as opposed to deliberate practice, routine practice does not appear to lead to improved performance. Experience in the use of productivity tools, such as testing frameworks and IDE also has positive effects. Conclusion. Years of experience are a poor predictor of programmer performance. Academic background and specialized knowledge of task-relatedaspects appear to be rather good predictors.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3022</post_id>
		<post_date><![CDATA[2018-07-26 06:17:55]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:55]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[empirical-evaluation-of-the-effects-of-experience-on-code-quality-and-programmer-productivity-an-exploratory-study-articulo-relevante]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="academy"><![CDATA[academy]]></category>
		<category domain="post_tag" nicename="experience"><![CDATA[experience]]></category>
		<category domain="post_tag" nicename="external-quality"><![CDATA[external quality]]></category>
		<category domain="post_tag" nicename="industry"><![CDATA[industry]]></category>
		<category domain="post_tag" nicename="iterative-test-last-development"><![CDATA[iterative test-last development]]></category>
		<category domain="post_tag" nicename="performance"><![CDATA[Performance]]></category>
		<category domain="post_tag" nicename="productivity"><![CDATA[productivity]]></category>
		<category domain="post_tag" nicename="programming"><![CDATA[programming]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Context. There is a widespread belief in both SE and other branches of science that experience helps professionals to improve their performance. However, cases have been reported where experience not only does not have a positive influence but sometimes even degrades the performance of professionals. Aim. Determine
whether years of experience influence programmer performance. Method. We have analysed 10 quasi-experiments executed both in academia with graduate and postgraduate students and in industry with professionals. The experimental task was to apply ITLD on two experimental problems and then measure external code quality and programmer productivity. Results. Programming experience gained in industry does not appear to have any effect whatsoever on quality and productivity. Overall programming experience gained in academia does tend to have a positive influence on programmer performance. These two findings may be related to the fact that, as opposed to deliberate practice, routine practice does not appear to lead to improved performance. Experience in the use of productivity tools, such as testing frameworks and IDE also has positive effects. Conclusion. Years of experience are a poor predictor of programmer performance. Academic background and specialized knowledge of task-related
aspects appear to be rather good predictors.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-100.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-100.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Oscar Dieste]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[odieste@fi.upm.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad Politécnica de Madrid - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/096]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Una aproximación Web para la gestión dinámica de segmentos poblacionales</title>
		<link>https://biblioteca.sistedes.es/articulo/una-aproximacion-web-para-la-gestion-dinamica-de-segmentos-poblacionales/</link>
		<pubDate>Thu, 26 Jul 2018 04:17:55 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/una-aproximacion-web-para-la-gestion-dinamica-de-segmentos-poblacionales/</guid>
		<description></description>
		<content><![CDATA[En los últimos años, el concepto de Smart City ha estado en los planes estratégicos y agendas digitales de muchas administraciones públicas tanto de ámbito local como regional o nacional. Así, se ha hecho un importante esfuerzo por sensorizar ciudades, generando un gran volumen de datos de las mismas. Sin embargo, actualmente sólo el 5% de los datos generados llega a ser procesado, obteniendo un beneficio muy inferior al potencial que estos datos ofrecen. En este trabajo se presenta un prototipo basado en la utilización de Flujos Dinámicos de Actividad Geo-Temporal que pretende dar soporte al consumo de estos datos mediante el uso de un recurso ampliamente utilizado para representar las ciudades a lo largo de la historia, sus mapas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3023</post_id>
		<post_date><![CDATA[2018-07-26 06:17:55]]></post_date>
		<post_date_gmt><![CDATA[2018-07-26 04:17:55]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[una-aproximacion-web-para-la-gestion-dinamica-de-segmentos-poblacionales]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="post_tag" nicename="actividad-geo-temporal"><![CDATA[Actividad Geo-Temporal]]></category>
		<category domain="post_tag" nicename="flujos-de-datos-inteligentes"><![CDATA[Flujos de Datos Inteligentes]]></category>
		<category domain="post_tag" nicename="smart-cities"><![CDATA[Smart Cities]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En los últimos años, el concepto de Smart City ha estado en los planes estratégicos y agendas digitales de muchas administraciones públicas tanto de ámbito local como regional o nacional. Así, se ha hecho un importante esfuerzo por sensorizar ciudades, generando un gran volumen de datos de las mismas. Sin embargo, actualmente sólo el 5% de los datos generados llega a ser procesado, obteniendo un beneficio muy inferior al potencial que estos datos ofrecen. En este trabajo se presenta un prototipo basado en la utilización de Flujos Dinámicos de Actividad Geo-Temporal que pretende dar soporte al consumo de estos datos mediante el uso de un recurso ampliamente utilizado para representar las ciudades a lo largo de la historia, sus mapas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[1]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-101.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JISBD/2018-JISBD-101.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Álvaro E. Prieto]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[aeprieto@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José María Conejero]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[chemacm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Carlos Preciado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jcpreciado@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Extremadura - Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JISBD/2018/097]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Linking Data and BPMN Processes to Achieve Executable Models (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/linking-data-and-bpmn-processes-to-achieve-executable-models-summary/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/linking-data-and-bpmn-processes-to-achieve-executable-models-summary/</guid>
		<description></description>
		<content><![CDATA[Summary of the Contribution The two main assets of any organization are (i) information, i.e., data, which are the things that the organization knows about, and (ii) processes, which are collections of activities that describe how work is performed within an organiza- tion. Recent research has highlighted the importance of considering both process and data as key elements in process and service design. However, models that represent processes and data are typically developed by different teams, resulting in unrelated models which neglect the interaction between the two.
Bearing this in mind, in this paper we propose to connect processes and data, and a way to automatically execute the resulting model. To do so, we assume that processes are represented using BPMN and data in a UML class diagram.
In order to link both formalisms, we propose the following: (1) the creation of an Artifact, which represents a set of process variables associated to a certain process instance, and (2) the specification of the activities or tasks in the process, showing how they make changes to the data. We propose representing the artifact as an additional class in the UML class diagram. On the other hand, we opt for OCL operation contracts (with a pre and a postcondition) to specify details of the process activities. Note that other languages could be used to represent the data, the process and the contracts, as long as they have unambiguous semantics and whose expressiveness is equivalent to first-order logic.
Following this framework, we can then achieve executability of the frame- work, by relying on SQL technology. The UML class diagram is encoded as a relational database, the BPMN diagram can be formalized as a Petri net, and the OCL contracts can be encoded as logic rules from which SQL statements can be derived and applied to the database.
To prove the feasiblity of our approach, we have developed a prototype tool in Java which can load the models in our framework and execute the operations at runtime in a relational database.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3116</post_id>
		<post_date><![CDATA[2018-08-02 18:53:01]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[linking-data-and-bpmn-processes-to-achieve-executable-models-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Summary of the Contribution The two main assets of any organization are (i) information, i.e., data, which are the things that the organization knows about, and (ii) processes, which are collections of activities that describe how work is performed within an organiza- tion. Recent research has highlighted the importance of considering both process and data as key elements in process and service design. However, models that represent processes and data are typically developed by different teams, resulting in unrelated models which neglect the interaction between the two.
Bearing this in mind, in this paper we propose to connect processes and data, and a way to automatically execute the resulting model. To do so, we assume that processes are represented using BPMN and data in a UML class diagram.
In order to link both formalisms, we propose the following: (1) the creation of an Artifact, which represents a set of process variables associated to a certain process instance, and (2) the specification of the activities or tasks in the process, showing how they make changes to the data. We propose representing the artifact as an additional class in the UML class diagram. On the other hand, we opt for OCL operation contracts (with a pre and a postcondition) to specify details of the process activities. Note that other languages could be used to represent the data, the process and the contracts, as long as they have unambiguous semantics and whose expressiveness is equivalent to first-order logic.
Following this framework, we can then achieve executability of the frame- work, by relying on SQL technology. The UML class diagram is encoded as a relational database, the BPMN diagram can be formalized as a Petri net, and the OCL contracts can be encoded as logic rules from which SQL statements can be derived and applied to the database.
To prove the feasiblity of our approach, we have developed a prototype tool in Java which can load the models in our framework and execute the operations at runtime in a relational database.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-001.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-001.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Giuseppe De Giacomo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[degiacomo@dis.uniroma1.it]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Sapienza Università di Roma, Rome, Italy]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Xavier Oriol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[oriol@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya, Barcelona, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Montserrat Estañol]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[estanyol@essi.upc.edu]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politècnica de Catalunya, Barcelona, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/001]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>VISUAL PPINOT: A Graphical Notation for Process Performance Indicators (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/visual-ppinot-a-graphical-notation-for-process-performance-indicators-summary/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/visual-ppinot-a-graphical-notation-for-process-performance-indicators-summary/</guid>
		<description></description>
		<content><![CDATA[Summary of the contribution

Process performance indicators (PPIs) allow the quantitative evaluation of business processes (BPs), providing essential information for decision making. However, PPI management is not only restricted to the evaluation phase of the BPM lifecycle, but also includes a number of steps that must be carried out throughout the whole lifecycle. PPIs need to be defined, the corresponding BPs must be instrumented, PPI values have to be computed, then they can be monitored and analysed using techniques such as business activity monitoring or process mining, and finally, a PPI redefinition can be required in case of the evolution of either the associated BPs or the PPIs themselves. It is common practice today that BPs and PPIs are usually modelled separately using graphical notations for the former and natural language for the latter. This approach makes PPI definitions simple to read and write, but it hinders maintenance consistency between BPs and PPIs. It also requires their manual translation into lower–level implementation languages for their operationalisation, which is a time–consuming, error– prone task because of the ambiguities inherent to natural language definitions. In this article we present Visual ppinot, a graphical notation for defining PPIs together with BP models aimed at facilitating and automating PPI management. This is mainly achieved by means of the following features. First, Visual ppinot is based on the ppinot metamodel, which provides a precise and unambiguous definition of PPIs, thus allowing their automated processing in the different ac- tivities of the lifecycle. Second, Visual ppinot provides traceability by design between PPIs and BPs because PPIs must be explicitly connected to BP elements, thus avoiding inconsistencies and promoting their co–evolution. Finally, Visual ppinot enables a definition of PPIs that is independent of the platforms used to support the PPIs in the BP lifecycle, which reduces vendor lock–in and allows definitions of PPIs encompassing several information systems. In addition, it improves current state–of–the–art proposals in terms of expressiveness and of providing an explicit visualisation of the link between PPIs and BPs. The reference implementation, developed as a complete tool suite, has allowed its validation in a multiple-case study, in which five dimensions were studied: expressiveness, precision, automation, understandability, and traceability.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3117</post_id>
		<post_date><![CDATA[2018-08-02 18:53:01]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[visual-ppinot-a-graphical-notation-for-process-performance-indicators-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Summary of the contribution

Process performance indicators (PPIs) allow the quantitative evaluation of busi- ness processes (BPs), providing essential information for decision making. How- ever, PPI management is not only restricted to the evaluation phase of the BPM lifecycle, but also includes a number of steps that must be carried out through- out the whole lifecycle. PPIs need to be defined, the corresponding BPs must be instrumented, PPI values have to be computed, then they can be monitored and analysed using techniques such as business activity monitoring or process mining, and finally, a PPI redefinition can be required in case of the evolution of either the associated BPs or the PPIs themselves. It is common practice today that BPs and PPIs are usually modelled separately using graphical notations for the former and natural language for the latter. This approach makes PPI definitions simple to read and write, but it hinders maintenance consistency between BPs and PPIs. It also requires their manual translation into lower–level implemen- tation languages for their operationalisation, which is a time–consuming, error– prone task because of the ambiguities inherent to natural language definitions. In this article we present Visual ppinot, a graphical notation for defining PPIs together with BP models aimed at facilitating and automating PPI management. This is mainly achieved by means of the following features. First, Visual ppinot is based on the ppinot metamodel, which provides a precise and unambiguous definition of PPIs, thus allowing their automated processing in the di?erent ac- tivities of the lifecycle. Second, Visual ppinot provides traceability by design between PPIs and BPs because PPIs must be explicitly connected to BP ele- ments, thus avoiding inconsistencies and promoting their co–evolution. Finally, Visual ppinot enables a definition of PPIs that is independent of the platforms used to support the PPIs in the BP lifecycle, which reduces vendor lock–in and allows definitions of PPIs encompassing several information systems. In addi- tion, it improves current state–of–the–art proposals in terms of expressiveness and of providing an explicit visualisation of the link between PPIs and BPs. The reference implementation, developed as a complete tool suite, has allowed its validation in a multiple-case study, in which five dimensions were studied: expressiveness, precision, automation, understandability, and traceability.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[Restringida]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-002.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-002.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Adela del-R??o-Ortega]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[adeladelrio@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Amador Durán]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[amador@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Beatriz Bernárdez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[beat@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Miguel Toro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[migueltoro@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/002]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Run-time prediction of business process indicators using evolutionary decision rules (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/run-time-prediction-of-business-process-indicators-using-evolutionary-decision-rules-summary/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/run-time-prediction-of-business-process-indicators-using-evolutionary-decision-rules-summary/</guid>
		<description></description>
		<content><![CDATA[Summary of the contribution

Predictive monitoring of business processes is a challenging topic of process min- ing which is concerned with the prediction of process indicators of running pro- cess instances. The main value of predictive monitoring is to provide information in order to take proactive and corrective actions to improve process performance and mitigate risks in real time. In this paper, we present an approach for pre- dictive monitoring based on the use of evolutionary algorithms. Our method provides a novel event window-based encoding and generates a set of decision rules for the run-time prediction of process indicators according to event log properties. These rules can be interpreted by users to extract further insight of the business processes while keeping a high level of accuracy. Furthermore, a full software stack consisting of a tool to support the training phase and a framework that enables the integration of run-time predictions with business process man- agement systems, has been developed. Obtained results show the validity of our proposal for two large real-life datasets: BPI Challenge 2013 and IT Department of Andalusian Health Service (SAS).]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3118</post_id>
		<post_date><![CDATA[2018-08-02 18:53:01]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[run-time-prediction-of-business-process-indicators-using-evolutionary-decision-rules-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="business-process-indicator"><![CDATA[Business process indicator]]></category>
		<category domain="post_tag" nicename="business-process-management"><![CDATA[Business Process Management]]></category>
		<category domain="post_tag" nicename="evolutionary-algorithm"><![CDATA[Evolutionary algorithm]]></category>
		<category domain="post_tag" nicename="predictive-mon-itoring"><![CDATA[Predictive mon- itoring]]></category>
		<category domain="post_tag" nicename="process-mining"><![CDATA[Process Mining]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Summary of the contribution

Predictive monitoring of business processes is a challenging topic of process min- ing which is concerned with the prediction of process indicators of running pro- cess instances. The main value of predictive monitoring is to provide information in order to take proactive and corrective actions to improve process performance and mitigate risks in real time. In this paper, we present an approach for pre- dictive monitoring based on the use of evolutionary algorithms. Our method provides a novel event window-based encoding and generates a set of decision rules for the run-time prediction of process indicators according to event log properties. These rules can be interpreted by users to extract further insight of the business processes while keeping a high level of accuracy. Furthermore, a full software stack consisting of a tool to support the training phase and a framework that enables the integration of run-time predictions with business process man- agement systems, has been developed. Obtained results show the validity of our proposal for two large real-life datasets: BPI Challenge 2013 and IT Department of Andalusian Health Service (SAS).]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-003.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-003.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alfonso E. Márquez-Chamorro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[amarquez6@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, University of Seville, Seville, Spain.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/003]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>CARED-SOA: a Context-AwaRe Event-Driven Service Oriented Architecture (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/cared-soa-a-context-aware-event-driven-service-oriented-architecture-summary/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/cared-soa-a-context-aware-event-driven-service-oriented-architecture-summary/</guid>
		<description></description>
		<content><![CDATA[Summary of the Contribution

Context awareness takes part of citizens’ day-to-day life. However, there is a limited amount of context-aware services that users can benefit from; there are still many of- fered services which are not context-aware. This need for being aware of what happens at every instant, requires a software infrastructure, not only for receiving the context information but also to make use of it to provide advantageous customized services. In parallel, the impressive evolution of the Internet of Things (IoT) over the last years has strongly favored the provision of a large amount of data that software applications can easily consume. Such data requires constant streaming processing for business decision-making. Technologies, such as Complex Event Processing (CEP), rise in order to provide such constant data processing in streaming. Additionally, currently the strategy for software development for citizens and other agents is mainly based on services, since Service Oriented Architectures (SOAs) are platform-independent and loosely coupled. Also, Representational State Transfer (REST) services have become very successful since they are light services which can be easily consumed by third-parties. Due to all these facts, in this paper we provided CARED-SOA to face this challenge. CARED-SOA is an Event-Driven SOA (ED-SOA) supported by an Enterprise Service Bus (ESB) which (1) facilitates the incorporation of data coming from devices con- nected to the IoT through several connectors and (2) facilitates communications among all involved agents. Besides, the architecture (3) provides real-time stream data processing through the integration of CEP technology and (4) offers REST services to the users, which will be context-aware. Besides, the paper also provides the implementation of a real-world case study, which permits the evaluation of the architecture.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3119</post_id>
		<post_date><![CDATA[2018-08-02 18:53:01]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[cared-soa-a-context-aware-event-driven-service-oriented-architecture-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Summary of the Contribution

Context awareness takes part of citizens’ day-to-day life. However, there is a limited amount of context-aware services that users can benefit from; there are still many of- fered services which are not context-aware. This need for being aware of what happens at every instant, requires a software infrastructure, not only for receiving the context information but also to make use of it to provide advantageous customized services. In parallel, the impressive evolution of the Internet of Things (IoT) over the last years has strongly favored the provision of a large amount of data that software applications can easily consume. Such data requires constant streaming processing for business deci- sion-making. Technologies, such as Complex Event Processing (CEP), rise in order to provide such constant data processing in streaming. Additionally, currently the strategy for software development for citizens and other agents is mainly based on services, since Service Oriented Architectures (SOAs) are platform-independent and loosely coupled. Also, Representational State Transfer (REST) services have become very suc- cessful since they are light services which can be easily consumed by third-parties. Due to all these facts, in this paper we provided CARED-SOA to face this challenge. CARED-SOA is an Event-Driven SOA (ED-SOA) supported by an Enterprise Service Bus (ESB) which (1) facilitates the incorporation of data coming from devices con- nected to the IoT through several connectors and (2) facilitates communications among all involved agents. Besides, the architecture (3) provides real-time stream data pro- cessing through the integration of CEP technology and (4) offers REST services to the users, which will be context-aware. Besides, the paper also provides the implementa- tion of a real-world case study, which permits the evaluation of the architecture.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-004.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-004.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alfonso García de Prado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alfonso.garciadeprado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/004]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Detección de concept drift en minería de procesos basado en agrupamiento de trazas</title>
		<link>https://biblioteca.sistedes.es/articulo/deteccion-de-concept-drift-en-mineria-de-procesos-basado-en-agrupamiento-de-trazas/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/deteccion-de-concept-drift-en-mineria-de-procesos-basado-en-agrupamiento-de-trazas/</guid>
		<description></description>
		<content><![CDATA[En este artículo se presenta un método para la detección y localización de concept drift en minería de procesos, que, a diferencia del resto de propuestas del estado del arte, combina técnicas de agrupamiento de trazas y descubrimiento de modelos para realizar una clasificación de las trazas de ejecución contra una serie de modelos que constituyen el ground truth de nuestro sistema. Esta aproximación permite detectar, localizar y caracterizar los cambios y evaluar la evolución sufrida por el proceso. El algoritmo ha sido validado con un registro de eventos sintético que presenta puntos de concept drift, demostrando que la aproximación tomada es válida a la hora de detectar cuándo tiene lugar un cambio en la estructura del modelo de proceso.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3120</post_id>
		<post_date><![CDATA[2018-08-02 18:53:01]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[deteccion-de-concept-drift-en-mineria-de-procesos-basado-en-agrupamiento-de-trazas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[En este artículo se presenta un método para la detección y localización de concept drift en minería de procesos, que, a diferencia del resto de propuestas del estado del arte, combina técnicas de agrupamien- to de trazas y descubrimiento de modelos para realizar una clasificación de las trazas de ejecución contra una serie de modelos que constituyen el ground truth de nuestro sistema. Esta aproximación permite detectar, localizar y caracterizar los cambios y evaluar la evolución sufrida por el proceso. El algoritmo ha sido validado con un registro de eventos sintético que presenta puntos de concept drift, demostrando que la aproximación tomada es válida a la hora de detectar cuándo tiene lugar un cambio en la estructura del modelo de proceso.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-005.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-005.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Víctor José Gallego Fontenla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[victorjose.gallego@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Carlos Vidal Aguiar]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juan.vidal@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Lama]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuel.lama@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información Universidade de Santiago de Compostela]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/005]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Discovering Infrequent Behavioral Patterns in Process Models (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/discovering-infrequent-behavioral-patterns-in-process-models-summary/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/discovering-infrequent-behavioral-patterns-in-process-models-summary/</guid>
		<description></description>
		<content><![CDATA[In this paper we present WoMine-i, a novel algorithm to detect infrequent behavioural patterns from a process model, measuring their frequency with the instances of the log. A behavioural pattern is a subgraph of the process model, com- posed by all type of structures —sequences, selections, parallels and/or loops—, which represents the behaviour of a part of the process. And it is considered infrequent when its complete execution happens in a number of cases from the log below a predefined threshold. To find the infrequent patterns, WoMine-i performs an a priori search starting with the minimal structures of the model. In this search, there is an expansion stage done in two ways: i) adding other minimal structures not contained in the current pattern, and ii) adding arcs. This expansion is followed by a pruning strategy that verifies the upward-closure property of support —also known as monotonicity. This property ensures that if a pattern is infrequent, all patterns containing it will be infrequent and, thus, it is no necessary to continue expanding it —the minimum pattern itself expresses all the infrequent behaviour containing it. This pruning presents an exception in order to simplify the results: If a pattern is infrequent and maintains the value of its frequency with the expansion, it is not removed from the expansion stage —it means it is being expanded with a selection branch with less frequency. In this way, WoMine-i returns the largest patterns expressing the minimum infrequent behaviour. In each step of the iterative process, WoMine-i reduces the search space by pruning some of the generated patterns. For this, an algorithm to check the frequency of a pattern is needed. WoMine-i generates the different paths of a pattern, henceforth simple patterns, and checks the frequency of each one. To measure the frequency of a simple pattern, WoMine-i replays the traces of the log and checks how many of them are compliant with it. At each step of the replay, the algorithm checks if the simple pattern is being correctly executed. Afterwards, WoMine-i assigns to the pattern the higher of its simple patterns frequency, and checks if the pattern is considered frequent w.r.t. the threshold. Thereby, given a log and a corresponding model, WoMine-i is able to return the infrequent patterns of it. Allowing to study them and enhance the process consequently.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3121</post_id>
		<post_date><![CDATA[2018-08-02 18:53:01]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[discovering-infrequent-behavioral-patterns-in-process-models-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[In this paper we present WoMine-i, a novel algorithm to detect infrequent be- havioural patterns from a process model, measuring their frequency with the in- stances of the log. A behavioural pattern is a subgraph of the process model, com- posed by all type of structures —sequences, selections, parallels and/or loops—, which represents the behaviour of a part of the process. And it is considered infrequent when its complete execution happens in a number of cases from the log below a predefined threshold. To find the infrequent patterns, WoMine-i performs an a priori search starting with the minimal structures of the model. In this search, there is an expansion stage done in two ways: i) adding other minimal structures not contained in the current pattern, and ii) adding arcs. This expansion is followed by a pruning strategy that verifies the upward-closure property of support —also known as monotonicity. This property ensures that if a pattern is infrequent, all patterns containing it will be infrequent and, thus, it is no necessary to continue expanding it —the minimum pattern itself expresses all the infrequent behaviour containing it. This pruning presents an exception in order to simplify the results: If a pattern is infrequent and maintains the value of its frequency with the expansion, it is not removed from the expansion stage —it means it is being expanded with a selection branch with less frequency. In this way, WoMine-i returns the largest patterns expressing the minimum infrequent behaviour. In each step of the iterative process, WoMine-i reduces the search space by pruning some of the generated patterns. For this, an algorithm to check the frequency of a pattern is needed. WoMine-i generates the different paths of a pattern, henceforth simple patterns, and checks the frequency of each one. To measure the frequency of a simple pattern, WoMine-i replays the traces of the log and checks how many of them are compliant with it. At each step of the replay, the algorithm checks if the simple pattern is being correctly executed. Afterwards, WoMine-i assigns to the pattern the higher of its simple patterns frequency, and checks if the pattern is considered frequent w.r.t. the threshold. Thereby, given a log and a corresponding model, WoMine-i is able to return the infrequent patterns of it. Allowing to study them and enhance the process consequently.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-006.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-006.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Chapela-Campa]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[david.chapela@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS) Universidade de Santiago de Compostela. Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Mucientes]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[manuel.mucientes@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS) Universidade de Santiago de Compostela. Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Lama]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[manuel.lama@usc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS) Universidade de Santiago de Compostela. Santiago de Compostela, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/006]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Generación de Datos Sintéticos para Arquitecturas de Procesamiento de Datos del Internet de las Cosas</title>
		<link>https://biblioteca.sistedes.es/articulo/generacion-de-datos-sinteticos-para-arquitecturas-de-procesamiento-de-datos-del-internet-de-las-cosas/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:01 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/generacion-de-datos-sinteticos-para-arquitecturas-de-procesamiento-de-datos-del-internet-de-las-cosas/</guid>
		<description></description>
		<content><![CDATA[La vertiginosa evolución del Internet de las Cosas, sumada a las grandes cantidades de datos heterogéneos que fluyen por los sistemas de información, han dado lugar a diversas plataformas software que analizan dichos datos con el objetivo de mejorar la toma de decisiones. Estas plataformas requieren de una prueba en materia de eficacia y eficiencia antes de su puesta en producción; para ello requieren de grandes cantidades de datos del dominio tecnológico y de aplicación en cuestión. Con este fin se implementa nITROGEN: un generador de datos sintéticos para el IoT que cubre las necesidades de estos sistemas.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3122</post_id>
		<post_date><![CDATA[2018-08-02 18:53:01]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:01]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[generacion-de-datos-sinteticos-para-arquitecturas-de-procesamiento-de-datos-del-internet-de-las-cosas]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="arquitecturas-orientadas-a-servicios"><![CDATA[arquitecturas orientadas a servicios]]></category>
		<category domain="post_tag" nicename="consciencia-del-contexto"><![CDATA[Consciencia del Contexto]]></category>
		<category domain="post_tag" nicename="generador-de-datos-sinteticos"><![CDATA[Generador de Datos Sintéticos]]></category>
		<category domain="post_tag" nicename="internet-de-las-cosas"><![CDATA[Internet de las Cosas]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La vertiginosa evolución del Internet de las Cosas, sumada a las gran- des cantidades de datos heterogéneos que fluyen por los sistemas de información, han dado lugar a diversas plataformas software que analizan dichos datos con el objetivo de mejorar la toma de decisiones. Estas plataformas requieren de una prueba en materia de eficacia y eficiencia antes de su puesta en producción; para ello requieren de grandes cantidades de datos del dominio tecnológico y de apli- cación en cuestión. Con este fin se implementa nITROGEN: un generador de datos sintéticos para el IoT que cubre las necesidades de estos sistemas.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-007.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-007.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alfonso García de Prado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[alfonso.garciadeprado@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software Escuela Superior de Ingeniería, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo UCASE de Ingeniería del Software Escuela Superior de Ingeniería, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanher@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo Quercus de Ingeniería del Software INTIA, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Enrique Moguel]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[enrique@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo Quercus de Ingeniería del Software INTIA, Universidad de Extremadura]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/007]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Analysis of users’ behavior in structured e-commerce websites (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/analysis-of-users-behavior-in-structured-e-commerce-websites-summary/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/analysis-of-users-behavior-in-structured-e-commerce-websites-summary/</guid>
		<description></description>
		<content><![CDATA[Los portales de comercio electrónico almacenan información sobre las páginas que visitan sus clientes y las acciones y servicios que estos usan durante la navegación. Esta información se puede enriquecer combinándola con los datos personales, geográficos, demográficos e historiales de compra de cada cliente particular. El análisis de todos estos datos permite ofrecer servicios más personalizados, mejorar la estructura y contenidos del portal, evaluar el impacto de las campañas publicitarias o fidelizar a nuevos clientes, entre otros usos. En este trabajo se propone el uso de técnicas de “model-checking” para el análisis del comportamiento que presentan los usuarios de un comercio electrónico. El procesado de los ficheros log del servidor permite extraer información sobre las sesiones de usuario. Una sesión se describe por medio de una secuencia de eventos (visitar un producto, visitar una categoría, añadir/eliminar un producto del carro, usar el buscador, comprar, etc.), donde cada evento consta de una colección de atributos que ofrece una visión detallada de lo sucedido. La técnica de análisis propuesta permite al experto en el negocio descubrir patrones de comportamiento habituales e inusuales de sus usuarios/clientes. Este descubrimiento se realiza por medio de una estrategia de inspección, es decir, a través de preguntas que son evaluadas contras las sesiones de usuario. Estas preguntas indagan sobre relaciones de causalidad de interés entre los eventos y son expresadas por medio de un nuevo tipo de lógica temporal lineal y evaluadas con un “model-checker”. En este artículo se presenta la metodología de análisis, la herramienta construida y un caso de aplicación real. Este caso corresponde con el análisis del portal de venta de la empresa Up&amp;Scrap, el principal distribuidor español online de productos de scrapbooking. Este trabajo de investigación está financiado por los proyectos TIN2014- 56633-C3-2-R y TIN2017-84796-C2-2-R del Ministerio de Economía, Industria y Competitividad del Gobierno de España.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3123</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analysis-of-users-behavior-in-structured-e-commerce-websites-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los portales de comercio electrónico almacenan información sobre las páginas que visitan sus clientes y las acciones y servicios que estos usan durante la navegación. Esta información se puede enriquecer combinándola con los datos personales, geográficos, demográficos e historiales de compra de cada cliente particular. El análisis de todos estos datos permite ofrecer servicios más personalizados, mejorar la estructura y contenidos del portal, evaluar el impacto de las campañas publicitarias o fidelizar a nuevos clientes, entre otros usos. En este trabajo se propone el uso de técnicas de “model-checking” para el análisis del comportamiento que presentan los usuarios de un comercio electrónico. El procesado de los ficheros log del servidor permite extraer información sobre las sesiones de usuario. Una sesión se describe por medio de una secuencia de eventos (visitar un producto, visitar una categor??a, añadir/eliminar un producto del carro, usar el buscador, comprar, etc.), donde cada evento consta de una colección de atributos que ofrece una visión detallada de lo sucedido. La técnica de análisis propuesta permite al experto en el negocio descubrir patrones de comportamiento habituales e inusuales de sus usuarios/clientes. Este descubrimiento se realiza por medio de una estrategia de inspección, es decir, a través de preguntas que son evaluadas contras las sesiones de usuario. Estas preguntas indagan sobre relaciones de causalidad de interés entre los eventos y son expresadas por medio de un nuevo tipo de lógica temporal lineal y evaluadas con un “model-checker”. En este art??culo 1 se presenta la metodolog??a de análisis, la herramienta construida y un caso de aplicación real. Este caso corresponde con el análisis del portal de venta de la empresa Up&Scrap, el principal distribuidor español online de productos de scrapbooking. Este trabajo de investigación está financiado por los proyectos TIN2014- 56633-C3-2-R y TIN2017-84796-C2-2-R del Ministerio de Econom??a, Industria y Competitividad del Gobierno de España.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-008.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-008.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[S. Hernández]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[shernandez@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Aragón Institute of Engineering Research (I3A) Department of Computer Science and Systems Engineering University of Zaragoza, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pedro Álvarez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[alvaper@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Aragón Institute of Engineering Research (I3A) Department of Computer Science and Systems Engineering University of Zaragoza, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[J. Fabra]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[jfabra@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Aragón Institute of Engineering Research (I3A) Department of Computer Science and Systems Engineering University of Zaragoza, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[J. Ezpeleta]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[ezpeleta@unizar.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Aragón Institute of Engineering Research (I3A) Department of Computer Science and Systems Engineering University of Zaragoza, Spain  ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/008]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Enhancing EUCalipTool Service Composition through Natural Language Processing</title>
		<link>https://biblioteca.sistedes.es/articulo/enhancing-eucaliptool-service-composition-through-natural-language-processing/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/enhancing-eucaliptool-service-composition-through-natural-language-processing/</guid>
		<description></description>
		<content><![CDATA[Although end-users have available a lot of on-line services to be con- sumed individually, it is their composed usage what has the potential to create new value-added services for end-users. In this sense, many efforts have been done to allow end-users to compose the services that they need by themselves. However, most of these solutions present two main problems: (1) they provide little support to help end-users to browse interminable lists of services, and (2) they present the blank piece of paper problem, which appears when end-users have to face an empty canvas to define a composition without any help to find the services that better fit their needs. In this paper, we present a solution to im- prove these problems by using natural language processing techniques in order to search and select the services end-users need to accomplish a specific goal. This solution has been implemented in the context of the EUCalipTool platform.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3124</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[enhancing-eucaliptool-service-composition-through-natural-language-processing]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="mobile-authoring-tool"><![CDATA[Mobile authoring Tool]]></category>
		<category domain="post_tag" nicename="natural-language-processing"><![CDATA[Natural Language Processing]]></category>
		<category domain="post_tag" nicename="service-selection-and-composition"><![CDATA[Service Selection and Composition]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Although end-users have available a lot of on-line services to be con- sumed individually, it is their composed usage what has the potential to create new value-added services for end-users. In this sense, many efforts have been done to allow end-users to compose the services that they need by themselves. However, most of these solutions present two main problems: (1) they provide little support to help end-users to browse interminable lists of services, and (2) they present the blank piece of paper problem, which appears when end-users have to face an empty canvas to define a composition without any help to find the services that better fit their needs. In this paper, we present a solution to im- prove these problems by using natural language processing techniques in order to search and select the services end-users need to accomplish a specific goal. This solution has been implemented in the context of the EUCalipTool platform.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-009.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-009.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Pedro Valderas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[pvalderas@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Victoria Torres]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[vtorres@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Vicente Pelechano]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pele@pros.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universitat Politécnica de Valéncia Pros Research Center]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/009]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Model-driven Migration Approach among Cloud Providers</title>
		<link>https://biblioteca.sistedes.es/articulo/a-model-driven-migration-approach-among-cloud-providers/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-model-driven-migration-approach-among-cloud-providers/</guid>
		<description></description>
		<content><![CDATA[Cloud computing has become the primary model of pay-per-use to ob- tain cloud services in a short time. Companies are using the cloud services to get access to computing resources located in a virtualized environment. However, the traditional method of using a single cloud provider has numerous limitation in terms of privacy, security, performance, and geography reach. Furthermore, companies are focusing their efforts on avoiding dependent on a single vendor for products and services. As a result, companies start to use multiple clouds and look for methods to move or migrate their infrastructure from a cloud provider to another one. In previous work, we have presented ARGON, which is an infra- structure modeling tool for cloud provisioning. In this paper, we propose an ex- tension of ARGON to provide a model-driven migration approach among cloud providers.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3125</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-model-driven-migration-approach-among-cloud-providers]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="cloud-computing"><![CDATA[Cloud Computing]]></category>
		<category domain="post_tag" nicename="infrastructure-as-a-service"><![CDATA[Infrastructure as a Service]]></category>
		<category domain="post_tag" nicename="infrastructure-as-code"><![CDATA[Infrastructure as Code]]></category>
		<category domain="post_tag" nicename="infrastructure-migra-tion"><![CDATA[Infrastructure Migra- tion]]></category>
		<category domain="post_tag" nicename="model-driven-engineering"><![CDATA[Model-Driven Engineering]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Cloud computing has become the primary model of pay-per-use to ob- tain cloud services in a short time. Companies are using the cloud services to get access to computing resources located in a virtualized environment. However, the traditional method of using a single cloud provider has numerous limitation in terms of privacy, security, performance, and geography reach. Furthermore, companies are focusing their efforts on avoiding dependent on a single vendor for products and services. As a result, companies start to use multiple clouds and look for methods to move or migrate their infrastructure from a cloud provider to another one. In previous work, we have presented ARGON, which is an infra- structure modeling tool for cloud provisioning. In this paper, we propose an ex- tension of ARGON to provide a model-driven migration approach among cloud providers.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-010.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-010.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Julio Sandobalín]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[julio.sandobalin@epn.edu.ec]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Informática y Ciencias de la Computación, Escuela Politécnica Nacional, Ecuador]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Emilio Insfran]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[einsfran@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Silvia Abrahao]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[sabrahao@dsic.upv.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/010]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[2]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Fostering SLA-Driven API Specifications</title>
		<link>https://biblioteca.sistedes.es/articulo/fostering-sla-driven-api-specifications/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/fostering-sla-driven-api-specifications/</guid>
		<description></description>
		<content><![CDATA[Software architecture tendencies are shifting to a microser- vice paradigm. In this context, RESTful APIs are being established the standard of integration. API designer often identifies two key issues to be competitive in such growing market. On the one hand, the generation of accurate documentation of the behavior and capabilities of the API to promote its usage; on the other hand, the design of a pricing plan that fits into the potential API user’s needs. Besides the increasing number of API modeling alternatives is emerging, there is a lack of proposals on the definition of flexible pricing plans usually contained in the Service Level Agreements (SLAs). In this paper we propose two different modeling techniques for the de- scription of SLA in a RESTful API context: iAgree and SLA4OAI.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3126</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[fostering-sla-driven-api-specifications]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Software architecture tendencies are shifting to a microser- vice paradigm. In this context, RESTful APIs are being established the standard of integration. API designer often identifies two key issues to be competitive in such growing market. On the one hand, the generation of accurate documentation of the behavior and capabilities of the API to promote its usage; on the other hand, the design of a pricing plan that fits into the potential API user’s needs. Besides the increasing number of API modeling alternatives is emerging, there is a lack of proposals on the definition of flexible pricing plans usually contained in the Service Level Agreements (SLAs). In this paper we propose two different modeling techniques for the de- scription of SLA in a RESTful API context: iAgree and SLA4OAI.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-011.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-011.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Antonio Gámez-Díaz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[agamez2@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/011]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Hacia una arquitectura para el procesamiento y análisis en tiempo real de datos heterogéneos en IoT</title>
		<link>https://biblioteca.sistedes.es/articulo/hacia-una-arquitectura-para-el-procesamiento-y-analisis-en-tiempo-real-de-datos-heterogeneos-en-iot/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/hacia-una-arquitectura-para-el-procesamiento-y-analisis-en-tiempo-real-de-datos-heterogeneos-en-iot/</guid>
		<description></description>
		<content><![CDATA[Uno de los grandes retos del Internet de las Cosas es la falta de un formato de datos común o una estructura homogénea que facilite el procesamiento y análisis de estos datos. Ser capaces de recibir información heterogénea de múltiples fuentes y, a continuación, poder procesarla para su análisis en tiempo real ofrece la posibilidad de reaccionar a situaciones críticas detectadas de forma inmediata. En este artículo se propone una arquitectura para inferir situaciones críticas en tiempo real que permita dar una respuesta adecuada lo más rápidamente posible.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3127</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[hacia-una-arquitectura-para-el-procesamiento-y-analisis-en-tiempo-real-de-datos-heterogeneos-en-iot]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="analisis-en-tiempo-real"><![CDATA[Análisis en Tiempo Real]]></category>
		<category domain="post_tag" nicename="internet-de-las-cosas"><![CDATA[Internet de las Cosas]]></category>
		<category domain="post_tag" nicename="procesamiento-de-eventos-complejos"><![CDATA[procesamiento de eventos complejos]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Uno de los grandes retos del Internet de las Cosas es la falta de un formato de datos común o una estructura homogénea que facilite el procesa- miento y análisis de estos datos. Ser capaces de recibir información heterogénea de múltiples fuentes y, a continuación, poder procesarla para su análisis en tiempo real ofrece la posibilidad de reaccionar a situaciones críticas detectadas de forma inmediata. En este artículo se propone una arquitectura para inferir situaciones críticas en tiempo real que permita dar una respuesta adecuada lo más rápida- mente posible.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-012.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-012.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Corral-Plaza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[david.corral@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Escuela Superior de Ingeniería Avda. de la Universidad de Cádiz 10, 11519 Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Inmaculada Medina-Bulo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[inmaculada.medina@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Escuela Superior de Ingeniería Avda. de la Universidad de Cádiz 10, 11519 Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Guadalupe Ortiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[guadalupe.ortiz@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Escuela Superior de Ingeniería Avda. de la Universidad de Cádiz 10, 11519 Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Escuela Superior de Ingeniería Avda. de la Universidad de Cádiz 10, 11519 Puerto Real, Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/012]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un Recorrido por los Principales Proveedores de Servicios de Machine Learning y Predicción en la Nube</title>
		<link>https://biblioteca.sistedes.es/articulo/un-recorrido-por-los-principales-proveedores-de-servicios-de-machine-learning-y-prediccion-en-la-nube/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/un-recorrido-por-los-principales-proveedores-de-servicios-de-machine-learning-y-prediccion-en-la-nube/</guid>
		<description></description>
		<content><![CDATA[Los medios tecnológicos para el consumo, producción e intercambio de información no hacen más que aumentar cada día que pasa. Nos encontramos envueltos en el fenómeno Big Data, donde ser capaces de analizar esta informa- ción con el objetivo de poder inferir situaciones del futuro basándonos en datos del pasado y del presente, nos puede reportar una ventaja competitiva que nos distinga claramente de otras opciones. Dentro de las múltiples disciplinas exis- tentes para el análisis de grandes cantidades información encontramos el Ma- chine Learning y, a su vez, dentro de este podemos destacar la capacidad predic- tiva que nos proporcionan muchas de las opciones existentes actualmente en el mercado. En este trabajo realizamos un análisis de estas principales opciones de APIs predictivas en la nube, las comparamos entre sí, y finalmente llevamos a cabo una experimentación con datos reales de la Red de Vigilancia y Control de la Calidad del Aire de la Junta de Andalucía. Los resultados demuestran que estas herramientas son una opción muy interesante a considerar a la hora de tratar de predecir valores de contaminantes que pueden afectar a nuestra salud seriamente, pudiéndose llevar a cabo acciones preventivas sobre la población afectada.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3128</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-recorrido-por-los-principales-proveedores-de-servicios-de-machine-learning-y-prediccion-en-la-nube]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="api"><![CDATA[API]]></category>
		<category domain="post_tag" nicename="big-data"><![CDATA[big data]]></category>
		<category domain="post_tag" nicename="cloud"><![CDATA[Cloud]]></category>
		<category domain="post_tag" nicename="machine-learning"><![CDATA[Machine Learning]]></category>
		<category domain="post_tag" nicename="prediccion"><![CDATA[Predicción]]></category>
		<category domain="post_tag" nicename="software-as-a-service"><![CDATA[Software as a Service]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los medios tecnológicos para el consumo, producción e intercambio de información no hacen más que aumentar cada día que pasa. Nos encontramos envueltos en el fenómeno Big Data, donde ser capaces de analizar esta informa- ción con el objetivo de poder inferir situaciones del futuro basándonos en datos del pasado y del presente, nos puede reportar una ventaja competitiva que nos distinga claramente de otras opciones. Dentro de las múltiples disciplinas exis- tentes para el análisis de grandes cantidades información encontramos el Ma- chine Learning y, a su vez, dentro de este podemos destacar la capacidad predic- tiva que nos proporcionan muchas de las opciones existentes actualmente en el mercado. En este trabajo realizamos un análisis de estas principales opciones de APIs predictivas en la nube, las comparamos entre sí, y finalmente llevamos a cabo una experimentación con datos reales de la Red de Vigilancia y Control de la Calidad del Aire de la Junta de Andalucía. Los resultados demuestran que estas herramientas son una opción muy interesante a considerar a la hora de tratar de predecir valores de contaminantes que pueden afectar a nuestra salud seriamente, pudiéndose llevar a cabo acciones preventivas sobre la población afectada.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-013.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-013.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[David Corral-Plaza]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[david.corral@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Juan Boubeta-Puig]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[juan.boubeta@uca.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Ingeniería Informática, Universidad de Cádiz]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Dpto. Lenguajes y Sistemas Informáticos, Universidad de Sevilla]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/013]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>A Template-based Approach for Responsibility Management in Executable Business Processes (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/a-template-based-approach-for-responsibility-management-in-executable-business-processes-summary/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/a-template-based-approach-for-responsibility-management-in-executable-business-processes-summary/</guid>
		<description></description>
		<content><![CDATA[Summary of the Contribution

Process-oriented organisations need to manage the different types of responsi- bilities their employees may have w.r.t. the activities involved in their business processes. Despite several approaches provide support for responsibility modelling, in current Business Process Management Systems (BPMS) the only responsibility considered at run time is the one related to performing the work required for activity completion. Others like accountability or consultation must be implemented by manually adding activities in the executable process model, which is time-consuming and error-prone. This paper addresses this limitation by enabling current BPMS to execute processes in which people with different responsibilities interact to complete the activities. A metamodel based on Responsibility Assignment Matrices (RAM) is designed to model the responsibility assignment for each activity, and a template- based mechanism that automatically transforms such information into BPMN elements is developed. The approach is independent of the platform and hence, the output models can be interpreted and executed by BPMS that support BPMN. Furthermore, the original structure of the process model remains unchanged, as the templates for modelling responsibilities are defined at subprocess level. This provides transparency and does not affect the readability of the original model. As our approach does not enforce any specific behaviour but new templates can be modelled to specify the interaction that best suits the activity requirements, there is high flexibility and generalisability. Moreover, template libraries can be created and reused in different processes. We provide a reference implementation and build a library of templates for a well-known set of responsibilities.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3129</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[a-template-based-approach-for-responsibility-management-in-executable-business-processes-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Summary of the Contribution

Process-oriented organisations need to manage the di?erent types of responsi- bilities their employees may have w.r.t. the activities involved in their business processes. Despite several approaches provide support for responsibility mod- elling, in current Business Process Management Systems (BPMS) the only re- sponsibility considered at run time is the one related to performing the work required for activity completion. Others like accountability or consultation must be implemented by manually adding activities in the executable process model, which is time-consuming and error-prone. This paper addresses this limitation by enabling current BPMS to execute processes in which people with di?erent responsibilities interact to complete the activities. A metamodel based on Responsibility Assignment Matrices (RAM) is designed to model the responsibility assignment for each activity, and a template- based mechanism that automatically transforms such information into BPMN el- ements is developed. The approach is independent of the platform and hence, the output models can be interpreted and executed by BPMS that support BPMN. Furthermore, the original structure of the process model remains unchanged, as the templates for modelling responsibilities are defined at subprocess level. This provides transparency and does not a?ect the readability of the original model. As our approach does not enforce any specific behaviour but new templates can be modelled to specify the interaction that best suits the activity requirements, there is high flexibility and generalisability. Moreover, template libraries can be created and reused in different processes. We provide a reference implementation and build a library of templates for a well-known set of responsibilities.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-014.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-014.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Cristina Cabanillas]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[cristina.cabanillas@wu.ac.at]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Vienna University of Economics and Business, Austria]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Manuel Resinas,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[resinas@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Seville, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/014]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Automated analysis of cloud offerings for optimal service provisioning (Summary)</title>
		<link>https://biblioteca.sistedes.es/articulo/automated-analysis-of-cloud-offerings-for-optimal-service-provisioning-summary/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/automated-analysis-of-cloud-offerings-for-optimal-service-provisioning-summary/</guid>
		<description></description>
		<content><![CDATA[Resumen de la contribución

La aparición del paradigma de la computación en la nube ha conllevado un cambio significativo dentro de la industria de las tecnologías de la información, tanto para proveedores de servicios como para los propios consumidores. Así, existen servicios como los de Amazon Elastic Computing Cloud (EC2) o Google Compute Engine que ofrecen computación virtualizada y almacenamiento de recursos (comúmente denominados Infraestructuras como Servicios o IaaS por sus siglas en inglés), de forma que los clientes pueden adquirirlos para reducir los costes de operación de sus sistemas, en comparación con el aprovisionamiento de las mismas infraestructuras de computación en un entorno local. Sin embargo, el aprovisionamiento de servicios en la nube resulta una tarea muy compleja dada la abrumadora variedad de proveedores, configuraciones y opciones de compra disponibles. En este escenario aparecen además diversas dificultades para comparar las ofertas de los distintos proveedores, debido a la heterogeneidad en la descripción de las configuraciones, opciones de compra, o incluso descuentos aplicables. A su vez, las necesidades concretas de los consumidores podrían incluir restricciones adicionales para tener en cuenta una planificación temporal previa en cuanto al número de instancias de IaaS que necesitarán en determinados momentos. Aunque existen algunas herramientas y calculadoras on-line que permiten buscar configuraciones concretas de IaaS, éstas no tienen en cuenta cuestiones como la planificación y la optimización de las opciones de compra. En este trabajo presentamos un framework de análisis automático que es capaz de analizar y comparar ofertas de servicios en la nube de distintos proveedores para obtener un plan de aprovisionamiento óptimo de acuerdo con las necesidades de los consumidores. Dicho plan especifica la cantidad y el tipo de instancias de IaaS que deben adquirirse, junto con la planificación de su uso. Hemos desarrollado un prototipo que ha sido validado en un escenario de virtualización de clases de laboratorio, comparando las opciones de dos proveedores.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3130</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[automated-analysis-of-cloud-offerings-for-optimal-service-provisioning-summary]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Resumen de la contribución

La aparición del paradigma de la computación en la nube ha conllevado un cambio significativo dentro de la industria de las tecnolog??as de la información, tanto para proveedores de servicios como para los propios consumidores. As??, existen servicios como los de Amazon Elastic Computing Cloud (EC2) o Google Compute Engine que ofrecen computación virtualizada y almacenamiento de recursos (comúmente denomi- nados Infraestructuras como Servicios o IaaS por sus siglas en inglés), de forma que los clientes pueden adquirirlos para reducir los costes de operación de sus sistemas, en comparación con el aprovisionamiento de las mismas infraestructuras de computación en un entorno local. Sin embargo, el aprovisionamiento de servicios en la nube resulta una tarea muy compleja dada la abrumadora variedad de proveedores, configuraciones y opciones de compra disponibles. En este escenario aparecen además diversas dificultades para comparar las ofer- tas de los distintos proveedores, debido a la heterogeneidad en la descripción de las configuraciones, opciones de compra, o incluso descuentos aplicables. A su vez, las ne- cesidades concretas de los consumidores podr??an incluir restricciones adicionales para tener en cuenta una planificación temporal previa en cuanto al número de instancias de IaaS que necesitarán en determinados momentos. Aunque existen algunas herramientas y calculadoras on-line que permiten buscar configuraciones concretas de IaaS, éstas no tienen en cuenta cuestiones como la plani- ficación y la optimización de las opciones de compra. En este trabajo presentamos un framework de análisis automático que es capaz de analizar y comparar ofertas de ser- vicios en la nube de distintos proveedores para obtener un plan de aprovisionamiento óptimo de acuerdo con las necesidades de los consumidores. Dicho plan especifica la cantidad y el tipo de instancias de IaaS que deben adquirirse, junto con la planificación de su uso. Hemos desarrollado un prototipo que ha sido validado en un escenario de virtualización de clases de laboratorio, comparando las opciones de dos proveedores. ]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-015.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-015.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[José María García]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[josemgarcia@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Octavio Mart??n-D??az]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[omartindiaz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Pablo Fernandez,]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[pablofm@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Antonio Ruiz-Cortés]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[aruiz@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Miguel Toro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[migueltoro@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/015]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Entorno extensible para la monitorización y detección de síntomas de depresión</title>
		<link>https://biblioteca.sistedes.es/articulo/entorno-extensible-para-la-monitorizacion-y-deteccion-de-sintomas-de-depresion/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/entorno-extensible-para-la-monitorizacion-y-deteccion-de-sintomas-de-depresion/</guid>
		<description></description>
		<content><![CDATA[La depresión es una enfermedad silenciosa que está aumentando de forma alarmante debido al ritmo de vida de la sociedad. Los propios síntomas de la depresión hacen que los pacientes se enfrenten a barreras psicológicas que dificultan la búsqueda de tratamiento. Actualmente, los dispositivos móviles están siendo usados para monitorizar el comportamiento de las personas y, así, identificar si presentan distintas enfermedades. En este artículo se presenta un conjunto de aplicaciones que detectan síntomas de depresión de forma pasiva para el usuario, reduciendo los posibles obstáculos para la identificación de esta enfermedad. Estas aplicaciones han sido desarrolladas para que los datos monitorizados puedan ser reutilizados por otros sistemas, sin que ello conlleve un incremento en el consumo de recursos.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3131</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[entorno-extensible-para-la-monitorizacion-y-deteccion-de-sintomas-de-depresion]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="contexto"><![CDATA[Contexto]]></category>
		<category domain="post_tag" nicename="depresion"><![CDATA[Depresión]]></category>
		<category domain="post_tag" nicename="salud"><![CDATA[Salud]]></category>
		<category domain="post_tag" nicename="telefono-inteligente"><![CDATA[Teléfono Inteligente]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[La depresión es una enfermedad silenciosa que está aumen- tando de forma alarmante debido al ritmo de vida de la sociedad. Los propios s??ntomas de la depresión hacen que los pacientes se enfrenten a barreras psicológicas que dificultan la búsqueda de tratamiento. Actual- mente, los dispositivos móviles están siendo usados para monitorizar el comportamiento de las personas y, así, identificar si presentan distintas enfermedades. En este art??culo se presenta un conjunto de aplicaciones que detectan síntomas de depresión de forma pasiva para el usuario, redu- ciendo los posibles obstáculos para la identificación de esta enfermedad. Estas aplicaciones han sido desarrolladas para que los datos monitoriza- dos puedan ser reutilizados por otros sistemas, sin que ello conlleve un incremento en el consumo de recursos.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-016.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-016.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Javier Berrocal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[jberolm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[José Garcia-Alonso]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[jgaralo@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Daniel Flores-Martin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[dfloresm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Jaime Galán-Jiménez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[jaime@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_5]]></meta_key>
			<meta_value><![CDATA[Alejandro Pérez-Vereda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_5]]></meta_key>
			<meta_value><![CDATA[apvereda@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_5]]></meta_key>
			<meta_value><![CDATA[University of Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_6]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_6]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_6]]></meta_key>
			<meta_value><![CDATA[University of Málaga, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_7]]></meta_key>
			<meta_value><![CDATA[Juan M. Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_7]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_7]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/016]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un Framework de Programación Dinámica para IoT</title>
		<link>https://biblioteca.sistedes.es/articulo/un-framework-de-programacion-dinamica-para-iot/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/un-framework-de-programacion-dinamica-para-iot/</guid>
		<description></description>
		<content><![CDATA[El crecimiento del Internet of Things está permitiendo la conexión a la red de muchos dispositivos. La tecnología debería permitir a estos dispositivos adaptarse automáticamente a las necesidades de sus usuarios. Con este propósito, desarrollamos en trabajos anteriores la arquitectura de referencia People as a Service, para crear perfiles virtuales de los usuarios almacenados en sus smartphones. Sin embargo, para la obtención de un perfil completo necesitamos información de contexto, que solo pueden proporcionarnos estos dispositivos del entorno. Nuestro objetivo es desarrollar un framework en el que usuarios y dispositivos conectados se integren de manera transparente y dinámica, permitiendo una actualización programática de los perfiles y el comportamiento de los dispositivos. De esta forma, damos un primer paso hacia un Mundo Programable.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3132</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-framework-de-programacion-dinamica-para-iot]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="beacons"><![CDATA[Beacons]]></category>
		<category domain="post_tag" nicename="framework-de-programacion"><![CDATA[Framework de programación]]></category>
		<category domain="post_tag" nicename="internet-of-things"><![CDATA[Internet of Things]]></category>
		<category domain="post_tag" nicename="mundo-programable"><![CDATA[Mundo Programable]]></category>
		<category domain="post_tag" nicename="people-as-a-service"><![CDATA[People as a Service]]></category>
		<category domain="post_tag" nicename="perfiles-virtuales-de-usuarios"><![CDATA[Perfiles virtuales de usuarios]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El crecimiento del Internet of Things está permitiendo la conexión a la red de muchos dispositivos. La tecnología debería permitir a estos dispositivos adaptarse automáticamente a las necesidades de sus usuarios. Con este propósito, desarrollamos en trabajos anteriores la arquitectura de referencia People as a Ser- vice, para crear perfiles virtuales de los usuarios almacenados en sus smartpho- nes. Sin embargo, para la obtención de un perfil completo necesitamos informa- ción de contexto, que solo pueden proporcionarnos estos dispositivos del entorno. Nuestro objetivo es desarrollar un framework en el que usuarios y dispositivos conectados se integren de manera transparente y dinámica, permitiendo una ac- tualización programática de los perfiles y el comportamiento de los dispositivos. De esta forma, damos un primer paso hacia un Mundo Programable.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-018.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-018.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Alejandro Pérez-Vereda]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[apvereda@uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[University of Malaga]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Daniel Flores-Martin]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[dfloresm@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Carlos Canal]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[canal@lcc.uma.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Juan M. Murillo]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[juanmamu@unex.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[University of Extremadura, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/017]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Un breve estudio sobre las metodologías para el proceso de “Service Design”</title>
		<link>https://biblioteca.sistedes.es/articulo/un-breve-estudio-sobre-las-metodologias-para-el-proceso-de-service-design/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/un-breve-estudio-sobre-las-metodologias-para-el-proceso-de-service-design/</guid>
		<description></description>
		<content><![CDATA[El sector servicios es en la actualidad uno de los más importantes en la economía mundial y el diseño de servicios es una actividad clave dentro de este sector. A pesar de ello, existen muy pocos estudios que profundicen en cómo deben llevarse a cabo esta actividad. Es por ello, que este trabajo pretende estudiar brevemente las diferentes aportaciones existentes en la literatura sobre cómo llevar a cabo el proceso de “Service Design”. Dicho estudio se ha realizado siguiendo el método de revisión sistemática de la literatura. Como resultado se han obtenido 14 estudios primarios. Una vez efectuado este estudio se ha podido percibir la importancia de dos componentes fundamentales, la co-creation y la experiencia del cliente, los cuales son indispensable en una metodología que permita diseñar servicios cada vez más adaptados al mercado actual.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3133</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[un-breve-estudio-sobre-las-metodologias-para-el-proceso-de-service-design]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="creacion-de-servicio"><![CDATA[Creación de servicio]]></category>
		<category domain="post_tag" nicename="diseno-de-servicios"><![CDATA[Diseño de servicios]]></category>
		<category domain="post_tag" nicename="herramienta"><![CDATA[Herramienta]]></category>
		<category domain="post_tag" nicename="innovacion-de-servicio"><![CDATA[Innovación de servicio]]></category>
		<category domain="post_tag" nicename="metodologia"><![CDATA[Metodología]]></category>
		<category domain="post_tag" nicename="modelo"><![CDATA[Modelo]]></category>
		<category domain="post_tag" nicename="servitizacion"><![CDATA[Servitización]]></category>
		<category domain="post_tag" nicename="tecnica"><![CDATA[Técnica]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[El sector servicios es en la actualidad uno de los más importantes en la economía mundial y el diseño de servicios es una actividad clave dentro de este sector. A pesar de ello, existen muy pocos estudios que profundicen en cómo deben llevarse a cabo esta actividad. Es por ello, que este trabajo pretende estu- diar brevemente las diferentes aportaciones existentes en la literatura sobre cómo llevar a cabo el proceso de “Service Design”. Dicho estudio se ha realizado si- guiendo el método de revisión sistemática de la literatura. Como resultado se han obtenido 14 estudios primarios. Una vez efectuado este estudio se ha podido per- cibir la importancia de dos componentes fundamentales, la co-creation y la ex- periencia del cliente, los cuales son indispensable en una metodología que per- mita diseñar servicios cada vez más adaptados al mercado actual.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-019.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-019.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Maricela Salgado]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[maricela.salgado@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Calle Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Esperanza Marcos]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[esperanza.marcos@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Calle Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Juan M. Vara, Marcos López]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[juanmanuel.vara@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Calle Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[Marí­a Valeria De Castro]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[valeria.decastro@urjc.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Grupo de Investigación Kybele, Universidad Rey Juan Carlos Calle Tulipán S/N, 28933 Móstoles, Madrid, España]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/018]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Towards a new Tool for Managing Declarative Temporal Business Process Models</title>
		<link>https://biblioteca.sistedes.es/articulo/towards-a-new-tool-for-managing-declarative-temporal-business-process-models/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/towards-a-new-tool-for-managing-declarative-temporal-business-process-models/</guid>
		<description></description>
		<content><![CDATA[Business processes which require a high flexibility are com- monly specified in a declarative (e.g., constraint-based) way. In general, offering operational support (e.g., generating possible execution traces) to declarative business process models entails more complexity when compared to imperative modeling alternatives. Such support becomes even more complex in many real scenarios where the management of complex temporal relations between the process activities is crucial (i.e., the temporal perspective should be managed). Despite the needs for enabling process flexibility and dealing with temporal constraints, most existing tools are unable to manage both. In a previous work, we then proposed TConDec-R, which is a constraint-based process modeling lan- guage which allows for the specification of temporal constraints. In this paper we introduce the basis and a prototype of a constraint-based tool with a client/server architecture for providing operational support to TConDec-R process models.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3134</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[towards-a-new-tool-for-managing-declarative-temporal-business-process-models]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="business-process-modeling-support"><![CDATA[business process modeling support]]></category>
		<category domain="post_tag" nicename="constraint-programming"><![CDATA[Constraint programming]]></category>
		<category domain="post_tag" nicename="constraint-satisfaction-problems"><![CDATA[constraint satisfaction problems]]></category>
		<category domain="post_tag" nicename="process-flexibility"><![CDATA[process flexibility]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Business processes which require a high flexibility are com- monly specified in a declarative (e.g., constraint-based) way. In general, offering operational support (e.g., generating possible execution traces) to declarative business process models entails more complexity when compared to imperative modeling alternatives. Such support becomes even more complex in many real scenarios where the management of complex temporal relations between the process activities is crucial (i.e., the temporal perspective should be managed). Despite the needs for en- abling process flexibility and dealing with temporal constraints, most existing tools are unable to manage both. In a previous work, we then proposed TConDec-R, which is a constraint-based process modeling lan- guage which allows for the specification of temporal constraints. In this paper we introduce the basis and a prototype of a constraint-based tool with a client/server architecture for providing operational support to TConDec-R process models.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-020.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-020.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Andrés Jiménez-Ramírez]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[ajramirez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Irene Barba]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[irenebr@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Carmelo del Valle]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[carmelo@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Departamento de Lenguajes y Sistemas Informáticos, Universidad de Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/019]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
	<item>
		<title>Análisis de los datos y coreografia de múltiples procesos en entornos logísticos</title>
		<link>https://biblioteca.sistedes.es/articulo/analisis-de-los-datos-y-coreografia-de-multiples-procesos-en-entornos-logisticos/</link>
		<pubDate>Thu, 02 Aug 2018 16:53:02 +0000</pubDate>
		<creator><![CDATA[efreimen]]></creator>
		<guid isPermaLink="false">https://biblioteca.sistedes.es/articulo/analisis-de-los-datos-y-coreografia-de-multiples-procesos-en-entornos-logisticos/</guid>
		<description></description>
		<content><![CDATA[Los procesos de negocio permiten la descripción de modelos colaborativos donde varios procesos y sus instancias se puedan coreografiar. Un ejemplo de la dificultad que implican dichos procesos se encuentra en los entornos logísticos, donde instancias de diferentes procesos y con diferentes cardinalidades deben de trabajar para alcanzar un objetivo común. En este trabajo se identifican el conjunto de retos a resolver para facilitar la incorporación de la ingeniería de los procesos de negocio a entornos logísticos. En el artículo se analizan además los trabajos previos, y se esboza una solución basada en el análisis de los artefactos de datos involucrados y la capacidad del modelado orientado a actividades de los procesos de negocios.]]></content>
		<excerpt><![CDATA[]]></excerpt>
		<post_id>3135</post_id>
		<post_date><![CDATA[2018-08-02 18:53:02]]></post_date>
		<post_date_gmt><![CDATA[2018-08-02 16:53:02]]></post_date_gmt>
		<comment_status><![CDATA[closed]]></comment_status>
		<ping_status><![CDATA[closed]]></ping_status>
		<post_name><![CDATA[analisis-de-los-datos-y-coreografia-de-multiples-procesos-en-entornos-logisticos]]></post_name>
		<status><![CDATA[publish]]></status>
		<post_parent>0</post_parent>
		<menu_order>0</menu_order>
		<post_type><![CDATA[articulo]]></post_type>
		<post_password><![CDATA[]]></post_password>
		<is_sticky>0</is_sticky>
		<category domain="author" nicename="cap-efreimen"><![CDATA[efreimen]]></category>
		<category domain="post_tag" nicename="artefactos"><![CDATA[Artefactos]]></category>
		<category domain="post_tag" nicename="coreografia-de-procesos-de-negocio"><![CDATA[Coreografia de Procesos de Negocio]]></category>
		<category domain="post_tag" nicename="procesos-de-logstica"><![CDATA[Procesos de Log??stica]]></category>
		<postmeta>
			<meta_key><![CDATA[abstract]]></meta_key>
			<meta_value><![CDATA[Los procesos de negocio permiten la descripción de mode- los colaborativos donde varios procesos y sus instancias se puedan core- ografiar. Un ejemplo de la dificultad que implican dichos procesos se encuentra en los entornos log??sticos, donde instancias de diferentes pro- cesos y con diferentes cardinalidades deben de trabajar para alcanzar un objetivo común. En este trabajo se identifican el conjunto de retos a resolver para facilitar la incorporación de la ingeniería de los procesos de negocio a entornos logísticos. En el artículo se analizan además los trabajos previos, y se esboza una solución basada en el análisis de los artefactos de datos involucrados y la capacidad del modelado orientado a actividades de los procesos de negocios.]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[autorizacion]]></meta_key>
			<meta_value><![CDATA[CreativeCommons Reconocimiento (by)]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-021.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[paper_pdf_file]]></meta_key>
			<meta_value><![CDATA[descargas/2018/JCIS/2018-JCIS-021.pdf]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_1]]></meta_key>
			<meta_value><![CDATA[Kevin Daniel Cisneros Carreño]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_1]]></meta_key>
			<meta_value><![CDATA[kev.cisn@hotmail.com]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_1]]></meta_key>
			<meta_value><![CDATA[Tecnológico Nacional de México, Instituto Tecnológico de Zacatepec, México]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_2]]></meta_key>
			<meta_value><![CDATA[Angel Jesus Varela Vaca]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_2]]></meta_key>
			<meta_value><![CDATA[ajvarela@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_2]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_3]]></meta_key>
			<meta_value><![CDATA[Luisa Parody]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_3]]></meta_key>
			<meta_value><![CDATA[mlparody@uloyola.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_3]]></meta_key>
			<meta_value><![CDATA[Universidad Loyola Andalucía, Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_name_4]]></meta_key>
			<meta_value><![CDATA[María Teresa Gómez-López]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_email_4]]></meta_key>
			<meta_value><![CDATA[maytegomez@us.es]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[author_univ_4]]></meta_key>
			<meta_value><![CDATA[Universidad de Sevilla, Sevilla, Spain]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[handle]]></meta_key>
			<meta_value><![CDATA[11705/JCIS/2018/020]]></meta_value>
		</postmeta>
		<postmeta>
			<meta_key><![CDATA[_edit_last]]></meta_key>
			<meta_value><![CDATA[5]]></meta_value>
		</postmeta>
	</item>
</rss>
